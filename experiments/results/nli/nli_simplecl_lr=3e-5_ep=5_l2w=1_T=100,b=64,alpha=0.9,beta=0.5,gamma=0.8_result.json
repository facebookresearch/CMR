{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/snli_bart-base_1109_upstream_model/best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/nli/er/nli_simplecl_lr=3e-5_ep=5_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=10, kg_eval_mode='metric', kr_eval_freq=10, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=5.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=10, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/nli/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/nli/nli_simplecl_lr=3e-5_ep=5_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8_result.json', submission_stream_data='experiments/eval_data/nli/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/nli/upstream_eval.jsonl')", "model_update_steps": 5, "online_eval_results": [{"timecode": 0, "UKR": 0.91015625, "KG": 0.587890625, "before_eval_results": {"predictions": ["entailment", "neutral", "entailment", "contradiction", "neutral", "neutral", "entailment", "neutral", "contradiction", "neutral", "entailment", "entailment", "contradiction", "contradiction", "entailment", "entailment", "neutral", "contradiction", "entailment", "contradiction", "contradiction", "neutral", "contradiction", "contradiction", "entailment", "entailment", "entailment", "neutral", "contradiction", "neutral", "entailment", "entailment", "contradiction", "neutral", "neutral", "contradiction", "neutral", "entailment", "entailment", "entailment", "contradiction", "contradiction", "contradiction", "neutral", "neutral", "contradiction", "neutral", "entailment", "neutral", "contradiction", "entailment", "contradiction", "entailment", "entailment", "entailment", "contradiction", "entailment", "entailment", "entailment", "entailment", "neutral", "entailment", "entailment", "entailment"], "metric_results": {"EM": 0.890625, "QA-F1": 0.890625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["snli-validation-4990", "snli-validation-2182", "snli-validation-5881", "snli-validation-1790", "snli-validation-3303", "snli-validation-7154", "snli-validation-5834"], "SR": 0.890625, "CSR": 0.890625, "EFR": 1.0, "Overall": 0.9453125}]}