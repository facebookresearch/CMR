{"method_class": "er", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/QA_er_lr=3e-5_ep=10_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.9,gamma=0.8', gradient_accumulation_steps=1, inference_query_size=1, init_memory_cache_path='na', kg_eval_freq=10, kg_eval_mode='metric', kr_eval_freq=10, kr_eval_mode='metric', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='experiments/ckpt_dirs/qa/er/QA_er_lr=3e-5_ep=10_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.9,gamma=0.8/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, replay_candidate_size=8, replay_frequency=1, replay_size=64, save_ckpt_freq=10, skip_instant_eval=False, total_steps=10000, upstream_sample_ratio=0.5, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/QA_er_lr=3e-5_ep=10_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.9,gamma=0.8_result.json', submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.9,gamma=0.8.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 11730, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["a combination of anthrax and other pandemics", "Children in Need", "July 2013", "4 August 1915 until November 1918", "three hundred years", "Cultural imperialism", "caning", "three to five", "weak labor movements", "a school or other place of formal education", "agricola", "Denmark, Iceland and Norway", "colonizing empires", "removed some parts", "Los Angeles Times", "Richard Lindzen", "nineteenth-century cartographic techniques", "1903", "Japan", "international metropolitan region", "United States", "ash leaf", "the problem of multiplying two integers", "an official school sport", "Hong Kong", "Book of Common Prayer", "until 1796", "full independent prescribing authority", "democracy", "a mainline Protestant Methodist denomination", "Michael Eisner", "Slipback", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Jerusalem", "pH or available iron", "Bart Starr", "the disbelieving (Kafir) colonial powers", "cryptomonads", "on Fresno's far southeast side", "four", "Demaryius Thomas", "faith", "William Hartnell's poor health", "Annual Conference Order of Elders", "Any member", "Thomas Reid and Dugald Stewart", "Kurt Vonnegut", "Paul Revere", "Warszawa", "the instance", "he sent missionaries", "fourteen", "Zhongtong", "Del\u00fc\u00fcn Boldog", "Rev. Paul T. Stallsworth", "market", "73", "20.8%", "live", "free", "inequality", "260 kilometres", "The Daleks", "a Latin translation of the Qur'an"], "metric_results": {"EM": 0.84375, "QA-F1": 0.86171875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-1891", "mrqa_squad-validation-1766", "mrqa_squad-validation-9918", "mrqa_squad-validation-4662", "mrqa_squad-validation-2372", "mrqa_squad-validation-3119", "mrqa_squad-validation-3130", "mrqa_squad-validation-7527", "mrqa_squad-validation-7574", "mrqa_squad-validation-2289"], "SR": 0.84375, "CSR": 0.84375, "EFR": 1.0, "Overall": 0.921875}, {"timecode": 1, "before_eval_results": {"predictions": ["canceled", "photooxidative damage", "Spain", "too much grief", "Ps. 31:5", "five", "applications such as on-line betting, financial applications", "Josh Norman", "DuMont", "24", "Dutch Cape Colony", "Buckland Valley", "The Curse of the Daleks", "lecture theatre", "progressivity", "convenience of the railroad and worried about flooding", "Roman", "mid-18th century", "WatchESPN", "co-chair", "Mike Carey", "Mick Mixon", "Sweynforkbeard", "starch", "1% to 3%", "European People's Party", "15 February 1546", "DNA results may be flawed", "northern China", "Institute for Policy Studies", "Port of Long Beach", "Pannerdens Kanaal", "underpinning", "proplastids", "Teenage Mutant Ninja Turtles: Out of the Shadows", "strong sedimentation", "elect and appoint bishops", "prime ideals", "lower incomes", "near their current locations", "Catholicism", "cartels", "Titian", "Pattern recognition receptors", "1275", "5 to 15 years", "August 1967", "Arabic numerals", "3:08", "Jamukha", "England", "EastEnders", "A fundamental error", "quantum", "water", "c1180", "heart disease, chronic pain, and asthma", "end of the Pleistocene", "It says \"Adam Trask was born on a farm on the outskirts of a little town which was not far from a big town in Connecticut", "It's the only NBA team name that uses a state nickname", "In 1879 the existing settlement was incorporated and named Crookston, after... drove the first spike of the St. Paul & Pacific Railroad, the first railroad in Minnesota", "At one of their seances a man tied the brothers so tightly that it was neces", "What separates a Cyberpunk setting from a", "unemployment benefits"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7578004807692308}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.7499999999999999, 0.08, 0.16666666666666666, 0.0, 0.0, 0.33333333333333337, 0.10256410256410257]}}, "before_error_ids": ["mrqa_squad-validation-1500", "mrqa_squad-validation-5835", "mrqa_squad-validation-7307", "mrqa_squad-validation-2226", "mrqa_squad-validation-8558", "mrqa_squad-validation-1092", "mrqa_squad-validation-8597", "mrqa_squad-validation-4999", "mrqa_squad-validation-3355", "mrqa_squad-validation-8927", "mrqa_squad-validation-3165", "mrqa_squad-validation-4528", "mrqa_squad-validation-9145", "mrqa_searchqa-validation-16816", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-4674", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-541", "mrqa_newsqa-validation-160"], "SR": 0.703125, "CSR": 0.7734375, "retrieved_ids": ["mrqa_squad-train-45101", "mrqa_squad-train-22084", "mrqa_squad-train-41929", "mrqa_squad-train-24506", "mrqa_squad-train-63778", "mrqa_squad-train-15341", "mrqa_squad-train-73670", "mrqa_squad-train-33883", "mrqa_squad-train-56717", "mrqa_squad-train-5831", "mrqa_squad-train-82869", "mrqa_squad-train-78785", "mrqa_squad-train-67158", "mrqa_squad-train-57627", "mrqa_squad-train-27034", "mrqa_squad-train-83975", "mrqa_squad-train-59994", "mrqa_squad-train-69505", "mrqa_squad-train-71285", "mrqa_squad-train-48367", "mrqa_squad-train-13150", "mrqa_squad-train-15940", "mrqa_squad-train-41089", "mrqa_squad-train-76760", "mrqa_squad-train-48237", "mrqa_squad-train-65285", "mrqa_squad-train-61274", "mrqa_squad-train-12091", "mrqa_squad-train-25807", "mrqa_squad-train-47170", "mrqa_squad-train-11432", "mrqa_squad-train-9318", "mrqa_squad-validation-3130", "mrqa_squad-validation-3119", "mrqa_squad-validation-1766", "mrqa_squad-validation-9918", "mrqa_squad-validation-2372", "mrqa_squad-validation-7574", "mrqa_squad-validation-1891", "mrqa_squad-validation-7527", "mrqa_squad-validation-2289", "mrqa_squad-validation-4662"], "EFR": 1.0, "Overall": 0.88671875}, {"timecode": 2, "before_eval_results": {"predictions": ["night", "animosity toward each other", "Jan Andrzej Menich", "49\u201315", "10", "infrequent rain", "Chicago Theological Seminary", "upper sixth", "delay in the CSM caused by the fire", "1971", "Thomas Edison", "Children of Earth", "WTRF-TV", "picture thinking", "1066", "BBC 1", "one", "two", "Over 61", "Genghis Khan", "an innate force of impetus", "24\u201310", "Newcastle", "1887", "It requires the pupil to remain in school at a given time in the school day (such as lunch, recess or after school); or even to attend school on a non-school day", "torn down", "punts", "\u00a320,980", "2011", "Khuruldai", "SAP Center", "NBA", "1724 to 1725", "Two thirds", "the courts of member states and the Court of Justice of the European Union", "Jim Gray", "Fort Beaus\u00e9jour", "Queen Victoria and Prince Albert", "Education", "oxyacetylene", "war, famine, and weather", "Wesel-Datteln Canal", "TLC", "on the south side of the garden", "novel", "friendly and supportive", "Eero Saarinen", "Newton", "41", "that he may have intercepted Marconi's European experiments", "The Lodger", "1954", "the pastrami", "Fondue", "the Green Hornet", "the scrum-half", "Danskin", "London", "the Old French and Latin words meant \"bloody, blood-colored\"", "New Hampshire", "Sequoyah Nuclear Plant", "a boardinghouse for beagles or borzois", "1 April 1985", "Ford Motor Company"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7847581417624521}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0689655172413793, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-236", "mrqa_squad-validation-4015", "mrqa_squad-validation-3699", "mrqa_squad-validation-2920", "mrqa_squad-validation-1941", "mrqa_squad-validation-5525", "mrqa_squad-validation-6393", "mrqa_squad-validation-1529", "mrqa_squad-validation-7687", "mrqa_searchqa-validation-5963", "mrqa_searchqa-validation-5539", "mrqa_searchqa-validation-1701", "mrqa_searchqa-validation-14790", "mrqa_searchqa-validation-10193", "mrqa_searchqa-validation-6374", "mrqa_searchqa-validation-9403", "mrqa_hotpotqa-validation-1297"], "SR": 0.734375, "CSR": 0.7604166666666666, "retrieved_ids": ["mrqa_squad-train-39060", "mrqa_squad-train-38954", "mrqa_squad-train-14229", "mrqa_squad-train-19568", "mrqa_squad-train-39050", "mrqa_squad-train-53700", "mrqa_squad-train-2123", "mrqa_squad-train-78755", "mrqa_squad-train-84202", "mrqa_squad-train-23011", "mrqa_squad-train-28558", "mrqa_squad-train-66185", "mrqa_squad-train-59541", "mrqa_squad-train-9577", "mrqa_squad-train-85958", "mrqa_squad-train-43353", "mrqa_squad-train-22022", "mrqa_squad-train-66657", "mrqa_squad-train-84505", "mrqa_squad-train-9711", "mrqa_squad-train-71672", "mrqa_squad-train-73010", "mrqa_squad-train-71505", "mrqa_squad-train-32823", "mrqa_squad-train-12365", "mrqa_squad-train-50825", "mrqa_squad-train-16260", "mrqa_squad-train-50936", "mrqa_squad-train-69753", "mrqa_squad-train-50521", "mrqa_squad-train-70727", "mrqa_squad-train-69069", "mrqa_squad-validation-1092", "mrqa_squad-validation-7527", "mrqa_squad-validation-4528", "mrqa_squad-validation-8558", "mrqa_squad-validation-2289", "mrqa_squad-validation-4662", "mrqa_squad-validation-4999", "mrqa_squad-validation-8927", "mrqa_searchqa-validation-4674", "mrqa_squad-validation-2372", "mrqa_squad-validation-9918", "mrqa_squad-validation-1500", "mrqa_squad-validation-7574", "mrqa_squad-validation-1766", "mrqa_squad-validation-3130", "mrqa_squad-validation-2226", "mrqa_searchqa-validation-4266", "mrqa_newsqa-validation-160", "mrqa_squad-validation-9145", "mrqa_searchqa-validation-541", "mrqa_squad-validation-3165", "mrqa_squad-validation-3355", "mrqa_squad-validation-3119", "mrqa_squad-validation-8597", "mrqa_searchqa-validation-16816", "mrqa_searchqa-validation-11770", "mrqa_squad-validation-1891", "mrqa_squad-validation-7307", "mrqa_squad-validation-5835"], "EFR": 1.0, "Overall": 0.8802083333333333}, {"timecode": 3, "before_eval_results": {"predictions": ["1474", "average teacher salaries", "mother-of-pearl", "Elizabeth", "technological superiority", "four classes", "San Joaquin Light & Power Building", "1972", "three", "science fiction", "behavioral and demographic", "David McLetchie", "north", "the Legislative Assembly", "African-American", "few British troops", "12.5 acres", "technical problems and flight delays", "the US Supreme Court", "trust God's word", "The zeta function", "those who proceed to secondary school or vocational training", "139th out of 176 total countries", "eight", "kinetic friction force", "early 1526", "1939", "1986", "Black's Law Dictionary", "November 28, 1995", "the head of government", "ten", "1 a.m.", "Department of State Affairs", "occupational stress among teachers", "with a rolling circle mechanism", "San Jose", "7.8%", "three", "Bainbridge's", "WBT", "cellular respiration", "Giuliano da Sangallo", "2009", "that the individual circumstances of a patient justify waiting lists, and this is also true in the context of the UK's National Health Service", "BBC HD", "Byker", "Genoa", "the Common Core State Standards", "Chickamauga", "a brown one with gold mane is one of the tier 2 horses", "National Center for Physical Acoustics", "Gaius Maecenas", "The Silmarillion", "the Kings of Denmark, Bavaria, and Wrttemberg", "the Student loan Scheme", "the legendary magician/comedian pair Penn & Teller", "the Opera", "Albert Spalding", "John Osborne", "Nineteen Eighty-Four", "the Barbizon school", "Harry Potter", "a mansard roof"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7146577380952381}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1662", "mrqa_squad-validation-9533", "mrqa_squad-validation-6809", "mrqa_squad-validation-4462", "mrqa_squad-validation-5456", "mrqa_searchqa-validation-12119", "mrqa_searchqa-validation-2022", "mrqa_searchqa-validation-9109", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-13077", "mrqa_searchqa-validation-9548", "mrqa_searchqa-validation-10925", "mrqa_searchqa-validation-10318", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-198", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9733", "mrqa_searchqa-validation-3102", "mrqa_searchqa-validation-12876", "mrqa_triviaqa-validation-412"], "SR": 0.6875, "CSR": 0.7421875, "retrieved_ids": ["mrqa_squad-train-24180", "mrqa_squad-train-31941", "mrqa_squad-train-63461", "mrqa_squad-train-5112", "mrqa_squad-train-48807", "mrqa_squad-train-71527", "mrqa_squad-train-26445", "mrqa_squad-train-26333", "mrqa_squad-train-19064", "mrqa_squad-train-16205", "mrqa_squad-train-20267", "mrqa_squad-train-15023", "mrqa_squad-train-34837", "mrqa_squad-train-4680", "mrqa_squad-train-84367", "mrqa_squad-train-3860", "mrqa_squad-train-84060", "mrqa_squad-train-68859", "mrqa_squad-train-65747", "mrqa_squad-train-36565", "mrqa_squad-train-46118", "mrqa_squad-train-45458", "mrqa_squad-train-68973", "mrqa_squad-train-64669", "mrqa_squad-train-85476", "mrqa_squad-train-17641", "mrqa_squad-train-75345", "mrqa_squad-train-27746", "mrqa_squad-train-52978", "mrqa_squad-train-47959", "mrqa_squad-train-36380", "mrqa_squad-train-56417", "mrqa_squad-validation-3130", "mrqa_squad-validation-2289", "mrqa_squad-validation-6393", "mrqa_squad-validation-8558", "mrqa_searchqa-validation-10193", "mrqa_squad-validation-1092", "mrqa_squad-validation-236", "mrqa_searchqa-validation-9403", "mrqa_hotpotqa-validation-1297", "mrqa_squad-validation-5525", "mrqa_squad-validation-2920", "mrqa_searchqa-validation-16816", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-4674", "mrqa_squad-validation-1941", "mrqa_squad-validation-3355", "mrqa_squad-validation-1500", "mrqa_searchqa-validation-5963", "mrqa_squad-validation-9918", "mrqa_squad-validation-7527", "mrqa_squad-validation-3119", "mrqa_squad-validation-8927", "mrqa_searchqa-validation-1701", "mrqa_squad-validation-4528", "mrqa_searchqa-validation-541", "mrqa_searchqa-validation-5539", "mrqa_squad-validation-1766", "mrqa_squad-validation-2226", "mrqa_squad-validation-7307", "mrqa_squad-validation-4015", "mrqa_squad-validation-2372", "mrqa_squad-validation-7687"], "EFR": 0.95, "Overall": 0.84609375}, {"timecode": 4, "before_eval_results": {"predictions": ["1873", "Because everyday clothing from previous eras has not generally survived", "July 1969", "six", "the Lord's Prayer", "$5 million", "peroxide, superoxide, and singlet oxygen", "2.666 million", "Industry and manufacturing", "they don't have to be non-violent", "The Parish Church of St Andrew", "1262", "New Orleans", "April 1523", "Dating of lava and volcanic ash layers", "the Wesleyan Holiness Consortium", "26 seasons", "Suleiman the Magnificent", "James Bryant Conant", "2010", "accountants", "an imposed selective breeding version of eugenics", "15 May 1525", "lupus erythematosus", "Education", "cholera", "Monday", "Pickawillany", "plan the physical proceedings, and to integrate those proceedings with the other parts", "Cybermen", "graduate and undergraduate students", "16", "standard", "Lucas\u2013Lehmer", "Level 3 Communications", "the Ilkhanate", "1685", "19", "economically", "general and complete disarmament", "electromagnetic theory", "killed", "the Ark", "opera buffa", "Okinawa", "14", "the kidney", "potato pancake", "Basin Street", "Tarsus", "Paris", "Woody Allen", "Jane Austen", "Bob Schieffer", "Treasure Island", "Death Watch", "Charles Marion Russell", "Liqueur Devoille", "white", "The Crush", "September, 2016", "radius", "Alistair Grant", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6870873917748918}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.1212121212121212]}}, "before_error_ids": ["mrqa_squad-validation-2346", "mrqa_squad-validation-3543", "mrqa_squad-validation-6791", "mrqa_squad-validation-117", "mrqa_squad-validation-7653", "mrqa_squad-validation-1841", "mrqa_squad-validation-10506", "mrqa_squad-validation-4861", "mrqa_squad-validation-1215", "mrqa_searchqa-validation-14838", "mrqa_searchqa-validation-14398", "mrqa_searchqa-validation-5785", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-6962", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-6843", "mrqa_searchqa-validation-33", "mrqa_searchqa-validation-1843", "mrqa_searchqa-validation-11816", "mrqa_searchqa-validation-7852", "mrqa_naturalquestions-validation-1549", "mrqa_triviaqa-validation-4742", "mrqa_newsqa-validation-2983"], "SR": 0.640625, "CSR": 0.721875, "retrieved_ids": ["mrqa_squad-train-72129", "mrqa_squad-train-85765", "mrqa_squad-train-64851", "mrqa_squad-train-69819", "mrqa_squad-train-54769", "mrqa_squad-train-17812", "mrqa_squad-train-72346", "mrqa_squad-train-44277", "mrqa_squad-train-82912", "mrqa_squad-train-80878", "mrqa_squad-train-49361", "mrqa_squad-train-69619", "mrqa_squad-train-63865", "mrqa_squad-train-66291", "mrqa_squad-train-79315", "mrqa_squad-train-16100", "mrqa_squad-train-45187", "mrqa_squad-train-14808", "mrqa_squad-train-21193", "mrqa_squad-train-31541", "mrqa_squad-train-84991", "mrqa_squad-train-28085", "mrqa_squad-train-67516", "mrqa_squad-train-67202", "mrqa_squad-train-72651", "mrqa_squad-train-22993", "mrqa_squad-train-20906", "mrqa_squad-train-5784", "mrqa_squad-train-16379", "mrqa_squad-train-45973", "mrqa_squad-train-35840", "mrqa_squad-train-80503", "mrqa_squad-validation-7307", "mrqa_squad-validation-4999", "mrqa_squad-validation-1662", "mrqa_searchqa-validation-4674", "mrqa_searchqa-validation-3102", "mrqa_squad-validation-5456", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-13077", "mrqa_squad-validation-4662", "mrqa_squad-validation-6393", "mrqa_triviaqa-validation-412", "mrqa_squad-validation-5835", "mrqa_squad-validation-9918", "mrqa_searchqa-validation-9109", "mrqa_squad-validation-8597", "mrqa_squad-validation-6809", "mrqa_searchqa-validation-9548", "mrqa_squad-validation-3699", "mrqa_searchqa-validation-5963", "mrqa_searchqa-validation-6374", "mrqa_squad-validation-236", "mrqa_squad-validation-1941", "mrqa_squad-validation-2920", "mrqa_searchqa-validation-3441", "mrqa_squad-validation-1529", "mrqa_newsqa-validation-160", "mrqa_squad-validation-9145", "mrqa_squad-validation-2226", "mrqa_searchqa-validation-16816", "mrqa_searchqa-validation-10193", "mrqa_searchqa-validation-5539", "mrqa_searchqa-validation-4624"], "EFR": 1.0, "Overall": 0.8609375}, {"timecode": 5, "before_eval_results": {"predictions": ["an ash leaf", "75,000 to 100,000", "the 1970s", "King Gilgamesh of Uruk and Atilla the Hun", "The majority may be powerful but it is not necessarily right", "Hendrix v Employee Insurance Institute", "local government, sport and the arts, transport, training, tourism, research and statistics and social work", "SAP Center", "one-eighth the number of French Catholics", "Video On Demand content", "extended structure", "principle of equivalence", "pump this into the mesoglea", "closed system", "21 to 11", "The Earth's crustal rock", "to formalize a unified front in trade and negotiations with various Indians", "ten to fifteen", "the public PAD service Telepad", "a separate condenser", "to the North Sea", "Cam Newton", "requiring his arrest", "John Mayow", "state or government schools", "soluble components (molecules)", "45,000 pounds", "Gottfried Fritschel", "the third most abundant chemical element in the universe", "39", "a human", "metals", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "threatened \"Old Briton\" with severe consequences if he continued to trade with the British", "100\u20135,000 hp", "at Petitcodiac in 1755 and at Bloody Creek near Annapolis Royal in 1757", "a UNESCO World Heritage Site", "Frederick II the Great", "the action of propelling the ball toward the wicket defended by.... The origins of the game of cricket are lost in the mists of time.", "Donner", "(G) Parker", "the Dutch", "Monrovia", "umpires", "Taiwan", "Omaha", "Gigli", "Nez Perce", "George Gershwin", "New Funk And Wagnalls", "Oprah Winfrey", "sewing machines", "the Drazens", "Inchon", "February 29", "beetles", "Alabama", "Bennington", "Giorgio Armani", "the mint moved from London to a new 38 acres ( 15 ha ) plant in Llantrisant, Wales", "insects and their relationship to humans, other organisms, and the environment", "Squam Lake", "in the 20 years since the Berlin Wall has fallen there has been a renaissance of the game in the region", "the District of Columbia National Guard"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6247007737632737}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.5, 1.0, 0.07407407407407407, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 0.0, 0.0, 1.0, 0.1111111111111111, 1.0, 0.0, 0.9600000000000001, 1.0, 1.0, 0.1, 0.0, 0.4, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 0.15384615384615385, 0.888888888888889]}}, "before_error_ids": ["mrqa_squad-validation-9640", "mrqa_squad-validation-2976", "mrqa_squad-validation-4452", "mrqa_squad-validation-973", "mrqa_squad-validation-10214", "mrqa_squad-validation-9320", "mrqa_squad-validation-3559", "mrqa_squad-validation-639", "mrqa_squad-validation-7719", "mrqa_squad-validation-9489", "mrqa_squad-validation-1441", "mrqa_squad-validation-10274", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-16886", "mrqa_searchqa-validation-700", "mrqa_searchqa-validation-15748", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-5857", "mrqa_searchqa-validation-10823", "mrqa_searchqa-validation-2175", "mrqa_searchqa-validation-15847", "mrqa_searchqa-validation-3735", "mrqa_searchqa-validation-8845", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-7010", "mrqa_naturalquestions-validation-866", "mrqa_triviaqa-validation-3868", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-1289"], "SR": 0.53125, "CSR": 0.6901041666666667, "retrieved_ids": ["mrqa_squad-train-62184", "mrqa_squad-train-78761", "mrqa_squad-train-43542", "mrqa_squad-train-7511", "mrqa_squad-train-8800", "mrqa_squad-train-66781", "mrqa_squad-train-46662", "mrqa_squad-train-73069", "mrqa_squad-train-31663", "mrqa_squad-train-45776", "mrqa_squad-train-82904", "mrqa_squad-train-83065", "mrqa_squad-train-45378", "mrqa_squad-train-21671", "mrqa_squad-train-67358", "mrqa_squad-train-64315", "mrqa_squad-train-49468", "mrqa_squad-train-50890", "mrqa_squad-train-50924", "mrqa_squad-train-75161", "mrqa_squad-train-44559", "mrqa_squad-train-51000", "mrqa_squad-train-58103", "mrqa_squad-train-50531", "mrqa_squad-train-59670", "mrqa_squad-train-76590", "mrqa_squad-train-44374", "mrqa_squad-train-17657", "mrqa_squad-train-34295", "mrqa_squad-train-47776", "mrqa_squad-train-36747", "mrqa_squad-train-28026", "mrqa_squad-validation-2289", "mrqa_newsqa-validation-2983", "mrqa_squad-validation-10506", "mrqa_searchqa-validation-6374", "mrqa_searchqa-validation-10193", "mrqa_searchqa-validation-4624", "mrqa_squad-validation-5525", "mrqa_squad-validation-9918", "mrqa_naturalquestions-validation-1549", "mrqa_squad-validation-5835", "mrqa_squad-validation-4861", "mrqa_squad-validation-6809", "mrqa_searchqa-validation-14838", "mrqa_searchqa-validation-541", "mrqa_searchqa-validation-14790", "mrqa_searchqa-validation-10925", "mrqa_squad-validation-7653", "mrqa_searchqa-validation-3102", "mrqa_hotpotqa-validation-1297", "mrqa_searchqa-validation-16816", "mrqa_squad-validation-7527", "mrqa_searchqa-validation-9116", "mrqa_squad-validation-1891", "mrqa_squad-validation-4999", "mrqa_searchqa-validation-6843", "mrqa_squad-validation-2920", "mrqa_squad-validation-1500", "mrqa_searchqa-validation-14398", "mrqa_searchqa-validation-9733", "mrqa_searchqa-validation-11816", "mrqa_squad-validation-2346", "mrqa_squad-validation-2372"], "EFR": 1.0, "Overall": 0.8450520833333334}, {"timecode": 6, "before_eval_results": {"predictions": ["The Central Region", "Fred Singer", "north", "for Lutheran views", "Bible", "water pump", "86.66%", "Gender", "Scottish Parliament", "science fiction", "a background check and psychiatric evaluation", "Super Bowl XX", "Queen Bees", "the study of rocks", "RogerNFL", "to avoid being targeted by the boycott", "(circa 1964\u20131965", "a guru", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers", "Judith Merril", "the connection id in a table", "Von Miller", "weekly screenings of all available classic episodes", "type III secretion system", "30 schools", "12 May 1191", "The Three Doctors", "1870 to 1939", "Ealy", "Seven Days to the River Rhine", "ten", "New Orleans", "when the oxygen concentration is too high", "to punish Christians by God", "global village", "Sun City", "Freeport, Maine", "the tapir", "auction community", "Liberty Island", "of kin", "Tom Cruise", "Lenin", "Bill Hickok", "Amtrak", "the Pioneer Log House", "The Pianist", "Patty Duke", "the king", "a Macintosh computer", "Richard Cory", "Jay", "South Africa", "the greyhound", "alliterative creatures", "mountains of Eastern Nevada", "Trenton", "copper", "different philosophers and statesmen have designed different lists of what they believe to be natural rights", "of Southern Spain", "Margarita", "prostate cancer", "DNA's structure", "Pyrenees mountains"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7019097222222223}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, true, false, true, false, false, true, false, false, false, false, true, true, false, false, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.8, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7473", "mrqa_squad-validation-87", "mrqa_squad-validation-5589", "mrqa_squad-validation-7051", "mrqa_squad-validation-2564", "mrqa_searchqa-validation-11091", "mrqa_searchqa-validation-8570", "mrqa_searchqa-validation-6722", "mrqa_searchqa-validation-11888", "mrqa_searchqa-validation-1384", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-2252", "mrqa_searchqa-validation-1162", "mrqa_searchqa-validation-10297", "mrqa_searchqa-validation-11704", "mrqa_searchqa-validation-11710", "mrqa_searchqa-validation-2214", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-6372", "mrqa_naturalquestions-validation-9273", "mrqa_triviaqa-validation-2363", "mrqa_triviaqa-validation-4255"], "SR": 0.640625, "CSR": 0.6830357142857143, "retrieved_ids": ["mrqa_squad-train-40757", "mrqa_squad-train-12943", "mrqa_squad-train-51115", "mrqa_squad-train-40890", "mrqa_squad-train-7339", "mrqa_squad-train-8445", "mrqa_squad-train-71341", "mrqa_squad-train-15845", "mrqa_squad-train-23013", "mrqa_squad-train-44056", "mrqa_squad-train-24537", "mrqa_squad-train-80267", "mrqa_squad-train-70819", "mrqa_squad-train-590", "mrqa_squad-train-56743", "mrqa_squad-train-23925", "mrqa_squad-train-49365", "mrqa_squad-train-25033", "mrqa_squad-train-10510", "mrqa_squad-train-4791", "mrqa_squad-train-24408", "mrqa_squad-train-36885", "mrqa_squad-train-72488", "mrqa_squad-train-41795", "mrqa_squad-train-58561", "mrqa_squad-train-13301", "mrqa_squad-train-80973", "mrqa_squad-train-46919", "mrqa_squad-train-69967", "mrqa_squad-train-22660", "mrqa_squad-train-32278", "mrqa_squad-train-33464", "mrqa_searchqa-validation-10925", "mrqa_searchqa-validation-8845", "mrqa_searchqa-validation-9109", "mrqa_squad-validation-1841", "mrqa_searchqa-validation-15847", "mrqa_squad-validation-2226", "mrqa_squad-validation-1891", "mrqa_searchqa-validation-16816", "mrqa_searchqa-validation-13657", "mrqa_squad-validation-1529", "mrqa_squad-validation-7653", "mrqa_squad-validation-1766", "mrqa_naturalquestions-validation-1549", "mrqa_squad-validation-973", "mrqa_squad-validation-4452", "mrqa_searchqa-validation-10823", "mrqa_squad-validation-1662", "mrqa_squad-validation-10274", "mrqa_hotpotqa-validation-1297", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-12876", "mrqa_squad-validation-2372", "mrqa_searchqa-validation-5857", "mrqa_squad-validation-4528", "mrqa_searchqa-validation-1843", "mrqa_squad-validation-2920", "mrqa_searchqa-validation-7852", "mrqa_squad-validation-7687", "mrqa_searchqa-validation-11770", "mrqa_squad-validation-4999", "mrqa_searchqa-validation-541", "mrqa_squad-validation-5456"], "EFR": 0.9565217391304348, "Overall": 0.8197787267080745}, {"timecode": 7, "before_eval_results": {"predictions": ["Mercedes-Benz Superdome", "Works Council Directive", "Court of Justice", "United Kingdom", "Brooklyn", "1569", "Computational complexity theory", "models", "Death wish Coffee", "Denver Steelers", "McManus", "Gemini", "Dave Logan", "Northern Europe and the Mid-Atlantic", "Africa", "X-rays", "corporal punishment", "1 October 1998", "Marconi successfully transmitted the letter S from England to Newfoundland", "LOVE Radio", "The Holocene", "Hasar, Hachiun, and Tem\u00fcge", "AD 0\u20131250", "Mongols and the Semuren", "to civil disobedients", "Because oil was priced in dollars, oil producers' real income decreased", "Chuck Howley", "the holy catholic (or universal) church", "competition", "1516", "decrease in wages", "Prudhoe Bay", "a cat's eye", "cigar", "William Godwin", "Lucy Hayes", "a second fiddle", "Mollie Haycock", "Eight Is Enough", "Madrid", "Humphrey Bogart", "The Name of the Rose", "Thomas Paine", "a blue whale", "(D Doom)", "TriviaBistro.com", "Karl Shapiro", "Julius Caesar", "malaria", "a blonde", "Hairspray", "Johann Wolfgang von Goethe", "masks", "Greek letter society", "a seaplane", "Sherman Antitrust Act", "Hafnium", "Ricardo Chavira", "Harold Bierman", "Winnie the Pooh", "Ryder Russell", "a steam-driven, paddlewheeled overnight passenger boat", "Officer Joe Harn", "Reid's dismissal"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6057933964183964}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615383, 0.14285714285714288, 0.07407407407407407, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-490", "mrqa_squad-validation-694", "mrqa_squad-validation-1407", "mrqa_squad-validation-8412", "mrqa_squad-validation-6759", "mrqa_squad-validation-3718", "mrqa_searchqa-validation-5128", "mrqa_searchqa-validation-2532", "mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-10060", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-5915", "mrqa_searchqa-validation-10103", "mrqa_searchqa-validation-8495", "mrqa_searchqa-validation-16911", "mrqa_searchqa-validation-11451", "mrqa_searchqa-validation-11427", "mrqa_searchqa-validation-7384", "mrqa_searchqa-validation-86", "mrqa_naturalquestions-validation-519", "mrqa_triviaqa-validation-6277", "mrqa_hotpotqa-validation-2600", "mrqa_newsqa-validation-2246", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-689"], "SR": 0.59375, "CSR": 0.671875, "retrieved_ids": ["mrqa_squad-train-84529", "mrqa_squad-train-47599", "mrqa_squad-train-32197", "mrqa_squad-train-70579", "mrqa_squad-train-19578", "mrqa_squad-train-77293", "mrqa_squad-train-36380", "mrqa_squad-train-18870", "mrqa_squad-train-47476", "mrqa_squad-train-44081", "mrqa_squad-train-24292", "mrqa_squad-train-13224", "mrqa_squad-train-60526", "mrqa_squad-train-86356", "mrqa_squad-train-35773", "mrqa_squad-train-8427", "mrqa_squad-train-79418", "mrqa_squad-train-47110", "mrqa_squad-train-69265", "mrqa_squad-train-59090", "mrqa_squad-train-44512", "mrqa_squad-train-61486", "mrqa_squad-train-13707", "mrqa_squad-train-46790", "mrqa_squad-train-74123", "mrqa_squad-train-71588", "mrqa_squad-train-69211", "mrqa_squad-train-84069", "mrqa_squad-train-40082", "mrqa_squad-train-27828", "mrqa_squad-train-3793", "mrqa_squad-train-45238", "mrqa_squad-validation-7051", "mrqa_squad-validation-5589", "mrqa_squad-validation-9145", "mrqa_searchqa-validation-6372", "mrqa_squad-validation-3543", "mrqa_searchqa-validation-9733", "mrqa_squad-validation-1766", "mrqa_searchqa-validation-4674", "mrqa_squad-validation-9533", "mrqa_searchqa-validation-14790", "mrqa_squad-validation-3130", "mrqa_squad-validation-973", "mrqa_searchqa-validation-15847", "mrqa_searchqa-validation-8570", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-541", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-10823", "mrqa_searchqa-validation-700", "mrqa_squad-validation-3355", "mrqa_newsqa-validation-2983", "mrqa_squad-validation-2976", "mrqa_searchqa-validation-5785", "mrqa_squad-validation-9640", "mrqa_searchqa-validation-11888", "mrqa_searchqa-validation-6722", "mrqa_squad-validation-10274", "mrqa_triviaqa-validation-4742", "mrqa_squad-validation-4999", "mrqa_searchqa-validation-4266", "mrqa_squad-validation-10506", "mrqa_searchqa-validation-14148"], "EFR": 1.0, "Overall": 0.8359375}, {"timecode": 8, "before_eval_results": {"predictions": ["the 1970s", "at Madison Square Garden", "Han Chinese, Khitans, Jurchens, Mongols, and Tibetan Buddhists", "Lucas Horenbout", "safaris", "Silk Road", "The Sinclair Broadcast Group", "8", "1.6 kilometres", "deportation of the French-speaking Acadian population from the area", "Ryan Seacrest", "his last statement", "buildings, infrastructure and industrial", "a broken arm", "August 10, 1948", "not having a residence permit", "Cheyenne", "large dumbbell-shaped chloroplasts", "his friendship", "Kevin Harlan", "30%", "The Open Championship golf and The Wimbledon tennis tournaments", "when the oxygen concentration is too high", "Anglican tradition's Book of Common Prayer", "Golden Gate Bridge", "Diarmaid MacCulloch", "inferior", "2015", "trenchcoat", "leptospira", "Thor Avengers", "a natural satellite", "tango", "Longhorn Caverns", "bamboos", "Nevil Shute", "Messalina", "Vlad Tepes", "barb wire", "ginseng", "cocoa powder", "Depeche Mode", "Gatorade", "Deep brain stimulation", "Vanna White", "a hippopotamus", "1492", "the Madding Crowd", "(M Mikhail) Baryshakov", "Mars", "the Boston Massacre Trials", "a bee", "a 9mm Uzi Submachine gun", "Venice", "May 5", "Mrs. Calabash", "Carl Sagan", "February 2011", "General Paulus", "John Ford", "Cirque du Soleil", "from a donor molecule to an acceptor molecule", "Sylvester Stallone", "The Mongol - led Yuan dynasty"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6697916666666668}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, false, false, false, true, false, false, true, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 0.16666666666666666, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1456", "mrqa_squad-validation-8294", "mrqa_squad-validation-8400", "mrqa_squad-validation-6402", "mrqa_squad-validation-8864", "mrqa_squad-validation-10011", "mrqa_squad-validation-10061", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-6638", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-11086", "mrqa_searchqa-validation-8582", "mrqa_searchqa-validation-2617", "mrqa_searchqa-validation-3222", "mrqa_searchqa-validation-6815", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-1256", "mrqa_searchqa-validation-14631", "mrqa_searchqa-validation-37", "mrqa_searchqa-validation-6992", "mrqa_searchqa-validation-2863", "mrqa_searchqa-validation-3478", "mrqa_searchqa-validation-10604", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-6321"], "SR": 0.578125, "CSR": 0.6614583333333333, "retrieved_ids": ["mrqa_squad-train-29149", "mrqa_squad-train-48376", "mrqa_squad-train-15760", "mrqa_squad-train-15939", "mrqa_squad-train-24747", "mrqa_squad-train-2180", "mrqa_squad-train-21279", "mrqa_squad-train-50966", "mrqa_squad-train-42693", "mrqa_squad-train-40938", "mrqa_squad-train-45085", "mrqa_squad-train-28733", "mrqa_squad-train-74999", "mrqa_squad-train-85382", "mrqa_squad-train-69166", "mrqa_squad-train-63863", "mrqa_squad-train-21926", "mrqa_squad-train-29212", "mrqa_squad-train-37361", "mrqa_squad-train-11913", "mrqa_squad-train-5122", "mrqa_squad-train-2047", "mrqa_squad-train-972", "mrqa_squad-train-19604", "mrqa_squad-train-79033", "mrqa_squad-train-60805", "mrqa_squad-train-55504", "mrqa_squad-train-13525", "mrqa_squad-train-53174", "mrqa_squad-train-13092", "mrqa_squad-train-69463", "mrqa_squad-train-12254", "mrqa_triviaqa-validation-6277", "mrqa_squad-validation-2289", "mrqa_squad-validation-4861", "mrqa_triviaqa-validation-412", "mrqa_newsqa-validation-689", "mrqa_squad-validation-4999", "mrqa_squad-validation-1092", "mrqa_squad-validation-10506", "mrqa_searchqa-validation-86", "mrqa_squad-validation-117", "mrqa_searchqa-validation-9116", "mrqa_squad-validation-8597", "mrqa_squad-validation-9640", "mrqa_searchqa-validation-16886", "mrqa_squad-validation-9489", "mrqa_searchqa-validation-2252", "mrqa_triviaqa-validation-4742", "mrqa_squad-validation-8927", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11816", "mrqa_squad-validation-6809", "mrqa_searchqa-validation-11704", "mrqa_searchqa-validation-4266", "mrqa_squad-validation-7653", "mrqa_searchqa-validation-1162", "mrqa_searchqa-validation-13077", "mrqa_squad-validation-7051", "mrqa_searchqa-validation-6962", "mrqa_newsqa-validation-491", "mrqa_searchqa-validation-6843", "mrqa_squad-validation-2976", "mrqa_searchqa-validation-14148"], "EFR": 1.0, "Overall": 0.8307291666666666}, {"timecode": 9, "before_eval_results": {"predictions": ["the Metropolitan Police Authority", "Henry Laurens", "parallel importers", "200", "Genghis Khan", "five", "governmental entities", "Great Yuan", "Jordan Norwood", "immune system adapts its response during an infection to improve its recognition of the pathogen", "70", "movements of nature, movements of free and unequal durations", "1850s", "2000", "Bruno Mars", "electrical arc light based illumination systems", "megaprojects", "James Lofton", "gurus", "limiting aggregate demand", "five", "Danny Lane", "5,500,000", "an adjustable spring-loaded valve", "classical position variables", "The Left Hand of Darkness", "Luther", "George Jetson", "deus ex machina", "an arboretum", "pommel horse", "William McKinley", "PSP", "Daphne du Maurier", "Latin", "a quip", "saguaro", "the American Revolution", "Morrie Schwartz", "the periodic table", "Mercury and Venus", "Tokyo", "an entry-level restaurant job or a labor-saving appliance", "a gorillas", "The Pentagon", "oats", "4 pecks", "China", "Gone With the Wind", "A Delicate Balance", "Nancy Reagan", "grasshopper", "Lord Baden-Powell", "Pyrrhus", "The Miracle Worker", "insulin", "in the mid-1990s", "Hudson Bay", "Dr Ichak", "Melpomene", "Boston Bruins", "James Lofton", "a converter box", "raping and murdering a woman"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6130208333333333}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.5, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3118", "mrqa_squad-validation-4068", "mrqa_squad-validation-6185", "mrqa_squad-validation-6757", "mrqa_squad-validation-8046", "mrqa_squad-validation-6680", "mrqa_squad-validation-1640", "mrqa_squad-validation-664", "mrqa_squad-validation-1849", "mrqa_searchqa-validation-3258", "mrqa_searchqa-validation-2768", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-4888", "mrqa_searchqa-validation-2752", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-5456", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-12302", "mrqa_searchqa-validation-11495", "mrqa_searchqa-validation-2394", "mrqa_searchqa-validation-5679", "mrqa_searchqa-validation-3127", "mrqa_searchqa-validation-8236", "mrqa_naturalquestions-validation-4124", "mrqa_triviaqa-validation-2735", "mrqa_hotpotqa-validation-5831", "mrqa_hotpotqa-validation-3949", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-1271"], "SR": 0.53125, "CSR": 0.6484375, "retrieved_ids": ["mrqa_squad-train-64251", "mrqa_squad-train-27670", "mrqa_squad-train-2732", "mrqa_squad-train-11152", "mrqa_squad-train-59197", "mrqa_squad-train-16688", "mrqa_squad-train-57180", "mrqa_squad-train-30434", "mrqa_squad-train-65254", "mrqa_squad-train-41383", "mrqa_squad-train-1214", "mrqa_squad-train-37310", "mrqa_squad-train-64288", "mrqa_squad-train-46494", "mrqa_squad-train-30692", "mrqa_squad-train-65417", "mrqa_squad-train-26254", "mrqa_squad-train-16321", "mrqa_squad-train-74364", "mrqa_squad-train-69811", "mrqa_squad-train-10770", "mrqa_squad-train-46174", "mrqa_squad-train-22041", "mrqa_squad-train-55183", "mrqa_squad-train-67798", "mrqa_squad-train-46645", "mrqa_squad-train-38339", "mrqa_squad-train-78250", "mrqa_squad-train-77758", "mrqa_squad-train-77777", "mrqa_squad-train-82430", "mrqa_squad-train-34323", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-2022", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-9548", "mrqa_searchqa-validation-6962", "mrqa_searchqa-validation-3960", "mrqa_squad-validation-6759", "mrqa_searchqa-validation-16816", "mrqa_triviaqa-validation-2363", "mrqa_searchqa-validation-13813", "mrqa_squad-validation-1500", "mrqa_squad-validation-8558", "mrqa_squad-validation-5456", "mrqa_searchqa-validation-2863", "mrqa_squad-validation-8597", "mrqa_squad-validation-2346", "mrqa_squad-validation-9489", "mrqa_squad-validation-6809", "mrqa_searchqa-validation-11086", "mrqa_squad-validation-2920", "mrqa_searchqa-validation-10103", "mrqa_searchqa-validation-9403", "mrqa_searchqa-validation-3478", "mrqa_searchqa-validation-1701", "mrqa_searchqa-validation-4266", "mrqa_squad-validation-10011", "mrqa_squad-validation-9320", "mrqa_squad-validation-3718", "mrqa_newsqa-validation-1289", "mrqa_searchqa-validation-9116", "mrqa_squad-validation-2226"], "EFR": 1.0, "Overall": 0.82421875}, {"timecode": 10, "UKR": 0.7890625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1297", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-2600", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-2949", "mrqa_hotpotqa-validation-3358", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-5831", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4124", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-866", "mrqa_naturalquestions-validation-9273", "mrqa_newsqa-validation-1271", "mrqa_newsqa-validation-1289", "mrqa_newsqa-validation-160", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-689", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-10060", "mrqa_searchqa-validation-10103", "mrqa_searchqa-validation-10193", "mrqa_searchqa-validation-10297", "mrqa_searchqa-validation-10308", "mrqa_searchqa-validation-10318", "mrqa_searchqa-validation-10604", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10790", "mrqa_searchqa-validation-10823", "mrqa_searchqa-validation-10925", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-11002", "mrqa_searchqa-validation-11091", "mrqa_searchqa-validation-11139", "mrqa_searchqa-validation-11427", "mrqa_searchqa-validation-11451", "mrqa_searchqa-validation-11557", "mrqa_searchqa-validation-1162", "mrqa_searchqa-validation-11704", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-11816", "mrqa_searchqa-validation-11944", "mrqa_searchqa-validation-12117", "mrqa_searchqa-validation-12302", "mrqa_searchqa-validation-12312", "mrqa_searchqa-validation-12317", "mrqa_searchqa-validation-12357", "mrqa_searchqa-validation-12462", "mrqa_searchqa-validation-125", "mrqa_searchqa-validation-12547", "mrqa_searchqa-validation-1256", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-12876", "mrqa_searchqa-validation-13434", "mrqa_searchqa-validation-13459", "mrqa_searchqa-validation-13476", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-1384", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14398", "mrqa_searchqa-validation-1453", "mrqa_searchqa-validation-14631", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-14790", "mrqa_searchqa-validation-14838", "mrqa_searchqa-validation-14884", "mrqa_searchqa-validation-15224", "mrqa_searchqa-validation-15554", "mrqa_searchqa-validation-15748", "mrqa_searchqa-validation-15795", "mrqa_searchqa-validation-15804", "mrqa_searchqa-validation-15847", "mrqa_searchqa-validation-15915", "mrqa_searchqa-validation-16282", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-16886", "mrqa_searchqa-validation-16911", "mrqa_searchqa-validation-1701", "mrqa_searchqa-validation-1843", "mrqa_searchqa-validation-198", "mrqa_searchqa-validation-1992", "mrqa_searchqa-validation-2175", "mrqa_searchqa-validation-2214", "mrqa_searchqa-validation-2252", "mrqa_searchqa-validation-2394", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-2532", "mrqa_searchqa-validation-2617", "mrqa_searchqa-validation-2752", "mrqa_searchqa-validation-2863", "mrqa_searchqa-validation-2963", "mrqa_searchqa-validation-3060", "mrqa_searchqa-validation-3102", "mrqa_searchqa-validation-3222", "mrqa_searchqa-validation-3258", "mrqa_searchqa-validation-33", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-3497", "mrqa_searchqa-validation-37", "mrqa_searchqa-validation-3735", "mrqa_searchqa-validation-3887", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-4004", "mrqa_searchqa-validation-4057", "mrqa_searchqa-validation-414", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-4386", "mrqa_searchqa-validation-4553", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-4674", "mrqa_searchqa-validation-4888", "mrqa_searchqa-validation-4910", "mrqa_searchqa-validation-5128", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-5329", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-5456", "mrqa_searchqa-validation-5539", "mrqa_searchqa-validation-5679", "mrqa_searchqa-validation-5785", "mrqa_searchqa-validation-5857", "mrqa_searchqa-validation-5915", "mrqa_searchqa-validation-5963", "mrqa_searchqa-validation-6122", "mrqa_searchqa-validation-6372", "mrqa_searchqa-validation-6638", "mrqa_searchqa-validation-695", "mrqa_searchqa-validation-6962", "mrqa_searchqa-validation-697", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-700", "mrqa_searchqa-validation-7010", "mrqa_searchqa-validation-7384", "mrqa_searchqa-validation-7564", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-7852", "mrqa_searchqa-validation-7880", "mrqa_searchqa-validation-7985", "mrqa_searchqa-validation-8236", "mrqa_searchqa-validation-8532", "mrqa_searchqa-validation-8570", "mrqa_searchqa-validation-8582", "mrqa_searchqa-validation-8590", "mrqa_searchqa-validation-86", "mrqa_searchqa-validation-8658", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8845", "mrqa_searchqa-validation-8869", "mrqa_searchqa-validation-9109", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9403", "mrqa_searchqa-validation-9733", "mrqa_searchqa-validation-9777", "mrqa_squad-validation-10010", "mrqa_squad-validation-10011", "mrqa_squad-validation-10061", "mrqa_squad-validation-10092", "mrqa_squad-validation-10125", "mrqa_squad-validation-10137", "mrqa_squad-validation-10140", "mrqa_squad-validation-10141", "mrqa_squad-validation-10214", "mrqa_squad-validation-10218", "mrqa_squad-validation-10273", "mrqa_squad-validation-10274", "mrqa_squad-validation-10280", "mrqa_squad-validation-10287", "mrqa_squad-validation-10306", "mrqa_squad-validation-10338", "mrqa_squad-validation-10380", "mrqa_squad-validation-10387", "mrqa_squad-validation-10433", "mrqa_squad-validation-10489", "mrqa_squad-validation-10494", "mrqa_squad-validation-10506", "mrqa_squad-validation-1055", "mrqa_squad-validation-1079", "mrqa_squad-validation-1082", "mrqa_squad-validation-1092", "mrqa_squad-validation-1118", "mrqa_squad-validation-1122", "mrqa_squad-validation-1125", "mrqa_squad-validation-117", "mrqa_squad-validation-1177", "mrqa_squad-validation-1206", "mrqa_squad-validation-1207", "mrqa_squad-validation-1215", "mrqa_squad-validation-1290", "mrqa_squad-validation-132", "mrqa_squad-validation-1347", "mrqa_squad-validation-1404", "mrqa_squad-validation-1407", "mrqa_squad-validation-1441", "mrqa_squad-validation-1467", "mrqa_squad-validation-1529", "mrqa_squad-validation-1615", "mrqa_squad-validation-1640", "mrqa_squad-validation-1641", "mrqa_squad-validation-1662", "mrqa_squad-validation-167", "mrqa_squad-validation-172", "mrqa_squad-validation-1725", "mrqa_squad-validation-1766", "mrqa_squad-validation-1841", "mrqa_squad-validation-1849", "mrqa_squad-validation-19", "mrqa_squad-validation-192", "mrqa_squad-validation-1921", "mrqa_squad-validation-1936", "mrqa_squad-validation-1955", "mrqa_squad-validation-1983", "mrqa_squad-validation-2059", "mrqa_squad-validation-2066", "mrqa_squad-validation-2088", "mrqa_squad-validation-2095", "mrqa_squad-validation-2149", "mrqa_squad-validation-2190", "mrqa_squad-validation-2192", "mrqa_squad-validation-2209", "mrqa_squad-validation-2226", "mrqa_squad-validation-2235", "mrqa_squad-validation-2283", "mrqa_squad-validation-2286", "mrqa_squad-validation-2346", "mrqa_squad-validation-2353", "mrqa_squad-validation-236", "mrqa_squad-validation-2365", "mrqa_squad-validation-2372", "mrqa_squad-validation-2374", "mrqa_squad-validation-2387", "mrqa_squad-validation-2411", "mrqa_squad-validation-2421", "mrqa_squad-validation-2441", "mrqa_squad-validation-2442", "mrqa_squad-validation-2472", "mrqa_squad-validation-2476", "mrqa_squad-validation-25", "mrqa_squad-validation-253", "mrqa_squad-validation-2550", "mrqa_squad-validation-2552", "mrqa_squad-validation-2560", "mrqa_squad-validation-2564", "mrqa_squad-validation-2622", "mrqa_squad-validation-2640", "mrqa_squad-validation-2656", "mrqa_squad-validation-272", "mrqa_squad-validation-2748", "mrqa_squad-validation-2765", "mrqa_squad-validation-2783", "mrqa_squad-validation-2831", "mrqa_squad-validation-2844", "mrqa_squad-validation-2857", "mrqa_squad-validation-2865", "mrqa_squad-validation-2893", "mrqa_squad-validation-2920", "mrqa_squad-validation-2926", "mrqa_squad-validation-2942", "mrqa_squad-validation-2949", "mrqa_squad-validation-2973", "mrqa_squad-validation-2976", "mrqa_squad-validation-3022", "mrqa_squad-validation-3040", "mrqa_squad-validation-3068", "mrqa_squad-validation-3118", "mrqa_squad-validation-3119", "mrqa_squad-validation-3165", "mrqa_squad-validation-3166", "mrqa_squad-validation-3168", "mrqa_squad-validation-3215", "mrqa_squad-validation-3355", "mrqa_squad-validation-3382", "mrqa_squad-validation-3393", "mrqa_squad-validation-3407", "mrqa_squad-validation-3417", "mrqa_squad-validation-3461", "mrqa_squad-validation-3493", "mrqa_squad-validation-3508", "mrqa_squad-validation-3543", "mrqa_squad-validation-3559", "mrqa_squad-validation-3663", "mrqa_squad-validation-3699", "mrqa_squad-validation-3718", "mrqa_squad-validation-3779", "mrqa_squad-validation-3947", "mrqa_squad-validation-3954", "mrqa_squad-validation-3955", "mrqa_squad-validation-3959", "mrqa_squad-validation-4001", "mrqa_squad-validation-4068", "mrqa_squad-validation-4101", "mrqa_squad-validation-4144", "mrqa_squad-validation-42", "mrqa_squad-validation-4329", "mrqa_squad-validation-4452", "mrqa_squad-validation-4462", "mrqa_squad-validation-455", "mrqa_squad-validation-4550", "mrqa_squad-validation-457", "mrqa_squad-validation-457", "mrqa_squad-validation-4585", "mrqa_squad-validation-4594", "mrqa_squad-validation-4633", "mrqa_squad-validation-4633", "mrqa_squad-validation-466", "mrqa_squad-validation-4662", "mrqa_squad-validation-4664", "mrqa_squad-validation-4694", "mrqa_squad-validation-477", "mrqa_squad-validation-4774", "mrqa_squad-validation-4782", "mrqa_squad-validation-4797", "mrqa_squad-validation-4829", "mrqa_squad-validation-4841", "mrqa_squad-validation-490", "mrqa_squad-validation-4932", "mrqa_squad-validation-5003", "mrqa_squad-validation-5014", "mrqa_squad-validation-5029", "mrqa_squad-validation-5071", "mrqa_squad-validation-5099", "mrqa_squad-validation-518", "mrqa_squad-validation-5185", "mrqa_squad-validation-5296", "mrqa_squad-validation-5309", "mrqa_squad-validation-5348", "mrqa_squad-validation-5377", "mrqa_squad-validation-538", "mrqa_squad-validation-5451", "mrqa_squad-validation-5456", "mrqa_squad-validation-5470", "mrqa_squad-validation-5498", "mrqa_squad-validation-5513", "mrqa_squad-validation-5528", "mrqa_squad-validation-5589", "mrqa_squad-validation-560", "mrqa_squad-validation-5616", "mrqa_squad-validation-565", "mrqa_squad-validation-5724", "mrqa_squad-validation-5727", "mrqa_squad-validation-5765", "mrqa_squad-validation-5771", "mrqa_squad-validation-5804", "mrqa_squad-validation-5824", "mrqa_squad-validation-5830", "mrqa_squad-validation-5852", "mrqa_squad-validation-588", "mrqa_squad-validation-5956", "mrqa_squad-validation-5995", "mrqa_squad-validation-605", "mrqa_squad-validation-6086", "mrqa_squad-validation-6097", "mrqa_squad-validation-6121", "mrqa_squad-validation-6147", "mrqa_squad-validation-6156", "mrqa_squad-validation-6185", "mrqa_squad-validation-6206", "mrqa_squad-validation-6224", "mrqa_squad-validation-6334", "mrqa_squad-validation-6354", "mrqa_squad-validation-639", "mrqa_squad-validation-6393", "mrqa_squad-validation-6402", "mrqa_squad-validation-641", "mrqa_squad-validation-6557", "mrqa_squad-validation-6569", "mrqa_squad-validation-6572", "mrqa_squad-validation-6594", "mrqa_squad-validation-6609", "mrqa_squad-validation-6614", "mrqa_squad-validation-664", "mrqa_squad-validation-6680", "mrqa_squad-validation-6714", "mrqa_squad-validation-6757", "mrqa_squad-validation-6759", "mrqa_squad-validation-6792", "mrqa_squad-validation-6809", "mrqa_squad-validation-6869", "mrqa_squad-validation-6881", "mrqa_squad-validation-6917", "mrqa_squad-validation-693", "mrqa_squad-validation-694", "mrqa_squad-validation-703", "mrqa_squad-validation-704", "mrqa_squad-validation-7051", "mrqa_squad-validation-7081", "mrqa_squad-validation-7090", "mrqa_squad-validation-7128", "mrqa_squad-validation-7202", "mrqa_squad-validation-7291", "mrqa_squad-validation-7307", "mrqa_squad-validation-7330", "mrqa_squad-validation-7412", "mrqa_squad-validation-7424", "mrqa_squad-validation-7431", "mrqa_squad-validation-7439", "mrqa_squad-validation-7473", "mrqa_squad-validation-7527", "mrqa_squad-validation-7574", "mrqa_squad-validation-7608", "mrqa_squad-validation-7622", "mrqa_squad-validation-763", "mrqa_squad-validation-7653", "mrqa_squad-validation-7665", "mrqa_squad-validation-7687", "mrqa_squad-validation-7719", "mrqa_squad-validation-7729", "mrqa_squad-validation-773", "mrqa_squad-validation-7733", "mrqa_squad-validation-774", "mrqa_squad-validation-7772", "mrqa_squad-validation-7785", "mrqa_squad-validation-7794", "mrqa_squad-validation-7822", "mrqa_squad-validation-7829", "mrqa_squad-validation-7836", "mrqa_squad-validation-7837", "mrqa_squad-validation-784", "mrqa_squad-validation-7908", "mrqa_squad-validation-7918", "mrqa_squad-validation-7934", "mrqa_squad-validation-7951", "mrqa_squad-validation-7958", "mrqa_squad-validation-7964", "mrqa_squad-validation-8033", "mrqa_squad-validation-8056", "mrqa_squad-validation-8067", "mrqa_squad-validation-8097", "mrqa_squad-validation-8115", "mrqa_squad-validation-8136", "mrqa_squad-validation-8149", "mrqa_squad-validation-8196", "mrqa_squad-validation-825", "mrqa_squad-validation-828", "mrqa_squad-validation-8294", "mrqa_squad-validation-8400", "mrqa_squad-validation-8403", "mrqa_squad-validation-8412", "mrqa_squad-validation-8436", "mrqa_squad-validation-8442", "mrqa_squad-validation-8495", "mrqa_squad-validation-850", "mrqa_squad-validation-851", "mrqa_squad-validation-8551", "mrqa_squad-validation-8558", "mrqa_squad-validation-8566", "mrqa_squad-validation-8568", "mrqa_squad-validation-8575", "mrqa_squad-validation-8597", "mrqa_squad-validation-862", "mrqa_squad-validation-8657", "mrqa_squad-validation-8683", "mrqa_squad-validation-8689", "mrqa_squad-validation-87", "mrqa_squad-validation-883", "mrqa_squad-validation-8864", "mrqa_squad-validation-8923", "mrqa_squad-validation-8923", "mrqa_squad-validation-8927", "mrqa_squad-validation-8939", "mrqa_squad-validation-8981", "mrqa_squad-validation-9017", "mrqa_squad-validation-9054", "mrqa_squad-validation-9110", "mrqa_squad-validation-9145", "mrqa_squad-validation-919", "mrqa_squad-validation-9205", "mrqa_squad-validation-9234", "mrqa_squad-validation-9310", "mrqa_squad-validation-932", "mrqa_squad-validation-9320", "mrqa_squad-validation-9334", "mrqa_squad-validation-9362", "mrqa_squad-validation-937", "mrqa_squad-validation-9489", "mrqa_squad-validation-9533", "mrqa_squad-validation-9559", "mrqa_squad-validation-9581", "mrqa_squad-validation-9687", "mrqa_squad-validation-973", "mrqa_squad-validation-9731", "mrqa_squad-validation-9810", "mrqa_squad-validation-9822", "mrqa_squad-validation-985", "mrqa_squad-validation-9869", "mrqa_squad-validation-9870", "mrqa_squad-validation-9910", "mrqa_squad-validation-9954", "mrqa_squad-validation-997", "mrqa_squad-validation-997", "mrqa_squad-validation-9993", "mrqa_squad-validation-9996", "mrqa_triviaqa-validation-1927", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-412", "mrqa_triviaqa-validation-4255", "mrqa_triviaqa-validation-5338", "mrqa_triviaqa-validation-6277", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-7474"], "OKR": 0.921875, "KG": 0.4578125, "before_eval_results": {"predictions": ["Mike Figgis", "1.7 billion years ago", "the Nieuwe Merwede", "technical problems and flight delays", "the fact (Fermat's little theorem)", "Virgin Media", "killed through overwork", "Times Square Studios", "Philip Webb and William Morris", "the sacrament of baptism", "Amtrak San Joaquins", "refusing to make a commitment", "regulations and directives", "in the possession of already-wealthy individuals or entities", "26", "formal imperialism", "30 July 1891", "the Bible", "Lower Lorraine", "parish churches", "kinetic friction", "a third group of pigments found in cyanobacteria, and glaucophyte, red algal, and cryptophyte chloroplasts", "photoelectric", "(Gaby) Seyfert", "an anatomic structure that serves as a place to collect or retain fluid.", "Memoirs of a Geisha", "stability control", "a pistol", "Gothic Names", "Aluminium", "Rhett Akins", "the Cenozoic", "Angola", "Reddi-wip", "Jeopardy", "coffee", "Larry Fortensky", "the fire", "Shakira", "Aimee Semple McPherson", "Hawaii", "Time & 1936", "the Jeffersons", "The Sopranos", "The Crucible", "Liston", "French Impressionist", "Willa Cather", "Aida", "The Strange & Curious Tale of the Last True Hermit", "Burgundy", "public high schools", "a screw extractor", "zero", "Australian & New Zealand", "Vermont", "Neela Montgomery", "wall mounted faucet and the sink rim", "Peter Biskind", "John Ford", "119", "the Vigor, Prelude, CR-X, and Quint.", "a skilled hacker could disrupt the system and cause a computer attack on its control system.", "Frank Ricci"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5907738095238095}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.2666666666666667, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9178", "mrqa_squad-validation-9023", "mrqa_squad-validation-2455", "mrqa_searchqa-validation-15312", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-1747", "mrqa_searchqa-validation-13939", "mrqa_searchqa-validation-3369", "mrqa_searchqa-validation-409", "mrqa_searchqa-validation-13028", "mrqa_searchqa-validation-8368", "mrqa_searchqa-validation-6737", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-2651", "mrqa_searchqa-validation-16625", "mrqa_searchqa-validation-2871", "mrqa_searchqa-validation-8117", "mrqa_searchqa-validation-5298", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-13844", "mrqa_searchqa-validation-6011", "mrqa_searchqa-validation-16848", "mrqa_searchqa-validation-10883", "mrqa_searchqa-validation-7043", "mrqa_searchqa-validation-9725", "mrqa_naturalquestions-validation-5297", "mrqa_triviaqa-validation-862", "mrqa_hotpotqa-validation-939", "mrqa_hotpotqa-validation-400", "mrqa_newsqa-validation-3608"], "SR": 0.53125, "CSR": 0.6377840909090908, "retrieved_ids": ["mrqa_squad-train-38397", "mrqa_squad-train-21741", "mrqa_squad-train-29343", "mrqa_squad-train-6688", "mrqa_squad-train-17888", "mrqa_squad-train-19160", "mrqa_squad-train-16891", "mrqa_squad-train-84842", "mrqa_squad-train-1377", "mrqa_squad-train-50725", "mrqa_squad-train-48550", "mrqa_squad-train-388", "mrqa_squad-train-17816", "mrqa_squad-train-20393", "mrqa_squad-train-25269", "mrqa_squad-train-5306", "mrqa_squad-train-12226", "mrqa_squad-train-64140", "mrqa_squad-train-29453", "mrqa_squad-train-32433", "mrqa_squad-train-50546", "mrqa_squad-train-28197", "mrqa_squad-train-73477", "mrqa_squad-train-33795", "mrqa_squad-train-19205", "mrqa_squad-train-37934", "mrqa_squad-train-55616", "mrqa_squad-train-72041", "mrqa_squad-train-73712", "mrqa_squad-train-80706", "mrqa_squad-train-49388", "mrqa_squad-train-68689", "mrqa_squad-validation-4015", "mrqa_squad-validation-7473", "mrqa_searchqa-validation-3441", "mrqa_newsqa-validation-4098", "mrqa_searchqa-validation-9548", "mrqa_squad-validation-9145", "mrqa_naturalquestions-validation-6321", "mrqa_naturalquestions-validation-1549", "mrqa_squad-validation-6757", "mrqa_searchqa-validation-6722", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-10823", "mrqa_squad-validation-2289", "mrqa_squad-validation-1841", "mrqa_searchqa-validation-9403", "mrqa_squad-validation-7719", "mrqa_squad-validation-4528", "mrqa_squad-validation-3543", "mrqa_squad-validation-6185", "mrqa_searchqa-validation-12876", "mrqa_searchqa-validation-7010", "mrqa_naturalquestions-validation-4124", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7852", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-4888", "mrqa_squad-validation-8046", "mrqa_squad-validation-4068", "mrqa_searchqa-validation-4266", "mrqa_squad-validation-9320", "mrqa_squad-validation-9533", "mrqa_searchqa-validation-15847"], "EFR": 1.0, "Overall": 0.7613068181818182}, {"timecode": 11, "before_eval_results": {"predictions": ["the study of rocks", "imperialist", "A plant cell which contains chloroplasts", "to provide high-speed interconnection between NSF-sponsored supercomputing centers and select access points in the United States", "allowing the lander spacecraft to be used as a \"lifeboat\"", "Doctor Who", "Maria Sk\u0142odowska-Curie", "1978", "2000", "Cargill Meat Solutions and Foster Farms", "25 May 1521", "97", "concrete", "anti-colonial movements", "Lampea", "75%", "$60,000", "oppidum Ubiorum", "The entrance to studio 5 at the City Road complex", "1.7 million", "August 4, 2000", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "free", "Bob Dole", "1959", "Stratfor", "three", "137", "the green grump", "the Grand Ole Opry", "Asashoryu", "Conway", "How I Met Your Mother", "13 and 15", "the insurgency", "Chinese", "he would actively engage Arab media.", "that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance for parts of the Midwest", "127 acres", "that \"Sex and the City\" stars really are estranged from other famous women", "Rev. Alberto Cutie", "blind", "the military commissions", "opium", "President Obama's race in 2008.", "named his company Polo", "Zahi Hawass", "Arabic, French and English", "a youth ballpark", "seven", "Honduran President Jose Manuel Zelaya", "island stronghold of the Islamic militant group Abu Sayyaf", "two soldiers and two civilians", "the July 7, 2005, London transit bombings", "Democrats and Republicans", "middle of the 15th century", "1966", "J. S. Bach", "Groucho Marx", "Fitzroya cupressoides", "Janet Evanovich", "Sweeney Todd", "Andorra", "Uncle Tom's Cabin"], "metric_results": {"EM": 0.53125, "QA-F1": 0.613713858970895}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.16666666666666669, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.1142857142857143, 0.6666666666666666, 0.21428571428571427, 1.0, 0.0, 0.058823529411764705, 1.0, 0.10810810810810811, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4911", "mrqa_squad-validation-1313", "mrqa_squad-validation-9298", "mrqa_squad-validation-5465", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-267", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-2562", "mrqa_newsqa-validation-162", "mrqa_newsqa-validation-2629", "mrqa_newsqa-validation-3987", "mrqa_newsqa-validation-1641", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1011", "mrqa_newsqa-validation-2611", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3881", "mrqa_newsqa-validation-3406", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-893", "mrqa_newsqa-validation-3151", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-5492", "mrqa_hotpotqa-validation-5394", "mrqa_hotpotqa-validation-3070"], "SR": 0.53125, "CSR": 0.62890625, "retrieved_ids": ["mrqa_squad-train-44144", "mrqa_squad-train-86518", "mrqa_squad-train-35835", "mrqa_squad-train-78456", "mrqa_squad-train-68123", "mrqa_squad-train-85702", "mrqa_squad-train-73339", "mrqa_squad-train-50403", "mrqa_squad-train-66601", "mrqa_squad-train-9162", "mrqa_squad-train-82945", "mrqa_squad-train-70131", "mrqa_squad-train-70497", "mrqa_squad-train-71225", "mrqa_squad-train-3585", "mrqa_squad-train-23669", "mrqa_squad-train-40409", "mrqa_squad-train-44885", "mrqa_squad-train-73275", "mrqa_squad-train-68988", "mrqa_squad-train-2259", "mrqa_squad-train-6386", "mrqa_squad-train-85196", "mrqa_squad-train-35182", "mrqa_squad-train-2577", "mrqa_squad-train-66420", "mrqa_squad-train-6190", "mrqa_squad-train-78447", "mrqa_squad-train-72673", "mrqa_squad-train-26863", "mrqa_squad-train-35259", "mrqa_squad-train-3619", "mrqa_searchqa-validation-6992", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-10103", "mrqa_searchqa-validation-5857", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-2175", "mrqa_searchqa-validation-12119", "mrqa_searchqa-validation-15748", "mrqa_searchqa-validation-1384", "mrqa_squad-validation-7527", "mrqa_squad-validation-4452", "mrqa_searchqa-validation-2022", "mrqa_searchqa-validation-11091", "mrqa_squad-validation-4462", "mrqa_searchqa-validation-2214", "mrqa_squad-validation-8558", "mrqa_searchqa-validation-2394", "mrqa_squad-validation-490", "mrqa_squad-validation-6757", "mrqa_searchqa-validation-11710", "mrqa_squad-validation-7687", "mrqa_searchqa-validation-7043", "mrqa_squad-validation-6809", "mrqa_squad-validation-9023", "mrqa_searchqa-validation-8236", "mrqa_squad-validation-5835", "mrqa_squad-validation-1407", "mrqa_newsqa-validation-491", "mrqa_searchqa-validation-6011", "mrqa_searchqa-validation-16816", "mrqa_hotpotqa-validation-939", "mrqa_searchqa-validation-3258"], "EFR": 0.9666666666666667, "Overall": 0.7528645833333334}, {"timecode": 12, "before_eval_results": {"predictions": ["San Jose State", "Halo", "avionics, telecommunications, and computers", "136", "55.1%", "Mandatory Committees", "main porch", "Warren Buffett", "3.55 inches", "Doctor Who", "Prime ideals", "Council of Industrial Design", "The Open Championship golf and The Wimbledon tennis tournaments", "781", "Andr\u00e9s Marzal De Sax", "the reported rates of mortality in rural areas during the 14th-century pandemic were inconsistent with the modern bubonic plague", "3,792,621", "Chinggis Khaan International Airport", "23 years", "Korean peninsula", "Jason Chaffetz", "Draquila -- Italy Trembles.", "Chinese", "recovery from last spring's tornado, severe storms and flooding in Jasper County and in Joplin.", "two", "CNN", "Muhammad Ali, Kareem Abdul-Jabbar and the Persian poet Mawlana Jalal al-Din Rumi,", "Suwardi", "Maj. Nidal Malik Hasan,", "U.S. senators", "a cold shower", "Muslim", "California, Texas and Florida", "Lillo Brancato Jr.", "Argentina", "Three searches", "creation of an Islamic emirate", "Gulf of Aden", "The United Nations is calling on NATO to do more to stop the Afghan opium trade after a new survey showed how the drug dominates Afghanistan's economy.", "Pope Benedict XVI", "discusses his roots as he castigates U.S. policies and deplores Israel's offensive in Gaza that started in late December 2008 and continued into January.", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment", "Apple employees", "a German citizen", "Haiti", "\"Stagecoach\"", "test-launched a rocket capable of carrying a satellite", "Nieb\u00fcll", "Juan Martin Del Potro.", "the New Jersey Economic Development Authority's 20% tax credit on TV shows filmed or produced in the state", "Seoul", "John Wayne", "Afghanistan", "seven", "the journalists' Swedish attorney.", "Fix You", "Bill McPherson", "Ytterby", "George III", "Philadelphia", "Alien Resurrection", "Gurney", "Moscow", "a dressage"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6170755414176466}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.14285714285714288, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.3157894736842105, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4921", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-3172", "mrqa_newsqa-validation-627", "mrqa_newsqa-validation-3370", "mrqa_newsqa-validation-1308", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-1309", "mrqa_newsqa-validation-4028", "mrqa_newsqa-validation-2338", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-3965", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-293", "mrqa_newsqa-validation-3817", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-3863", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-2044", "mrqa_naturalquestions-validation-4193", "mrqa_searchqa-validation-266"], "SR": 0.578125, "CSR": 0.625, "retrieved_ids": ["mrqa_squad-train-75753", "mrqa_squad-train-78394", "mrqa_squad-train-22678", "mrqa_squad-train-10267", "mrqa_squad-train-31098", "mrqa_squad-train-68493", "mrqa_squad-train-29056", "mrqa_squad-train-83602", "mrqa_squad-train-52143", "mrqa_squad-train-4736", "mrqa_squad-train-55857", "mrqa_squad-train-77024", "mrqa_squad-train-70531", "mrqa_squad-train-46001", "mrqa_squad-train-30635", "mrqa_squad-train-55045", "mrqa_squad-train-76970", "mrqa_squad-train-23091", "mrqa_squad-train-24431", "mrqa_squad-train-4306", "mrqa_squad-train-13464", "mrqa_squad-train-5573", "mrqa_squad-train-18150", "mrqa_squad-train-32799", "mrqa_squad-train-21783", "mrqa_squad-train-79643", "mrqa_squad-train-80188", "mrqa_squad-train-14866", "mrqa_squad-train-59262", "mrqa_squad-train-15053", "mrqa_squad-train-27561", "mrqa_squad-train-79806", "mrqa_squad-validation-3165", "mrqa_searchqa-validation-3259", "mrqa_squad-validation-9320", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-2768", "mrqa_squad-validation-6757", "mrqa_searchqa-validation-7043", "mrqa_squad-validation-3543", "mrqa_searchqa-validation-11888", "mrqa_squad-validation-236", "mrqa_squad-validation-3118", "mrqa_searchqa-validation-5857", "mrqa_searchqa-validation-11495", "mrqa_searchqa-validation-11086", "mrqa_searchqa-validation-15312", "mrqa_newsqa-validation-1641", "mrqa_searchqa-validation-1301", "mrqa_squad-validation-9023", "mrqa_squad-validation-7687", "mrqa_searchqa-validation-3478", "mrqa_searchqa-validation-13077", "mrqa_searchqa-validation-4266", "mrqa_squad-validation-8412", "mrqa_squad-validation-5456", "mrqa_squad-validation-87", "mrqa_searchqa-validation-3258", "mrqa_searchqa-validation-409", "mrqa_searchqa-validation-10883", "mrqa_naturalquestions-validation-6321", "mrqa_searchqa-validation-9725", "mrqa_searchqa-validation-1256", "mrqa_searchqa-validation-16886"], "EFR": 0.9629629629629629, "Overall": 0.7513425925925926}, {"timecode": 13, "before_eval_results": {"predictions": ["before World War I", "war, famine, and weather", "Gryphon", "March 2003", "Elders", "Jon Culshaw", "CD4", "1995", "2014", "multi-stage centrifugal", "salvation", "6.4 nanometers", "WJRT-TV and WTVG", "1939", "Treaty on the Functioning of the European Union", "City of Edinburgh Council", "his father, Osama", "rural California", "Hearst Castle", "CNN's", "Al Gore.", "north coast of Puerto Rico", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "Spanish flu", "Israel's offensive in Gaza that started in late December 2008 and continued into January.", "iPhone 4S news", "in the southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "John McCain", "South Africa", "2006", "Iran's nuclear program.", "North Korea", "December 1", "police car sits outside the Westroads Mall in Omaha, Nebraska,", "Haeftling", "ireport", "Kurt Cobain", "Nkepile M abuse", "\" happy ending\" to the case.", "San Diego", "tie salesman", "At least 40", "$1,500", "25", "137", "suppress the memories and to live as normal a life as possible", "Copts", "poor", "Ewan McGregor", "ancient Egyptian antiquities in the world", "27-year-old", "165", "\"It was incredible. We've had so much rain, and yet today it was beautiful.", "\"We essentially closed the wheelhouse doors. I went to the port side, and I looked out up at the derrick.", "16,801", "Ali", "Kansas", "October", "modern dance", "Melanie Owen", "Lusitania", "a disc", "Coronation Street", "Turkey"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5601334064327486}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9333333333333333, 0.0, 0.0, 0.0, 0.5263157894736842, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7555555555555554, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5911", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-2632", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2791", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-2249", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-616", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-3069", "mrqa_newsqa-validation-2634", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-2204", "mrqa_naturalquestions-validation-3427", "mrqa_triviaqa-validation-2202", "mrqa_hotpotqa-validation-5850", "mrqa_searchqa-validation-2338", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2251"], "SR": 0.46875, "CSR": 0.6138392857142857, "retrieved_ids": ["mrqa_squad-train-28424", "mrqa_squad-train-52362", "mrqa_squad-train-79889", "mrqa_squad-train-35834", "mrqa_squad-train-29440", "mrqa_squad-train-73418", "mrqa_squad-train-6043", "mrqa_squad-train-37735", "mrqa_squad-train-49881", "mrqa_squad-train-41987", "mrqa_squad-train-45292", "mrqa_squad-train-37415", "mrqa_squad-train-43771", "mrqa_squad-train-74835", "mrqa_squad-train-65214", "mrqa_squad-train-11682", "mrqa_squad-train-47862", "mrqa_squad-train-27348", "mrqa_squad-train-65012", "mrqa_squad-train-71233", "mrqa_squad-train-71155", "mrqa_squad-train-19244", "mrqa_squad-train-55878", "mrqa_squad-train-83319", "mrqa_squad-train-39868", "mrqa_squad-train-9166", "mrqa_squad-train-51573", "mrqa_squad-train-25222", "mrqa_squad-train-20588", "mrqa_squad-train-71494", "mrqa_squad-train-61960", "mrqa_squad-train-23300", "mrqa_squad-validation-6680", "mrqa_searchqa-validation-4888", "mrqa_hotpotqa-validation-939", "mrqa_naturalquestions-validation-4124", "mrqa_squad-validation-2372", "mrqa_squad-validation-10061", "mrqa_searchqa-validation-3222", "mrqa_squad-validation-1500", "mrqa_newsqa-validation-1641", "mrqa_squad-validation-2226", "mrqa_squad-validation-3355", "mrqa_squad-validation-10011", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-266", "mrqa_searchqa-validation-541", "mrqa_naturalquestions-validation-4134", "mrqa_searchqa-validation-3735", "mrqa_squad-validation-9145", "mrqa_searchqa-validation-12302", "mrqa_squad-validation-3559", "mrqa_searchqa-validation-1256", "mrqa_newsqa-validation-150", "mrqa_squad-validation-5465", "mrqa_searchqa-validation-8582", "mrqa_searchqa-validation-3478", "mrqa_triviaqa-validation-2735", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-11427", "mrqa_searchqa-validation-5539", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-4028", "mrqa_squad-validation-3718"], "EFR": 0.9705882352941176, "Overall": 0.7506355042016807}, {"timecode": 14, "before_eval_results": {"predictions": ["Thomas Reid and Dugald Stewart", "between September and November 1946", "$2.50 per AC horsepower royalty", "1990s", "organic", "Stagg Field", "2010", "Reuben Townroe", "the Black Death", "a water pump", "high growth rates", "roads, bridges and large plazas", "two", "non-Mongol physicians", "ABC International", "Zuma", "Bangladesh", "At least 88", "the U.S.", "Inter Milan", "98 people", "the European Alps", "merit-based civil service system.", "The Ski Train", "severe", "Naples home.", "Stella McCartney", "Col. Elspeth Cameron-Ritchie,", "homicide", "the \"surge\" strategy he implemented last year.", "The few workers who went into the water swam to safety,", "voice-assistant software", "International Polo Club", "impeachment", "Kearny, New Jersey", "Thessaloniki and Athens,", "Tendai Biti,", "the # JustSayin", "gang rape", "The remaining 240 patients will be taken to hospitals in other provinces", "the genocide", "genocide", "The oldest documented bikinis", "Fullerton, California,", "Ma Khin Khin Leh,", "Charman Sinkfield, 30; Demario Ware, 20; and Jquante Crews,", "\"Don't Ask, Don't Tell\"", "Consumer Reports", "Sharon Bialek", "Sheikh Abu al-Nour al-Maqdessi,", "an independent homeland", "Florida's Everglades", "88-year-old", "\"It's more likely that lightning would cause a fire or punch a hole through the aircraft structure,\"", "ninth", "Magnavox Odyssey", "The Marriage Contract", "robin", "young earth creationism", "The Guest", "Green Day", "a skull", "2020 National Football League ( NFL ) season", "6 January 793"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5755208333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, true, false, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4908", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2753", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-1636", "mrqa_newsqa-validation-2709", "mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-3058", "mrqa_newsqa-validation-158", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-886", "mrqa_newsqa-validation-4122", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-1210", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-25", "mrqa_newsqa-validation-258", "mrqa_newsqa-validation-367", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-2945", "mrqa_newsqa-validation-667", "mrqa_naturalquestions-validation-861", "mrqa_triviaqa-validation-2022", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1239", "mrqa_searchqa-validation-3932", "mrqa_naturalquestions-validation-4863"], "SR": 0.515625, "CSR": 0.6072916666666667, "retrieved_ids": ["mrqa_squad-train-19997", "mrqa_squad-train-29656", "mrqa_squad-train-20698", "mrqa_squad-train-25385", "mrqa_squad-train-41390", "mrqa_squad-train-3858", "mrqa_squad-train-42932", "mrqa_squad-train-578", "mrqa_squad-train-58637", "mrqa_squad-train-14112", "mrqa_squad-train-77050", "mrqa_squad-train-85083", "mrqa_squad-train-13220", "mrqa_squad-train-80739", "mrqa_squad-train-35592", "mrqa_squad-train-66678", "mrqa_squad-train-39336", "mrqa_squad-train-78292", "mrqa_squad-train-49471", "mrqa_squad-train-19069", "mrqa_squad-train-63056", "mrqa_squad-train-727", "mrqa_squad-train-22272", "mrqa_squad-train-84261", "mrqa_squad-train-58708", "mrqa_squad-train-50436", "mrqa_squad-train-33390", "mrqa_squad-train-66183", "mrqa_squad-train-76722", "mrqa_squad-train-63342", "mrqa_squad-train-70648", "mrqa_squad-train-31956", "mrqa_squad-validation-4861", "mrqa_squad-validation-236", "mrqa_naturalquestions-validation-866", "mrqa_squad-validation-1529", "mrqa_searchqa-validation-3259", "mrqa_newsqa-validation-43", "mrqa_searchqa-validation-6638", "mrqa_newsqa-validation-2371", "mrqa_searchqa-validation-5963", "mrqa_searchqa-validation-11704", "mrqa_hotpotqa-validation-2600", "mrqa_squad-validation-3119", "mrqa_naturalquestions-validation-4193", "mrqa_squad-validation-9145", "mrqa_newsqa-validation-3863", "mrqa_newsqa-validation-616", "mrqa_squad-validation-7307", "mrqa_newsqa-validation-2614", "mrqa_squad-validation-7719", "mrqa_triviaqa-validation-2251", "mrqa_searchqa-validation-37", "mrqa_searchqa-validation-6011", "mrqa_squad-validation-7653", "mrqa_newsqa-validation-162", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-2122", "mrqa_squad-validation-2564", "mrqa_newsqa-validation-2632", "mrqa_squad-validation-10061", "mrqa_squad-validation-87", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-5"], "EFR": 1.0, "Overall": 0.7552083333333334}, {"timecode": 15, "before_eval_results": {"predictions": ["moist tropical", "90%", "1966", "Turkey", "Ollie Treiz", "salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species", "organisms", "libertarian", "late 1870s", "Death wish Coffee", "quality of a country's institutions and high levels of education", "proportionally", "North", "Mohammed Mohsen Zayed,", "they are \"still trying to absorb the impact of this week's stunning events,\"", "President Obama", "Friday,", "CNN affiliate WFTV.", "dropped dead in a mysterious scene Sunday before a polo match", "Brett Cummins,", "sculptures", "along the equator between South America and Africa.", "The 725-mile Veracruz regatta", "more than 200.", "at the ancient Greek site of Olympia", "Patrick McGoohan,", "Michael Partain,", "$627", "27-year-old's", "Virgin America", "\"Buying a Prius shows the world that you love the environment and hate using fuel,\"", "(CBTs)", "U.S.", "at Davidson college", "Sporting Lisbon", "Polo", "the defending champions were held to a 1-1 draw at Stoke City.", "1998.", "Jean Van de Velde", "overturned", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Secretary of State Hillary Clinton", "will look at how the universe formed by analyzing particle collisions.", "10 below", "\"She was focused so much on learning that she didn't notice,\"", "President Obama", "\"Dancing With the Stars\"", "two", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours,", "more than 1.2 million", "club managers,", "\"We say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well,", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "his mother", "pigs", "Matt Flinders", "Isar", "East of Eden", "Sam Bettley", "33-member", "the Sea of Galilee", "honey", "Oxfordshire", "Krusty Krab"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6614611813624971}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.5454545454545454, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.9473684210526316, 0.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714285, 0.6666666666666666, 1.0, 0.14545454545454548, 0.2666666666666667, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-543", "mrqa_squad-validation-9528", "mrqa_newsqa-validation-817", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-469", "mrqa_newsqa-validation-4126", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1104", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-3098", "mrqa_newsqa-validation-3190", "mrqa_newsqa-validation-3053", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2473", "mrqa_newsqa-validation-3899", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-346", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-92", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-3088", "mrqa_triviaqa-validation-5573"], "SR": 0.578125, "CSR": 0.60546875, "retrieved_ids": ["mrqa_squad-train-60629", "mrqa_squad-train-12442", "mrqa_squad-train-63190", "mrqa_squad-train-70367", "mrqa_squad-train-61815", "mrqa_squad-train-36908", "mrqa_squad-train-52284", "mrqa_squad-train-53482", "mrqa_squad-train-13306", "mrqa_squad-train-66767", "mrqa_squad-train-35501", "mrqa_squad-train-45366", "mrqa_squad-train-63567", "mrqa_squad-train-10208", "mrqa_squad-train-21972", "mrqa_squad-train-67410", "mrqa_squad-train-44860", "mrqa_squad-train-83738", "mrqa_squad-train-41536", "mrqa_squad-train-73600", "mrqa_squad-train-492", "mrqa_squad-train-81089", "mrqa_squad-train-9421", "mrqa_squad-train-80366", "mrqa_squad-train-67216", "mrqa_squad-train-6356", "mrqa_squad-train-5287", "mrqa_squad-train-36592", "mrqa_squad-train-68489", "mrqa_squad-train-73680", "mrqa_squad-train-76927", "mrqa_squad-train-10781", "mrqa_newsqa-validation-1271", "mrqa_naturalquestions-validation-4124", "mrqa_squad-validation-1766", "mrqa_searchqa-validation-16886", "mrqa_hotpotqa-validation-3070", "mrqa_searchqa-validation-5785", "mrqa_newsqa-validation-1947", "mrqa_squad-validation-9298", "mrqa_squad-validation-4015", "mrqa_searchqa-validation-16848", "mrqa_squad-validation-6393", "mrqa_squad-validation-3699", "mrqa_searchqa-validation-4674", "mrqa_squad-validation-4861", "mrqa_searchqa-validation-2252", "mrqa_searchqa-validation-86", "mrqa_newsqa-validation-1641", "mrqa_newsqa-validation-258", "mrqa_newsqa-validation-4203", "mrqa_squad-validation-4908", "mrqa_naturalquestions-validation-9273", "mrqa_searchqa-validation-10925", "mrqa_newsqa-validation-1101", "mrqa_searchqa-validation-8368", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-293", "mrqa_squad-validation-7051", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-1216", "mrqa_squad-validation-8046", "mrqa_newsqa-validation-502", "mrqa_searchqa-validation-13844"], "EFR": 1.0, "Overall": 0.75484375}, {"timecode": 16, "before_eval_results": {"predictions": ["np\u2261n (mod p) for any n if p is a prime number", "adjustable spring-loaded valve", "Grumman", "Synthetic aperture radar", "A fundamental error", "recant his writings", "varied collections of geologic, topographic, and natural ecosystem", "one can include arbitrarily many instances of 1 in any factorization", "136", "union membership", "Larger Catechism", "The European Court of Justice", "two", "Martin \"Al\" Culhane,", "Robert Park", "Rima Fakih", "fatally shooting a limo driver on February 14, 2002.", "2nd Lt. Holley Wimunc.", "1918-1919.", "Ben Kingsley", "U.S. Holocaust Memorial Museum,", "from Texas and Oklahoma to points east,", "Asashoryu's", "Mary Phagan,", "Barnes & Noble", "that the National Guard reallocated reconnaissance helicopters and robotic surveillance craft to the \"border states\" to prevent illegal immigration.", "The syndicate,", "U.S. senators who couldn't resist taking the vehicles for a spin.", "Ninety-two percent", "Larry Ellison,", "Taher Nunu", "Obama", "Karen Floyd", "U.S. Chamber of Commerce", "Kim Il Sung died", "Juan Martin Del Potro.", "Caylee Anthony,", "\"People have lost their homes, their jobs, their hope,\"", "25 dead", "200.", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "the guerrillas detained and \"executed\" eight people on February 6 in the town of Rio Bravo because the Indians were gathering information about the rebels to give to the Colombian military.", "\" Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "South African ministers and the deputy president have resigned as President Thabo Mbeki prepares to leave office.", "Seoul,", "Haiti,", "The United States", "\"Tiger Woods will be speaking to a small group of friends, colleagues and close associates,\"", "Daytime Emmy Lifetime Achievement Award", "Republican", "\" Teen Patti\"", "Eleven people died and 36 were wounded in the Monday terror attack,", "Hugo Chavez", "Four bodies", "translocation Down syndrome", "starch", "the UK", "Diptera", "100th anniversary of the first \" Tour de France\" bicycle race", "acid techno and drum and bass electronic musician", "cartilage", "Johannes Brahms", "the 17th century", "Orson Welles"], "metric_results": {"EM": 0.59375, "QA-F1": 0.695253558575927}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.6153846153846153, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.42857142857142855, 0.06666666666666668, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.10526315789473682, 1.0, 0.0, 0.6666666666666666, 0.16666666666666669, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.19999999999999998, 0.7692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2788", "mrqa_newsqa-validation-1420", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-1392", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-1442", "mrqa_newsqa-validation-2461", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-697", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3758", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-334", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-9726", "mrqa_triviaqa-validation-4760", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-1296", "mrqa_hotpotqa-validation-4478"], "SR": 0.59375, "CSR": 0.6047794117647058, "retrieved_ids": ["mrqa_squad-train-72524", "mrqa_squad-train-53600", "mrqa_squad-train-2562", "mrqa_squad-train-59244", "mrqa_squad-train-73744", "mrqa_squad-train-56788", "mrqa_squad-train-21410", "mrqa_squad-train-37053", "mrqa_squad-train-13115", "mrqa_squad-train-59883", "mrqa_squad-train-37978", "mrqa_squad-train-24572", "mrqa_squad-train-69514", "mrqa_squad-train-60535", "mrqa_squad-train-85050", "mrqa_squad-train-17819", "mrqa_squad-train-12407", "mrqa_squad-train-20162", "mrqa_squad-train-79897", "mrqa_squad-train-29936", "mrqa_squad-train-11354", "mrqa_squad-train-39308", "mrqa_squad-train-26842", "mrqa_squad-train-61640", "mrqa_squad-train-45457", "mrqa_squad-train-83159", "mrqa_squad-train-39436", "mrqa_squad-train-54475", "mrqa_squad-train-10169", "mrqa_squad-train-47639", "mrqa_squad-train-43017", "mrqa_squad-train-46482", "mrqa_searchqa-validation-12750", "mrqa_squad-validation-7473", "mrqa_searchqa-validation-6374", "mrqa_squad-validation-3543", "mrqa_squad-validation-2920", "mrqa_searchqa-validation-9777", "mrqa_squad-validation-1529", "mrqa_squad-validation-4908", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-162", "mrqa_searchqa-validation-12876", "mrqa_newsqa-validation-2249", "mrqa_newsqa-validation-2122", "mrqa_squad-validation-1313", "mrqa_newsqa-validation-1963", "mrqa_searchqa-validation-10883", "mrqa_newsqa-validation-2791", "mrqa_searchqa-validation-11770", "mrqa_newsqa-validation-1011", "mrqa_newsqa-validation-3949", "mrqa_hotpotqa-validation-1239", "mrqa_triviaqa-validation-2735", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-4015", "mrqa_searchqa-validation-8236", "mrqa_searchqa-validation-86", "mrqa_triviaqa-validation-5573", "mrqa_searchqa-validation-13077", "mrqa_newsqa-validation-5", "mrqa_searchqa-validation-14148", "mrqa_newsqa-validation-1425", "mrqa_searchqa-validation-5056"], "EFR": 1.0, "Overall": 0.7547058823529411}, {"timecode": 17, "before_eval_results": {"predictions": ["trade liberalisation", "1498", "lymphocytes or an antibody-based humoral response", "lens-shaped, 5\u20138 \u03bcm in diameter and 1\u20133 \u03bcm thick", "multi-cultural", "the father of the house when in his home", "John Fox", "US$1,000,000", "their Annual Conference", "Colonel Monckton", "thermodynamic", "a Russian-language component", "the FBI.", "helping to plan the September 11, 2001, terror attacks,", "an equine crisis", "he was diagnosed with skin cancer.", "Saturn owners", "iTunes", "Seoul", "a remote part of northwestern Montana", "President Mahmoud Ahmadinejad", "South Africa", "not named in Michael Jackson's 2002 will,", "Sunday", "Amsterdam, in the Netherlands,", "seven", "Iran test-launched a rocket capable of carrying a satellite,", "Lousiana", "\"Itsy Bitsy Teeny Weeny Yellow Polka Dot Bikini.\"", "2008", "the FBI.", "250,000", "the release of the four men", "Jake Garner", "question people if there's reason to suspect they're in the United States illegally.", "4,000", "allegations that a dorm parent mistreated students at the school.", "Pakistan", "St. Louis, Missouri,", "\"I'm just getting started.\"", "Pittsburgh", "flooding and debris", "Oxbow,", "Asashoryu", "Florida Everglades.", "Deputy Treasury Secretary", "Dubai", "Alfredo Astiz,", "a ban on inflatable or portable signs and banners on public property.", "Tim Clark, Matt Kuchar and Bubba Watson", "15,000", "President Bush", "corruption", "Terrell Owens", "Rajendra Prasad", "Hartford", "Ginger Rogers", "five", "Marine Corps", "Garfield", "a pickpocket", "seven", "the Ash Tree", "a transistor"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7106150793650794}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true], "QA-F1": [0.0, 0.0, 0.33333333333333337, 0.19999999999999998, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.8, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7535", "mrqa_squad-validation-8337", "mrqa_squad-validation-6559", "mrqa_squad-validation-8749", "mrqa_squad-validation-2318", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1799", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-2936", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-3144", "mrqa_newsqa-validation-593", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-1458", "mrqa_newsqa-validation-2148", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-621", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-3601", "mrqa_newsqa-validation-4147", "mrqa_searchqa-validation-16210", "mrqa_triviaqa-validation-5425"], "SR": 0.609375, "CSR": 0.6050347222222222, "retrieved_ids": ["mrqa_squad-train-29684", "mrqa_squad-train-59858", "mrqa_squad-train-60485", "mrqa_squad-train-69111", "mrqa_squad-train-81133", "mrqa_squad-train-37927", "mrqa_squad-train-62332", "mrqa_squad-train-57655", "mrqa_squad-train-68395", "mrqa_squad-train-37159", "mrqa_squad-train-69996", "mrqa_squad-train-82089", "mrqa_squad-train-12092", "mrqa_squad-train-60910", "mrqa_squad-train-53250", "mrqa_squad-train-25313", "mrqa_squad-train-33524", "mrqa_squad-train-21447", "mrqa_squad-train-81638", "mrqa_squad-train-3544", "mrqa_squad-train-69408", "mrqa_squad-train-75880", "mrqa_squad-train-5797", "mrqa_squad-train-24252", "mrqa_squad-train-63425", "mrqa_squad-train-8539", "mrqa_squad-train-9887", "mrqa_squad-train-40002", "mrqa_squad-train-56814", "mrqa_squad-train-62639", "mrqa_squad-train-34557", "mrqa_squad-train-82549", "mrqa_searchqa-validation-3735", "mrqa_searchqa-validation-37", "mrqa_squad-validation-8400", "mrqa_squad-validation-639", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-198", "mrqa_searchqa-validation-33", "mrqa_squad-validation-10011", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-14148", "mrqa_newsqa-validation-3543", "mrqa_searchqa-validation-1301", "mrqa_hotpotqa-validation-5831", "mrqa_hotpotqa-validation-1039", "mrqa_searchqa-validation-10297", "mrqa_squad-validation-8046", "mrqa_naturalquestions-validation-4124", "mrqa_newsqa-validation-2735", "mrqa_searchqa-validation-2651", "mrqa_squad-validation-3699", "mrqa_searchqa-validation-8236", "mrqa_searchqa-validation-3259", "mrqa_newsqa-validation-43", "mrqa_squad-validation-1456", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-10060", "mrqa_searchqa-validation-5128", "mrqa_squad-validation-5835", "mrqa_searchqa-validation-5857", "mrqa_newsqa-validation-1101", "mrqa_searchqa-validation-9403", "mrqa_searchqa-validation-14720"], "EFR": 1.0, "Overall": 0.7547569444444445}, {"timecode": 18, "before_eval_results": {"predictions": ["Lower Lorraine", "Westchester", "humid subtropical climate", "American Sign Language", "Fort Caroline", "specialty drugs", "Doctor of Theology", "God", "The Prince of P\u0142ock", "multi-stage centrifugal pumps", "Pet Sounds", "40", "Sax Rohmer", "Aug 24, 1572", "mathematics", "albino sperm whale", "Ilie Nastase", "Elijah", "Jeffrey Archer", "General Paulus", "Anne Boleyn", "Golda Meyerson", "a fur hat", "Objectivism", "Thai", "Parsley", "Japan", "Runic", "plutonium", "Andy Murray", "blancmange", "baloney cubed", "a rubbing", "recorder", "the heptathlon", "Microsoft", "Austria", "Isambard Kingdom Brunel", "Edward Lear", "Jamaica", "John Ford", "Petronas", "Beyonce", "Microsoft", "Charlemagne", "Praseodymium", "The Battle of the Three Emperors", "southern Pacific Ocean", "Trimdon,", "Midnight Cowboy", "Dada", "FIFA World Cup 2010", "Southwest Airlines", "Afghanistan", "Thomas Middleditch", "Rudolf H\u00f6ss", "3 May 1958", "Tom Hanks", "off Somalia's coast.", "cannibalism", "\"Royal\"", "Peugeot", "Banff", "a calves"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7098958333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6390", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2413", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-7672", "mrqa_triviaqa-validation-2542", "mrqa_triviaqa-validation-6649", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-6198", "mrqa_triviaqa-validation-237", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-2431", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-544", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3824", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-9943", "mrqa_searchqa-validation-3267"], "SR": 0.640625, "CSR": 0.606907894736842, "retrieved_ids": ["mrqa_squad-train-71186", "mrqa_squad-train-30774", "mrqa_squad-train-77272", "mrqa_squad-train-43796", "mrqa_squad-train-71541", "mrqa_squad-train-49086", "mrqa_squad-train-28520", "mrqa_squad-train-10730", "mrqa_squad-train-71954", "mrqa_squad-train-79666", "mrqa_squad-train-77756", "mrqa_squad-train-25132", "mrqa_squad-train-21376", "mrqa_squad-train-41109", "mrqa_squad-train-3077", "mrqa_squad-train-33245", "mrqa_squad-train-65160", "mrqa_squad-train-12355", "mrqa_squad-train-34871", "mrqa_squad-train-43768", "mrqa_squad-train-9694", "mrqa_squad-train-78303", "mrqa_squad-train-9588", "mrqa_squad-train-27465", "mrqa_squad-train-63638", "mrqa_squad-train-2874", "mrqa_squad-train-18790", "mrqa_squad-train-10021", "mrqa_squad-train-44759", "mrqa_squad-train-81092", "mrqa_squad-train-41448", "mrqa_squad-train-19470", "mrqa_squad-validation-4462", "mrqa_searchqa-validation-7384", "mrqa_newsqa-validation-2204", "mrqa_triviaqa-validation-2022", "mrqa_searchqa-validation-10624", "mrqa_squad-validation-7051", "mrqa_newsqa-validation-893", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-10017", "mrqa_naturalquestions-validation-6324", "mrqa_searchqa-validation-5301", "mrqa_newsqa-validation-3370", "mrqa_squad-validation-694", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-1104", "mrqa_squad-validation-639", "mrqa_searchqa-validation-2752", "mrqa_newsqa-validation-2148", "mrqa_squad-validation-10011", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2133", "mrqa_hotpotqa-validation-1239", "mrqa_newsqa-validation-2371", "mrqa_searchqa-validation-10103", "mrqa_newsqa-validation-2122", "mrqa_squad-validation-1529", "mrqa_naturalquestions-validation-4193", "mrqa_newsqa-validation-1224", "mrqa_searchqa-validation-6011", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-158", "mrqa_newsqa-validation-621"], "EFR": 1.0, "Overall": 0.7551315789473685}, {"timecode": 19, "before_eval_results": {"predictions": ["2.2 inches", "tentilla", "Sky Q Silver set top boxes", "ash tree", "24 September 2007", "2001", "34\u201319", "1991", "Canada", "protects and holds the lungs, heart, trachea, esophagus, endocrine glands, thoracic aorta and the pulmonary artery.", "Tony Blair", "The Flintstones", "9-1-1", "Jonathan Swift", "South Sudan", "Maria Bueno", "dill", "Frankie Laine,", "1948", "Thor", "Germany", "Goosnargh", "a bear suit", "dna structure", "Montr\u00e9al", "Adidas", "\"A toast to you [Sir]\"", "The Rocky and Bullwinkle Show", "Jack Regan", "the Lackawanna six", "Poland", "Indiana Jones", "Sousa Band", "Hyde Park Corner", "Sydney", "Alabama, Alaska, Arizona, Arkansas and California,", "Jura", "armoured all-terrain fighting vehicles", "a finger", "a meteoroid", "Lew Hoad", "bobbyjo", "Lola", "Bodhidharma", "Klaus dolls", "Albert Reynolds", "a rope", "Baltic Sea port", "Singapore", "cathead", "yellow", "cat food", "austerio Piaggio", "Squamish, British Columbia, Canada", "2015", "Theme Park World", "Cape Cod", "\"Itsy Bitsy Teeny Weeny Yellow Polka Dot Bikini.\"", "10 percent", "867-5309", "\"D\" Briefing Flashcards", "Madame Flora", "the small intestine", "Buddha"], "metric_results": {"EM": 0.5, "QA-F1": 0.5765625}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4634", "mrqa_triviaqa-validation-3450", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-7311", "mrqa_triviaqa-validation-3423", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-4973", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-7281", "mrqa_triviaqa-validation-5592", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-7563", "mrqa_triviaqa-validation-7383", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3815", "mrqa_triviaqa-validation-7777", "mrqa_triviaqa-validation-4580", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-2541", "mrqa_triviaqa-validation-644", "mrqa_triviaqa-validation-2858", "mrqa_triviaqa-validation-3087", "mrqa_triviaqa-validation-7426", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-1772", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4323", "mrqa_newsqa-validation-2375", "mrqa_searchqa-validation-10359", "mrqa_searchqa-validation-6041"], "SR": 0.5, "CSR": 0.6015625, "retrieved_ids": ["mrqa_squad-train-55848", "mrqa_squad-train-60798", "mrqa_squad-train-54915", "mrqa_squad-train-19588", "mrqa_squad-train-4163", "mrqa_squad-train-35038", "mrqa_squad-train-2115", "mrqa_squad-train-59748", "mrqa_squad-train-16678", "mrqa_squad-train-18409", "mrqa_squad-train-11073", "mrqa_squad-train-81112", "mrqa_squad-train-58552", "mrqa_squad-train-86460", "mrqa_squad-train-29446", "mrqa_squad-train-79330", "mrqa_squad-train-53507", "mrqa_squad-train-83232", "mrqa_squad-train-76447", "mrqa_squad-train-70582", "mrqa_squad-train-42214", "mrqa_squad-train-23101", "mrqa_squad-train-63542", "mrqa_squad-train-883", "mrqa_squad-train-65377", "mrqa_squad-train-56329", "mrqa_squad-train-52338", "mrqa_squad-train-74812", "mrqa_squad-train-44344", "mrqa_squad-train-81972", "mrqa_squad-train-73144", "mrqa_squad-train-60985", "mrqa_triviaqa-validation-3824", "mrqa_squad-validation-1500", "mrqa_searchqa-validation-2022", "mrqa_searchqa-validation-6843", "mrqa_searchqa-validation-5963", "mrqa_squad-validation-2455", "mrqa_hotpotqa-validation-3070", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-3127", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-2148", "mrqa_searchqa-validation-15748", "mrqa_triviaqa-validation-4363", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2399", "mrqa_searchqa-validation-11451", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-3258", "mrqa_squad-validation-6393", "mrqa_triviaqa-validation-2363", "mrqa_squad-validation-8864", "mrqa_searchqa-validation-37", "mrqa_newsqa-validation-2032", "mrqa_squad-validation-8597", "mrqa_searchqa-validation-6374", "mrqa_searchqa-validation-8715", "mrqa_newsqa-validation-3863", "mrqa_squad-validation-7574", "mrqa_searchqa-validation-1384", "mrqa_squad-validation-7051"], "EFR": 1.0, "Overall": 0.7540625000000001}, {"timecode": 20, "UKR": 0.779296875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1296", "mrqa_hotpotqa-validation-1297", "mrqa_hotpotqa-validation-1331", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-2949", "mrqa_hotpotqa-validation-3070", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4478", "mrqa_hotpotqa-validation-5014", "mrqa_hotpotqa-validation-5049", "mrqa_hotpotqa-validation-5112", "mrqa_hotpotqa-validation-5394", "mrqa_hotpotqa-validation-5831", "mrqa_naturalquestions-validation-3545", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-4479", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6206", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7733", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9726", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1011", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-1152", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-1210", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-1309", "mrqa_newsqa-validation-1396", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-1434", "mrqa_newsqa-validation-1455", "mrqa_newsqa-validation-1458", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-162", "mrqa_newsqa-validation-1636", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2186", "mrqa_newsqa-validation-2190", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2436", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-2592", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2697", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2753", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2791", "mrqa_newsqa-validation-2791", "mrqa_newsqa-validation-2836", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2861", "mrqa_newsqa-validation-2967", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-2990", "mrqa_newsqa-validation-3016", "mrqa_newsqa-validation-3027", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3088", "mrqa_newsqa-validation-3098", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3419", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-3472", "mrqa_newsqa-validation-3499", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-3601", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3665", "mrqa_newsqa-validation-367", "mrqa_newsqa-validation-3685", "mrqa_newsqa-validation-3722", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3758", "mrqa_newsqa-validation-3762", "mrqa_newsqa-validation-3795", "mrqa_newsqa-validation-3797", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-3878", "mrqa_newsqa-validation-3881", "mrqa_newsqa-validation-3886", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3899", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-3965", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-407", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4178", "mrqa_newsqa-validation-469", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-548", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-605", "mrqa_newsqa-validation-627", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-92", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-10297", "mrqa_searchqa-validation-10359", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10823", "mrqa_searchqa-validation-10883", "mrqa_searchqa-validation-11002", "mrqa_searchqa-validation-11091", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-11451", "mrqa_searchqa-validation-11477", "mrqa_searchqa-validation-1162", "mrqa_searchqa-validation-12038", "mrqa_searchqa-validation-12312", "mrqa_searchqa-validation-12313", "mrqa_searchqa-validation-12462", "mrqa_searchqa-validation-12547", "mrqa_searchqa-validation-1256", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-13459", "mrqa_searchqa-validation-13476", "mrqa_searchqa-validation-13844", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-13899", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-1453", "mrqa_searchqa-validation-14734", "mrqa_searchqa-validation-15224", "mrqa_searchqa-validation-15795", "mrqa_searchqa-validation-15804", "mrqa_searchqa-validation-16282", "mrqa_searchqa-validation-16625", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-16886", "mrqa_searchqa-validation-1843", "mrqa_searchqa-validation-198", "mrqa_searchqa-validation-2175", "mrqa_searchqa-validation-2214", "mrqa_searchqa-validation-2338", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-2863", "mrqa_searchqa-validation-2871", "mrqa_searchqa-validation-3127", "mrqa_searchqa-validation-3139", "mrqa_searchqa-validation-3478", "mrqa_searchqa-validation-3644", "mrqa_searchqa-validation-3932", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-4057", "mrqa_searchqa-validation-4386", "mrqa_searchqa-validation-4553", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-4674", "mrqa_searchqa-validation-4910", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-5329", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-541", "mrqa_searchqa-validation-5456", "mrqa_searchqa-validation-5785", "mrqa_searchqa-validation-6011", "mrqa_searchqa-validation-6122", "mrqa_searchqa-validation-6264", "mrqa_searchqa-validation-6490", "mrqa_searchqa-validation-6638", "mrqa_searchqa-validation-6722", "mrqa_searchqa-validation-6992", "mrqa_searchqa-validation-7043", "mrqa_searchqa-validation-7384", "mrqa_searchqa-validation-7564", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8117", "mrqa_searchqa-validation-8574", "mrqa_searchqa-validation-86", "mrqa_searchqa-validation-8658", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8869", "mrqa_searchqa-validation-9403", "mrqa_searchqa-validation-9605", "mrqa_searchqa-validation-9777", "mrqa_squad-validation-10011", "mrqa_squad-validation-10011", "mrqa_squad-validation-10014", "mrqa_squad-validation-10125", "mrqa_squad-validation-10218", "mrqa_squad-validation-10252", "mrqa_squad-validation-10274", "mrqa_squad-validation-10280", "mrqa_squad-validation-10287", "mrqa_squad-validation-10307", "mrqa_squad-validation-10380", "mrqa_squad-validation-10395", "mrqa_squad-validation-10433", "mrqa_squad-validation-1049", "mrqa_squad-validation-10494", "mrqa_squad-validation-10506", "mrqa_squad-validation-1086", "mrqa_squad-validation-1092", "mrqa_squad-validation-1122", "mrqa_squad-validation-1177", "mrqa_squad-validation-1206", "mrqa_squad-validation-1215", "mrqa_squad-validation-1329", "mrqa_squad-validation-1347", "mrqa_squad-validation-1407", "mrqa_squad-validation-1456", "mrqa_squad-validation-1548", "mrqa_squad-validation-1587", "mrqa_squad-validation-1615", "mrqa_squad-validation-1661", "mrqa_squad-validation-167", "mrqa_squad-validation-1753", "mrqa_squad-validation-19", "mrqa_squad-validation-1983", "mrqa_squad-validation-2009", "mrqa_squad-validation-204", "mrqa_squad-validation-2072", "mrqa_squad-validation-2088", "mrqa_squad-validation-2095", "mrqa_squad-validation-2102", "mrqa_squad-validation-217", "mrqa_squad-validation-2190", "mrqa_squad-validation-2192", "mrqa_squad-validation-2226", "mrqa_squad-validation-2286", "mrqa_squad-validation-2289", "mrqa_squad-validation-2346", "mrqa_squad-validation-2353", "mrqa_squad-validation-2365", "mrqa_squad-validation-2372", "mrqa_squad-validation-2395", "mrqa_squad-validation-2411", "mrqa_squad-validation-2421", "mrqa_squad-validation-2476", "mrqa_squad-validation-25", "mrqa_squad-validation-253", "mrqa_squad-validation-2560", "mrqa_squad-validation-2564", "mrqa_squad-validation-2622", "mrqa_squad-validation-2656", "mrqa_squad-validation-2684", "mrqa_squad-validation-2762", "mrqa_squad-validation-2833", "mrqa_squad-validation-2844", "mrqa_squad-validation-2857", "mrqa_squad-validation-2865", "mrqa_squad-validation-2932", "mrqa_squad-validation-2949", "mrqa_squad-validation-2976", "mrqa_squad-validation-3040", "mrqa_squad-validation-3130", "mrqa_squad-validation-3168", "mrqa_squad-validation-3382", "mrqa_squad-validation-3393", "mrqa_squad-validation-3407", "mrqa_squad-validation-3456", "mrqa_squad-validation-3461", "mrqa_squad-validation-3493", "mrqa_squad-validation-3543", "mrqa_squad-validation-3559", "mrqa_squad-validation-3654", "mrqa_squad-validation-3681", "mrqa_squad-validation-3699", "mrqa_squad-validation-3941", "mrqa_squad-validation-3954", "mrqa_squad-validation-3955", "mrqa_squad-validation-4015", "mrqa_squad-validation-4162", "mrqa_squad-validation-4308", "mrqa_squad-validation-4382", "mrqa_squad-validation-4398", "mrqa_squad-validation-4402", "mrqa_squad-validation-4452", "mrqa_squad-validation-4489", "mrqa_squad-validation-4502", "mrqa_squad-validation-452", "mrqa_squad-validation-455", "mrqa_squad-validation-4550", "mrqa_squad-validation-457", "mrqa_squad-validation-4585", "mrqa_squad-validation-4594", "mrqa_squad-validation-4619", "mrqa_squad-validation-4633", "mrqa_squad-validation-4634", "mrqa_squad-validation-466", "mrqa_squad-validation-4664", "mrqa_squad-validation-4694", "mrqa_squad-validation-4736", "mrqa_squad-validation-4763", "mrqa_squad-validation-4764", "mrqa_squad-validation-477", "mrqa_squad-validation-4782", "mrqa_squad-validation-4829", "mrqa_squad-validation-494", "mrqa_squad-validation-4956", "mrqa_squad-validation-4975", "mrqa_squad-validation-4999", "mrqa_squad-validation-5003", "mrqa_squad-validation-5014", "mrqa_squad-validation-5029", "mrqa_squad-validation-5071", "mrqa_squad-validation-5178", "mrqa_squad-validation-5302", "mrqa_squad-validation-5311", "mrqa_squad-validation-5333", "mrqa_squad-validation-5360", "mrqa_squad-validation-5370", "mrqa_squad-validation-5377", "mrqa_squad-validation-538", "mrqa_squad-validation-5418", "mrqa_squad-validation-543", "mrqa_squad-validation-5451", "mrqa_squad-validation-5465", "mrqa_squad-validation-5470", "mrqa_squad-validation-5528", "mrqa_squad-validation-5570", "mrqa_squad-validation-5589", "mrqa_squad-validation-5616", "mrqa_squad-validation-5617", "mrqa_squad-validation-5706", "mrqa_squad-validation-5806", "mrqa_squad-validation-5824", "mrqa_squad-validation-5824", "mrqa_squad-validation-5852", "mrqa_squad-validation-5911", "mrqa_squad-validation-5956", "mrqa_squad-validation-5961", "mrqa_squad-validation-5995", "mrqa_squad-validation-6058", "mrqa_squad-validation-6082", "mrqa_squad-validation-6097", "mrqa_squad-validation-6185", "mrqa_squad-validation-6206", "mrqa_squad-validation-6241", "mrqa_squad-validation-6349", "mrqa_squad-validation-6354", "mrqa_squad-validation-641", "mrqa_squad-validation-6557", "mrqa_squad-validation-6569", "mrqa_squad-validation-6572", "mrqa_squad-validation-6680", "mrqa_squad-validation-693", "mrqa_squad-validation-694", "mrqa_squad-validation-6975", "mrqa_squad-validation-703", "mrqa_squad-validation-7051", "mrqa_squad-validation-7064", "mrqa_squad-validation-719", "mrqa_squad-validation-7243", "mrqa_squad-validation-7307", "mrqa_squad-validation-7330", "mrqa_squad-validation-7338", "mrqa_squad-validation-7462", "mrqa_squad-validation-7608", "mrqa_squad-validation-7622", "mrqa_squad-validation-763", "mrqa_squad-validation-7659", "mrqa_squad-validation-7665", "mrqa_squad-validation-7719", "mrqa_squad-validation-7729", "mrqa_squad-validation-773", "mrqa_squad-validation-7751", "mrqa_squad-validation-7785", "mrqa_squad-validation-7822", "mrqa_squad-validation-7829", "mrqa_squad-validation-7837", "mrqa_squad-validation-7855", "mrqa_squad-validation-7908", "mrqa_squad-validation-7918", "mrqa_squad-validation-7958", "mrqa_squad-validation-7964", "mrqa_squad-validation-8046", "mrqa_squad-validation-8056", "mrqa_squad-validation-8115", "mrqa_squad-validation-813", "mrqa_squad-validation-8136", "mrqa_squad-validation-8196", "mrqa_squad-validation-8204", "mrqa_squad-validation-8210", "mrqa_squad-validation-8216", "mrqa_squad-validation-828", "mrqa_squad-validation-8337", "mrqa_squad-validation-8436", "mrqa_squad-validation-850", "mrqa_squad-validation-8575", "mrqa_squad-validation-8597", "mrqa_squad-validation-8683", "mrqa_squad-validation-87", "mrqa_squad-validation-883", "mrqa_squad-validation-8864", "mrqa_squad-validation-9017", "mrqa_squad-validation-9054", "mrqa_squad-validation-9110", "mrqa_squad-validation-9135", "mrqa_squad-validation-9145", "mrqa_squad-validation-9178", "mrqa_squad-validation-919", "mrqa_squad-validation-9198", "mrqa_squad-validation-9227", "mrqa_squad-validation-9298", "mrqa_squad-validation-9334", "mrqa_squad-validation-9362", "mrqa_squad-validation-9365", "mrqa_squad-validation-9373", "mrqa_squad-validation-9559", "mrqa_squad-validation-957", "mrqa_squad-validation-9603", "mrqa_squad-validation-9617", "mrqa_squad-validation-9640", "mrqa_squad-validation-9734", "mrqa_squad-validation-9870", "mrqa_squad-validation-9918", "mrqa_squad-validation-997", "mrqa_squad-validation-9993", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-1358", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-1452", "mrqa_triviaqa-validation-1524", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-1927", "mrqa_triviaqa-validation-1927", "mrqa_triviaqa-validation-1945", "mrqa_triviaqa-validation-2071", "mrqa_triviaqa-validation-2073", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-2251", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-2344", "mrqa_triviaqa-validation-2431", "mrqa_triviaqa-validation-2541", "mrqa_triviaqa-validation-2677", "mrqa_triviaqa-validation-2681", "mrqa_triviaqa-validation-2858", "mrqa_triviaqa-validation-3006", "mrqa_triviaqa-validation-3087", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3383", "mrqa_triviaqa-validation-3423", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-3562", "mrqa_triviaqa-validation-3732", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-3905", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-4336", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-4742", "mrqa_triviaqa-validation-4782", "mrqa_triviaqa-validation-4973", "mrqa_triviaqa-validation-5338", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-544", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-5766", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-6198", "mrqa_triviaqa-validation-644", "mrqa_triviaqa-validation-6675", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-7474", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-7624", "mrqa_triviaqa-validation-7777"], "OKR": 0.888671875, "KG": 0.4609375, "before_eval_results": {"predictions": ["chromalveolate", "non-specific", "1525\u201332", "Only a few", "solution", "2011", "random noise", "Wardenclyffe", "Passepartout", "Ogaden", "Washington Post", "My Town Tokyo", "Steve Biko", "pottery and china", "blister beetle", "acute", "nasa bayabasan", "sour", "Beyonce", "Norman Kingsley Mailer", "Oliver!", "kunsky", "Bolton", "Hawaii", "tsarevitch", "taxidermist", "junk Planet", "Bridgeport", "your Excellency", "George III", "George Atzerodt", "Severn", "Canada", "Leonard Nimoy", "islands in the Caribbean", "(John) Bercow", "Jesse Garon Presley", "komando Pasukan Khusus", "lithium", "40", "The Duchess", "Nick Ross", "white", "China", "Salt Lake City", "Perseus", "Capricorn", "rugby", "Sergio Garcia", "butterfly", "(Jerry Stiller) and Estelle Costanza (Estelle Harris)", "The Savoy", "Steve Jobs", "habitat", "2 %", "729", "Twitch Interactive", "right-wing extremist groups.", "Rocky Ford brand cantaloupes", "Heartbreak Hotel", "leopard", "Wes Craven", "Australian", "\"$10,000 Kelly,\""], "metric_results": {"EM": 0.5, "QA-F1": 0.5683531746031746}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8756", "mrqa_squad-validation-2513", "mrqa_triviaqa-validation-7536", "mrqa_triviaqa-validation-6930", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6527", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2716", "mrqa_triviaqa-validation-3725", "mrqa_triviaqa-validation-3820", "mrqa_triviaqa-validation-3232", "mrqa_triviaqa-validation-5789", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-4453", "mrqa_triviaqa-validation-5698", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-5810", "mrqa_triviaqa-validation-5659", "mrqa_triviaqa-validation-4152", "mrqa_triviaqa-validation-1961", "mrqa_triviaqa-validation-4442", "mrqa_triviaqa-validation-5771", "mrqa_triviaqa-validation-2250", "mrqa_triviaqa-validation-7635", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-875", "mrqa_hotpotqa-validation-3843", "mrqa_hotpotqa-validation-4791", "mrqa_newsqa-validation-4158", "mrqa_searchqa-validation-10273", "mrqa_hotpotqa-validation-2205"], "SR": 0.5, "CSR": 0.5967261904761905, "retrieved_ids": ["mrqa_squad-train-84710", "mrqa_squad-train-4747", "mrqa_squad-train-41574", "mrqa_squad-train-86472", "mrqa_squad-train-36880", "mrqa_squad-train-54939", "mrqa_squad-train-42035", "mrqa_squad-train-23667", "mrqa_squad-train-72644", "mrqa_squad-train-52832", "mrqa_squad-train-83140", "mrqa_squad-train-37246", "mrqa_squad-train-71026", "mrqa_squad-train-61645", "mrqa_squad-train-28677", "mrqa_squad-train-52243", "mrqa_squad-train-7021", "mrqa_squad-train-82218", "mrqa_squad-train-79088", "mrqa_squad-train-17305", "mrqa_squad-train-68604", "mrqa_squad-train-80940", "mrqa_squad-train-39740", "mrqa_squad-train-45551", "mrqa_squad-train-82846", "mrqa_squad-train-1659", "mrqa_squad-train-83652", "mrqa_squad-train-72513", "mrqa_squad-train-61487", "mrqa_squad-train-81295", "mrqa_squad-train-64624", "mrqa_squad-train-2606", "mrqa_newsqa-validation-3965", "mrqa_searchqa-validation-7852", "mrqa_searchqa-validation-11888", "mrqa_naturalquestions-validation-1549", "mrqa_newsqa-validation-2204", "mrqa_hotpotqa-validation-1239", "mrqa_squad-validation-2920", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-937", "mrqa_searchqa-validation-1301", "mrqa_newsqa-validation-1309", "mrqa_newsqa-validation-2246", "mrqa_searchqa-validation-16848", "mrqa_searchqa-validation-5301", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-3406", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-4019", "mrqa_searchqa-validation-6638", "mrqa_squad-validation-10274", "mrqa_newsqa-validation-4203", "mrqa_naturalquestions-validation-4193", "mrqa_newsqa-validation-1289", "mrqa_squad-validation-7719", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-2133", "mrqa_searchqa-validation-12876", "mrqa_newsqa-validation-4122", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-10925", "mrqa_searchqa-validation-266", "mrqa_searchqa-validation-12750"], "EFR": 1.0, "Overall": 0.7451264880952382}, {"timecode": 21, "before_eval_results": {"predictions": ["Edison Medal", "Extension", "bourgeois architecture", "confrontational", "the Florida legislature", "gold", "Chinese", "Southern Counties", "Telstar", "wED/RLS", "Buzz Aldrin", "saint Timothy", "Niger", "Backgammon", "Instagram", "Home alone", "Columbus", "T.S. Eliot", "Venus", "The Wailers", "the Crusades", "nicky Henderson", "gable-roof", "dagger", "norman-Woman", "piu forte (piu f)", "Socrates", "selenium", "Stephen King", "chestnut", "Catskill Mountains", "j Johnny Depp", "watt", "fluid", "Jordan", "Noah Beery, Jr.", "London", "chainsaw", "Poland", "EGBDF", "between the eyebrows", "dill", "eukharisti\u0101", "a hundred years", "liqueurs", "Washington, D.C.", "hanger Lane Junction & Acton Town tube station", "kurkama", "Melbourne, Victoria, Australia", "jags Edinburgh City", "Tangled", "Vincent Motorcycle Company", "Melissa Duck", "inner core", "Mr. Chipping", "The Prodigy", "John Anthony \"Jack\" White", "Michelle Rounds", "21-year-old", "george Stein", "Daytona", "nick Reiner", "Mickey's PhilharMagic", "hiphop"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5338541666666666}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-927", "mrqa_triviaqa-validation-868", "mrqa_triviaqa-validation-2296", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-5322", "mrqa_triviaqa-validation-170", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-381", "mrqa_triviaqa-validation-6199", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-5052", "mrqa_triviaqa-validation-7334", "mrqa_triviaqa-validation-5909", "mrqa_triviaqa-validation-3555", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-6066", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-2406", "mrqa_triviaqa-validation-5681", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-1972", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-6827", "mrqa_triviaqa-validation-7233", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-3402", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-7539", "mrqa_naturalquestions-validation-4083", "mrqa_hotpotqa-validation-2932", "mrqa_searchqa-validation-1488", "mrqa_hotpotqa-validation-2731", "mrqa_hotpotqa-validation-550"], "SR": 0.46875, "CSR": 0.5909090909090908, "retrieved_ids": ["mrqa_squad-train-38719", "mrqa_squad-train-25189", "mrqa_squad-train-657", "mrqa_squad-train-67158", "mrqa_squad-train-48458", "mrqa_squad-train-43528", "mrqa_squad-train-70356", "mrqa_squad-train-36333", "mrqa_squad-train-78391", "mrqa_squad-train-887", "mrqa_squad-train-20344", "mrqa_squad-train-52453", "mrqa_squad-train-69857", "mrqa_squad-train-563", "mrqa_squad-train-52783", "mrqa_squad-train-5689", "mrqa_squad-train-48469", "mrqa_squad-train-11770", "mrqa_squad-train-16731", "mrqa_squad-train-15315", "mrqa_squad-train-47950", "mrqa_squad-train-84528", "mrqa_squad-train-1089", "mrqa_squad-train-35692", "mrqa_squad-train-75750", "mrqa_squad-train-30912", "mrqa_squad-train-36709", "mrqa_squad-train-72990", "mrqa_squad-train-11086", "mrqa_squad-train-57406", "mrqa_squad-train-86333", "mrqa_squad-train-82722", "mrqa_newsqa-validation-2032", "mrqa_searchqa-validation-16210", "mrqa_searchqa-validation-5679", "mrqa_squad-validation-1456", "mrqa_newsqa-validation-2408", "mrqa_triviaqa-validation-4442", "mrqa_searchqa-validation-8845", "mrqa_searchqa-validation-16625", "mrqa_triviaqa-validation-4760", "mrqa_squad-validation-3543", "mrqa_triviaqa-validation-2754", "mrqa_squad-validation-2455", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-2122", "mrqa_squad-validation-6809", "mrqa_triviaqa-validation-7777", "mrqa_newsqa-validation-2892", "mrqa_searchqa-validation-3960", "mrqa_squad-validation-9533", "mrqa_searchqa-validation-2617", "mrqa_searchqa-validation-11451", "mrqa_squad-validation-236", "mrqa_triviaqa-validation-3815", "mrqa_newsqa-validation-2632", "mrqa_newsqa-validation-616", "mrqa_newsqa-validation-1041", "mrqa_searchqa-validation-14631", "mrqa_squad-validation-4921", "mrqa_squad-validation-4452", "mrqa_triviaqa-validation-862", "mrqa_squad-validation-6759", "mrqa_newsqa-validation-3350"], "EFR": 1.0, "Overall": 0.7439630681818181}, {"timecode": 22, "before_eval_results": {"predictions": ["The Times newspaper", "being drafted into the Austro-Hungarian Army", "63,523", "faith in Christ", "Ticonderoga Point", "a seal", "Season 4", "Jaime", "1972 -- 81 )", "Dottie West", "May 1980", "tim Allen", "Central and South regions", "Muguruza", "Missi Hale", "2018", "over two days", "variation in plants", "Baltimore, Maryland", "The United States is the only Western country currently applying the death penalty, one of 57 countries worldwide applying it,", "Second Battle of Manassas", "Paspahegh Indians", "left atrium and ventricle", "Brewster family", "1560s.", "Davos", "Prince James, Duke of York and of Albany", "jazz", "2008", "the U.S. service members who have died without their remains being identified", "March 16, 2018", "Narendra Modi", "Sohrai", "an explosion", "a pop and R&B ballad", "Annette", "May 2017", "yorkshire rhinoceros", "ABC", "cell nucleus", "carrying an amino acid to the protein synthetic machinery of a cell ( ribosome )", "Henry Purcell", "Thomas Edison", "Hellenism", "1967 onwards", "Jack Nicklaus", "Jenny Slate", "9.1 %", "hero", "37.7", "1954", "1922 to 1991", "ebert", "gda\u0144sk", "Ethiopia", "Mountain West Conference", "Sydney", "Talib Kweli", "look at how the universe formed by analyzing particle collisions.", "five female pastors", "combat veterans", "a Mill on the Floss", "Antarctica", "cherry bomb"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5771599200530653}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.5, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.14285714285714288, 1.0, 0.4, 0.0, 0.0, 0.8, 0.6451612903225806, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.16666666666666669, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-2919", "mrqa_squad-validation-2373", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-5942", "mrqa_naturalquestions-validation-8355", "mrqa_naturalquestions-validation-1414", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-7962", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-1433", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-3962", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-142", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-7003", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-6089", "mrqa_naturalquestions-validation-6383", "mrqa_naturalquestions-validation-7080", "mrqa_triviaqa-validation-69", "mrqa_newsqa-validation-2275", "mrqa_newsqa-validation-4157", "mrqa_searchqa-validation-15953"], "SR": 0.421875, "CSR": 0.5835597826086957, "retrieved_ids": ["mrqa_squad-train-40393", "mrqa_squad-train-49871", "mrqa_squad-train-74272", "mrqa_squad-train-19727", "mrqa_squad-train-47476", "mrqa_squad-train-68827", "mrqa_squad-train-19977", "mrqa_squad-train-86064", "mrqa_squad-train-49092", "mrqa_squad-train-56679", "mrqa_squad-train-18564", "mrqa_squad-train-12150", "mrqa_squad-train-51957", "mrqa_squad-train-8792", "mrqa_squad-train-7405", "mrqa_squad-train-48188", "mrqa_squad-train-20568", "mrqa_squad-train-45893", "mrqa_squad-train-66419", "mrqa_squad-train-59182", "mrqa_squad-train-57401", "mrqa_squad-train-45113", "mrqa_squad-train-38433", "mrqa_squad-train-27315", "mrqa_squad-train-54448", "mrqa_squad-train-48684", "mrqa_squad-train-71588", "mrqa_squad-train-13078", "mrqa_squad-train-62243", "mrqa_squad-train-20702", "mrqa_squad-train-32016", "mrqa_squad-train-14870", "mrqa_squad-validation-7051", "mrqa_searchqa-validation-11770", "mrqa_squad-validation-1529", "mrqa_searchqa-validation-6962", "mrqa_squad-validation-543", "mrqa_newsqa-validation-2632", "mrqa_newsqa-validation-2122", "mrqa_triviaqa-validation-1630", "mrqa_newsqa-validation-3911", "mrqa_triviaqa-validation-412", "mrqa_searchqa-validation-13813", "mrqa_newsqa-validation-2629", "mrqa_newsqa-validation-1428", "mrqa_triviaqa-validation-7743", "mrqa_searchqa-validation-2871", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-7334", "mrqa_newsqa-validation-2872", "mrqa_triviaqa-validation-4453", "mrqa_searchqa-validation-5963", "mrqa_searchqa-validation-10318", "mrqa_searchqa-validation-9777", "mrqa_squad-validation-2372", "mrqa_searchqa-validation-15312", "mrqa_squad-validation-8864", "mrqa_triviaqa-validation-1961", "mrqa_hotpotqa-validation-4323", "mrqa_searchqa-validation-2022", "mrqa_newsqa-validation-4147", "mrqa_triviaqa-validation-7635", "mrqa_newsqa-validation-3899", "mrqa_squad-validation-117"], "EFR": 1.0, "Overall": 0.7424932065217391}, {"timecode": 23, "before_eval_results": {"predictions": ["Andrew Alper", "Newton", "life on Tyneside", "vicious and destructive", "60%", "girls", "in the 1980s", "Rakuten Kitazawa", "almost 3,000", "`` Audrey II ''", "T'Pau", "Millerlite", "comedy web television series", "Universal Pictures and Focus Features", "LED illuminated display", "a line of committed and effective Sultans", "there are no repeated data values", "Mangal Pandey", "North Carolina", "innermost in the eye", "IBM", "Felicity Huffman", "Djokovic", "84", "United States economy first went into an economic recession", "Welsh Borders and Shropshire area of the UK", "1979 / 80", "Pyeongchang County, Gangwon Province, South Korea", "Sanchez Navarro", "the nerves and ganglia outside the brain and spinal cord", "Nalini Negi", "very important", "in the Southern United States", "Jodie Foster", "Frederick Chiluba, Levy Mwanawasa, Rupiah Banda, Michael Sata, and current President Edgar Lungu.", "May 18, 2018", "10 May 1940", "Sally Field", "Queen M\u00e1xima of the Netherlands", "deals with American musician Lenny Kravitz for his second studio album, Mama Said ( 1991 )", "Massillon, Ohio", "African - Americans", "giant planet", "RAF, Fighter Command", "10,000 BC", "New York City", "Egypt", "20 July 2015", "Coroebus of Elis", "Tami Lynn", "Phil Simms", "1", "Nepal", "Elton John", "ozone", "Pakistan", "Sam Raimi", "7 October 1978", "a bill in the Texas Legislature that would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "natural disasters", "1819", "wiki", "a gaffer"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6811011904761904}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.4, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.2, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9047619047619047, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3352", "mrqa_naturalquestions-validation-9032", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-486", "mrqa_naturalquestions-validation-4097", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-276", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-7352", "mrqa_naturalquestions-validation-3555", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-2605", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-954", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-3898", "mrqa_triviaqa-validation-79", "mrqa_newsqa-validation-692", "mrqa_searchqa-validation-8619", "mrqa_searchqa-validation-8291"], "SR": 0.578125, "CSR": 0.5833333333333333, "retrieved_ids": ["mrqa_squad-train-23595", "mrqa_squad-train-71171", "mrqa_squad-train-63359", "mrqa_squad-train-76535", "mrqa_squad-train-13851", "mrqa_squad-train-69264", "mrqa_squad-train-80869", "mrqa_squad-train-74827", "mrqa_squad-train-50392", "mrqa_squad-train-72860", "mrqa_squad-train-5201", "mrqa_squad-train-60258", "mrqa_squad-train-47945", "mrqa_squad-train-26362", "mrqa_squad-train-55369", "mrqa_squad-train-68719", "mrqa_squad-train-74042", "mrqa_squad-train-85177", "mrqa_squad-train-18552", "mrqa_squad-train-17840", "mrqa_squad-train-84026", "mrqa_squad-train-73550", "mrqa_squad-train-43468", "mrqa_squad-train-67261", "mrqa_squad-train-49444", "mrqa_squad-train-38914", "mrqa_squad-train-32437", "mrqa_squad-train-11229", "mrqa_squad-train-78337", "mrqa_squad-train-46407", "mrqa_squad-train-67930", "mrqa_squad-train-3484", "mrqa_triviaqa-validation-5492", "mrqa_triviaqa-validation-2265", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-3144", "mrqa_squad-validation-9640", "mrqa_newsqa-validation-2204", "mrqa_searchqa-validation-10823", "mrqa_searchqa-validation-541", "mrqa_triviaqa-validation-3868", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-5", "mrqa_squad-validation-8864", "mrqa_naturalquestions-validation-7067", "mrqa_searchqa-validation-16210", "mrqa_searchqa-validation-700", "mrqa_triviaqa-validation-6198", "mrqa_searchqa-validation-4888", "mrqa_squad-validation-7574", "mrqa_naturalquestions-validation-4134", "mrqa_newsqa-validation-2133", "mrqa_squad-validation-10274", "mrqa_squad-validation-1841", "mrqa_naturalquestions-validation-6321", "mrqa_triviaqa-validation-2101", "mrqa_squad-validation-6390", "mrqa_newsqa-validation-3891", "mrqa_squad-validation-7527", "mrqa_squad-validation-2373", "mrqa_squad-validation-3118", "mrqa_squad-validation-1215", "mrqa_squad-validation-9918", "mrqa_newsqa-validation-3758"], "EFR": 0.9259259259259259, "Overall": 0.7276331018518518}, {"timecode": 24, "before_eval_results": {"predictions": ["22,000\u201314,000 yr BP", "ancestors", "German creedal hymn", "April 20", "Tanzania", "March 29, 2018", "Ethiopia ( Abyssinia ), the Dervish state ( a portion of present - day Somalia ) and Liberia", "1928", "Northern Kingdom of Israel", "northern China", "Missouri River", "Harrys", "September 21, 2017", "Austria - Hungary", "Robert Gillespie Adamson IV", "1946", "May 3, 2005", "Tony Curran", "Vijaya Mulay", "Mediterranean Shipping Company S.A.", "1977", "Cody Fern", "22 November 1970", "The Star Spangled Banner", "2007", "at Camping World Stadium in Orlando, Florida", "Aldis Hodge", "US $11,770", "Hans Zimmer, Steve Mazzaro & Missi Hale", "two alkyl halides are reacted with sodium metal in dry ether solution to form a higher alkane", "James", "Kimberlin Brown", "based by British - American rock band Fleetwood Mac", "its genome", "rizal finished all the chapters of the novel noli me tangere in?", "American rock band R.E.M.", "a blend of ground beef and other ingredients", "Juliet", "colonialism was coming to an end worldwide", "July 25, 2017", "Rachel Kelly Tucker", "September 24, 2012", "rocks and minerals", "various submucosal membrane sites", "2017", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "its vast territory was divided into several successor polities", "St. Theodosius Russian Orthodox Cathedral", "a beauty queen", "England", "Ahmad Given ( Real ) and Kamal Givens ( Chance )", "Beorn", "Robert Plant", "beetles", "Copenhagen", "Super Bowl XXIX", "Vladimir Menshov", "Elbow River", "41,", "Fareed Zakaria.", "Afghan National Security Forces", "austerio", "a rabbit", "the International Committee of the Red Cross"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6356788706272074}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6875000000000001, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.25, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.29629629629629634, 0.0, 0.7741935483870968, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5928", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-9789", "mrqa_naturalquestions-validation-5452", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-6116", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-5004", "mrqa_naturalquestions-validation-1657", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-9368", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-1001", "mrqa_naturalquestions-validation-5051", "mrqa_hotpotqa-validation-3362", "mrqa_searchqa-validation-13806", "mrqa_searchqa-validation-1833", "mrqa_searchqa-validation-11809"], "SR": 0.515625, "CSR": 0.580625, "retrieved_ids": ["mrqa_squad-train-20754", "mrqa_squad-train-17680", "mrqa_squad-train-19929", "mrqa_squad-train-80940", "mrqa_squad-train-80472", "mrqa_squad-train-70308", "mrqa_squad-train-57963", "mrqa_squad-train-72873", "mrqa_squad-train-19694", "mrqa_squad-train-68150", "mrqa_squad-train-25915", "mrqa_squad-train-66010", "mrqa_squad-train-78473", "mrqa_squad-train-28766", "mrqa_squad-train-73135", "mrqa_squad-train-5990", "mrqa_squad-train-55744", "mrqa_squad-train-22484", "mrqa_squad-train-56409", "mrqa_squad-train-8420", "mrqa_squad-train-51110", "mrqa_squad-train-85309", "mrqa_squad-train-13808", "mrqa_squad-train-365", "mrqa_squad-train-12377", "mrqa_squad-train-33572", "mrqa_squad-train-57292", "mrqa_squad-train-19180", "mrqa_squad-train-20536", "mrqa_squad-train-61946", "mrqa_squad-train-69692", "mrqa_squad-train-61296", "mrqa_naturalquestions-validation-7886", "mrqa_newsqa-validation-2983", "mrqa_searchqa-validation-6992", "mrqa_squad-validation-8864", "mrqa_searchqa-validation-1843", "mrqa_naturalquestions-validation-9032", "mrqa_squad-validation-8558", "mrqa_newsqa-validation-4015", "mrqa_squad-validation-6185", "mrqa_newsqa-validation-1126", "mrqa_squad-validation-1941", "mrqa_newsqa-validation-43", "mrqa_hotpotqa-validation-4478", "mrqa_naturalquestions-validation-7962", "mrqa_searchqa-validation-9548", "mrqa_newsqa-validation-2872", "mrqa_searchqa-validation-3259", "mrqa_newsqa-validation-3015", "mrqa_naturalquestions-validation-4193", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-3190", "mrqa_naturalquestions-validation-2605", "mrqa_newsqa-validation-162", "mrqa_newsqa-validation-2044", "mrqa_triviaqa-validation-2363", "mrqa_squad-validation-3543", "mrqa_searchqa-validation-5785", "mrqa_newsqa-validation-3758", "mrqa_searchqa-validation-16210", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-7352", "mrqa_hotpotqa-validation-1297"], "EFR": 0.967741935483871, "Overall": 0.7354546370967742}, {"timecode": 25, "before_eval_results": {"predictions": ["exceeds any given number", "8:10 p.m.", "about 5 nanometers across", "1894", "production by a class of owners", "Atlanta, Georgia", "Thunder Road", "Acid rain", "Bette Midler", "gathering money from the public", "the pyloric valve", "(Kim) Wellens", "Julia Ormond", "synovial joint", "The Satavahanas", "March 16, 2018", "Hathi Jr", "by capillary action", "twice", "Asuka", "in the pachytene stage of prophase I of meiosis during a process called synapsis", "Hathi Jr.", "the Lower Mainland in Vancouver", "development of electronic computers in the 1950s", "notorious Welsh pirate Edward Kenway", "Madison, Wisconsin, United States", "neutrality", "May 26, 2017", "1981", "USS Chesapeake", "single player protagonist, Iden Versio, leader of an Imperial Special Forces group known as Inferno Squad", "a spiritual conversion", "to address the historic oppression, inequality and discrimination faced by those communities", "Harishchandra", "The Intolerable Acts", "31 January 1934", "Cairo, Illinois", "Mad - Eye Moody", "Lee Mack", "without deviating from basic strategy", "Burnham Beeches in Buckinghamshire", "1898", "Clarence Anglin", "April 1st", "9.7 m ( 31.82 ft )", "the Northeast Monsoon or Retreating Monsoon", "Michael Crawford", "1930s", "Thomas Mundy Peterson", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "April 28, 2008", "The Parlement de Bretagne", "Steve Davis", "phosphorus", "Spencer Perceval", "highland regions of Scotland", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "Jack Kilby", "Cpl. Richard Findley,", "Venezuela's Libertador", "a national telephone survey of more than 78,000 parents of children ages 3 to 17.", "Stark County, Ohio", "Edward VI", "New Orleans"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5982818092173755}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.28571428571428575, 0.3333333333333333, 1.0, 0.14285714285714285, 0.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.9565217391304348, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.4444444444444445, 0.7857142857142858, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1290322580645161, 0.0, 0.4, 0.0, 1.0, 1.0, 0.4, 0.4, 0.0, 0.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1583", "mrqa_squad-validation-8869", "mrqa_squad-validation-7514", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-5564", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-4165", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-3922", "mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4200", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-10070", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-6671", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-1015", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-5483", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-9737", "mrqa_naturalquestions-validation-7021", "mrqa_triviaqa-validation-5467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-3902", "mrqa_newsqa-validation-990", "mrqa_newsqa-validation-3029", "mrqa_newsqa-validation-3191", "mrqa_searchqa-validation-1563"], "SR": 0.453125, "CSR": 0.5757211538461539, "retrieved_ids": ["mrqa_squad-train-76711", "mrqa_squad-train-41419", "mrqa_squad-train-35507", "mrqa_squad-train-52857", "mrqa_squad-train-5152", "mrqa_squad-train-57190", "mrqa_squad-train-41848", "mrqa_squad-train-22872", "mrqa_squad-train-14388", "mrqa_squad-train-47414", "mrqa_squad-train-54216", "mrqa_squad-train-1456", "mrqa_squad-train-53853", "mrqa_squad-train-13970", "mrqa_squad-train-51849", "mrqa_squad-train-72293", "mrqa_squad-train-72494", "mrqa_squad-train-13156", "mrqa_squad-train-75490", "mrqa_squad-train-70612", "mrqa_squad-train-46106", "mrqa_squad-train-27533", "mrqa_squad-train-3144", "mrqa_squad-train-60351", "mrqa_squad-train-36347", "mrqa_squad-train-61609", "mrqa_squad-train-45492", "mrqa_squad-train-32792", "mrqa_squad-train-13389", "mrqa_squad-train-12654", "mrqa_squad-train-37194", "mrqa_squad-train-24875", "mrqa_searchqa-validation-6041", "mrqa_searchqa-validation-1747", "mrqa_searchqa-validation-11704", "mrqa_searchqa-validation-11770", "mrqa_hotpotqa-validation-3949", "mrqa_squad-validation-2788", "mrqa_squad-validation-7307", "mrqa_triviaqa-validation-3527", "mrqa_squad-validation-7473", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-7164", "mrqa_triviaqa-validation-3889", "mrqa_searchqa-validation-5963", "mrqa_searchqa-validation-2752", "mrqa_triviaqa-validation-6649", "mrqa_squad-validation-927", "mrqa_newsqa-validation-4203", "mrqa_hotpotqa-validation-3070", "mrqa_newsqa-validation-4126", "mrqa_triviaqa-validation-45", "mrqa_naturalquestions-validation-5004", "mrqa_newsqa-validation-1612", "mrqa_searchqa-validation-3267", "mrqa_newsqa-validation-2098", "mrqa_naturalquestions-validation-4124", "mrqa_squad-validation-5589", "mrqa_newsqa-validation-3370", "mrqa_squad-validation-2564", "mrqa_searchqa-validation-12302", "mrqa_searchqa-validation-13657", "mrqa_naturalquestions-validation-9421"], "EFR": 0.9714285714285714, "Overall": 0.735211195054945}, {"timecode": 26, "before_eval_results": {"predictions": ["deterministic Turing machine", "State Route 99", "those who already hold wealth", "vector quantities", "the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Thomas Alva Edison", "Andy Serkis", "England", "a virtual reality simulator", "the five - year time jump", "seven years earlier", "September 6, 2019", "an integral membrane protein that builds up a proton gradient across a biological membrane", "18", "Jack Nicklaus", "20th Century Fox, produced by 1492 Pictures", "Spanish missionaries, ranchers and troops", "Sedimentary rock", "the Internal Revenue Service ( IRS ) on form 8938", "the Western world", "Vicente Fox", "certain actions taken by employers or unions that violate the National Labor Relations Act of 1935", "Ben Rosenbaum", "Zilphia Horton", "Richard Stallman", "Santa Monica", "South Asia", "December 15", "Ed Sheeran", "Johnson", "the liver and kidneys", "the lumbar cistern", "a tradeable entity used to avoid the inconvenienceiences of a pure barter system", "1927", "Geoffrey Zakarian", "Tommy James and the Shondells", "in a wide surrounding area, in the Georgia counties of Newton ( where Covington is located ), Rockdale, Walton, Morgan, and Jasper", "Bonnie Aarons", "March 31, 2018", "Jay Baruchel", "De Waynene Warren", "2004", "rear - view mirror", "Portuguese and Spanish - French origins", "1986", "the terrestrial biosphere", "1937", "2017", "Beijing", "the court from its members", "convert single - stranded genomic RNA into double - stranded cDNA", "Thomas Edison", "October", "5.52\u00d71026", "Famous Players-Lasky Corporation", "Tiffany & Company", "Al Gore", "villanelle", "a man's lifeless, naked body", "man's lifeless, naked body", "four months ago,", "magnesium", "Captain John Smith", "rotunda"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6121428618893172}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.782608695652174, 1.0, 1.0, 1.0, 0.35294117647058826, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.5283018867924527, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.8, 1.0, 1.0, 1.0, 0.25, 0.9, 0.0, 1.0, 1.0, 0.8387096774193548, 1.0, 0.3333333333333333, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.4864864864864865, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10320", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-4338", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5185", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-7059", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-290", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-6091", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-5034", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-10353", "mrqa_naturalquestions-validation-154", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-1974", "mrqa_triviaqa-validation-667", "mrqa_triviaqa-validation-86", "mrqa_hotpotqa-validation-2141", "mrqa_hotpotqa-validation-4485", "mrqa_hotpotqa-validation-3245", "mrqa_newsqa-validation-464", "mrqa_searchqa-validation-11352", "mrqa_searchqa-validation-11530"], "SR": 0.46875, "CSR": 0.5717592592592593, "retrieved_ids": ["mrqa_squad-train-51789", "mrqa_squad-train-47721", "mrqa_squad-train-82120", "mrqa_squad-train-76127", "mrqa_squad-train-60790", "mrqa_squad-train-16382", "mrqa_squad-train-27049", "mrqa_squad-train-62678", "mrqa_squad-train-83151", "mrqa_squad-train-77011", "mrqa_squad-train-76203", "mrqa_squad-train-71996", "mrqa_squad-train-60510", "mrqa_squad-train-61961", "mrqa_squad-train-46555", "mrqa_squad-train-32628", "mrqa_squad-train-27791", "mrqa_squad-train-36299", "mrqa_squad-train-33216", "mrqa_squad-train-35552", "mrqa_squad-train-15601", "mrqa_squad-train-44796", "mrqa_squad-train-9978", "mrqa_squad-train-7330", "mrqa_squad-train-38993", "mrqa_squad-train-19465", "mrqa_squad-train-82956", "mrqa_squad-train-30064", "mrqa_squad-train-14408", "mrqa_squad-train-55353", "mrqa_squad-train-65741", "mrqa_squad-train-56360", "mrqa_newsqa-validation-1073", "mrqa_triviaqa-validation-5592", "mrqa_naturalquestions-validation-6089", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-5467", "mrqa_hotpotqa-validation-3902", "mrqa_triviaqa-validation-1961", "mrqa_squad-validation-9145", "mrqa_triviaqa-validation-3725", "mrqa_newsqa-validation-2098", "mrqa_triviaqa-validation-2265", "mrqa_newsqa-validation-2664", "mrqa_searchqa-validation-9943", "mrqa_newsqa-validation-697", "mrqa_searchqa-validation-1384", "mrqa_newsqa-validation-2068", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-7067", "mrqa_newsqa-validation-1442", "mrqa_triviaqa-validation-4363", "mrqa_squad-validation-8294", "mrqa_newsqa-validation-3608", "mrqa_squad-validation-1640", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-346", "mrqa_naturalquestions-validation-1001", "mrqa_squad-validation-1215", "mrqa_triviaqa-validation-3450", "mrqa_triviaqa-validation-4453", "mrqa_naturalquestions-validation-1925", "mrqa_squad-validation-1441", "mrqa_triviaqa-validation-1772"], "EFR": 0.9117647058823529, "Overall": 0.7224860430283224}, {"timecode": 27, "before_eval_results": {"predictions": ["voluminous", "Dane", "Albert C. Outler", "Colonel (later Major General) Henry Young Darracott Scott", "Seminole Tribe", "about 12 million", "Tuesday,", "Dan Parris, 25, and Rob Lehr, 26,", "George Washington", "Mubarak", "22-year-old", "southern port city of Karachi,", "Brian David Mitchell,", "NASCAR's", "reaffirmed commitment to lesbian, gay, bisexual and transgender Americans.", "leftist Workers' Party.", "a motor scooter that goes about 55 miles per hour -- on 12-inch wheels.", "step up", "helping to plan the September 11, 2001,", "tried to fake his own death by crashing his private plane into a Florida swamp.", "a tuatara", "Little Rock military recruiting center", "saying privately in 2008 that Obama could be successful as a black candidate in part because of his \"light-skinned\" appearance and speaking patterns \"with no Negro dialect, unless he wanted to have one.", "directly to the inmates that designed certain pieces", "blew up", "Michelle Rounds", "telephone survey", "not speak", "African National Congress Deputy President Kgalema Motlanthe", "Turkey", "Bill Stanton", "humans", "Herman Thomas", "Werder Bremen", "a lightning strike", "Deputy Treasury Secretary", "Columbia, Illinois,", "Arizona", "hundreds", "Al-Shabaab", "Tom Hanks", "outside his house in Najaf's Adala neighborhood", "11th year in a row", "the last surviving British soldier from World War I", "Rocky Ford brand cantaloupes", "Both men were hospitalized and expected to survive,", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "22", "Briton Carl Froch", "Abdullah Gul,", "1979", "Heshmatollah Attarzadeh", "Richard Masur", "Jughead Jones", "Sarah Josepha Hale", "1998", "violin", "to stop a video or step backwards through your selections", "House of Fraser", "Reginald Engelbach", "Johnny Torrio", "pottery", "shrimp", "cnidarians"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5945265671828172}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, true, false, true, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.7499999999999999, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.09090909090909093, 0.5, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3299", "mrqa_newsqa-validation-257", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-3453", "mrqa_newsqa-validation-3192", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-619", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-302", "mrqa_naturalquestions-validation-5640", "mrqa_triviaqa-validation-6620", "mrqa_triviaqa-validation-3394", "mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-5444", "mrqa_searchqa-validation-1085", "mrqa_searchqa-validation-5522", "mrqa_searchqa-validation-3554"], "SR": 0.515625, "CSR": 0.5697544642857143, "retrieved_ids": ["mrqa_squad-train-74166", "mrqa_squad-train-50024", "mrqa_squad-train-66908", "mrqa_squad-train-1471", "mrqa_squad-train-7728", "mrqa_squad-train-54544", "mrqa_squad-train-4683", "mrqa_squad-train-190", "mrqa_squad-train-52888", "mrqa_squad-train-8299", "mrqa_squad-train-63214", "mrqa_squad-train-83899", "mrqa_squad-train-8228", "mrqa_squad-train-22400", "mrqa_squad-train-52949", "mrqa_squad-train-60530", "mrqa_squad-train-17198", "mrqa_squad-train-70263", "mrqa_squad-train-52264", "mrqa_squad-train-53321", "mrqa_squad-train-80940", "mrqa_squad-train-147", "mrqa_squad-train-53426", "mrqa_squad-train-1390", "mrqa_squad-train-84494", "mrqa_squad-train-85300", "mrqa_squad-train-78354", "mrqa_squad-train-1732", "mrqa_squad-train-42408", "mrqa_squad-train-44425", "mrqa_squad-train-13061", "mrqa_squad-train-57606", "mrqa_naturalquestions-validation-6671", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-15748", "mrqa_naturalquestions-validation-1433", "mrqa_newsqa-validation-258", "mrqa_searchqa-validation-10297", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2133", "mrqa_searchqa-validation-2768", "mrqa_searchqa-validation-4266", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-1128", "mrqa_triviaqa-validation-6649", "mrqa_newsqa-validation-1271", "mrqa_naturalquestions-validation-6453", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-268", "mrqa_triviaqa-validation-5592", "mrqa_naturalquestions-validation-3427", "mrqa_newsqa-validation-1210", "mrqa_squad-validation-8749", "mrqa_triviaqa-validation-5659", "mrqa_naturalquestions-validation-7058", "mrqa_triviaqa-validation-2363", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2562", "mrqa_searchqa-validation-86", "mrqa_triviaqa-validation-3450", "mrqa_naturalquestions-validation-10070"], "EFR": 1.0, "Overall": 0.7397321428571428}, {"timecode": 28, "before_eval_results": {"predictions": ["Beyonc\u00e9 and Bruno Mars", "Nepali", "German", "Sheikh Sharif Sheikh Ahmed", "Africa", "Thursday and Friday", "Rod Blagojevich", "gasoline", "Denver,", "Dolgorsuren Dagvadorj,", "it does not", "Zac Efron", "Picasso's muse and mistress, Marie-Therese Walter.", "Deputy Treasury Secretary", "drowned in the Pacific Ocean", "Kurt Cobain's", "Peshawar", "The Casalesi Camorra clan", "President Clinton.", "he regret describing her as \"wacko.", "Adenhart", "earthquake", "unemployment benefits", "environmental", "2009", "problems with the way Britain implements European Union employment directives.", "France's", "More than 15,000", "Tens of thousands of new voters", "0-0 draw", "Spaniard", "the National Guard reallocate reconnaissance helicopters and robotic surveillance craft", "$50 less", "Amsterdam,", "Kim Clijsters.", "Misty Croslin,", "Zed,", "Nazi Germany", "Sharon Bialek", "Kurdish militant group", "military veterans", "41,", "millionaire's surtax", "Sabina Guzzanti", "Booches Billiard Hall,", "More than 15,000", "Nearly eight in 10", "China", "Najaf.", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify. Military commission judges also will be able to establish the jurisdiction of their own courts.", "Haitians", "Bobby Jindal", "necessary, but not sufficient", "the town of Acolman", "1973", "football", "rabies", "Parkinson's", "seventh", "Disha Patani", "Anah\u00ed", "Tony Blair", "The Ignorance of Bedivere", "hanging"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5888888888888889}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3179", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1430", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3794", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-159", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1443", "mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-3753", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-1303", "mrqa_newsqa-validation-4207", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-10680", "mrqa_triviaqa-validation-2926", "mrqa_triviaqa-validation-4573", "mrqa_hotpotqa-validation-2876", "mrqa_searchqa-validation-11053", "mrqa_searchqa-validation-15007", "mrqa_searchqa-validation-3163"], "SR": 0.515625, "CSR": 0.5678879310344828, "retrieved_ids": ["mrqa_squad-train-34196", "mrqa_squad-train-23737", "mrqa_squad-train-11300", "mrqa_squad-train-37149", "mrqa_squad-train-44085", "mrqa_squad-train-80768", "mrqa_squad-train-41208", "mrqa_squad-train-56318", "mrqa_squad-train-56607", "mrqa_squad-train-1692", "mrqa_squad-train-36600", "mrqa_squad-train-2009", "mrqa_squad-train-52529", "mrqa_squad-train-19827", "mrqa_squad-train-40842", "mrqa_squad-train-86258", "mrqa_squad-train-49051", "mrqa_squad-train-74079", "mrqa_squad-train-34542", "mrqa_squad-train-44624", "mrqa_squad-train-6872", "mrqa_squad-train-41893", "mrqa_squad-train-34081", "mrqa_squad-train-11194", "mrqa_squad-train-79024", "mrqa_squad-train-43333", "mrqa_squad-train-6220", "mrqa_squad-train-26462", "mrqa_squad-train-73750", "mrqa_squad-train-85860", "mrqa_squad-train-39345", "mrqa_squad-train-37446", "mrqa_hotpotqa-validation-3362", "mrqa_newsqa-validation-1289", "mrqa_searchqa-validation-11816", "mrqa_newsqa-validation-1948", "mrqa_naturalquestions-validation-1731", "mrqa_squad-validation-6680", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-1756", "mrqa_naturalquestions-validation-3898", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-700", "mrqa_squad-validation-2373", "mrqa_searchqa-validation-14601", "mrqa_triviaqa-validation-862", "mrqa_newsqa-validation-302", "mrqa_searchqa-validation-13939", "mrqa_squad-validation-4462", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-6234", "mrqa_triviaqa-validation-3725", "mrqa_newsqa-validation-1442", "mrqa_triviaqa-validation-5789", "mrqa_naturalquestions-validation-5155", "mrqa_searchqa-validation-10883", "mrqa_searchqa-validation-8619", "mrqa_triviaqa-validation-7777", "mrqa_naturalquestions-validation-5317", "mrqa_newsqa-validation-4147", "mrqa_naturalquestions-validation-132", "mrqa_searchqa-validation-2022", "mrqa_newsqa-validation-3863"], "EFR": 1.0, "Overall": 0.7393588362068966}, {"timecode": 29, "before_eval_results": {"predictions": ["Systemic acquired resistance", "quarterback Denver Broncos", "teach by rote", "a cupcake was exchanged instead of harsh words.", "\"Dance Your Ass Off.\"", "Robert Barnett,", "possible securities violations", "Almost all British troops in Iraq", "Jacob Zuma,", "Simon Cowell", "jazz", "\"falling space debris,\"", "Obama's", "30", "Monday night", "Haeftling", "Franklin, Tennessee,", "The BBC", "the coalition", "sexual assault on a child.", "Brian David Mitchell,", "a Christmas parade in Soddy-Daisy, Tennessee,", "football", "consumer confidence", "Republican Party", "only normal maritime traffic", "Dean Martin, Katharine Hepburn and Spencer Tracy", "vitamin injections that promise to improve health and beauty.", "the area was sealed off, so they did not know casualty figures.", "twice.", "The EU naval force", "Paul Ryan", "top designers,", "about 5:20 p.m. at Terminal C", "any group that tries to take justice into its own hands.", "Darrel Mohler", "Casalesi Camorra", "the Obama and McCain camps", "Sen. Barack Obama", "heavy brush,", "more than 30", "Empire of the Sun", "30-minute", "11", "Laura Ling and Euna Lee,", "a paragraph about the king and crown prince", "second time since the 1990s", "Monday,", "Brazil", "Caylee Anthony,", "reached an agreement late Thursday to form a government of national reconciliation.", "6-4", "Don Valley Parkway / Highway 402 Junction", "the Western Bloc ( the United States, its NATO allies and others )", "January or early February", "Galileo Galilei", "Zeus", "paper", "Christian Kern", "Indianola", "Wayne County, Michigan", "Diff'rent Strokes", "Akihito", "the Algonquin Round Table"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6287130098251422}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, true, false, true, true, true, true, true, false, false, true, true, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.11764705882352941, 0.4, 0.6666666666666666, 0.5, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.4444444444444444, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.0, 0.47619047619047616, 0.3636363636363636, 0.39999999999999997, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-627", "mrqa_newsqa-validation-3121", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2688", "mrqa_newsqa-validation-1256", "mrqa_newsqa-validation-4130", "mrqa_newsqa-validation-2259", "mrqa_newsqa-validation-2808", "mrqa_newsqa-validation-832", "mrqa_newsqa-validation-2934", "mrqa_newsqa-validation-3063", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-3625", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-336", "mrqa_newsqa-validation-3796", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-8441", "mrqa_triviaqa-validation-2856", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-1681", "mrqa_searchqa-validation-9488", "mrqa_searchqa-validation-1614", "mrqa_searchqa-validation-2389"], "SR": 0.515625, "CSR": 0.5661458333333333, "retrieved_ids": ["mrqa_squad-train-4604", "mrqa_squad-train-41770", "mrqa_squad-train-5300", "mrqa_squad-train-20831", "mrqa_squad-train-68372", "mrqa_squad-train-19080", "mrqa_squad-train-66883", "mrqa_squad-train-62874", "mrqa_squad-train-82377", "mrqa_squad-train-12208", "mrqa_squad-train-74731", "mrqa_squad-train-20388", "mrqa_squad-train-5067", "mrqa_squad-train-52719", "mrqa_squad-train-34865", "mrqa_squad-train-8492", "mrqa_squad-train-2353", "mrqa_squad-train-75939", "mrqa_squad-train-40609", "mrqa_squad-train-6697", "mrqa_squad-train-83075", "mrqa_squad-train-63786", "mrqa_squad-train-30730", "mrqa_squad-train-75014", "mrqa_squad-train-52172", "mrqa_squad-train-52017", "mrqa_squad-train-55041", "mrqa_squad-train-56185", "mrqa_squad-train-4032", "mrqa_squad-train-31085", "mrqa_squad-train-83522", "mrqa_squad-train-71432", "mrqa_newsqa-validation-1963", "mrqa_naturalquestions-validation-276", "mrqa_searchqa-validation-6843", "mrqa_naturalquestions-validation-3352", "mrqa_newsqa-validation-627", "mrqa_squad-validation-7307", "mrqa_searchqa-validation-3163", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-9726", "mrqa_newsqa-validation-373", "mrqa_searchqa-validation-8291", "mrqa_newsqa-validation-2042", "mrqa_naturalquestions-validation-9273", "mrqa_newsqa-validation-174", "mrqa_squad-validation-2920", "mrqa_naturalquestions-validation-4863", "mrqa_hotpotqa-validation-5850", "mrqa_newsqa-validation-3190", "mrqa_squad-validation-7514", "mrqa_searchqa-validation-10103", "mrqa_naturalquestions-validation-7165", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-2251", "mrqa_newsqa-validation-1428", "mrqa_naturalquestions-validation-7003", "mrqa_searchqa-validation-409", "mrqa_searchqa-validation-4888", "mrqa_triviaqa-validation-3402", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-1289", "mrqa_naturalquestions-validation-4338", "mrqa_newsqa-validation-1458"], "EFR": 1.0, "Overall": 0.7390104166666667}, {"timecode": 30, "UKR": 0.7734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1296", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1681", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3070", "mrqa_hotpotqa-validation-3843", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4056", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-491", "mrqa_hotpotqa-validation-5112", "mrqa_hotpotqa-validation-5831", "mrqa_naturalquestions-validation-1001", "mrqa_naturalquestions-validation-10070", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-1385", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-1433", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2098", "mrqa_naturalquestions-validation-2745", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-3352", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-3555", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-3853", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-4053", "mrqa_naturalquestions-validation-4124", "mrqa_naturalquestions-validation-4165", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-4303", "mrqa_naturalquestions-validation-4413", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-4628", "mrqa_naturalquestions-validation-485", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-5185", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-5371", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-5452", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-5662", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-6116", "mrqa_naturalquestions-validation-6206", "mrqa_naturalquestions-validation-6321", "mrqa_naturalquestions-validation-6382", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6506", "mrqa_naturalquestions-validation-6671", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-6849", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7880", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-8153", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-8972", "mrqa_naturalquestions-validation-8975", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-9273", "mrqa_naturalquestions-validation-9284", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-9434", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-954", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-9824", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1011", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1022", "mrqa_newsqa-validation-1022", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-1152", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-1185", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-1235", "mrqa_newsqa-validation-1303", "mrqa_newsqa-validation-1309", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1434", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-1636", "mrqa_newsqa-validation-1655", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-1799", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2072", "mrqa_newsqa-validation-2106", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2186", "mrqa_newsqa-validation-2190", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2436", "mrqa_newsqa-validation-2528", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-2592", "mrqa_newsqa-validation-2593", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2624", "mrqa_newsqa-validation-2656", "mrqa_newsqa-validation-2697", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-2791", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2808", "mrqa_newsqa-validation-2836", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2861", "mrqa_newsqa-validation-2967", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-3027", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3088", "mrqa_newsqa-validation-3098", "mrqa_newsqa-validation-3179", "mrqa_newsqa-validation-3192", "mrqa_newsqa-validation-3234", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3360", "mrqa_newsqa-validation-3370", "mrqa_newsqa-validation-3370", "mrqa_newsqa-validation-3419", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-3499", "mrqa_newsqa-validation-3625", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3685", "mrqa_newsqa-validation-3722", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3758", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-3878", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3886", "mrqa_newsqa-validation-3899", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-3987", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-4023", "mrqa_newsqa-validation-407", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-4158", "mrqa_newsqa-validation-4178", "mrqa_newsqa-validation-464", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-557", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-578", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-621", "mrqa_newsqa-validation-627", "mrqa_newsqa-validation-673", "mrqa_newsqa-validation-741", "mrqa_newsqa-validation-916", "mrqa_newsqa-validation-990", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-10359", "mrqa_searchqa-validation-10790", "mrqa_searchqa-validation-11002", "mrqa_searchqa-validation-11352", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-11451", "mrqa_searchqa-validation-11809", "mrqa_searchqa-validation-11875", "mrqa_searchqa-validation-12038", "mrqa_searchqa-validation-12312", "mrqa_searchqa-validation-12462", "mrqa_searchqa-validation-1256", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-13459", "mrqa_searchqa-validation-13476", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-13899", "mrqa_searchqa-validation-14273", "mrqa_searchqa-validation-1453", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-15224", "mrqa_searchqa-validation-15804", "mrqa_searchqa-validation-16831", "mrqa_searchqa-validation-1843", "mrqa_searchqa-validation-2214", "mrqa_searchqa-validation-2338", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-2863", "mrqa_searchqa-validation-2871", "mrqa_searchqa-validation-3127", "mrqa_searchqa-validation-3139", "mrqa_searchqa-validation-3222", "mrqa_searchqa-validation-33", "mrqa_searchqa-validation-3369", "mrqa_searchqa-validation-3478", "mrqa_searchqa-validation-3720", "mrqa_searchqa-validation-4057", "mrqa_searchqa-validation-4383", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-5329", "mrqa_searchqa-validation-541", "mrqa_searchqa-validation-5522", "mrqa_searchqa-validation-5539", "mrqa_searchqa-validation-5728", "mrqa_searchqa-validation-5762", "mrqa_searchqa-validation-5785", "mrqa_searchqa-validation-5963", "mrqa_searchqa-validation-6041", "mrqa_searchqa-validation-6264", "mrqa_searchqa-validation-6638", "mrqa_searchqa-validation-6843", "mrqa_searchqa-validation-6992", "mrqa_searchqa-validation-7564", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8117", "mrqa_searchqa-validation-8574", "mrqa_searchqa-validation-86", "mrqa_searchqa-validation-8658", "mrqa_searchqa-validation-9605", "mrqa_searchqa-validation-9687", "mrqa_searchqa-validation-9777", "mrqa_squad-validation-10011", "mrqa_squad-validation-10014", "mrqa_squad-validation-10218", "mrqa_squad-validation-10249", "mrqa_squad-validation-10274", "mrqa_squad-validation-10307", "mrqa_squad-validation-10489", "mrqa_squad-validation-10494", "mrqa_squad-validation-1086", "mrqa_squad-validation-1092", "mrqa_squad-validation-111", "mrqa_squad-validation-1177", "mrqa_squad-validation-1215", "mrqa_squad-validation-1490", "mrqa_squad-validation-1587", "mrqa_squad-validation-1641", "mrqa_squad-validation-1661", "mrqa_squad-validation-1753", "mrqa_squad-validation-204", "mrqa_squad-validation-2088", "mrqa_squad-validation-217", "mrqa_squad-validation-2190", "mrqa_squad-validation-2192", "mrqa_squad-validation-2226", "mrqa_squad-validation-2283", "mrqa_squad-validation-2286", "mrqa_squad-validation-2353", "mrqa_squad-validation-2372", "mrqa_squad-validation-2373", "mrqa_squad-validation-2395", "mrqa_squad-validation-2411", "mrqa_squad-validation-2421", "mrqa_squad-validation-25", "mrqa_squad-validation-2622", "mrqa_squad-validation-2656", "mrqa_squad-validation-2762", "mrqa_squad-validation-2857", "mrqa_squad-validation-304", "mrqa_squad-validation-3040", "mrqa_squad-validation-3130", "mrqa_squad-validation-3168", "mrqa_squad-validation-3382", "mrqa_squad-validation-3393", "mrqa_squad-validation-3508", "mrqa_squad-validation-3559", "mrqa_squad-validation-3654", "mrqa_squad-validation-3699", "mrqa_squad-validation-3796", "mrqa_squad-validation-3941", "mrqa_squad-validation-3955", "mrqa_squad-validation-3975", "mrqa_squad-validation-4015", "mrqa_squad-validation-4162", "mrqa_squad-validation-4382", "mrqa_squad-validation-4398", "mrqa_squad-validation-4452", "mrqa_squad-validation-4550", "mrqa_squad-validation-457", "mrqa_squad-validation-4585", "mrqa_squad-validation-4619", "mrqa_squad-validation-4634", "mrqa_squad-validation-466", "mrqa_squad-validation-4694", "mrqa_squad-validation-4753", "mrqa_squad-validation-4763", "mrqa_squad-validation-4764", "mrqa_squad-validation-4774", "mrqa_squad-validation-4782", "mrqa_squad-validation-490", "mrqa_squad-validation-4933", "mrqa_squad-validation-494", "mrqa_squad-validation-4956", "mrqa_squad-validation-4975", "mrqa_squad-validation-5003", "mrqa_squad-validation-5014", "mrqa_squad-validation-5029", "mrqa_squad-validation-5071", "mrqa_squad-validation-5302", "mrqa_squad-validation-5360", "mrqa_squad-validation-5370", "mrqa_squad-validation-5377", "mrqa_squad-validation-538", "mrqa_squad-validation-543", "mrqa_squad-validation-5465", "mrqa_squad-validation-5528", "mrqa_squad-validation-5589", "mrqa_squad-validation-5616", "mrqa_squad-validation-5806", "mrqa_squad-validation-5824", "mrqa_squad-validation-5824", "mrqa_squad-validation-5852", "mrqa_squad-validation-5956", "mrqa_squad-validation-5961", "mrqa_squad-validation-5995", "mrqa_squad-validation-6058", "mrqa_squad-validation-6082", "mrqa_squad-validation-6151", "mrqa_squad-validation-6206", "mrqa_squad-validation-6224", "mrqa_squad-validation-6241", "mrqa_squad-validation-6349", "mrqa_squad-validation-641", "mrqa_squad-validation-6557", "mrqa_squad-validation-6572", "mrqa_squad-validation-6792", "mrqa_squad-validation-6809", "mrqa_squad-validation-693", "mrqa_squad-validation-694", "mrqa_squad-validation-704", "mrqa_squad-validation-719", "mrqa_squad-validation-7281", "mrqa_squad-validation-7291", "mrqa_squad-validation-7307", "mrqa_squad-validation-7330", "mrqa_squad-validation-7462", "mrqa_squad-validation-7527", "mrqa_squad-validation-7608", "mrqa_squad-validation-7622", "mrqa_squad-validation-7659", "mrqa_squad-validation-7665", "mrqa_squad-validation-7719", "mrqa_squad-validation-7729", "mrqa_squad-validation-7751", "mrqa_squad-validation-7785", "mrqa_squad-validation-7822", "mrqa_squad-validation-7829", "mrqa_squad-validation-7837", "mrqa_squad-validation-7855", "mrqa_squad-validation-7908", "mrqa_squad-validation-7964", "mrqa_squad-validation-7990", "mrqa_squad-validation-8046", "mrqa_squad-validation-8056", "mrqa_squad-validation-8204", "mrqa_squad-validation-8210", "mrqa_squad-validation-8216", "mrqa_squad-validation-8269", "mrqa_squad-validation-828", "mrqa_squad-validation-8558", "mrqa_squad-validation-8568", "mrqa_squad-validation-8597", "mrqa_squad-validation-87", "mrqa_squad-validation-883", "mrqa_squad-validation-9019", "mrqa_squad-validation-9054", "mrqa_squad-validation-9110", "mrqa_squad-validation-9135", "mrqa_squad-validation-9145", "mrqa_squad-validation-9178", "mrqa_squad-validation-9298", "mrqa_squad-validation-9334", "mrqa_squad-validation-9365", "mrqa_squad-validation-9379", "mrqa_squad-validation-957", "mrqa_squad-validation-9603", "mrqa_squad-validation-9640", "mrqa_squad-validation-973", "mrqa_squad-validation-9870", "mrqa_squad-validation-9918", "mrqa_squad-validation-9993", "mrqa_triviaqa-validation-1055", "mrqa_triviaqa-validation-1198", "mrqa_triviaqa-validation-1245", "mrqa_triviaqa-validation-1358", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-1452", "mrqa_triviaqa-validation-1524", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-1788", "mrqa_triviaqa-validation-1866", "mrqa_triviaqa-validation-1927", "mrqa_triviaqa-validation-1927", "mrqa_triviaqa-validation-1945", "mrqa_triviaqa-validation-1961", "mrqa_triviaqa-validation-199", "mrqa_triviaqa-validation-2023", "mrqa_triviaqa-validation-2171", "mrqa_triviaqa-validation-2251", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2296", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-2344", "mrqa_triviaqa-validation-2406", "mrqa_triviaqa-validation-2541", "mrqa_triviaqa-validation-2573", "mrqa_triviaqa-validation-2676", "mrqa_triviaqa-validation-2716", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2815", "mrqa_triviaqa-validation-2925", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-3087", "mrqa_triviaqa-validation-3090", "mrqa_triviaqa-validation-3168", "mrqa_triviaqa-validation-3232", "mrqa_triviaqa-validation-3383", "mrqa_triviaqa-validation-3423", "mrqa_triviaqa-validation-3555", "mrqa_triviaqa-validation-3662", "mrqa_triviaqa-validation-3725", "mrqa_triviaqa-validation-3732", "mrqa_triviaqa-validation-391", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4567", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-4721", "mrqa_triviaqa-validation-4772", "mrqa_triviaqa-validation-4782", "mrqa_triviaqa-validation-528", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-544", "mrqa_triviaqa-validation-5492", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-5592", "mrqa_triviaqa-validation-5659", "mrqa_triviaqa-validation-5705", "mrqa_triviaqa-validation-5810", "mrqa_triviaqa-validation-5910", "mrqa_triviaqa-validation-6050", "mrqa_triviaqa-validation-6066", "mrqa_triviaqa-validation-6199", "mrqa_triviaqa-validation-6282", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-6632", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6827", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-6930", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-7233", "mrqa_triviaqa-validation-7387", "mrqa_triviaqa-validation-7426", "mrqa_triviaqa-validation-7536", "mrqa_triviaqa-validation-7635", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-79"], "OKR": 0.88671875, "KG": 0.47890625, "before_eval_results": {"predictions": ["Super Bowl XX", "undermining the communist ideology", "67.9", "a message", "Montford Point", "Queen Mary II", "Pula Arena", "catfish", "Google", "helium", "HIV", "a claws", "Wonder Woman", "The Last Starfighter", "(to)", "House of Romanov", "a mirror", "fermentation", "Oscar Wilde", "Morocco", "Little Red Riding Hood", "distressing", "The Simpsons Movie", "( Clara) Barton", "(Amelia) Earhart", "Minnesota", "austerio ( Geena Davis)", "Han Solo", "(Gutzon) Borglum", "Catherine of Aragon", "Zeus", "St Mark", "Oklahoma", "Salman Rushdie", "the United Nations", "Tycho Brahe", "a mid-season replacement", "(Gail) Norton", "elephants", "cloister", "(President) Roosevelt", "Pakistan", "DOS for Dummies", "Clue", "(L.S. Heath)", "(Lovely Rita) meter", "( Ellen) Wilson", "herbicides", "a tornado", "Omaha", "It's a wonderful Life", "the Mayflower", "Vienna", "Zachary John Quinto", "March 16, 2018", "Popowo", "Senator Robert Kennedy", "Mercury", "Jello Biafra", "Niveda Thomas", "1967", "illegal immigrants", "CEO of an engineering and construction company", "maintain an \"aesthetic environment\" and ensure public safety,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6286458333333333}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, true, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, false, false, true, true, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13142", "mrqa_searchqa-validation-1784", "mrqa_searchqa-validation-12438", "mrqa_searchqa-validation-13853", "mrqa_searchqa-validation-2171", "mrqa_searchqa-validation-7112", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-5757", "mrqa_searchqa-validation-9915", "mrqa_searchqa-validation-3540", "mrqa_searchqa-validation-13347", "mrqa_searchqa-validation-1117", "mrqa_searchqa-validation-396", "mrqa_searchqa-validation-5939", "mrqa_searchqa-validation-5951", "mrqa_searchqa-validation-5510", "mrqa_searchqa-validation-14508", "mrqa_searchqa-validation-15778", "mrqa_searchqa-validation-16660", "mrqa_searchqa-validation-2226", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-14425", "mrqa_searchqa-validation-1317", "mrqa_searchqa-validation-7006", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4028", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-4424", "mrqa_newsqa-validation-1432"], "SR": 0.53125, "CSR": 0.5650201612903225, "retrieved_ids": ["mrqa_squad-train-1177", "mrqa_squad-train-64625", "mrqa_squad-train-64101", "mrqa_squad-train-29391", "mrqa_squad-train-57767", "mrqa_squad-train-53282", "mrqa_squad-train-34327", "mrqa_squad-train-43794", "mrqa_squad-train-23303", "mrqa_squad-train-31538", "mrqa_squad-train-85657", "mrqa_squad-train-2355", "mrqa_squad-train-15288", "mrqa_squad-train-52879", "mrqa_squad-train-39878", "mrqa_squad-train-43318", "mrqa_squad-train-3256", "mrqa_squad-train-38986", "mrqa_squad-train-79021", "mrqa_squad-train-77757", "mrqa_squad-train-86330", "mrqa_squad-train-48668", "mrqa_squad-train-43579", "mrqa_squad-train-51367", "mrqa_squad-train-24086", "mrqa_squad-train-260", "mrqa_squad-train-76849", "mrqa_squad-train-3044", "mrqa_squad-train-69784", "mrqa_squad-train-42943", "mrqa_squad-train-25980", "mrqa_squad-train-64507", "mrqa_searchqa-validation-6722", "mrqa_squad-validation-6402", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-2101", "mrqa_naturalquestions-validation-64", "mrqa_searchqa-validation-8236", "mrqa_searchqa-validation-16848", "mrqa_searchqa-validation-3163", "mrqa_squad-validation-9320", "mrqa_triviaqa-validation-5425", "mrqa_newsqa-validation-3625", "mrqa_naturalquestions-validation-290", "mrqa_newsqa-validation-627", "mrqa_searchqa-validation-13028", "mrqa_hotpotqa-validation-1297", "mrqa_newsqa-validation-2983", "mrqa_triviaqa-validation-2858", "mrqa_squad-validation-1215", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-1414", "mrqa_newsqa-validation-2275", "mrqa_newsqa-validation-464", "mrqa_squad-validation-1841", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-616", "mrqa_triviaqa-validation-412", "mrqa_newsqa-validation-1606", "mrqa_naturalquestions-validation-7059", "mrqa_triviaqa-validation-7311", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-2044"], "EFR": 1.0, "Overall": 0.7408165322580645}, {"timecode": 31, "before_eval_results": {"predictions": ["vocational subjects", "Lenin", "quotient", "Carson Palmer", "hail", "Andes", "Chiefland", "the Hippocratic Oath", "Queen Latifah", "a Golden Retriever", "Shropshire", "the Aegean sea", "fingers", "a bogey", "... Buzz", "a crocodile", "mutton", "Christmas", "the Chesapeake Bay", "Mao Zedong", "World War I", "John Alden", "a conscientious objector", "Trans Alaska Pipeline", "trout", "Friday the 13th", "Dixie Chicks", "Carl Bernstein", "a buffalo", "the u.s.a.", "Istanbul", "Sitting Bull", "Wiktionary", "Rehab", "the Golden Hind", "Administrative Professionals Week", "Gamal Abdel Nasser", "Van Halen", "a black bear", "dams", "Djibouti", "pyrite", "a cyclone", "Ted Morgan", "cashmere", "Diana the Princess", "spilt milk", "grasshopper", "carat", "Robin Hood", "the chalk cliffs", "tendang", "September 29, 2017", "Wake County, it lies just north of the state capital, Raleigh", "December 1800", "Nicolas Sarkozy", "the Republican Party", "a double whole note", "Rabies", "Environmental Protection Agency", "Robert Gibson", "Mogadishu is having a devastating impact on the city's population causing enormous suffering and massive displacement,\" the U.N. High Commissioner for Refugees said.", "45 minutes, five days a week.", "400 years"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6963994565217391}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.8695652173913044, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 0.09523809523809523, 0.5714285714285715, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-16971", "mrqa_searchqa-validation-11095", "mrqa_searchqa-validation-946", "mrqa_searchqa-validation-12318", "mrqa_searchqa-validation-13787", "mrqa_searchqa-validation-16913", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-9398", "mrqa_searchqa-validation-15099", "mrqa_searchqa-validation-5970", "mrqa_searchqa-validation-9137", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-4519", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-8756", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-11136", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-14198", "mrqa_naturalquestions-validation-4359", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-2760", "mrqa_hotpotqa-validation-1298", "mrqa_newsqa-validation-3162", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-4100"], "SR": 0.578125, "CSR": 0.5654296875, "retrieved_ids": ["mrqa_squad-train-30140", "mrqa_squad-train-4103", "mrqa_squad-train-45525", "mrqa_squad-train-80737", "mrqa_squad-train-8611", "mrqa_squad-train-79144", "mrqa_squad-train-14016", "mrqa_squad-train-24761", "mrqa_squad-train-28153", "mrqa_squad-train-16019", "mrqa_squad-train-85809", "mrqa_squad-train-56659", "mrqa_squad-train-43829", "mrqa_squad-train-16961", "mrqa_squad-train-1955", "mrqa_squad-train-53188", "mrqa_squad-train-21456", "mrqa_squad-train-34080", "mrqa_squad-train-60145", "mrqa_squad-train-60600", "mrqa_squad-train-60465", "mrqa_squad-train-67298", "mrqa_squad-train-75102", "mrqa_squad-train-75686", "mrqa_squad-train-58196", "mrqa_squad-train-882", "mrqa_squad-train-3958", "mrqa_squad-train-20906", "mrqa_squad-train-14949", "mrqa_squad-train-52306", "mrqa_squad-train-78585", "mrqa_squad-train-57463", "mrqa_newsqa-validation-1309", "mrqa_searchqa-validation-10925", "mrqa_searchqa-validation-5539", "mrqa_triviaqa-validation-6527", "mrqa_triviaqa-validation-2250", "mrqa_naturalquestions-validation-10680", "mrqa_triviaqa-validation-3527", "mrqa_hotpotqa-validation-1127", "mrqa_searchqa-validation-16660", "mrqa_naturalquestions-validation-7352", "mrqa_searchqa-validation-1843", "mrqa_triviaqa-validation-4019", "mrqa_newsqa-validation-3863", "mrqa_searchqa-validation-3478", "mrqa_squad-validation-4662", "mrqa_triviaqa-validation-2302", "mrqa_hotpotqa-validation-1239", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-13853", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-4011", "mrqa_hotpotqa-validation-3245", "mrqa_newsqa-validation-3794", "mrqa_newsqa-validation-3608", "mrqa_squad-validation-2788", "mrqa_squad-validation-1849", "mrqa_naturalquestions-validation-10353", "mrqa_squad-validation-927", "mrqa_naturalquestions-validation-5851", "mrqa_squad-validation-5835", "mrqa_squad-validation-6185", "mrqa_squad-validation-117"], "EFR": 1.0, "Overall": 0.7408984375000001}, {"timecode": 32, "before_eval_results": {"predictions": ["30", "neuro immune system", "prone", "Madrid", "the Declaration of Independence", "Jackie Moon", "a tornado", "the Trump Taj Mahal", "yuca", "a arugula", "John", "Liverpool", "Andy Taylor", "Nassau", "the Mediterranean", "Celsius", "Janet Reno", "Santiago", "Seinfeld", "steroids", "Atlantic City", "Galt", "Richard Nixon", "Jordan", "taro", "Sanssouci", "Clark Kent", "Peter Ilyich Tchaikovsky", "Malle Babbe", "the Stone Age", "Paul Gauguin", "Billy Pilgrim", "Louis XIV", "Cain's offering was not accepted by God", "Prince Charles", "the Sacred Heart", "whiskers", "a cigarette lighter", "Elmer", "the CretaceousPaleogene extinction", "Peggy Fleming", "Panama", "the electron", "Sweden", "Castle Rock", "fuchsia", "the Mediterranean Sea", "republicans", "Michelle Pfeiffer", "Sinclair Lewis", "Daphne du Maurier", "Snoop Dogg", "Queen M\u00e1xima of the Netherlands", "the New England Patriots", "an inability to comprehend and formulate language", "Dean Wareham", "Krak\u00f3w", "Ken Burns", "Pennacook", "Flashback", "Manchester United", "the Yemeni port city of Aden", "between South America and Africa.", "four decades"], "metric_results": {"EM": 0.4375, "QA-F1": 0.558881222943723}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.3636363636363636, 0.0, 0.7142857142857143, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6489", "mrqa_searchqa-validation-4246", "mrqa_searchqa-validation-16053", "mrqa_searchqa-validation-7455", "mrqa_searchqa-validation-3216", "mrqa_searchqa-validation-8752", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-1946", "mrqa_searchqa-validation-6763", "mrqa_searchqa-validation-10799", "mrqa_searchqa-validation-1791", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-2462", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-16917", "mrqa_searchqa-validation-16617", "mrqa_searchqa-validation-2029", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-7229", "mrqa_searchqa-validation-9024", "mrqa_searchqa-validation-3156", "mrqa_searchqa-validation-8272", "mrqa_searchqa-validation-15491", "mrqa_searchqa-validation-8080", "mrqa_searchqa-validation-11372", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5547", "mrqa_searchqa-validation-4697", "mrqa_searchqa-validation-16407", "mrqa_naturalquestions-validation-3840", "mrqa_triviaqa-validation-1459", "mrqa_hotpotqa-validation-486", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-305", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-2782"], "SR": 0.4375, "CSR": 0.5615530303030303, "retrieved_ids": ["mrqa_squad-train-69341", "mrqa_squad-train-39535", "mrqa_squad-train-21349", "mrqa_squad-train-26666", "mrqa_squad-train-68044", "mrqa_squad-train-15955", "mrqa_squad-train-1032", "mrqa_squad-train-48979", "mrqa_squad-train-50275", "mrqa_squad-train-65485", "mrqa_squad-train-17240", "mrqa_squad-train-76140", "mrqa_squad-train-74260", "mrqa_squad-train-72356", "mrqa_squad-train-59279", "mrqa_squad-train-10073", "mrqa_squad-train-76099", "mrqa_squad-train-52680", "mrqa_squad-train-34753", "mrqa_squad-train-40935", "mrqa_squad-train-16610", "mrqa_squad-train-1690", "mrqa_squad-train-147", "mrqa_squad-train-41647", "mrqa_squad-train-82865", "mrqa_squad-train-16276", "mrqa_squad-train-56175", "mrqa_squad-train-17501", "mrqa_squad-train-35118", "mrqa_squad-train-29687", "mrqa_squad-train-75346", "mrqa_squad-train-3834", "mrqa_searchqa-validation-8236", "mrqa_triviaqa-validation-1772", "mrqa_naturalquestions-validation-5155", "mrqa_triviaqa-validation-5573", "mrqa_naturalquestions-validation-7352", "mrqa_searchqa-validation-4888", "mrqa_searchqa-validation-13657", "mrqa_squad-validation-1441", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-7383", "mrqa_newsqa-validation-3557", "mrqa_squad-validation-1849", "mrqa_searchqa-validation-1784", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-158", "mrqa_newsqa-validation-1673", "mrqa_squad-validation-8337", "mrqa_searchqa-validation-11361", "mrqa_newsqa-validation-3190", "mrqa_naturalquestions-validation-1925", "mrqa_searchqa-validation-12302", "mrqa_newsqa-validation-268", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-5554", "mrqa_newsqa-validation-1011", "mrqa_squad-validation-1313", "mrqa_squad-validation-5456", "mrqa_naturalquestions-validation-1696", "mrqa_squad-validation-6757"], "EFR": 1.0, "Overall": 0.740123106060606}, {"timecode": 33, "before_eval_results": {"predictions": ["intuition", "gurus, mullahs, rabbis, pastors/youth pastors and lamas", "echinacea", "poker", "kiwis", "Malawian Airlines", "the Mycenaean palatial civilization", "Japan", "Thomas Merton", "ex-wife", "a phantom limb", "Crystal Car Fathers Day Auto Show", "The Mad Mad Mad World", "74.3 years", "Dunkin' Donuts", "the magma", "a hanter", "German", "the Tharsis Montes", "Audrey Hepburn", "Chicago", "dolomite", "Alaska", "ducks, hummingbirds", "Columbia University", "Jack O'Lanterns", "Sexuality", "Greece", "the Inca Empire", "contagious", "Vin Diesel", "the Mob", "New Mexico", "the French Revolution", "a Purple Heart", "a white diamond", "the CPU", "Lasky", "the wakizashi", "Return to sender", "Jean Lafitte", "the Komodo dragon", "Italian", "Churchill", "knitting", "Atonement", "receipt", "Damascus", "Lu Hsun", "Innsbruck", "Noah's flood", "the Orange County, California", "donor hair on the chest, back, shoulders, torso and / or legs", "Article Two", "Andy Cole", "Genghis Khan", "Roy Rogers", "African violet", "the Great Northern Railway", "25 October 1921", "katarina Witt", "\"Rin Tin Tin: The Life and the Legend\"", "reaching out and opening the door for the man who shot him,", "cardiac arrest"], "metric_results": {"EM": 0.53125, "QA-F1": 0.611541889483066}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, true, true, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8235294117647058, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-5943", "mrqa_searchqa-validation-12775", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-7396", "mrqa_searchqa-validation-1212", "mrqa_searchqa-validation-13753", "mrqa_searchqa-validation-7499", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-7603", "mrqa_searchqa-validation-4207", "mrqa_searchqa-validation-2912", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-15437", "mrqa_searchqa-validation-6880", "mrqa_searchqa-validation-1863", "mrqa_searchqa-validation-9506", "mrqa_searchqa-validation-11961", "mrqa_searchqa-validation-11096", "mrqa_searchqa-validation-5339", "mrqa_searchqa-validation-13178", "mrqa_searchqa-validation-2508", "mrqa_searchqa-validation-3398", "mrqa_searchqa-validation-12588", "mrqa_searchqa-validation-11473", "mrqa_searchqa-validation-3194", "mrqa_searchqa-validation-15608", "mrqa_naturalquestions-validation-6442", "mrqa_triviaqa-validation-7627", "mrqa_newsqa-validation-2940", "mrqa_newsqa-validation-3614"], "SR": 0.53125, "CSR": 0.5606617647058824, "retrieved_ids": ["mrqa_squad-train-19208", "mrqa_squad-train-20231", "mrqa_squad-train-6188", "mrqa_squad-train-26298", "mrqa_squad-train-83291", "mrqa_squad-train-2212", "mrqa_squad-train-58311", "mrqa_squad-train-14830", "mrqa_squad-train-13909", "mrqa_squad-train-74920", "mrqa_squad-train-32070", "mrqa_squad-train-60408", "mrqa_squad-train-55048", "mrqa_squad-train-86033", "mrqa_squad-train-66921", "mrqa_squad-train-61198", "mrqa_squad-train-65613", "mrqa_squad-train-33398", "mrqa_squad-train-58051", "mrqa_squad-train-57540", "mrqa_squad-train-48954", "mrqa_squad-train-79635", "mrqa_squad-train-76725", "mrqa_squad-train-80928", "mrqa_squad-train-22040", "mrqa_squad-train-7225", "mrqa_squad-train-62754", "mrqa_squad-train-37035", "mrqa_squad-train-67127", "mrqa_squad-train-60258", "mrqa_squad-train-22814", "mrqa_squad-train-2927", "mrqa_hotpotqa-validation-1756", "mrqa_triviaqa-validation-1993", "mrqa_squad-validation-694", "mrqa_naturalquestions-validation-1925", "mrqa_newsqa-validation-1382", "mrqa_triviaqa-validation-2760", "mrqa_hotpotqa-validation-939", "mrqa_squad-validation-8927", "mrqa_searchqa-validation-1317", "mrqa_hotpotqa-validation-3902", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-1117", "mrqa_naturalquestions-validation-132", "mrqa_newsqa-validation-1224", "mrqa_searchqa-validation-10964", "mrqa_newsqa-validation-2227", "mrqa_naturalquestions-validation-5096", "mrqa_squad-validation-1941", "mrqa_searchqa-validation-6041", "mrqa_naturalquestions-validation-5034", "mrqa_searchqa-validation-6843", "mrqa_squad-validation-7307", "mrqa_searchqa-validation-11091", "mrqa_newsqa-validation-937", "mrqa_searchqa-validation-16911", "mrqa_searchqa-validation-11888", "mrqa_newsqa-validation-2473", "mrqa_newsqa-validation-158", "mrqa_squad-validation-9023", "mrqa_newsqa-validation-1303", "mrqa_searchqa-validation-8619", "mrqa_searchqa-validation-6737"], "EFR": 0.9666666666666667, "Overall": 0.7332781862745098}, {"timecode": 34, "before_eval_results": {"predictions": ["three-dimensional", "cortisol and catecholamines", "Moon River", "Ray Harryhausen", "Leif Ericsson", "the Dutch West India Company", "Hans Christian Andersen", "Luffa", "The Hershey Company", "Alsace", "a doodle", "Muhammad Ali", "a deodorant", "the Supreme Court", "the north magnetic pole", "Vladimir Putin", "a thunderstorm", "Kennebunkport", "a satellite", "the Black Death", "Devon", "Amelia Earhart", "the Colorado River", "Panty Raid", "French", "cricket", "The Pythian Games", "The \"NFL HQ\" crew", "Tonto", "the chinchillidae", "white", "How to Cut the High Cost of Flying to Africa", "a keypunch", "the Amazons", "The Fugitive", "China", "a forge", "Harpers Ferry", "a lens", "lilac", "a crossword", "Tampa", "zinc", "The Lord Chamberlain's Men", "Leo", "the 25th anniversary", "Nautilus", "salaam", "Bigfoot", "Jurisprudence", "call option", "The Thing", "Sebastian Lund ( Rob Kerkovich )", "Stephen Curry", "Kusha", "Mars", "Captain America", "the Great Depression", "South America", "1998", "Picric acid", "Nineteen", "natural disasters", "Siri."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13921", "mrqa_searchqa-validation-9204", "mrqa_searchqa-validation-14868", "mrqa_searchqa-validation-14346", "mrqa_searchqa-validation-14554", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-8094", "mrqa_searchqa-validation-10045", "mrqa_searchqa-validation-11260", "mrqa_searchqa-validation-8097", "mrqa_searchqa-validation-15530", "mrqa_searchqa-validation-5028", "mrqa_searchqa-validation-1239", "mrqa_searchqa-validation-16912", "mrqa_searchqa-validation-11050", "mrqa_searchqa-validation-6030", "mrqa_searchqa-validation-5783", "mrqa_searchqa-validation-7418", "mrqa_searchqa-validation-12254", "mrqa_searchqa-validation-1088", "mrqa_searchqa-validation-11102", "mrqa_searchqa-validation-10105", "mrqa_searchqa-validation-4893", "mrqa_searchqa-validation-13951", "mrqa_searchqa-validation-5457", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1930", "mrqa_triviaqa-validation-7740", "mrqa_newsqa-validation-3365"], "SR": 0.546875, "CSR": 0.5602678571428572, "retrieved_ids": ["mrqa_squad-train-59785", "mrqa_squad-train-17070", "mrqa_squad-train-26194", "mrqa_squad-train-41083", "mrqa_squad-train-36580", "mrqa_squad-train-14865", "mrqa_squad-train-13741", "mrqa_squad-train-23488", "mrqa_squad-train-68963", "mrqa_squad-train-48223", "mrqa_squad-train-2072", "mrqa_squad-train-58085", "mrqa_squad-train-63084", "mrqa_squad-train-17534", "mrqa_squad-train-45845", "mrqa_squad-train-43733", "mrqa_squad-train-34809", "mrqa_squad-train-28044", "mrqa_squad-train-74267", "mrqa_squad-train-11382", "mrqa_squad-train-8821", "mrqa_squad-train-74547", "mrqa_squad-train-54380", "mrqa_squad-train-44009", "mrqa_squad-train-1548", "mrqa_squad-train-22239", "mrqa_squad-train-65201", "mrqa_squad-train-57742", "mrqa_squad-train-13697", "mrqa_squad-train-10722", "mrqa_squad-train-58282", "mrqa_squad-train-14438", "mrqa_newsqa-validation-2983", "mrqa_triviaqa-validation-5659", "mrqa_searchqa-validation-10297", "mrqa_searchqa-validation-15312", "mrqa_naturalquestions-validation-9421", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-1212", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-1022", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1303", "mrqa_naturalquestions-validation-1476", "mrqa_squad-validation-8400", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-3698", "mrqa_searchqa-validation-4207", "mrqa_searchqa-validation-6992", "mrqa_naturalquestions-validation-6340", "mrqa_searchqa-validation-6638", "mrqa_searchqa-validation-6374", "mrqa_newsqa-validation-4077", "mrqa_searchqa-validation-13753", "mrqa_newsqa-validation-2408", "mrqa_searchqa-validation-16210", "mrqa_newsqa-validation-692", "mrqa_searchqa-validation-9915", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-2030", "mrqa_hotpotqa-validation-939"], "EFR": 0.9310344827586207, "Overall": 0.7260729679802955}, {"timecode": 35, "before_eval_results": {"predictions": ["Nairobi, Mombasa and Kisumu", "The next three drives of the game would end in punts.", "\"How I Met Your Mother,\"", "two-state solution", "blue-purple", "little blue booties.", "forgery and flying without a valid license,", "Kurdistan Freedom Falcons,", "Lee Myung-Bak", "end of a biology department", "Malawi", "usion teams", "James Whitehouse,", "shut down buses, subways and trolleys that carry almost a million people daily.", "Muslim", "Muslim festival of Eid al-Adha.", "IAAF", "Fiona MacKeown", "Christian bookstores across the country that carry the publication.", "death of cardiac arrest", "\"Drug trafficking is a transnational threat, and therefore national initiatives have their limitations,\"", "rural Tennessee.", "The BBC", "the Caribbean", "B", "seven", "Karen Floyd", "Expedia", "Kenneth Cole", "\"wider relationship\"", "death squad killings", "hand-painted Swedish wooden clogs", "July for A Country Christmas,", "first night in his car.", "piano", "Roy", "They decided to use a surrogate to have a baby,", "her landlord defaulted on the mortgage and the house fell into foreclosure.", "job training", "State Department employee", "two years,", "Operation Cast Lead", "Diego Maradona", "21-year-old", "bartering -- trading goods and services without exchanging money --", "Rawalpindi", "the need for reconciliation in a country that endured a brutal civil war lasting nearly three decades.", "Leo Frank", "Port-au-Prince", "Buddhism", "Russian", "President Bill Clinton", "independently in different parts of the globe", "Sophocles", "charbagh", "Brando", "western Caribbean Sea", "Valletta", "The Eisenhower Executive Office Building", "Premier League club Tottenham Hotspur and the England national team", "Jeri Lynn Ryan", "Palatine Hill", "petrol", "Norbit"], "metric_results": {"EM": 0.5, "QA-F1": 0.6141887626262625}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, true, true, true], "QA-F1": [1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.5, 0.5, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.36363636363636365, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.05555555555555555, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-707", "mrqa_newsqa-validation-1709", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-416", "mrqa_newsqa-validation-2104", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-510", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-324", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-474", "mrqa_newsqa-validation-3156", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-3621", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-2690", "mrqa_newsqa-validation-939", "mrqa_newsqa-validation-1749", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-600", "mrqa_newsqa-validation-3491", "mrqa_naturalquestions-validation-8119", "mrqa_triviaqa-validation-4493", "mrqa_triviaqa-validation-1912", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-1743"], "SR": 0.5, "CSR": 0.55859375, "retrieved_ids": ["mrqa_squad-train-17249", "mrqa_squad-train-20296", "mrqa_squad-train-83007", "mrqa_squad-train-30781", "mrqa_squad-train-72692", "mrqa_squad-train-64898", "mrqa_squad-train-66775", "mrqa_squad-train-8244", "mrqa_squad-train-43630", "mrqa_squad-train-62971", "mrqa_squad-train-78729", "mrqa_squad-train-38378", "mrqa_squad-train-55137", "mrqa_squad-train-70689", "mrqa_squad-train-59718", "mrqa_squad-train-75241", "mrqa_squad-train-5215", "mrqa_squad-train-65413", "mrqa_squad-train-81629", "mrqa_squad-train-67657", "mrqa_squad-train-78727", "mrqa_squad-train-19180", "mrqa_squad-train-76087", "mrqa_squad-train-19054", "mrqa_squad-train-82461", "mrqa_squad-train-66514", "mrqa_squad-train-10367", "mrqa_squad-train-19960", "mrqa_squad-train-9235", "mrqa_squad-train-48942", "mrqa_squad-train-18858", "mrqa_squad-train-52547", "mrqa_triviaqa-validation-7563", "mrqa_triviaqa-validation-3862", "mrqa_searchqa-validation-198", "mrqa_searchqa-validation-6843", "mrqa_triviaqa-validation-330", "mrqa_searchqa-validation-1301", "mrqa_newsqa-validation-257", "mrqa_searchqa-validation-6992", "mrqa_searchqa-validation-13939", "mrqa_newsqa-validation-2611", "mrqa_newsqa-validation-990", "mrqa_newsqa-validation-1216", "mrqa_naturalquestions-validation-6671", "mrqa_triviaqa-validation-4760", "mrqa_newsqa-validation-1003", "mrqa_triviaqa-validation-2202", "mrqa_hotpotqa-validation-2731", "mrqa_naturalquestions-validation-3962", "mrqa_squad-validation-6791", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-2768", "mrqa_naturalquestions-validation-553", "mrqa_triviaqa-validation-2406", "mrqa_triviaqa-validation-7281", "mrqa_searchqa-validation-11816", "mrqa_naturalquestions-validation-4552", "mrqa_triviaqa-validation-1916", "mrqa_naturalquestions-validation-7733", "mrqa_triviaqa-validation-3889", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-4130", "mrqa_naturalquestions-validation-276"], "EFR": 1.0, "Overall": 0.73953125}, {"timecode": 36, "before_eval_results": {"predictions": ["the General Conference", "future exploration of the moon and beyond.", "\"Nothing But Love\"", "Mississippi", "Vernon Forrest,", "without bail", "a paragraph about the king and crown prince", "death of cardiac arrest", "$1.5 million", "\"Top Gun\"", "us to step up.", "discard", "one", "Jaipur", "Barack Obama", "April 6, 1994", "(the Democratic VP candidate)", "Cologne, Germany,", "34", "London's 20,000-capacity O2 Arena.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "U.S. President-elect Barack Obama", "Immigration Minister Eric Besson", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "suicides", "Facebook and Google,", "Asashoryu", "Henrik Stenson", "Seoul", "seeking help", "Evans", "Some truly mind-blowing structures are being planned for the Middle East.", "FARC rebels.", "Dan Brown", "The pilot, whose name has not yet been released,", "Paul McCartney and Ringo Starr", "Booches Billiard Hall,", "the National Guard reallocate reconnaissance helicopters and robotic surveillance craft", "\"She was focused so much on learning that she didn't notice,\"", "in a Starbucks", "finance", "Monday.", "diagnosed with skin cancer.", "Vicente Carrillo Leyva", "Deutschneudorf,", "more than 5,600", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "21 percent suggesting that", "Yoko Ono Lennon, Olivia Harrison and Ringo Starr", "at least $20 million to $30 million,", "Mexico,", "based on the idea of laying out a tournament ladder by arranging slips of paper with the names of players on them", "densely packed in the fovea centralis", "10 years", "jerry archer", "a palla", "Jack Nicholson", "Flatbush Zombies", "Louis King", "Venice", "a blowpipe", "reconnaissance", "Magic", "Fix You"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6567011981074481}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.2222222222222222, 0.33333333333333337, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 0.1, 0.0, 0.0, 0.4444444444444445, 0.0, 0.6923076923076923, 0.7499999999999999, 0.0, 0.5, 0.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-413", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-3640", "mrqa_newsqa-validation-2296", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-360", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-232", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2792", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-7358", "mrqa_naturalquestions-validation-960", "mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-111", "mrqa_hotpotqa-validation-3456", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-1127"], "SR": 0.53125, "CSR": 0.5578547297297297, "retrieved_ids": ["mrqa_squad-train-61597", "mrqa_squad-train-1216", "mrqa_squad-train-75509", "mrqa_squad-train-5682", "mrqa_squad-train-46896", "mrqa_squad-train-74799", "mrqa_squad-train-43681", "mrqa_squad-train-11356", "mrqa_squad-train-73259", "mrqa_squad-train-39140", "mrqa_squad-train-17646", "mrqa_squad-train-78323", "mrqa_squad-train-27636", "mrqa_squad-train-5917", "mrqa_squad-train-84333", "mrqa_squad-train-3216", "mrqa_squad-train-82305", "mrqa_squad-train-44979", "mrqa_squad-train-43966", "mrqa_squad-train-71926", "mrqa_squad-train-29776", "mrqa_squad-train-12395", "mrqa_squad-train-39200", "mrqa_squad-train-20983", "mrqa_squad-train-3326", "mrqa_squad-train-21479", "mrqa_squad-train-32330", "mrqa_squad-train-27241", "mrqa_squad-train-24937", "mrqa_squad-train-41349", "mrqa_squad-train-71852", "mrqa_squad-train-41260", "mrqa_squad-validation-10214", "mrqa_searchqa-validation-198", "mrqa_naturalquestions-validation-6289", "mrqa_triviaqa-validation-1630", "mrqa_hotpotqa-validation-1756", "mrqa_searchqa-validation-16617", "mrqa_searchqa-validation-8570", "mrqa_naturalquestions-validation-4200", "mrqa_newsqa-validation-2735", "mrqa_squad-validation-2788", "mrqa_triviaqa-validation-330", "mrqa_squad-validation-6680", "mrqa_newsqa-validation-3593", "mrqa_triviaqa-validation-6527", "mrqa_naturalquestions-validation-132", "mrqa_triviaqa-validation-5681", "mrqa_squad-validation-9320", "mrqa_naturalquestions-validation-1433", "mrqa_squad-validation-7574", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-12318", "mrqa_newsqa-validation-367", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-1309", "mrqa_searchqa-validation-11095", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-3343", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2735", "mrqa_searchqa-validation-12119", "mrqa_newsqa-validation-3899", "mrqa_searchqa-validation-13813"], "EFR": 1.0, "Overall": 0.739383445945946}, {"timecode": 37, "before_eval_results": {"predictions": ["hospitals and clinics", "Ricardo Valles de la Rosa,", "500", "Sunni Arab and Shiite tribal leaders", "Beatle's", "Kgalema Motlanthe,", "ferry", "1994,", "Belfast, Northern Ireland.", "Herman Cain", "Dan Parris, 25, and Rob Lehr, 26,", "lone ranger Clarkson", "CEO of an engineering and construction company", "London's Heathrow airport", "40 lashings", "take immunosuppression drugs for life", "almost 9 million", "the soldiers", "NATO fighters", "low-calorie meals", "1,500", "Grayback forest-firefighters", "authorizing killings and kidnappings by paramilitary death squads.", "8 p.m.", "Bergdahl,", "Stuntman: Wayne Michaels", "Brian Smith.", "U.S. District Judge Ricardo Urbina", "Swansea Crown Court,", "Virgin America", "The Kirchners", "about 3,000 kilometers", "murder", "nuclear", "Iran's parliament speaker", "No 4,", "playing Count Dracula and his roles in \"Lord of the Rings\" and \"Star Wars\" films.", "people have chosen their rides based on what their cars say about them.", "10", "artificial intelligence.", "There's no chance", "10", "April 13,", "Juri Kibuishi,", "London", "Obama", "16", "Ralph Lauren", "$10 billion", "35,000.", "three", "David Ben - Gurion", "Kiss", "20 years from the filing date subject to the payment of maintenance fees", "Ben Affleck", "Noises Off", "aeoline", "Dachau and Mauthausen", "Delilah Rene", "Tampa Bay Storm", "Pope John Paul II", "the Redeemer", "the Invisible Man", "Pembrokeshire Coast National Park"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6163910825077036}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.4444444444444445, 0.4, 1.0, 0.0, 0.5, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.36363636363636365, 0.0, 0.16666666666666669, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.18604651162790697, 0.14285714285714288, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5882352941176471, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6319", "mrqa_newsqa-validation-2640", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-2196", "mrqa_newsqa-validation-1483", "mrqa_newsqa-validation-1758", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-1988", "mrqa_newsqa-validation-2578", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3861", "mrqa_newsqa-validation-1563", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-2779", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-940", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-2935", "mrqa_naturalquestions-validation-633", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-1952", "mrqa_hotpotqa-validation-4450", "mrqa_searchqa-validation-3381"], "SR": 0.515625, "CSR": 0.5567434210526316, "retrieved_ids": ["mrqa_squad-train-33007", "mrqa_squad-train-31448", "mrqa_squad-train-61682", "mrqa_squad-train-29765", "mrqa_squad-train-27290", "mrqa_squad-train-45332", "mrqa_squad-train-18833", "mrqa_squad-train-72995", "mrqa_squad-train-48257", "mrqa_squad-train-50319", "mrqa_squad-train-34424", "mrqa_squad-train-56611", "mrqa_squad-train-25143", "mrqa_squad-train-73688", "mrqa_squad-train-52240", "mrqa_squad-train-77815", "mrqa_squad-train-17736", "mrqa_squad-train-67225", "mrqa_squad-train-58674", "mrqa_squad-train-48220", "mrqa_squad-train-75556", "mrqa_squad-train-77100", "mrqa_squad-train-75778", "mrqa_squad-train-38974", "mrqa_squad-train-52681", "mrqa_squad-train-975", "mrqa_squad-train-37754", "mrqa_squad-train-9897", "mrqa_squad-train-80589", "mrqa_squad-train-6544", "mrqa_squad-train-11828", "mrqa_squad-train-50464", "mrqa_naturalquestions-validation-6091", "mrqa_searchqa-validation-3194", "mrqa_naturalquestions-validation-2552", "mrqa_searchqa-validation-8752", "mrqa_searchqa-validation-11809", "mrqa_naturalquestions-validation-1930", "mrqa_squad-validation-8869", "mrqa_triviaqa-validation-2926", "mrqa_triviaqa-validation-5681", "mrqa_naturalquestions-validation-9789", "mrqa_naturalquestions-validation-1549", "mrqa_searchqa-validation-10060", "mrqa_naturalquestions-validation-7058", "mrqa_searchqa-validation-10359", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-609", "mrqa_naturalquestions-validation-7731", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-15437", "mrqa_triviaqa-validation-4493", "mrqa_naturalquestions-validation-3614", "mrqa_searchqa-validation-2912", "mrqa_naturalquestions-validation-10265", "mrqa_newsqa-validation-616", "mrqa_naturalquestions-validation-6022", "mrqa_squad-validation-7473", "mrqa_newsqa-validation-1417", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-5539", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2005", "mrqa_squad-validation-4908"], "EFR": 0.967741935483871, "Overall": 0.7327095713073006}, {"timecode": 38, "before_eval_results": {"predictions": ["events and festivals", "\"The U.S. subcontracted out an assassination program against al Qaeda... in early 2006.\"", "environmental and political events.", "U.S. Holocaust Memorial Museum", "Ireland.", "33", "2007", "heavy turbulence", "Liza Murphy", "Gaslight Theater.", "Brett Cummins,", "Rod Blagojevich", "Diego Maradona", "40", "Miguel Cotto", "\"Draquila", "he acted in self defense in punching businessman Marcus McGhee.", "Libreville, Gabon.", "September 23,", "1980", "Haiti", "Hanin Zoabi,", "Desmond Tutu", "84-year-old", "Hayden", "President George Bush", "humans", "Sylt's dining scene", "Congressman Paul Ryan (R-WI) will not support the Stop Online Piracy Act,", "Vice's broadband television network.", "Charles Lock", "he rejected the option of committing more forces for an undefined mission of nation-building without any deadlines.", "30", "Lisa Brown", "133", "it would", "A severe famine swept the nation in 1991-1993, devastating crops, killing up to 280,000 people and displacing up to 2 million,", "Italian Serie A title", "Superman brought down the Ku Klux Klan,", "He tall 34-year-old, slouching exhausted in a Johannesburg church that has become a de facto transit camp,", "mental health and recovery.", "The National Infrastructure Program,", "consumer confidence", "a one-shot victory in the Bob Hope Classic", "Bryan Whitman said such joint exercises between nations are not unusual. \"We exercise all around the globe and have joint exercises with countries all over the world. So do many other nations.", "Musharraf", "two courses", "first grand Slam,", "MS Columbus", "The iconic boogeyman Jason Voorhees in the new \"Friday the 13th\" movie.", "The local Republican Party", "1 October 2006", "1834", "cell surface ( particularly caveolae internalization )", "jazz", "Scafell Pike", "the memory-robbing disease", "University College of North Staffordshire", "9,984", "Smithfield, Rhode Island", "glass", "Donna Rice Hughes", "anbatross", "actress"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6681010787627985}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473685, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.7777777777777778, 0.0, 0.0, 0.16, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1904761904761905, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6046511627906976, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2631578947368421, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-509", "mrqa_newsqa-validation-3321", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3628", "mrqa_newsqa-validation-2680", "mrqa_newsqa-validation-3434", "mrqa_newsqa-validation-2657", "mrqa_newsqa-validation-4063", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-2413", "mrqa_newsqa-validation-3120", "mrqa_newsqa-validation-538", "mrqa_newsqa-validation-108", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-3488", "mrqa_newsqa-validation-848", "mrqa_newsqa-validation-492", "mrqa_newsqa-validation-1154", "mrqa_newsqa-validation-3203", "mrqa_naturalquestions-validation-10355", "mrqa_triviaqa-validation-7029", "mrqa_triviaqa-validation-3468", "mrqa_searchqa-validation-12340", "mrqa_searchqa-validation-7185", "mrqa_searchqa-validation-6977", "mrqa_hotpotqa-validation-3314"], "SR": 0.578125, "CSR": 0.5572916666666667, "retrieved_ids": ["mrqa_squad-train-9004", "mrqa_squad-train-84589", "mrqa_squad-train-39476", "mrqa_squad-train-49471", "mrqa_squad-train-69177", "mrqa_squad-train-37289", "mrqa_squad-train-15699", "mrqa_squad-train-31524", "mrqa_squad-train-84867", "mrqa_squad-train-19117", "mrqa_squad-train-72835", "mrqa_squad-train-57448", "mrqa_squad-train-65132", "mrqa_squad-train-20591", "mrqa_squad-train-48292", "mrqa_squad-train-36450", "mrqa_squad-train-37129", "mrqa_squad-train-57931", "mrqa_squad-train-44505", "mrqa_squad-train-54105", "mrqa_squad-train-84555", "mrqa_squad-train-78363", "mrqa_squad-train-19432", "mrqa_squad-train-65872", "mrqa_squad-train-1700", "mrqa_squad-train-54453", "mrqa_squad-train-43087", "mrqa_squad-train-46673", "mrqa_squad-train-67314", "mrqa_squad-train-48472", "mrqa_squad-train-9143", "mrqa_squad-train-62824", "mrqa_searchqa-validation-11053", "mrqa_newsqa-validation-4117", "mrqa_searchqa-validation-15491", "mrqa_newsqa-validation-1612", "mrqa_naturalquestions-validation-10368", "mrqa_newsqa-validation-4126", "mrqa_searchqa-validation-16617", "mrqa_triviaqa-validation-5499", "mrqa_naturalquestions-validation-1414", "mrqa_newsqa-validation-1442", "mrqa_newsqa-validation-4147", "mrqa_triviaqa-validation-6827", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-2338", "mrqa_newsqa-validation-619", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-3121", "mrqa_squad-validation-1215", "mrqa_triviaqa-validation-3087", "mrqa_squad-validation-8597", "mrqa_newsqa-validation-3049", "mrqa_squad-validation-2372", "mrqa_searchqa-validation-541", "mrqa_naturalquestions-validation-5185", "mrqa_newsqa-validation-3054", "mrqa_hotpotqa-validation-4450", "mrqa_newsqa-validation-893", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3758", "mrqa_triviaqa-validation-7334", "mrqa_newsqa-validation-3621", "mrqa_squad-validation-9178"], "EFR": 0.9259259259259259, "Overall": 0.7244560185185185}, {"timecode": 39, "before_eval_results": {"predictions": ["Bj\u00f6rn Waldeg\u00e5rd, Hannu Mikkola, Tommi M\u00e4kinen, Shekhar Mehta, Carlos Sainz and Colin McRae", "$10 billion", "\"People have lost their homes, their jobs, their hope,\"", "her husband", "Iranian consulate,", "renew registration", "30,000", "last week", "ties", "Addis Ababa,", "then-Sen. Obama", "Uighurs,", "Leo Frank,", "Michael Arrington", "\"It appears that they just made those numbers up,\"", "Harlem,", "the fact that the teens were charged as adults.", "Palestinian-Israeli issue", "navy", "Saturday,", "alleviation of their pain", "Robert", "suicides", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.", "serious consequences for Haiti,", "fighting charges of Nazi war crimes", "Tina Constable,", "Too many glass shards left by beer drinkers", "over 1,000 pounds", "two satellites", "Halloween", "onto the college campus.", "At least 33 people", "three", "$50", "at the Lindsey oil refinery in eastern England.", "1,300 meters in the Mediterranean Sea.", "\"He love his fans, and he's completely flattered by the fan response,\"", "Pakistan", "Thursday", "\"I will be asking questions,\"", "fluoroquinolone", "to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.", "Empire of the Sun", "digging", "1000 square meters", "President Obama", "North Korea", "Kingman Regional Medical Center,", "Henrik Stenson", "The Rev. Alberto Cutie", "the 2001 -- 2002 season", "786 -- 802", "31 March 2018", "Muhammad Ali", "the tallest building in the world", "81st anniversary of the first inflight movie", "Premier League", "Secret Intelligence Service", "75", "Salmagundi", "grasshopper", "The Knesset", "the Interior"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6348225581983806}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.125, 0.0, 1.0, 1.0, 0.0, 0.0, 0.09523809523809523, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8421052631578948, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.4, 0.7142857142857143, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3114", "mrqa_newsqa-validation-1565", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-3609", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-418", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-2482", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-796", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2438", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-1804", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1702", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-115", "mrqa_hotpotqa-validation-3900", "mrqa_hotpotqa-validation-1791", "mrqa_hotpotqa-validation-667", "mrqa_searchqa-validation-11207"], "SR": 0.546875, "CSR": 0.55703125, "retrieved_ids": ["mrqa_squad-train-33080", "mrqa_squad-train-47235", "mrqa_squad-train-26405", "mrqa_squad-train-23320", "mrqa_squad-train-57958", "mrqa_squad-train-24099", "mrqa_squad-train-36894", "mrqa_squad-train-86414", "mrqa_squad-train-48177", "mrqa_squad-train-45031", "mrqa_squad-train-19192", "mrqa_squad-train-29194", "mrqa_squad-train-83917", "mrqa_squad-train-84588", "mrqa_squad-train-33810", "mrqa_squad-train-79214", "mrqa_squad-train-46824", "mrqa_squad-train-36686", "mrqa_squad-train-20633", "mrqa_squad-train-4487", "mrqa_squad-train-66632", "mrqa_squad-train-38173", "mrqa_squad-train-23932", "mrqa_squad-train-83544", "mrqa_squad-train-67345", "mrqa_squad-train-31394", "mrqa_squad-train-24610", "mrqa_squad-train-51526", "mrqa_squad-train-5786", "mrqa_squad-train-33976", "mrqa_squad-train-25136", "mrqa_squad-train-13053", "mrqa_searchqa-validation-7010", "mrqa_searchqa-validation-11260", "mrqa_naturalquestions-validation-7358", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-381", "mrqa_searchqa-validation-5457", "mrqa_triviaqa-validation-4363", "mrqa_searchqa-validation-5757", "mrqa_triviaqa-validation-5052", "mrqa_searchqa-validation-7581", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-290", "mrqa_newsqa-validation-1749", "mrqa_squad-validation-627", "mrqa_triviaqa-validation-3715", "mrqa_newsqa-validation-4126", "mrqa_newsqa-validation-267", "mrqa_newsqa-validation-3863", "mrqa_hotpotqa-validation-3314", "mrqa_searchqa-validation-4674", "mrqa_searchqa-validation-1791", "mrqa_triviaqa-validation-6643", "mrqa_searchqa-validation-8845", "mrqa_hotpotqa-validation-1239", "mrqa_triviaqa-validation-980", "mrqa_searchqa-validation-396", "mrqa_naturalquestions-validation-3348", "mrqa_newsqa-validation-3817", "mrqa_searchqa-validation-9915", "mrqa_searchqa-validation-3259", "mrqa_squad-validation-7535", "mrqa_newsqa-validation-469"], "EFR": 1.0, "Overall": 0.73921875}, {"timecode": 40, "UKR": 0.7421875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-2861", "mrqa_hotpotqa-validation-2949", "mrqa_hotpotqa-validation-3142", "mrqa_hotpotqa-validation-3358", "mrqa_hotpotqa-validation-3902", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4056", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-4478", "mrqa_hotpotqa-validation-550", "mrqa_hotpotqa-validation-5707", "mrqa_hotpotqa-validation-86", "mrqa_hotpotqa-validation-92", "mrqa_hotpotqa-validation-996", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10369", "mrqa_naturalquestions-validation-10448", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-10688", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-154", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-2609", "mrqa_naturalquestions-validation-3013", "mrqa_naturalquestions-validation-3232", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-333", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-3555", "mrqa_naturalquestions-validation-3593", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-4165", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-4338", "mrqa_naturalquestions-validation-454", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-477", "mrqa_naturalquestions-validation-4869", "mrqa_naturalquestions-validation-5002", "mrqa_naturalquestions-validation-5051", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-5425", "mrqa_naturalquestions-validation-5483", "mrqa_naturalquestions-validation-5564", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6206", "mrqa_naturalquestions-validation-633", "mrqa_naturalquestions-validation-6382", "mrqa_naturalquestions-validation-6442", "mrqa_naturalquestions-validation-6561", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-8164", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-9660", "mrqa_naturalquestions-validation-9726", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1056", "mrqa_newsqa-validation-1069", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1177", "mrqa_newsqa-validation-1177", "mrqa_newsqa-validation-1280", "mrqa_newsqa-validation-13", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-1309", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1377", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-1430", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1501", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1709", "mrqa_newsqa-validation-1812", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-2106", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-216", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-2252", "mrqa_newsqa-validation-2296", "mrqa_newsqa-validation-2338", "mrqa_newsqa-validation-2357", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2428", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2465", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-2562", "mrqa_newsqa-validation-257", "mrqa_newsqa-validation-2578", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-2632", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2656", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-2740", "mrqa_newsqa-validation-2753", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2808", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2865", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2945", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-3114", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-3144", "mrqa_newsqa-validation-3156", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3179", "mrqa_newsqa-validation-3190", "mrqa_newsqa-validation-3218", "mrqa_newsqa-validation-324", "mrqa_newsqa-validation-3247", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-3299", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-3313", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3360", "mrqa_newsqa-validation-3370", "mrqa_newsqa-validation-3406", "mrqa_newsqa-validation-344", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3488", "mrqa_newsqa-validation-3499", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-3602", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-3614", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-3688", "mrqa_newsqa-validation-3688", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3722", "mrqa_newsqa-validation-3758", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3795", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3849", "mrqa_newsqa-validation-3852", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3876", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-4002", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-407", "mrqa_newsqa-validation-4119", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4178", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-510", "mrqa_newsqa-validation-538", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-555", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-570", "mrqa_newsqa-validation-578", "mrqa_newsqa-validation-625", "mrqa_newsqa-validation-627", "mrqa_newsqa-validation-704", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-754", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-785", "mrqa_newsqa-validation-832", "mrqa_newsqa-validation-885", "mrqa_newsqa-validation-893", "mrqa_newsqa-validation-898", "mrqa_newsqa-validation-92", "mrqa_searchqa-validation-100", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-10045", "mrqa_searchqa-validation-10090", "mrqa_searchqa-validation-10116", "mrqa_searchqa-validation-10193", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10790", "mrqa_searchqa-validation-1085", "mrqa_searchqa-validation-11002", "mrqa_searchqa-validation-11050", "mrqa_searchqa-validation-11375", "mrqa_searchqa-validation-11450", "mrqa_searchqa-validation-11451", "mrqa_searchqa-validation-11466", "mrqa_searchqa-validation-11495", "mrqa_searchqa-validation-11710", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-11867", "mrqa_searchqa-validation-12117", "mrqa_searchqa-validation-12313", "mrqa_searchqa-validation-12317", "mrqa_searchqa-validation-12340", "mrqa_searchqa-validation-12357", "mrqa_searchqa-validation-12409", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13028", "mrqa_searchqa-validation-13326", "mrqa_searchqa-validation-13434", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-13616", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-13951", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14346", "mrqa_searchqa-validation-14398", "mrqa_searchqa-validation-14405", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-15158", "mrqa_searchqa-validation-15749", "mrqa_searchqa-validation-16053", "mrqa_searchqa-validation-16144", "mrqa_searchqa-validation-16282", "mrqa_searchqa-validation-16605", "mrqa_searchqa-validation-16886", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-16913", "mrqa_searchqa-validation-1791", "mrqa_searchqa-validation-1843", "mrqa_searchqa-validation-2175", "mrqa_searchqa-validation-2260", "mrqa_searchqa-validation-2386", "mrqa_searchqa-validation-2394", "mrqa_searchqa-validation-2462", "mrqa_searchqa-validation-248", "mrqa_searchqa-validation-2508", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-2963", "mrqa_searchqa-validation-3127", "mrqa_searchqa-validation-3163", "mrqa_searchqa-validation-3381", "mrqa_searchqa-validation-3398", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3540", "mrqa_searchqa-validation-3554", "mrqa_searchqa-validation-3644", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-409", "mrqa_searchqa-validation-4142", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-4383", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-4697", "mrqa_searchqa-validation-4972", "mrqa_searchqa-validation-4978", "mrqa_searchqa-validation-5522", "mrqa_searchqa-validation-5757", "mrqa_searchqa-validation-5970", "mrqa_searchqa-validation-6372", "mrqa_searchqa-validation-6420", "mrqa_searchqa-validation-689", "mrqa_searchqa-validation-697", "mrqa_searchqa-validation-6977", "mrqa_searchqa-validation-7019", "mrqa_searchqa-validation-7022", "mrqa_searchqa-validation-7132", "mrqa_searchqa-validation-7396", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-7418", "mrqa_searchqa-validation-8236", "mrqa_searchqa-validation-8368", "mrqa_searchqa-validation-8667", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8770", "mrqa_searchqa-validation-8776", "mrqa_searchqa-validation-9109", "mrqa_searchqa-validation-9399", "mrqa_searchqa-validation-9687", "mrqa_searchqa-validation-9725", "mrqa_searchqa-validation-9943", "mrqa_squad-validation-10011", "mrqa_squad-validation-10494", "mrqa_squad-validation-1055", "mrqa_squad-validation-1092", "mrqa_squad-validation-1213", "mrqa_squad-validation-1268", "mrqa_squad-validation-1384", "mrqa_squad-validation-1490", "mrqa_squad-validation-1512", "mrqa_squad-validation-1529", "mrqa_squad-validation-1615", "mrqa_squad-validation-167", "mrqa_squad-validation-1725", "mrqa_squad-validation-1742", "mrqa_squad-validation-1771", "mrqa_squad-validation-1849", "mrqa_squad-validation-1891", "mrqa_squad-validation-1936", "mrqa_squad-validation-1941", "mrqa_squad-validation-204", "mrqa_squad-validation-2059", "mrqa_squad-validation-2095", "mrqa_squad-validation-2283", "mrqa_squad-validation-2387", "mrqa_squad-validation-2416", "mrqa_squad-validation-2476", "mrqa_squad-validation-2613", "mrqa_squad-validation-2640", "mrqa_squad-validation-2788", "mrqa_squad-validation-2857", "mrqa_squad-validation-2865", "mrqa_squad-validation-2920", "mrqa_squad-validation-2932", "mrqa_squad-validation-2938", "mrqa_squad-validation-3040", "mrqa_squad-validation-3068", "mrqa_squad-validation-3283", "mrqa_squad-validation-3317", "mrqa_squad-validation-3407", "mrqa_squad-validation-3456", "mrqa_squad-validation-3493", "mrqa_squad-validation-3790", "mrqa_squad-validation-3941", "mrqa_squad-validation-3954", "mrqa_squad-validation-4241", "mrqa_squad-validation-4398", "mrqa_squad-validation-4402", "mrqa_squad-validation-4452", "mrqa_squad-validation-457", "mrqa_squad-validation-4633", "mrqa_squad-validation-4764", "mrqa_squad-validation-477", "mrqa_squad-validation-4841", "mrqa_squad-validation-4933", "mrqa_squad-validation-5003", "mrqa_squad-validation-5029", "mrqa_squad-validation-5185", "mrqa_squad-validation-5222", "mrqa_squad-validation-5311", "mrqa_squad-validation-543", "mrqa_squad-validation-5470", "mrqa_squad-validation-5479", "mrqa_squad-validation-57", "mrqa_squad-validation-5765", "mrqa_squad-validation-5778", "mrqa_squad-validation-5804", "mrqa_squad-validation-5961", "mrqa_squad-validation-6121", "mrqa_squad-validation-6147", "mrqa_squad-validation-6241", "mrqa_squad-validation-6470", "mrqa_squad-validation-6548", "mrqa_squad-validation-664", "mrqa_squad-validation-677", "mrqa_squad-validation-6792", "mrqa_squad-validation-6869", "mrqa_squad-validation-693", "mrqa_squad-validation-694", "mrqa_squad-validation-7022", "mrqa_squad-validation-7064", "mrqa_squad-validation-719", "mrqa_squad-validation-7202", "mrqa_squad-validation-7243", "mrqa_squad-validation-7338", "mrqa_squad-validation-7443", "mrqa_squad-validation-7494", "mrqa_squad-validation-7546", "mrqa_squad-validation-7729", "mrqa_squad-validation-7733", "mrqa_squad-validation-7747", "mrqa_squad-validation-7772", "mrqa_squad-validation-7908", "mrqa_squad-validation-7918", "mrqa_squad-validation-7951", "mrqa_squad-validation-7964", "mrqa_squad-validation-809", "mrqa_squad-validation-8115", "mrqa_squad-validation-8196", "mrqa_squad-validation-8204", "mrqa_squad-validation-8216", "mrqa_squad-validation-8412", "mrqa_squad-validation-8495", "mrqa_squad-validation-850", "mrqa_squad-validation-851", "mrqa_squad-validation-8551", "mrqa_squad-validation-8558", "mrqa_squad-validation-8683", "mrqa_squad-validation-8864", "mrqa_squad-validation-8923", "mrqa_squad-validation-9087", "mrqa_squad-validation-9178", "mrqa_squad-validation-9227", "mrqa_squad-validation-9528", "mrqa_squad-validation-957", "mrqa_squad-validation-9581", "mrqa_squad-validation-9775", "mrqa_squad-validation-9910", "mrqa_squad-validation-9944", "mrqa_squad-validation-9954", "mrqa_squad-validation-997", "mrqa_squad-validation-9993", "mrqa_squad-validation-9996", "mrqa_triviaqa-validation-115", "mrqa_triviaqa-validation-1198", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-1459", "mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-1866", "mrqa_triviaqa-validation-1972", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2250", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2541", "mrqa_triviaqa-validation-2676", "mrqa_triviaqa-validation-2815", "mrqa_triviaqa-validation-3097", "mrqa_triviaqa-validation-3232", "mrqa_triviaqa-validation-3423", "mrqa_triviaqa-validation-3450", "mrqa_triviaqa-validation-3562", "mrqa_triviaqa-validation-381", "mrqa_triviaqa-validation-3815", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-3931", "mrqa_triviaqa-validation-395", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4094", "mrqa_triviaqa-validation-4336", "mrqa_triviaqa-validation-4442", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-4493", "mrqa_triviaqa-validation-4580", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5659", "mrqa_triviaqa-validation-5766", "mrqa_triviaqa-validation-5771", "mrqa_triviaqa-validation-5863", "mrqa_triviaqa-validation-5910", "mrqa_triviaqa-validation-6001", "mrqa_triviaqa-validation-6050", "mrqa_triviaqa-validation-6277", "mrqa_triviaqa-validation-6282", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-6649", "mrqa_triviaqa-validation-6846", "mrqa_triviaqa-validation-6930", "mrqa_triviaqa-validation-6939", "mrqa_triviaqa-validation-7281", "mrqa_triviaqa-validation-7474", "mrqa_triviaqa-validation-7563", "mrqa_triviaqa-validation-7672", "mrqa_triviaqa-validation-795"], "OKR": 0.890625, "KG": 0.4765625, "before_eval_results": {"predictions": ["1985", "a nurse who tried to treat Jackson's insomnia with natural remedies", "eight", "Austin Wuennenberg,", "in a canyon in the path of the blaze", "machine guns and two silencers", "Matthew Fisher", "Republican Gov. Bobby Jindal", "NATO", "Sen. Joe Lieberman", "the meter reader", "the Gulf", "Haiti.", "northwest Pakistan", "Basel", "Pyongyang and Seoul", "\"And even though she's not here anymore, I'm not afraid to say it, sometimes she was a pain in the ass,\"", "Kurt Cobain's", "he was disqualified from a bout for pulling on the top-knot of an opponent,", "1983", "22-10.", "Egypt.", "Fakih", "delivers a big speech", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "Justicialist Party,", "between 3 million and 4 million fossilized bones.", "The Falklands, known as Las Malvinas in Argentina,", "86", "future relations between the Middle East and Washington.", "cell phones", "six", "2004.", "Egypt", "U.S. security coordinator and chief of the Office of Military Cooperation.", "19-year-old", "a bucket truck used for repairing power lines to something resembling an enclosed golf cart to a pair of hot-looking, two-seater sports cars.", "President Obama's", "\"Walk -- Don't Run\" and \"Hawaii Five-O\"", "melt", "Communist", "the journalists and the flight crew will be freed,", "Haitians", "Sri Lanka", "he said Chaudhary's death should serve as a warning to management,", "summer", "The Rev. Alberto Cutie", "since 1983.", "the child might still be alive,", "the content of the speech,", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Afghanistan", "Tsetse fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "in 1957", "Jack Ruby", "The Altamont Speedway Free Festival", "Trainspotting", "John Gielgud", "6, 1967", "Latin American culture", "Jake Farris", "People of the Book", "Stranger in a Strange Land", "Nippon Professional Baseball"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6948383879524868}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 0.5, 1.0, 0.923076923076923, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.17142857142857143, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5454545454545454, 1.0, 1.0, 0.9767441860465117, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1241", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-1598", "mrqa_newsqa-validation-3223", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-3703", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1902", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-878", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-2330", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-1870", "mrqa_hotpotqa-validation-4027", "mrqa_searchqa-validation-13556", "mrqa_searchqa-validation-4535", "mrqa_hotpotqa-validation-5556"], "SR": 0.578125, "CSR": 0.5575457317073171, "retrieved_ids": ["mrqa_squad-train-1469", "mrqa_squad-train-83647", "mrqa_squad-train-50362", "mrqa_squad-train-29050", "mrqa_squad-train-39010", "mrqa_squad-train-43598", "mrqa_squad-train-47579", "mrqa_squad-train-84662", "mrqa_squad-train-62895", "mrqa_squad-train-49661", "mrqa_squad-train-717", "mrqa_squad-train-44176", "mrqa_squad-train-80588", "mrqa_squad-train-29018", "mrqa_squad-train-42000", "mrqa_squad-train-44562", "mrqa_squad-train-31560", "mrqa_squad-train-37848", "mrqa_squad-train-787", "mrqa_squad-train-1525", "mrqa_squad-train-57301", "mrqa_squad-train-45691", "mrqa_squad-train-27667", "mrqa_squad-train-62938", "mrqa_squad-train-48671", "mrqa_squad-train-32308", "mrqa_squad-train-66169", "mrqa_squad-train-18419", "mrqa_squad-train-73942", "mrqa_squad-train-13815", "mrqa_squad-train-24959", "mrqa_squad-train-69653", "mrqa_newsqa-validation-714", "mrqa_hotpotqa-validation-1791", "mrqa_naturalquestions-validation-3348", "mrqa_triviaqa-validation-2858", "mrqa_newsqa-validation-2287", "mrqa_naturalquestions-validation-3427", "mrqa_triviaqa-validation-2972", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-4063", "mrqa_naturalquestions-validation-10719", "mrqa_searchqa-validation-2252", "mrqa_searchqa-validation-7043", "mrqa_searchqa-validation-5056", "mrqa_newsqa-validation-1749", "mrqa_searchqa-validation-9777", "mrqa_triviaqa-validation-412", "mrqa_triviaqa-validation-2735", "mrqa_newsqa-validation-2945", "mrqa_triviaqa-validation-1630", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-3608", "mrqa_searchqa-validation-7581", "mrqa_newsqa-validation-1128", "mrqa_triviaqa-validation-5052", "mrqa_squad-validation-1500", "mrqa_searchqa-validation-3216", "mrqa_searchqa-validation-2768", "mrqa_searchqa-validation-8080", "mrqa_searchqa-validation-11095", "mrqa_searchqa-validation-8368", "mrqa_newsqa-validation-158", "mrqa_searchqa-validation-6737"], "EFR": 1.0, "Overall": 0.7333841463414634}, {"timecode": 41, "before_eval_results": {"predictions": ["historians", "Adam Lambert", "in a Nazi concentration camp,", "in the mouth.", "opening the door for the man who shot him,", "A Brazilian supreme court judge", "the trip had caused fury among some in the military who saw it as a waste of time and money at a time when British forces are thinly-stretched, fighting in Iraq and Afghanistan.", "KBR's", "the same drama that pulls in the crowds", "across Greece", "a monthly allowance,", "U.S. Navy", "their \"Freshman Year\" experience", "Marcell J Hansen", "he believed he was about to be attacked himself.", "Ross Perot.", "outside the municipal building of Abu Ghraib in western Baghdad,", "Al Nisr Al Saudi", "two years ago.", "Appathurai", "The sailboat, named Cynthia Woods,", "The FBI's Baltimore field office", "Tuesday in Los Angeles.", "Honduran", "curfew", "Sri Lankan", "Robert", "as he exercised in a park in a residential area of Mexico City,", "16 times.", "Disney", "into the picturesque Gamla Vaster neighborhood", "the Russian air force,", "an Italian and six Africans", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "an auxiliary lock", "German Chancellor Angela Merkel", "2,700-acre", "Missouri.", "a small minority who said they wanted to demand", "Ketamine", "Haleigh Cummings,", "two and a half hours.", "Bobby Darin,", "New Year's Day", "Monday.", "Hakeemullah Mehsud", "kill then-Sen. Obama", "an obscure story of flowers", "Kuranyi's", "Kris Allen,", "\"There is no way to even begin to share the things we've heard and seen since 5 p.m. yesterday,\"", "2", "Supplemental oxygen", "between 11000 and 9000 BC", "ditz", "james stewart", "Harriet Tubman", "lion", "German", "Forbes", "devils or demons", "cholesterol", "Orlando", "The Italian Agostino Bassi"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5727456980866801}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, true, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.3333333333333333, 1.0, 0.3157894736842105, 0.4, 0.4878048780487806, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8421052631578948, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.8, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.5, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-2941", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-1287", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-2143", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-2485", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-1275", "mrqa_newsqa-validation-1102", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-522", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-1920", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-3854", "mrqa_newsqa-validation-1334", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1569", "mrqa_newsqa-validation-3132", "mrqa_newsqa-validation-706", "mrqa_naturalquestions-validation-997", "mrqa_naturalquestions-validation-7589", "mrqa_triviaqa-validation-5724", "mrqa_triviaqa-validation-7627", "mrqa_triviaqa-validation-5973", "mrqa_hotpotqa-validation-3343", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-13584", "mrqa_naturalquestions-validation-8733"], "SR": 0.4375, "CSR": 0.5546875, "retrieved_ids": ["mrqa_squad-train-68467", "mrqa_squad-train-66590", "mrqa_squad-train-72680", "mrqa_squad-train-9674", "mrqa_squad-train-49003", "mrqa_squad-train-77029", "mrqa_squad-train-69543", "mrqa_squad-train-79096", "mrqa_squad-train-54410", "mrqa_squad-train-9747", "mrqa_squad-train-17752", "mrqa_squad-train-22226", "mrqa_squad-train-53713", "mrqa_squad-train-12046", "mrqa_squad-train-56995", "mrqa_squad-train-9669", "mrqa_squad-train-70829", "mrqa_squad-train-20501", "mrqa_squad-train-26675", "mrqa_squad-train-26472", "mrqa_squad-train-6869", "mrqa_squad-train-17429", "mrqa_squad-train-68279", "mrqa_squad-train-80171", "mrqa_squad-train-29257", "mrqa_squad-train-47845", "mrqa_squad-train-32563", "mrqa_squad-train-46620", "mrqa_squad-train-50109", "mrqa_squad-train-48569", "mrqa_squad-train-85681", "mrqa_squad-train-58574", "mrqa_newsqa-validation-3557", "mrqa_searchqa-validation-14508", "mrqa_searchqa-validation-16053", "mrqa_squad-validation-6390", "mrqa_searchqa-validation-3735", "mrqa_searchqa-validation-2617", "mrqa_squad-validation-1092", "mrqa_newsqa-validation-1303", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-2614", "mrqa_squad-validation-694", "mrqa_newsqa-validation-1101", "mrqa_naturalquestions-validation-10265", "mrqa_triviaqa-validation-2716", "mrqa_naturalquestions-validation-7059", "mrqa_newsqa-validation-336", "mrqa_newsqa-validation-3899", "mrqa_triviaqa-validation-115", "mrqa_newsqa-validation-2680", "mrqa_naturalquestions-validation-1657", "mrqa_searchqa-validation-15953", "mrqa_naturalquestions-validation-5564", "mrqa_searchqa-validation-10799", "mrqa_searchqa-validation-2175", "mrqa_squad-validation-6680", "mrqa_naturalquestions-validation-1414", "mrqa_newsqa-validation-2791", "mrqa_naturalquestions-validation-5185", "mrqa_naturalquestions-validation-6116", "mrqa_triviaqa-validation-2406"], "EFR": 0.9444444444444444, "Overall": 0.7217013888888889}, {"timecode": 42, "before_eval_results": {"predictions": ["non-Mongol physicians", "minimum viable", "Freddie Highmore", "Elvis Presley", "divergent tectonic", "Stefanie Scott", "Tanvi Shah", "Kida", "1991", "Sam Waterston", "Bobby Beathard, Robert Brazile, Brian Dawkins, Jerry Kramer, Ray Lewis, Randy Moss, Terrell Owens, and Brian Urlacher", "Palmer Williams Jr.", "Chicago metropolitan area", "Coldplay", "$19.8 trillion", "3,000 metres ( 9,800 ft )", "Ann Gillespie", "Brooklyn Heights, New York", "Doc '' Brown", "the opisthodomus", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Albert Einstein", "1994", "Fred E. Ahlert", "Institute of Chartered Accountants of India ( ICAI )", "2018", "Bette Midler", "push the food down the esophagus", "Walter Mondale", "Nick Sager", "Sweden's long - standing policy of neutrality was tested on many occasions during the 1930s", "end of the 18th century", "Graham McTavish", "1962", "Julie Adams", "Theodosius I", "James Long", "one", "Bill Belichick", "to address the historic oppression, inequality and discrimination faced by those communities and to give these communities a place", "Brobee", "January 15, 2007", "John Garfield", "small Garden plants such as balsam", "10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "Geophysicists", "billy", "360", "November 17, 2017", "John Barry", "Bart Millard", "Sven Goran Eriksson", "the Marshall Plan", "Norfolk Island", "1932", "the Fundamentalist Church of Jesus Christ of Latter Day Saints", "erie Stowe", "The Screening Room", "supermodel", "people around the world commented, pondered, and paid tribute to pop legend Michael Jackson,", "a surrogate", "salt", "Rocky Marciano", "consumer confidence"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6008109286045624}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.21052631578947367, 0.7499999999999999, 1.0, 0.19999999999999998, 0.5, 0.4, 1.0, 0.5714285714285715, 0.6666666666666666, 0.0, 0.35294117647058826, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5555555555555556, 0.29629629629629634, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1818181818181818, 0.0, 1.0, 1.0, 0.1, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-4915", "mrqa_naturalquestions-validation-3257", "mrqa_naturalquestions-validation-6555", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-8794", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-4930", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-6363", "mrqa_naturalquestions-validation-1147", "mrqa_naturalquestions-validation-8099", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-6857", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-4225", "mrqa_triviaqa-validation-6972", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-4294", "mrqa_newsqa-validation-1351", "mrqa_searchqa-validation-10233"], "SR": 0.515625, "CSR": 0.5537790697674418, "retrieved_ids": ["mrqa_squad-train-14889", "mrqa_squad-train-19749", "mrqa_squad-train-18313", "mrqa_squad-train-13713", "mrqa_squad-train-30447", "mrqa_squad-train-31865", "mrqa_squad-train-33628", "mrqa_squad-train-7608", "mrqa_squad-train-20797", "mrqa_squad-train-63711", "mrqa_squad-train-80391", "mrqa_squad-train-10840", "mrqa_squad-train-20531", "mrqa_squad-train-21500", "mrqa_squad-train-64239", "mrqa_squad-train-5519", "mrqa_squad-train-14404", "mrqa_squad-train-29739", "mrqa_squad-train-46041", "mrqa_squad-train-12743", "mrqa_squad-train-17954", "mrqa_squad-train-63067", "mrqa_squad-train-29396", "mrqa_squad-train-80746", "mrqa_squad-train-55173", "mrqa_squad-train-62560", "mrqa_squad-train-72861", "mrqa_squad-train-28195", "mrqa_squad-train-58743", "mrqa_squad-train-47752", "mrqa_squad-train-20378", "mrqa_squad-train-65441", "mrqa_squad-validation-5456", "mrqa_squad-validation-7653", "mrqa_triviaqa-validation-2431", "mrqa_searchqa-validation-4624", "mrqa_naturalquestions-validation-9931", "mrqa_newsqa-validation-336", "mrqa_squad-validation-9533", "mrqa_newsqa-validation-4003", "mrqa_triviaqa-validation-6643", "mrqa_newsqa-validation-232", "mrqa_triviaqa-validation-381", "mrqa_triviaqa-validation-7539", "mrqa_triviaqa-validation-3087", "mrqa_squad-validation-7687", "mrqa_triviaqa-validation-3468", "mrqa_searchqa-validation-15530", "mrqa_triviaqa-validation-6199", "mrqa_naturalquestions-validation-5928", "mrqa_searchqa-validation-4266", "mrqa_newsqa-validation-3162", "mrqa_newsqa-validation-4126", "mrqa_squad-validation-1500", "mrqa_newsqa-validation-2799", "mrqa_searchqa-validation-15608", "mrqa_naturalquestions-validation-5317", "mrqa_newsqa-validation-3343", "mrqa_triviaqa-validation-5573", "mrqa_searchqa-validation-16816", "mrqa_newsqa-validation-2653", "mrqa_searchqa-validation-1701", "mrqa_searchqa-validation-8619", "mrqa_newsqa-validation-4158"], "EFR": 0.967741935483871, "Overall": 0.7261792010502626}, {"timecode": 43, "before_eval_results": {"predictions": ["confrontational", "A witness", "34", "Miami Beach, Florida,", "team of eight surgeons", "Somalia's piracy problem was fueled by environmental and political events.(CNN)", "Cash for Clunkers", "Kim Clijsters", "it has witnessed only normal maritime traffic around Haiti, and it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "California-based Current TV", "I, the chief executive officer, the one on the very top", "Kevin Kuranyi", "Matt Kuchar and Bubba Watson", "Columbia", "Omar Bongo,", "\"active athletes,\"", "mother", "Casablanca, Morocco,", "1940's Japan.", "tax incentives", "ketamine.", "people have chosen their rides based on what their", "up three", "Chinese", "Passers-by", "\"He hears what I'm saying, but there's just no coming through,\"", "not guilty by reason of insanity that would have resulted in psychiatric custody.", "Larry Ellison,", "The Mexican military", "Sporting Lisbon", "The Kirchners", "she sought Cain's help finding a job after being laid off from the trade association's education foundation in 1997.", "July 1999", "CNN's", "\"weighing all options necessary to protect his client?\"", "London's O2 arena,", "90", "Col. Elspeth Cameron-Ritchie,", "most of those who managed to survive the incident hid in a boiler room and storage closets during the rampage.", "his parents", "nearly 28 years", "(3 degrees Fahrenheit),", "Claude Monet pastel drawing of London's Waterloo Bridge", "Princess Diana", "Consumer Reports", "Cash for Clunkers", "nine-wicket win", "(3 degrees Fahrenheit),", "Plymouth Rock", "co-wrote its signature song,\"The Devil Went Down to Georgia.\"", "Michael Schumacher", "freedom of speech, the freedom of the press, the right to peaceably assemble, or to petition for a governmental redress of grievances", "provides for the states to finance health care for individuals who were at or close to the public assistance level with federal matching funds", "Julia Roberts", "line code", "a miller", "The Muffin Man", "Childeric I", "Kunta Kinte", "Almeda Mall", "Greek cheese", "Fram", "the Ross Ice Shelf", "dani\u00eb"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5889585444870644}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.9, 1.0, 0.6666666666666666, 0.08695652173913045, 0.8, 0.0, 1.0, 0.8333333333333333, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.21276595744680854, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.058823529411764705, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6792452830188679, 0.9777777777777777, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1680", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-805", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-142", "mrqa_newsqa-validation-649", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-1549", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2456", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-1968", "mrqa_newsqa-validation-2586", "mrqa_newsqa-validation-2392", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-792", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-3990", "mrqa_naturalquestions-validation-9837", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-6285", "mrqa_triviaqa-validation-2314", "mrqa_triviaqa-validation-1439", "mrqa_hotpotqa-validation-721", "mrqa_hotpotqa-validation-4198", "mrqa_hotpotqa-validation-5199", "mrqa_searchqa-validation-1615", "mrqa_triviaqa-validation-7164"], "SR": 0.453125, "CSR": 0.5514914772727273, "retrieved_ids": ["mrqa_squad-train-8183", "mrqa_squad-train-7219", "mrqa_squad-train-36221", "mrqa_squad-train-2839", "mrqa_squad-train-885", "mrqa_squad-train-82017", "mrqa_squad-train-44398", "mrqa_squad-train-68037", "mrqa_squad-train-22099", "mrqa_squad-train-56979", "mrqa_squad-train-22521", "mrqa_squad-train-3206", "mrqa_squad-train-31082", "mrqa_squad-train-5971", "mrqa_squad-train-42288", "mrqa_squad-train-78020", "mrqa_squad-train-36474", "mrqa_squad-train-40345", "mrqa_squad-train-76051", "mrqa_squad-train-8429", "mrqa_squad-train-16050", "mrqa_squad-train-16791", "mrqa_squad-train-84629", "mrqa_squad-train-31525", "mrqa_squad-train-3697", "mrqa_squad-train-77965", "mrqa_squad-train-62020", "mrqa_squad-train-55726", "mrqa_squad-train-55016", "mrqa_squad-train-37584", "mrqa_squad-train-76447", "mrqa_squad-train-64569", "mrqa_newsqa-validation-3029", "mrqa_searchqa-validation-396", "mrqa_squad-validation-4908", "mrqa_searchqa-validation-5939", "mrqa_searchqa-validation-6763", "mrqa_triviaqa-validation-862", "mrqa_hotpotqa-validation-2379", "mrqa_searchqa-validation-5339", "mrqa_squad-validation-9533", "mrqa_naturalquestions-validation-7080", "mrqa_newsqa-validation-1443", "mrqa_naturalquestions-validation-5452", "mrqa_naturalquestions-validation-1784", "mrqa_searchqa-validation-9137", "mrqa_searchqa-validation-4624", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-3775", "mrqa_naturalquestions-validation-9032", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-15007", "mrqa_newsqa-validation-1128", "mrqa_searchqa-validation-4888", "mrqa_searchqa-validation-13787", "mrqa_naturalquestions-validation-2781", "mrqa_searchqa-validation-2226", "mrqa_triviaqa-validation-1916", "mrqa_naturalquestions-validation-633", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-495", "mrqa_searchqa-validation-14198", "mrqa_naturalquestions-validation-4193", "mrqa_newsqa-validation-886"], "EFR": 0.9714285714285714, "Overall": 0.7264590097402597}, {"timecode": 44, "before_eval_results": {"predictions": ["Grey Street", "Stratfor,", "269,000", "August 4, 2000", "Sunday", "Why he's more American than a German,", "Wilhelmina Kids,", "Rawalpindi", "poor.", "40", "700", "The woman involved -- Mandi Hamlin", "breast cancer.", "Alfredo Astiz,", "$5.5 billion", "Her husband and attorney, James Whitehouse,", "3.5", "Thailand", "rural Tennessee.", "39,", "question people if there's reason to suspect they're in the United States illegally.", "Derek Mears", "Sunday,", "Stuttgart", "27 Awa", "45 minutes,", "14 years", "Chesley \"Sully\"", "not", "repression and dire economic circumstances.", "He hit the Sunday talk show circuit this weekend and tried out the attack dog role, criticizing Republican John McCain for his stance on Georgia, Iraq and national security.", "the way their business books were being handled.", "The Bronx County District Attorneys Office", "Ma Khin Khin Leh,", "a federal judge in Mississippi", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify. Military commission judges also will be able to establish the jurisdiction of their own courts.", "he fears a desperate country with a potential power vacuum that could lash out.", "123 pounds of cocaine and 4.5 pounds of heroin,", "3-0", "70,000 or so", "citizenship", "Manuel Mejia Munera", "2,700-acre", "his comments", "two weeks after Black History Month", "smiley.", "Barzee,", "pro-democracy activists", "Kim Jong Un", "3,000 kilometers (1,900 miles),", "taking the product off the market would result in hardship for terminally ill patients and their caregivers,", "typically closes for two and half weeks in late summer", "the euro", "a member of the family Sturnidae ( starlings and mynas ) native to Asia", "stoup", "Fun Advice Trivia", "Douglas MacArthur", "PlayStation 4", "CNBC Europe, Independent Television News and BBC News", "cricket fighting", "Patty Duke", "Galileo Galilei", "Carson McCullers", "fearful man, all in coarse gray with a great iron on his leg"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6911277958152958}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5714285714285715, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 1.0, 0.42857142857142855, 1.0, 0.22222222222222224, 0.0, 0.19999999999999998, 1.0, 0.0, 1.0, 1.0, 0.9090909090909091, 0.13333333333333333, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1554", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-388", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-4078", "mrqa_newsqa-validation-2083", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1879", "mrqa_newsqa-validation-1833", "mrqa_newsqa-validation-4211", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2773", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-205", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-3827", "mrqa_newsqa-validation-1065", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-5687", "mrqa_triviaqa-validation-6608", "mrqa_triviaqa-validation-7376", "mrqa_hotpotqa-validation-1685", "mrqa_searchqa-validation-10531", "mrqa_triviaqa-validation-3284"], "SR": 0.578125, "CSR": 0.5520833333333333, "retrieved_ids": ["mrqa_squad-train-4798", "mrqa_squad-train-14354", "mrqa_squad-train-47119", "mrqa_squad-train-19226", "mrqa_squad-train-51469", "mrqa_squad-train-31982", "mrqa_squad-train-64249", "mrqa_squad-train-27210", "mrqa_squad-train-49793", "mrqa_squad-train-71911", "mrqa_squad-train-78244", "mrqa_squad-train-59199", "mrqa_squad-train-10945", "mrqa_squad-train-52888", "mrqa_squad-train-68954", "mrqa_squad-train-9117", "mrqa_squad-train-19758", "mrqa_squad-train-44213", "mrqa_squad-train-51317", "mrqa_squad-train-63031", "mrqa_squad-train-53733", "mrqa_squad-train-20428", "mrqa_squad-train-545", "mrqa_squad-train-29990", "mrqa_squad-train-1189", "mrqa_squad-train-26162", "mrqa_squad-train-44015", "mrqa_squad-train-20227", "mrqa_squad-train-12299", "mrqa_squad-train-56589", "mrqa_squad-train-8421", "mrqa_squad-train-49408", "mrqa_naturalquestions-validation-327", "mrqa_newsqa-validation-1436", "mrqa_naturalquestions-validation-3840", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-886", "mrqa_naturalquestions-validation-5483", "mrqa_triviaqa-validation-5810", "mrqa_newsqa-validation-367", "mrqa_newsqa-validation-1844", "mrqa_naturalquestions-validation-2680", "mrqa_newsqa-validation-1309", "mrqa_searchqa-validation-8080", "mrqa_searchqa-validation-14366", "mrqa_triviaqa-validation-2022", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-2934", "mrqa_naturalquestions-validation-9246", "mrqa_squad-validation-1941", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-3993", "mrqa_newsqa-validation-2473", "mrqa_searchqa-validation-8756", "mrqa_naturalquestions-validation-6116", "mrqa_squad-validation-9640", "mrqa_naturalquestions-validation-519", "mrqa_newsqa-validation-1393", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-3369", "mrqa_newsqa-validation-416", "mrqa_newsqa-validation-2456", "mrqa_searchqa-validation-6722"], "EFR": 1.0, "Overall": 0.7322916666666666}, {"timecode": 45, "before_eval_results": {"predictions": ["sports tourism", "0-0 draw", "Aung San Suu Kyi", "led the weekend box office, grossing $55.7 million during its first weekend.", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Al-Shabaab,", "a treadmill", "Iran", "Piers Morgan", "Mary Phagan", "well over two decades.", "100,000", "drowned in the Pacific Ocean", "more than a million residents", "12-1 on aggregate.", "drama of the action in-and-around the golf course", "poems telling of the pain and suffering of children just like her;", "\"mentally deranged person steeped in the inveterate enmity towards the system\" in the North.", "teenage", "100% of its byproducts", "it really like to be a new member of the world's most powerful legislature?", "participate in Iraq's government.", "The Rosie Show", "helicopters and unmanned aerial vehicles", "racial intolerance.", "model of sustainability.", "Rolling Stone", "dogs who walk on ice in Alaska.", "Ralph Lauren", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "82", "\"A U.N. Security Council resolution in 2006 banned North Korea from conducting ballistic missile activity.", "\"a striking blow to due process and the rule of law.\"", "his brother to surrender.", "$250,000 for Rivers' charity: God's Love We Deliver.", "Elizabeth Birnbaum", "three", "once on New Year's", "Lindsey Vonn", "last month's", "Rwanda", "cancer", "Jose Manuel Zelaya", "around 10:30 p.m. October 3,", "onto the college campus.", "200", "a full garden and pool, a tennis court, or several heli-pads.", "an annual road trip,", "Brian Mabry", "\"Phil Spector did not testify at his five-month murder trial. The jury said it was split 10-2.", "July", "December 2, 2013, and the third season concluded on October 1, 2017", "1,070 km ( 665 mi ) east - southeast of Cape Hatteras, North Carolina ; 1,236 km ( 768 mi ) south of Cape Sable Island, Nova Scotia", "Christopher Lloyd", "Nero", "Somalia", "the Andes Mountains of Chile and Argentina", "River Shiel", "7 miles", "Burnley", "O. Henry", "Robert Downey Jr.", "James Clerk Maxwell", "system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7466688064114535}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.5555555555555556, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.5, 1.0, 0.16666666666666669, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.7499999999999999, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8148148148148148, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.2222222222222222]}}, "before_error_ids": ["mrqa_newsqa-validation-3159", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-2116", "mrqa_newsqa-validation-3178", "mrqa_newsqa-validation-2991", "mrqa_newsqa-validation-3075", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-1660", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-3879", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-4771", "mrqa_triviaqa-validation-495", "mrqa_triviaqa-validation-6295", "mrqa_triviaqa-validation-3547", "mrqa_searchqa-validation-13808", "mrqa_searchqa-validation-9553", "mrqa_naturalquestions-validation-952"], "SR": 0.640625, "CSR": 0.5540081521739131, "retrieved_ids": ["mrqa_squad-train-68449", "mrqa_squad-train-35332", "mrqa_squad-train-80242", "mrqa_squad-train-82172", "mrqa_squad-train-65378", "mrqa_squad-train-40807", "mrqa_squad-train-11386", "mrqa_squad-train-84974", "mrqa_squad-train-15336", "mrqa_squad-train-7396", "mrqa_squad-train-17897", "mrqa_squad-train-33647", "mrqa_squad-train-53223", "mrqa_squad-train-66327", "mrqa_squad-train-60758", "mrqa_squad-train-75968", "mrqa_squad-train-24856", "mrqa_squad-train-68695", "mrqa_squad-train-46604", "mrqa_squad-train-80630", "mrqa_squad-train-55817", "mrqa_squad-train-16492", "mrqa_squad-train-81325", "mrqa_squad-train-79279", "mrqa_squad-train-32994", "mrqa_squad-train-76839", "mrqa_squad-train-41995", "mrqa_squad-train-71998", "mrqa_squad-train-57713", "mrqa_squad-train-20485", "mrqa_squad-train-83121", "mrqa_squad-train-44094", "mrqa_searchqa-validation-10318", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-15007", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-367", "mrqa_newsqa-validation-593", "mrqa_newsqa-validation-1458", "mrqa_triviaqa-validation-330", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3350", "mrqa_searchqa-validation-7852", "mrqa_triviaqa-validation-7635", "mrqa_naturalquestions-validation-861", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-1303", "mrqa_naturalquestions-validation-3993", "mrqa_triviaqa-validation-237", "mrqa_naturalquestions-validation-6324", "mrqa_searchqa-validation-946", "mrqa_naturalquestions-validation-5966", "mrqa_newsqa-validation-418", "mrqa_searchqa-validation-409", "mrqa_newsqa-validation-4027", "mrqa_naturalquestions-validation-5687", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3406", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-3827", "mrqa_searchqa-validation-6992", "mrqa_naturalquestions-validation-154", "mrqa_newsqa-validation-1022"], "EFR": 0.9565217391304348, "Overall": 0.7239809782608695}, {"timecode": 46, "before_eval_results": {"predictions": ["Islam", "an insect sting", "al Fayed's", "opium", "maintain an \"aesthetic environment\" and ensure public safety,", "Tuesday", "science fiction", "the Beatles", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "23", "around Ciudad Juarez, across the border from El Paso, Texas.", "former U.S. secretary of state.", "South Africa", "Communist", "Charlotte Gainsbourg", "DBG,", "Ike", "The military commission decision", "41,", "Tuesday", "withdrawing most U.S. forces by the end of his current term,", "The local Republican Party", "the Taliban", "debris", "8,", "new materials -- including ultra-high-strength steel and boron", "a president who understands the world today, the future we seek and the change we need.", "in the neighboring country of Djibouti,", "in the mouth.", "over 1000 square meters in forward deck space,", "Alfredo Astiz,", "\"I remember growing up in the Middle East, influenced, enjoying his music, waiting for his albums,\"", "14 years", "1979", "300", "byproducts", "prostate cancer,", "EU naval force", "vice-chairman of Hussein's Revolutionary Command Council.", "Michelle Obama", "a fight outside of an Atlanta strip club", "\"People have lost their homes, their jobs, their hope,\"", "Afghanistan", "bodies and heads from view,", "Seoul.", "to make life a little easier for these families by organizing the distribution of wheelchair,", "Muqtada al-Sadr", "a house party in Crandon, Wisconsin,", "Ozzy Osbourne", "almost 100", "$81,88010", "Hungarian : Magyarorsz\u00e1g z\u00e1szlaja", "over 800 chapters and more than 80 tank\u014dbon volumes", "Ben Findon, Mike Myers and Bob Puzey", "Boxing Day", "Ernest Hemingway", "n\u00famero", "Ellie Kemper", "President's Volunteer Service Award", "nursery rhyme", "the Equator", "University of Washington", "Holly", "Lundy Island"], "metric_results": {"EM": 0.5, "QA-F1": 0.6526095456742036}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7272727272727273, 0.9565217391304348, 0.33333333333333337, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 0.0, 1.0, 0.30769230769230765, 1.0, 1.0, 0.9090909090909091, 0.0, 0.3529411764705882, 1.0, 0.28571428571428575, 1.0, 0.8, 0.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-979", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-4204", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-455", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-2341", "mrqa_newsqa-validation-2198", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-1051", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2315", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-6020", "mrqa_naturalquestions-validation-5049", "mrqa_naturalquestions-validation-7206", "mrqa_triviaqa-validation-5184", "mrqa_hotpotqa-validation-2820", "mrqa_hotpotqa-validation-5346", "mrqa_searchqa-validation-12477"], "SR": 0.5, "CSR": 0.5528590425531915, "retrieved_ids": ["mrqa_squad-train-73882", "mrqa_squad-train-63058", "mrqa_squad-train-82758", "mrqa_squad-train-42697", "mrqa_squad-train-42731", "mrqa_squad-train-55675", "mrqa_squad-train-80482", "mrqa_squad-train-45968", "mrqa_squad-train-23753", "mrqa_squad-train-76119", "mrqa_squad-train-67750", "mrqa_squad-train-22076", "mrqa_squad-train-28704", "mrqa_squad-train-30450", "mrqa_squad-train-83997", "mrqa_squad-train-31962", "mrqa_squad-train-12767", "mrqa_squad-train-23944", "mrqa_squad-train-61300", "mrqa_squad-train-63015", "mrqa_squad-train-32036", "mrqa_squad-train-64119", "mrqa_squad-train-75089", "mrqa_squad-train-77667", "mrqa_squad-train-26420", "mrqa_squad-train-19573", "mrqa_squad-train-36722", "mrqa_squad-train-14002", "mrqa_squad-train-25252", "mrqa_squad-train-19027", "mrqa_squad-train-57441", "mrqa_squad-train-28509", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-3863", "mrqa_searchqa-validation-1085", "mrqa_hotpotqa-validation-667", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-8161", "mrqa_triviaqa-validation-111", "mrqa_newsqa-validation-1563", "mrqa_newsqa-validation-1194", "mrqa_triviaqa-validation-3394", "mrqa_triviaqa-validation-7160", "mrqa_newsqa-validation-3299", "mrqa_newsqa-validation-3167", "mrqa_hotpotqa-validation-4791", "mrqa_triviaqa-validation-6277", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-158", "mrqa_naturalquestions-validation-9032", "mrqa_newsqa-validation-2976", "mrqa_searchqa-validation-5915", "mrqa_searchqa-validation-946", "mrqa_squad-validation-1441", "mrqa_triviaqa-validation-69", "mrqa_squad-validation-4911", "mrqa_newsqa-validation-3554", "mrqa_hotpotqa-validation-4450", "mrqa_triviaqa-validation-170", "mrqa_newsqa-validation-3488", "mrqa_triviaqa-validation-3715", "mrqa_newsqa-validation-2296", "mrqa_newsqa-validation-1641"], "EFR": 0.96875, "Overall": 0.7261968085106383}, {"timecode": 47, "before_eval_results": {"predictions": ["\"Itsy Bitsy Teeny Weeny Yellow Polka Dot Bikini.\"", "Body Works", "\"a striking blow to due process and the rule of law.\"", "make the new truck safer,", "200", "Alexey Pajitnov,", "1959.", "a lightning strike", "Harrison Ford", "at least 18 federal agents and two soldiers", "$17,000", "\"The oceans are kind of the last frontier for use and development,\"", "Animal Planet", "Caster Semenya", "a mammoth", "$3 billion,", "Ireland", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "more than 100.", "had been waterboarded for \" about 30 seconds, 35 seconds\" and agreed to cooperate with interrogators", "Bishop", "hardship for terminally ill patients and their caregivers,", "100 percent", "near Garacad, Somalia,", "Portuguese water dog", "Long Island", "arrested, arraigned and jailed,", "Damon Bankston", "Authorities", "clogs", "\"The Rough Guide to Climate Change\"", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "Ventures", "the same amount of electricity", "Deputy Treasury Secretary", "an Italian and six Africans", "supply vessel Damon Bankston", "warning about tendon problems.", "London and Buenos Aires", "eradication of the Zetas cartel", "get out of the game,", "\"We essentially closed the wheelhouse doors. I went to the port side, and I looked out up at the derrick. That's when I see the mud coming out of the top of the Derrick,\"", "art fair,", "former Procol Harum bandmate Gary Brooker", "No 4,", "Tuesday", "she's in love,", "Miguel Cotto", "Zac Efron", "a bird strike disabled its engines", "269,000", "rear - view mirror", "an edited version of a film ( or television episode, music video, commercial, or video game )", "the National Football League", "Turkey", "czarevitch", "auk", "Portland, OR", "1993 to 1996", "Minette Walters", "Tom Sennett", "Frank", "a photoelectric cell", "March 23, 2018"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5781012084320908}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.13333333333333333, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.0, 0.19047619047619047, 1.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615383, 0.4, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-452", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-4165", "mrqa_newsqa-validation-1511", "mrqa_newsqa-validation-1227", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2477", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-145", "mrqa_newsqa-validation-3806", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1791", "mrqa_newsqa-validation-2209", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1688", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-551", "mrqa_newsqa-validation-2089", "mrqa_newsqa-validation-2053", "mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-3217", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-2625", "mrqa_searchqa-validation-12326", "mrqa_searchqa-validation-13582", "mrqa_searchqa-validation-5955"], "SR": 0.484375, "CSR": 0.5514322916666667, "retrieved_ids": ["mrqa_squad-train-82458", "mrqa_squad-train-42628", "mrqa_squad-train-23945", "mrqa_squad-train-70458", "mrqa_squad-train-56487", "mrqa_squad-train-49769", "mrqa_squad-train-4495", "mrqa_squad-train-35852", "mrqa_squad-train-62395", "mrqa_squad-train-52061", "mrqa_squad-train-86406", "mrqa_squad-train-71565", "mrqa_squad-train-74099", "mrqa_squad-train-23124", "mrqa_squad-train-3460", "mrqa_squad-train-81054", "mrqa_squad-train-16821", "mrqa_squad-train-27396", "mrqa_squad-train-53515", "mrqa_squad-train-45609", "mrqa_squad-train-6983", "mrqa_squad-train-85276", "mrqa_squad-train-27728", "mrqa_squad-train-58840", "mrqa_squad-train-34718", "mrqa_squad-train-10670", "mrqa_squad-train-15214", "mrqa_squad-train-7957", "mrqa_squad-train-80810", "mrqa_squad-train-15029", "mrqa_squad-train-73815", "mrqa_squad-train-76687", "mrqa_newsqa-validation-1041", "mrqa_naturalquestions-validation-387", "mrqa_squad-validation-6809", "mrqa_naturalquestions-validation-754", "mrqa_triviaqa-validation-1993", "mrqa_squad-validation-9528", "mrqa_searchqa-validation-6880", "mrqa_newsqa-validation-1138", "mrqa_squad-validation-707", "mrqa_newsqa-validation-3350", "mrqa_searchqa-validation-1162", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-4130", "mrqa_searchqa-validation-7603", "mrqa_triviaqa-validation-5592", "mrqa_searchqa-validation-9506", "mrqa_searchqa-validation-9725", "mrqa_searchqa-validation-14601", "mrqa_newsqa-validation-232", "mrqa_newsqa-validation-2684", "mrqa_searchqa-validation-12340", "mrqa_newsqa-validation-3860", "mrqa_naturalquestions-validation-1731", "mrqa_searchqa-validation-11102", "mrqa_searchqa-validation-16710", "mrqa_squad-validation-1849", "mrqa_searchqa-validation-33", "mrqa_naturalquestions-validation-916", "mrqa_newsqa-validation-3203", "mrqa_triviaqa-validation-7160", "mrqa_newsqa-validation-367"], "EFR": 0.9696969696969697, "Overall": 0.7261008522727274}, {"timecode": 48, "before_eval_results": {"predictions": ["racial intolerance.", "North Korea intends to launch a long-range missile in the near future,", "Lindsey Vonn", "Salt Lake City, Utah,", "Lana Clarkson", "Wake Forest,", "The 27-year-old American has made a name for himself singing enka,", "The city,", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "the L'Aquila earthquake,", "a judge to order the pop star's estate to pay him a monthly allowance,", "Lashkar-e-Jhangvi, was planning to conduct attacks in Karachi,", "Peppermint oil, soluble fiber, and antispasmodic drugs", "crashing his private plane into a Florida swamp.", "David Beckham", "Aryan Airlines Flight 1625", "pizza,", "Kris Allen,", "death", "4-1 Serie A", "Haitians", "suppress the memories and to live as normal a life as possible;", "1981,", "Colombia's", "Bill Gates", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "Bob Bogle", "the FDA is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "Iran test-launched a rocket capable of carrying a satellite,", "$279", "his brother to surrender.", "helping to plan the September 11, 2001,", "F-14 fighter pilot", "Kit of Elsinore", "it really like to be a new member of the world's most powerful legislature?", "New York City", "NATO fighters", "Michelle Obama", "In the last four weeks, authorities arrested three men with suicide vests who were plotting to carry out the attacks,", "$250,000", "WBO welterweight title from Miguel Cotto", "Courtney Love,", "Chinese President Hu Jintao", "Bahrain", "54", "Anil Kapoor", "murder", "African National Congress", "walk", "Carl", "maintain an \"aesthetic environment\" and ensure public safety,", "Iowa ( 36.6 % )", "season seven", "BeBe Winans", "Pickwick", "Claire Goose", "Bangladesh", "four", "nursery rhyme", "Edward R. Murrow", "injecton", "Rabbi Small", "Cheers", "Coleman Hawkins"], "metric_results": {"EM": 0.5, "QA-F1": 0.6454422668190083}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.7058823529411764, 1.0, 0.2, 0.7368421052631579, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.0, 1.0, 0.0, 1.0, 1.0, 0.10526315789473684, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-903", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-98", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-1911", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2041", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-1806", "mrqa_newsqa-validation-3784", "mrqa_newsqa-validation-349", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1536", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-3517", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-4107", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-4079", "mrqa_triviaqa-validation-6309", "mrqa_hotpotqa-validation-5346", "mrqa_searchqa-validation-12017", "mrqa_searchqa-validation-11020", "mrqa_hotpotqa-validation-864"], "SR": 0.5, "CSR": 0.5503826530612245, "retrieved_ids": ["mrqa_squad-train-41797", "mrqa_squad-train-30395", "mrqa_squad-train-27161", "mrqa_squad-train-17379", "mrqa_squad-train-74228", "mrqa_squad-train-50273", "mrqa_squad-train-56948", "mrqa_squad-train-49269", "mrqa_squad-train-33001", "mrqa_squad-train-18424", "mrqa_squad-train-6757", "mrqa_squad-train-36532", "mrqa_squad-train-49965", "mrqa_squad-train-33487", "mrqa_squad-train-12396", "mrqa_squad-train-74792", "mrqa_squad-train-72701", "mrqa_squad-train-22787", "mrqa_squad-train-22884", "mrqa_squad-train-60079", "mrqa_squad-train-84315", "mrqa_squad-train-5547", "mrqa_squad-train-83697", "mrqa_squad-train-38035", "mrqa_squad-train-37656", "mrqa_squad-train-21078", "mrqa_squad-train-5559", "mrqa_squad-train-72636", "mrqa_squad-train-48210", "mrqa_squad-train-52739", "mrqa_squad-train-16679", "mrqa_squad-train-1328", "mrqa_searchqa-validation-5857", "mrqa_searchqa-validation-16625", "mrqa_newsqa-validation-848", "mrqa_triviaqa-validation-6277", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5180", "mrqa_searchqa-validation-2912", "mrqa_naturalquestions-validation-8441", "mrqa_searchqa-validation-15099", "mrqa_searchqa-validation-409", "mrqa_naturalquestions-validation-5928", "mrqa_newsqa-validation-1436", "mrqa_triviaqa-validation-6199", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-2614", "mrqa_squad-validation-8864", "mrqa_triviaqa-validation-7777", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-937", "mrqa_squad-validation-664", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-3796", "mrqa_squad-validation-2564", "mrqa_searchqa-validation-6975", "mrqa_naturalquestions-validation-7358", "mrqa_newsqa-validation-1799", "mrqa_triviaqa-validation-2251", "mrqa_naturalquestions-validation-1802", "mrqa_triviaqa-validation-3820", "mrqa_naturalquestions-validation-5034", "mrqa_triviaqa-validation-1459", "mrqa_newsqa-validation-946"], "EFR": 0.96875, "Overall": 0.725701530612245}, {"timecode": 49, "before_eval_results": {"predictions": ["a delegation of American Muslim and Christian leaders", "\"an Afghan patriot\" who \"has sacrificed his life for the sake of Afghanistan and for the peace of our country.", "35,000.", "curfew in Jaipur", "Martin Luther King Jr.", "Four", "its nude beaches.", "The Falklands,", "Pyongyang and Seoul", "the IV cafe.", "Africa", "Haiti", "the world's poorest children.", "a lump in Henry's nether regions was a cancerous tumor.", "\"The station was getting continuing inquiries, and Brett thought it would be best if he resigned,\"", "\"It was a wrong thing to say, something that we both acknowledge,\"", "racially-tinged remark made by his former caddy,", "David McKenzie", "\"If we're going to revise our policies here, we need to make it so for all the camps,\"", "Daniel Radcliffe", "\"The Da Vinci Code,\"", "exotic sports cars", "the secrets of Freemasonry", "al Qaeda,", "Polis", "the state's first lady,", "\"I think if I had known that she was gay, I wouldn't have been brave enough to talk to her,\"", "Bob Bogle,", "$8.8 million", "attacks", "$60 million", "4,000 credit cards and the company's \"private client\" list,", "95.", "At least 33", "Carrousel du Louvre.", "dozens", "bartering", "Austin Wuennenberg,", "he believed he was about to be attacked himself.", "\"momentous discovery\"", "Bob Bogle,", "Mitt Romney", "a plaque", "Wednesday,", "15-year-old's", "almost 100 vessels", "Matthew Fisher,", "the southern city of Naples", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "Saturday", "Both women", "Andy Serkis", "in the very late 1980s", "the end of January in Davos", "Malm\u00f6", "Richard Attenborough", "an eclipse", "Roman \u00e0 clef", "London", "Oklahoma", "Kevin Nealon", "Protestant", "Tammy Wynette", "Joseph Sherrard Kearns"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7094895249766573}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, false, false, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.08333333333333333, 1.0, 0.5, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.11764705882352941, 0.625, 0.4444444444444445, 1.0, 0.09523809523809523, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.37499999999999994, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-283", "mrqa_newsqa-validation-1616", "mrqa_newsqa-validation-1308", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3953", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1466", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3662", "mrqa_newsqa-validation-3022", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-2082", "mrqa_newsqa-validation-2370", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2919", "mrqa_searchqa-validation-1891"], "SR": 0.609375, "CSR": 0.5515625, "retrieved_ids": ["mrqa_squad-train-23752", "mrqa_squad-train-80517", "mrqa_squad-train-43883", "mrqa_squad-train-8577", "mrqa_squad-train-30074", "mrqa_squad-train-28194", "mrqa_squad-train-43804", "mrqa_squad-train-42200", "mrqa_squad-train-81795", "mrqa_squad-train-587", "mrqa_squad-train-54889", "mrqa_squad-train-14842", "mrqa_squad-train-22790", "mrqa_squad-train-38140", "mrqa_squad-train-65492", "mrqa_squad-train-43429", "mrqa_squad-train-64231", "mrqa_squad-train-36980", "mrqa_squad-train-23495", "mrqa_squad-train-70512", "mrqa_squad-train-53996", "mrqa_squad-train-7726", "mrqa_squad-train-72746", "mrqa_squad-train-69431", "mrqa_squad-train-45525", "mrqa_squad-train-24553", "mrqa_squad-train-47473", "mrqa_squad-train-74442", "mrqa_squad-train-33029", "mrqa_squad-train-3422", "mrqa_squad-train-18572", "mrqa_squad-train-83948", "mrqa_squad-validation-5911", "mrqa_searchqa-validation-6638", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-2541", "mrqa_hotpotqa-validation-2237", "mrqa_searchqa-validation-6011", "mrqa_squad-validation-3699", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-252", "mrqa_hotpotqa-validation-5199", "mrqa_searchqa-validation-6962", "mrqa_squad-validation-7574", "mrqa_newsqa-validation-1382", "mrqa_triviaqa-validation-6827", "mrqa_naturalquestions-validation-3898", "mrqa_newsqa-validation-609", "mrqa_naturalquestions-validation-4193", "mrqa_squad-validation-7473", "mrqa_newsqa-validation-1227", "mrqa_triviaqa-validation-2302", "mrqa_searchqa-validation-5457", "mrqa_triviaqa-validation-7334", "mrqa_newsqa-validation-3300", "mrqa_naturalquestions-validation-7206", "mrqa_newsqa-validation-1989", "mrqa_triviaqa-validation-1993", "mrqa_newsqa-validation-893", "mrqa_newsqa-validation-2249", "mrqa_newsqa-validation-3159", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-469", "mrqa_newsqa-validation-3488"], "EFR": 0.96, "Overall": 0.7241875}, {"timecode": 50, "UKR": 0.7890625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-1791", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-2820", "mrqa_hotpotqa-validation-2861", "mrqa_hotpotqa-validation-2949", "mrqa_hotpotqa-validation-3142", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-3358", "mrqa_hotpotqa-validation-3902", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4030", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-4478", "mrqa_hotpotqa-validation-5181", "mrqa_hotpotqa-validation-5323", "mrqa_hotpotqa-validation-5707", "mrqa_hotpotqa-validation-86", "mrqa_hotpotqa-validation-864", "mrqa_hotpotqa-validation-92", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-10060", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10369", "mrqa_naturalquestions-validation-10448", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-154", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-2629", "mrqa_naturalquestions-validation-3232", "mrqa_naturalquestions-validation-333", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-3555", "mrqa_naturalquestions-validation-3593", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-4037", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-4338", "mrqa_naturalquestions-validation-454", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-4729", "mrqa_naturalquestions-validation-477", "mrqa_naturalquestions-validation-4869", "mrqa_naturalquestions-validation-5002", "mrqa_naturalquestions-validation-5425", "mrqa_naturalquestions-validation-5483", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6206", "mrqa_naturalquestions-validation-6382", "mrqa_naturalquestions-validation-6442", "mrqa_naturalquestions-validation-6451", "mrqa_naturalquestions-validation-6555", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-9660", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-9953", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1056", "mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-1087", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1177", "mrqa_newsqa-validation-1287", "mrqa_newsqa-validation-1309", "mrqa_newsqa-validation-1310", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-142", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-1430", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1501", "mrqa_newsqa-validation-1660", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1680", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1706", "mrqa_newsqa-validation-1709", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1799", "mrqa_newsqa-validation-1812", "mrqa_newsqa-validation-1815", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-1930", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1966", "mrqa_newsqa-validation-1968", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2038", "mrqa_newsqa-validation-2050", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-2089", "mrqa_newsqa-validation-2106", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2133", "mrqa_newsqa-validation-2143", "mrqa_newsqa-validation-2164", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-2296", "mrqa_newsqa-validation-231", "mrqa_newsqa-validation-2338", "mrqa_newsqa-validation-2357", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2417", "mrqa_newsqa-validation-2428", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2438", "mrqa_newsqa-validation-2465", "mrqa_newsqa-validation-2477", "mrqa_newsqa-validation-2481", "mrqa_newsqa-validation-2485", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-2562", "mrqa_newsqa-validation-257", "mrqa_newsqa-validation-2578", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2656", "mrqa_newsqa-validation-2680", "mrqa_newsqa-validation-2690", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-2753", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2808", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2865", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-2875", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2953", "mrqa_newsqa-validation-2992", "mrqa_newsqa-validation-3024", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-3134", "mrqa_newsqa-validation-3156", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3159", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-3190", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-3218", "mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-324", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3259", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-3299", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3370", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3488", "mrqa_newsqa-validation-3499", "mrqa_newsqa-validation-3499", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-3591", "mrqa_newsqa-validation-3601", "mrqa_newsqa-validation-3602", "mrqa_newsqa-validation-3614", "mrqa_newsqa-validation-3688", "mrqa_newsqa-validation-3688", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-3704", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3722", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3827", "mrqa_newsqa-validation-3849", "mrqa_newsqa-validation-3876", "mrqa_newsqa-validation-3885", "mrqa_newsqa-validation-3886", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-4", "mrqa_newsqa-validation-4038", "mrqa_newsqa-validation-4063", "mrqa_newsqa-validation-407", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-4119", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4178", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-448", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-510", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-555", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-570", "mrqa_newsqa-validation-578", "mrqa_newsqa-validation-625", "mrqa_newsqa-validation-627", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-706", "mrqa_newsqa-validation-737", "mrqa_newsqa-validation-785", "mrqa_newsqa-validation-796", "mrqa_newsqa-validation-861", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-885", "mrqa_newsqa-validation-893", "mrqa_newsqa-validation-898", "mrqa_newsqa-validation-917", "mrqa_newsqa-validation-92", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-960", "mrqa_newsqa-validation-987", "mrqa_searchqa-validation-100", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-10045", "mrqa_searchqa-validation-10193", "mrqa_searchqa-validation-10233", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10790", "mrqa_searchqa-validation-1085", "mrqa_searchqa-validation-11002", "mrqa_searchqa-validation-11050", "mrqa_searchqa-validation-11102", "mrqa_searchqa-validation-11375", "mrqa_searchqa-validation-11450", "mrqa_searchqa-validation-11466", "mrqa_searchqa-validation-11495", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-12117", "mrqa_searchqa-validation-12313", "mrqa_searchqa-validation-12317", "mrqa_searchqa-validation-12326", "mrqa_searchqa-validation-12357", "mrqa_searchqa-validation-12409", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13028", "mrqa_searchqa-validation-13326", "mrqa_searchqa-validation-13434", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-13556", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-13951", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14346", "mrqa_searchqa-validation-14398", "mrqa_searchqa-validation-14405", "mrqa_searchqa-validation-15158", "mrqa_searchqa-validation-15412", "mrqa_searchqa-validation-15749", "mrqa_searchqa-validation-16053", "mrqa_searchqa-validation-16282", "mrqa_searchqa-validation-16605", "mrqa_searchqa-validation-16886", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-16913", "mrqa_searchqa-validation-1791", "mrqa_searchqa-validation-2175", "mrqa_searchqa-validation-2260", "mrqa_searchqa-validation-2394", "mrqa_searchqa-validation-2462", "mrqa_searchqa-validation-248", "mrqa_searchqa-validation-2508", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-2963", "mrqa_searchqa-validation-3398", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3540", "mrqa_searchqa-validation-3554", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-409", "mrqa_searchqa-validation-409", "mrqa_searchqa-validation-4142", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-4972", "mrqa_searchqa-validation-4978", "mrqa_searchqa-validation-5757", "mrqa_searchqa-validation-5970", "mrqa_searchqa-validation-6372", "mrqa_searchqa-validation-6420", "mrqa_searchqa-validation-6796", "mrqa_searchqa-validation-689", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-7019", "mrqa_searchqa-validation-7022", "mrqa_searchqa-validation-7132", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-7418", "mrqa_searchqa-validation-8368", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8776", "mrqa_searchqa-validation-9109", "mrqa_searchqa-validation-9399", "mrqa_searchqa-validation-9687", "mrqa_searchqa-validation-9725", "mrqa_searchqa-validation-9943", "mrqa_squad-validation-10494", "mrqa_squad-validation-1055", "mrqa_squad-validation-1213", "mrqa_squad-validation-1268", "mrqa_squad-validation-1384", "mrqa_squad-validation-1490", "mrqa_squad-validation-1529", "mrqa_squad-validation-1615", "mrqa_squad-validation-167", "mrqa_squad-validation-1725", "mrqa_squad-validation-1742", "mrqa_squad-validation-1849", "mrqa_squad-validation-1891", "mrqa_squad-validation-1941", "mrqa_squad-validation-204", "mrqa_squad-validation-2095", "mrqa_squad-validation-2283", "mrqa_squad-validation-2387", "mrqa_squad-validation-2613", "mrqa_squad-validation-2857", "mrqa_squad-validation-2865", "mrqa_squad-validation-2938", "mrqa_squad-validation-3040", "mrqa_squad-validation-3317", "mrqa_squad-validation-3456", "mrqa_squad-validation-3493", "mrqa_squad-validation-3790", "mrqa_squad-validation-3941", "mrqa_squad-validation-3954", "mrqa_squad-validation-4241", "mrqa_squad-validation-4402", "mrqa_squad-validation-4452", "mrqa_squad-validation-457", "mrqa_squad-validation-4633", "mrqa_squad-validation-4764", "mrqa_squad-validation-477", "mrqa_squad-validation-4841", "mrqa_squad-validation-4933", "mrqa_squad-validation-5029", "mrqa_squad-validation-5185", "mrqa_squad-validation-5222", "mrqa_squad-validation-5311", "mrqa_squad-validation-543", "mrqa_squad-validation-5470", "mrqa_squad-validation-5479", "mrqa_squad-validation-57", "mrqa_squad-validation-5804", "mrqa_squad-validation-5961", "mrqa_squad-validation-6121", "mrqa_squad-validation-6147", "mrqa_squad-validation-6241", "mrqa_squad-validation-6470", "mrqa_squad-validation-6548", "mrqa_squad-validation-664", "mrqa_squad-validation-6792", "mrqa_squad-validation-6869", "mrqa_squad-validation-693", "mrqa_squad-validation-694", "mrqa_squad-validation-7022", "mrqa_squad-validation-7064", "mrqa_squad-validation-719", "mrqa_squad-validation-7338", "mrqa_squad-validation-7443", "mrqa_squad-validation-7494", "mrqa_squad-validation-7546", "mrqa_squad-validation-7733", "mrqa_squad-validation-7747", "mrqa_squad-validation-7908", "mrqa_squad-validation-7918", "mrqa_squad-validation-7951", "mrqa_squad-validation-7964", "mrqa_squad-validation-809", "mrqa_squad-validation-8115", "mrqa_squad-validation-8204", "mrqa_squad-validation-8204", "mrqa_squad-validation-8216", "mrqa_squad-validation-8412", "mrqa_squad-validation-8495", "mrqa_squad-validation-8551", "mrqa_squad-validation-8558", "mrqa_squad-validation-8683", "mrqa_squad-validation-8923", "mrqa_squad-validation-9087", "mrqa_squad-validation-9178", "mrqa_squad-validation-9227", "mrqa_squad-validation-9528", "mrqa_squad-validation-9581", "mrqa_squad-validation-9775", "mrqa_squad-validation-9910", "mrqa_squad-validation-9944", "mrqa_squad-validation-997", "mrqa_squad-validation-9993", "mrqa_squad-validation-9996", "mrqa_triviaqa-validation-115", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-1972", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2250", "mrqa_triviaqa-validation-2541", "mrqa_triviaqa-validation-2676", "mrqa_triviaqa-validation-3097", "mrqa_triviaqa-validation-3232", "mrqa_triviaqa-validation-3423", "mrqa_triviaqa-validation-3450", "mrqa_triviaqa-validation-354", "mrqa_triviaqa-validation-3547", "mrqa_triviaqa-validation-3562", "mrqa_triviaqa-validation-3699", "mrqa_triviaqa-validation-381", "mrqa_triviaqa-validation-3815", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-3931", "mrqa_triviaqa-validation-4336", "mrqa_triviaqa-validation-4442", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-4493", "mrqa_triviaqa-validation-4580", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5659", "mrqa_triviaqa-validation-5771", "mrqa_triviaqa-validation-6001", "mrqa_triviaqa-validation-6050", "mrqa_triviaqa-validation-6277", "mrqa_triviaqa-validation-6282", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-6649", "mrqa_triviaqa-validation-6930", "mrqa_triviaqa-validation-6939", "mrqa_triviaqa-validation-7474", "mrqa_triviaqa-validation-7627", "mrqa_triviaqa-validation-7672", "mrqa_triviaqa-validation-795"], "OKR": 0.908203125, "KG": 0.490625, "before_eval_results": {"predictions": ["Palestinian-Israeli issue", "Fareed Zakaria.", "11", "July 1999,", "the actor who created one of British television's most surreal thrillers,", "Haiti.", "May 4", "Baghdad.", "11", "Shanghai", "\"Den of Spies\"", "\"It appears that there was a struggle between the victim and the suspect in the threshold of the hotel room immediately prior to the shooting,\"", "Cash for Clunkers", "19-year-old", "This will be the second", "Islamabad for a 10-day retreat,", "March 8", "arson", "off-duty federal agents in southwestern Mexico,", "celebrity", "CEO of an engineering and construction company", "Sunni Arab and Shiite tribal leaders", "the Little Rock Nine,", "U.S. Holocaust Memorial Museum", "The Human Rights Watch organization", "10 municipal police officers", "massive popularity of Indian film beyond its homeland have made stars like Kumar hot property.", "12", "Arabic, French and English,", "40", "Johannesburg", "L'Aquila", "\" Body Works\"", "North Korea,", "at least 27", "racially-tinged remark made by his former caddy,", "Amsterdam,", "burned over 65 percent of his body after being set on fire,", "45 minutes, five days a week.", "the 45-year-old future president", "Madonna", "shoot down the object whether it is a missile or a satellite.", "posting a $1,725 bail,", "Bill", "more than 78,000 parents", "Apple Inc.", "London's", "\"fusion teams,\"", "martial arts,", "Dr. Jennifer Arnold and husband Bill Klein,", "Operation Crank Call,\"", "Moulmein", "Assam Provincial Congress Committee was formed with its headquarters at Guwahati and Kuladhar Chaliha as its president", "Prior to and through the early Christian centuries, winter festivals -- especially those centered on the winter solstice -- were the most popular of the year in many European pagan cultures", "Frenchman", "sheep", "daisy", "1853", "musicologist", "1902", "Folly", "\"Twelfth Night\"", "trenchcoat", "Iden Versio, leader of an Imperial Special Forces group known as Inferno Squad"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6181355392292892}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.18181818181818182, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.9743589743589743, 1.0, 1.0, 0.4, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.1111111111111111, 0.14814814814814814, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2947", "mrqa_newsqa-validation-2059", "mrqa_newsqa-validation-93", "mrqa_newsqa-validation-200", "mrqa_newsqa-validation-2495", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-839", "mrqa_newsqa-validation-2642", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-2821", "mrqa_newsqa-validation-971", "mrqa_newsqa-validation-3711", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-880", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2813", "mrqa_newsqa-validation-2103", "mrqa_newsqa-validation-3346", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-3194", "mrqa_naturalquestions-validation-2735", "mrqa_naturalquestions-validation-3688", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-7329", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-2863", "mrqa_searchqa-validation-14319", "mrqa_searchqa-validation-16778"], "SR": 0.515625, "CSR": 0.5508578431372548, "retrieved_ids": ["mrqa_squad-train-23701", "mrqa_squad-train-43826", "mrqa_squad-train-589", "mrqa_squad-train-1035", "mrqa_squad-train-24759", "mrqa_squad-train-37549", "mrqa_squad-train-17322", "mrqa_squad-train-1345", "mrqa_squad-train-54626", "mrqa_squad-train-3103", "mrqa_squad-train-50375", "mrqa_squad-train-75090", "mrqa_squad-train-84342", "mrqa_squad-train-41848", "mrqa_squad-train-18795", "mrqa_squad-train-60394", "mrqa_squad-train-52209", "mrqa_squad-train-34626", "mrqa_squad-train-67658", "mrqa_squad-train-79268", "mrqa_squad-train-53697", "mrqa_squad-train-56801", "mrqa_squad-train-61030", "mrqa_squad-train-5349", "mrqa_squad-train-33992", "mrqa_squad-train-3343", "mrqa_squad-train-45837", "mrqa_squad-train-59563", "mrqa_squad-train-40628", "mrqa_squad-train-11762", "mrqa_squad-train-17386", "mrqa_squad-train-57688", "mrqa_newsqa-validation-3529", "mrqa_searchqa-validation-6992", "mrqa_newsqa-validation-1021", "mrqa_naturalquestions-validation-7352", "mrqa_squad-validation-2346", "mrqa_searchqa-validation-5456", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-3987", "mrqa_newsqa-validation-3932", "mrqa_squad-validation-2919", "mrqa_newsqa-validation-792", "mrqa_newsqa-validation-2934", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-6363", "mrqa_newsqa-validation-743", "mrqa_naturalquestions-validation-960", "mrqa_triviaqa-validation-4457", "mrqa_searchqa-validation-2029", "mrqa_squad-validation-1640", "mrqa_squad-validation-8294", "mrqa_searchqa-validation-16816", "mrqa_newsqa-validation-2179", "mrqa_naturalquestions-validation-1026", "mrqa_newsqa-validation-2392", "mrqa_naturalquestions-validation-4338", "mrqa_hotpotqa-validation-2876", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-983", "mrqa_searchqa-validation-13142", "mrqa_triviaqa-validation-1622"], "EFR": 0.967741935483871, "Overall": 0.7412980807242252}, {"timecode": 51, "before_eval_results": {"predictions": ["Kenyan and Somali", "\"disagreements\" with the Port Authority of New York and New Jersey,", "Auckland,", "film a public-television show.", "at least nine", "Kgalema Motlanthe,", "mental health and recovery.", "1.2 million", "Arizona", "Kenyan and Somali", "The meter reader", "Diego Maradona", "London", "Oregon State Senior troopers David Petersen after he was able to catch up with six exotic sports cars on a stretch of Highway 18 near Grand Ronde on Thursday,", "in rural Tennessee.", "Fakih", "as", "14", "Former Mobile County Circuit Judge Herman Thomas denies all the charges,", "18", "Abdullah Gul,", "April 13,", "Washington Redskins fan and loved to travel,", "Kindle Fire", "Amado Carrillo Fuentes,\"", "Dolgorsuren Dagvadorj,", "they would not be making any further comments, citing the investigation.", "41,", "Anil Kapoor", "two years,", "cell phones.", "forgery and flying without a valid license,", "Larry Ellison,", "digging", "Wednesday.", "the pirates", "the estate", "Isabella", "March 22,", "Hamas,", "3,000 kilometers (1,900 miles),", "September 21.", "cell phones", "a U.S. helicopter crashed in northeastern Baghdad as", "served in the military,", "air support.", "the L'Aquila earthquake,", "11th year in a row.", "200", "Seminole", "morphine sulfate oral solution 20 mg/ml.", "16.5 quadrillion BTUs of primary energy to electric power plants in 2013, which made up nearly 92 % of coal's contribution to energy supply", "Charlton Heston", "administrative supervision", "Sigurd the Dragonslayer", "a Landsturm", "Monopoly", "in New York City", "Kentucky, Virginia, and Tennessee", "1999", "beans", "Mountain Dew", "Whopper", "Japan"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7221033476459235}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.4615384615384615, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19354838709677416, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.23076923076923078, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1379", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-3314", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-1339", "mrqa_newsqa-validation-1025", "mrqa_newsqa-validation-3004", "mrqa_newsqa-validation-631", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-5512", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-1613", "mrqa_hotpotqa-validation-2623"], "SR": 0.640625, "CSR": 0.5525841346153846, "retrieved_ids": ["mrqa_squad-train-42587", "mrqa_squad-train-40132", "mrqa_squad-train-12269", "mrqa_squad-train-68606", "mrqa_squad-train-37098", "mrqa_squad-train-41377", "mrqa_squad-train-8383", "mrqa_squad-train-57073", "mrqa_squad-train-3255", "mrqa_squad-train-37160", "mrqa_squad-train-36065", "mrqa_squad-train-36948", "mrqa_squad-train-4602", "mrqa_squad-train-27647", "mrqa_squad-train-77743", "mrqa_squad-train-35699", "mrqa_squad-train-75135", "mrqa_squad-train-75289", "mrqa_squad-train-16864", "mrqa_squad-train-19452", "mrqa_squad-train-77444", "mrqa_squad-train-3067", "mrqa_squad-train-67108", "mrqa_squad-train-81353", "mrqa_squad-train-67861", "mrqa_squad-train-80681", "mrqa_squad-train-53861", "mrqa_squad-train-55297", "mrqa_squad-train-72848", "mrqa_squad-train-24898", "mrqa_squad-train-78157", "mrqa_squad-train-69574", "mrqa_newsqa-validation-3069", "mrqa_squad-validation-2318", "mrqa_triviaqa-validation-7029", "mrqa_newsqa-validation-1210", "mrqa_newsqa-validation-2413", "mrqa_naturalquestions-validation-7262", "mrqa_searchqa-validation-11020", "mrqa_squad-validation-4452", "mrqa_squad-validation-1841", "mrqa_triviaqa-validation-2022", "mrqa_naturalquestions-validation-6234", "mrqa_squad-validation-8749", "mrqa_triviaqa-validation-7426", "mrqa_squad-validation-490", "mrqa_newsqa-validation-3098", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-2399", "mrqa_naturalquestions-validation-4124", "mrqa_searchqa-validation-8752", "mrqa_squad-validation-664", "mrqa_searchqa-validation-16886", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-1065", "mrqa_searchqa-validation-7418", "mrqa_newsqa-validation-3614", "mrqa_newsqa-validation-4028", "mrqa_naturalquestions-validation-866", "mrqa_naturalquestions-validation-9421", "mrqa_newsqa-validation-3608", "mrqa_hotpotqa-validation-2820", "mrqa_triviaqa-validation-2856", "mrqa_newsqa-validation-421"], "EFR": 1.0, "Overall": 0.748094951923077}, {"timecode": 52, "before_eval_results": {"predictions": ["1.2 million", "Ben Roethlisberger", "death", "St. Louis, Missouri.", "Honduran President Jose Manuel Zelaya", "mother.", "education", "$55.7 million", "\"To my fellow Americans who have loved ones over here, who know what it's like to miss them,", "U.S. security coordinator", "Ashley \"A.J.\" Jewell,", "The Angels said the two dead at the scene were the female driver of the Mitsubishi and another male.", "Department of Homeland Security Secretary Janet Napolitano", "Too many glass shards left by beer drinkers in the city center,", "any abuse that occurred in his diocese.", "Manchester City", "planned attacks", "\"falling space debris,\"", "Michael Schumacher", "Sen. Barack Obama", "Rolling Stone", "Alfredo Astiz,", "\"We don't see at this point any indication of an individual out in the neighborhoods committing additional crimes or homicides,", "Kingman Regional Medical Center,", "bronze medal", "Long Island", "5,600", "Pew Research Center held favorable views of America,", "Sharon Bialek", "The chairs are made by prisoners at the South Dakota State Penitentiary and ultimately delivered in Iraq", "two", "\"We get a signal prior to violence,\"", "Muslim", "certain pieces of evidence presented by prosecutors were prejudicial and had the effect of denying al-Moayad and Zayed a fair trial.", "Kevin Evans", "near the Somali coast to use extreme caution because of the recent pirate attacks.", "Consumer Reports magazine", "2008,", "killing rampage.", "\"Twilight\" book series.", "trading goods and services without exchanging money", "not guilty", "Dennis Davern,", "Joe Pantoliano,", "The sailboat matching the description of the missing 38-foot boat was found overturned about 5:15 p.m. Saturday,", "relatives of the five suspects,", "Trevor Rees-Jones,", "Dubai", "June 6, 1944,", "the surge,", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "a female given name, the Latin transliteration of the Greek name Berenice, \u0392\u03b5\u03c1\u03b5\u03bd\u03af\u03ba\u03b7.", "the sex organs, such as ovaries, fallopian tubes, uterus, vulva, vagina, testes, vas deferens, seminal vesicles, prostate and penis", "Mace Coronel", "Rebecca Adlington", "Buckinghamshire", "10.", "Consigliere", "2007", "The entity", "The Suite Life of gunned & Cody", "a 1992 American erotic thriller", "launch one ship", "northern latitudes"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5723669733044733}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.23999999999999996, 0.4444444444444445, 1.0, 0.16666666666666666, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.4444444444444445, 1.0, 1.0, 0.5454545454545454, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.1, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.13333333333333336, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2520", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-3157", "mrqa_newsqa-validation-3187", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-4154", "mrqa_newsqa-validation-1206", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-3873", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-3830", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-490", "mrqa_newsqa-validation-1176", "mrqa_newsqa-validation-815", "mrqa_newsqa-validation-4075", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-181", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-2960", "mrqa_newsqa-validation-161", "mrqa_newsqa-validation-3052", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-5499", "mrqa_triviaqa-validation-7151", "mrqa_triviaqa-validation-2481", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-118", "mrqa_searchqa-validation-15800", "mrqa_searchqa-validation-9831", "mrqa_naturalquestions-validation-6214"], "SR": 0.46875, "CSR": 0.5510023584905661, "retrieved_ids": ["mrqa_squad-train-21121", "mrqa_squad-train-28103", "mrqa_squad-train-6590", "mrqa_squad-train-53540", "mrqa_squad-train-72332", "mrqa_squad-train-48066", "mrqa_squad-train-77207", "mrqa_squad-train-53609", "mrqa_squad-train-81392", "mrqa_squad-train-21589", "mrqa_squad-train-23502", "mrqa_squad-train-37006", "mrqa_squad-train-58267", "mrqa_squad-train-59120", "mrqa_squad-train-80283", "mrqa_squad-train-43007", "mrqa_squad-train-67102", "mrqa_squad-train-4845", "mrqa_squad-train-69967", "mrqa_squad-train-57278", "mrqa_squad-train-84119", "mrqa_squad-train-13769", "mrqa_squad-train-41500", "mrqa_squad-train-51672", "mrqa_squad-train-75786", "mrqa_squad-train-65414", "mrqa_squad-train-58795", "mrqa_squad-train-5770", "mrqa_squad-train-39401", "mrqa_squad-train-79695", "mrqa_squad-train-49128", "mrqa_squad-train-76173", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-1630", "mrqa_searchqa-validation-11102", "mrqa_triviaqa-validation-6608", "mrqa_searchqa-validation-1784", "mrqa_newsqa-validation-3473", "mrqa_squad-validation-3119", "mrqa_hotpotqa-validation-2919", "mrqa_searchqa-validation-13347", "mrqa_searchqa-validation-1317", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4771", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-6285", "mrqa_searchqa-validation-12974", "mrqa_newsqa-validation-158", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-7067", "mrqa_newsqa-validation-249", "mrqa_searchqa-validation-11053", "mrqa_triviaqa-validation-7777", "mrqa_newsqa-validation-792", "mrqa_newsqa-validation-3114", "mrqa_newsqa-validation-1076", "mrqa_searchqa-validation-14319", "mrqa_naturalquestions-validation-6289", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-469", "mrqa_naturalquestions-validation-6363", "mrqa_hotpotqa-validation-4689", "mrqa_naturalquestions-validation-5640", "mrqa_searchqa-validation-8582"], "EFR": 1.0, "Overall": 0.7477785966981132}, {"timecode": 53, "before_eval_results": {"predictions": ["a \"happy ending\" to the case.", "Lance Cpl. Maria Lauterbach", "throwing three punches", "Argentine", "Ferraris, a Lamborghini and an Acura NSX", "died in a fire pit January 11 in Marine Cpl. Cesar Laurean's backyard.", "1983", "the simple puzzle video game,", "\"Dancing With the Stars.\"", "Time's", "across Greece", "morphine sulfate oral solution 20 mg/ml.", "Lance Cpl. Maria Lauterbach", "US Airways Flight 1549", "he failed to return home,", "Jiverly Wong,", "Ireland", "Gaslight Theater.", "punish participants in this week's bloody mutiny,", "Mildred", "Sunday's", "help nations trapped by hunger and extreme poverty,", "$10 billion", "prosecutors", "April 22.", "Mitt Romney", "twice.", "seeking help", "Mary Phagan,", "National Infrastructure Program,", "judge", "Herman Cain,", "60 euros", "$60 billion on America's infrastructure.", "Revolutionary Armed Forces of Colombia,", "Kurt Cobain's", "The BBC", "Islamabad", "the UK", "Roy", "give detainees greater latitude in selecting legal representation", "some one-liners", "Vernon Forrest,", "Tomas Olsson,", "1983.", "He reassured Muslims in America that \"We are a nation of Christians and Muslims, Jews and Hindus -- and nonbelievers.\"", "Sunday", "a share in the royalties for the tune.", "drug cartels", "in a canyon in the path of the blaze Thursday.", "number of calls,", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "Anatomy", "seven", "professor of phonetics Henry Higgins", "footwear", "Herbert Lom,", "Battle of Prome", "Union Hill section", "Jean- Marc Vall\u00e9e", "Chance", "Pudge", "Tom Osborne", "Kwame Nkrumah"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7401106366459628}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6956521739130436, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2525", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-3469", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-1813", "mrqa_newsqa-validation-2517", "mrqa_newsqa-validation-3403", "mrqa_newsqa-validation-1816", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-3062", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-2151", "mrqa_newsqa-validation-3970", "mrqa_naturalquestions-validation-8374", "mrqa_naturalquestions-validation-9078", "mrqa_triviaqa-validation-7280", "mrqa_triviaqa-validation-6536", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-2323", "mrqa_searchqa-validation-11037"], "SR": 0.65625, "CSR": 0.5529513888888888, "retrieved_ids": ["mrqa_squad-train-52766", "mrqa_squad-train-50007", "mrqa_squad-train-78763", "mrqa_squad-train-38229", "mrqa_squad-train-60149", "mrqa_squad-train-3649", "mrqa_squad-train-63259", "mrqa_squad-train-30702", "mrqa_squad-train-18227", "mrqa_squad-train-60911", "mrqa_squad-train-21772", "mrqa_squad-train-41386", "mrqa_squad-train-21190", "mrqa_squad-train-68201", "mrqa_squad-train-55539", "mrqa_squad-train-61477", "mrqa_squad-train-41852", "mrqa_squad-train-64115", "mrqa_squad-train-22037", "mrqa_squad-train-56256", "mrqa_squad-train-28463", "mrqa_squad-train-11881", "mrqa_squad-train-76334", "mrqa_squad-train-46711", "mrqa_squad-train-47661", "mrqa_squad-train-13167", "mrqa_squad-train-51394", "mrqa_squad-train-64574", "mrqa_squad-train-80483", "mrqa_squad-train-31835", "mrqa_squad-train-1600", "mrqa_squad-train-50630", "mrqa_newsqa-validation-3713", "mrqa_searchqa-validation-12588", "mrqa_newsqa-validation-2897", "mrqa_squad-validation-4908", "mrqa_newsqa-validation-2495", "mrqa_squad-validation-6489", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-1911", "mrqa_newsqa-validation-1165", "mrqa_squad-validation-7051", "mrqa_newsqa-validation-2738", "mrqa_naturalquestions-validation-7003", "mrqa_naturalquestions-validation-486", "mrqa_newsqa-validation-1709", "mrqa_squad-validation-7514", "mrqa_triviaqa-validation-5592", "mrqa_newsqa-validation-2315", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-320", "mrqa_squad-validation-10274", "mrqa_hotpotqa-validation-3362", "mrqa_newsqa-validation-2735", "mrqa_newsqa-validation-878", "mrqa_naturalquestions-validation-5034", "mrqa_searchqa-validation-10105", "mrqa_searchqa-validation-11961", "mrqa_newsqa-validation-6", "mrqa_triviaqa-validation-86", "mrqa_naturalquestions-validation-9457", "mrqa_newsqa-validation-2854", "mrqa_naturalquestions-validation-7352"], "EFR": 1.0, "Overall": 0.7481684027777777}, {"timecode": 54, "before_eval_results": {"predictions": ["$249", "diabetes and hypertension,", "Europe's", "many different", "at least 27", "last week,", "Peruvian Supreme Court", "Joan Rivers", "\"Watchmen\"", "not just to the islands, but to any resources that could be found there.", "NATO", "Bangladesh", "as", "complicated man underneath a confident exterior,", "made 109", "reading a novel", "would slow economic growth with higher taxes.", "voluntary manslaughter", "dancing", "South Africa", "The noose incident", "the world's poorest children.", "propofol,", "Catholic church sex abuse scandal,", "head injury.", "500 feet down an embankment", "Marxist guerrillas", "World War I", "Rwanda", "UNHCR", "Jenny Sanford,", "African National Congress Deputy President Kgalema Motlanthe,", "6-2 6-1", "graduate from this school district.", "CNN", "Jobs", "pulling on the top-knot of an opponent,", "his comments", "Juan Martin Del Potro.", "Tehran,", "gasoline", "Thirty to 40 ships", "Las Vegas.", "former Vice President Dick Cheney,", "Tuesday", "Stuntman: Wayne Michaels", "The UNHCR recommended against granting asylum,", "Kenyan forces", "Michael Jackson", "planning processes are urgently needed", "Molotov cocktails, rocks and glass.", "2017", "October 2", "quartz or feldspar", "kursk", "squash", "Caroline Garcia", "Caesars Entertainment Corporation", "Premier League club", "London Review of Books", "Eudora Welty", "Richard Nixon", "sousaphone", "National Lottery"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6150412087912087}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.07692307692307693, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2695", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-1325", "mrqa_newsqa-validation-3672", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-2233", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-4170", "mrqa_naturalquestions-validation-2095", "mrqa_naturalquestions-validation-655", "mrqa_triviaqa-validation-5969", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-65", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-7251", "mrqa_hotpotqa-validation-5604"], "SR": 0.5625, "CSR": 0.553125, "retrieved_ids": ["mrqa_squad-train-61249", "mrqa_squad-train-4869", "mrqa_squad-train-41572", "mrqa_squad-train-34364", "mrqa_squad-train-74469", "mrqa_squad-train-83878", "mrqa_squad-train-64267", "mrqa_squad-train-30863", "mrqa_squad-train-23012", "mrqa_squad-train-47614", "mrqa_squad-train-34535", "mrqa_squad-train-3146", "mrqa_squad-train-46261", "mrqa_squad-train-8965", "mrqa_squad-train-19269", "mrqa_squad-train-2268", "mrqa_squad-train-66070", "mrqa_squad-train-56214", "mrqa_squad-train-45292", "mrqa_squad-train-77455", "mrqa_squad-train-12196", "mrqa_squad-train-41316", "mrqa_squad-train-60608", "mrqa_squad-train-79811", "mrqa_squad-train-74974", "mrqa_squad-train-47698", "mrqa_squad-train-85000", "mrqa_squad-train-7599", "mrqa_squad-train-15821", "mrqa_squad-train-5063", "mrqa_squad-train-72572", "mrqa_squad-train-55714", "mrqa_squad-validation-8046", "mrqa_triviaqa-validation-2363", "mrqa_searchqa-validation-3554", "mrqa_naturalquestions-validation-10255", "mrqa_newsqa-validation-538", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-2940", "mrqa_searchqa-validation-10359", "mrqa_squad-validation-9640", "mrqa_newsqa-validation-1162", "mrqa_naturalquestions-validation-1802", "mrqa_searchqa-validation-1212", "mrqa_naturalquestions-validation-7003", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-4338", "mrqa_newsqa-validation-3987", "mrqa_newsqa-validation-3120", "mrqa_hotpotqa-validation-5850", "mrqa_hotpotqa-validation-1681", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-1206", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-154", "mrqa_hotpotqa-validation-4441", "mrqa_triviaqa-validation-1772", "mrqa_newsqa-validation-3159", "mrqa_newsqa-validation-3791", "mrqa_hotpotqa-validation-2323", "mrqa_squad-validation-3165", "mrqa_newsqa-validation-1483", "mrqa_searchqa-validation-14601", "mrqa_naturalquestions-validation-8733"], "EFR": 0.9642857142857143, "Overall": 0.7410602678571429}, {"timecode": 55, "before_eval_results": {"predictions": ["a bond hearing Friday,", "without the", "Mexico", "Monica Majumdar", "five", "customers are lining up for vitamin injections that promise", "a thorough understanding of the dogs' needs,", "actor", "\"We want to reset our relationship and so we will do it together.'\"", "Cambodian territory", "general astonishment", "June 6, 1944,", "a lightning strike", "2", "Sen. Barack Obama", "money or other discreet aid", "people have chosen their rides based on what their", "Sri Lanka's Tamil rebels", "Pakistani territory", "Steve Williams", "200 human bodies at various life stages -- from conception to old age, including embryos and fetuses taken from historic anatomical collections.", "Elisabeth", "Nearly eight in 10", "saw it as a waste of time and money at a time when British forces are thinly-stretched, fighting in Iraq and Afghanistan.", "3rd District of Utah.", "Golfer Tiger Woods", "organizing the distribution of wheelchairs,", "shock, quickly followed by speculation about what was going to happen next,\"", "\"She was focused so much on learning that she didn't notice,\"", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "punish participants in this week's bloody mutiny,", "piracy", "Alaska or Hawaii.", "Robert Park", "Djibouti,", "\"There are about 100 different types of human papillomavirus,\"", "Six", "Bahrain", "delivers a big speech", "Facebook and Google,", "Sheikh Sharif Sheikh Ahmed", "2006,", "18th", "March 24,", "The father of Haleigh Cummings,", "a senior at Stetson University studying computer science.", "Saturday,", "NATO fighters", "\"Empire of the Sun,\"", "New Zealand", "Reusable Lessons", "Billy Ocean", "summer", "79", "neoclassic", "squeeze", "golf", "Montagues and Capulets", "Atlas ICBM", "Walt Disney World Resort in Lake Buena Vista, Florida", "1966", "mass", "spoiled", "Neville Chamberlain"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6206521343240092}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3846153846153846, 0.0, 1.0, 0.125, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-1478", "mrqa_newsqa-validation-2060", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2018", "mrqa_newsqa-validation-2906", "mrqa_newsqa-validation-1287", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-2809", "mrqa_newsqa-validation-1147", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-1053", "mrqa_newsqa-validation-3351", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-3767", "mrqa_newsqa-validation-2923", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-2418", "mrqa_naturalquestions-validation-10114", "mrqa_triviaqa-validation-3763", "mrqa_hotpotqa-validation-1350", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-7008", "mrqa_searchqa-validation-11933", "mrqa_triviaqa-validation-920"], "SR": 0.5625, "CSR": 0.5532924107142857, "retrieved_ids": ["mrqa_squad-train-40649", "mrqa_squad-train-21328", "mrqa_squad-train-25206", "mrqa_squad-train-13192", "mrqa_squad-train-85009", "mrqa_squad-train-53537", "mrqa_squad-train-34637", "mrqa_squad-train-64007", "mrqa_squad-train-22042", "mrqa_squad-train-7234", "mrqa_squad-train-1773", "mrqa_squad-train-16604", "mrqa_squad-train-70331", "mrqa_squad-train-30347", "mrqa_squad-train-65796", "mrqa_squad-train-49141", "mrqa_squad-train-76547", "mrqa_squad-train-18503", "mrqa_squad-train-36030", "mrqa_squad-train-67332", "mrqa_squad-train-66772", "mrqa_squad-train-41534", "mrqa_squad-train-86013", "mrqa_squad-train-53018", "mrqa_squad-train-26548", "mrqa_squad-train-9558", "mrqa_squad-train-76120", "mrqa_squad-train-45227", "mrqa_squad-train-16560", "mrqa_squad-train-6323", "mrqa_squad-train-41738", "mrqa_squad-train-33770", "mrqa_searchqa-validation-8094", "mrqa_naturalquestions-validation-2735", "mrqa_newsqa-validation-1911", "mrqa_triviaqa-validation-4760", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-990", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-2926", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-2690", "mrqa_searchqa-validation-5547", "mrqa_searchqa-validation-1212", "mrqa_naturalquestions-validation-997", "mrqa_searchqa-validation-5028", "mrqa_triviaqa-validation-5973", "mrqa_hotpotqa-validation-3362", "mrqa_naturalquestions-validation-875", "mrqa_newsqa-validation-4022", "mrqa_squad-validation-6390", "mrqa_hotpotqa-validation-4198", "mrqa_naturalquestions-validation-672", "mrqa_squad-validation-9145", "mrqa_newsqa-validation-3121", "mrqa_searchqa-validation-10233", "mrqa_triviaqa-validation-5659", "mrqa_naturalquestions-validation-8441", "mrqa_searchqa-validation-13657", "mrqa_triviaqa-validation-3547", "mrqa_searchqa-validation-5963", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3854", "mrqa_newsqa-validation-3703"], "EFR": 0.9285714285714286, "Overall": 0.7339508928571429}, {"timecode": 56, "before_eval_results": {"predictions": ["Tuesday", "Dr. Cade", "those traveling near the Somali coast", "\"To My Mother\"", "billboards with an image of the burning World Trade Center", "2.5 million", "almost 100", "137", "1,500", "Worry Free Dinners,", "Rod Blagojevich,", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "\"still trying to absorb the impact of this week's stunning events.\"", "terrorism.", "Trevor Rees,", "the most-wanted man in the world", "Carrousel du Louvre,", "three men with suicide vests who were plotting to carry out the attacks,", "don't have to visit laundromats because they enjoy the luxury of a free", "101", "Tim Masters,", "75 miles east of Yakima", "shows the world that you love the environment and hate using fuel,\"", "The apartment building collapsed together with two other buildings", "11", "Henrik Stenson", "CEO of an engineering and construction company", "Milan", "strife in Somalia,", "cancerous tumor.", "provided Syria and Iraq 500 cubic meters of water a second,", "Abdullah Gul,", "three empty vodka bottles,", "11th year in a row.", "children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans,", "Gov. Rod Blagojevich", "national telephone", "TSA", "the shootings,", "Ben Roethlisberger", "Larry Ellison,", "Newcastle", "228", "is a city of romance, of incredible architecture and history.", "gasoline", "Utah,", "Swansea Crown Court,", "Carol Browner", "the Dominican Republic", "militants", "Monday", "a Celtic people living in northern Asia Minor", "diastema", "to manage the characteristics of the beer's head", "cryonic suspension", "Cambridge", "Mercury", "13 October 1958", "Bassline", "Pansexuality, or omnisexuality", "the Invisible Man", "Zachary Taylor", "Battlestar Galactica", "Marilyn Monroe"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7221929493794819}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.2222222222222222, 0.9411764705882353, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.10526315789473685, 1.0, 0.4, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.5, 0.7692307692307692, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3086", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-860", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-1531", "mrqa_newsqa-validation-2446", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-387", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-3219", "mrqa_naturalquestions-validation-2990", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-6999", "mrqa_hotpotqa-validation-2826", "mrqa_hotpotqa-validation-3408"], "SR": 0.609375, "CSR": 0.5542763157894737, "retrieved_ids": ["mrqa_squad-train-23442", "mrqa_squad-train-53035", "mrqa_squad-train-17961", "mrqa_squad-train-69494", "mrqa_squad-train-64075", "mrqa_squad-train-73258", "mrqa_squad-train-3044", "mrqa_squad-train-65228", "mrqa_squad-train-58308", "mrqa_squad-train-15009", "mrqa_squad-train-53366", "mrqa_squad-train-78407", "mrqa_squad-train-30010", "mrqa_squad-train-69810", "mrqa_squad-train-74377", "mrqa_squad-train-51664", "mrqa_squad-train-48799", "mrqa_squad-train-63134", "mrqa_squad-train-4949", "mrqa_squad-train-10778", "mrqa_squad-train-11877", "mrqa_squad-train-25506", "mrqa_squad-train-62383", "mrqa_squad-train-50309", "mrqa_squad-train-40294", "mrqa_squad-train-15936", "mrqa_squad-train-49565", "mrqa_squad-train-1708", "mrqa_squad-train-54469", "mrqa_squad-train-69843", "mrqa_squad-train-25786", "mrqa_squad-train-71190", "mrqa_newsqa-validation-3054", "mrqa_naturalquestions-validation-754", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-1025", "mrqa_newsqa-validation-3097", "mrqa_hotpotqa-validation-2623", "mrqa_squad-validation-6489", "mrqa_triviaqa-validation-2413", "mrqa_triviaqa-validation-5698", "mrqa_newsqa-validation-394", "mrqa_naturalquestions-validation-1147", "mrqa_squad-validation-3119", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-5483", "mrqa_newsqa-validation-2680", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2133", "mrqa_triviaqa-validation-7329", "mrqa_searchqa-validation-7581", "mrqa_newsqa-validation-2960", "mrqa_naturalquestions-validation-226", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-16210", "mrqa_triviaqa-validation-3110", "mrqa_newsqa-validation-510", "mrqa_naturalquestions-validation-3427", "mrqa_squad-validation-2373", "mrqa_squad-validation-3543", "mrqa_squad-validation-9023", "mrqa_newsqa-validation-1193", "mrqa_triviaqa-validation-920", "mrqa_triviaqa-validation-3725"], "EFR": 0.96, "Overall": 0.7404333881578947}, {"timecode": 57, "before_eval_results": {"predictions": ["producing rock music with a country influence.", "African National Congress", "Expedia.", "Molotov cocktails, rocks and glass.", "Mad Men", "5,600", "the European Commission", "three", "using recreational drugs", "0-0 draw", "air support.", "Christopher Savoie", "American pop star's", "not speak", "\"Draquila", "al Qaeda,", "U.S. Chamber of Commerce", "physicist Steven Chu", "U.N. Security Council", "\" Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "actor", "\"We tortured (Mohammed al-) Qahtani,\"", "an empty water bottle down the touchline", "a U.S. helicopter crashed in northeastern Baghdad as", "children of street cleaners and firefighters.", "Marie-Therese Walter.", "acid attack", "Congress", "the southern city of Naples", "her most important work is her charity, the Happy Hearts Fund.", "The model set up the foundation after her near-death experience", "South Africa", "Somali", "returning combat veterans could be recruited by right-wing extremist groups.", "opposition supporters", "Michael Schumacher", "consumer confidence", "Golfer", "Longo-Ciprelli", "Fernando Caceres", "iPods", "a treadmill", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "RheinEnergieStadion.", "$40 and a bread.", "tennis", "No. 1 slot", "Jan Brewer.", "Boundary County, Idaho,", "securities", "$150 billion", "experimental", "Michael Crawford", "the beginning", "coconut shy", "Fenn Street School", "ear", "Australian", "Argentinian", "fibre optic cable", "rap", "inducere", "Harvard", "129,007"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7638020833333333}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, true, true, false, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.5833333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-950", "mrqa_newsqa-validation-3918", "mrqa_newsqa-validation-614", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-317", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-2824", "mrqa_newsqa-validation-536", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-3580", "mrqa_newsqa-validation-3677", "mrqa_naturalquestions-validation-4112", "mrqa_triviaqa-validation-2349", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-3729", "mrqa_searchqa-validation-1502", "mrqa_searchqa-validation-9174"], "SR": 0.703125, "CSR": 0.5568426724137931, "retrieved_ids": ["mrqa_squad-train-34884", "mrqa_squad-train-4490", "mrqa_squad-train-1975", "mrqa_squad-train-4009", "mrqa_squad-train-53509", "mrqa_squad-train-49774", "mrqa_squad-train-12639", "mrqa_squad-train-8885", "mrqa_squad-train-33681", "mrqa_squad-train-6079", "mrqa_squad-train-12028", "mrqa_squad-train-52095", "mrqa_squad-train-22574", "mrqa_squad-train-781", "mrqa_squad-train-26930", "mrqa_squad-train-11420", "mrqa_squad-train-29084", "mrqa_squad-train-60051", "mrqa_squad-train-30026", "mrqa_squad-train-12015", "mrqa_squad-train-4062", "mrqa_squad-train-18143", "mrqa_squad-train-64954", "mrqa_squad-train-84857", "mrqa_squad-train-34915", "mrqa_squad-train-27830", "mrqa_squad-train-4920", "mrqa_squad-train-74919", "mrqa_squad-train-3796", "mrqa_squad-train-11935", "mrqa_squad-train-45170", "mrqa_squad-train-52152", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-3817", "mrqa_newsqa-validation-1563", "mrqa_newsqa-validation-3990", "mrqa_triviaqa-validation-4742", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-4760", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-12477", "mrqa_naturalquestions-validation-5554", "mrqa_newsqa-validation-2897", "mrqa_searchqa-validation-8272", "mrqa_searchqa-validation-5522", "mrqa_newsqa-validation-3203", "mrqa_naturalquestions-validation-3677", "mrqa_searchqa-validation-14868", "mrqa_hotpotqa-validation-1952", "mrqa_newsqa-validation-609", "mrqa_searchqa-validation-5951", "mrqa_newsqa-validation-1904", "mrqa_hotpotqa-validation-4027", "mrqa_searchqa-validation-8097", "mrqa_newsqa-validation-1176", "mrqa_naturalquestions-validation-327", "mrqa_squad-validation-8927", "mrqa_triviaqa-validation-5592", "mrqa_newsqa-validation-160", "mrqa_newsqa-validation-1920", "mrqa_newsqa-validation-367", "mrqa_triviaqa-validation-3284", "mrqa_newsqa-validation-2338"], "EFR": 1.0, "Overall": 0.7489466594827586}, {"timecode": 58, "before_eval_results": {"predictions": ["African National Congress Deputy President Kgalema Motlanthe,", "Summer", "\"The missile defense system is not aimed at Russia,\"", "Six", "sitting in Renaissance-era clothes and holding a book.", "\u00a320 million ($41.1 million) fortune", "40 militants and six Pakistan soldiers", "5 season", "Arthur E. Morgan III,", "Jason Chaffetz", "\"a very thorough, 78-page decision by the district court\"", "Casey Anthony,", "The Ski Train", "bronze medal in the women's figure skating final,", "No 4, the highest ever position", "People Against Switching Sides (PASS)", "\"If they are not secure, I don't have a great deal of confidence that the rest of our critical infrastructure on the electric grid is secure,\"", "\"A chicken soaked in the rain,\"", "President Obama.", "Jacob Zuma,", "1937,", "help rebuild the nation's highways, bridges and other public-use facilities.", "18", "the Southeast,", "\"Up,\"", "a way of getting into that Lexus, Lincoln, Infiniti or Porsche you always wanted, without laying out $70,000 or $80,000 for something you're not actually going to live in.", "fascinating transformation that takes place when carving a pumpkin.", "school,", "a motor scooter", "safer surroundings.", "$50 less,", "J.Crew", "$106.5 million", "Nearly eight in 10", "credit card", "he was one of 10 gunmen who attacked several targets in Mumbai", "Akio Toyoda", "in July", "changed the business of music,", "a \"black box\" label warning", "NATO to do more to stop the Afghan opium trade", "Cancer awareness", "Virgin America", "to humiliate herself by standing next to a story,\"", "It's so weird. There's two different versions. There're my version of how it went about, and there's the producer's", "Kenyan and Somali governments", "opium trade", "83", "a man had been stoned to death by an angry mob.", "Africa", "the most-wanted man in the world", "left - sided heart failure", "4.09", "Devastator", "Madness", "Jelly Roll Morton", "vice-admiral", "George Mikan", "Kait Parker", "Centre-du-Qu\u00e9bec", "Nguyen", "doughboy", "United We Stand", "professor siegfried Trebitsch"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6974439775910365}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false], "QA-F1": [0.4444444444444445, 1.0, 0.4, 1.0, 0.9333333333333333, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.11111111111111112, 0.4, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.9444444444444444, 0.8571428571428571, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333]}}, "before_error_ids": ["mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-2534", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-3636", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-2740", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-2965", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-900", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-3374", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-505", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6523", "mrqa_hotpotqa-validation-2803", "mrqa_searchqa-validation-3774", "mrqa_triviaqa-validation-7280"], "SR": 0.546875, "CSR": 0.5566737288135593, "retrieved_ids": ["mrqa_squad-train-23206", "mrqa_squad-train-65877", "mrqa_squad-train-14973", "mrqa_squad-train-22370", "mrqa_squad-train-84", "mrqa_squad-train-39364", "mrqa_squad-train-72578", "mrqa_squad-train-68063", "mrqa_squad-train-56478", "mrqa_squad-train-70616", "mrqa_squad-train-30255", "mrqa_squad-train-29313", "mrqa_squad-train-3075", "mrqa_squad-train-32707", "mrqa_squad-train-45323", "mrqa_squad-train-30398", "mrqa_squad-train-43021", "mrqa_squad-train-47353", "mrqa_squad-train-68469", "mrqa_squad-train-80677", "mrqa_squad-train-30070", "mrqa_squad-train-1708", "mrqa_squad-train-38437", "mrqa_squad-train-3222", "mrqa_squad-train-42625", "mrqa_squad-train-14902", "mrqa_squad-train-1681", "mrqa_squad-train-31621", "mrqa_squad-train-44949", "mrqa_squad-train-65015", "mrqa_squad-train-38629", "mrqa_squad-train-16053", "mrqa_triviaqa-validation-5573", "mrqa_newsqa-validation-1016", "mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-8119", "mrqa_squad-validation-8864", "mrqa_newsqa-validation-1138", "mrqa_triviaqa-validation-170", "mrqa_naturalquestions-validation-3553", "mrqa_searchqa-validation-3222", "mrqa_naturalquestions-validation-2990", "mrqa_triviaqa-validation-3284", "mrqa_hotpotqa-validation-4323", "mrqa_squad-validation-3165", "mrqa_newsqa-validation-98", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-1660", "mrqa_squad-validation-4528", "mrqa_searchqa-validation-13142", "mrqa_triviaqa-validation-6608", "mrqa_newsqa-validation-2563", "mrqa_triviaqa-validation-5969", "mrqa_squad-validation-8400", "mrqa_newsqa-validation-1305", "mrqa_searchqa-validation-14198", "mrqa_triviaqa-validation-1916", "mrqa_newsqa-validation-388", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1225", "mrqa_searchqa-validation-10823", "mrqa_newsqa-validation-4003", "mrqa_naturalquestions-validation-8095"], "EFR": 0.8620689655172413, "Overall": 0.7213266638661602}, {"timecode": 59, "before_eval_results": {"predictions": ["his business dealings for possible securities violations", "1913,", "$40 and a loaf of bread.", "14-day", "U Win Tin,", "543", "Knox's parents, Curt Knox and Edda Mellas,", "11 healthy eggs", "four", "64,", "The mammoth's fossil", "at least two and a half hours.", "shark River Park in Monmouth County", "take on greenhouse gas emissions.", "a gift to the Obama girls from Sen. Ted Kennedy.", "\"I miss your beautiful face and voice,\"", "More than 15,000", "\"Teen Patti\" (\"Card Game\")", "Muslim countries,", "Piers Morgan Tonight", "Illness", "Basel", "She wasn't the best \"coach,\" and she was kind of picky, but she had such a good eye,", "Strategic Arms Reduction Treaty", "sumo wrestling", "10 below", "The escalating conflict in Mogadishu is having a devastating impact on the city's population causing enormous suffering and massive displacement,\"", "recall", "Roy", "VBS.TV", "Dr. Albert Reiter,", "Marxist guerrillas", "Greeley, Colorado,", "five", "NATO's International Security Assistance Force", "Jacob Zuma,", "Muslim and a Coptic family", "toxic smoke from burn pits", "Fullerton, California,", "an unprecedented wave of buying amid the elections.", "34", "3,000", "Workers'", "helicopters and unmanned aerial vehicles", "dual nationality", "\"We get a lot of people coming and going,\"", "the Muslim north of Sudan", "at least 18 federal agents and two soldiers", "Bahrain", "33", "Kenneth Cole", "the Devastator", "Indonesia", "Theodore Roosevelt", "vice-admiral", "the Boston Braves", "jockey", "Greek-American", "feats of exploration", "his uncle Juan Nepomuceno Guerra", "Monarch", "Yale", "Kansas City", "Briton Allan McNish"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6675595238095238}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, false], "QA-F1": [0.6, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.5000000000000001, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.3, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-742", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-2743", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-3012", "mrqa_newsqa-validation-2355", "mrqa_newsqa-validation-1120", "mrqa_newsqa-validation-1077", "mrqa_newsqa-validation-3164", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1693", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2817", "mrqa_naturalquestions-validation-5620", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-4241", "mrqa_searchqa-validation-156", "mrqa_hotpotqa-validation-2473"], "SR": 0.59375, "CSR": 0.5572916666666667, "retrieved_ids": ["mrqa_squad-train-83681", "mrqa_squad-train-83365", "mrqa_squad-train-16439", "mrqa_squad-train-64742", "mrqa_squad-train-31199", "mrqa_squad-train-51821", "mrqa_squad-train-46931", "mrqa_squad-train-26135", "mrqa_squad-train-42263", "mrqa_squad-train-11112", "mrqa_squad-train-20979", "mrqa_squad-train-83391", "mrqa_squad-train-43119", "mrqa_squad-train-11657", "mrqa_squad-train-23681", "mrqa_squad-train-51547", "mrqa_squad-train-24947", "mrqa_squad-train-71918", "mrqa_squad-train-50851", "mrqa_squad-train-26163", "mrqa_squad-train-73946", "mrqa_squad-train-23440", "mrqa_squad-train-21329", "mrqa_squad-train-59493", "mrqa_squad-train-745", "mrqa_squad-train-55635", "mrqa_squad-train-23751", "mrqa_squad-train-28155", "mrqa_squad-train-60090", "mrqa_squad-train-12547", "mrqa_squad-train-59951", "mrqa_squad-train-41798", "mrqa_squad-validation-6791", "mrqa_searchqa-validation-9116", "mrqa_newsqa-validation-2471", "mrqa_triviaqa-validation-4028", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-1417", "mrqa_squad-validation-8400", "mrqa_triviaqa-validation-7151", "mrqa_searchqa-validation-15608", "mrqa_newsqa-validation-3088", "mrqa_triviaqa-validation-3763", "mrqa_naturalquestions-validation-519", "mrqa_searchqa-validation-2651", "mrqa_naturalquestions-validation-226", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-10531", "mrqa_squad-validation-9533", "mrqa_naturalquestions-validation-2782", "mrqa_squad-validation-5525", "mrqa_searchqa-validation-4697", "mrqa_squad-validation-2513", "mrqa_newsqa-validation-160", "mrqa_searchqa-validation-10318", "mrqa_naturalquestions-validation-6234", "mrqa_newsqa-validation-1758", "mrqa_newsqa-validation-3641", "mrqa_naturalquestions-validation-114", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-108", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-4075"], "EFR": 1.0, "Overall": 0.7490364583333334}, {"timecode": 60, "UKR": 0.787109375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1756", "mrqa_hotpotqa-validation-1791", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-2820", "mrqa_hotpotqa-validation-2861", "mrqa_hotpotqa-validation-2863", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-3358", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-3902", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4030", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-4799", "mrqa_hotpotqa-validation-92", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-10060", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-10255", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10369", "mrqa_naturalquestions-validation-10526", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-154", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-2629", "mrqa_naturalquestions-validation-3232", "mrqa_naturalquestions-validation-3381", "mrqa_naturalquestions-validation-3555", "mrqa_naturalquestions-validation-3593", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-4037", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-454", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-4729", "mrqa_naturalquestions-validation-477", "mrqa_naturalquestions-validation-4869", "mrqa_naturalquestions-validation-5002", "mrqa_naturalquestions-validation-5425", "mrqa_naturalquestions-validation-5483", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-5865", "mrqa_naturalquestions-validation-6206", "mrqa_naturalquestions-validation-6382", "mrqa_naturalquestions-validation-6442", "mrqa_naturalquestions-validation-6451", "mrqa_naturalquestions-validation-6555", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-875", "mrqa_naturalquestions-validation-8787", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-935", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-9953", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1040", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1056", "mrqa_newsqa-validation-1069", "mrqa_newsqa-validation-1087", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1167", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1176", "mrqa_newsqa-validation-1177", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-1309", "mrqa_newsqa-validation-1339", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1379", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-142", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-1430", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-145", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1501", "mrqa_newsqa-validation-1501", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-153", "mrqa_newsqa-validation-1536", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1619", "mrqa_newsqa-validation-1660", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1680", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1706", "mrqa_newsqa-validation-1709", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1799", "mrqa_newsqa-validation-1812", "mrqa_newsqa-validation-1815", "mrqa_newsqa-validation-1816", "mrqa_newsqa-validation-183", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1895", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-1902", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-1935", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1966", "mrqa_newsqa-validation-1968", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-1984", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2018", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2038", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-2089", "mrqa_newsqa-validation-2106", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2143", "mrqa_newsqa-validation-2164", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2284", "mrqa_newsqa-validation-2296", "mrqa_newsqa-validation-230", "mrqa_newsqa-validation-231", "mrqa_newsqa-validation-2310", "mrqa_newsqa-validation-2338", "mrqa_newsqa-validation-2357", "mrqa_newsqa-validation-2388", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-2403", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2429", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2438", "mrqa_newsqa-validation-2465", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-2481", "mrqa_newsqa-validation-2485", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2502", "mrqa_newsqa-validation-2520", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-2562", "mrqa_newsqa-validation-257", "mrqa_newsqa-validation-2578", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2584", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2656", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2680", "mrqa_newsqa-validation-269", "mrqa_newsqa-validation-2695", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-2743", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-2753", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2808", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-2842", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2865", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-2909", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2992", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-3134", "mrqa_newsqa-validation-3156", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-3192", "mrqa_newsqa-validation-3194", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3218", "mrqa_newsqa-validation-324", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3259", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-3299", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-3346", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3360", "mrqa_newsqa-validation-3370", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-343", "mrqa_newsqa-validation-3436", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3488", "mrqa_newsqa-validation-3499", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-3614", "mrqa_newsqa-validation-3633", "mrqa_newsqa-validation-3688", "mrqa_newsqa-validation-3688", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-3704", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3722", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3823", "mrqa_newsqa-validation-3827", "mrqa_newsqa-validation-3849", "mrqa_newsqa-validation-3876", "mrqa_newsqa-validation-3885", "mrqa_newsqa-validation-3886", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3927", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-4", "mrqa_newsqa-validation-4038", "mrqa_newsqa-validation-4063", "mrqa_newsqa-validation-407", "mrqa_newsqa-validation-4078", "mrqa_newsqa-validation-4088", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-4119", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4178", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-448", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-460", "mrqa_newsqa-validation-490", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-510", "mrqa_newsqa-validation-543", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-570", "mrqa_newsqa-validation-578", "mrqa_newsqa-validation-625", "mrqa_newsqa-validation-627", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-631", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-706", "mrqa_newsqa-validation-737", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-772", "mrqa_newsqa-validation-785", "mrqa_newsqa-validation-861", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-885", "mrqa_newsqa-validation-893", "mrqa_newsqa-validation-898", "mrqa_newsqa-validation-917", "mrqa_newsqa-validation-92", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-960", "mrqa_newsqa-validation-979", "mrqa_newsqa-validation-987", "mrqa_searchqa-validation-100", "mrqa_searchqa-validation-10017", "mrqa_searchqa-validation-10045", "mrqa_searchqa-validation-10193", "mrqa_searchqa-validation-10233", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10790", "mrqa_searchqa-validation-1085", "mrqa_searchqa-validation-11002", "mrqa_searchqa-validation-11050", "mrqa_searchqa-validation-11375", "mrqa_searchqa-validation-11466", "mrqa_searchqa-validation-11770", "mrqa_searchqa-validation-12117", "mrqa_searchqa-validation-12313", "mrqa_searchqa-validation-12326", "mrqa_searchqa-validation-12409", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13326", "mrqa_searchqa-validation-13434", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-13556", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-13951", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14346", "mrqa_searchqa-validation-14398", "mrqa_searchqa-validation-14405", "mrqa_searchqa-validation-15158", "mrqa_searchqa-validation-15412", "mrqa_searchqa-validation-15749", "mrqa_searchqa-validation-16053", "mrqa_searchqa-validation-16282", "mrqa_searchqa-validation-16605", "mrqa_searchqa-validation-16886", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-16913", "mrqa_searchqa-validation-1791", "mrqa_searchqa-validation-2260", "mrqa_searchqa-validation-2462", "mrqa_searchqa-validation-248", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-2963", "mrqa_searchqa-validation-3398", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3540", "mrqa_searchqa-validation-3554", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-4142", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-4972", "mrqa_searchqa-validation-4978", "mrqa_searchqa-validation-5970", "mrqa_searchqa-validation-6297", "mrqa_searchqa-validation-6372", "mrqa_searchqa-validation-6420", "mrqa_searchqa-validation-6796", "mrqa_searchqa-validation-689", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-7019", "mrqa_searchqa-validation-7022", "mrqa_searchqa-validation-7132", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-7418", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8776", "mrqa_searchqa-validation-9109", "mrqa_searchqa-validation-9399", "mrqa_searchqa-validation-9687", "mrqa_searchqa-validation-9725", "mrqa_squad-validation-10494", "mrqa_squad-validation-1055", "mrqa_squad-validation-1268", "mrqa_squad-validation-1384", "mrqa_squad-validation-1490", "mrqa_squad-validation-1529", "mrqa_squad-validation-1615", "mrqa_squad-validation-167", "mrqa_squad-validation-1742", "mrqa_squad-validation-1941", "mrqa_squad-validation-204", "mrqa_squad-validation-2095", "mrqa_squad-validation-2283", "mrqa_squad-validation-2387", "mrqa_squad-validation-2613", "mrqa_squad-validation-2857", "mrqa_squad-validation-2865", "mrqa_squad-validation-3040", "mrqa_squad-validation-3317", "mrqa_squad-validation-3456", "mrqa_squad-validation-3493", "mrqa_squad-validation-3790", "mrqa_squad-validation-3941", "mrqa_squad-validation-3954", "mrqa_squad-validation-4241", "mrqa_squad-validation-4402", "mrqa_squad-validation-4452", "mrqa_squad-validation-457", "mrqa_squad-validation-4633", "mrqa_squad-validation-4764", "mrqa_squad-validation-477", "mrqa_squad-validation-4841", "mrqa_squad-validation-4933", "mrqa_squad-validation-5029", "mrqa_squad-validation-5185", "mrqa_squad-validation-5222", "mrqa_squad-validation-5311", "mrqa_squad-validation-543", "mrqa_squad-validation-5479", "mrqa_squad-validation-57", "mrqa_squad-validation-5804", "mrqa_squad-validation-5961", "mrqa_squad-validation-6121", "mrqa_squad-validation-6147", "mrqa_squad-validation-6241", "mrqa_squad-validation-6470", "mrqa_squad-validation-664", "mrqa_squad-validation-6792", "mrqa_squad-validation-6869", "mrqa_squad-validation-694", "mrqa_squad-validation-7022", "mrqa_squad-validation-7064", "mrqa_squad-validation-7338", "mrqa_squad-validation-7443", "mrqa_squad-validation-7494", "mrqa_squad-validation-7546", "mrqa_squad-validation-7733", "mrqa_squad-validation-7747", "mrqa_squad-validation-7908", "mrqa_squad-validation-7918", "mrqa_squad-validation-7964", "mrqa_squad-validation-809", "mrqa_squad-validation-8115", "mrqa_squad-validation-8204", "mrqa_squad-validation-8204", "mrqa_squad-validation-8216", "mrqa_squad-validation-8412", "mrqa_squad-validation-8495", "mrqa_squad-validation-8551", "mrqa_squad-validation-8558", "mrqa_squad-validation-8923", "mrqa_squad-validation-9087", "mrqa_squad-validation-9178", "mrqa_squad-validation-9227", "mrqa_squad-validation-9581", "mrqa_squad-validation-9775", "mrqa_squad-validation-9910", "mrqa_squad-validation-9944", "mrqa_squad-validation-9993", "mrqa_squad-validation-9996", "mrqa_triviaqa-validation-115", "mrqa_triviaqa-validation-1363", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-1839", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2291", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2541", "mrqa_triviaqa-validation-2676", "mrqa_triviaqa-validation-3097", "mrqa_triviaqa-validation-3423", "mrqa_triviaqa-validation-3450", "mrqa_triviaqa-validation-354", "mrqa_triviaqa-validation-3547", "mrqa_triviaqa-validation-3562", "mrqa_triviaqa-validation-381", "mrqa_triviaqa-validation-3815", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-3931", "mrqa_triviaqa-validation-4442", "mrqa_triviaqa-validation-4493", "mrqa_triviaqa-validation-4580", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-6001", "mrqa_triviaqa-validation-6050", "mrqa_triviaqa-validation-6282", "mrqa_triviaqa-validation-6287", "mrqa_triviaqa-validation-6309", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-6649", "mrqa_triviaqa-validation-6930", "mrqa_triviaqa-validation-6939", "mrqa_triviaqa-validation-7280", "mrqa_triviaqa-validation-7474", "mrqa_triviaqa-validation-7627", "mrqa_triviaqa-validation-7672", "mrqa_triviaqa-validation-795"], "OKR": 0.888671875, "KG": 0.49765625, "before_eval_results": {"predictions": ["183", "Ed McMahon,", "fastest circumnavigation of the globe in a powerboat", "the Airbus A330-200 encountered heavy turbulence about 02:15 a.m. local time Monday", "Paul McCartney and Ringo Starr", "ballots", "transit bombings", "2000.", "Martin \"Al\" Culhane,", "normal maritime", "\"It feels great to be back at work,\"", "Iran's", "was found Sunday on an island stronghold of the Islamic militant group Abu Sayyaf,", "Sixteen former Argentine military officers", "Obama", "both Russian residents and worldwide viewers,", "34", "five victims by helicopter, one who died, two in critical condition and two in serious condition.", "Herman Cain,", "\"She was focused so much on learning that she didn't notice,\"", "South African police have opened a criminal investigation into allegations that a dorm parent mistreated students at the school.", "Vertikal-T,", "to comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "Michael Brewer,", "Sunday's", "don't have to visit laundromats because they enjoy the luxury of a free", "death squad killings", "Ozzy Osbourne", "it is not just $3 billion of new money into the economy.", "\"Steamboat Bill, Jr.\"", "Omar Bongo,", "he wants a \"happy ending\" to the case.", "Obama and McCain camps", "Africa", "Fayetteville, North Carolina,", "the only goal of the game", "French", "Honduran water workers", "U.S. security coordinator", "North Korea intends to launch a long-range missile in the near future,", "Nasser Medical Institute in Cairo,", "1991-1993,", "to a civil disturbance call,", "images of the small girl being sexually assaulted.", "Iran's parliament speaker", "Deputy Treasury Secretary", "Operation Pipeline Express.", "Islamabad", "Williams' body", "Kris Allen,", "sections of the roof", "Lalo Schifrin", "April 17, 1982", "Billy Idol", "mental disorders", "secretary of state for education", "every ten years", "five months", "The Dragon", "1994", "Magnolia", "1st", "Jupiter", "mural"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6534448549534757}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, false, false, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13793103448275862, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.2, 0.4, 0.4, 0.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-3404", "mrqa_newsqa-validation-1538", "mrqa_newsqa-validation-2828", "mrqa_newsqa-validation-4121", "mrqa_newsqa-validation-3034", "mrqa_newsqa-validation-3799", "mrqa_newsqa-validation-1468", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-3438", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-2515", "mrqa_newsqa-validation-2141", "mrqa_newsqa-validation-297", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-1711", "mrqa_newsqa-validation-239", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-2768", "mrqa_triviaqa-validation-7704", "mrqa_triviaqa-validation-5502", "mrqa_searchqa-validation-16357"], "SR": 0.578125, "CSR": 0.5576331967213115, "retrieved_ids": ["mrqa_squad-train-53516", "mrqa_squad-train-64630", "mrqa_squad-train-81840", "mrqa_squad-train-53162", "mrqa_squad-train-47278", "mrqa_squad-train-32816", "mrqa_squad-train-46205", "mrqa_squad-train-26133", "mrqa_squad-train-76747", "mrqa_squad-train-21925", "mrqa_squad-train-60178", "mrqa_squad-train-9907", "mrqa_squad-train-15585", "mrqa_squad-train-67250", "mrqa_squad-train-29966", "mrqa_squad-train-38795", "mrqa_squad-train-6281", "mrqa_squad-train-64641", "mrqa_squad-train-15097", "mrqa_squad-train-62611", "mrqa_squad-train-45804", "mrqa_squad-train-49430", "mrqa_squad-train-6945", "mrqa_squad-train-49376", "mrqa_squad-train-18593", "mrqa_squad-train-53391", "mrqa_squad-train-3809", "mrqa_squad-train-59698", "mrqa_squad-train-35366", "mrqa_squad-train-30159", "mrqa_squad-train-35397", "mrqa_squad-train-64185", "mrqa_hotpotqa-validation-5850", "mrqa_searchqa-validation-14720", "mrqa_newsqa-validation-3565", "mrqa_naturalquestions-validation-2951", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-860", "mrqa_hotpotqa-validation-985", "mrqa_newsqa-validation-3861", "mrqa_newsqa-validation-4183", "mrqa_naturalquestions-validation-6523", "mrqa_newsqa-validation-3863", "mrqa_newsqa-validation-3784", "mrqa_triviaqa-validation-6066", "mrqa_newsqa-validation-1844", "mrqa_triviaqa-validation-4493", "mrqa_squad-validation-8412", "mrqa_searchqa-validation-5783", "mrqa_newsqa-validation-416", "mrqa_searchqa-validation-2912", "mrqa_hotpotqa-validation-550", "mrqa_newsqa-validation-1301", "mrqa_squad-validation-8046", "mrqa_newsqa-validation-2789", "mrqa_triviaqa-validation-6295", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-3370", "mrqa_searchqa-validation-6011", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-3351", "mrqa_searchqa-validation-3259", "mrqa_naturalquestions-validation-4097", "mrqa_newsqa-validation-2780"], "EFR": 0.9629629629629629, "Overall": 0.7388067319368549}, {"timecode": 61, "before_eval_results": {"predictions": ["re-impose order", "South Dakota State Penitentiary", "$8.8 million", "Friday,", "11th year in a row.", "Russian concerns that the defensive shield could be used for offensive aims.", "Victor Mejia Munera was a drug lord with ties to paramilitary groups,", "a baseball bat", "six", "a book.", "Venezuela", "Kerstin", "$1.45 billion", "Iranian consulate,", "VoteWoz.com", "Janet Napolitano", "Malawi", "Daniel Radcliffe", "the attacks that started in April 1994,", "\"Raiders of the Lost Ark.\"", "Explosives are set off in the Missouri River", "\"The Sopranos,\"", "artificial intelligence.", "sculptures", "Shanghai mayor", "the foyer of the BBC building in Glasgow, Scotland", "\"Lean, Clean and Local\"", "engineering and construction", "\"Drug trafficking is a transnational threat, and therefore national initiatives have their limitations,\"", "ties", "\"procedure on her heart,\"", "civilians,", "66th annual Golden Globe Awards", "9:20 p.m. ET Wednesday.", "tallest building,", "\"Zed,\" a Columbian mammoth", "Spc. Megan Lynn Touma,", "1979", "three out of four questioned say that things are going well for them personally.", "The island's dining scene", "fascinating transformation that takes place when carving a pumpkin.", "prisoners", "Intensifying", "More than 15,000", "Princess Diana", "\"Zed,\" a Columbian mammoth", "he \"remained at the bottom of the hill surviving on leaves and water from a nearby creek,\"", "businesses hiring veterans as well as job training for all service members leaving the military.", "The port won't be back for a while. Roads have been split apart and buckled, fences have fallen over.", "the UK", "bipartisan", "tomato puree has a thicker consistency and a deeper flavour than sauce", "skeletal muscle and the brain", "1985 -- 1993", "Dublin", "goldfinger", "Lidice", "Baltimore", "Wynonna", "LGBT rights activist", "the Italians", "a hoo-hoo", "Canada", "Bolton"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6980666035353535}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, true, false, true, true, false, false, true, true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.4444444444444445, 0.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-2700", "mrqa_newsqa-validation-3662", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-887", "mrqa_newsqa-validation-2493", "mrqa_newsqa-validation-1348", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-2546", "mrqa_newsqa-validation-105", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-2521", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-3627", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-2853", "mrqa_naturalquestions-validation-2943", "mrqa_hotpotqa-validation-1868", "mrqa_hotpotqa-validation-5251", "mrqa_searchqa-validation-16084", "mrqa_searchqa-validation-4753"], "SR": 0.640625, "CSR": 0.5589717741935484, "retrieved_ids": ["mrqa_squad-train-40678", "mrqa_squad-train-42094", "mrqa_squad-train-37365", "mrqa_squad-train-47434", "mrqa_squad-train-59370", "mrqa_squad-train-25057", "mrqa_squad-train-48758", "mrqa_squad-train-18828", "mrqa_squad-train-30319", "mrqa_squad-train-1601", "mrqa_squad-train-36045", "mrqa_squad-train-66216", "mrqa_squad-train-74577", "mrqa_squad-train-5285", "mrqa_squad-train-61764", "mrqa_squad-train-80336", "mrqa_squad-train-42871", "mrqa_squad-train-16204", "mrqa_squad-train-32442", "mrqa_squad-train-39922", "mrqa_squad-train-66625", "mrqa_squad-train-37194", "mrqa_squad-train-45756", "mrqa_squad-train-81949", "mrqa_squad-train-50674", "mrqa_squad-train-5375", "mrqa_squad-train-74701", "mrqa_squad-train-1719", "mrqa_squad-train-55742", "mrqa_squad-train-54272", "mrqa_squad-train-64640", "mrqa_squad-train-27762", "mrqa_newsqa-validation-4122", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-293", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-509", "mrqa_triviaqa-validation-5573", "mrqa_searchqa-validation-11037", "mrqa_hotpotqa-validation-1685", "mrqa_searchqa-validation-15007", "mrqa_naturalquestions-validation-954", "mrqa_squad-validation-6319", "mrqa_newsqa-validation-2103", "mrqa_squad-validation-8046", "mrqa_triviaqa-validation-2582", "mrqa_newsqa-validation-1181", "mrqa_searchqa-validation-2022", "mrqa_searchqa-validation-7603", "mrqa_newsqa-validation-1398", "mrqa_naturalquestions-validation-5411", "mrqa_newsqa-validation-2207", "mrqa_triviaqa-validation-3555", "mrqa_newsqa-validation-2652", "mrqa_squad-validation-5456", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-16660", "mrqa_squad-validation-2513", "mrqa_squad-validation-1529", "mrqa_squad-validation-7719", "mrqa_hotpotqa-validation-1039", "mrqa_newsqa-validation-4085"], "EFR": 0.9565217391304348, "Overall": 0.7377862026647966}, {"timecode": 62, "before_eval_results": {"predictions": ["Gorakhpur Junction", "Colman", "the Michael Douglas film, The Jewel of the Nile, the sequel to the hit blockbuster film, Romancing the Stone", "Nodar Kumaritashvili", "three", "constitutional monarchy", "sperm and ova", "Michael Buffer", "14", "16,801 students", "Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Egypt", "in the 1820s", "Iraq, Syria, Lebanon, Cyprus, Jordan, Israel, Palestine, Egypt", "third", "Andrew Garfield", "The Fixx", "The acid plays a key role in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1971 -- 1979", "4 in", "March 8, 2018", "Camping World Stadium in Orlando, Florida", "George Harrison", "Kristy Swanson", "from within the Bank, with the incumbent grooming his or her successor", "simulation", "James Martin Lafferty", "Kenny Anderson", "agriculture", "a vas surgical reconstruction", "Kingdom of Strathclyde", "As late as the 1890s, building regulations in London did not require working - class housing to have indoor toilets", "18 May 1048 -- 4 December 1131", "Uralic", "C\u03bc and C\u03b4", "Universal Pictures", "Tbilisi", "dry lake beds northeast of Los Angeles", "tolled ( quota ) highways", "a Consular Report of Birth Abroad", "outside cultivated areas", "Buffalo Bill", "IIII", "extremely slowly in the absence of a catalyst", "the Maginot Line", "Gustav Bauer", "James Watson and Francis Crick", "the state", "card verification code", "unbiased relationships", "Sondheim", "Tasmania", "Laura Robson", "Afghanistan", "Todd McFarlane", "Massachusetts", "one", "\"significant skeletal remains\"", "the forward's lawyer", "super-yacht", "syrup", "palate", "locoweed", "December 1974"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6437263257575757}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.9166666666666666, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.33333333333333337, 0.9818181818181818, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.20000000000000004, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.1, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-9089", "mrqa_naturalquestions-validation-303", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-6252", "mrqa_naturalquestions-validation-4674", "mrqa_naturalquestions-validation-5152", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-9723", "mrqa_naturalquestions-validation-3902", "mrqa_naturalquestions-validation-2399", "mrqa_naturalquestions-validation-538", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-6998", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7226", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-9755", "mrqa_triviaqa-validation-5221", "mrqa_newsqa-validation-1699"], "SR": 0.546875, "CSR": 0.5587797619047619, "retrieved_ids": ["mrqa_squad-train-426", "mrqa_squad-train-12752", "mrqa_squad-train-11643", "mrqa_squad-train-34195", "mrqa_squad-train-48100", "mrqa_squad-train-83699", "mrqa_squad-train-23802", "mrqa_squad-train-63770", "mrqa_squad-train-55793", "mrqa_squad-train-15024", "mrqa_squad-train-47637", "mrqa_squad-train-81297", "mrqa_squad-train-49475", "mrqa_squad-train-28662", "mrqa_squad-train-12364", "mrqa_squad-train-22025", "mrqa_squad-train-58338", "mrqa_squad-train-17916", "mrqa_squad-train-54842", "mrqa_squad-train-73307", "mrqa_squad-train-45562", "mrqa_squad-train-13025", "mrqa_squad-train-25797", "mrqa_squad-train-20597", "mrqa_squad-train-84957", "mrqa_squad-train-27724", "mrqa_squad-train-19435", "mrqa_squad-train-53103", "mrqa_squad-train-4130", "mrqa_squad-train-5597", "mrqa_squad-train-80361", "mrqa_squad-train-5456", "mrqa_hotpotqa-validation-3900", "mrqa_triviaqa-validation-69", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-4126", "mrqa_searchqa-validation-6815", "mrqa_newsqa-validation-1154", "mrqa_searchqa-validation-3591", "mrqa_newsqa-validation-848", "mrqa_newsqa-validation-2296", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-367", "mrqa_squad-validation-6759", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3088", "mrqa_naturalquestions-validation-4771", "mrqa_newsqa-validation-4122", "mrqa_searchqa-validation-15278", "mrqa_newsqa-validation-3184", "mrqa_squad-validation-639", "mrqa_hotpotqa-validation-4241", "mrqa_newsqa-validation-23", "mrqa_triviaqa-validation-2541", "mrqa_triviaqa-validation-6199", "mrqa_triviaqa-validation-862", "mrqa_newsqa-validation-2027", "mrqa_naturalquestions-validation-7165", "mrqa_newsqa-validation-2854", "mrqa_searchqa-validation-3381", "mrqa_newsqa-validation-3011", "mrqa_searchqa-validation-4945", "mrqa_hotpotqa-validation-4478"], "EFR": 0.9655172413793104, "Overall": 0.7395469006568145}, {"timecode": 63, "before_eval_results": {"predictions": ["Detective Inspector", "Coriolis force", "1776", "1994", "Roger Dean Stadium", "James Brown", "Everywhere", "1 mile ( 1.6 km )", "Coldplay", "Jessica Sanders", "Article 1, Section 2", "Lex Luger and Rick Rude", "November 2, 2010", "Foreign minister Hermann M\u00fcller and colonial minister Johannes Bell", "annuity", "Mark Lowry", "1877", "31", "c. 1000 AD", "bow bridge", "Dick Rutan and Jeana Yeager", "a stretch of Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "July 1790", "King Saud University", "Hugo Weaving", "Book of Exodus", "a standard form contract", "Bart Howard", "to transform agricultural productivity, particularly with irrigated rather than dry - land cultivation", "Sean O' Neal", "Toby Kebbell", "1066", "Simon Peter", "Phil Johnston", "glycine and arginine", "art of the Persian Safavid dynasty", "Stephen A. Douglas", "Dolby Theatre in Hollywood, Los Angeles, California", "24 -- 3", "Republic of Tecala", "during meiosis", "2009", "Andy Serkis", "the priests and virgins", "1560s", "twice", "Border Collie", "Gwendoline Christie", "September 19 - 22, 2017", "provinces along the Yangtze River and in provinces in the south", "humid subtropical climate", "1990", "furniture", "Berlin", "Marjorie McGinnis", "Saxe-Coburg and Gotha", "U.S. Representative", "Anne Frank,", "Sunday,", "123 pounds of cocaine and 4.5 pounds of heroin,", "Twilight Zone: The Movie", "The Benchwarmers", "the No Child Left Behind Act", "part of the proceeds"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5599205633597044}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, false, false, true, true, true, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 0.8, 0.0, 0.0, 0.6153846153846153, 0.16666666666666669, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.8387096774193549, 0.0, 1.0, 1.0, 1.0, 0.046511627906976744, 1.0, 0.15384615384615383, 0.4, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.888888888888889, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3756", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-6555", "mrqa_naturalquestions-validation-1452", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-9922", "mrqa_naturalquestions-validation-9782", "mrqa_naturalquestions-validation-3789", "mrqa_naturalquestions-validation-10550", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-171", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-3199", "mrqa_naturalquestions-validation-7549", "mrqa_naturalquestions-validation-8177", "mrqa_naturalquestions-validation-9075", "mrqa_naturalquestions-validation-2583", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-686", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-9961", "mrqa_hotpotqa-validation-862", "mrqa_hotpotqa-validation-4560", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2386", "mrqa_searchqa-validation-311", "mrqa_searchqa-validation-7607"], "SR": 0.421875, "CSR": 0.556640625, "retrieved_ids": ["mrqa_squad-train-40500", "mrqa_squad-train-20814", "mrqa_squad-train-78151", "mrqa_squad-train-60811", "mrqa_squad-train-15590", "mrqa_squad-train-32946", "mrqa_squad-train-58953", "mrqa_squad-train-45436", "mrqa_squad-train-29053", "mrqa_squad-train-68440", "mrqa_squad-train-34071", "mrqa_squad-train-60628", "mrqa_squad-train-46824", "mrqa_squad-train-59241", "mrqa_squad-train-47453", "mrqa_squad-train-18918", "mrqa_squad-train-28931", "mrqa_squad-train-44999", "mrqa_squad-train-78055", "mrqa_squad-train-61858", "mrqa_squad-train-13677", "mrqa_squad-train-85861", "mrqa_squad-train-66769", "mrqa_squad-train-68694", "mrqa_squad-train-59794", "mrqa_squad-train-492", "mrqa_squad-train-37102", "mrqa_squad-train-46244", "mrqa_squad-train-2344", "mrqa_squad-train-38829", "mrqa_squad-train-16238", "mrqa_squad-train-30567", "mrqa_squad-validation-3559", "mrqa_squad-validation-10214", "mrqa_newsqa-validation-3159", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-681", "mrqa_triviaqa-validation-1459", "mrqa_newsqa-validation-267", "mrqa_searchqa-validation-14997", "mrqa_newsqa-validation-297", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-37", "mrqa_newsqa-validation-317", "mrqa_naturalquestions-validation-9715", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-551", "mrqa_naturalquestions-validation-553", "mrqa_squad-validation-2289", "mrqa_newsqa-validation-3911", "mrqa_searchqa-validation-10799", "mrqa_naturalquestions-validation-916", "mrqa_searchqa-validation-14868", "mrqa_hotpotqa-validation-4689", "mrqa_triviaqa-validation-3232", "mrqa_naturalquestions-validation-4664", "mrqa_triviaqa-validation-7672", "mrqa_squad-validation-5525", "mrqa_searchqa-validation-10060", "mrqa_naturalquestions-validation-190"], "EFR": 0.918918918918919, "Overall": 0.7297994087837838}, {"timecode": 64, "before_eval_results": {"predictions": ["the winter solstice", "19 July 1990", "senators", "Rex Harrison", "special economic zones", "Turducken", "Patrick Warburton", "Judas Iscariot", "1960", "the President of the United States", "administrative supervision over all courts and the personnel thereof", "James Fleet", "the intersection of Mud Mountain Road and Highway 410", "Yuzuru Hanyu", "Tracy McConnell", "Dottie West", "small intestine", "Action Jackson", "Thomas Alva Edison", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "Charles Haley", "the prince", "Sylvester Stallone", "from 35 to 40 hours per week", "Naomi", "a body", "to address the historic oppression, inequality and discrimination faced by those communities and to give these communities a place", "December 25", "Louis XV", "Waylon Jennings", "1996", "mid - to late 1920s", "Far Away", "John C. Reilly", "100,000", "Richard Masur", "5", "Johnny Cash", "consistency", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "John C. Reilly", "Mount Baker - Snoqualmie National Forest and Nooksack Falls in the North Cascades range of, Washington", "Saint Peter", "King Saud University", "the presence of correctly oriented P waves", "Brenda", "1792", "Cyanea capillata", "Bonnie Lipton", "2002", "Charles Haley", "Dawn French", "translation", "Ut\u00f8ya island", "Flyweight", "Old World fossil representatives", "1964", "pesos", "in North Korea", "\"E! News\"", "accelerator", "the superdelegates", "The Greatest Show on Earth", "Catherine"], "metric_results": {"EM": 0.625, "QA-F1": 0.723987079607484}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.5, 0.5714285714285715, 1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 1.0, 0.923076923076923, 0.0, 0.125, 1.0, 0.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 0.0, 0.07999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4389", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-7489", "mrqa_naturalquestions-validation-8355", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-2839", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-9675", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-4309", "mrqa_triviaqa-validation-7290", "mrqa_hotpotqa-validation-1810", "mrqa_newsqa-validation-3238", "mrqa_searchqa-validation-16383", "mrqa_triviaqa-validation-3010"], "SR": 0.625, "CSR": 0.5576923076923077, "retrieved_ids": ["mrqa_squad-train-23859", "mrqa_squad-train-67571", "mrqa_squad-train-53751", "mrqa_squad-train-53607", "mrqa_squad-train-21307", "mrqa_squad-train-77324", "mrqa_squad-train-63506", "mrqa_squad-train-59830", "mrqa_squad-train-21", "mrqa_squad-train-8521", "mrqa_squad-train-35821", "mrqa_squad-train-39582", "mrqa_squad-train-49885", "mrqa_squad-train-31283", "mrqa_squad-train-76712", "mrqa_squad-train-1377", "mrqa_squad-train-65085", "mrqa_squad-train-48269", "mrqa_squad-train-13209", "mrqa_squad-train-65251", "mrqa_squad-train-79961", "mrqa_squad-train-64421", "mrqa_squad-train-69634", "mrqa_squad-train-65894", "mrqa_squad-train-3213", "mrqa_squad-train-85208", "mrqa_squad-train-13455", "mrqa_squad-train-3468", "mrqa_squad-train-31190", "mrqa_squad-train-33360", "mrqa_squad-train-22948", "mrqa_squad-train-25873", "mrqa_squad-validation-1891", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-3179", "mrqa_searchqa-validation-15437", "mrqa_newsqa-validation-3022", "mrqa_searchqa-validation-8094", "mrqa_naturalquestions-validation-5370", "mrqa_newsqa-validation-2884", "mrqa_triviaqa-validation-2314", "mrqa_triviaqa-validation-1912", "mrqa_newsqa-validation-1271", "mrqa_newsqa-validation-2791", "mrqa_naturalquestions-validation-5004", "mrqa_newsqa-validation-1436", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-7112", "mrqa_newsqa-validation-2104", "mrqa_hotpotqa-validation-118", "mrqa_triviaqa-validation-5221", "mrqa_searchqa-validation-3267", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3406", "mrqa_searchqa-validation-5522", "mrqa_newsqa-validation-2028", "mrqa_naturalquestions-validation-6324", "mrqa_newsqa-validation-1758", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3827", "mrqa_squad-validation-6319", "mrqa_searchqa-validation-946"], "EFR": 0.9583333333333334, "Overall": 0.7378926282051281}, {"timecode": 65, "before_eval_results": {"predictions": ["Mel Gibson", "the season seven finale", "2016", "Jocelyn Flores", "1956", "November 25, 2002", "zinc", "Pebe Sebert", "Thomas Chisholm", "The interstellar medium", "Lesley Gore", "Paul", "comic book", "the belligerents", "ingredients", "George III's German - born wife, Charlotte of Mecklenburg - Strelitz", "December 1, 2009", "four", "com TLD", "Neil Young", "Ren\u00e9 Verdon", "Melanie Martinez", "the Director of National Intelligence", "Liam Cunningham", "Elliot Scheiner", "a cylinder of glass or plastic that runs along the fiber's length", "Ace", "Goths", "H CO", "StubHub Center", "the city of Indianapolis", "Jaydev Shah", "Dougie MacLean", "Glenn Close", "between the Mediterranean Sea to the north and the Red Sea in the south", "the Germanic elements `` hrod '' meaning renown and `` beraht '' meaning bright", "1888", "Nashville, Tennessee", "San Crist\u00f3bal, Pinar del R\u00edo Province ( now in Artemisa Province ), in western Cuba", "performance marker", "Super Bowl LII", "the White River between Enumclaw and Buckley", "Columbia River Gorge", "Setsuko Thurlow", "John Joseph Patrick Ryan", "1912", "Luke 6 : 67 -- 71", "Ric Flair", "sometime between 124 and 800 CE", "Pangaea", "2010", "Adam Werritty", "the Jets", "her white halter dress", "Kim Jong-hyun", "Edward II", "Harrods", "\"Most of my friends have put in at least a couple hours,\"", "job training", "Arnold Drummond", "Nixon", "Great Expectations", "cathode", "\"No Surprises\""], "metric_results": {"EM": 0.484375, "QA-F1": 0.6261540022477522}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.3076923076923077, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6153846153846153, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428572, 1.0, 1.0, 0.5714285714285715, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 0.9, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.75, 1.0, 0.4799999999999999, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7737", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-8309", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-10410", "mrqa_naturalquestions-validation-5515", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-1829", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6514", "mrqa_naturalquestions-validation-4039", "mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-7202", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-337", "mrqa_naturalquestions-validation-9386", "mrqa_triviaqa-validation-1851", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-4129", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1827", "mrqa_hotpotqa-validation-1697"], "SR": 0.484375, "CSR": 0.5565814393939394, "retrieved_ids": ["mrqa_squad-train-19026", "mrqa_squad-train-7602", "mrqa_squad-train-5219", "mrqa_squad-train-34053", "mrqa_squad-train-86377", "mrqa_squad-train-74757", "mrqa_squad-train-77305", "mrqa_squad-train-547", "mrqa_squad-train-56404", "mrqa_squad-train-54539", "mrqa_squad-train-463", "mrqa_squad-train-85528", "mrqa_squad-train-59629", "mrqa_squad-train-57517", "mrqa_squad-train-58878", "mrqa_squad-train-9123", "mrqa_squad-train-31842", "mrqa_squad-train-46070", "mrqa_squad-train-33017", "mrqa_squad-train-32034", "mrqa_squad-train-49166", "mrqa_squad-train-34942", "mrqa_squad-train-78747", "mrqa_squad-train-49945", "mrqa_squad-train-83752", "mrqa_squad-train-53377", "mrqa_squad-train-25246", "mrqa_squad-train-19199", "mrqa_squad-train-76249", "mrqa_squad-train-51554", "mrqa_squad-train-62199", "mrqa_squad-train-50897", "mrqa_triviaqa-validation-79", "mrqa_newsqa-validation-368", "mrqa_naturalquestions-validation-5370", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-1804", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-3121", "mrqa_newsqa-validation-1563", "mrqa_hotpotqa-validation-3245", "mrqa_searchqa-validation-15437", "mrqa_newsqa-validation-3796", "mrqa_newsqa-validation-1808", "mrqa_triviaqa-validation-3354", "mrqa_newsqa-validation-1120", "mrqa_triviaqa-validation-86", "mrqa_searchqa-validation-13853", "mrqa_searchqa-validation-11427", "mrqa_newsqa-validation-2793", "mrqa_naturalquestions-validation-6340", "mrqa_triviaqa-validation-862", "mrqa_triviaqa-validation-6827", "mrqa_searchqa-validation-11053", "mrqa_newsqa-validation-2151", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2936", "mrqa_newsqa-validation-2813", "mrqa_naturalquestions-validation-5034", "mrqa_naturalquestions-validation-5004", "mrqa_squad-validation-543", "mrqa_triviaqa-validation-1706"], "EFR": 0.9090909090909091, "Overall": 0.7278219696969697}, {"timecode": 66, "before_eval_results": {"predictions": ["substitute good", "October 1980", "IX", "Edgar Lungu", "Juice Newton", "Massachusetts", "as an extension to this procedure", "harmful for the one whose envy inflicts it on others as well as for the sufferer", "W. Edwards Deming", "Jackie Robinson", "saturated hydraulic conductivity", "Kathy Najimy", "Nicole Gale Anderson", "Jethalal Gada", "a transformative change of heart ; especially : a spiritual conversion", "alcohol or smoking", "Richard Crispin Armitage", "the Himalayas", "Hagrid", "volcanic activity", "Sir Rowland Hill", "late - September through early January", "1991", "Joseph Sherrard Kearns", "The Union's forces were slow in positioning themselves, allowing Confederate reinforcements time to arrive by rail", "1 September 1939", "a loop", "Carlos Alan Autry Jr.", "the fictional town of West Egg on prosperous Long Island", "Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "certified question or proposition of law from one of the United States Courts of Appeals", "after World War II", "Guwahati", "about 1 nautical mile ( 2 km ) off - coast from Piraeus and about 16 kilometres ( 10 miles ) west of Athens", "Cheap trick", "October 29, 2015", "Pir Panjal Railway Tunnel", "16", "3.5 million years old", "The federal government received only those powers which the colonies had recognized as belonging to king and parliament", "Tigris and Euphrates rivers", "bicameral Congress", "In the year 2026", "The Beverly Hills, 90210 actress Shannen Doherty was cast as the eldest sister Prue Halliwell", "H.G. Wells", "Michael Crawford", "a password recovery tool for Microsoft Windows", "at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "Los Angeles", "moral tale", "Lana Del Rey", "the NBA", "a greyhound", "Aristotle", "Northwest Mall", "\"Supergirl\"", "Field Marshal Lord Gort", "WILL MISS YOU! WE LOVE YOU MICHAEL!!!\"", "gun", "government soldiers and Taliban militants in the Swat Valley.", "Odysseus", "Louisiana", "Boy Scouts of America", "three"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6658140691215128}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.125, 0.5, 1.0, 1.0, 1.0, 0.7200000000000001, 0.11764705882352941, 0.0, 1.0, 0.9268292682926829, 1.0, 0.0, 0.36363636363636365, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.5714285714285715, 1.0, 0.058823529411764705, 0.8620689655172413, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1198", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-5579", "mrqa_naturalquestions-validation-746", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-10026", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-767", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7995", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-6117", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9944", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-7705", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-2578", "mrqa_naturalquestions-validation-4242", "mrqa_triviaqa-validation-4501", "mrqa_hotpotqa-validation-992", "mrqa_newsqa-validation-2240", "mrqa_searchqa-validation-4320"], "SR": 0.546875, "CSR": 0.5564365671641791, "retrieved_ids": ["mrqa_squad-train-17432", "mrqa_squad-train-61774", "mrqa_squad-train-40751", "mrqa_squad-train-70654", "mrqa_squad-train-60837", "mrqa_squad-train-4371", "mrqa_squad-train-7831", "mrqa_squad-train-76739", "mrqa_squad-train-4099", "mrqa_squad-train-18439", "mrqa_squad-train-75", "mrqa_squad-train-25077", "mrqa_squad-train-16064", "mrqa_squad-train-67233", "mrqa_squad-train-43323", "mrqa_squad-train-25897", "mrqa_squad-train-37953", "mrqa_squad-train-41661", "mrqa_squad-train-70675", "mrqa_squad-train-72554", "mrqa_squad-train-42057", "mrqa_squad-train-1857", "mrqa_squad-train-86059", "mrqa_squad-train-15439", "mrqa_squad-train-83572", "mrqa_squad-train-50929", "mrqa_squad-train-82489", "mrqa_squad-train-7913", "mrqa_squad-train-18115", "mrqa_squad-train-9938", "mrqa_squad-train-66457", "mrqa_squad-train-33451", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-142", "mrqa_newsqa-validation-880", "mrqa_newsqa-validation-3854", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-3733", "mrqa_naturalquestions-validation-154", "mrqa_naturalquestions-validation-9523", "mrqa_searchqa-validation-11704", "mrqa_triviaqa-validation-7743", "mrqa_squad-validation-2513", "mrqa_newsqa-validation-1104", "mrqa_searchqa-validation-6041", "mrqa_newsqa-validation-649", "mrqa_newsqa-validation-1763", "mrqa_naturalquestions-validation-2942", "mrqa_searchqa-validation-2768", "mrqa_newsqa-validation-3640", "mrqa_searchqa-validation-3932", "mrqa_searchqa-validation-6722", "mrqa_searchqa-validation-1384", "mrqa_naturalquestions-validation-3756", "mrqa_searchqa-validation-4893", "mrqa_newsqa-validation-1417", "mrqa_naturalquestions-validation-9824", "mrqa_newsqa-validation-652", "mrqa_squad-validation-4462", "mrqa_naturalquestions-validation-4079", "mrqa_triviaqa-validation-7627", "mrqa_searchqa-validation-7384", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-9273"], "EFR": 0.9655172413793104, "Overall": 0.7390782617086978}, {"timecode": 67, "before_eval_results": {"predictions": ["the year 2026", "Egypt", "1904", "1885", "In 1984", "Clarence Darrow", "John B. Watson", "Spanish", "Tara", "a child with Treacher Collins syndrome trying to fit in", "when the forward reaction proceeds at the same rate as the reverse reaction", "on the idea of laying out a tournament ladder by arranging slips of paper with the names of players on them the way seeds or seedlings are arranged in a garden : smaller plants up front, larger ones behind", "Ceramic art", "March 6, 2018", "Erica Rivera", "Bill Irwin", "Donald Trump", "Matt Flinders", "Kansas and Oklahoma", "Ancient Greek terms \u03c6\u03af\u03bb\u03bf\u03c2 ph\u00edlos ( beloved, dear ) and \u1f00\u03b4\u03b5\u03bb\u03c6\u03cc\u03c2 adelph\u00f3s ( brother, brotherly )", "Sir Ronald Ross", "Georgia", "Domhnall Gleeson", "CeCe Drake", "March 11, 2016", "March 11, 2018", "Thomas Mundy Peterson", "not", "boxing", "consistency", "Nucleotides", "acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "James Intveld", "United Support of Artists ( USA )", "Amybeth McNulty", "the King James Bible", "Bob Peterson", "intermembrane space", "February 25, 2004", "breast or lower chest of beef or veal", "the state'sDM, which is required to drive", "Dr. Hartwell Carver", "two", "following the 2017 season", "Arunachal Pradesh", "Charles R Ranch, County Road 24, Las Vegas, New Mexico, USA", "the pursuit of excessive wealth", "his brother", "Washington metropolitan area", "euro", "Ferm\u00edn Francisco de Lasu\u00e9n", "Aslan", "Richmond in North Yorkshire", "drinking song", "the tissues of the outer third of the vagina", "Bergen", "Cartoon Network", "\"She was focused so much on learning that she didn't notice,\"", "change course", "a federal judge in Mississippi", "Hippos & baboons", "the Russian Second Army", "Tommy Hilfiger", "a jug or pitcher with a wide mouth"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6584211909253027}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, false, false, true, true, false, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.2105263157894737, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.06666666666666667, 1.0, 1.0, 0.7499999999999999, 1.0, 0.7692307692307693, 1.0, 0.375, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1555", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-930", "mrqa_naturalquestions-validation-379", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-10147", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-1340", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-9459", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7575", "mrqa_naturalquestions-validation-4593", "mrqa_naturalquestions-validation-10536", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-2448", "mrqa_naturalquestions-validation-4667", "mrqa_naturalquestions-validation-8999", "mrqa_naturalquestions-validation-10565", "mrqa_triviaqa-validation-7430", "mrqa_hotpotqa-validation-4194", "mrqa_searchqa-validation-5472", "mrqa_searchqa-validation-808", "mrqa_triviaqa-validation-2358"], "SR": 0.546875, "CSR": 0.5562959558823529, "retrieved_ids": ["mrqa_squad-train-40863", "mrqa_squad-train-36496", "mrqa_squad-train-32542", "mrqa_squad-train-75709", "mrqa_squad-train-35002", "mrqa_squad-train-11576", "mrqa_squad-train-31495", "mrqa_squad-train-7967", "mrqa_squad-train-36483", "mrqa_squad-train-58236", "mrqa_squad-train-50664", "mrqa_squad-train-6287", "mrqa_squad-train-4110", "mrqa_squad-train-44487", "mrqa_squad-train-76595", "mrqa_squad-train-56800", "mrqa_squad-train-26497", "mrqa_squad-train-13985", "mrqa_squad-train-24789", "mrqa_squad-train-4636", "mrqa_squad-train-49722", "mrqa_squad-train-42173", "mrqa_squad-train-76066", "mrqa_squad-train-71404", "mrqa_squad-train-5209", "mrqa_squad-train-15855", "mrqa_squad-train-70718", "mrqa_squad-train-54466", "mrqa_squad-train-18710", "mrqa_squad-train-28090", "mrqa_squad-train-70152", "mrqa_squad-train-46135", "mrqa_newsqa-validation-75", "mrqa_hotpotqa-validation-2820", "mrqa_squad-validation-6390", "mrqa_squad-validation-5465", "mrqa_newsqa-validation-1417", "mrqa_searchqa-validation-1256", "mrqa_hotpotqa-validation-2533", "mrqa_naturalquestions-validation-5215", "mrqa_searchqa-validation-6763", "mrqa_hotpotqa-validation-4198", "mrqa_searchqa-validation-13753", "mrqa_newsqa-validation-1334", "mrqa_newsqa-validation-2614", "mrqa_naturalquestions-validation-7733", "mrqa_searchqa-validation-11095", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-3162", "mrqa_newsqa-validation-3609", "mrqa_naturalquestions-validation-10367", "mrqa_newsqa-validation-1028", "mrqa_squad-validation-7051", "mrqa_newsqa-validation-2515", "mrqa_newsqa-validation-619", "mrqa_newsqa-validation-2586", "mrqa_searchqa-validation-2863", "mrqa_newsqa-validation-3316", "mrqa_searchqa-validation-11037", "mrqa_searchqa-validation-13584", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1397", "mrqa_naturalquestions-validation-8161", "mrqa_newsqa-validation-1749"], "EFR": 0.9655172413793104, "Overall": 0.7390501394523327}, {"timecode": 68, "before_eval_results": {"predictions": ["2016", "B.R. Ambedkar", "Lalo Schifrin", "Gwendoline Christie", "Rockwell", "Chris Sarandon", "Olivia Olson", "21 June 2007", "Peter Klaven ( Paul Rudd )", "G. Hannelius", "4 January 2011", "her brother, Brian", "Elizabeth Dean Lail", "Bindusara", "Omar Khayyam", "keep the leaves in the light and provide a place for the plant to keep its flowers and fruits", "British Columbia, Canada", "the government - owned Panama Canal Authority", "Johnny Cash", "the first year begins", "personnel directors", "Davos", "Louis Hynes", "1900", "Elizabeth Weber", "stems and roots of certain vascular plants", "third season of Stranger Things has been greenlit, no official release date has been given, though it is expected in either late 2018 or early 2019", "R.E.M.", "the Gentiles", "symbol I and atomic number 53", "the Ark of the Covenant ( the Aron Habrit in Hebrew )", "Luther Ingram", "September 29, 2017", "Joseph Sherrard Kearns", "Kelly Reno", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida", "Iran", "2001", "Jikji", "Elected Emperor of the Romans", "1799", "Kid Creole & The Coconuts", "a god of the Ammonites", "late - night", "an official document permitting a specific individual to operate one or more types of motorized vehicles, such as a motorcycle, car, truck, or bus on a public road", "Toto", "social commentary, and condemns rural depopulation and the pursuit of excessive wealth", "By 1770 BC", "Australia's Sir Donald Bradman", "Roman Reigns", "Rocky Dzidzornu", "Sikhism", "guitar", "September 27 1825", "Miracle", "Dumfries and Galloway", "the Crab Orchard Mountains", "President Obama and Britain's Prince Charles", "NATO fighters", "19, standing 6'2\", with his auburn hair pulled back in a queue.", "a lighthouse", "lullaby", "E. E. Cummings", "Minerals Management Service Director Elizabeth Birnbaum"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6783111712254155}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, true, false, false, false, true, true, true, true, false, true, true, false, false, true, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 0.3846153846153846, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.22222222222222224, 0.8181818181818181, 1.0, 0.0, 0.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.5555555555555556, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.8837209302325582, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.26666666666666666, 1.0, 0.16666666666666669, 1.0, 1.0, 0.8, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-7853", "mrqa_naturalquestions-validation-8933", "mrqa_naturalquestions-validation-946", "mrqa_naturalquestions-validation-3097", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-5465", "mrqa_naturalquestions-validation-8599", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-3284", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-3027", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-6917", "mrqa_naturalquestions-validation-8201", "mrqa_naturalquestions-validation-8845", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-158", "mrqa_naturalquestions-validation-9816", "mrqa_triviaqa-validation-3425", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5586", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-3345", "mrqa_searchqa-validation-13013", "mrqa_newsqa-validation-2665"], "SR": 0.546875, "CSR": 0.5561594202898551, "retrieved_ids": ["mrqa_squad-train-15035", "mrqa_squad-train-8983", "mrqa_squad-train-52719", "mrqa_squad-train-64815", "mrqa_squad-train-60052", "mrqa_squad-train-56113", "mrqa_squad-train-43669", "mrqa_squad-train-61587", "mrqa_squad-train-5627", "mrqa_squad-train-27095", "mrqa_squad-train-29071", "mrqa_squad-train-8508", "mrqa_squad-train-46072", "mrqa_squad-train-16466", "mrqa_squad-train-28240", "mrqa_squad-train-79123", "mrqa_squad-train-883", "mrqa_squad-train-3499", "mrqa_squad-train-17657", "mrqa_squad-train-70104", "mrqa_squad-train-79925", "mrqa_squad-train-34621", "mrqa_squad-train-77356", "mrqa_squad-train-74386", "mrqa_squad-train-26213", "mrqa_squad-train-10829", "mrqa_squad-train-63084", "mrqa_squad-train-2897", "mrqa_squad-train-50799", "mrqa_squad-train-7939", "mrqa_squad-train-75342", "mrqa_squad-train-73466", "mrqa_triviaqa-validation-1706", "mrqa_searchqa-validation-5457", "mrqa_naturalquestions-validation-8056", "mrqa_searchqa-validation-9137", "mrqa_newsqa-validation-1693", "mrqa_searchqa-validation-13808", "mrqa_hotpotqa-validation-4478", "mrqa_newsqa-validation-1428", "mrqa_searchqa-validation-11710", "mrqa_squad-validation-9640", "mrqa_newsqa-validation-3806", "mrqa_squad-validation-7527", "mrqa_searchqa-validation-3163", "mrqa_naturalquestions-validation-1657", "mrqa_newsqa-validation-2456", "mrqa_searchqa-validation-6638", "mrqa_newsqa-validation-2104", "mrqa_newsqa-validation-3060", "mrqa_naturalquestions-validation-6117", "mrqa_newsqa-validation-3012", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-3711", "mrqa_newsqa-validation-1514", "mrqa_newsqa-validation-1988", "mrqa_searchqa-validation-11053", "mrqa_searchqa-validation-13556", "mrqa_newsqa-validation-2519", "mrqa_naturalquestions-validation-486", "mrqa_newsqa-validation-3325", "mrqa_triviaqa-validation-4255", "mrqa_triviaqa-validation-5771", "mrqa_newsqa-validation-25"], "EFR": 0.896551724137931, "Overall": 0.7252297288855571}, {"timecode": 69, "before_eval_results": {"predictions": ["Thawne", "Manchester United Football Club is a professional football club based in Old Trafford, Greater Manchester, England, that competes in the Premier League, the top flight of English football", "The Intolerable Acts", "in skeletal muscle and the brain", "libretto", "up to 13 individuals", "1947, 1956, 1975, 2015 and 2017", "the St. Louis Cardinals", "Andy Serkis", "Panning", "September 21, 2017", "Bob Dylan", "Virginia Beach is an independent city located on the southeastern coast of the Commonwealth of Virginia in the United States", "the sidewalk between Division Street and East Broadway", "Garbi\u00f1e Muguruza", "HTTP / 1.1", "petioles", "eleven players", "In Canada, the small business tax rate is the tax rate paid by a small business", "Roger Dean Stadium is one of only two stadiums in Florida to host two Major League Baseball teams annually for spring training", "in `` Blood is the New Black ''", "Otis Timson", "four", "colonial agent in London", "a routing table, or routing information base ( RIB )", "James Rodr\u00edguez", "in Ephesus in AD 95 -- 110", "Johnson, a lifelong Democrat and the Republican majority in Congress over how best to deal with the defeated Southern states", "more than 2,500 locations in all states except Alaska, Hawaii, Connecticut, Maine, New Hampshire, and Vermont", "from the top of the leg to the foot on the posterior aspect", "the surly librarian who looks after his alcoholic sister Mary Elizabeth ( Margaret Hoard )", "Ashoka", "dermis", "Hodel", "October 27, 2017", "Wolfgang Hochstetter", "a popular medieval given throughout Europe, coming from the biblical name, Thomas being one of Jesus'disciples", "April 10, 2018", "the fourth C key from left on a standard 88 - key piano keyboard", "Aegisthus", "NFL coaches, general managers, and scouts", "no official release date has been given, though it is expected in either late 2018 or early 2019", "Terrell Suggs", "Latitude", "the courts", "September 29, 2017", "10 : 30am", "Algeria", "Russia", "Manley", "December 15, 2017", "Wyatt", "Wednesday 31 Dec 2014", "\"In God we Trust\"", "2006", "Carter", "2027 Fairmount Avenue between Corinthian Avenue and North 22nd Street", "sexual harassment", "At least 40", "Juan Martin Del Potro.", "the Caspian Sea", "Sweden", "photoelectric", "republic of Namibia"], "metric_results": {"EM": 0.5, "QA-F1": 0.642512395012395}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.14814814814814814, 1.0, 0.888888888888889, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.24000000000000002, 0.888888888888889, 0.0, 1.0, 0.0, 0.7272727272727273, 1.0, 0.6666666666666666, 0.1111111111111111, 0.4, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2280", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-413", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-5912", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7760", "mrqa_naturalquestions-validation-6951", "mrqa_naturalquestions-validation-9494", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-1047", "mrqa_naturalquestions-validation-8911", "mrqa_naturalquestions-validation-3121", "mrqa_naturalquestions-validation-9597", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-4370", "mrqa_naturalquestions-validation-9009", "mrqa_naturalquestions-validation-10378", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-5164", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9007", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-7391", "mrqa_hotpotqa-validation-4969", "mrqa_hotpotqa-validation-744", "mrqa_triviaqa-validation-5834"], "SR": 0.5, "CSR": 0.5553571428571429, "retrieved_ids": ["mrqa_squad-train-46717", "mrqa_squad-train-69532", "mrqa_squad-train-39168", "mrqa_squad-train-77523", "mrqa_squad-train-5947", "mrqa_squad-train-11747", "mrqa_squad-train-38020", "mrqa_squad-train-34535", "mrqa_squad-train-44546", "mrqa_squad-train-82164", "mrqa_squad-train-63687", "mrqa_squad-train-2783", "mrqa_squad-train-47222", "mrqa_squad-train-16387", "mrqa_squad-train-41365", "mrqa_squad-train-60489", "mrqa_squad-train-24578", "mrqa_squad-train-16618", "mrqa_squad-train-10417", "mrqa_squad-train-36943", "mrqa_squad-train-21399", "mrqa_squad-train-7485", "mrqa_squad-train-55394", "mrqa_squad-train-72045", "mrqa_squad-train-67435", "mrqa_squad-train-6860", "mrqa_squad-train-61680", "mrqa_squad-train-5863", "mrqa_squad-train-19399", "mrqa_squad-train-37077", "mrqa_squad-train-72573", "mrqa_squad-train-25782", "mrqa_naturalquestions-validation-290", "mrqa_squad-validation-490", "mrqa_newsqa-validation-2080", "mrqa_naturalquestions-validation-2990", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2370", "mrqa_hotpotqa-validation-5850", "mrqa_newsqa-validation-2520", "mrqa_newsqa-validation-3277", "mrqa_searchqa-validation-5939", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-4089", "mrqa_searchqa-validation-9548", "mrqa_searchqa-validation-15278", "mrqa_triviaqa-validation-644", "mrqa_newsqa-validation-317", "mrqa_newsqa-validation-995", "mrqa_triviaqa-validation-7376", "mrqa_newsqa-validation-2392", "mrqa_naturalquestions-validation-10265", "mrqa_triviaqa-validation-7160", "mrqa_newsqa-validation-551", "mrqa_naturalquestions-validation-2680", "mrqa_searchqa-validation-8976", "mrqa_naturalquestions-validation-1198", "mrqa_newsqa-validation-418", "mrqa_newsqa-validation-2671", "mrqa_hotpotqa-validation-4689", "mrqa_searchqa-validation-3369", "mrqa_newsqa-validation-2204", "mrqa_triviaqa-validation-6066"], "EFR": 0.90625, "Overall": 0.7270089285714285}, {"timecode": 70, "UKR": 0.802734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1350", "mrqa_hotpotqa-validation-1952", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2600", "mrqa_hotpotqa-validation-3362", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-3900", "mrqa_hotpotqa-validation-4580", "mrqa_hotpotqa-validation-4791", "mrqa_hotpotqa-validation-5199", "mrqa_hotpotqa-validation-5394", "mrqa_hotpotqa-validation-5604", "mrqa_hotpotqa-validation-5707", "mrqa_hotpotqa-validation-5865", "mrqa_hotpotqa-validation-703", "mrqa_hotpotqa-validation-92", "mrqa_hotpotqa-validation-996", "mrqa_naturalquestions-validation-10070", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10383", "mrqa_naturalquestions-validation-10485", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-10639", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1147", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-1248", "mrqa_naturalquestions-validation-1324", "mrqa_naturalquestions-validation-1330", "mrqa_naturalquestions-validation-1369", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1504", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-1555", "mrqa_naturalquestions-validation-1655", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2234", "mrqa_naturalquestions-validation-2399", "mrqa_naturalquestions-validation-2583", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-2903", "mrqa_naturalquestions-validation-3232", "mrqa_naturalquestions-validation-3470", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3836", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-3902", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-4037", "mrqa_naturalquestions-validation-4053", "mrqa_naturalquestions-validation-413", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-5338", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5466", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5662", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-5865", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-6285", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-673", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-6917", "mrqa_naturalquestions-validation-7003", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-7760", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-8016", "mrqa_naturalquestions-validation-8153", "mrqa_naturalquestions-validation-8177", "mrqa_naturalquestions-validation-8201", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-8766", "mrqa_naturalquestions-validation-8972", "mrqa_naturalquestions-validation-8999", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-938", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-954", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9850", "mrqa_naturalquestions-validation-9967", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-1025", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-1065", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-114", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1235", "mrqa_newsqa-validation-1256", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1302", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1310", "mrqa_newsqa-validation-1342", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1443", "mrqa_newsqa-validation-1443", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-1466", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1565", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-159", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-1758", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-181", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1879", "mrqa_newsqa-validation-1888", "mrqa_newsqa-validation-1902", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1930", "mrqa_newsqa-validation-1933", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-200", "mrqa_newsqa-validation-2009", "mrqa_newsqa-validation-2018", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2044", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-2055", "mrqa_newsqa-validation-2060", "mrqa_newsqa-validation-2089", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2141", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2186", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-222", "mrqa_newsqa-validation-2222", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2229", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-2280", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-2341", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2375", "mrqa_newsqa-validation-2390", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2417", "mrqa_newsqa-validation-2446", "mrqa_newsqa-validation-2464", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2510", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-258", "mrqa_newsqa-validation-2584", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-2629", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-2688", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2813", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2842", "mrqa_newsqa-validation-2843", "mrqa_newsqa-validation-2853", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2861", "mrqa_newsqa-validation-2865", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-2920", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2949", "mrqa_newsqa-validation-2953", "mrqa_newsqa-validation-297", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-3034", "mrqa_newsqa-validation-3053", "mrqa_newsqa-validation-3069", "mrqa_newsqa-validation-3082", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-317", "mrqa_newsqa-validation-3178", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-327", "mrqa_newsqa-validation-3321", "mrqa_newsqa-validation-3345", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3403", "mrqa_newsqa-validation-3419", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-346", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3490", "mrqa_newsqa-validation-35", "mrqa_newsqa-validation-3591", "mrqa_newsqa-validation-3608", "mrqa_newsqa-validation-3609", "mrqa_newsqa-validation-3662", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-3672", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-3711", "mrqa_newsqa-validation-3758", "mrqa_newsqa-validation-3762", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3784", "mrqa_newsqa-validation-379", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3850", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-3878", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3962", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-3985", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4075", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-4130", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4154", "mrqa_newsqa-validation-418", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-448", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-50", "mrqa_newsqa-validation-538", "mrqa_newsqa-validation-546", "mrqa_newsqa-validation-555", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-613", "mrqa_newsqa-validation-615", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-695", "mrqa_newsqa-validation-77", "mrqa_newsqa-validation-781", "mrqa_newsqa-validation-825", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-861", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-878", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-962", "mrqa_newsqa-validation-971", "mrqa_searchqa-validation-10105", "mrqa_searchqa-validation-10549", "mrqa_searchqa-validation-10681", "mrqa_searchqa-validation-10853", "mrqa_searchqa-validation-11095", "mrqa_searchqa-validation-11466", "mrqa_searchqa-validation-11477", "mrqa_searchqa-validation-11513", "mrqa_searchqa-validation-11557", "mrqa_searchqa-validation-1200", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-13051", "mrqa_searchqa-validation-13313", "mrqa_searchqa-validation-13326", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-13645", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-14273", "mrqa_searchqa-validation-14346", "mrqa_searchqa-validation-14395", "mrqa_searchqa-validation-14631", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-16422", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-16831", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-248", "mrqa_searchqa-validation-2532", "mrqa_searchqa-validation-2576", "mrqa_searchqa-validation-3258", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-3718", "mrqa_searchqa-validation-3774", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-4386", "mrqa_searchqa-validation-443", "mrqa_searchqa-validation-4553", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-5028", "mrqa_searchqa-validation-5339", "mrqa_searchqa-validation-5955", "mrqa_searchqa-validation-6041", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-638", "mrqa_searchqa-validation-6490", "mrqa_searchqa-validation-6727", "mrqa_searchqa-validation-689", "mrqa_searchqa-validation-7285", "mrqa_searchqa-validation-7702", "mrqa_searchqa-validation-7985", "mrqa_searchqa-validation-8272", "mrqa_searchqa-validation-8343", "mrqa_searchqa-validation-8532", "mrqa_searchqa-validation-8710", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8869", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-9399", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-952", "mrqa_searchqa-validation-9733", "mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-9922", "mrqa_squad-validation-10011", "mrqa_squad-validation-10252", "mrqa_squad-validation-10306", "mrqa_squad-validation-111", "mrqa_squad-validation-1290", "mrqa_squad-validation-1407", "mrqa_squad-validation-1441", "mrqa_squad-validation-1512", "mrqa_squad-validation-1583", "mrqa_squad-validation-1662", "mrqa_squad-validation-192", "mrqa_squad-validation-1955", "mrqa_squad-validation-2059", "mrqa_squad-validation-2365", "mrqa_squad-validation-245", "mrqa_squad-validation-2748", "mrqa_squad-validation-275", "mrqa_squad-validation-2857", "mrqa_squad-validation-2893", "mrqa_squad-validation-2920", "mrqa_squad-validation-2932", "mrqa_squad-validation-2942", "mrqa_squad-validation-3222", "mrqa_squad-validation-3493", "mrqa_squad-validation-3551", "mrqa_squad-validation-3663", "mrqa_squad-validation-4001", "mrqa_squad-validation-4162", "mrqa_squad-validation-455", "mrqa_squad-validation-4797", "mrqa_squad-validation-4908", "mrqa_squad-validation-5003", "mrqa_squad-validation-5029", "mrqa_squad-validation-5348", "mrqa_squad-validation-5470", "mrqa_squad-validation-5617", "mrqa_squad-validation-57", "mrqa_squad-validation-5730", "mrqa_squad-validation-5765", "mrqa_squad-validation-5956", "mrqa_squad-validation-5995", "mrqa_squad-validation-605", "mrqa_squad-validation-6334", "mrqa_squad-validation-6393", "mrqa_squad-validation-641", "mrqa_squad-validation-6546", "mrqa_squad-validation-6548", "mrqa_squad-validation-7051", "mrqa_squad-validation-7330", "mrqa_squad-validation-7338", "mrqa_squad-validation-763", "mrqa_squad-validation-7751", "mrqa_squad-validation-7836", "mrqa_squad-validation-7918", "mrqa_squad-validation-7958", "mrqa_squad-validation-8149", "mrqa_squad-validation-8403", "mrqa_squad-validation-8495", "mrqa_squad-validation-8575", "mrqa_squad-validation-883", "mrqa_squad-validation-8869", "mrqa_squad-validation-9110", "mrqa_squad-validation-9178", "mrqa_squad-validation-9298", "mrqa_squad-validation-9362", "mrqa_squad-validation-9365", "mrqa_squad-validation-9373", "mrqa_squad-validation-9528", "mrqa_squad-validation-9687", "mrqa_squad-validation-973", "mrqa_squad-validation-9940", "mrqa_triviaqa-validation-1055", "mrqa_triviaqa-validation-1315", "mrqa_triviaqa-validation-1358", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-1788", "mrqa_triviaqa-validation-1927", "mrqa_triviaqa-validation-2071", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2171", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-2251", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2458", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2858", "mrqa_triviaqa-validation-2963", "mrqa_triviaqa-validation-3090", "mrqa_triviaqa-validation-3168", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3626", "mrqa_triviaqa-validation-3790", "mrqa_triviaqa-validation-3815", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3905", "mrqa_triviaqa-validation-4255", "mrqa_triviaqa-validation-4412", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-495", "mrqa_triviaqa-validation-4952", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-6295", "mrqa_triviaqa-validation-6427", "mrqa_triviaqa-validation-6435", "mrqa_triviaqa-validation-6637", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-7029", "mrqa_triviaqa-validation-721", "mrqa_triviaqa-validation-7280", "mrqa_triviaqa-validation-7383", "mrqa_triviaqa-validation-7387", "mrqa_triviaqa-validation-79", "mrqa_triviaqa-validation-920"], "OKR": 0.900390625, "KG": 0.4984375, "before_eval_results": {"predictions": ["Chris Sarandon", "March 26, 1973", "Abanindranath Tagore", "scission", "Lagaan ( English : Taxation ; also called Lagaon : Once Upon a Time in India )", "Super Bowl XXXIX", "close quarters and poor hygiene", "September 2017", "Kanawha River", "12.65 m", "1820s", "customer's account", "D\u00e1in", "punk rock", "volcanic and sedimentary rock sequences ( magnetostratigraphy )", "as a prison from 1100 ( Ranulf Flambard ) until 1952 ( Kray twins ), although that was not its primary purpose", "Supreme Court of Canada", "July 1, 1923", "Qutab - ud - din Aibak", "October 2008", "4 January 2011", "Yul Brynner", "Khliehriat, West Jaintia Hills district, headquarter Jowai, East Khasi Hills district", "approximately 1,070 km ( 665 mi ) east - southeast of Cape Hatteras, North Carolina ; 1,236 km ( 768 mi ) south of Cape Sable Island, Nova Scotia ; and 1,578 km", "irsten Simone Vangsness", "Frankie Laine's `` I Believe ''", "between 1765 and 1783", "Iran, Pakistan, India, Nepal, Bhutan, Bangladesh and Sri Lanka", "2002 Tamil film Ramanaa", "RAF Coningsby in Lincolnshire", "the President", "De pictura", "more than 2,500 locations", "1919", "September 19, 1977", "Augustus Waters, an ex- basketball player and amputee", "Ferrari driver Sebastian Vettel", "Woods", "2018", "Speaker of the House of Representatives", "The couple will reconcile briefly in the final scene of the fourth season, though ( because of Shannen Doherty's departure )", "Lord's", "a mid-size four - wheel drive luxury SUVs", "Ingrid Bergman", "Malayalam", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Wabanaki Confederacy members Abenaki and Mi'kmaq, and Algonquin, Lenape, Ojibwa, Ottawa, Shawnee, and Wyandot", "terrestrial", "Jack ( Billy Bob Thornton ) and Jill ( Amy Sedaris )", "Austria - Hungary", "upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "eye", "Vietnam", "Rutger Hauer", "Canada", "Robert Jenrick", "Srinagar", "Jewish tradition", "the Dalai Lama's current \"middle way approach,\"", "San Simeon, California,", "Crawford", "Blue Ridge Mountains", "William", "electric currents and magnetic fields"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6697080453458812}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.8, 0.05882352941176471, 0.9090909090909091, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 1.0, 0.1, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4313725490196079, 0.896551724137931, 0.6666666666666666, 0.6666666666666665, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6250000000000001, 0.6666666666666666, 0.0, 1.0, 1.0, 0.47619047619047616, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.9142857142857143, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6009", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-3296", "mrqa_naturalquestions-validation-3118", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-6660", "mrqa_naturalquestions-validation-1446", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-52", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-2100", "mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-3491", "mrqa_naturalquestions-validation-8502", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-7605", "mrqa_triviaqa-validation-1122", "mrqa_hotpotqa-validation-2134", "mrqa_newsqa-validation-2266", "mrqa_newsqa-validation-477", "mrqa_hotpotqa-validation-820"], "SR": 0.484375, "CSR": 0.5543573943661972, "retrieved_ids": ["mrqa_squad-train-20758", "mrqa_squad-train-40181", "mrqa_squad-train-35792", "mrqa_squad-train-52494", "mrqa_squad-train-57808", "mrqa_squad-train-76005", "mrqa_squad-train-51480", "mrqa_squad-train-2196", "mrqa_squad-train-13391", "mrqa_squad-train-3166", "mrqa_squad-train-69247", "mrqa_squad-train-25246", "mrqa_squad-train-69732", "mrqa_squad-train-1879", "mrqa_squad-train-79811", "mrqa_squad-train-34051", "mrqa_squad-train-15030", "mrqa_squad-train-42235", "mrqa_squad-train-8593", "mrqa_squad-train-29914", "mrqa_squad-train-66562", "mrqa_squad-train-74383", "mrqa_squad-train-19467", "mrqa_squad-train-37880", "mrqa_squad-train-13274", "mrqa_squad-train-70359", "mrqa_squad-train-6437", "mrqa_squad-train-5998", "mrqa_squad-train-53245", "mrqa_squad-train-7796", "mrqa_squad-train-77235", "mrqa_squad-train-53717", "mrqa_triviaqa-validation-6972", "mrqa_searchqa-validation-3932", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-10218", "mrqa_newsqa-validation-3534", "mrqa_naturalquestions-validation-7489", "mrqa_newsqa-validation-3493", "mrqa_searchqa-validation-16912", "mrqa_squad-validation-2919", "mrqa_hotpotqa-validation-4560", "mrqa_newsqa-validation-1963", "mrqa_searchqa-validation-11495", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-10565", "mrqa_newsqa-validation-3120", "mrqa_naturalquestions-validation-4930", "mrqa_newsqa-validation-1245", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-9054", "mrqa_naturalquestions-validation-1784", "mrqa_triviaqa-validation-2265", "mrqa_hotpotqa-validation-3362", "mrqa_hotpotqa-validation-1810", "mrqa_searchqa-validation-8360", "mrqa_newsqa-validation-3543", "mrqa_searchqa-validation-6372", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-2945", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-6453", "mrqa_triviaqa-validation-4363", "mrqa_searchqa-validation-5963"], "EFR": 0.7272727272727273, "Overall": 0.696638524327785}, {"timecode": 71, "before_eval_results": {"predictions": ["William Wyler", "Megyn Price", "Pepsi Super Bowl LII", "the following day", "Labour Party", "Judi Dench", "after a scuffle with the Beast Folk", "six degrees of freedom", "Spanish moss", "Matt Monro", "1990", "Friedman Billings Ramsey", "PC2, a type II endoprotease, cleaves the C peptide - A chain bond", "drivers who were Daytona Pole Award winners, former Daytona 500 pole winners who competed full - time in 2017, and drivers who qualified for the 2017 Playoffs are eligible", "Charles Carroll", "1959", "indigenous to many forested parts of the world", "Hermia", "in and around an unnamed village, later established in An Acceptable Time as being in Connecticut", "MercyMe", "Lagaan ( English : Taxation ; also called Lagaon : Once Upon a Time in India )", "Super Bowl XIX", "2007", "Toto", "V\u1e5bksayurveda", "the 15th century", "Hasmukh Adhia", "16.5 quadrillion BTUs", "Lorazepam", "April 1, 2016", "its absolute temperature", "electron donors", "April 26, 2005", "Russia", "rapid destruction of the donor red blood cells by host antibodies ( IgG, IgM )", "1994", "the 15th day of the first calendar month", "Phosphorus pentoxide", "a cake or biscuit", "1886", "a violation of nature and the resulting psychological effects on the mariner and on all those who hear him", "Ray Harroun", "Ethel Robinson", "Bonnie Aarons", "Fusajiro Yamauchi", "Manchuria", "Henry Purcell", "the pulmonary arteries", "Steve Russell", "2016", "1799", "Celtic", "Zachary Taylor", "Oscar Wilde", "S7", "The New Yorker", "Citgo Petroleum Corporation", "school in South Africa", "The e-mails", "Rolling Stone", "nuggets", "Mr. Smith Goes to Washington", "Fergie", "Forrest Gump"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7017415104997342}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, false, true, false, false, false, true, true, false, false, false, false, true, false, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5263157894736842, 0.4, 1.0, 1.0, 0.25, 1.0, 0.0, 0.5789473684210525, 0.6666666666666666, 1.0, 1.0, 0.0, 0.13333333333333333, 0.0, 0.9090909090909091, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.2222222222222222, 1.0, 0.16666666666666666, 0.0, 0.3157894736842105, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6618", "mrqa_naturalquestions-validation-894", "mrqa_naturalquestions-validation-7906", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-4190", "mrqa_naturalquestions-validation-9149", "mrqa_naturalquestions-validation-4196", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-3095", "mrqa_naturalquestions-validation-7963", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-6272", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-2210", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-6612", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-3298", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-5766", "mrqa_searchqa-validation-10641"], "SR": 0.59375, "CSR": 0.5549045138888888, "retrieved_ids": ["mrqa_squad-train-34724", "mrqa_squad-train-38447", "mrqa_squad-train-56878", "mrqa_squad-train-27551", "mrqa_squad-train-62365", "mrqa_squad-train-14170", "mrqa_squad-train-20600", "mrqa_squad-train-44270", "mrqa_squad-train-28596", "mrqa_squad-train-78919", "mrqa_squad-train-66796", "mrqa_squad-train-21296", "mrqa_squad-train-56183", "mrqa_squad-train-60272", "mrqa_squad-train-33475", "mrqa_squad-train-43041", "mrqa_squad-train-43852", "mrqa_squad-train-33008", "mrqa_squad-train-23971", "mrqa_squad-train-61343", "mrqa_squad-train-16170", "mrqa_squad-train-75988", "mrqa_squad-train-51435", "mrqa_squad-train-61463", "mrqa_squad-train-30422", "mrqa_squad-train-8052", "mrqa_squad-train-59140", "mrqa_squad-train-41046", "mrqa_squad-train-26814", "mrqa_squad-train-82454", "mrqa_squad-train-21187", "mrqa_squad-train-65244", "mrqa_searchqa-validation-6041", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1150", "mrqa_hotpotqa-validation-761", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1392", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-1990", "mrqa_naturalquestions-validation-4495", "mrqa_triviaqa-validation-3110", "mrqa_naturalquestions-validation-754", "mrqa_newsqa-validation-2811", "mrqa_naturalquestions-validation-1930", "mrqa_triviaqa-validation-7334", "mrqa_newsqa-validation-2207", "mrqa_squad-validation-8597", "mrqa_newsqa-validation-3964", "mrqa_searchqa-validation-3267", "mrqa_searchqa-validation-86", "mrqa_naturalquestions-validation-746", "mrqa_newsqa-validation-1641", "mrqa_searchqa-validation-11207", "mrqa_searchqa-validation-16912", "mrqa_hotpotqa-validation-5394", "mrqa_searchqa-validation-10103", "mrqa_naturalquestions-validation-4200", "mrqa_squad-validation-8558", "mrqa_newsqa-validation-2773", "mrqa_newsqa-validation-3863", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-1430", "mrqa_newsqa-validation-2520"], "EFR": 0.8846153846153846, "Overall": 0.7282164797008547}, {"timecode": 72, "before_eval_results": {"predictions": ["pigs", "Edward Furlong", "Toby Keith", "General George Washington", "architect Louis Le Vau", "Ed", "15 February 1998", "Diego Tinoco", "Bart Millard", "1978", "Vasoepididymostomy", "Jonathan Harris", "Paul Lynde", "14", "President Lyndon Johnson", "16 seasons", "the government - owned Panama Canal Authority", "First Lieutenant Israel Greene", "the nucleus", "Coroebus of Elis", "Carol Worthington", "the 17th episode in the third season", "the Kansas City Chiefs", "Yuzuru Hanyu", "Owen Hunt ( Kevin McKidd )", "Ceramic", "February 26, 2018", "Iran", "The alveolar process", "Middlesex County, Province of Massachusetts Bay", "Representatives", "Lisa Stelly", "Ali", "Meg Optimus", "Rachel Kelly Tucker", "1881", "pneumonoultramicroscopicsilicovolcanoconiosis", "on location", "the New Jersey Devils of the National Hockey League ( NHL ) and the Seton Hall Pirates", "Season 6", "perhaps most common in Australia, but can occur at tropical and subtropical latitudes from the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "Scott Schwartz", "Empire of Japan", "Djokovic", "won gold in the half - pipe", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins", "2002", "a 14 - year - old girl who falls in love with Robbie and tries to get him to be her boyfriend throughout the film", "Incudomalleolar joint ( more correctly called incudomallear joint ) or articulatio incudomlearis", "London, United Kingdom", "the Attorney General", "rack of lamb", "Ross MacManus", "York", "Hamburger Sport-Verein e.V.", "2", "Los Angeles Dance Theater", "100 meter", "President Sheikh Sharif Sheikh Ahmed", "Brooklyn, New York,", "Suntory", "Victoria", "a yoke", "Funcom"], "metric_results": {"EM": 0.640625, "QA-F1": 0.734863782051282}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3846153846153846, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.4799999999999999, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 1.0, 0.0, 0.9, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-4315", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-1567", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-3569", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-5292", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-4784", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-2333", "mrqa_hotpotqa-validation-1572", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-1335", "mrqa_searchqa-validation-13611", "mrqa_hotpotqa-validation-1074"], "SR": 0.640625, "CSR": 0.5560787671232876, "retrieved_ids": ["mrqa_squad-train-37401", "mrqa_squad-train-1201", "mrqa_squad-train-2145", "mrqa_squad-train-15372", "mrqa_squad-train-28115", "mrqa_squad-train-71621", "mrqa_squad-train-83081", "mrqa_squad-train-48175", "mrqa_squad-train-58580", "mrqa_squad-train-4793", "mrqa_squad-train-50015", "mrqa_squad-train-14293", "mrqa_squad-train-22725", "mrqa_squad-train-17654", "mrqa_squad-train-50586", "mrqa_squad-train-58048", "mrqa_squad-train-6953", "mrqa_squad-train-69511", "mrqa_squad-train-5356", "mrqa_squad-train-16988", "mrqa_squad-train-12418", "mrqa_squad-train-53052", "mrqa_squad-train-59653", "mrqa_squad-train-22916", "mrqa_squad-train-12164", "mrqa_squad-train-22658", "mrqa_squad-train-17316", "mrqa_squad-train-60078", "mrqa_squad-train-57518", "mrqa_squad-train-83208", "mrqa_squad-train-6403", "mrqa_squad-train-49831", "mrqa_squad-validation-2289", "mrqa_newsqa-validation-1522", "mrqa_naturalquestions-validation-7356", "mrqa_newsqa-validation-1397", "mrqa_naturalquestions-validation-1198", "mrqa_newsqa-validation-1840", "mrqa_naturalquestions-validation-1784", "mrqa_searchqa-validation-6638", "mrqa_newsqa-validation-401", "mrqa_naturalquestions-validation-2399", "mrqa_newsqa-validation-2471", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-5096", "mrqa_newsqa-validation-2497", "mrqa_searchqa-validation-16971", "mrqa_newsqa-validation-3187", "mrqa_triviaqa-validation-2101", "mrqa_newsqa-validation-1519", "mrqa_naturalquestions-validation-327", "mrqa_newsqa-validation-1988", "mrqa_newsqa-validation-4113", "mrqa_naturalquestions-validation-10410", "mrqa_searchqa-validation-4753", "mrqa_hotpotqa-validation-2323", "mrqa_naturalquestions-validation-9007", "mrqa_newsqa-validation-2640", "mrqa_searchqa-validation-1088", "mrqa_naturalquestions-validation-3922", "mrqa_searchqa-validation-16912", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-2085", "mrqa_newsqa-validation-4147"], "EFR": 0.8260869565217391, "Overall": 0.7167456447290054}, {"timecode": 73, "before_eval_results": {"predictions": ["Robin", "January 2018", "Patrick Swayze", "Martin Lawrence", "revenge and karma", "October 1986", "Disha Vakani", "the efferent nerves that directly innervate muscles", "Johannes Gutenberg", "Shawn Wayans", "federal republic", "regulatory site", "3", "the Baltic Fleet", "Woodrow Wilson", "Jeff East", "Terry Reid", "Brazil", "March 31 to April 8, 2018", "military units from their parent countries of Great Britain and France, as well as by American Indian allies", "radius R of the turntable", "the Royal Air Force ( RAF ) defended the United Kingdom ( UK ) against large - scale attacks by Nazi Germany's air force, the Luftwaffe", "1945", "Alex Drake", "April 12, 2017", "post translational modification", "1960", "Congress in 1790 passed the first naturalization law for the United States, the Naturalization Act of 1790", "September 6, 2019", "Bulgaria", "Michael Douglas", "Coldplay with special guest performers Beyonc\u00e9 and Bruno Mars", "save, rescue, savior", "1983", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W \ufeff / \ufefb\ufffd 26.617 \u00b0 N 81.519", "Werner Ruchti", "Brooklyn, New York", "the British singer - songwriter Chris Rea", "Julie Adams", "pneumonoultramicroscopicsilicovolcanoconiosis", "2010", "the king's army", "Mary Elizabeth ( Margaret Hoard )", "Michelangelo", "1,350", "Uruguay", "to ordain presbyters / bishops and to exercise general oversight", "all the world's a stage", "2002", "Anna Faris", "Cress", "montreal", "her uncle, William IV", "Gerald Ford Jr.", "South Korea's 63 Building", "Tata Consultancy Services in Kochi", "Corendon Dutch Airlines", "Jenny Sanford,", "to alert patients of possible tendon ruptures and tendonitis.", "a particular health ailment or beauty concern.", "Herbert Hoover", "the Queen of England", "a compound", "Pearl Jam"], "metric_results": {"EM": 0.578125, "QA-F1": 0.690005888719124}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, true, false, false, false, false, false, false, true, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0909090909090909, 0.0, 0.19999999999999998, 1.0, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.823529411764706, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-9896", "mrqa_naturalquestions-validation-3373", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-681", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-10009", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-5980", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-1910", "mrqa_triviaqa-validation-3448", "mrqa_triviaqa-validation-6593", "mrqa_triviaqa-validation-5000", "mrqa_hotpotqa-validation-189", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-1640", "mrqa_searchqa-validation-1415", "mrqa_searchqa-validation-15202"], "SR": 0.578125, "CSR": 0.5563766891891893, "retrieved_ids": ["mrqa_squad-train-28877", "mrqa_squad-train-48139", "mrqa_squad-train-10184", "mrqa_squad-train-56903", "mrqa_squad-train-22056", "mrqa_squad-train-65998", "mrqa_squad-train-17035", "mrqa_squad-train-5112", "mrqa_squad-train-23426", "mrqa_squad-train-81660", "mrqa_squad-train-27922", "mrqa_squad-train-24451", "mrqa_squad-train-74134", "mrqa_squad-train-33862", "mrqa_squad-train-72443", "mrqa_squad-train-43066", "mrqa_squad-train-77267", "mrqa_squad-train-46505", "mrqa_squad-train-38573", "mrqa_squad-train-31968", "mrqa_squad-train-37002", "mrqa_squad-train-59182", "mrqa_squad-train-81253", "mrqa_squad-train-58030", "mrqa_squad-train-58912", "mrqa_squad-train-47039", "mrqa_squad-train-39149", "mrqa_squad-train-71315", "mrqa_squad-train-47954", "mrqa_squad-train-25992", "mrqa_squad-train-38589", "mrqa_squad-train-5075", "mrqa_newsqa-validation-3201", "mrqa_searchqa-validation-10964", "mrqa_newsqa-validation-3011", "mrqa_triviaqa-validation-7151", "mrqa_naturalquestions-validation-10684", "mrqa_squad-validation-1841", "mrqa_newsqa-validation-3187", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-1181", "mrqa_squad-validation-10061", "mrqa_searchqa-validation-5539", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-6363", "mrqa_naturalquestions-validation-1433", "mrqa_newsqa-validation-1123", "mrqa_naturalquestions-validation-930", "mrqa_searchqa-validation-16816", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-1146", "mrqa_naturalquestions-validation-2605", "mrqa_searchqa-validation-11770", "mrqa_naturalquestions-validation-9457", "mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-1206", "mrqa_newsqa-validation-1598", "mrqa_naturalquestions-validation-8999", "mrqa_newsqa-validation-2947", "mrqa_searchqa-validation-10641", "mrqa_searchqa-validation-6815", "mrqa_naturalquestions-validation-5185", "mrqa_newsqa-validation-1833", "mrqa_newsqa-validation-4107"], "EFR": 0.7407407407407407, "Overall": 0.699735985985986}, {"timecode": 74, "before_eval_results": {"predictions": ["the Lgion d'honneur", "Shaft", "\" Kinetic warfare.\"", "Berenice", "pharaoh", "Tony Dungy", "the Rolling Stones", "ancora", "chili", "a cell", "universal and equal suffrage", "60", "the Enigma", "a twister", "a daytime peformance", "\"Elaine the fair maid of Astolat\"", "Laryngitis", "a black bear", "terraces", "a voodoo sorcerer", "Aquiline", "Hair", "a cozy", "Jalisco", "Davenport", "Sammy Sosa", "Maruti Suzuki", "one billion", "the green-eyed monster", "Mount Olympus", "haematoma", "Death", "a Coral snake", "General William Tecumseh Sherman", "Fess Parker", "a duvet", "Baltimore", "a crayfish", "Japan", "liberty", "the African Union", "William Wrigley Jr.", "Nepal", "the United States Department of Agriculture", "cat scratch fever", "freezing", "\"A Season in Purgatory\"", "a kangaroo court", "Whatchamacallit", "Little Richard", "Fantasy Island", "pigs", "between the Eastern Ghats and the Bay of Bengal", "the oneness of the body, the church, through what Christians have in common, what they have communion in", "benjamin franklin", "Sororicide", "saint aidan", "Sulla", "Switzerland", "Parlophone Records", "keyboardist and", "150", "mental health", "the contestant"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6085601478494623}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, true, true, false, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.8, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.06451612903225806]}}, "before_error_ids": ["mrqa_searchqa-validation-4470", "mrqa_searchqa-validation-8929", "mrqa_searchqa-validation-1276", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-10139", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-13908", "mrqa_searchqa-validation-11800", "mrqa_searchqa-validation-8349", "mrqa_searchqa-validation-16892", "mrqa_searchqa-validation-1795", "mrqa_searchqa-validation-10777", "mrqa_searchqa-validation-3405", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-13780", "mrqa_searchqa-validation-11657", "mrqa_searchqa-validation-14672", "mrqa_searchqa-validation-8248", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-6289", "mrqa_searchqa-validation-1214", "mrqa_searchqa-validation-7585", "mrqa_searchqa-validation-10978", "mrqa_searchqa-validation-15977", "mrqa_searchqa-validation-5900", "mrqa_searchqa-validation-14189", "mrqa_triviaqa-validation-1931", "mrqa_naturalquestions-validation-5636"], "SR": 0.546875, "CSR": 0.55625, "retrieved_ids": ["mrqa_squad-train-22241", "mrqa_squad-train-14144", "mrqa_squad-train-21050", "mrqa_squad-train-33389", "mrqa_squad-train-32709", "mrqa_squad-train-7958", "mrqa_squad-train-7290", "mrqa_squad-train-80802", "mrqa_squad-train-32615", "mrqa_squad-train-71331", "mrqa_squad-train-27308", "mrqa_squad-train-30154", "mrqa_squad-train-36176", "mrqa_squad-train-22071", "mrqa_squad-train-9814", "mrqa_squad-train-35583", "mrqa_squad-train-48079", "mrqa_squad-train-13001", "mrqa_squad-train-51284", "mrqa_squad-train-67774", "mrqa_squad-train-78016", "mrqa_squad-train-7806", "mrqa_squad-train-19250", "mrqa_squad-train-69274", "mrqa_squad-train-66609", "mrqa_squad-train-53376", "mrqa_squad-train-74464", "mrqa_squad-train-52193", "mrqa_squad-train-63482", "mrqa_squad-train-69308", "mrqa_squad-train-58175", "mrqa_squad-train-43061", "mrqa_naturalquestions-validation-387", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-2317", "mrqa_hotpotqa-validation-1298", "mrqa_newsqa-validation-2563", "mrqa_squad-validation-3355", "mrqa_searchqa-validation-5510", "mrqa_searchqa-validation-8582", "mrqa_newsqa-validation-1699", "mrqa_triviaqa-validation-79", "mrqa_newsqa-validation-4211", "mrqa_newsqa-validation-1295", "mrqa_naturalquestions-validation-9824", "mrqa_squad-validation-6319", "mrqa_triviaqa-validation-3715", "mrqa_searchqa-validation-3216", "mrqa_newsqa-validation-990", "mrqa_newsqa-validation-1331", "mrqa_naturalquestions-validation-5942", "mrqa_naturalquestions-validation-5512", "mrqa_hotpotqa-validation-4791", "mrqa_naturalquestions-validation-4338", "mrqa_naturalquestions-validation-7165", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-3666", "mrqa_naturalquestions-validation-4196", "mrqa_newsqa-validation-1688", "mrqa_searchqa-validation-13852", "mrqa_searchqa-validation-13077", "mrqa_naturalquestions-validation-8412", "mrqa_newsqa-validation-619", "mrqa_triviaqa-validation-7233"], "EFR": 0.9310344827586207, "Overall": 0.7377693965517241}, {"timecode": 75, "before_eval_results": {"predictions": ["8 Mile", "paul newman", "Louisiana", "a clapper", "Tombs of Kobol", "A Tale Told By an Idiot", "a pancetta", "six days", "Cosmo Kramer", "Poetic Justice", "the guillitine", "the Colossus of Rhodes", "Hugh Jackman", "silver", "Lebanon", "the eagle", "The Communist Party of China", "Larry King", "King Claudius", "Mussolini", "Margot Fonteyn", "Alfred Nobel", "lifejackets", "adverb", "General Mills", "Emmitt Smith", "clay", "a black hole", "Uganda", "Department on Agriculture", "Heisenberg", "Sin City", "David Hyde Pierce", "1060 - 13-LETTER WORDS - TriviaBistro", "Old North Church", "spinal column", "Red Bull", "the Jolly Roger", "the North West Territories", "Alaska", "the Electric Company", "Vienna", "(Trumbull) Pop Warner", "Red", "a waxy coating", "Ellen Wilson", "Esau", "skull", "Agatha Christie", "Ronald Reagan", "Ford Motor Co.", "1947", "Moira Kelly", "Zoe", "Mt Kenya", "Christian Wulff", "Mata Hari", "Princess Aisha bint Hussein", "French", "Oxford", "Kaka", "133", "Gunther von Hagens", "Minnesota"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6362580128205129}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-666", "mrqa_searchqa-validation-4053", "mrqa_searchqa-validation-14575", "mrqa_searchqa-validation-6199", "mrqa_searchqa-validation-3276", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-452", "mrqa_searchqa-validation-15327", "mrqa_searchqa-validation-16240", "mrqa_searchqa-validation-4447", "mrqa_searchqa-validation-11404", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-2164", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-4211", "mrqa_searchqa-validation-3739", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-5450", "mrqa_searchqa-validation-14546", "mrqa_searchqa-validation-11498", "mrqa_searchqa-validation-4191", "mrqa_searchqa-validation-7703", "mrqa_searchqa-validation-6857", "mrqa_naturalquestions-validation-8847", "mrqa_triviaqa-validation-5309", "mrqa_hotpotqa-validation-4950", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-3364"], "SR": 0.546875, "CSR": 0.556126644736842, "retrieved_ids": ["mrqa_squad-train-79905", "mrqa_squad-train-22868", "mrqa_squad-train-80659", "mrqa_squad-train-1857", "mrqa_squad-train-14852", "mrqa_squad-train-68021", "mrqa_squad-train-28982", "mrqa_squad-train-6132", "mrqa_squad-train-32142", "mrqa_squad-train-10040", "mrqa_squad-train-4612", "mrqa_squad-train-55580", "mrqa_squad-train-63211", "mrqa_squad-train-27561", "mrqa_squad-train-12391", "mrqa_squad-train-73452", "mrqa_squad-train-20212", "mrqa_squad-train-9361", "mrqa_squad-train-40394", "mrqa_squad-train-34164", "mrqa_squad-train-62304", "mrqa_squad-train-27410", "mrqa_squad-train-43379", "mrqa_squad-train-27448", "mrqa_squad-train-62688", "mrqa_squad-train-62713", "mrqa_squad-train-67111", "mrqa_squad-train-4747", "mrqa_squad-train-58028", "mrqa_squad-train-72191", "mrqa_squad-train-21410", "mrqa_squad-train-51645", "mrqa_searchqa-validation-4246", "mrqa_hotpotqa-validation-3729", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-1704", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-1334", "mrqa_triviaqa-validation-3824", "mrqa_naturalquestions-validation-1802", "mrqa_newsqa-validation-2389", "mrqa_naturalquestions-validation-2605", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1339", "mrqa_newsqa-validation-3370", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-2098", "mrqa_hotpotqa-validation-3949", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-3686", "mrqa_naturalquestions-validation-4930", "mrqa_newsqa-validation-2773", "mrqa_newsqa-validation-4211", "mrqa_newsqa-validation-3060", "mrqa_searchqa-validation-1615", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-7006", "mrqa_naturalquestions-validation-3474", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-1635", "mrqa_naturalquestions-validation-3707"], "EFR": 0.6896551724137931, "Overall": 0.689468863430127}, {"timecode": 76, "before_eval_results": {"predictions": ["diabetes", "Wynton Marsalis", "the Treasury", "Montserrat", "a cyclone", "Starland Vocal Band", "the gallows", "ohm", "Bookshelf: 100 Must-Reads For Kids 9-14", "earthquakes", "the Potomac", "Indiana", "Mary Stuart", "Hulk Hogan", "air pressure", "Russia", "Adam Sandler", "Ted Koppel", "Melissa Etheridge", "Macbeth", "Erin Go Bragh", "Lake Victoria", "Thanksgiving", "Wool Sack dress", "Don't Worry, Be Happy", "Bethlehem Steel", "Capitol Hill", "a glider", "a heart", "Guyana", "jelly", "camels", "drought", "a truth known by actual experience or observation; something known to be true", "Jonathan Winters", "Pink", "Rhode Island", "Isaac Newton", "Malawi", "Joseph Smith", "Theodore Roosevelt", "gold", "Joshua", "Jamestown", "Lignite", "Seymour Cray", "Private Practice", "corticosteroids", "Georgetown", "cinnamon", "Beowulf", "Experimental neuropsychology", "pigs", "Nickelback", "Neptune", "Scotland", "yellow", "chalk quarry", "SBS", "Ezo", "Tomas Olsson,", "71 percent of Americans consider China an economic threat to the United States,", "Appathurai", "Benzodiazepines"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8338541666666668}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5641", "mrqa_searchqa-validation-11726", "mrqa_searchqa-validation-4666", "mrqa_searchqa-validation-16031", "mrqa_searchqa-validation-11245", "mrqa_searchqa-validation-15538", "mrqa_searchqa-validation-4499", "mrqa_searchqa-validation-8386", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-15581", "mrqa_naturalquestions-validation-9959", "mrqa_naturalquestions-validation-7095", "mrqa_triviaqa-validation-7732", "mrqa_hotpotqa-validation-512"], "SR": 0.78125, "CSR": 0.5590503246753247, "retrieved_ids": ["mrqa_squad-train-50017", "mrqa_squad-train-34005", "mrqa_squad-train-10515", "mrqa_squad-train-56558", "mrqa_squad-train-12012", "mrqa_squad-train-61685", "mrqa_squad-train-65032", "mrqa_squad-train-6923", "mrqa_squad-train-55987", "mrqa_squad-train-56798", "mrqa_squad-train-35872", "mrqa_squad-train-61609", "mrqa_squad-train-37425", "mrqa_squad-train-63718", "mrqa_squad-train-65488", "mrqa_squad-train-21130", "mrqa_squad-train-34523", "mrqa_squad-train-9977", "mrqa_squad-train-67413", "mrqa_squad-train-74011", "mrqa_squad-train-548", "mrqa_squad-train-77392", "mrqa_squad-train-2622", "mrqa_squad-train-71063", "mrqa_squad-train-37301", "mrqa_squad-train-54802", "mrqa_squad-train-73768", "mrqa_squad-train-51004", "mrqa_squad-train-82313", "mrqa_squad-train-72677", "mrqa_squad-train-67975", "mrqa_squad-train-59652", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1963", "mrqa_triviaqa-validation-6827", "mrqa_searchqa-validation-7010", "mrqa_naturalquestions-validation-4083", "mrqa_hotpotqa-validation-5444", "mrqa_newsqa-validation-1606", "mrqa_squad-validation-7535", "mrqa_searchqa-validation-1512", "mrqa_newsqa-validation-3049", "mrqa_naturalquestions-validation-9675", "mrqa_newsqa-validation-1330", "mrqa_naturalquestions-validation-4674", "mrqa_naturalquestions-validation-4540", "mrqa_newsqa-validation-817", "mrqa_newsqa-validation-2959", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-820", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-2578", "mrqa_newsqa-validation-4003", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-1640", "mrqa_searchqa-validation-13753", "mrqa_naturalquestions-validation-7206", "mrqa_searchqa-validation-3222", "mrqa_newsqa-validation-2266", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-2935", "mrqa_newsqa-validation-647"], "EFR": 0.7857142857142857, "Overall": 0.7092654220779221}, {"timecode": 77, "before_eval_results": {"predictions": ["Charles Darwin", "the Inuit", "Bologna", "the Kid", "Rudyard Kipling", "Frasier", "Tarzan of the Apes", "Edward VI", "Leon Trotsky", "Flanders", "Sister Wendy", "1066", "ibuprofen", "the vrijbuiter", "George Washington Carver", "the Bulldog Drummond", "Spooky Salem", "the Tigris", "the Baltic Sea", "no contest", "gum", "Abel", "Louis XV", "Wayne Gretzky", "Anna Karenina", "Sacramento", "the Cordillera Real", "jury dutyserve", "dreams", "Pantaloons", "Confucius", "Paul Newman", "Harry S. Truman", "the champagne flutes", "Rhode Island", "The Simple Life", "Laos", "Agent Orange", "the Philippines", "Kellogg\\'s", "the Backstreet Boys", "Luxor", "Latin", "Venus", "the Hawthorne", "the Congo", "Charles VII", "Horatio Nelson,", "a crocodilian", "Ferrari", "the iris", "John Adams", "1886", "Ali", "tahrir Square", "1914", "Hedonismbot", "ESPN College Football Friday Primetime", "R&B vocal group", "Memphis Minnie", "protective shoes", "Diego Maradona", "Transportation Security Administration", "silver"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6473214285714285}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.8571428571428571, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13301", "mrqa_searchqa-validation-918", "mrqa_searchqa-validation-16268", "mrqa_searchqa-validation-7162", "mrqa_searchqa-validation-7050", "mrqa_searchqa-validation-7622", "mrqa_searchqa-validation-4009", "mrqa_searchqa-validation-3332", "mrqa_searchqa-validation-13555", "mrqa_searchqa-validation-9720", "mrqa_searchqa-validation-1015", "mrqa_searchqa-validation-8387", "mrqa_searchqa-validation-3756", "mrqa_searchqa-validation-14127", "mrqa_searchqa-validation-13821", "mrqa_searchqa-validation-9986", "mrqa_searchqa-validation-11373", "mrqa_searchqa-validation-3569", "mrqa_searchqa-validation-2767", "mrqa_searchqa-validation-11688", "mrqa_searchqa-validation-4548", "mrqa_searchqa-validation-3357", "mrqa_searchqa-validation-7197", "mrqa_searchqa-validation-337", "mrqa_naturalquestions-validation-4737", "mrqa_naturalquestions-validation-5637", "mrqa_triviaqa-validation-4756", "mrqa_triviaqa-validation-4449", "mrqa_hotpotqa-validation-3307", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5319"], "SR": 0.515625, "CSR": 0.5584935897435898, "retrieved_ids": ["mrqa_squad-train-85907", "mrqa_squad-train-23178", "mrqa_squad-train-24626", "mrqa_squad-train-68538", "mrqa_squad-train-40756", "mrqa_squad-train-60278", "mrqa_squad-train-32243", "mrqa_squad-train-81327", "mrqa_squad-train-24275", "mrqa_squad-train-25910", "mrqa_squad-train-2794", "mrqa_squad-train-1586", "mrqa_squad-train-83929", "mrqa_squad-train-64900", "mrqa_squad-train-11888", "mrqa_squad-train-24614", "mrqa_squad-train-14118", "mrqa_squad-train-46596", "mrqa_squad-train-28108", "mrqa_squad-train-70123", "mrqa_squad-train-3917", "mrqa_squad-train-78789", "mrqa_squad-train-54952", "mrqa_squad-train-39337", "mrqa_squad-train-30727", "mrqa_squad-train-26738", "mrqa_squad-train-71236", "mrqa_squad-train-51448", "mrqa_squad-train-59224", "mrqa_squad-train-36183", "mrqa_squad-train-74251", "mrqa_squad-train-46348", "mrqa_triviaqa-validation-3448", "mrqa_naturalquestions-validation-2605", "mrqa_triviaqa-validation-3450", "mrqa_naturalquestions-validation-2100", "mrqa_newsqa-validation-1216", "mrqa_triviaqa-validation-5038", "mrqa_newsqa-validation-2927", "mrqa_searchqa-validation-4320", "mrqa_searchqa-validation-2617", "mrqa_squad-validation-10011", "mrqa_newsqa-validation-3469", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-2690", "mrqa_naturalquestions-validation-6252", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-9275", "mrqa_newsqa-validation-1778", "mrqa_squad-validation-10506", "mrqa_searchqa-validation-8752", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-3187", "mrqa_searchqa-validation-13556", "mrqa_naturalquestions-validation-8733", "mrqa_searchqa-validation-9725", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-3597", "mrqa_squad-validation-3130", "mrqa_searchqa-validation-13077", "mrqa_searchqa-validation-11770"], "EFR": 0.7419354838709677, "Overall": 0.7003983147229115}, {"timecode": 78, "before_eval_results": {"predictions": ["Romulus", "March", "Eve", "The Firm", "Schwalbe", "circumnavigate", "Marilyn Monroe", "Cheddar", "a comet", "wings", "Enigma", "surface-to-air missile", "an igloo", "Phobos", "a dermatologist", "Kramer vs. Kramer", "The Tempest", "yellow", "Annie", "rubber", "Schwarzenegger", "Lafayette", "John Bayley", "Ironman", "Kamba", "the NHL", "florals", "a chestnut", "Ramesses II", "Scheherazade", "Scott McClellan", "Jeremiah", "Thomas Edison", "A Chorus Line", "Guadalajara", "Sydney", "flavor", "Dutchman", "Gideon", "the Alamo", "oats", "Zlatan Ibrahimovic", "Pell grants", "Rush", "being buried alive", "Swan", "Kansas Jayhawks", "Helsinki", "a kidney", "One Flew Over the Cuckoo's Nest", "the Nobel Prize", "non-ferrous", "Brooke Wexler", "Rosalind Bailey", "Standard Motor Company", "Portugal", "cooperative", "Double Agent", "#5", "Madeleine L'Engle", "Almost all British troops", "three", "$3 billion,", "Tom Ewell"], "metric_results": {"EM": 0.609375, "QA-F1": 0.675}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true], "QA-F1": [0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15817", "mrqa_searchqa-validation-4600", "mrqa_searchqa-validation-11859", "mrqa_searchqa-validation-133", "mrqa_searchqa-validation-11927", "mrqa_searchqa-validation-11559", "mrqa_searchqa-validation-1169", "mrqa_searchqa-validation-1026", "mrqa_searchqa-validation-8426", "mrqa_searchqa-validation-4421", "mrqa_searchqa-validation-2707", "mrqa_searchqa-validation-3174", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-938", "mrqa_searchqa-validation-948", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-1167", "mrqa_searchqa-validation-8681", "mrqa_searchqa-validation-7017", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-8766", "mrqa_triviaqa-validation-5933", "mrqa_hotpotqa-validation-2678", "mrqa_newsqa-validation-1259", "mrqa_newsqa-validation-3010"], "SR": 0.609375, "CSR": 0.5591376582278481, "retrieved_ids": ["mrqa_squad-train-15140", "mrqa_squad-train-60876", "mrqa_squad-train-35669", "mrqa_squad-train-52961", "mrqa_squad-train-24318", "mrqa_squad-train-35173", "mrqa_squad-train-5732", "mrqa_squad-train-34123", "mrqa_squad-train-23958", "mrqa_squad-train-44231", "mrqa_squad-train-75792", "mrqa_squad-train-80481", "mrqa_squad-train-844", "mrqa_squad-train-56557", "mrqa_squad-train-17548", "mrqa_squad-train-70596", "mrqa_squad-train-25521", "mrqa_squad-train-57484", "mrqa_squad-train-32791", "mrqa_squad-train-82392", "mrqa_squad-train-21113", "mrqa_squad-train-36837", "mrqa_squad-train-25561", "mrqa_squad-train-44151", "mrqa_squad-train-63597", "mrqa_squad-train-37473", "mrqa_squad-train-2059", "mrqa_squad-train-48536", "mrqa_squad-train-75090", "mrqa_squad-train-75409", "mrqa_squad-train-15961", "mrqa_squad-train-29196", "mrqa_triviaqa-validation-6277", "mrqa_newsqa-validation-1339", "mrqa_searchqa-validation-16917", "mrqa_newsqa-validation-3627", "mrqa_naturalquestions-validation-1195", "mrqa_searchqa-validation-11726", "mrqa_triviaqa-validation-3868", "mrqa_naturalquestions-validation-5185", "mrqa_newsqa-validation-1120", "mrqa_newsqa-validation-536", "mrqa_naturalquestions-validation-5951", "mrqa_searchqa-validation-11136", "mrqa_hotpotqa-validation-3070", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-2767", "mrqa_newsqa-validation-2634", "mrqa_naturalquestions-validation-538", "mrqa_newsqa-validation-3621", "mrqa_naturalquestions-validation-6612", "mrqa_hotpotqa-validation-4027", "mrqa_newsqa-validation-2298", "mrqa_searchqa-validation-2651", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-1878", "mrqa_squad-validation-7514", "mrqa_newsqa-validation-686", "mrqa_naturalquestions-validation-5579", "mrqa_searchqa-validation-7229", "mrqa_naturalquestions-validation-1975", "mrqa_newsqa-validation-232", "mrqa_newsqa-validation-4100", "mrqa_naturalquestions-validation-522"], "EFR": 0.44, "Overall": 0.6401400316455697}, {"timecode": 79, "before_eval_results": {"predictions": ["Wyandotte County", "New Zealand", "Peter the Rock", "mixed-breed", "New Zealand", "fontanels", "Southern California", "Nero", "the Dalmatians", "Cecil Day-Lewis", "cotton", "Bridget Fonda", "South Africa", "Punk", "the Mediterranean", "Catherine de' Medici", "potato pancakes", "the adder", "a puzzle", "the River Thames", "a scribe", "Pitcairn", "Adam Sandler", "Mayo", "\"You had me atHello\"", "arrested Development", "the Renaissance", "German", "Rodeo and Oklahoma", "repent", "Denzel Washington", "Bonn", "nougat", "Jeopary", "rani", "Tiffany", "Louise Birds", "conk", "Hillary Clinton", "globalization", "Van Halen", "the Rhine", "salt", "Samsonite L luggage", "chili", "salam", "Faraday", "pearls", "Norse", "Niagara Falls", "the Bronx", "the National Football League ( NFL ) for the Atlanta Falcons, the San Francisco 49ers, the Dallas Cowboys, the Washington Redskins and the Baltimore Steelers", "Ethel Merman", "Forbes Burnham", "Denmark", "Angus Deayton", "Spain", "Russian Ark", "The Walking Dead", "237 square miles", "over two decades.", "health-care", "14", "8th and 16th"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6371279761904762}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666665, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_searchqa-validation-6416", "mrqa_searchqa-validation-8092", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-3736", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-4188", "mrqa_searchqa-validation-12947", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-14384", "mrqa_searchqa-validation-5786", "mrqa_searchqa-validation-5794", "mrqa_searchqa-validation-10079", "mrqa_searchqa-validation-8379", "mrqa_searchqa-validation-10386", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-7343", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-16560", "mrqa_searchqa-validation-11283", "mrqa_searchqa-validation-15970", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-4080", "mrqa_searchqa-validation-2447", "mrqa_searchqa-validation-3297", "mrqa_searchqa-validation-13908", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-8019", "mrqa_naturalquestions-validation-4544", "mrqa_naturalquestions-validation-8433", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3765"], "SR": 0.484375, "CSR": 0.558203125, "retrieved_ids": ["mrqa_squad-train-78091", "mrqa_squad-train-71774", "mrqa_squad-train-23814", "mrqa_squad-train-8695", "mrqa_squad-train-56879", "mrqa_squad-train-26263", "mrqa_squad-train-54994", "mrqa_squad-train-46820", "mrqa_squad-train-4499", "mrqa_squad-train-76698", "mrqa_squad-train-77453", "mrqa_squad-train-37169", "mrqa_squad-train-2272", "mrqa_squad-train-58562", "mrqa_squad-train-8936", "mrqa_squad-train-28364", "mrqa_squad-train-76812", "mrqa_squad-train-72183", "mrqa_squad-train-70173", "mrqa_squad-train-37416", "mrqa_squad-train-83992", "mrqa_squad-train-33553", "mrqa_squad-train-85387", "mrqa_squad-train-43439", "mrqa_squad-train-42702", "mrqa_squad-train-2181", "mrqa_squad-train-4", "mrqa_squad-train-24832", "mrqa_squad-train-9508", "mrqa_squad-train-56464", "mrqa_squad-train-77174", "mrqa_squad-train-30560", "mrqa_newsqa-validation-629", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-8599", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-1303", "mrqa_newsqa-validation-3713", "mrqa_naturalquestions-validation-9284", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-9816", "mrqa_searchqa-validation-16911", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-205", "mrqa_newsqa-validation-1702", "mrqa_naturalquestions-validation-3112", "mrqa_searchqa-validation-6374", "mrqa_newsqa-validation-3159", "mrqa_hotpotqa-validation-2685", "mrqa_newsqa-validation-1511", "mrqa_searchqa-validation-16428", "mrqa_naturalquestions-validation-6442", "mrqa_newsqa-validation-1224", "mrqa_searchqa-validation-10823", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-1704", "mrqa_searchqa-validation-10045", "mrqa_newsqa-validation-1137", "mrqa_searchqa-validation-5943", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-3097", "mrqa_naturalquestions-validation-8933", "mrqa_searchqa-validation-6030", "mrqa_naturalquestions-validation-222"], "EFR": 0.6060606060606061, "Overall": 0.6731652462121211}, {"timecode": 80, "UKR": 0.814453125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1350", "mrqa_hotpotqa-validation-1952", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-2208", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2600", "mrqa_hotpotqa-validation-3000", "mrqa_hotpotqa-validation-3362", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-3765", "mrqa_hotpotqa-validation-4580", "mrqa_hotpotqa-validation-4791", "mrqa_hotpotqa-validation-512", "mrqa_hotpotqa-validation-5199", "mrqa_hotpotqa-validation-5394", "mrqa_hotpotqa-validation-5604", "mrqa_hotpotqa-validation-5865", "mrqa_hotpotqa-validation-92", "mrqa_hotpotqa-validation-996", "mrqa_naturalquestions-validation-10070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10383", "mrqa_naturalquestions-validation-10485", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-10639", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1147", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-1248", "mrqa_naturalquestions-validation-1324", "mrqa_naturalquestions-validation-1330", "mrqa_naturalquestions-validation-1369", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1504", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-1555", "mrqa_naturalquestions-validation-1655", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2234", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-2903", "mrqa_naturalquestions-validation-3043", "mrqa_naturalquestions-validation-3055", "mrqa_naturalquestions-validation-3232", "mrqa_naturalquestions-validation-3470", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-413", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-5256", "mrqa_naturalquestions-validation-5338", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5466", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5662", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-5865", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-6285", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-673", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-6917", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-7760", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-8016", "mrqa_naturalquestions-validation-8043", "mrqa_naturalquestions-validation-8153", "mrqa_naturalquestions-validation-8201", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-8650", "mrqa_naturalquestions-validation-8766", "mrqa_naturalquestions-validation-8972", "mrqa_naturalquestions-validation-8999", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-954", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-9850", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-9959", "mrqa_naturalquestions-validation-9967", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-114", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1235", "mrqa_newsqa-validation-1256", "mrqa_newsqa-validation-1259", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1302", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1310", "mrqa_newsqa-validation-1342", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1466", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1565", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-159", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-1758", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1879", "mrqa_newsqa-validation-1890", "mrqa_newsqa-validation-1902", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1933", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-200", "mrqa_newsqa-validation-2009", "mrqa_newsqa-validation-2018", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2044", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-2060", "mrqa_newsqa-validation-2089", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2141", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2186", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-222", "mrqa_newsqa-validation-2222", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2229", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-2280", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-2341", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2375", "mrqa_newsqa-validation-2390", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2417", "mrqa_newsqa-validation-2446", "mrqa_newsqa-validation-2464", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-258", "mrqa_newsqa-validation-2584", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-2629", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2813", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2842", "mrqa_newsqa-validation-2843", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2865", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-2920", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2949", "mrqa_newsqa-validation-2953", "mrqa_newsqa-validation-297", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-3053", "mrqa_newsqa-validation-3069", "mrqa_newsqa-validation-3082", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-317", "mrqa_newsqa-validation-3178", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-327", "mrqa_newsqa-validation-3321", "mrqa_newsqa-validation-3345", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3419", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-346", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3490", "mrqa_newsqa-validation-35", "mrqa_newsqa-validation-3591", "mrqa_newsqa-validation-3608", "mrqa_newsqa-validation-3609", "mrqa_newsqa-validation-3662", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-3672", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-3758", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3784", "mrqa_newsqa-validation-379", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3850", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-3878", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-3985", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4075", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-4130", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4154", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-448", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-50", "mrqa_newsqa-validation-538", "mrqa_newsqa-validation-546", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-613", "mrqa_newsqa-validation-615", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-695", "mrqa_newsqa-validation-77", "mrqa_newsqa-validation-825", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-861", "mrqa_newsqa-validation-878", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-962", "mrqa_newsqa-validation-971", "mrqa_searchqa-validation-10105", "mrqa_searchqa-validation-1013", "mrqa_searchqa-validation-10262", "mrqa_searchqa-validation-10303", "mrqa_searchqa-validation-10549", "mrqa_searchqa-validation-10681", "mrqa_searchqa-validation-10777", "mrqa_searchqa-validation-10853", "mrqa_searchqa-validation-11091", "mrqa_searchqa-validation-11095", "mrqa_searchqa-validation-11466", "mrqa_searchqa-validation-11477", "mrqa_searchqa-validation-11513", "mrqa_searchqa-validation-11557", "mrqa_searchqa-validation-1200", "mrqa_searchqa-validation-12030", "mrqa_searchqa-validation-12331", "mrqa_searchqa-validation-126", "mrqa_searchqa-validation-12947", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-13051", "mrqa_searchqa-validation-13295", "mrqa_searchqa-validation-133", "mrqa_searchqa-validation-13313", "mrqa_searchqa-validation-13326", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-13645", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-13755", "mrqa_searchqa-validation-13813", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-13974", "mrqa_searchqa-validation-14014", "mrqa_searchqa-validation-14189", "mrqa_searchqa-validation-14325", "mrqa_searchqa-validation-14395", "mrqa_searchqa-validation-14631", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-14775", "mrqa_searchqa-validation-14847", "mrqa_searchqa-validation-14934", "mrqa_searchqa-validation-15123", "mrqa_searchqa-validation-15299", "mrqa_searchqa-validation-15869", "mrqa_searchqa-validation-15977", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-16422", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-16831", "mrqa_searchqa-validation-200", "mrqa_searchqa-validation-2447", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-248", "mrqa_searchqa-validation-2532", "mrqa_searchqa-validation-2576", "mrqa_searchqa-validation-3106", "mrqa_searchqa-validation-3258", "mrqa_searchqa-validation-3332", "mrqa_searchqa-validation-3405", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-3718", "mrqa_searchqa-validation-3774", "mrqa_searchqa-validation-3991", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-4191", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-4365", "mrqa_searchqa-validation-4386", "mrqa_searchqa-validation-443", "mrqa_searchqa-validation-4553", "mrqa_searchqa-validation-4583", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-4810", "mrqa_searchqa-validation-5028", "mrqa_searchqa-validation-5190", "mrqa_searchqa-validation-5955", "mrqa_searchqa-validation-6041", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-638", "mrqa_searchqa-validation-6490", "mrqa_searchqa-validation-6727", "mrqa_searchqa-validation-689", "mrqa_searchqa-validation-7017", "mrqa_searchqa-validation-7702", "mrqa_searchqa-validation-7746", "mrqa_searchqa-validation-7985", "mrqa_searchqa-validation-8200", "mrqa_searchqa-validation-8263", "mrqa_searchqa-validation-8272", "mrqa_searchqa-validation-8343", "mrqa_searchqa-validation-8379", "mrqa_searchqa-validation-8435", "mrqa_searchqa-validation-8532", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8869", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-9049", "mrqa_searchqa-validation-938", "mrqa_searchqa-validation-9399", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-952", "mrqa_searchqa-validation-9733", "mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-9922", "mrqa_squad-validation-10011", "mrqa_squad-validation-10252", "mrqa_squad-validation-1290", "mrqa_squad-validation-1407", "mrqa_squad-validation-1441", "mrqa_squad-validation-1512", "mrqa_squad-validation-1583", "mrqa_squad-validation-1662", "mrqa_squad-validation-192", "mrqa_squad-validation-1955", "mrqa_squad-validation-2059", "mrqa_squad-validation-245", "mrqa_squad-validation-2748", "mrqa_squad-validation-2857", "mrqa_squad-validation-2893", "mrqa_squad-validation-2920", "mrqa_squad-validation-2932", "mrqa_squad-validation-3222", "mrqa_squad-validation-3493", "mrqa_squad-validation-3551", "mrqa_squad-validation-3663", "mrqa_squad-validation-4162", "mrqa_squad-validation-455", "mrqa_squad-validation-5029", "mrqa_squad-validation-5348", "mrqa_squad-validation-57", "mrqa_squad-validation-5730", "mrqa_squad-validation-5765", "mrqa_squad-validation-5956", "mrqa_squad-validation-5995", "mrqa_squad-validation-605", "mrqa_squad-validation-6334", "mrqa_squad-validation-6393", "mrqa_squad-validation-641", "mrqa_squad-validation-6548", "mrqa_squad-validation-7051", "mrqa_squad-validation-7330", "mrqa_squad-validation-7338", "mrqa_squad-validation-763", "mrqa_squad-validation-7751", "mrqa_squad-validation-7836", "mrqa_squad-validation-8403", "mrqa_squad-validation-8495", "mrqa_squad-validation-883", "mrqa_squad-validation-8869", "mrqa_squad-validation-9110", "mrqa_squad-validation-9178", "mrqa_squad-validation-9298", "mrqa_squad-validation-9362", "mrqa_squad-validation-9365", "mrqa_squad-validation-9373", "mrqa_squad-validation-9528", "mrqa_squad-validation-9687", "mrqa_squad-validation-973", "mrqa_squad-validation-9940", "mrqa_triviaqa-validation-1055", "mrqa_triviaqa-validation-1315", "mrqa_triviaqa-validation-1358", "mrqa_triviaqa-validation-1931", "mrqa_triviaqa-validation-2071", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2171", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-2251", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2458", "mrqa_triviaqa-validation-2858", "mrqa_triviaqa-validation-2963", "mrqa_triviaqa-validation-3090", "mrqa_triviaqa-validation-3168", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3626", "mrqa_triviaqa-validation-3815", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3905", "mrqa_triviaqa-validation-4255", "mrqa_triviaqa-validation-4412", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-4952", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-6295", "mrqa_triviaqa-validation-6427", "mrqa_triviaqa-validation-6435", "mrqa_triviaqa-validation-6637", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-7029", "mrqa_triviaqa-validation-721", "mrqa_triviaqa-validation-7280", "mrqa_triviaqa-validation-7312", "mrqa_triviaqa-validation-7383", "mrqa_triviaqa-validation-7387", "mrqa_triviaqa-validation-79", "mrqa_triviaqa-validation-920"], "OKR": 0.916015625, "KG": 0.51875, "before_eval_results": {"predictions": ["Washington", "the National Hockey League", "blue", "Georgia", "William Devereaux", "scalpels", "the English Channel", "William Shakespeare", "French", "Thornton Wilder", "Baton Rouge", "cupboard", "frittata", "pardon", "Bartholomew Cubbins", "myelogenous (or myeloid or myelocytic) leukemia", "Target", "Regrets", "a possum", "Hot Fuzz", "Pamplona", "Easter Island", "Frans", "Madonna", "drought", "staycation", "safer than sorry", "Makkedah", "Yogi Bear", "Idaho", "Sharyn Rohlfsen", "a carpool", "1215", "Benjamin Harrison", "the skyscraper", "Billy the Kid", "The Killing Fields", "Oliver Twist", "a landmark", "gyros", "bread", "Boston", "Martinique", "Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb", "the Grand Canal", "Sons of Liberty", "a telescope", "Catholic", "the tuba", "a deep pass", "a cube", "Nicole Gale Anderson", "`` Goodbye Toby ''", "1986", "Charles II", "eight", "dragonflies", "acidic", "Roc Me Out", "\"Twice in a Lifetime\"", "10:30 p.m. October 3,", "Dean Martin, Katharine Hepburn and Spencer Tracy", "2006,", "attempted burgl stemming from a fatal encounter with police officer Daniel Enchautegui."], "metric_results": {"EM": 0.6875, "QA-F1": 0.7349187271062272}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-4421", "mrqa_searchqa-validation-11868", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-3033", "mrqa_searchqa-validation-9591", "mrqa_searchqa-validation-9229", "mrqa_searchqa-validation-16593", "mrqa_searchqa-validation-13887", "mrqa_searchqa-validation-9576", "mrqa_searchqa-validation-2069", "mrqa_searchqa-validation-9061", "mrqa_searchqa-validation-16754", "mrqa_searchqa-validation-8538", "mrqa_searchqa-validation-2804", "mrqa_searchqa-validation-15737", "mrqa_searchqa-validation-1408", "mrqa_triviaqa-validation-4590", "mrqa_hotpotqa-validation-3391", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2839"], "SR": 0.6875, "CSR": 0.5597993827160495, "retrieved_ids": ["mrqa_squad-train-31378", "mrqa_squad-train-22395", "mrqa_squad-train-11116", "mrqa_squad-train-68470", "mrqa_squad-train-3275", "mrqa_squad-train-48633", "mrqa_squad-train-25072", "mrqa_squad-train-41118", "mrqa_squad-train-33848", "mrqa_squad-train-70386", "mrqa_squad-train-52680", "mrqa_squad-train-44385", "mrqa_squad-train-52559", "mrqa_squad-train-10500", "mrqa_squad-train-74841", "mrqa_squad-train-10300", "mrqa_squad-train-74794", "mrqa_squad-train-80448", "mrqa_squad-train-3621", "mrqa_squad-train-43748", "mrqa_squad-train-6364", "mrqa_squad-train-85430", "mrqa_squad-train-66680", "mrqa_squad-train-54751", "mrqa_squad-train-50644", "mrqa_squad-train-68468", "mrqa_squad-train-74526", "mrqa_squad-train-20670", "mrqa_squad-train-66153", "mrqa_squad-train-51784", "mrqa_squad-train-2320", "mrqa_squad-train-72790", "mrqa_triviaqa-validation-3298", "mrqa_triviaqa-validation-3423", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-11352", "mrqa_searchqa-validation-1127", "mrqa_naturalquestions-validation-1198", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-1514", "mrqa_squad-validation-10320", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-495", "mrqa_hotpotqa-validation-985", "mrqa_newsqa-validation-2116", "mrqa_newsqa-validation-83", "mrqa_naturalquestions-validation-916", "mrqa_newsqa-validation-3641", "mrqa_hotpotqa-validation-3364", "mrqa_searchqa-validation-15007", "mrqa_hotpotqa-validation-2731", "mrqa_searchqa-validation-16210", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-1720", "mrqa_hotpotqa-validation-2625", "mrqa_newsqa-validation-2945", "mrqa_newsqa-validation-3608", "mrqa_hotpotqa-validation-2978", "mrqa_newsqa-validation-1245", "mrqa_searchqa-validation-11136", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-2859"], "EFR": 0.5, "Overall": 0.6618036265432099}, {"timecode": 81, "before_eval_results": {"predictions": ["order", "New York", "Katrina & the Waves", "the French and Indian War", "Tom Brady", "philosophy", "the Red Cross", "harm", "Bonnie Raitt", "As Good as It Gets", "pickles", "a bull", "neurons", "Evian", "a geese", "The Life and Death of a Man of Character", "the olfactory nerve", "a bay window", "Newton", "YouTube", "Alexander Hamilton", "the Colorado River", "Dune", "a duel", "YouTube", "heresy", "British series", "Charlie Watts", "a black widow spider", "a button", "Virginia", "abundant", "Albert Schweitzer", "the right hemisphere", "dive bomber", "Toulouse-Lautrec", "Helen Hayes", "Dada", "biddy", "H.G. Wells", "save the best for last", "Terry Caster and his wife, Barbara", "the Hippopotamus", "Friedrich Nietzsche", "a dog eat dog world", "Alexander Hamilton", "Israel", "Niagara Falls", "a oar", "carrots", "gallantentry", "Abanindranath Tagore CIE", "at slightly different times when viewed from different points on Earth", "the trunk", "Carrefour", "Obama", "milk", "Todd Phillips", "a priest", "Bharat Ratna", "Joe Pantoliano,", "national telephone", "the Catholic League.", "Ennio Morricone"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7725243506493507}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [0.0, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.060606060606060615, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-5233", "mrqa_searchqa-validation-8686", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-2891", "mrqa_searchqa-validation-16547", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-9621", "mrqa_searchqa-validation-12904", "mrqa_searchqa-validation-4772", "mrqa_searchqa-validation-11719", "mrqa_searchqa-validation-3884", "mrqa_searchqa-validation-2780", "mrqa_searchqa-validation-1250", "mrqa_searchqa-validation-11852", "mrqa_naturalquestions-validation-5968", "mrqa_triviaqa-validation-6193"], "SR": 0.703125, "CSR": 0.561547256097561, "retrieved_ids": ["mrqa_squad-train-85376", "mrqa_squad-train-78724", "mrqa_squad-train-56313", "mrqa_squad-train-78199", "mrqa_squad-train-49040", "mrqa_squad-train-16372", "mrqa_squad-train-18724", "mrqa_squad-train-69709", "mrqa_squad-train-60154", "mrqa_squad-train-46987", "mrqa_squad-train-66937", "mrqa_squad-train-60338", "mrqa_squad-train-3224", "mrqa_squad-train-31037", "mrqa_squad-train-60845", "mrqa_squad-train-9183", "mrqa_squad-train-27900", "mrqa_squad-train-56940", "mrqa_squad-train-57326", "mrqa_squad-train-11693", "mrqa_squad-train-54811", "mrqa_squad-train-10883", "mrqa_squad-train-60940", "mrqa_squad-train-61924", "mrqa_squad-train-8122", "mrqa_squad-train-86076", "mrqa_squad-train-82564", "mrqa_squad-train-81687", "mrqa_squad-train-41560", "mrqa_squad-train-44373", "mrqa_squad-train-41127", "mrqa_squad-train-6794", "mrqa_triviaqa-validation-5969", "mrqa_naturalquestions-validation-10684", "mrqa_newsqa-validation-2446", "mrqa_triviaqa-validation-7430", "mrqa_naturalquestions-validation-9961", "mrqa_naturalquestions-validation-9284", "mrqa_newsqa-validation-2891", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-1244", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-14127", "mrqa_naturalquestions-validation-553", "mrqa_hotpotqa-validation-2205", "mrqa_squad-validation-3559", "mrqa_searchqa-validation-8019", "mrqa_searchqa-validation-9548", "mrqa_searchqa-validation-8766", "mrqa_searchqa-validation-16210", "mrqa_triviaqa-validation-644", "mrqa_newsqa-validation-387", "mrqa_newsqa-validation-3953", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-415", "mrqa_triviaqa-validation-2542", "mrqa_newsqa-validation-105", "mrqa_squad-validation-10320", "mrqa_newsqa-validation-1159", "mrqa_searchqa-validation-15007", "mrqa_searchqa-validation-11207", "mrqa_searchqa-validation-9506"], "EFR": 0.3684210526315789, "Overall": 0.6358374117458279}, {"timecode": 82, "before_eval_results": {"predictions": ["Julius Caesar", "The Big Easy", "the beaver", "Dorothy", "Survivor: Fiji", "the Wild Wild West", "Rudolf Nureyev", "Wilbur", "Maine", "Anne Hathaway", "Eternity", "Andrew Marvell", "Quiz Show", "the NCAA", "acetone", "Heart of Darkness", "Psycho", "Napoleon", "lullaby", "the capuchins", "Napoleon", "the Sahara", "reticulatus", "Munich", "digestif", "a filter", "Pope Francis", "Los Alamos Scientific Laboratory", "Somerset Maugham", "sapphire", "Three Coins in the Fountain", "ER", "the Goldenrod", "Luke", "the rectum", "pterodactyl", "frequency", "Grease", "the salamander", "Alexander Solzhenitsyn", "Eyebrows", "the Romaunt", "Guyana", "Charlie Bartlett", "Vanity Fair", "the Big Sky Conference", "the beavers", "Boston", "(Kim) Bridges", "a ruckus", "Sweden", "Ajay Tyagi", "the 17th episode in the third season", "94 by 50 feet", "Salix", "Fachords Scales Harmonizer", "thomas hebrides", "University of Kentucky", "Rock You Like a Hurricane", "1988", "Hollywood", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah,", "$10 billion", "her boyfriend,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6998263888888888}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-6067", "mrqa_searchqa-validation-11514", "mrqa_searchqa-validation-15479", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-7336", "mrqa_searchqa-validation-9876", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-1599", "mrqa_searchqa-validation-11183", "mrqa_searchqa-validation-2271", "mrqa_searchqa-validation-4093", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7699", "mrqa_searchqa-validation-9246", "mrqa_searchqa-validation-13948", "mrqa_searchqa-validation-8710", "mrqa_searchqa-validation-13719", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-1711", "mrqa_hotpotqa-validation-1561", "mrqa_newsqa-validation-909"], "SR": 0.640625, "CSR": 0.5625, "retrieved_ids": ["mrqa_squad-train-66984", "mrqa_squad-train-10323", "mrqa_squad-train-51062", "mrqa_squad-train-85292", "mrqa_squad-train-51056", "mrqa_squad-train-61274", "mrqa_squad-train-82647", "mrqa_squad-train-26752", "mrqa_squad-train-35683", "mrqa_squad-train-36170", "mrqa_squad-train-4688", "mrqa_squad-train-72196", "mrqa_squad-train-20174", "mrqa_squad-train-1965", "mrqa_squad-train-33674", "mrqa_squad-train-71240", "mrqa_squad-train-62425", "mrqa_squad-train-27261", "mrqa_squad-train-73269", "mrqa_squad-train-2672", "mrqa_squad-train-86490", "mrqa_squad-train-82508", "mrqa_squad-train-72492", "mrqa_squad-train-48108", "mrqa_squad-train-1476", "mrqa_squad-train-82499", "mrqa_squad-train-62320", "mrqa_squad-train-31180", "mrqa_squad-train-49192", "mrqa_squad-train-76770", "mrqa_squad-train-63365", "mrqa_squad-train-33283", "mrqa_squad-validation-8864", "mrqa_newsqa-validation-3029", "mrqa_newsqa-validation-2519", "mrqa_squad-validation-3165", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6564", "mrqa_newsqa-validation-3713", "mrqa_naturalquestions-validation-6998", "mrqa_newsqa-validation-880", "mrqa_newsqa-validation-2401", "mrqa_triviaqa-validation-5425", "mrqa_newsqa-validation-530", "mrqa_triviaqa-validation-6193", "mrqa_newsqa-validation-2665", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-1244", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-12750", "mrqa_naturalquestions-validation-7059", "mrqa_newsqa-validation-614", "mrqa_newsqa-validation-928", "mrqa_searchqa-validation-15608", "mrqa_newsqa-validation-3970", "mrqa_squad-validation-2373", "mrqa_searchqa-validation-11800", "mrqa_searchqa-validation-1833", "mrqa_newsqa-validation-1563", "mrqa_squad-validation-4662", "mrqa_searchqa-validation-15530", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-3826"], "EFR": 0.34782608695652173, "Overall": 0.6319089673913043}, {"timecode": 83, "before_eval_results": {"predictions": ["the East Sea", "Stitch", "Joe Torre", "a kettledrum", "P.G. Wodehouse", "Santa Fe", "Rastafarianism", "cinnamon", "The Pirates of Penzance", "reasonable", "St. Patrick's Day", "beer", "Wall Street", "Nathaniel Hawthorne", "Trinity College", "Geneva", "Asklepios", "troll", "The Flying Dutchman", "Dan Quayle", "Naomi", "William Faulkner", "Nothing without Providence", "a phaser", "Dylan", "Lincoln", "Crank Yankers", "the stratosphere", "Paul McCartney", "Juno", "distressing", "Mercury", "the Mad Hatter", "the Marshall Islands", "Nepal", "Thomas Jefferson", "God", "Indiana", "Hair", "cicadas", "Steel Pier", "the shaft which flies In darkness", "the saguaro", "Zappa", "Hip-hop", "Federico Fellini", "dampers", "Sirius", "onomatopoeia", "a loaf of bread", "Portugal", "Long Island", "lifetime", "Glynis Johns", "Porridge", "daniels", "Magdalene Laundries", "King Kelly", "\u00c6thelwald Moll", "Lord Cavendish", "60 euros", "Prince George's County Correctional Center,", "Kurdistan Freedom Falcons,", "1937"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7096354166666666}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, false, true, false, true, false, false, false, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.25, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4066", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-13001", "mrqa_searchqa-validation-1568", "mrqa_searchqa-validation-1991", "mrqa_searchqa-validation-2881", "mrqa_searchqa-validation-2265", "mrqa_searchqa-validation-11315", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-8764", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-15463", "mrqa_searchqa-validation-8061", "mrqa_searchqa-validation-16266", "mrqa_searchqa-validation-2126", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-4151", "mrqa_searchqa-validation-15435", "mrqa_searchqa-validation-8399", "mrqa_searchqa-validation-15055", "mrqa_triviaqa-validation-5339", "mrqa_hotpotqa-validation-3822", "mrqa_hotpotqa-validation-4204", "mrqa_newsqa-validation-419", "mrqa_newsqa-validation-1509"], "SR": 0.609375, "CSR": 0.5630580357142857, "retrieved_ids": ["mrqa_squad-train-42533", "mrqa_squad-train-73816", "mrqa_squad-train-44693", "mrqa_squad-train-61623", "mrqa_squad-train-80831", "mrqa_squad-train-67055", "mrqa_squad-train-75454", "mrqa_squad-train-45702", "mrqa_squad-train-65690", "mrqa_squad-train-9709", "mrqa_squad-train-78796", "mrqa_squad-train-7862", "mrqa_squad-train-25966", "mrqa_squad-train-8243", "mrqa_squad-train-42003", "mrqa_squad-train-66342", "mrqa_squad-train-81570", "mrqa_squad-train-64284", "mrqa_squad-train-76326", "mrqa_squad-train-30243", "mrqa_squad-train-53870", "mrqa_squad-train-86152", "mrqa_squad-train-84155", "mrqa_squad-train-21225", "mrqa_squad-train-50685", "mrqa_squad-train-33719", "mrqa_squad-train-54648", "mrqa_squad-train-71121", "mrqa_squad-train-51626", "mrqa_squad-train-21398", "mrqa_squad-train-15775", "mrqa_squad-train-58714", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-7920", "mrqa_newsqa-validation-1511", "mrqa_newsqa-validation-767", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-5980", "mrqa_naturalquestions-validation-2429", "mrqa_newsqa-validation-2197", "mrqa_triviaqa-validation-2302", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1458", "mrqa_newsqa-validation-2482", "mrqa_newsqa-validation-2753", "mrqa_newsqa-validation-2695", "mrqa_naturalquestions-validation-5297", "mrqa_newsqa-validation-3687", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-900", "mrqa_searchqa-validation-1214", "mrqa_newsqa-validation-2927", "mrqa_naturalquestions-validation-1657", "mrqa_newsqa-validation-1104", "mrqa_triviaqa-validation-862", "mrqa_newsqa-validation-878", "mrqa_searchqa-validation-6374", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-3089", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-6931", "mrqa_searchqa-validation-16660"], "EFR": 0.24, "Overall": 0.6104553571428571}, {"timecode": 84, "before_eval_results": {"predictions": ["words per minute", "the crescent", "a trident", "Abercrombie & Fitch", "H. L. Hunley", "Standard Oil", "Crustacea", "Laura Ingalls Wilder", "a carriage", "Monet", "burning gasoline, coal, or other fossil fuels", "Gerald R. Ford", "Louis Rukeyser", "Jupiter", "Clinton", "Truisms", "tin", "Stephen Hawking", "Kilimanjaro", "Munich", "London", "Nunavut", "Georgia Bulldogs", "La Bohme", "abbreviated", "Heroes", "Lichen Planus", "Kublai Khan", "Lafitte", "the Flushing River", "a relic", "cyclosporine", "the Northern Mockingbird", "RESTRICTIVE WILL OF THIS, CLAUSE", "Comedy", "The Kittiwake", "Perimeter", "60 Minutes", "a terrarium", "Vulcan", "cor", "the narwhal", "Stephen Hawking", "sea birds", "Albert Camus", "Mexico", "Kleopatra", "Finding Nemo", "The Oresteia", "Scotland", "the Big Dipper", "1924", "937 total weeks", "January 17, 1899", "Douglas MacArthur", "Project Gutenberg", "Indonesia", "Latin American culture", "a co-op of grape growers", "David Naughton", "\"Nothing But Love\"", "helping to plan the September 11, 2001, terror attacks,", "650", "$1.5 million."], "metric_results": {"EM": 0.640625, "QA-F1": 0.730406746031746}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, false, true, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.8571428571428571, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-511", "mrqa_searchqa-validation-5795", "mrqa_searchqa-validation-1837", "mrqa_searchqa-validation-5385", "mrqa_searchqa-validation-1633", "mrqa_searchqa-validation-15821", "mrqa_searchqa-validation-16254", "mrqa_searchqa-validation-3331", "mrqa_searchqa-validation-6486", "mrqa_searchqa-validation-1304", "mrqa_searchqa-validation-9151", "mrqa_searchqa-validation-6947", "mrqa_searchqa-validation-3908", "mrqa_searchqa-validation-3003", "mrqa_searchqa-validation-15526", "mrqa_searchqa-validation-3254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-3503", "mrqa_searchqa-validation-6009", "mrqa_naturalquestions-validation-4428", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1148", "mrqa_newsqa-validation-3820"], "SR": 0.640625, "CSR": 0.5639705882352941, "retrieved_ids": ["mrqa_squad-train-52150", "mrqa_squad-train-41686", "mrqa_squad-train-23033", "mrqa_squad-train-48190", "mrqa_squad-train-17301", "mrqa_squad-train-60838", "mrqa_squad-train-73778", "mrqa_squad-train-39810", "mrqa_squad-train-53254", "mrqa_squad-train-60265", "mrqa_squad-train-8893", "mrqa_squad-train-85939", "mrqa_squad-train-20401", "mrqa_squad-train-46526", "mrqa_squad-train-84002", "mrqa_squad-train-16558", "mrqa_squad-train-12143", "mrqa_squad-train-45283", "mrqa_squad-train-46672", "mrqa_squad-train-53204", "mrqa_squad-train-2389", "mrqa_squad-train-14748", "mrqa_squad-train-77442", "mrqa_squad-train-68300", "mrqa_squad-train-36242", "mrqa_squad-train-70224", "mrqa_squad-train-5612", "mrqa_squad-train-25225", "mrqa_squad-train-25727", "mrqa_squad-train-11842", "mrqa_squad-train-33940", "mrqa_squad-train-86377", "mrqa_newsqa-validation-3662", "mrqa_naturalquestions-validation-64", "mrqa_newsqa-validation-1879", "mrqa_newsqa-validation-4008", "mrqa_searchqa-validation-5457", "mrqa_naturalquestions-validation-9054", "mrqa_triviaqa-validation-2296", "mrqa_searchqa-validation-5028", "mrqa_naturalquestions-validation-6442", "mrqa_triviaqa-validation-5289", "mrqa_searchqa-validation-15847", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-13657", "mrqa_naturalquestions-validation-1586", "mrqa_searchqa-validation-4191", "mrqa_naturalquestions-validation-2100", "mrqa_searchqa-validation-3033", "mrqa_squad-validation-694", "mrqa_squad-validation-1500", "mrqa_newsqa-validation-1334", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-502", "mrqa_searchqa-validation-11888", "mrqa_naturalquestions-validation-10255", "mrqa_searchqa-validation-11372", "mrqa_naturalquestions-validation-8584", "mrqa_squad-validation-639", "mrqa_naturalquestions-validation-2095", "mrqa_naturalquestions-validation-6514", "mrqa_newsqa-validation-2753", "mrqa_newsqa-validation-1308", "mrqa_searchqa-validation-3441"], "EFR": 0.08695652173913043, "Overall": 0.5800291719948849}, {"timecode": 85, "before_eval_results": {"predictions": ["archery", "Albright", "silver", "the Mummy", "the Washington Redskins", "asteroids", "Ellen Holly", "The Prince and the Pauper", "Pushing Daisies", "Thanksgiving", "the reaper", "Pearl Jam", "candle", "apples", "Solomon", "New Brunswick", "Lake County, Indiana", "Cleopatra", "the northern pike", "Krispy Kreme", "New York Luxury Real Estate", "Martin Luther", "rice", "Frasier", "Kansas City", "arteries", "\"Chinatown.\"", "improvisation", "Hamlet", "lime", "Apocalypse Now", "alkaline nedir, ne demek, alkaline anlam", "Robert Duvall", "Joan of Arc", "abundance", "Crete", "Alfred Hitchcock", "Brett Favre", "Their Eyes Were watching God", "Fiddler on the Roof", "Pitcairn Island", "hockey", "etching", "Mars", "dermal scales", "David", "Potato Dish", "a cookie jar", "Babe Ruth", "a cheesesteak", "Nicky Hilton", "he hosted a short - lived talk show in WCW called A Flair for the Gold", "August 21, Clash of Champions on September 25 and the following night on Raw", "Jessica Simpson", "William Schuman", "leaves", "Robert Plant", "Oklahoma", "138,535 people", "Martin Scorsese", "\"Michael Phelps, partying your face off in public is not the way to reclaim your good guy image.", "reptiles,", "Gustav", "\"A total of seven died on our property,\""], "metric_results": {"EM": 0.625, "QA-F1": 0.7101934523809524}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3676", "mrqa_searchqa-validation-15955", "mrqa_searchqa-validation-6308", "mrqa_searchqa-validation-6539", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-5953", "mrqa_searchqa-validation-14943", "mrqa_searchqa-validation-5556", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-12891", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-13581", "mrqa_searchqa-validation-7358", "mrqa_searchqa-validation-8231", "mrqa_searchqa-validation-8377", "mrqa_searchqa-validation-6317", "mrqa_searchqa-validation-12173", "mrqa_naturalquestions-validation-9003", "mrqa_naturalquestions-validation-6049", "mrqa_triviaqa-validation-533", "mrqa_hotpotqa-validation-1363", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-3909", "mrqa_newsqa-validation-2301"], "SR": 0.625, "CSR": 0.5646802325581395, "retrieved_ids": ["mrqa_squad-train-53521", "mrqa_squad-train-67790", "mrqa_squad-train-46910", "mrqa_squad-train-74407", "mrqa_squad-train-54386", "mrqa_squad-train-42607", "mrqa_squad-train-2357", "mrqa_squad-train-13673", "mrqa_squad-train-55284", "mrqa_squad-train-21119", "mrqa_squad-train-4299", "mrqa_squad-train-20752", "mrqa_squad-train-53443", "mrqa_squad-train-82815", "mrqa_squad-train-73123", "mrqa_squad-train-43944", "mrqa_squad-train-82639", "mrqa_squad-train-22719", "mrqa_squad-train-71768", "mrqa_squad-train-82539", "mrqa_squad-train-78211", "mrqa_squad-train-54505", "mrqa_squad-train-51178", "mrqa_squad-train-7438", "mrqa_squad-train-34991", "mrqa_squad-train-69456", "mrqa_squad-train-40003", "mrqa_squad-train-2127", "mrqa_squad-train-4999", "mrqa_squad-train-25715", "mrqa_squad-train-80903", "mrqa_squad-train-6429", "mrqa_searchqa-validation-12947", "mrqa_naturalquestions-validation-6009", "mrqa_squad-validation-8400", "mrqa_hotpotqa-validation-550", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-7266", "mrqa_newsqa-validation-1512", "mrqa_triviaqa-validation-237", "mrqa_searchqa-validation-6486", "mrqa_newsqa-validation-1531", "mrqa_triviaqa-validation-5289", "mrqa_newsqa-validation-1808", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-16913", "mrqa_naturalquestions-validation-2942", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-7731", "mrqa_triviaqa-validation-3284", "mrqa_newsqa-validation-3321", "mrqa_newsqa-validation-4027", "mrqa_searchqa-validation-6293", "mrqa_triviaqa-validation-1961", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-1688", "mrqa_squad-validation-1500", "mrqa_newsqa-validation-1149", "mrqa_searchqa-validation-16917", "mrqa_naturalquestions-validation-4366", "mrqa_searchqa-validation-4499"], "EFR": 0.0, "Overall": 0.5627797965116279}, {"timecode": 86, "before_eval_results": {"predictions": ["a dishwasher", "Pulp Fiction", "Leo Tolstoy", "Louisiana", "The New Yorker", "Nicaragua", "Chastity", "Frank Sinatra", "Dmitri Mendeleev", "Kathleen Winsor", "Blitzkrieg", "luminous intensity", "Edward Tudor, Prince of Wales", "the Eurasian Economic Union", "Christina Ricci", "John Paul Jones", "the Rolling Stones", "The Goblet of Fire", "Samuel A. Alito", "femslash mermaids", "Civic", "Hermann Hesse", "Copernicus", "Jane Addams", "Paris", "a rail", "The Cat in the Hat", "Rich Girl", "Yogi Berra", "cor", "a jigger", "calcium", "Constitution", "the eastern Mediterranean", "virtual reality", "bass", "The Last Remake of Beau Geste", "hot air balloons", "Tarzan & Jane", "an RBIs", "David Berkowitz", "oblique", "pecan", "Breed's Hill", "Sam Walton", "fritter", "the Spanish Republic", "Sweden", "Chicago", "The Matrix", "the Bolsheviks", "April 17, 1982", "Jesus Himself referenced the flower, saying `` Consider the lilies how they grow : they toil not, they spin not ; and yet I say unto you, that Solomon in all his glory was not arrayed like one of these", "France", "James Cameron", "\"One Night / I Got Stung\"", "Japan", "Whittlesey", "Kingdom of Dalmatia", "Japan", "Monday.", "Six", "Scotland", "Jacob Zuma,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7145567602040817}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.08163265306122448, 1.0, 1.0, 0.0, 1.0, 0.4, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6099", "mrqa_searchqa-validation-110", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-7402", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-2950", "mrqa_searchqa-validation-5240", "mrqa_searchqa-validation-6658", "mrqa_searchqa-validation-1845", "mrqa_searchqa-validation-8478", "mrqa_searchqa-validation-3254", "mrqa_searchqa-validation-10993", "mrqa_searchqa-validation-3534", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-3800", "mrqa_searchqa-validation-394", "mrqa_searchqa-validation-16576", "mrqa_searchqa-validation-7134", "mrqa_naturalquestions-validation-4942", "mrqa_triviaqa-validation-6355", "mrqa_hotpotqa-validation-3895", "mrqa_hotpotqa-validation-4669"], "SR": 0.640625, "CSR": 0.5655531609195402, "retrieved_ids": ["mrqa_squad-train-44662", "mrqa_squad-train-67525", "mrqa_squad-train-57819", "mrqa_squad-train-45892", "mrqa_squad-train-58737", "mrqa_squad-train-239", "mrqa_squad-train-57641", "mrqa_squad-train-81752", "mrqa_squad-train-14310", "mrqa_squad-train-10387", "mrqa_squad-train-71740", "mrqa_squad-train-83510", "mrqa_squad-train-40240", "mrqa_squad-train-1639", "mrqa_squad-train-36960", "mrqa_squad-train-79008", "mrqa_squad-train-14777", "mrqa_squad-train-44303", "mrqa_squad-train-86396", "mrqa_squad-train-25704", "mrqa_squad-train-5883", "mrqa_squad-train-85751", "mrqa_squad-train-32661", "mrqa_squad-train-42125", "mrqa_squad-train-59842", "mrqa_squad-train-57803", "mrqa_squad-train-70221", "mrqa_squad-train-56483", "mrqa_squad-train-84143", "mrqa_squad-train-74016", "mrqa_squad-train-27992", "mrqa_squad-train-77019", "mrqa_searchqa-validation-15437", "mrqa_searchqa-validation-7006", "mrqa_newsqa-validation-3171", "mrqa_squad-validation-9533", "mrqa_triviaqa-validation-7311", "mrqa_newsqa-validation-283", "mrqa_squad-validation-2346", "mrqa_searchqa-validation-9576", "mrqa_newsqa-validation-477", "mrqa_squad-validation-3130", "mrqa_newsqa-validation-3932", "mrqa_squad-validation-10274", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-2601", "mrqa_triviaqa-validation-2431", "mrqa_newsqa-validation-2413", "mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-633", "mrqa_searchqa-validation-16971", "mrqa_newsqa-validation-3184", "mrqa_naturalquestions-validation-495", "mrqa_newsqa-validation-2143", "mrqa_newsqa-validation-2032", "mrqa_hotpotqa-validation-1791", "mrqa_triviaqa-validation-5309", "mrqa_naturalquestions-validation-9063", "mrqa_squad-validation-7687", "mrqa_newsqa-validation-3879", "mrqa_newsqa-validation-2983", "mrqa_hotpotqa-validation-1743", "mrqa_newsqa-validation-3703", "mrqa_searchqa-validation-13921"], "EFR": 0.0, "Overall": 0.562954382183908}, {"timecode": 87, "before_eval_results": {"predictions": ["Macbeth", "El burlador de Sevilla", "a spinning mule", "onerous", "Clown portrait", "Fargo", "the Dailies", "fiberboard", "the River Thames", "Napster", "The Partridge Family", "Coors Field", "Elizabeth of England", "Wicked", "Dementia", "face detection", "Nadir", "the Golden Fleece", "satisfaction", "caution", "Macaulay Culkin", "the Tom Thumb", "John Edwards", "Hawaii", "Kennedy", "Daniel Boone", "a quart", "Hemoglobin", "Nancy Sinatra", "Ear infections", "foxes", "tabby", "Amerigo Vespucci", "Wisconsin", "the Hashemite monarchy", "Canada", "bipolar", "a brownie", "the iron clock", "Alexander Calder", "honey", "Ferris B Mueller", "Christopher Columbus", "Spider-Man Jr,", "Zyrtec", "a coyote", "Yahtzee", "Jerry Mathers", "Kansas City, Missouri", "axiom", "electors", "3.5 mya", "Tommy Shaw", "Mark Jackson", "kosher", "whale", "Meta", "Marvel's Agent Carter", "Parthian Empire", "\"Kill Your Darlings\"", "planning processes are urgently needed", "Iran", "Brett Cummins,", "Brown-Waite"], "metric_results": {"EM": 0.625, "QA-F1": 0.7078125}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-535", "mrqa_searchqa-validation-5909", "mrqa_searchqa-validation-4369", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-873", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-5987", "mrqa_searchqa-validation-12042", "mrqa_searchqa-validation-14009", "mrqa_searchqa-validation-16734", "mrqa_searchqa-validation-14465", "mrqa_searchqa-validation-1792", "mrqa_searchqa-validation-4111", "mrqa_searchqa-validation-10767", "mrqa_searchqa-validation-10494", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-5640", "mrqa_searchqa-validation-5842", "mrqa_naturalquestions-validation-7027", "mrqa_triviaqa-validation-4384", "mrqa_triviaqa-validation-7725", "mrqa_hotpotqa-validation-1102"], "SR": 0.625, "CSR": 0.5662286931818181, "retrieved_ids": ["mrqa_squad-train-55692", "mrqa_squad-train-71092", "mrqa_squad-train-10978", "mrqa_squad-train-58753", "mrqa_squad-train-9", "mrqa_squad-train-32467", "mrqa_squad-train-36278", "mrqa_squad-train-2181", "mrqa_squad-train-43393", "mrqa_squad-train-49842", "mrqa_squad-train-23699", "mrqa_squad-train-68913", "mrqa_squad-train-66010", "mrqa_squad-train-30887", "mrqa_squad-train-37253", "mrqa_squad-train-50592", "mrqa_squad-train-81032", "mrqa_squad-train-49184", "mrqa_squad-train-26493", "mrqa_squad-train-78450", "mrqa_squad-train-17054", "mrqa_squad-train-78777", "mrqa_squad-train-15661", "mrqa_squad-train-83170", "mrqa_squad-train-5173", "mrqa_squad-train-56973", "mrqa_squad-train-25109", "mrqa_squad-train-74843", "mrqa_squad-train-55589", "mrqa_squad-train-15894", "mrqa_squad-train-36292", "mrqa_squad-train-3916", "mrqa_triviaqa-validation-6620", "mrqa_newsqa-validation-983", "mrqa_naturalquestions-validation-7853", "mrqa_hotpotqa-validation-3900", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-1731", "mrqa_hotpotqa-validation-2863", "mrqa_naturalquestions-validation-6234", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-1981", "mrqa_naturalquestions-validation-10680", "mrqa_newsqa-validation-3121", "mrqa_searchqa-validation-8092", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-2448", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-1508", "mrqa_searchqa-validation-8399", "mrqa_hotpotqa-validation-5199", "mrqa_searchqa-validation-4470", "mrqa_hotpotqa-validation-3456", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-2386", "mrqa_newsqa-validation-2891", "mrqa_searchqa-validation-10993", "mrqa_hotpotqa-validation-3408", "mrqa_naturalquestions-validation-4540", "mrqa_searchqa-validation-11809", "mrqa_searchqa-validation-3540", "mrqa_searchqa-validation-12340", "mrqa_naturalquestions-validation-5004"], "EFR": 0.0, "Overall": 0.5630894886363637}, {"timecode": 88, "before_eval_results": {"predictions": ["Cairo", "a highchair", "Biggie Smalls", "Judas", "John Paul II", "Hillary Clinton", "Ariel Sharon", "Rich Girl", "Lady Macbeth", "Strom Thurmond", "Windsor, Ontario", "Armageddon", "yellow", "Vegas", "Sleepover", "Spain", "Scrabble", "the Caspian Sea", "football", "the Los Angeles Angels of Anaheim", "Cardiff", "the Blacklist", "Time", "go back into the water", "Graceland", "a telescope", "9 to 5", "Dr. Hook & the Medicine Show", "the coxswain", "Transamerica", "China", "Carter", "the Delacorte", "Henry Clay", "the wire loop", "Petsmart", "Charles Darwin", "Electric Avenue", "a glossary", "Jerusalem", "Vanna White", "Toyota", "(cella)", "Istanbul", "F. Scott Fitzgerald", "Dixie", "Linkin Park", "Tycho Brahe", "King", "Elisabeth", "Shinto", "the following day", "early 1980s", "Taron Egerton", "a linesider", "Henry of Valence", "The Undertones", "Groupe PSA", "Premier Division", "The Five", "The court, based in Los Angeles grand jury room after her indictment in the 1969 \"Manson murders.\"", "Herman Cain,", "grizzly bear", "Harrison Ford"], "metric_results": {"EM": 0.609375, "QA-F1": 0.65546875}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.75, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-528", "mrqa_searchqa-validation-7582", "mrqa_searchqa-validation-8178", "mrqa_searchqa-validation-1656", "mrqa_searchqa-validation-12316", "mrqa_searchqa-validation-8763", "mrqa_searchqa-validation-7301", "mrqa_searchqa-validation-8732", "mrqa_searchqa-validation-2831", "mrqa_searchqa-validation-5542", "mrqa_searchqa-validation-13919", "mrqa_searchqa-validation-7826", "mrqa_searchqa-validation-10215", "mrqa_searchqa-validation-14857", "mrqa_searchqa-validation-5388", "mrqa_searchqa-validation-5520", "mrqa_searchqa-validation-13674", "mrqa_searchqa-validation-14789", "mrqa_searchqa-validation-4664", "mrqa_naturalquestions-validation-844", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-6545", "mrqa_hotpotqa-validation-1686", "mrqa_newsqa-validation-3714"], "SR": 0.609375, "CSR": 0.5667134831460674, "retrieved_ids": ["mrqa_squad-train-60359", "mrqa_squad-train-54507", "mrqa_squad-train-80610", "mrqa_squad-train-44982", "mrqa_squad-train-27098", "mrqa_squad-train-22352", "mrqa_squad-train-23523", "mrqa_squad-train-26699", "mrqa_squad-train-72490", "mrqa_squad-train-23302", "mrqa_squad-train-46578", "mrqa_squad-train-53125", "mrqa_squad-train-56952", "mrqa_squad-train-53658", "mrqa_squad-train-55454", "mrqa_squad-train-54982", "mrqa_squad-train-84029", "mrqa_squad-train-75211", "mrqa_squad-train-55364", "mrqa_squad-train-1089", "mrqa_squad-train-62353", "mrqa_squad-train-26676", "mrqa_squad-train-64884", "mrqa_squad-train-17419", "mrqa_squad-train-15422", "mrqa_squad-train-68236", "mrqa_squad-train-18025", "mrqa_squad-train-65780", "mrqa_squad-train-6761", "mrqa_squad-train-1773", "mrqa_squad-train-59637", "mrqa_squad-train-68000", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-3112", "mrqa_squad-validation-4015", "mrqa_newsqa-validation-2793", "mrqa_squad-validation-1313", "mrqa_newsqa-validation-3346", "mrqa_newsqa-validation-2743", "mrqa_hotpotqa-validation-3806", "mrqa_newsqa-validation-3949", "mrqa_searchqa-validation-7160", "mrqa_newsqa-validation-4033", "mrqa_naturalquestions-validation-9591", "mrqa_newsqa-validation-2418", "mrqa_squad-validation-3355", "mrqa_newsqa-validation-1102", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-5510", "mrqa_searchqa-validation-1384", "mrqa_hotpotqa-validation-2826", "mrqa_searchqa-validation-11498", "mrqa_hotpotqa-validation-3314", "mrqa_naturalquestions-validation-9054", "mrqa_searchqa-validation-12017", "mrqa_naturalquestions-validation-4309", "mrqa_newsqa-validation-2534", "mrqa_hotpotqa-validation-4441", "mrqa_newsqa-validation-3403", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2209", "mrqa_searchqa-validation-2126", "mrqa_newsqa-validation-1011", "mrqa_searchqa-validation-7358"], "EFR": 0.0, "Overall": 0.5631864466292134}, {"timecode": 89, "before_eval_results": {"predictions": ["the ermine", "Nemo", "easel", "a state of resting after exertion or strain", "Lewis and Clark", "Erica Kane", "Henry VIII", "Seattle", "the United Kingdom", "Denmark", "the saguaro", "Saigon", "Shinto", "Chris", "Venus", "iris", "MichaelBurberyy", "Armistice", "toilet paper", "the Panama Canal", "Cesare Borgia", "pearl", "cognac", "Hangman", "Charles Dickens", "October", "Stephen Foster", "George Bernard Shaw", "Linkin Park", "dogie", "a storm", "lungs", "gravity", "Elizabeth", "Robert the Bruce", "Marlon Brando", "the United States", "Lana Turner", "a bolt", "Othello", "Emiliano Zapata", "Bone Thugs-N-Harmony", "zebras", "Helio Castroneves", "Richard III", "Hugh Grant", "Godot", "voyeurism", "the Articles of Confederation", "Pavlov", "a hull", "Hot Wings", "England, Northern Ireland, Scotland and Wales", "James Madison", "The Firm", "Harriet Tubman", "Hebrew", "\" Finding Nemo\"", "his superhero roles as the Marvel Comics characters Steve Rogers / Captain America in the Marvel Cinematic Universe and Johnny Storm / Human Torch in \"Fantastic Four\" and", "Sam Raimi", "sniff out cell phones.", "forgery and flying without a valid license,", "Apple employees", "the Pir Panjal Range in Jammu and Kashmir"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7624563834154351}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3448275862068966, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-10034", "mrqa_searchqa-validation-10711", "mrqa_searchqa-validation-16252", "mrqa_searchqa-validation-14958", "mrqa_searchqa-validation-2173", "mrqa_searchqa-validation-9343", "mrqa_searchqa-validation-10869", "mrqa_searchqa-validation-3804", "mrqa_searchqa-validation-9761", "mrqa_searchqa-validation-7480", "mrqa_searchqa-validation-4127", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-1138", "mrqa_searchqa-validation-10008", "mrqa_naturalquestions-validation-8612", "mrqa_triviaqa-validation-6466", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-2099"], "SR": 0.703125, "CSR": 0.5682291666666667, "retrieved_ids": ["mrqa_squad-train-28444", "mrqa_squad-train-37174", "mrqa_squad-train-80141", "mrqa_squad-train-85810", "mrqa_squad-train-28930", "mrqa_squad-train-63090", "mrqa_squad-train-61825", "mrqa_squad-train-7345", "mrqa_squad-train-60209", "mrqa_squad-train-83072", "mrqa_squad-train-85687", "mrqa_squad-train-10221", "mrqa_squad-train-36715", "mrqa_squad-train-59230", "mrqa_squad-train-38694", "mrqa_squad-train-71137", "mrqa_squad-train-40084", "mrqa_squad-train-33897", "mrqa_squad-train-63343", "mrqa_squad-train-72928", "mrqa_squad-train-80747", "mrqa_squad-train-56064", "mrqa_squad-train-34987", "mrqa_squad-train-30283", "mrqa_squad-train-72805", "mrqa_squad-train-75749", "mrqa_squad-train-64451", "mrqa_squad-train-45247", "mrqa_squad-train-45444", "mrqa_squad-train-74510", "mrqa_squad-train-26267", "mrqa_squad-train-20568", "mrqa_searchqa-validation-13780", "mrqa_searchqa-validation-10604", "mrqa_naturalquestions-validation-226", "mrqa_triviaqa-validation-3715", "mrqa_searchqa-validation-3554", "mrqa_naturalquestions-validation-6289", "mrqa_newsqa-validation-995", "mrqa_searchqa-validation-8976", "mrqa_newsqa-validation-686", "mrqa_naturalquestions-validation-3902", "mrqa_triviaqa-validation-4019", "mrqa_searchqa-validation-2707", "mrqa_newsqa-validation-631", "mrqa_newsqa-validation-2360", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-3789", "mrqa_searchqa-validation-14783", "mrqa_newsqa-validation-880", "mrqa_searchqa-validation-5510", "mrqa_searchqa-validation-8619", "mrqa_newsqa-validation-2198", "mrqa_squad-validation-7719", "mrqa_naturalquestions-validation-3962", "mrqa_searchqa-validation-4009", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-1712", "mrqa_naturalquestions-validation-6931", "mrqa_searchqa-validation-14790", "mrqa_naturalquestions-validation-4674", "mrqa_searchqa-validation-15538", "mrqa_triviaqa-validation-5973"], "EFR": 0.0, "Overall": 0.5634895833333333}, {"timecode": 90, "UKR": 0.8125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1350", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-1952", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-2208", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2600", "mrqa_hotpotqa-validation-3000", "mrqa_hotpotqa-validation-3362", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-3765", "mrqa_hotpotqa-validation-4580", "mrqa_hotpotqa-validation-4791", "mrqa_hotpotqa-validation-4941", "mrqa_hotpotqa-validation-512", "mrqa_hotpotqa-validation-5199", "mrqa_hotpotqa-validation-5556", "mrqa_hotpotqa-validation-5604", "mrqa_hotpotqa-validation-5865", "mrqa_hotpotqa-validation-92", "mrqa_hotpotqa-validation-996", "mrqa_naturalquestions-validation-10070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10485", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-10639", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1147", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-1248", "mrqa_naturalquestions-validation-1330", "mrqa_naturalquestions-validation-1369", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-1555", "mrqa_naturalquestions-validation-1655", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2234", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-2903", "mrqa_naturalquestions-validation-3043", "mrqa_naturalquestions-validation-3055", "mrqa_naturalquestions-validation-3470", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-413", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-4428", "mrqa_naturalquestions-validation-4942", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-5256", "mrqa_naturalquestions-validation-5338", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5466", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5662", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-5865", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-6285", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-673", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-6917", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-7760", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-8016", "mrqa_naturalquestions-validation-8153", "mrqa_naturalquestions-validation-8201", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-8650", "mrqa_naturalquestions-validation-8766", "mrqa_naturalquestions-validation-8972", "mrqa_naturalquestions-validation-8999", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-954", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9850", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-9959", "mrqa_naturalquestions-validation-9967", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-1126", "mrqa_newsqa-validation-114", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1235", "mrqa_newsqa-validation-1256", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1302", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1310", "mrqa_newsqa-validation-1342", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1565", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-159", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-1758", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1879", "mrqa_newsqa-validation-1890", "mrqa_newsqa-validation-1902", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1933", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-200", "mrqa_newsqa-validation-2009", "mrqa_newsqa-validation-2018", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2044", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-2055", "mrqa_newsqa-validation-2060", "mrqa_newsqa-validation-2089", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2141", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2186", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-222", "mrqa_newsqa-validation-222", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-2280", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2375", "mrqa_newsqa-validation-2390", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2417", "mrqa_newsqa-validation-2446", "mrqa_newsqa-validation-2464", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-258", "mrqa_newsqa-validation-2584", "mrqa_newsqa-validation-2629", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2842", "mrqa_newsqa-validation-2843", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2865", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2949", "mrqa_newsqa-validation-2953", "mrqa_newsqa-validation-297", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-3053", "mrqa_newsqa-validation-3069", "mrqa_newsqa-validation-3082", "mrqa_newsqa-validation-317", "mrqa_newsqa-validation-3178", "mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-327", "mrqa_newsqa-validation-3345", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3419", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3490", "mrqa_newsqa-validation-35", "mrqa_newsqa-validation-3591", "mrqa_newsqa-validation-3608", "mrqa_newsqa-validation-3609", "mrqa_newsqa-validation-3662", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-3672", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3784", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3850", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-3878", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3909", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-3985", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4075", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-4130", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4154", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-448", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-50", "mrqa_newsqa-validation-538", "mrqa_newsqa-validation-546", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-695", "mrqa_newsqa-validation-825", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-878", "mrqa_newsqa-validation-962", "mrqa_newsqa-validation-971", "mrqa_searchqa-validation-1013", "mrqa_searchqa-validation-10262", "mrqa_searchqa-validation-10298", "mrqa_searchqa-validation-10549", "mrqa_searchqa-validation-10616", "mrqa_searchqa-validation-10681", "mrqa_searchqa-validation-10777", "mrqa_searchqa-validation-10853", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-11091", "mrqa_searchqa-validation-11095", "mrqa_searchqa-validation-11183", "mrqa_searchqa-validation-11466", "mrqa_searchqa-validation-11477", "mrqa_searchqa-validation-11513", "mrqa_searchqa-validation-11514", "mrqa_searchqa-validation-11557", "mrqa_searchqa-validation-12030", "mrqa_searchqa-validation-12248", "mrqa_searchqa-validation-12331", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-126", "mrqa_searchqa-validation-12765", "mrqa_searchqa-validation-12913", "mrqa_searchqa-validation-12947", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-133", "mrqa_searchqa-validation-13313", "mrqa_searchqa-validation-13326", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-13573", "mrqa_searchqa-validation-13650", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-13755", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-13974", "mrqa_searchqa-validation-14014", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-14325", "mrqa_searchqa-validation-14395", "mrqa_searchqa-validation-14464", "mrqa_searchqa-validation-14598", "mrqa_searchqa-validation-14631", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-14775", "mrqa_searchqa-validation-14847", "mrqa_searchqa-validation-14855", "mrqa_searchqa-validation-14934", "mrqa_searchqa-validation-14987", "mrqa_searchqa-validation-15115", "mrqa_searchqa-validation-15123", "mrqa_searchqa-validation-15299", "mrqa_searchqa-validation-15526", "mrqa_searchqa-validation-15869", "mrqa_searchqa-validation-15977", "mrqa_searchqa-validation-16160", "mrqa_searchqa-validation-16266", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-1636", "mrqa_searchqa-validation-16422", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-16808", "mrqa_searchqa-validation-16831", "mrqa_searchqa-validation-16946", "mrqa_searchqa-validation-1793", "mrqa_searchqa-validation-200", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-248", "mrqa_searchqa-validation-2532", "mrqa_searchqa-validation-2576", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-2950", "mrqa_searchqa-validation-3106", "mrqa_searchqa-validation-3121", "mrqa_searchqa-validation-3258", "mrqa_searchqa-validation-3332", "mrqa_searchqa-validation-3405", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-3676", "mrqa_searchqa-validation-3682", "mrqa_searchqa-validation-3718", "mrqa_searchqa-validation-3774", "mrqa_searchqa-validation-3867", "mrqa_searchqa-validation-394", "mrqa_searchqa-validation-3991", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-4191", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-4295", "mrqa_searchqa-validation-4365", "mrqa_searchqa-validation-4369", "mrqa_searchqa-validation-4386", "mrqa_searchqa-validation-443", "mrqa_searchqa-validation-4553", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-4810", "mrqa_searchqa-validation-5028", "mrqa_searchqa-validation-5791", "mrqa_searchqa-validation-5955", "mrqa_searchqa-validation-6041", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-611", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-638", "mrqa_searchqa-validation-6391", "mrqa_searchqa-validation-6394", "mrqa_searchqa-validation-6490", "mrqa_searchqa-validation-6658", "mrqa_searchqa-validation-6727", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-689", "mrqa_searchqa-validation-7017", "mrqa_searchqa-validation-7028", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-7676", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-7746", "mrqa_searchqa-validation-7985", "mrqa_searchqa-validation-8200", "mrqa_searchqa-validation-8225", "mrqa_searchqa-validation-8263", "mrqa_searchqa-validation-8272", "mrqa_searchqa-validation-8379", "mrqa_searchqa-validation-8435", "mrqa_searchqa-validation-8478", "mrqa_searchqa-validation-8532", "mrqa_searchqa-validation-8623", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8764", "mrqa_searchqa-validation-8869", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-9049", "mrqa_searchqa-validation-9254", "mrqa_searchqa-validation-9289", "mrqa_searchqa-validation-9364", "mrqa_searchqa-validation-938", "mrqa_searchqa-validation-9399", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9491", "mrqa_searchqa-validation-952", "mrqa_searchqa-validation-9564", "mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-9876", "mrqa_searchqa-validation-9922", "mrqa_squad-validation-10011", "mrqa_squad-validation-10252", "mrqa_squad-validation-1290", "mrqa_squad-validation-1407", "mrqa_squad-validation-1441", "mrqa_squad-validation-1512", "mrqa_squad-validation-1583", "mrqa_squad-validation-1662", "mrqa_squad-validation-1955", "mrqa_squad-validation-2059", "mrqa_squad-validation-2748", "mrqa_squad-validation-2857", "mrqa_squad-validation-2893", "mrqa_squad-validation-2920", "mrqa_squad-validation-2932", "mrqa_squad-validation-3222", "mrqa_squad-validation-3493", "mrqa_squad-validation-3551", "mrqa_squad-validation-3663", "mrqa_squad-validation-4162", "mrqa_squad-validation-455", "mrqa_squad-validation-5029", "mrqa_squad-validation-5348", "mrqa_squad-validation-57", "mrqa_squad-validation-5730", "mrqa_squad-validation-5765", "mrqa_squad-validation-5956", "mrqa_squad-validation-5995", "mrqa_squad-validation-605", "mrqa_squad-validation-6393", "mrqa_squad-validation-7051", "mrqa_squad-validation-7330", "mrqa_squad-validation-7338", "mrqa_squad-validation-763", "mrqa_squad-validation-7836", "mrqa_squad-validation-8403", "mrqa_squad-validation-8495", "mrqa_squad-validation-8869", "mrqa_squad-validation-9178", "mrqa_squad-validation-9298", "mrqa_squad-validation-9362", "mrqa_squad-validation-9365", "mrqa_squad-validation-9373", "mrqa_squad-validation-9528", "mrqa_squad-validation-9687", "mrqa_squad-validation-973", "mrqa_squad-validation-9940", "mrqa_triviaqa-validation-1055", "mrqa_triviaqa-validation-1237", "mrqa_triviaqa-validation-1315", "mrqa_triviaqa-validation-1358", "mrqa_triviaqa-validation-1931", "mrqa_triviaqa-validation-2071", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2171", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-2251", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2963", "mrqa_triviaqa-validation-3090", "mrqa_triviaqa-validation-3168", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3626", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3905", "mrqa_triviaqa-validation-4255", "mrqa_triviaqa-validation-4412", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-4952", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-6193", "mrqa_triviaqa-validation-6295", "mrqa_triviaqa-validation-6427", "mrqa_triviaqa-validation-6637", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-7280", "mrqa_triviaqa-validation-7312", "mrqa_triviaqa-validation-7383", "mrqa_triviaqa-validation-79", "mrqa_triviaqa-validation-920"], "OKR": 0.884765625, "KG": 0.51484375, "before_eval_results": {"predictions": ["Wisconsin", "Gonzo", "a stagecoach", "Henry Winkler", "faction & action", "Hasta la vista", "the United States", "the guillotine", "fruit", "Tunisia", "a plexus", "a rattlesnake", "Catherine the Great", "absinthe", "John F. Kennedy", "brakes", "Stonewall Jackson", "Captains Courageous", "Beyond the Sea", "the Thin Red Line", "Catherine of Aragon", "a blue rectangle", "Ravi Shankar", "Bangkok", "Spain", "archery", "oblique", "Joe Torre", "meatballs", "Kennedy Space Center", "Rosetta Stone", "Pilate", "the United States", "Marco Polo", "the adder", "sake", "Matt Leinart", "Alabama", "a brew", "Anne Boleyn", "the banjo", "a low-budget mediocre film", "Lolita", "a coyote", "the Graf Zeppelin", "Nirvana", "Frisbee", "Ceres", "Columbus", "prime minister", "Fi", "Telma Hopkins", "AD 95 -- 110", "pepsinogen", "Jorge Lorenzo", "1919", "Paris", "Point Place", "11", "National Aviation Hall of Fame", "Sunday,", "78,000 parents of children ages 3 to 17.iReport.com:", "prisoners at the South Dakota State Penitentiary", "Anne boleyn"], "metric_results": {"EM": 0.796875, "QA-F1": 0.8229166666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4144", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-3584", "mrqa_searchqa-validation-10199", "mrqa_searchqa-validation-3808", "mrqa_searchqa-validation-6175", "mrqa_searchqa-validation-15520", "mrqa_searchqa-validation-4692", "mrqa_searchqa-validation-12145", "mrqa_searchqa-validation-2661", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-10419", "mrqa_newsqa-validation-2384"], "SR": 0.796875, "CSR": 0.5707417582417582, "retrieved_ids": ["mrqa_squad-train-16776", "mrqa_squad-train-45332", "mrqa_squad-train-53068", "mrqa_squad-train-58519", "mrqa_squad-train-31440", "mrqa_squad-train-59107", "mrqa_squad-train-18746", "mrqa_squad-train-49619", "mrqa_squad-train-77069", "mrqa_squad-train-41958", "mrqa_squad-train-84791", "mrqa_squad-train-43564", "mrqa_squad-train-22084", "mrqa_squad-train-79092", "mrqa_squad-train-49036", "mrqa_squad-train-35238", "mrqa_squad-train-7106", "mrqa_squad-train-10705", "mrqa_squad-train-51569", "mrqa_squad-train-74357", "mrqa_squad-train-75634", "mrqa_squad-train-41576", "mrqa_squad-train-72238", "mrqa_squad-train-65347", "mrqa_squad-train-86540", "mrqa_squad-train-31822", "mrqa_squad-train-61807", "mrqa_squad-train-26471", "mrqa_squad-train-23236", "mrqa_squad-train-78850", "mrqa_squad-train-31867", "mrqa_squad-train-33703", "mrqa_searchqa-validation-15847", "mrqa_newsqa-validation-413", "mrqa_newsqa-validation-317", "mrqa_searchqa-validation-11315", "mrqa_naturalquestions-validation-154", "mrqa_searchqa-validation-2752", "mrqa_naturalquestions-validation-1704", "mrqa_newsqa-validation-848", "mrqa_newsqa-validation-2275", "mrqa_newsqa-validation-4211", "mrqa_hotpotqa-validation-305", "mrqa_searchqa-validation-12588", "mrqa_newsqa-validation-2651", "mrqa_naturalquestions-validation-7853", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-2018", "mrqa_naturalquestions-validation-8845", "mrqa_squad-validation-3559", "mrqa_searchqa-validation-1117", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-10265", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-3120", "mrqa_newsqa-validation-792", "mrqa_naturalquestions-validation-7059", "mrqa_naturalquestions-validation-6363", "mrqa_newsqa-validation-4154", "mrqa_naturalquestions-validation-6442", "mrqa_hotpotqa-validation-5346", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-2583", "mrqa_naturalquestions-validation-4544"], "EFR": 0.0, "Overall": 0.5565702266483517}, {"timecode": 91, "before_eval_results": {"predictions": ["Man and Superman", "an enchiladas", "Charles Dickens", "a supernatural being", "Vistula", "Coriolanus", "Texas", "aide-de-camp", "fracture", "Roman Polanski", "Court TV", "sharia", "Jake La Motta", "blog", "Pan Am", "Athens", "Holiday Inn", "the Buffalo Bills", "Bret Harte", "Islam", "Albright", "Mount Everest", "the Harlem Renaissance", "Martha Cannary", "John Lennon", "Ron Sandler", "catcher", "daytime running lights", "Tarzan", "Once", "Warren G. Harding", "Berrigan,", "Marilyn Monroe", "Icarus", "Flanders Field", "London", "Bonnie Raitt", "Friday", "Lord North", "Wrigley\\'s", "the euro", "the narwhal", "the wall", "(John) Marshall", "Wyatt Earp", "Punjabi", "Greece", "Department of Agriculture", "heels", "Frottage", "complementary", "1999", "cheated", "2017", "oskar Schindler", "Henry Hunt", "the Soviet Union", "Jane Mayer", "1993 to 2001", "Lovejoy", "about 12 million in America,", "Charlotte Gainsbourg", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.", "siegfried"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6764678030303031}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.06060606060606061, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-11956", "mrqa_searchqa-validation-16603", "mrqa_searchqa-validation-5822", "mrqa_searchqa-validation-9193", "mrqa_searchqa-validation-15667", "mrqa_searchqa-validation-2500", "mrqa_searchqa-validation-3676", "mrqa_searchqa-validation-736", "mrqa_searchqa-validation-3779", "mrqa_searchqa-validation-359", "mrqa_searchqa-validation-5401", "mrqa_searchqa-validation-7524", "mrqa_searchqa-validation-427", "mrqa_searchqa-validation-1050", "mrqa_searchqa-validation-15838", "mrqa_searchqa-validation-4653", "mrqa_searchqa-validation-3730", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-12975", "mrqa_naturalquestions-validation-7650", "mrqa_triviaqa-validation-6374", "mrqa_triviaqa-validation-1833", "mrqa_hotpotqa-validation-5098", "mrqa_newsqa-validation-2748", "mrqa_triviaqa-validation-5670"], "SR": 0.59375, "CSR": 0.5709918478260869, "retrieved_ids": ["mrqa_squad-train-80705", "mrqa_squad-train-731", "mrqa_squad-train-41173", "mrqa_squad-train-35738", "mrqa_squad-train-44790", "mrqa_squad-train-46460", "mrqa_squad-train-56270", "mrqa_squad-train-48891", "mrqa_squad-train-12545", "mrqa_squad-train-29931", "mrqa_squad-train-2469", "mrqa_squad-train-64333", "mrqa_squad-train-52479", "mrqa_squad-train-65983", "mrqa_squad-train-31671", "mrqa_squad-train-70392", "mrqa_squad-train-75229", "mrqa_squad-train-24052", "mrqa_squad-train-79168", "mrqa_squad-train-60021", "mrqa_squad-train-48153", "mrqa_squad-train-5173", "mrqa_squad-train-78988", "mrqa_squad-train-3780", "mrqa_squad-train-69696", "mrqa_squad-train-3750", "mrqa_squad-train-76045", "mrqa_squad-train-14567", "mrqa_squad-train-21866", "mrqa_squad-train-43458", "mrqa_squad-train-37080", "mrqa_squad-train-73423", "mrqa_triviaqa-validation-86", "mrqa_naturalquestions-validation-9597", "mrqa_naturalquestions-validation-5589", "mrqa_searchqa-validation-13178", "mrqa_naturalquestions-validation-6076", "mrqa_triviaqa-validation-2926", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-7760", "mrqa_searchqa-validation-1085", "mrqa_searchqa-validation-1656", "mrqa_naturalquestions-validation-6564", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-1673", "mrqa_naturalquestions-validation-7310", "mrqa_newsqa-validation-1457", "mrqa_squad-validation-4911", "mrqa_naturalquestions-validation-3614", "mrqa_naturalquestions-validation-3332", "mrqa_newsqa-validation-3641", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-1076", "mrqa_searchqa-validation-3174", "mrqa_naturalquestions-validation-3118", "mrqa_hotpotqa-validation-3806", "mrqa_naturalquestions-validation-10026", "mrqa_newsqa-validation-1813", "mrqa_hotpotqa-validation-1074", "mrqa_naturalquestions-validation-4428", "mrqa_naturalquestions-validation-5096", "mrqa_searchqa-validation-12904"], "EFR": 0.0, "Overall": 0.5566202445652173}, {"timecode": 92, "before_eval_results": {"predictions": ["the Andes", "the matchmaker", "Muhammad Bin Laden", "Tennessee", "diamonds", "a lighthouse", "calcium sulfate", "the Crimean War", "Sinclair Lewis", "Captains Courageous", "the handles", "Central Park", "the roof", "The Tyger", "Chinese", "Howard Hughes", "Pablo Escobar", "the European larch", "Joseph Isadore Lieberman", "asteroids", "first base", "leather", "Ichabod Crane", "T rex", "\"Chinatown.\"", "butterflies", "Lolita", "Nibelung", "tango", "Wesley K. Clark", "sirloin cap", "self", "Billie Jean King", "Bill & George Clinton", "Aristophanes", "Khrushchev", "Green Day", "Las Vegas", "Museum of Modern Art", "canals", "the Galatians", "Lewis Carroll", "meters", "corn on the cob", "Yale", "Brett Favre", "Tennessee", "Jean Harlow", "Manet", "tombs", "The Emperor Jones", "Jason Flemyng", "Eight full seasons", "British citizens", "Nicholas Garland", "Abraham Lincoln", "Europe", "1968", "Vytautas \u0160apranauskas", "Humvee", "a quarter-mile pier crumbling into the sea along with two of his trucks.", "Bright Automotive,", "Harry Nicolaides,", "1957"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6184027777777777}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8774", "mrqa_searchqa-validation-8403", "mrqa_searchqa-validation-2545", "mrqa_searchqa-validation-11004", "mrqa_searchqa-validation-1405", "mrqa_searchqa-validation-16368", "mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-12935", "mrqa_searchqa-validation-2725", "mrqa_searchqa-validation-15955", "mrqa_searchqa-validation-2904", "mrqa_searchqa-validation-12517", "mrqa_searchqa-validation-6758", "mrqa_searchqa-validation-137", "mrqa_searchqa-validation-931", "mrqa_searchqa-validation-1011", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-10904", "mrqa_searchqa-validation-2035", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-8145", "mrqa_naturalquestions-validation-306", "mrqa_naturalquestions-validation-3881", "mrqa_triviaqa-validation-4532", "mrqa_triviaqa-validation-6104", "mrqa_hotpotqa-validation-1040", "mrqa_hotpotqa-validation-2236"], "SR": 0.5625, "CSR": 0.5709005376344086, "retrieved_ids": ["mrqa_squad-train-49439", "mrqa_squad-train-58463", "mrqa_squad-train-86218", "mrqa_squad-train-81657", "mrqa_squad-train-8128", "mrqa_squad-train-55839", "mrqa_squad-train-83255", "mrqa_squad-train-19882", "mrqa_squad-train-76492", "mrqa_squad-train-4275", "mrqa_squad-train-64680", "mrqa_squad-train-23043", "mrqa_squad-train-58076", "mrqa_squad-train-13633", "mrqa_squad-train-79370", "mrqa_squad-train-737", "mrqa_squad-train-22320", "mrqa_squad-train-83001", "mrqa_squad-train-76857", "mrqa_squad-train-41814", "mrqa_squad-train-3953", "mrqa_squad-train-29219", "mrqa_squad-train-21453", "mrqa_squad-train-25337", "mrqa_squad-train-872", "mrqa_squad-train-72874", "mrqa_squad-train-62085", "mrqa_squad-train-66259", "mrqa_squad-train-62469", "mrqa_squad-train-26980", "mrqa_squad-train-40291", "mrqa_squad-train-46039", "mrqa_newsqa-validation-3089", "mrqa_searchqa-validation-3735", "mrqa_searchqa-validation-12904", "mrqa_naturalquestions-validation-2781", "mrqa_searchqa-validation-10105", "mrqa_triviaqa-validation-4501", "mrqa_newsqa-validation-815", "mrqa_triviaqa-validation-7391", "mrqa_squad-validation-4861", "mrqa_naturalquestions-validation-2680", "mrqa_newsqa-validation-1351", "mrqa_searchqa-validation-9876", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-3227", "mrqa_triviaqa-validation-7740", "mrqa_newsqa-validation-1157", "mrqa_naturalquestions-validation-8502", "mrqa_searchqa-validation-13948", "mrqa_searchqa-validation-736", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-1519", "mrqa_searchqa-validation-8272", "mrqa_naturalquestions-validation-1198", "mrqa_squad-validation-1841", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-170", "mrqa_newsqa-validation-2308", "mrqa_naturalquestions-validation-894", "mrqa_newsqa-validation-3677", "mrqa_naturalquestions-validation-9494", "mrqa_newsqa-validation-3403", "mrqa_newsqa-validation-1914"], "EFR": 0.0, "Overall": 0.5566019825268818}, {"timecode": 93, "before_eval_results": {"predictions": ["Blitzkrieg", "the Rhine & the Main", "Kingston", "Cheers", "Lake County, Indiana", "Walt Kelly", "a kidney", "Paris", "Gangbusters", "China", "Maine", "Gertrude Stein", "Ernest Hemingway", "a dryer", "The Da Vinci Code", "Cricket", "Death", "Mount Everest", "Rouen", "Varney Air Lines", "Notre Dame", "Tiberius Nero", "Jupiter", "loverly", "rugby", "the Falklands", "Broadway", "Iceland", "Orwell", "chess", "Heat Transfer", "Jonathan Swift", "Miracle on 34th Street", "turquoise", "Hamlet", "Mickey Mantle & Maris", "copper", "odor", "the Mesozoic", "Eisenhower", "Buffalo Springfield", "the Fourteen Points", "Freddie Mercury", "Mount Aso", "Harry Potter and the Order of the Phoenix", "Geronimo", "Wiley Post", "theMisty Mountains", "Cantaloupe", "London", "Carl Sandburg", "federal republic", "The Enchantress", "Eddie Murphy", "herald", "Kevin", "The Treaty of Waitangi", "Jessica Phyllis Lange", "Heinkel Flugzeugwerke", "Kenan & Kel", "269,000", "August 11, 12 and 13,", "around 8 p.m. local time Thursday", "digging ditches."], "metric_results": {"EM": 0.671875, "QA-F1": 0.7437499999999999}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, false, true, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7402", "mrqa_searchqa-validation-15906", "mrqa_searchqa-validation-5953", "mrqa_searchqa-validation-8812", "mrqa_searchqa-validation-16766", "mrqa_searchqa-validation-15431", "mrqa_searchqa-validation-2638", "mrqa_searchqa-validation-15423", "mrqa_searchqa-validation-13140", "mrqa_searchqa-validation-2724", "mrqa_searchqa-validation-11134", "mrqa_searchqa-validation-6754", "mrqa_searchqa-validation-1788", "mrqa_searchqa-validation-7173", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-10151", "mrqa_naturalquestions-validation-7166", "mrqa_triviaqa-validation-1062", "mrqa_hotpotqa-validation-590", "mrqa_hotpotqa-validation-4360", "mrqa_newsqa-validation-462"], "SR": 0.671875, "CSR": 0.5719747340425532, "retrieved_ids": ["mrqa_squad-train-467", "mrqa_squad-train-82242", "mrqa_squad-train-10483", "mrqa_squad-train-62596", "mrqa_squad-train-13336", "mrqa_squad-train-13118", "mrqa_squad-train-82742", "mrqa_squad-train-81314", "mrqa_squad-train-68699", "mrqa_squad-train-29475", "mrqa_squad-train-53128", "mrqa_squad-train-15354", "mrqa_squad-train-5890", "mrqa_squad-train-74267", "mrqa_squad-train-23865", "mrqa_squad-train-53439", "mrqa_squad-train-55017", "mrqa_squad-train-13637", "mrqa_squad-train-25420", "mrqa_squad-train-26375", "mrqa_squad-train-43100", "mrqa_squad-train-6825", "mrqa_squad-train-3408", "mrqa_squad-train-15803", "mrqa_squad-train-9406", "mrqa_squad-train-4176", "mrqa_squad-train-78591", "mrqa_squad-train-44090", "mrqa_squad-train-67398", "mrqa_squad-train-71494", "mrqa_squad-train-84539", "mrqa_squad-train-51890", "mrqa_triviaqa-validation-3452", "mrqa_searchqa-validation-8763", "mrqa_searchqa-validation-1792", "mrqa_newsqa-validation-1522", "mrqa_searchqa-validation-3449", "mrqa_squad-validation-3118", "mrqa_searchqa-validation-8478", "mrqa_squad-validation-4068", "mrqa_naturalquestions-validation-9837", "mrqa_searchqa-validation-6009", "mrqa_naturalquestions-validation-5034", "mrqa_searchqa-validation-13611", "mrqa_naturalquestions-validation-2571", "mrqa_squad-validation-3699", "mrqa_triviaqa-validation-6972", "mrqa_searchqa-validation-16254", "mrqa_searchqa-validation-3932", "mrqa_searchqa-validation-7162", "mrqa_naturalquestions-validation-2170", "mrqa_searchqa-validation-13806", "mrqa_newsqa-validation-2384", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-25", "mrqa_naturalquestions-validation-10026", "mrqa_triviaqa-validation-5499", "mrqa_searchqa-validation-10359", "mrqa_searchqa-validation-14465", "mrqa_triviaqa-validation-6593", "mrqa_naturalquestions-validation-7733", "mrqa_searchqa-validation-13548", "mrqa_newsqa-validation-2338", "mrqa_newsqa-validation-2808"], "EFR": 0.0, "Overall": 0.5568168218085106}, {"timecode": 94, "before_eval_results": {"predictions": ["E.B. White", "Starfighter", "Muqtada al-Sadr", "zoo", "Omega", "Nixon", "the Hudson River", "the pacarana", "Luxembourg", "Doolittle", "riot", "Lon Chaney", "New York", "the crossword clue", "Sicily", "the Boston Celtics", "rum", "Enron", "the fulcrum", "Central African Republic", "Rudolf Hess", "a fight", "the hippopotamus", "eye", "Bech", "Reagan & Bush", "Washington Irving", "the White Mountains of California", "the Egyptian government", "Existentialism", "mezcal", "Scarface", "Mitch McConnell", "Jim Beaver", "9 to 5", "the U.S. Department of Housing & Urban Development", "Extradition", "the head", "The Nutty Professor", "Michael Collins", "The Sopranos", "The Sound and the Fury", "Dyad", "Brazil", "obsessive-compulsive", "Katie Holmes", "Colloidal O oats", "arteries", "the American Revolution", "Joule", "Justice", "20 November 1989", "about 8 : 20 p.m. on 25 September 2007", "the forces of Andrew Moray and William Wallace defeated the combined English forces of John de Warenne, 6th Earl of Surrey, and Hugh de Cressingham", "February 8, 2015,", "window", "Crispin", "her translation of and commentary on Isaac Newton's book \"Principia\"", "PET", "SKUM", "12-hour-plus shifts", "Rivers", "This will be the second", "Mary Rose Foster"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6930912990196079}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, false, true, false, true, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.8333333333333334, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.9411764705882353, 0.4666666666666667, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-5272", "mrqa_searchqa-validation-5997", "mrqa_searchqa-validation-13399", "mrqa_searchqa-validation-6927", "mrqa_searchqa-validation-12503", "mrqa_searchqa-validation-11991", "mrqa_searchqa-validation-7614", "mrqa_searchqa-validation-11026", "mrqa_searchqa-validation-5724", "mrqa_searchqa-validation-16277", "mrqa_searchqa-validation-14194", "mrqa_searchqa-validation-11851", "mrqa_searchqa-validation-9412", "mrqa_searchqa-validation-11848", "mrqa_searchqa-validation-10970", "mrqa_searchqa-validation-10541", "mrqa_searchqa-validation-7196", "mrqa_searchqa-validation-9869", "mrqa_searchqa-validation-13540", "mrqa_searchqa-validation-15234", "mrqa_searchqa-validation-11521", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-6927", "mrqa_triviaqa-validation-1700", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1587"], "SR": 0.5625, "CSR": 0.571875, "retrieved_ids": ["mrqa_squad-train-45459", "mrqa_squad-train-41099", "mrqa_squad-train-17454", "mrqa_squad-train-67742", "mrqa_squad-train-54756", "mrqa_squad-train-39727", "mrqa_squad-train-44391", "mrqa_squad-train-29502", "mrqa_squad-train-28135", "mrqa_squad-train-35858", "mrqa_squad-train-21867", "mrqa_squad-train-53219", "mrqa_squad-train-40611", "mrqa_squad-train-3258", "mrqa_squad-train-53851", "mrqa_squad-train-24326", "mrqa_squad-train-8640", "mrqa_squad-train-56280", "mrqa_squad-train-86142", "mrqa_squad-train-32698", "mrqa_squad-train-2443", "mrqa_squad-train-29803", "mrqa_squad-train-81234", "mrqa_squad-train-57475", "mrqa_squad-train-84809", "mrqa_squad-train-30458", "mrqa_squad-train-73638", "mrqa_squad-train-31709", "mrqa_squad-train-66860", "mrqa_squad-train-15124", "mrqa_squad-train-57335", "mrqa_squad-train-86484", "mrqa_naturalquestions-validation-8374", "mrqa_searchqa-validation-1843", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-7490", "mrqa_newsqa-validation-2060", "mrqa_searchqa-validation-16576", "mrqa_searchqa-validation-2767", "mrqa_searchqa-validation-11800", "mrqa_newsqa-validation-474", "mrqa_naturalquestions-validation-6116", "mrqa_hotpotqa-validation-5850", "mrqa_searchqa-validation-452", "mrqa_naturalquestions-validation-4097", "mrqa_searchqa-validation-4322", "mrqa_newsqa-validation-706", "mrqa_naturalquestions-validation-9959", "mrqa_searchqa-validation-1833", "mrqa_naturalquestions-validation-6999", "mrqa_searchqa-validation-10494", "mrqa_naturalquestions-validation-2735", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3932", "mrqa_newsqa-validation-1680", "mrqa_newsqa-validation-1303", "mrqa_searchqa-validation-11102", "mrqa_newsqa-validation-880", "mrqa_naturalquestions-validation-10026", "mrqa_newsqa-validation-346", "mrqa_newsqa-validation-2768"], "EFR": 0.0, "Overall": 0.5567968750000001}, {"timecode": 95, "before_eval_results": {"predictions": ["Arseniy Yatsenyuk", "the ramcake", "the Communist Party", "The Goonies", "Velvet Revolver", "Halloween", "the Continental Congress", "Jimi Hendrix", "the Siberian Husky", "the sirloin", "fish", "place", "Casablanca", "The Dutchess", "Detroit River", "(George) Sand", "Northern Exposure", "Kilimanjaro", "Nebuchadnezzar", "a flip", "the Komodo dragon", "Mordecai Richler", "The Simpsons", "The West Wing", "Deviled Eggs", "ravens", "cheese", "(Wade) Pickren", "Pocahontas", "viruses", "John Hersey", "Patricia Arquette", "Ernie Banks", "a grotto", "Prince Harry", "Elizabeth Barrett Browning", "Hades", "the Whig", "Capone, Al", "Maria Callas", "iodine", "Tournament of Kings", "Antony", "Tennyson", "National Geographic", "The Song of the South", "Jerusalem", "a circle", "the Edict of Nantes", "Achilles", "Omega", "at the end of an interrogative sentence : `` How old are you?", "Dr. Lexie Grey", "since 3, 1, and 4 are the first three significant digits of \u03c0", "Nikolaus Esterh\u00e1zy", "exponentiation", "St. Kitts", "1972", "9 February 1971", "Lowe's", "snow,", "Fernando Gonzalez", "Chester Arthur Stiles,", "ants"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5814732142857143}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, true, true, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7142857142857143, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9486", "mrqa_searchqa-validation-6798", "mrqa_searchqa-validation-7141", "mrqa_searchqa-validation-14269", "mrqa_searchqa-validation-10797", "mrqa_searchqa-validation-16346", "mrqa_searchqa-validation-3092", "mrqa_searchqa-validation-16114", "mrqa_searchqa-validation-4356", "mrqa_searchqa-validation-11619", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-7456", "mrqa_searchqa-validation-6973", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14446", "mrqa_searchqa-validation-11643", "mrqa_searchqa-validation-13802", "mrqa_searchqa-validation-15634", "mrqa_searchqa-validation-12087", "mrqa_searchqa-validation-5077", "mrqa_searchqa-validation-5931", "mrqa_naturalquestions-validation-3841", "mrqa_naturalquestions-validation-3028", "mrqa_triviaqa-validation-1656", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-7180", "mrqa_hotpotqa-validation-3472", "mrqa_hotpotqa-validation-5354", "mrqa_triviaqa-validation-4855"], "SR": 0.546875, "CSR": 0.5716145833333333, "retrieved_ids": ["mrqa_squad-train-29542", "mrqa_squad-train-38980", "mrqa_squad-train-34133", "mrqa_squad-train-38183", "mrqa_squad-train-31244", "mrqa_squad-train-33482", "mrqa_squad-train-55312", "mrqa_squad-train-48736", "mrqa_squad-train-71741", "mrqa_squad-train-74917", "mrqa_squad-train-1431", "mrqa_squad-train-34891", "mrqa_squad-train-9555", "mrqa_squad-train-72666", "mrqa_squad-train-69118", "mrqa_squad-train-37437", "mrqa_squad-train-46459", "mrqa_squad-train-34905", "mrqa_squad-train-66790", "mrqa_squad-train-50734", "mrqa_squad-train-43574", "mrqa_squad-train-83714", "mrqa_squad-train-57650", "mrqa_squad-train-26750", "mrqa_squad-train-73626", "mrqa_squad-train-9234", "mrqa_squad-train-84403", "mrqa_squad-train-80886", "mrqa_squad-train-79236", "mrqa_squad-train-5721", "mrqa_squad-train-38551", "mrqa_squad-train-37429", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3613", "mrqa_newsqa-validation-2562", "mrqa_squad-validation-1662", "mrqa_squad-validation-4452", "mrqa_triviaqa-validation-1613", "mrqa_naturalquestions-validation-7203", "mrqa_newsqa-validation-3144", "mrqa_naturalquestions-validation-7027", "mrqa_searchqa-validation-3736", "mrqa_searchqa-validation-7010", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-validation-10009", "mrqa_hotpotqa-validation-5541", "mrqa_naturalquestions-validation-8999", "mrqa_newsqa-validation-3841", "mrqa_searchqa-validation-1117", "mrqa_newsqa-validation-3826", "mrqa_searchqa-validation-37", "mrqa_newsqa-validation-3321", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-2399", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1256", "mrqa_newsqa-validation-2308", "mrqa_searchqa-validation-11800", "mrqa_triviaqa-validation-2250", "mrqa_newsqa-validation-267", "mrqa_newsqa-validation-3601", "mrqa_hotpotqa-validation-1076"], "EFR": 0.0, "Overall": 0.5567447916666666}, {"timecode": 96, "before_eval_results": {"predictions": ["innovation", "a wheel", "assemble", "hot air balloons", "pathetic fallacy", "Nomar Garciaparra", "John Glenn", "the heron", "Gus Grissom", "the White Company", "New Balance", "General Andrew Jackson", "Joan of Arc", "finale", "mollusca", "Camille Claudel", "the East River", "caricaturist", "the Seven Years' War", "Meg Tilly", "Uncle Henry", "madding", "Indian tribes", "Ron Sandler", "the Netherlands", "Woodrow Wilson", "the Osmonds", "IN plants, they're reproductive structures", "the Tribbles", "Billy Joel", "Wyoming", "Tigger", "Geneva", "Frank Sinatra", "pastrami", "an Islamic leadership position", "backstroke", "Muhammad", "Sydney", "Dermatology", "Solomon", "Mikey: Help! Help!", "Georges Pompidou", "20", "a snowmobile", "Carrie and Irene Miner", "Surinam", "bloom", "Czechoslovakia", "the Corinthians", "Dilithium", "Help!", "1997", "2010", "1215", "Conchita Wurst", "president", "IndiGo", "Robert Gibson", "11 Grands Prix wins and 68 podiums", "skeletal dysplasia,", "The Screening Room", "$150 billion", "Rio Grande"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6332217261904762}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14411", "mrqa_searchqa-validation-7604", "mrqa_searchqa-validation-14762", "mrqa_searchqa-validation-10665", "mrqa_searchqa-validation-6065", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-16749", "mrqa_searchqa-validation-9812", "mrqa_searchqa-validation-12484", "mrqa_searchqa-validation-10276", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-359", "mrqa_searchqa-validation-8963", "mrqa_searchqa-validation-6419", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-3467", "mrqa_searchqa-validation-6532", "mrqa_searchqa-validation-11872", "mrqa_searchqa-validation-3066", "mrqa_searchqa-validation-7328", "mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-2149", "mrqa_searchqa-validation-12162", "mrqa_triviaqa-validation-2845", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-4265", "mrqa_newsqa-validation-1387"], "SR": 0.578125, "CSR": 0.5716817010309279, "retrieved_ids": ["mrqa_squad-train-7838", "mrqa_squad-train-6320", "mrqa_squad-train-1643", "mrqa_squad-train-29448", "mrqa_squad-train-22577", "mrqa_squad-train-78926", "mrqa_squad-train-36692", "mrqa_squad-train-19653", "mrqa_squad-train-36118", "mrqa_squad-train-12288", "mrqa_squad-train-61276", "mrqa_squad-train-72634", "mrqa_squad-train-17058", "mrqa_squad-train-15494", "mrqa_squad-train-10408", "mrqa_squad-train-67368", "mrqa_squad-train-2968", "mrqa_squad-train-67965", "mrqa_squad-train-80923", "mrqa_squad-train-25665", "mrqa_squad-train-21796", "mrqa_squad-train-73226", "mrqa_squad-train-23578", "mrqa_squad-train-44432", "mrqa_squad-train-16545", "mrqa_squad-train-46943", "mrqa_squad-train-38953", "mrqa_squad-train-7894", "mrqa_squad-train-39916", "mrqa_squad-train-36806", "mrqa_squad-train-52643", "mrqa_squad-train-20782", "mrqa_naturalquestions-validation-7598", "mrqa_squad-validation-4068", "mrqa_hotpotqa-validation-4198", "mrqa_newsqa-validation-2701", "mrqa_triviaqa-validation-5467", "mrqa_searchqa-validation-14384", "mrqa_newsqa-validation-1680", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-7334", "mrqa_naturalquestions-validation-4664", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-873", "mrqa_squad-validation-2788", "mrqa_searchqa-validation-8399", "mrqa_newsqa-validation-2617", "mrqa_searchqa-validation-7197", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2991", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-5385", "mrqa_newsqa-validation-2942", "mrqa_searchqa-validation-2804", "mrqa_newsqa-validation-2859", "mrqa_squad-validation-1891", "mrqa_triviaqa-validation-7430", "mrqa_searchqa-validation-12042", "mrqa_newsqa-validation-3601", "mrqa_newsqa-validation-697", "mrqa_hotpotqa-validation-3895", "mrqa_newsqa-validation-320", "mrqa_triviaqa-validation-4457", "mrqa_newsqa-validation-1511"], "EFR": 0.0, "Overall": 0.5567582152061856}, {"timecode": 97, "before_eval_results": {"predictions": ["Rear Window", "nomads", "Washington", "tribbles", "the Death Valley", "Shakespeare", "Cobb salad", "Hydra", "Gulliver\\'s Travels", "the Distant Early Warning Line", "Tordis and Toralv Maurstad", "peanut butter Fudge", "the North-East", "sonic boom", "Fergie", "Sacramento", "the emerald", "Swiss Cheese", "Ernest Hemingway", "Blue Mountain Coffee", "Annika Sorenstam", "atoms", "Grenadine", "The Innocents Abroad", "Las Vegas", "Hawaii", "Helen Keller", "the tooth Fairy", "General Sir Henry Shrapnel", "Venezuela", "Penelopeia", "Oklahoma City", "Brazil", "Chicago The Musical", "the dugong", "\"Treading Water", "1850", "the French and Indian War", "chess", "Waterloo", "a waterbed", "a mulatta", "a deck of cards", "a propeller", "bonnet", "155 feet", "Alexander Calder", "the cruller", "Helium", "Tokyo", "cheese", "Charles Perrault", "Bali, Indonesia", "c. 1000 AD", "Tony Blair", "bacteria", "big Dipper", "Sofia the First", "Africa", "Ben Elton", "an annual road trip,", "Schalke", "April 22,", "Sugar Ray Robinson"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6726190476190477}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2611", "mrqa_searchqa-validation-596", "mrqa_searchqa-validation-6978", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-8091", "mrqa_searchqa-validation-3549", "mrqa_searchqa-validation-1278", "mrqa_searchqa-validation-2001", "mrqa_searchqa-validation-10671", "mrqa_searchqa-validation-10013", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-6393", "mrqa_searchqa-validation-5233", "mrqa_searchqa-validation-13140", "mrqa_searchqa-validation-16676", "mrqa_searchqa-validation-15997", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-10389", "mrqa_searchqa-validation-11177", "mrqa_naturalquestions-validation-8823", "mrqa_hotpotqa-validation-3521", "mrqa_hotpotqa-validation-3237"], "SR": 0.609375, "CSR": 0.5720663265306123, "retrieved_ids": ["mrqa_squad-train-80946", "mrqa_squad-train-39519", "mrqa_squad-train-74561", "mrqa_squad-train-36056", "mrqa_squad-train-59635", "mrqa_squad-train-44295", "mrqa_squad-train-75066", "mrqa_squad-train-73813", "mrqa_squad-train-85432", "mrqa_squad-train-71299", "mrqa_squad-train-81292", "mrqa_squad-train-64023", "mrqa_squad-train-65597", "mrqa_squad-train-77106", "mrqa_squad-train-76516", "mrqa_squad-train-72723", "mrqa_squad-train-41006", "mrqa_squad-train-1862", "mrqa_squad-train-23890", "mrqa_squad-train-12571", "mrqa_squad-train-12459", "mrqa_squad-train-6561", "mrqa_squad-train-37609", "mrqa_squad-train-63727", "mrqa_squad-train-21253", "mrqa_squad-train-8114", "mrqa_squad-train-59674", "mrqa_squad-train-64075", "mrqa_squad-train-41783", "mrqa_squad-train-30728", "mrqa_squad-train-21503", "mrqa_squad-train-55031", "mrqa_searchqa-validation-15953", "mrqa_searchqa-validation-1368", "mrqa_newsqa-validation-3406", "mrqa_naturalquestions-validation-754", "mrqa_searchqa-validation-12706", "mrqa_naturalquestions-validation-4196", "mrqa_triviaqa-validation-3889", "mrqa_squad-validation-1215", "mrqa_naturalquestions-validation-276", "mrqa_newsqa-validation-1309", "mrqa_naturalquestions-validation-4247", "mrqa_newsqa-validation-3190", "mrqa_searchqa-validation-13802", "mrqa_naturalquestions-validation-5370", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-742", "mrqa_naturalquestions-validation-3592", "mrqa_squad-validation-3699", "mrqa_newsqa-validation-3861", "mrqa_triviaqa-validation-3468", "mrqa_newsqa-validation-817", "mrqa_newsqa-validation-4077", "mrqa_squad-validation-4908", "mrqa_triviaqa-validation-3010", "mrqa_searchqa-validation-8092", "mrqa_naturalquestions-validation-7549", "mrqa_searchqa-validation-13908", "mrqa_searchqa-validation-6374", "mrqa_triviaqa-validation-2858", "mrqa_hotpotqa-validation-4027", "mrqa_naturalquestions-validation-5968"], "EFR": 0.0, "Overall": 0.5568351403061225}, {"timecode": 98, "before_eval_results": {"predictions": ["Jacob Marley", "Magnum", "the Ottoman Empire", "Helen of Troy", "a whale", "New York", "Himalaya", "Wayne's World", "Poland", "Kwanzaa", "nuclear submarine", "Russell Crowe", "the Star Ship", "a Shelby GT350", "tears", "roulette", "W. Somerset Maugham", "Christo", "Henri Matisse", "the bottom", "All Quiet on the Western Front", "the Red Hot Chili Peppers", "Sanskrit", "one foot", "Montgomery Clift", "the Hellenic Republic", "Ford", "Sidney Sheldon", "Surround", "Faraday", "Breakfast", "Krispy Kreme", "the foreign dignitary", "Stanton Avery", "the Death Valley", "the Cumberland Gap", "yolk", "Defense", "a lap of luxury", "a brown rat", "Cleveland", "Edgar Allan Poe", "Belgium", "Georges Pompidou", "Grover Cleveland", "The Kingston Trio", "Luxor", "Spain", "The Beatles", "avocado", "Florence", "Scarlett Johansson", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Madison, Wisconsin, United States", "his finger", "Duncan I of Scotland", "Macbeth", "Carol Ann Duffy", "Ravenna", "travel diary", "keeping malls safe.", "Sgt. Jason Bendett", "Bahrami,", "organizing the distribution of wheelchairs,"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6988782051282052}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14622", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-14510", "mrqa_searchqa-validation-9510", "mrqa_searchqa-validation-11733", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14079", "mrqa_searchqa-validation-3993", "mrqa_searchqa-validation-5008", "mrqa_searchqa-validation-3898", "mrqa_searchqa-validation-13658", "mrqa_searchqa-validation-1978", "mrqa_searchqa-validation-16035", "mrqa_searchqa-validation-4971", "mrqa_searchqa-validation-2340", "mrqa_searchqa-validation-13186", "mrqa_searchqa-validation-3066", "mrqa_searchqa-validation-2666", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-10014", "mrqa_naturalquestions-validation-6874", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-7585", "mrqa_hotpotqa-validation-1364", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1644"], "SR": 0.59375, "CSR": 0.5722853535353536, "retrieved_ids": ["mrqa_squad-train-15393", "mrqa_squad-train-69941", "mrqa_squad-train-54755", "mrqa_squad-train-15526", "mrqa_squad-train-24772", "mrqa_squad-train-65954", "mrqa_squad-train-48912", "mrqa_squad-train-82325", "mrqa_squad-train-80883", "mrqa_squad-train-45286", "mrqa_squad-train-594", "mrqa_squad-train-73370", "mrqa_squad-train-30164", "mrqa_squad-train-60735", "mrqa_squad-train-33478", "mrqa_squad-train-11199", "mrqa_squad-train-45092", "mrqa_squad-train-42359", "mrqa_squad-train-33689", "mrqa_squad-train-10214", "mrqa_squad-train-47042", "mrqa_squad-train-20014", "mrqa_squad-train-656", "mrqa_squad-train-65991", "mrqa_squad-train-54677", "mrqa_squad-train-81213", "mrqa_squad-train-78963", "mrqa_squad-train-13871", "mrqa_squad-train-68827", "mrqa_squad-train-43749", "mrqa_squad-train-24399", "mrqa_squad-train-30955", "mrqa_searchqa-validation-3540", "mrqa_searchqa-validation-15431", "mrqa_newsqa-validation-2308", "mrqa_triviaqa-validation-4019", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-2143", "mrqa_hotpotqa-validation-5251", "mrqa_searchqa-validation-7196", "mrqa_triviaqa-validation-3889", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-3058", "mrqa_naturalquestions-validation-1047", "mrqa_searchqa-validation-7301", "mrqa_naturalquestions-validation-6089", "mrqa_naturalquestions-validation-359", "mrqa_newsqa-validation-2976", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-7760", "mrqa_searchqa-validation-3332", "mrqa_newsqa-validation-2821", "mrqa_newsqa-validation-1702", "mrqa_squad-validation-10506", "mrqa_naturalquestions-validation-3598", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-2913", "mrqa_searchqa-validation-5963", "mrqa_naturalquestions-validation-9675", "mrqa_searchqa-validation-13540", "mrqa_triviaqa-validation-6066", "mrqa_searchqa-validation-9506", "mrqa_squad-validation-4528", "mrqa_searchqa-validation-5045"], "EFR": 0.0, "Overall": 0.5568789457070707}, {"timecode": 99, "UKR": 0.8125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1350", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-1952", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-2208", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2600", "mrqa_hotpotqa-validation-3000", "mrqa_hotpotqa-validation-3362", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-3765", "mrqa_hotpotqa-validation-3845", "mrqa_hotpotqa-validation-4580", "mrqa_hotpotqa-validation-4791", "mrqa_hotpotqa-validation-512", "mrqa_hotpotqa-validation-5199", "mrqa_hotpotqa-validation-5556", "mrqa_hotpotqa-validation-5604", "mrqa_hotpotqa-validation-92", "mrqa_hotpotqa-validation-996", "mrqa_naturalquestions-validation-10070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-10368", "mrqa_naturalquestions-validation-10485", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-10639", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1147", "mrqa_naturalquestions-validation-1248", "mrqa_naturalquestions-validation-1330", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-1555", "mrqa_naturalquestions-validation-1655", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-190", "mrqa_naturalquestions-validation-2234", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-2896", "mrqa_naturalquestions-validation-2903", "mrqa_naturalquestions-validation-3043", "mrqa_naturalquestions-validation-3055", "mrqa_naturalquestions-validation-3470", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-3598", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-365", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-413", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-4177", "mrqa_naturalquestions-validation-4428", "mrqa_naturalquestions-validation-4942", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-5256", "mrqa_naturalquestions-validation-5338", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5466", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-5662", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-6285", "mrqa_naturalquestions-validation-6324", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-673", "mrqa_naturalquestions-validation-6780", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-7166", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7351", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7670", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-8016", "mrqa_naturalquestions-validation-8153", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-8766", "mrqa_naturalquestions-validation-8972", "mrqa_naturalquestions-validation-8999", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-9428", "mrqa_naturalquestions-validation-954", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9850", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-9959", "mrqa_naturalquestions-validation-9967", "mrqa_newsqa-validation-1008", "mrqa_newsqa-validation-1037", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-114", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-117", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1235", "mrqa_newsqa-validation-1256", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1302", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1310", "mrqa_newsqa-validation-1342", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1565", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-159", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-1758", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-1849", "mrqa_newsqa-validation-1879", "mrqa_newsqa-validation-1890", "mrqa_newsqa-validation-1902", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-200", "mrqa_newsqa-validation-2009", "mrqa_newsqa-validation-2018", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2044", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-2055", "mrqa_newsqa-validation-2060", "mrqa_newsqa-validation-2089", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2098", "mrqa_newsqa-validation-2141", "mrqa_newsqa-validation-2186", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-222", "mrqa_newsqa-validation-222", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-2280", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2375", "mrqa_newsqa-validation-2390", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2446", "mrqa_newsqa-validation-2464", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-258", "mrqa_newsqa-validation-2584", "mrqa_newsqa-validation-2629", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2816", "mrqa_newsqa-validation-2842", "mrqa_newsqa-validation-2843", "mrqa_newsqa-validation-2854", "mrqa_newsqa-validation-2865", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-2924", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2949", "mrqa_newsqa-validation-2953", "mrqa_newsqa-validation-297", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-3069", "mrqa_newsqa-validation-3082", "mrqa_newsqa-validation-317", "mrqa_newsqa-validation-3178", "mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-327", "mrqa_newsqa-validation-3345", "mrqa_newsqa-validation-3355", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-339", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3490", "mrqa_newsqa-validation-35", "mrqa_newsqa-validation-3591", "mrqa_newsqa-validation-3608", "mrqa_newsqa-validation-3609", "mrqa_newsqa-validation-3662", "mrqa_newsqa-validation-3672", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3784", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3850", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-3878", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3909", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-3985", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4075", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-4130", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-538", "mrqa_newsqa-validation-546", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-695", "mrqa_newsqa-validation-825", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-878", "mrqa_newsqa-validation-971", "mrqa_searchqa-validation-10013", "mrqa_searchqa-validation-10129", "mrqa_searchqa-validation-1013", "mrqa_searchqa-validation-10262", "mrqa_searchqa-validation-10298", "mrqa_searchqa-validation-10505", "mrqa_searchqa-validation-10549", "mrqa_searchqa-validation-10616", "mrqa_searchqa-validation-10681", "mrqa_searchqa-validation-10777", "mrqa_searchqa-validation-10853", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-11091", "mrqa_searchqa-validation-11095", "mrqa_searchqa-validation-11183", "mrqa_searchqa-validation-11477", "mrqa_searchqa-validation-11513", "mrqa_searchqa-validation-11514", "mrqa_searchqa-validation-11557", "mrqa_searchqa-validation-12030", "mrqa_searchqa-validation-12075", "mrqa_searchqa-validation-12162", "mrqa_searchqa-validation-12248", "mrqa_searchqa-validation-12331", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-12484", "mrqa_searchqa-validation-126", "mrqa_searchqa-validation-12765", "mrqa_searchqa-validation-12913", "mrqa_searchqa-validation-1301", "mrqa_searchqa-validation-13100", "mrqa_searchqa-validation-133", "mrqa_searchqa-validation-13313", "mrqa_searchqa-validation-13326", "mrqa_searchqa-validation-13548", "mrqa_searchqa-validation-13573", "mrqa_searchqa-validation-13650", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-13755", "mrqa_searchqa-validation-13918", "mrqa_searchqa-validation-13974", "mrqa_searchqa-validation-14014", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-14325", "mrqa_searchqa-validation-14464", "mrqa_searchqa-validation-14598", "mrqa_searchqa-validation-14631", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-14720", "mrqa_searchqa-validation-14775", "mrqa_searchqa-validation-14847", "mrqa_searchqa-validation-14855", "mrqa_searchqa-validation-14934", "mrqa_searchqa-validation-14987", "mrqa_searchqa-validation-15115", "mrqa_searchqa-validation-15123", "mrqa_searchqa-validation-15299", "mrqa_searchqa-validation-1542", "mrqa_searchqa-validation-15526", "mrqa_searchqa-validation-15977", "mrqa_searchqa-validation-16131", "mrqa_searchqa-validation-16160", "mrqa_searchqa-validation-16262", "mrqa_searchqa-validation-16266", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-1636", "mrqa_searchqa-validation-16422", "mrqa_searchqa-validation-16598", "mrqa_searchqa-validation-16603", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-16749", "mrqa_searchqa-validation-16808", "mrqa_searchqa-validation-16831", "mrqa_searchqa-validation-16946", "mrqa_searchqa-validation-1793", "mrqa_searchqa-validation-1895", "mrqa_searchqa-validation-200", "mrqa_searchqa-validation-2035", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-2340", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-2449", "mrqa_searchqa-validation-2468", "mrqa_searchqa-validation-248", "mrqa_searchqa-validation-2532", "mrqa_searchqa-validation-2576", "mrqa_searchqa-validation-2725", "mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-2950", "mrqa_searchqa-validation-3106", "mrqa_searchqa-validation-3121", "mrqa_searchqa-validation-3258", "mrqa_searchqa-validation-3332", "mrqa_searchqa-validation-3399", "mrqa_searchqa-validation-3405", "mrqa_searchqa-validation-3441", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-3676", "mrqa_searchqa-validation-3774", "mrqa_searchqa-validation-3779", "mrqa_searchqa-validation-3867", "mrqa_searchqa-validation-394", "mrqa_searchqa-validation-3991", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-4191", "mrqa_searchqa-validation-4197", "mrqa_searchqa-validation-4266", "mrqa_searchqa-validation-4295", "mrqa_searchqa-validation-4365", "mrqa_searchqa-validation-4369", "mrqa_searchqa-validation-4386", "mrqa_searchqa-validation-443", "mrqa_searchqa-validation-4553", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-4763", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-5724", "mrqa_searchqa-validation-5791", "mrqa_searchqa-validation-5955", "mrqa_searchqa-validation-5997", "mrqa_searchqa-validation-6041", "mrqa_searchqa-validation-611", "mrqa_searchqa-validation-6334", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-638", "mrqa_searchqa-validation-6391", "mrqa_searchqa-validation-6394", "mrqa_searchqa-validation-6658", "mrqa_searchqa-validation-6727", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-689", "mrqa_searchqa-validation-6937", "mrqa_searchqa-validation-7017", "mrqa_searchqa-validation-7028", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-7405", "mrqa_searchqa-validation-7456", "mrqa_searchqa-validation-7657", "mrqa_searchqa-validation-7676", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-7746", "mrqa_searchqa-validation-7790", "mrqa_searchqa-validation-7985", "mrqa_searchqa-validation-8055", "mrqa_searchqa-validation-8184", "mrqa_searchqa-validation-8190", "mrqa_searchqa-validation-8200", "mrqa_searchqa-validation-8225", "mrqa_searchqa-validation-8263", "mrqa_searchqa-validation-8272", "mrqa_searchqa-validation-8379", "mrqa_searchqa-validation-8435", "mrqa_searchqa-validation-8478", "mrqa_searchqa-validation-8532", "mrqa_searchqa-validation-8623", "mrqa_searchqa-validation-8746", "mrqa_searchqa-validation-8764", "mrqa_searchqa-validation-8869", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-9049", "mrqa_searchqa-validation-9087", "mrqa_searchqa-validation-9254", "mrqa_searchqa-validation-9289", "mrqa_searchqa-validation-9364", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9425", "mrqa_searchqa-validation-9491", "mrqa_searchqa-validation-952", "mrqa_searchqa-validation-9528", "mrqa_searchqa-validation-9564", "mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-9922", "mrqa_squad-validation-10011", "mrqa_squad-validation-10252", "mrqa_squad-validation-1290", "mrqa_squad-validation-1407", "mrqa_squad-validation-1441", "mrqa_squad-validation-1512", "mrqa_squad-validation-1583", "mrqa_squad-validation-1662", "mrqa_squad-validation-1955", "mrqa_squad-validation-2059", "mrqa_squad-validation-2748", "mrqa_squad-validation-2857", "mrqa_squad-validation-2893", "mrqa_squad-validation-2920", "mrqa_squad-validation-2932", "mrqa_squad-validation-3222", "mrqa_squad-validation-3493", "mrqa_squad-validation-3551", "mrqa_squad-validation-3663", "mrqa_squad-validation-4162", "mrqa_squad-validation-5029", "mrqa_squad-validation-5348", "mrqa_squad-validation-57", "mrqa_squad-validation-5730", "mrqa_squad-validation-5765", "mrqa_squad-validation-5956", "mrqa_squad-validation-5995", "mrqa_squad-validation-605", "mrqa_squad-validation-7330", "mrqa_squad-validation-7338", "mrqa_squad-validation-763", "mrqa_squad-validation-7836", "mrqa_squad-validation-8403", "mrqa_squad-validation-8495", "mrqa_squad-validation-8869", "mrqa_squad-validation-9178", "mrqa_squad-validation-9298", "mrqa_squad-validation-9362", "mrqa_squad-validation-9365", "mrqa_squad-validation-9373", "mrqa_squad-validation-9528", "mrqa_squad-validation-9687", "mrqa_squad-validation-973", "mrqa_squad-validation-9940", "mrqa_triviaqa-validation-1055", "mrqa_triviaqa-validation-1237", "mrqa_triviaqa-validation-1315", "mrqa_triviaqa-validation-1358", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1931", "mrqa_triviaqa-validation-2071", "mrqa_triviaqa-validation-2101", "mrqa_triviaqa-validation-2171", "mrqa_triviaqa-validation-2202", "mrqa_triviaqa-validation-2251", "mrqa_triviaqa-validation-3090", "mrqa_triviaqa-validation-3168", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3626", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3905", "mrqa_triviaqa-validation-4255", "mrqa_triviaqa-validation-4412", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-448", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-4952", "mrqa_triviaqa-validation-5302", "mrqa_triviaqa-validation-538", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-6193", "mrqa_triviaqa-validation-6427", "mrqa_triviaqa-validation-6637", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-7180", "mrqa_triviaqa-validation-7280", "mrqa_triviaqa-validation-7312", "mrqa_triviaqa-validation-7383", "mrqa_triviaqa-validation-79", "mrqa_triviaqa-validation-920"], "OKR": 0.859375, "KG": 0.51484375, "before_eval_results": {"predictions": ["the Hundred Years' War", "the backbone", "Alfred Binet", "Venial sin", "caution", "\"The Wizard of Oz:", "shrimp", "the Spanish Republic", "Vanessa Hudgens", "King Kong", "Sauron in Westeros", "a lemur", "Rhiannon", "Scotland", "Beaver", "Kurdish", "Ann Richards", "half-staff", "Korea", "Langston Hughes", "New Coke", "The Color Purple", "the THX surround sound system", "Macbeth", "El Greco", "General Motors", "Little Big Town", "a shark", "Frankie Valli", "a Dagger", "a backpacking route", "pineapple", "Buffalo nickel", "Pink", "Balaam", "ask for help", "Jamestown", "Joy Division", "fondue", "VOD", "Schwarzenegger", "AT&T", "Animal Crackers", "oblivion", "Goethe", "an organ", "Texas Chainsaw Massacre", "Finland", "Students for a Democratic Society", "All the King\\'s Men", "Liceo", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "18", "July 14, 2017", "James Mason", "a sackbut", "Anne Frank", "YG Entertainment", "Nova Scotia", "Rochdale", "Matamoros, Mexico,", "Florida", "Capitol Hill.", "The palace has 775 rooms"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7052083333333334}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, true, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-14942", "mrqa_searchqa-validation-4977", "mrqa_searchqa-validation-5987", "mrqa_searchqa-validation-13935", "mrqa_searchqa-validation-10474", "mrqa_searchqa-validation-7925", "mrqa_searchqa-validation-13979", "mrqa_searchqa-validation-14822", "mrqa_searchqa-validation-6184", "mrqa_searchqa-validation-8822", "mrqa_searchqa-validation-856", "mrqa_searchqa-validation-6823", "mrqa_searchqa-validation-6740", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-11396", "mrqa_searchqa-validation-1590", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-1302", "mrqa_triviaqa-validation-2452", "mrqa_newsqa-validation-1996", "mrqa_naturalquestions-validation-9572"], "SR": 0.671875, "CSR": 0.57328125, "retrieved_ids": ["mrqa_squad-train-42279", "mrqa_squad-train-11085", "mrqa_squad-train-63368", "mrqa_squad-train-17338", "mrqa_squad-train-62957", "mrqa_squad-train-48463", "mrqa_squad-train-25971", "mrqa_squad-train-64322", "mrqa_squad-train-75746", "mrqa_squad-train-34879", "mrqa_squad-train-40710", "mrqa_squad-train-9844", "mrqa_squad-train-17181", "mrqa_squad-train-84970", "mrqa_squad-train-72117", "mrqa_squad-train-21965", "mrqa_squad-train-85494", "mrqa_squad-train-19677", "mrqa_squad-train-48369", "mrqa_squad-train-64", "mrqa_squad-train-50220", "mrqa_squad-train-66282", "mrqa_squad-train-68064", "mrqa_squad-train-59331", "mrqa_squad-train-17871", "mrqa_squad-train-78880", "mrqa_squad-train-5294", "mrqa_squad-train-39969", "mrqa_squad-train-5957", "mrqa_squad-train-42960", "mrqa_squad-train-80351", "mrqa_squad-train-72329", "mrqa_naturalquestions-validation-1199", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-832", "mrqa_squad-validation-4452", "mrqa_newsqa-validation-1289", "mrqa_triviaqa-validation-4449", "mrqa_searchqa-validation-4535", "mrqa_searchqa-validation-16892", "mrqa_newsqa-validation-1077", "mrqa_newsqa-validation-1808", "mrqa_newsqa-validation-1509", "mrqa_searchqa-validation-9174", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-3066", "mrqa_newsqa-validation-360", "mrqa_hotpotqa-validation-2978", "mrqa_newsqa-validation-2246", "mrqa_triviaqa-validation-533", "mrqa_searchqa-validation-3540", "mrqa_naturalquestions-validation-633", "mrqa_searchqa-validation-6074", "mrqa_naturalquestions-validation-10114", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-2089", "mrqa_hotpotqa-validation-1239", "mrqa_newsqa-validation-3343", "mrqa_searchqa-validation-10318", "mrqa_searchqa-validation-6754", "mrqa_naturalquestions-validation-7262", "mrqa_newsqa-validation-3355", "mrqa_naturalquestions-validation-190", "mrqa_searchqa-validation-11473"], "EFR": 0.0, "Overall": 0.5519999999999999}]}