{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 2120, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.859375, "QA-F1": 0.8760416666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.859375, "CSR": 0.8671875, "EFR": 1.0, "Overall": 0.93359375}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "hot winds blowing from nearby semi-deserts", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "whether this connection is relevant on microscales", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "low ratio of organic matter to salt and water", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "time goes", "guardian", "guardian", "abolitionists", "50 feet"], "metric_results": {"EM": 0.625, "QA-F1": 0.6721252705627705}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.625, "CSR": 0.7864583333333334, "EFR": 1.0, "Overall": 0.8932291666666667}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "in committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "a group that included priests, religious leaders, and case workers as well as teachers", "Vistula River", "1290", "21 October 1512", "427,652", "double membrane", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "comb plates", "calcitriol", "Krak\u00f3w", "time", "since at least the mid-14th century", "the mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "the fundamental means by which forces are emitted and absorbed", "the A1 (Gateshead Newcastle Western Bypass", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail that have a coiled shell that is large enough for the animal to retract completely into", "Arestes", "the Galapagos Islands", "Connecticut", "the water changes from a liquid to a gas", "the best minds in the travel industry", "before", "a major raw", "Mycenaean", "a biological process that displays an endogenous, entrainable", "the Huyvesant Street", "the Normandy Landings", "John Dillinger", "the fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6872294372294372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-2192", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-10310", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-22", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.65625, "CSR": 0.75390625, "EFR": 0.9545454545454546, "Overall": 0.8542258522727273}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25 percent", "May 2013", "Torchwood (2006\u20132011) and The Sarah Jane Adventures (2007\u20132011", "capturing prey", "c4", "pasture for cattle", "Ford", "1,300,000", "rubisco starts accidentally adding oxygen to sugar precursors", "two tumen (20,000 soldiers", "eight", "A computational problem", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "Malkin Athletic Center", "24\u201310", "6.7+", "empires", "domestic legislation of the Scottish Parliament", "belly flab", "New York City Mayor Michael Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "tweed", "World War II", "semiconductors", "Tim Clark, Matt Kuchar and Bubba Watson", "fastest circumnavigation of the globe in a powerboat", "the man facing up, with his arms out to the side", "the foyer of the BBC building in Glasgow, Scotland", "buddhism", "Manchester City", "Noriko Savoie", "three", "change course", "Tsvangirai", "a Lion Among Men", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a miracle food", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.6875, "QA-F1": 0.751082251082251}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.2666666666666667, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-7626", "mrqa_squad-validation-8874", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.6875, "CSR": 0.740625, "EFR": 1.0, "Overall": 0.8703125}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium", "QuickBooks", "surface condensers", "clinical pharmacists", "seal", "Philip Howard", "Duke Richard II of Normandy", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "higher than normal O2 exposure for a fee", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "gurus, mullahs, rabbis, pastors/youth pastors and lamas", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Anjuna beach", "How I Met Your Mother", "France's famous Louvre museum", "Leo Frank", "in Thessaloniki and Athens", "Graziano Transmissioni", "opposition parties", "204,000", "United's", "release of the four men", "first lady Michelle Obama is weighing in on the issue by focusing on how health care can affect families.", "Ed McMahon", "Magna Carta", "Democratic VP candidate", "at the University of Alabama in Huntsville", "Ali Larijani", "paper ballots", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "promotes fuel economy and safety while boosted the economy.", "resting heart rate over 100 beats per minute", "Suffolk Punch", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6654204179141292}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.9166666666666666, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-8715", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-1852", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.578125, "CSR": 0.7135416666666667, "EFR": 1.0, "Overall": 0.8567708333333334}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "unfairly biased against Genghis Khan", "Warsaw Stock Exchange", "They may exist to increase the chloroplast's surface area for cross-membrane transport, because they are often branched and entangled with the endoplasmic reticulum.", "computational resource", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "a straight line", "In the autumn of 1991, talks were held for the broadcast rights for Premier League for a five-year period, from the 1992 season.", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "Working Group chairs", "laws of physics", "Denver's Executive Vice President of Football Operations and General Manager", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "if they are homebound", "eliminate all multiples of 1", "nerves", "1700", "Christo", "polysaccharides (poly = many),", "Governor of Vermont from 1991 to 2003 and Chair of the Democratic National Committee (DNC) from 2005 to 2009.", "the heart, blood, and blood vessels", "Troggs", "He could have created the whole universe, the earth and all it contains in no time at all.", "Bratislava,", "Diana, the Princess", "slave trade.", "vena cava", "Chesapecten Jeffersonius", "bull's-eye", "Tartarus", "\"cyc\" is short for this type of backdrop that suggests infinite space behind the performer.", "Si-Tchun", "Achaemenid Empire", "LAP", "Count Ferdinand von Zeppelin", "38th Mayor of San Francisco", "64", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas", "a group of characters who have safely gotten off the Island and are given", "TV series", "Love Is All Around", "Los Angeles Dance Theater", "Nivose", "FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6051668518263347}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.5517241379310345, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-2921", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-14782", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.53125, "CSR": 0.6875, "EFR": 0.9666666666666667, "Overall": 0.8270833333333334}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "encourage growth in richer countries", "K-9 and Company", "9.1 million", "little", "individual countries", "cattle and citrus", "Mongol", "a maze of semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "Capability deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rod Steiger", "hoo-hoo, the barn type", "Barack Obama", "Kenny G", "a coffee", "a peacock unitard", "Annapolis", "Season", "klammeraffe", "bark beetles", "Allah", "bones", "Python", "Cecil B. DeMille", "Ada Monroe", "Faith Hill", "Ben Affleck", "the U.S.", "V", "particle", "Yardbird and Bird", "Sweden", "Vietnam", "hydrogen", "Alexandria", "Perfume: The Story of a Murderer", "the New Jersey Economic Development Authority's 20% tax credit", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.53125, "QA-F1": 0.597362012987013}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7468", "mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-6220", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-3893", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_hotpotqa-validation-4891", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.53125, "CSR": 0.66796875, "EFR": 1.0, "Overall": 0.833984375}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu in the north", "silent film", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement", "Bannow Bay", "Red Army", "20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses against agricola and the antinomians, four of which became the basis for disputations between 1538 and 1540", "Body of Proof", "seven-eighths", "the cardinal de Richelieu", "the Atlas Mountains", "Madrid", "the Danube", "Yahweh", "leather", "George Pullman", "an an attractive dark purple, speckled and the flesh is greenish- yellow", "the Messiah", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "the tonka bean", "the divisor", "Hypnos", "Texas", "IHOP", "a white breed", "the Bill of Rights", "the SAT", "Rio de Janeiro", "Henry David Thoreau", "Southern California", "Harry Whittington", "an eagles", "Gustave Eiffel", "Edward Hopper", "the CIA", "d'Artagnan", "a green substance", "1985", "an apple", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6081796091137124}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.546875, "CSR": 0.6545138888888888, "EFR": 1.0, "Overall": 0.8272569444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "During the Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "Exploration is still continuing to determine if there are more reserves", "prep schools", "soft power", "a strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Khrushchev", "Rhea", "the vine", "Elton John", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Washington", "Carmen", "Italy", "12", "tarn", "100", "buffalo", "Ann Widdecombe", "an equilateral triangle", "the Old Kent Road", "Tuesday", "stone", "Ab Fab", "Massachusetts", "Barrow", "California", "the Susquehanna River", "Kajagoogoo", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "Deval Patrick", "Bea Benaderet"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6307291666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-8273", "mrqa_squad-validation-9870", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-5586", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.5625, "CSR": 0.6453125, "EFR": 0.9642857142857143, "Overall": 0.8047991071428571}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "the 'Lord's Enclosure'", "League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "a\u00e7ai", "a tree", "Ken Russell", "Dan Dare", "Gnaeus Junior", "Smiths", "Boxer Evander Holyfield", "\u00e7ai", "Passover", "hera", "kaleidoscope", "Uranus", "hera", "crimea", "Soviet Union", "Sydney", "Los Angeles", "Underground Railroad", "puck", "ummi", "passion fruit", "Portugal", "cricket", "Mariah Carey", "63 to 144 inches", "the Titanic", "William Tell", "Christian Dior", "a shaggy, candy-loving dog", "Mendip Hills", "Wichita", "the eukharisti\u0101", "New Croton Reservoir", "andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "Ni!", "Roman Polanski"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6835227272727273}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, false, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6263", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-5319", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.65625, "CSR": 0.6463068181818181, "EFR": 1.0, "Overall": 0.8231534090909091}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network headquartered in San Jose, CA that utilized virtual call packet switched technology", "public service", "Guy de Lusignan", "tiger team", "a sub-group of T cells", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "hizbullah", "five", "Whist", "bantu", "Toscana", "achromatopsia", "black", "Pluto", "chromium", "white gold", "The Hague", "brian", "Ironside", "george smiley", "Gorky", "brown trout", "Beyonce", "Wordsworth", "Man V Food", "Queen Elizabeth II", "J. Dodsley", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "black leaf", "hudson", "phoebus", "Shrek", "Oslo", "lions", "rhododendron", "All That Jazz", "sweden", "Shanghai", "julie de Becque", "motor from the load of holding the elevator cab -- it has to overcome only weight difference and inertia of the two masses", "Billy Colman", "17 October 2006", "beer", "Las Vegas to Arizona", "Saturday's Hungarian Grand Prix", "Capuchin", "Edgar Allan Poe", "morocco"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6034442640692641}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, false, false, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.09090909090909091, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-4870", "mrqa_squad-validation-6530", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-6278", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.53125, "CSR": 0.63671875, "EFR": 1.0, "Overall": 0.818359375}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith.", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadine", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas.", "The Handmaid's Tale", "pygmy chimpanzee", "The Fault in Our Stars", "CR-X", "video", "1961", "400 MW", "tag team", "galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Alpine, New Jersey", "Continental Army", "Jack Kilby", "Ryan Babel", "Akhmadovich Kadyrov", "July 16, 1971", "1933", "The Heirs", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel Comics", "Chris Brown", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point du Sable", "England", "sam Neill", "a basilica", "1994", "Ricky Nelson", "in Wakanda and the Savage Land", "mercury", "phobias", "drug trafficking is a transnational threat, and they poison economies and governments, and it is in everyone's interest to stop this proliferation.\"", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "samuel johnson", "n Nursery Rhymes", "pre-Columbian times"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6612672483766233}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.0, 0.125, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-9658", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-5658", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-1843", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.59375, "CSR": 0.6334134615384616, "EFR": 1.0, "Overall": 0.8167067307692308}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "partial funding", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "his most brilliant student", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Rudolf Schenker", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "Liquidambar styracif", "Marquis de Lafayette", "Indian state of Gujarat", "three", "Winter Haven", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "\"My Beautiful Dark Twisted Fantasy\"", "FCI Danbury", "a few", "\"Home of the Submarine Force\"", "Las Vegas", "Pope John X", "2007", "Arlo Looking Cloud", "Rwandan genocide of 1994", "Larnelle Harris", "President of the United States negotiates treaties with foreign nations", "2011", "1982", "rod", "Chris Robinson", "gossip Girl", "Compressible flow", "the coalitions threatening its core terrain", "Egyptian Goddess of Creation", "Richie Unterberger"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6601190476190477}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, true, false, false, true, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 0.4, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.7142857142857143, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-1441", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.5625, "CSR": 0.6283482142857143, "EFR": 0.9642857142857143, "Overall": 0.7963169642857143}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "only the series from 2009 onwards", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "Spreading throughout the Mediterranean and Europe", "kilogram-force", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "mathematical models of computation", "Vistula River", "100 to 150", "Apple's new iPod", "palesa and her granddaughter Alebohang,", "March 8", "Democrats and Republicans", "the Catholic League", "well over 1,000 pounds", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "Friday", "Movahedi", "different women coping with breast cancer in five vignettes", "\"black rain\" of drilling fluid and a roar of escaping gas erupted from the doomed Deepwater Horizon shortly before the explosion that sank the oil rig,", "depressed", "a quarter of bread", "Lance Cpl. Maria Lauterbach", "Cho Won-suk", "London", "400", "Val d'Isere, France", "the results by a chaplain about 1:45 p.m.", "two soldiers and two civilians", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J. Crew", "U.S. Secretary of State Hillary Clinton", "Depression-era bank robber", "boyhood experience in a World War II internment camp", "suppress the memories and to live as normal a life as possible", "4 meters (13 feet) high", "the Irish capital", "Republican", "Spanishfork,", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "quarter", "Sevens", "England", "Yemen", "artble.com", "giant", "mercury"], "metric_results": {"EM": 0.375, "QA-F1": 0.48970362103174603}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.3, 1.0, 0.6666666666666666, 0.8750000000000001, 0.11999999999999998, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191"], "SR": 0.375, "CSR": 0.6114583333333333, "EFR": 0.975, "Overall": 0.7932291666666667}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "Mercury", "a prime number", "50 fund", "Camisards", "over $40 million", "GTE", "1,100", "spinat", "Oligocene", "Melodie Rydalch,", "Christopher Columbus", "a Little Rock military recruiting center", "March 24,", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"She had a smile on her face, like she always does when she comes in here,\"", "56", "Pittsburgh Steelers quarterback Ben Roethlisberger", "\"The Da Vinci Code\"", "Heshmat Tehran Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Seoul", "resources", "highest ranking former member of Saddam Hussein's regime", "two Emmys", "\"To all of our valiant men and women, know that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.\"", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75", "eradication of the Zetas cartel from the state of Veracruz, Mexico,", "closing these racial gaps", "a bond hearing", "President Bush", "Amstetten,", "African National Congress Deputy President Kgalema Motlanthe,", "spiral into economic disaster.", "\"They'll probably begin to fade from the scene,\"", "Ralph Cifaretto", "a strict interpretation of the law", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "blue", "Thomas Jefferson", "The Left Book Club", "holography"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5319169834794835}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.4, 0.6428571428571429, 0.28571428571428575, 0.0, 1.0, 0.5454545454545454, 0.0, 0.13333333333333333, 0.5, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3293", "mrqa_squad-validation-9016", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-11133", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.453125, "CSR": 0.6015625, "EFR": 1.0, "Overall": 0.80078125}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand people", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary negligent after witnesses identified him and he was interviewed by police.", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "the 7th century", "murder", "next year", "his plans to overhaul domestic policies,", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear weapon within the next year.", "brutal choice", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.", "\"Walk -- Don't Run\" and \"Hawaii Five-O\"", "own environmental videos", "two women", "\"Vidal Sassoon, Christopher Lee and Nick Faldo are among those recognized this year on Queen Elizabeth's birthday honors list.", "Monday,", "women.", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs", "expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "around the United States", "1950s,", "the U.S. Air Force, operating an unmanned aerial vehicle, fired a Hellfire missile at three men spotted setting roadside bombs, killing all three.", "a government-run health facility that provides her with free drug treatment.", "vegan bake sales", "\"The Rosie Show,\"", "Trevor Rees", "Oxbow,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "first of three films that comprise the \"Three Colours\"", "2001", "vingtaines", "Joe Louis", "George Blake", "Bogota"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6548138559432717}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714285, 0.27272727272727276, 0.22222222222222224, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.08695652173913043, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0625, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_triviaqa-validation-6739"], "SR": 0.578125, "CSR": 0.6001838235294117, "EFR": 0.9629629629629629, "Overall": 0.7815733932461872}, {"timecode": 17, "before_eval_results": {"predictions": ["relatively equal distributions of wealth", "a pharmacy practice residency", "questions and answers", "\"the soul does not sleep (anima non sic dormit),", "Captain Francis Fowke,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich", "\"Mad Men\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's restive provinces", "400-year-old, slouching exhausted in a Johannesburg church that has become a de facto transit camp", "collaborating with the Colombian government", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Matthew Fisher,", "Peppermint oil, soluble fiber, and antispasmodic drugs can indeed help people with irritable bowel syndrome,", "in the north and west of the country,", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "introduce legislation Thursday to improve the military's suicide-prevention programs.\"", "$250,000", "Sunday afternoon.", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "kite surfers and wind surfers", "Virgin America", "Palm Beach, Florida,", "Daniel Wozniak,", "22-year-old", "Madrid's Barajas International Airport", "how health care can affect families.", "U.N.", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "at checkposts and military camps", "that the deadly attack on India's financial capital last month was planned inside Pakistan,", "Friday,", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "more than 20 times", "slapped and beaten with a baseball bat and the butt of a rifle.", "congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "the five - year time jump", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan", "surrealism", "C. S. Lewis", "7", "rice", "Halifax"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5987434785438701}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.125, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3529411764705882, 0.5217391304347826, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2408", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-4124", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.53125, "CSR": 0.5963541666666667, "EFR": 1.0, "Overall": 0.7981770833333334}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "circular", "Advanced Steam", "Defensive ends", "the dot", "chastity", "European Court of Justice", "bronze medal in the women's figure skating final,", "U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "the UK", "\" Teen Patti\"", "Argentina", "Congress", "28", "New Haven, Connecticut, firefighter Frank Ricci,", "Kurdish Gas City", "\"greatly moved\" by meeting victims of abuse in Valletta, Malta.", "Bill & Melinda Gates Foundation", "$106,482,500", "because everybody around me likes Obama,\"", "the FDA is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.\"", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Bahrain", "because Somalia-based terrorist organization Al Shabaab may have been plotting an attack timed to coincide with the event,", "the mammoth's fossil", "can play an important role in Afghanistan as a reliable NATO ally.", "because the federal government isn't actively engaged in border enforcement", "Molotov cocktails, rocks and glass.", "because they were near their goal of being offered half the jobs involved in one of the latest subcontracts connected to the construction project", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China,", "Lindsey Vonn", "Paul McCartney and Ringo Starr", "Amnesty International.", "race", "Brazil", "Hansa (Malmborgsgatan 6) and Triangeln (Sodra Forstadsgatan 41)", "trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "outside the Iranian consulate in Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "finding a leak in a Dike", "\"Sunny Afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth Tudor", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6296115554893128}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.125, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.9714285714285714, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.0, 1.0, 0.07142857142857142, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.16, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_squad-validation-8746", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_searchqa-validation-11385"], "SR": 0.53125, "CSR": 0.5929276315789473, "EFR": 0.9666666666666667, "Overall": 0.7797971491228071}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "if he were removed from the school, Tesla would be killed through overwork.", "Toyota", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah.", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "14 bodies from the building and 37 survivors,", "that the Bainbridge would be getting backup shortly.\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now.\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book.", "he was diagnosed with skin cancer.", "to stand down.", "Ashley \"A.J.\" Jewell,", "17", "Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "California,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "steam-driven, paddlewheeled overnight passenger boat.", "Haeftling range.", "about 3,000 kilometers (1,900 miles)", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "Rod Blagojevich", "Flint, Michigan,", "protective shoes", "public-sector labor unions launching a general strike,", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "glass shards", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International Airport", "\"Grandmasters\"", "Women's suffrage", "Canterbury", "Tunisia", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6618810237642474}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.27272727272727276, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.8, 1.0, 0.5, 0.28571428571428575, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.8, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.4, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-1326", "mrqa_squad-validation-3709", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_searchqa-validation-383"], "SR": 0.484375, "CSR": 0.5875, "EFR": 0.9393939393939394, "Overall": 0.7634469696969697}, {"timecode": 20, "before_eval_results": {"predictions": ["Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "De Materia Medica (Concerning medical substances)", "John D. Rockefeller", "four", "mistreatment from government officials.", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "U.S. foreign policy pledging to aid nations threatened by Soviet expansionism,", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhism", "1978", "1927, 1934, 1938, 1956 )", "1969", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Gavrilo Princip", "a central place in Christian eschatology", "October 1941", "to the well - being, welfare or safety of an individual or a group of individuals", "a charbagh", "Cee - Lo", "after Shawn's kidnapping", "lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour", "three times", "November 25, 2002", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two degrees of freedom", "Alberto Salazar", "a collection of live animals", "American", "Hoosick, Rensselaer", "CEO of an engineering and construction company with a vast personal fortune.", "1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "Washington State's decommissioned Hanford nuclear site,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6809910240169823}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8421052631578948, 0.0, 0.25, 1.0, 0.9565217391304348, 1.0, 0.0, 0.0, 0.9333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.5, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857]}}, "before_error_ids": ["mrqa_squad-validation-6314", "mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.546875, "CSR": 0.5855654761904762, "EFR": 0.9655172413793104, "Overall": 0.7755413587848933}, {"timecode": 21, "before_eval_results": {"predictions": ["about 515 million years ago", "Spanish", "an attack on New France's capital, Quebec", "the Fresno Traction Company", "Westminster", "they are prokaryotes", "four", "their bearers", "Washington metropolitan area", "the molar concentration", "the breast or lower chest of beef or veal", "the ruling city of the Northern Kingdom of Israel, Samaria", "the Philippines", "around 1600 BC", "By mid-1988", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "The New York Yankees", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford", "by the early 3rd century", "in the pancreas", "Kanawha Rivers", "1961", "Mac OS X 10.0", "in rocks and minerals", "Michael Schumacher", "currency option", "Introduced in 1957", "1776", "The last execution took place in 1963,", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "the teenage porcupine punk rocker", "the Transvaginal ultrasonography", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "In the 1979 -- 80 season", "Guy Berryman", "Evgeni Plushenko", "c. 497 / 6 -- winter 406 / 5 BC", "Tim Allen", "thick skin", "a cake", "Pakistan", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "the Major General of the Navy", "Marktown", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "Pardon Richard Nixon", "Ellen DeGeneres", "1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.34375, "QA-F1": 0.5020720547834518}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, false, false, false, false, true, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 0.28571428571428575, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.5, 0.6666666666666666, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.7777777777777778, 1.0, 0.0, 1.0, 0.6666666666666666, 0.08333333333333333, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4472", "mrqa_squad-validation-8780", "mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-3013", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_searchqa-validation-843", "mrqa_hotpotqa-validation-3984"], "SR": 0.34375, "CSR": 0.5745738636363636, "EFR": 1.0, "Overall": 0.7872869318181819}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "The Chainsmoker", "every year", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "two", "John Adams", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "a sound stage in front of a live audience in Burbank, California", "Grace Zabriskie", "2009", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas", "Jodie Foster", "February 27, 2007", "Neil Patrick Harris", "8ft", "Owen Vaccaro", "bacteria", "on the lateral side", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff / \ufefb\ufffd 90 \u00b0N - 0 \u00b0 E", "London", "in the bloodstream or surrounding tissue", "2012", "March 1", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "if he was not named Romeo he would still be handsome and be Juliet's love", "Hotel California", "Paul Revere", "an insect in one part of the country", "vocalist Eddie Vedder", "2005", "Dan Tyminski", "The 19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "southern port city of Karachi,", "at least nine", "Bashar al-Assad", "the Bible", "Biathlon"], "metric_results": {"EM": 0.5, "QA-F1": 0.610150593497633}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true], "QA-F1": [0.9473684210526316, 1.0, 1.0, 1.0, 0.25, 1.0, 0.4210526315789474, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.0, 0.8, 0.4444444444444445, 0.9523809523809523, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8148148148148148, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-3470", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-4138"], "SR": 0.5, "CSR": 0.5713315217391304, "EFR": 0.9375, "Overall": 0.7544157608695652}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "Romanesque", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "the Emperor", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2", "the Constitution of India came into effect on 26 January 1950", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Johnny Logan", "1981", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando", "February 10, 2017", "Alex Skuby", "Colony of Virginia", "March 2016", "1991", "Terry O'Neill", "Bacon", "an explosion", "Heather Stebbins", "the Redenbacher family", "molecules contain either two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "female", "Ann Doran", "1871", "the eye", "The History Boys", "gourmet treat", "White Knights of the Ku Klux Klan", "five", "Darkthrone", "Kingman Regional Medical Center,", "Phillip A. Myers", "Osama bin Laden", "Australian Antarctic Territory", "soma", "gourmet Mushrooms"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6080357142857142}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, 0.3333333333333333, 0.0, 0.5, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.1904761904761905, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_hotpotqa-validation-395", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-13614", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.453125, "CSR": 0.56640625, "EFR": 0.9714285714285714, "Overall": 0.7689174107142858}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "James Francis Thorpe", "the first hole of a sudden-death playoff with Kentucky native Kenny Perry", "the onset and progression of Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "the Indian School of Business", "Rockefeller Center", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin Button\"", "A55", "Corendon Dutch Airlines", "86", "Capella University", "Loch Duich", "Fatih Ozmen", "U.S.", "Pacific Place", "campaign organizer on staff for Presidential candidate John Kerry", "the Donny & Marie Showroom, at the Flamingo Las Vegas", "the City of Westminster, London", "2016", "Wildhorn", "New York University School of Law", "the Crips", "Harper's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Guadalcanal Campaign", "Bishop's Stortford", "Afroman", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "Prussian mythology", "Australia", "Julie Taymor", "Easy", "World War I", "79 AD", "musical research", "Portland", "Yoruba", "\"Lucky\"", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "1966", "the Stig", "Jehan Mubarak", "Medellin", "his father", "new, 100-mpg plug-in hybrid electric vehicle", "2004", "genes", "Olive", "Stockholm"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5925309065934066}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, false, false, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 0.4, 0.0, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-4328", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.484375, "CSR": 0.563125, "EFR": 0.9696969696969697, "Overall": 0.7664109848484848}, {"timecode": 25, "UKR": 0.701171875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-2250", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2289", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2988", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-3901", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-4461", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-5382", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10227", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-1123", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2380", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-4562", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5539", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-6851", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-7609", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8023", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-9001", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9505", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-1258", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-1733", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-1800", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-2583", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2727", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2944", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3206", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3410", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3654", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-3745", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-39", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4046", "mrqa_newsqa-validation-4095", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-65", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-660", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-94", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-11385", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-12624", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-1335", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-14663", "mrqa_searchqa-validation-14883", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-16181", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3783", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-4857", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-7702", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-9090", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-9705", "mrqa_searchqa-validation-9756", "mrqa_squad-validation-10045", "mrqa_squad-validation-10069", "mrqa_squad-validation-10074", "mrqa_squad-validation-10086", "mrqa_squad-validation-10216", "mrqa_squad-validation-10228", "mrqa_squad-validation-10254", "mrqa_squad-validation-10310", "mrqa_squad-validation-10324", "mrqa_squad-validation-10338", "mrqa_squad-validation-10353", "mrqa_squad-validation-1036", "mrqa_squad-validation-10378", "mrqa_squad-validation-10477", "mrqa_squad-validation-1090", "mrqa_squad-validation-1320", "mrqa_squad-validation-1450", "mrqa_squad-validation-1603", "mrqa_squad-validation-1636", "mrqa_squad-validation-1672", "mrqa_squad-validation-1694", "mrqa_squad-validation-178", "mrqa_squad-validation-1802", "mrqa_squad-validation-1852", "mrqa_squad-validation-1855", "mrqa_squad-validation-1857", "mrqa_squad-validation-1938", "mrqa_squad-validation-1967", "mrqa_squad-validation-2040", "mrqa_squad-validation-2126", "mrqa_squad-validation-2153", "mrqa_squad-validation-2216", "mrqa_squad-validation-2289", "mrqa_squad-validation-2384", "mrqa_squad-validation-2400", "mrqa_squad-validation-2436", "mrqa_squad-validation-2460", "mrqa_squad-validation-2477", "mrqa_squad-validation-255", "mrqa_squad-validation-2577", "mrqa_squad-validation-2602", "mrqa_squad-validation-2619", "mrqa_squad-validation-268", "mrqa_squad-validation-2693", "mrqa_squad-validation-2773", "mrqa_squad-validation-2782", "mrqa_squad-validation-2798", "mrqa_squad-validation-282", "mrqa_squad-validation-2824", "mrqa_squad-validation-285", "mrqa_squad-validation-2929", "mrqa_squad-validation-3019", "mrqa_squad-validation-3041", "mrqa_squad-validation-3135", "mrqa_squad-validation-3185", "mrqa_squad-validation-320", "mrqa_squad-validation-3337", "mrqa_squad-validation-3476", "mrqa_squad-validation-353", "mrqa_squad-validation-3589", "mrqa_squad-validation-3709", "mrqa_squad-validation-383", "mrqa_squad-validation-3931", "mrqa_squad-validation-3948", "mrqa_squad-validation-3955", "mrqa_squad-validation-397", "mrqa_squad-validation-3993", "mrqa_squad-validation-4005", "mrqa_squad-validation-4079", "mrqa_squad-validation-4140", "mrqa_squad-validation-415", "mrqa_squad-validation-4181", "mrqa_squad-validation-427", "mrqa_squad-validation-4291", "mrqa_squad-validation-4305", "mrqa_squad-validation-4333", "mrqa_squad-validation-4338", "mrqa_squad-validation-4472", "mrqa_squad-validation-462", "mrqa_squad-validation-4686", "mrqa_squad-validation-4704", "mrqa_squad-validation-4835", "mrqa_squad-validation-4856", "mrqa_squad-validation-4870", "mrqa_squad-validation-5054", "mrqa_squad-validation-5088", "mrqa_squad-validation-5096", "mrqa_squad-validation-5154", "mrqa_squad-validation-5176", "mrqa_squad-validation-5238", "mrqa_squad-validation-5302", "mrqa_squad-validation-5326", "mrqa_squad-validation-5376", "mrqa_squad-validation-550", "mrqa_squad-validation-5537", "mrqa_squad-validation-5541", "mrqa_squad-validation-5588", "mrqa_squad-validation-5616", "mrqa_squad-validation-5672", "mrqa_squad-validation-5703", "mrqa_squad-validation-5767", "mrqa_squad-validation-5777", "mrqa_squad-validation-5913", "mrqa_squad-validation-60", "mrqa_squad-validation-60", "mrqa_squad-validation-607", "mrqa_squad-validation-6099", "mrqa_squad-validation-6126", "mrqa_squad-validation-6143", "mrqa_squad-validation-6178", "mrqa_squad-validation-6220", "mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6362", "mrqa_squad-validation-6395", "mrqa_squad-validation-6414", "mrqa_squad-validation-6564", "mrqa_squad-validation-660", "mrqa_squad-validation-6641", "mrqa_squad-validation-6737", "mrqa_squad-validation-6754", "mrqa_squad-validation-6782", "mrqa_squad-validation-68", "mrqa_squad-validation-6817", "mrqa_squad-validation-6915", "mrqa_squad-validation-696", "mrqa_squad-validation-7018", "mrqa_squad-validation-703", "mrqa_squad-validation-7069", "mrqa_squad-validation-707", "mrqa_squad-validation-7150", "mrqa_squad-validation-7161", "mrqa_squad-validation-7180", "mrqa_squad-validation-7198", "mrqa_squad-validation-7260", "mrqa_squad-validation-7399", "mrqa_squad-validation-754", "mrqa_squad-validation-7552", "mrqa_squad-validation-7597", "mrqa_squad-validation-7640", "mrqa_squad-validation-765", "mrqa_squad-validation-7678", "mrqa_squad-validation-7770", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-7856", "mrqa_squad-validation-7882", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-804", "mrqa_squad-validation-8056", "mrqa_squad-validation-8104", "mrqa_squad-validation-8115", "mrqa_squad-validation-8189", "mrqa_squad-validation-8226", "mrqa_squad-validation-8226", "mrqa_squad-validation-8285", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8527", "mrqa_squad-validation-8629", "mrqa_squad-validation-8735", "mrqa_squad-validation-8760", "mrqa_squad-validation-8765", "mrqa_squad-validation-8832", "mrqa_squad-validation-884", "mrqa_squad-validation-8867", "mrqa_squad-validation-890", "mrqa_squad-validation-8957", "mrqa_squad-validation-898", "mrqa_squad-validation-9031", "mrqa_squad-validation-9066", "mrqa_squad-validation-9135", "mrqa_squad-validation-9186", "mrqa_squad-validation-9227", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9391", "mrqa_squad-validation-9392", "mrqa_squad-validation-9465", "mrqa_squad-validation-9504", "mrqa_squad-validation-9541", "mrqa_squad-validation-9552", "mrqa_squad-validation-9652", "mrqa_squad-validation-9658", "mrqa_squad-validation-9771", "mrqa_squad-validation-979", "mrqa_squad-validation-9818", "mrqa_squad-validation-987", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2626", "mrqa_triviaqa-validation-2685", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-3051", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-4107", "mrqa_triviaqa-validation-4171", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-4440", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-5568", "mrqa_triviaqa-validation-5671", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6290", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-6909", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-71", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-7548", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-776"], "OKR": 0.822265625, "KG": 0.4015625, "before_eval_results": {"predictions": ["A progressive tax", "Jacksonville", "monophyletic", "forces acting at ninety degrees to each other have no effect on the magnitude or direction of the other", "Fox Network", "the Anhaltisches Theater", "Anna Clyne", "Terence Winter, based on the memoir of the same name by Jordan Belfort", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "Sharyn McCrumb", "Acid house", "in  time which was popular in Austria, south Germany, German Switzerland, and Slovenia at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Leigh Lambert", "Shenandoah National Park", "BBC Formula One coverage on TV, radio and online", "10 Years", "Haleiwa Ali'i Beach Park", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles of Timmy Sanders and Jack", "PBS stations nationwide,", "second largest", "Citric acid", "in 1989", "Johnnie Ray", "The Five", "Walt Disney Feature Animation", "on 13 May 2018", "torpedo boats", "1972", "Geographical Indication tag", "Buck Owens and the Buckaroos", "the Cleveland Celtics", "World Championship Wrestling", "2003", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "1986", "Henry Louis", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram", "Java", "\"Death, be not\"", "green"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6594268578643578}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10397", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2056", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.546875, "CSR": 0.5625, "EFR": 0.9655172413793104, "Overall": 0.6906034482758621}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Jon Favreau", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool", "port city of Aden, on the southern coast", "American", "second cousin", "2013", "Archie Andrews", "2 May 2015", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Travolta", "Hall & Oates", "Pacific coast", "racehorse breeder", "Las Vegas", "1919", "Jon Bernthal", "Love Streams", "stunt jumping", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "CMYKOG", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Michael Baker", "1963", "a palla", "The Herald of Free Enterprise", "Nutshell", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "held by the Kong family itself", "a kite"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6324662316849817}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.25, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-5102", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268", "mrqa_searchqa-validation-3515", "mrqa_searchqa-validation-13669"], "SR": 0.546875, "CSR": 0.5619212962962963, "EFR": 1.0, "Overall": 0.6973842592592592}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "Fall 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Sir Matthew Alistair Grant", "Whitney Houston", "Dunlop India Ltd.", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "Josh Hartnett film \"40 Days and 40 Nights\"", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Primettes", "Cersei Westerister", "Elizabeth Keka\u02bbaniau La\u02bbanui Pratt", "Nugroho Notosusanto", "Don Bluth", "2007", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "Hong Kong Disneyland", "London", "Jim Diamond", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch Kiss M1914 machine gun", "Elena Verdugo", "Prussian statesman", "January 2004", "Peter Lawrence Buck", "ten", "seven species", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "glycerol", "identity documents belonging to Miguel Mejia Munera", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "salt", "nasal polyps", "Warp Drive"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6260233918128655}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-873", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.546875, "CSR": 0.5613839285714286, "EFR": 1.0, "Overall": 0.6972767857142858}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools and day schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "Herrenhausen Palace, Hanover", "Henry Mancini", "Jap\u00b7a\u00b7nese", "Gordon Ramsay", "Gorbachev", "A*S*H\" or the Bill Murray character", "the rose", "Rameses II (Yul Brynner)", "Aorably tongue-tied William (Grant)", "a scythe", "a balsam fir", "Paddy Doherty", "a double-stranded DNA virus", "the Hanging Gardens of Babylon", "Libya", "Chubby Checker", "a bia 515", "Khomeini\u2019s Iran", "Barbotty", "The Soul of Indiscretion", "a bagelonne", "Tax Day", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "a Barboy", "Barbados", "Manhattan", "Tom Stoppard", "The Greatest", "a singer and performer", "Northumberland", "a Tam o\u2019Shanter hat", "a jazz pianist", "Seattle", "the Penrhyn Castle", "Cardiff", "Baton Rouge", "a buretors", "Tahrir Square", "Romanian", "the \"useful life period\"", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "a foraging mammal", "Greek", "a passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "December 6, 1941 \u2013 December 5, 1991", "North America", "Florida's Everglades.", "Garth Brooks", "glamorous, sexy and international.", "a street or", "a set of steak knives", "Barb Barblin"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4618427579365079}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [0.0, 0.28571428571428575, 0.39999999999999997, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2216", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-1670", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-4432", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-12186", "mrqa_searchqa-validation-15919"], "SR": 0.359375, "CSR": 0.5544181034482758, "EFR": 1.0, "Overall": 0.6958836206896551}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Kyrie Irving", "James W. Marshall", "Blue laws", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Watson and Dan Stevens", "between 8.7 % and 9.1 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "the status line", "in the eye", "jimmy williamson", "Triple Alliance of Germany", "Andrew Lloyd Webber", "1955", "the president - elect and the love interest to Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar", "the original Star Trek television series", "1960", "Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "Christy Plunkett", "early to mid-2000s", "Fleetwood Mac", "the rise of literacy", "Cairo, Illinois", "in the 1970s and'80s", "in the books of Exodus and Deuteronomy", "Dusty Chandler", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "Marvin Gaye", "taxonomy", "elbow", "borner", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "27", "Long Island convenience store", "Romney", "rock", "heart disease", "bronchitis"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5883630952380953}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.5454545454545454, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.56, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.515625, "CSR": 0.553125, "EFR": 1.0, "Overall": 0.6956249999999999}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "tourism", "a circle", "( Sequoia sempervirens)", "The Fairly Oddparents", "(Elegy to the Spanish Republic)", "taximeter", "(coyote)", "The Sun Also Rises", "Harry Reid", "(2004)", "Axis", "forge", "Kinetoscope", "(Why did he kill them?)", "(Les Fleurs du mal)", "Blackbird", "Footprints", "(1.)2.334-335)", "(St.) corey Phillips", "(UZA)", "Tommy Lee Jones", "Zacchaeus", "The Memory Keeper's daughter", "George Eliot", "hubris", "Yahtzee", "Tony Danza", "Chemical Markup Language", "hives", "74.3", "William S. Hart", "(O Allah's Apostle) Muhammad", "Pride and Prejudice", "adjectives", "Kosher Wines", "Munich", "Michael Jordan", "(St.) Andrew's Day", "Prospero", "Hikaru Sulu", "(Pulsatrix perspicillata)", "dough", "Aso", "honey", "Boston", "Fisher- Price", "Arctic Ocean", "the Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Spamalot", "1935", "Harlow Cuadra and Joseph Kerekes", "her translation of and commentary on Isaac Newton's book \"Principia\"", "Israel", "top designers", "The European Commission"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5424479166666667}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, true, false, true, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-3260", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-5093", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-5162", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3915"], "SR": 0.46875, "CSR": 0.5504032258064516, "EFR": 1.0, "Overall": 0.6950806451612903}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Ferengi cocktails Quark", "Christian Kern", "June 26, 1970", "The Worcester Cold Storage and Warehouse Co.", "Elena Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge Aharon Barak", "Bangkok", "The Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland", "\"Slaughterhouse-Five\"", "Shohola Falls", "wine", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Lawton Chiles", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Air Force", "Isabella Palmieri", "Hathi Jr", "1935", "Manichora", "\"Slow\"", "The Miracles", "the 6.2-mile Moffat Tunnel, which passes underneath the Continental Divide.", "Microsoft", "Friday", "Burgundy", "Franklin D. Roosevelt", "Belarus"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7139623397435897}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.923076923076923, 0.5, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-2554", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055", "mrqa_searchqa-validation-2446"], "SR": 0.609375, "CSR": 0.55224609375, "EFR": 0.96, "Overall": 0.68744921875}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\"", "jellyfish", "March", "a second shoe", "fauntleroy", "the World Bank", "Eat porridge", "Kofi Annan", "oxygen", "the right to print was strictly controlled in England", "Taggart", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "Manfred Mann", "Sven Goran Eriksson", "Barry Taylor", "the railroads", "Brussels", "\"Stuarts being lost, the remainder of his life was \u2014 with a brief exception \u2014 spent in exile.", "John Poulson", "A\u00e9roport Roissy-Charles de Gaulle", "the Treaty on European Union", "Jack Frost", "the Precambrian Shield", "Laurent Planchon", "the Solent", "vomiting", "Basketball", "Bristol Aeroplane Company", "Spinach", "Stephen Hendry", "life of Pi", "Gemini", "Surrey", "1971", "chippenham", "London", "The Coquimbo Region", "William Shakespeare", "borax", "rail", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "The onset of rigor mortis and its resolution partially determine the tenderness of meat", "a system of measurements commonly used in the United States", "Miller Brewing", "northwestern Italian coast", "Sydney, New South Wales, Australia", "the earthquake's aftermath", "her decades-long portrayal of Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\"", "Peter Bogdanovich", "a Mourning dove", "the Federal Council of Churchesthe predecessor of the National Council of"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5134524329836829}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.3333333333333333, 1.0, 0.0, 0.7499999999999999, 0.0, 0.923076923076923, 0.12121212121212123, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.4375, "CSR": 0.5487689393939394, "EFR": 0.9722222222222222, "Overall": 0.6891982323232323}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "Lana Del Rey", "1,228 km / h ( 763 mph )", "New England Patriots", "Emmett Lathrop `` Doc '' Brown, Ph. D.", "Antarctica", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "long line", "Jesus'birth", "a habitat", "Simone Vangsness", "Saxony", "Andrew Johnson", "Bart Cummings", "Aegisthus", "electors", "Ludlow", "Sauron", "1961", "Aaron Lewis", "2013", "March 1", "novelization", "a usually red oxide formed by the redox reaction", "Spain", "Ridge Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "`` Jocelyn Flores", "abdicated in November 1918", "most - visited paid monument", "erosion", "March 2, 2016", "stuffing", "1996", "Ray Charles", "16", "the Ramones", "completed in 1800", "the Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "New Jersey", "May 2010", "France", "heath Ledger", "Wilson Pickett", "a centaur", "music lover", "cricket fighting", "Luis Resto", "drama that pulls in the crowds", "German authorities", "Islamabad", "Tunisia", "RAND", "alberta"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5634705563371736}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 0.8, 0.06451612903225806, 1.0, 1.0, 1.0, 0.18181818181818182, 0.6666666666666666, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-2891", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.46875, "CSR": 0.5464154411764706, "EFR": 0.9705882352941176, "Overall": 0.6884007352941176}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Cal", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission and final drive", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash", "March 14, 1942", "Nick Sager", "local authorities", "prophets", "state legislators of Assam", "digestion of proteins", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "temperature at which the phase transition occurs", "Mind your Ps and Qs", "Germany", "20 November 1989", "Tom\u00e1s de Torquemada", "Bob Gaudio", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "a four - page pamphlet in 1876", "2003", "Sebastian Lund ( Rob Kerkovich )", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "various submucosal membrane sites", "enterprise application development", "at Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "when the car comes to a halt", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Derrick Henry", "ice cap climate", "a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "brian close", "a heavy metal band", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "Olympic", "Henry Ford", "Toyota", "b. Paris", "brain tumour"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5498129903302317}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.16666666666666669, 0.4444444444444445, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 0.19999999999999998, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.26666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.29629629629629634, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 1.0, 0.20000000000000004, 0.2758620689655173, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.4375, "CSR": 0.5433035714285714, "EFR": 0.9166666666666666, "Overall": 0.6769940476190476}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "a supposed mild euphoric", "hankey", "Venezuela", "Croatia", "the Ring", "Finding Neverland", "d'Agnolo", "Arctic Ocean", "a vacuum", "obstructions", "Lafayette", "Elijah Muhammad", "a tropical depression, tropical storm, or hurricane", "the Royal Marines Band", "Alexander Pushkin", "Australia", "Munich", "Mexico", "The Night Shift", "the papacy", "Arkansas", "a Romero classic.", "Renoir", "december", "operas", "Innsbruck", "Lance Ito", "Microsoft", "a fern", "Sony Corp,", "vikings", "Atlantic City's", "Blackwater USA", "elephant", "American Airlines", "a Japanese serow", "Odysseus", "brian Sanders", "Kensington Palace", "a Union Pacific train", "Netherlands", "Pocahontas", "the CS Lewis Foundation", "John Galt", "the amygdala, the part of the brain that", "the Chicago Mercantile Exchange", "Las Vegas", "\"Tights: not just for dancing\"", "wheat", "Pablo Casals", "an ostrich or common ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "psychological horror", "John Morgan", "Hungarian Rhapsody No. 2", "Henry II", "House-passed bill that eliminates the 3% withholding requirement for government contractors", "63", "\"perezagruzka\""], "metric_results": {"EM": 0.4375, "QA-F1": 0.509970238095238}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, false, true, false, false, false, false, true, false, false, true, true, true, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-265", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-10308", "mrqa_searchqa-validation-5473", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.4375, "CSR": 0.5403645833333333, "EFR": 1.0, "Overall": 0.6930729166666666}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "Lucknow", "2013 -- 14", "National Industrial Recovery Act ( NIRA )", "User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "New Jersey's formal name for the new PATH station", "Southend Pier", "Santa Monica", "layered systems of sovereignty", "Aiko Watanabe", "31 January 1934", "Filipino", "1773", "modern random - access memory ( RAM )", "May 31, 2012", "April 1917", "Etienne de Mestre", "October 27, 1904", "Raghu II", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean", "2016", "Frank Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "the retinal ganglion cells of one retina", "1980s", "stored in soils", "card verification data", "exercise general oversight", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum -- the enkuklios paideia or `` education in a circle ''", "Mike Czerwien", "103", "Vienna", "English", "Mexico", "Pope Benedict XVI", "$10.5 million", "Al Horford", "Andrew Johnson", "$22 million", "Workers' Party", "his mother", "cotton", "Denzel Washington", "Quinn", "Towcester"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6716055645743145}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.1, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_hotpotqa-validation-4351", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953"], "SR": 0.578125, "CSR": 0.5413851351351351, "EFR": 0.8518518518518519, "Overall": 0.6636473973973974}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "the United States", "South Africa", "first among equals", "joseph taylor", "a cappella", "albinism", "Henry Hunt", "aglets", "Saturday Night Live", "FC Bayern M\u00fcnchen", "winter", "Bonnie and Clyde", "brazil", "copper", "Dawn French", "bbc", "b Benedict", "brazil author Orhan Pamuk", "Scooby-Doo", "Swaziland", "the festival of Britain on London's South Bank", "Kent", "the Humber", "a points based scoring system", "automobile", "Kent", "the b Von Trapp family", "josef toots", "Galileo Galilei", "Zelle", "a Scotland Yard detective", "Marilyn Manson", "brazil", "The Tempest", "spark-ignition", "brazil", "Boulder Dam", "bhang, Dope, draw, ganja, grass, hashish, resin, sensi, sinsemilla, skunk", "iran", "belle de Jour", "Morecambe", "(Russian Ballet trained)", "rain", "white", "the American astronomer Asaph Hall", "France", "geena Davis", "kunsky", "how human beings respond to the inevitability of their mortality and cope with the reality of loss", "joseph Graham", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Alexis S\u00e1nchez, Per Mertesacker and Olivier Giroud", "Ben Ainslie", "at least three bodies were trapped in a \"very compressed area.\"", "heavy turbulence", "different women coping with breast cancer in", "blankets", "a sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.5, "QA-F1": 0.5498316102756893}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, true, false, true, false, false, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.1111111111111111, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7368421052631579, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-69", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-6577", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2982", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_hotpotqa-validation-869", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.5, "CSR": 0.540296052631579, "EFR": 1.0, "Overall": 0.6930592105263157}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "tyne", "the stomach and esophagus", "40", "table salt", "Bears", "cuba", "cuba", "Phil Redmond", "Stevie Wonder", "head", "hound", "hanover", "a moon", "king Charles I of England", "work", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "Montezuma", "a 1934 Austin seven box saloon", "Paul Anka", "cuba", "cuba", "doris macbeth", "Blade Runner", "Jay-Z", "leopons", "drum", "air Bud", "San Diego", "doris taylor", "Ticket Sarasota", "South Africa", "Christian Dior", "scrobbesbyrig", "Killer whales", "Georgia", "France", "raspberries", "pilgrimage", "Cyprus", "aerodynamic shape", "dukes", "lizard", "cuba", "frauds", "a sea monster", "even numbers", "Tony Blair", "quartz or feldspar", "54 Mbit / s", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Ray Lynn", "piano", "paid tribute to pop legend Michael Jackson, who died Thursday afternoon in Los Angeles.", "Yang Hyong Sop, and Kim Kye Gwan", "French Guiana", "cuba", "a second son", "Tiger Woods"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5227306547619047}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-4822", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5730", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.453125, "CSR": 0.5380608974358974, "EFR": 1.0, "Overall": 0.6926121794871795}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "alivo", "Midnight Cowboy", "norm", "seborrheic dermatitis", "norma barrie", "steam engines", "Niger", "central Stockholm", "Tangled", "dogs", "norman tyson", "Bulls Eye", "l'Angleterre est une nation de boutiquiers", "baroque orchestras", "norman lunes", "charles Darwin", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "john Mellencamp", "isambard Kingdom Brunel", "norma", "1957", "Devon", "barles", "butter and oil", "normet", "ralph Vaughan Williams", "musical scale", "cats", "seawing", "e. T. A. Hoffmann", "Shanghai", "Spain", "grow", "Tuesday", "g Guru nak", "bleak house", "The Princess bride", "norm", "lJack Horner", "Indianapolis", "norma", "cuckoo", "norman joseph rome", "Dodge", "Alice Cooper", "mallorca", "norman Landsteiner", "Royal Bengal Tiger", "inward spiral", "Max", "television personality, sports and entertainment reporter, and longtime syndicated columnist for the \"New York Daily News\" and the Chicago Tribune New York News Syndicate", "1999", "Sela Ann Ward", "The Cycle of Life", "forgery and flying without a valid license", "183", "a log cabin", "March", "blitz", "Sondheim"], "metric_results": {"EM": 0.4375, "QA-F1": 0.48467261904761905}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6497", "mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-6282", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-777", "mrqa_naturalquestions-validation-9755"], "SR": 0.4375, "CSR": 0.535546875, "EFR": 0.9722222222222222, "Overall": 0.6865538194444444}, {"timecode": 40, "before_eval_results": {"predictions": ["the 19th Century", "Famous Players-Lasky", "Washington", "de quincey", "a pestilential fever", "horses", "bison", "avian", "a dove", "Sarajevo", "the Bill of Rights", "dust", "Neighbours", "jimmy boyigh", "trumpet", "Westminster Abbey", "origami", "resistance of an unknown resistor", "the Arabian Gulf", "secretary", "jimmy boyd", "mater", "jack Nicholson", "\u201cTonight Is Another Day\u201d or \u201cTote the weary Load\u201d", "diesel", "Tomorrow Never Dies", "Sudan", "a Great Dane", "Washington", "Angola", "New Hampshire", "jimmy i", "jimmy taylor", "the Philippines", "purple", "everyHit.com", "a charlie charblers", "winds", "rome", "10", "Southwest Airlines", "jimmy", "jimmy deaver", "The Comedy of Errors", "chicago", "glyn Jones", "President Ford", "crossword", "a serena", "Basque separatist", "rodinsons", "Humpty Dumpty", "1998", "Sukhvinder Singh", "the EN World web site", "the 100th anniversary of the first \" Tour de France\"", "a dimensionless quantity", "Janet and La Toya", "more than 2.5 million", "neuroethicists", "a dark neo-noir filled with console- cowboys, sentient AIs", "Seinfeld", "nibelung", "Inequality of opportunity was higher"], "metric_results": {"EM": 0.359375, "QA-F1": 0.45677083333333335}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.5, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.25, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999]}}, "before_error_ids": ["mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-2275", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4337", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.359375, "CSR": 0.53125, "EFR": 0.975609756097561, "Overall": 0.6863719512195121}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "london", "hula hoops", "n Nissan", "the Argonauts", "Roddy Doyle", "a counting table", "Robin Hood's Holy Grail", "sisyphus", "lazquez", "South African", "caracas", "henie", "tchaikovsky", "oscar Twist", "Scotland", "london vii", "david Bowie", "Neil Armstrong", "james paul sartre", "spruce vii", "Dick Turpin", "rust", "jane krakowski", "Wiltshire", "tbilisi", "henry tatum", "othello", "sewing up of a small hole or tear in a piece of material", "glenn close", "lacock Abbey", "lise Meyer", "cats", "anita Brookner", "james vii", "golda meir", "Black Sea", "bagram Theater Internment Facility", "james dent", "a power outage Sunday", "Vienna", "The Archers", "shylock", "james james sousa", "henry vii", "james boyd", "shakespears Sister", "The Four Marx Brothers", "avon", "r.A.P. of Amsterdam", "Dry Ice", "Pat McCormick", "19 June 2018", "2001", "from 1993 to 1996", "Michael Rispoli", "September 29, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones.", "a bassoon", "o.K. Corral", "butternut apples", "london"], "metric_results": {"EM": 0.5, "QA-F1": 0.5823739035087719}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5, 0.8, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.10526315789473685, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-5773", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.5, "CSR": 0.5305059523809523, "EFR": 0.96875, "Overall": 0.6848511904761905}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "some work rule issues.", "Eintracht Frankfurt", "Comoros Islands", "aston villa", "near Garacad, Somalia", "40", "tears", "\"Big change is hard,\"", "Manny Pacquiao", "$250,000", "Wednesday, at a house adjacent to the park", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "Salt Lake City, Utah", "Marty Abrams", "Michoacan Family", "64", "Myanmar's military junta", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career", "\"E! News\"", "Florida Emergency Operations Center.", "Madeleine K. Albright", "ice jam", "toxic smoke from burn pits in Iraq and contaminated water.", "Benazir Bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "Alan Graham", "her fianc\u00e9,", "Cal Ripken Jr.", "Johannesburg", "cancer", "acid attack", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "Hyundai", "about 5:20 p.m.", "former Mobile County Circuit Judge Herman Thomas", "\"A salute to the martyrs of the massacre, and our condolences to their families.\"", "a man's lifeless, naked body", "\"release\" civilians, who it said numbered about 70,000 in Sri Lanka's war zone.", "Dodi Fayed", "the shipping industry -- responsible for 5% of global greenhouse gas emissions,", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "Cuauhtemoc", "spain", "Misery", "purdy", "Antonio Lippi", "Thorgan", "River Clyde", "norwegian", "jimmy jim", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5467146796916533}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2, 0.8000000000000002, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.0, 0.0, 0.6, 0.05714285714285715, 1.0, 0.2666666666666667, 0.3636363636363636, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.453125, "CSR": 0.5287063953488372, "EFR": 1.0, "Overall": 0.6907412790697675}, {"timecode": 43, "before_eval_results": {"predictions": ["the twelfth most populous city in the United States", "House of Borromeo", "Washington, D.C.,", "1943", "Volvo 850", "the Mountain West Conference", "Atlanta Hawks", "Western Europe", "movie scripts written by ghost writers, nonfiction books on military subjects, and video games", "Schaeffler AG", "English football league", "1989 until 1994", "the Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown", "Lollywood and Pollywood films", "Emmanuel ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "Lynyrd Skynyrd", "15 October 1988", "coaxial", "Northern Lights", "three different covers", "Malayalam cinema", "held in Kingdom of Dalmatia", "August 11, 1946", "Vincent Landay", "May 26, 2010", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Brian A. Miller", "Nicolas Vanier", "1985", "Wonder Woman", "Meghan Markle", "Boeing B-17 Flying Fortress", "by a family of Portuguese descent", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33", "Brig Gen Augustine Warner Robins", "United Nations", "Alice", "two occasions", "by Ratcliff & Gretton Limited", "blue", "the elbow", "Citizens are picking members of the lower house of parliament,", "the Employee Free Choice act", "the release of the four men", "atonement", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.59375, "QA-F1": 0.684292963980464}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-7240", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070", "mrqa_searchqa-validation-260"], "SR": 0.59375, "CSR": 0.5301846590909092, "EFR": 1.0, "Overall": 0.6910369318181818}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "former White Zombie bassist Sean Yseult", "Washington, D.C.", "5.3 million", "Lucha de Apuesta", "Conservatorio Verdi", "the 43rd Vice President of the United States", "the backside", "the Docile Don", "The Future", "the Knight Company", "Adam Karpel", "Danish national ice hockey team", "2015 Orange Bowl", "Margarine Unie", "death", "Fort Valley, Georgia", "Tom Hanks", "Vladimir Valentinovich Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "The 2017 Major League Baseball (MLB) First-Year Player Draft", "Douglas Jackson", "roller", "Blackpool Football Club", "William Lyon Mackenzie King", "Ted", "Keith Crofford", "Fiat Chrysler", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Division of Fawkner", "S\u014dkr\u00e1t\u0113s", "American singer Toni Braxton", "Hindi", "Richard Masur", "Irish Chekhov", "311", "\"Dr. Gr\u00e4sler, Badearzt\"", "Alexandre Dimitri Song Billong", "The Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "1972", "John Goodman", "216", "Spectator", "Easter Parade", "Elgar\u2019s", "last summer.", "almost 100", "into the Southeast,", "a piece of the pie", "a stick to fish the filemot frith for treasures", "a rapid cavalry", "One Direction"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6523944805194806}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false, false, true], "QA-F1": [1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.6, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-2525", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1917", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-2915", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-3263", "mrqa_searchqa-validation-12050"], "SR": 0.53125, "CSR": 0.5302083333333334, "EFR": 1.0, "Overall": 0.6910416666666667}, {"timecode": 45, "before_eval_results": {"predictions": ["to be elected from and by the presbyterate", "QED", "Queen Elizabeth II", "Gauls", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "miniature golf", "Bill Hemmer", "Punxsutawney Phil Sowerby", "Pannonia", "yellow fever", "a sea otter", "M&M's", "Submarine sandwich", "a rod", "and illegal wiretapping", "dressage", "astronomer", "Mickey Mouse", "a bud", "Associate Professor", "a fruit snack", "Medusa", "a staircase", "tabby", "musical notes", "Voyager 1", "a surgeon's knife", "glucose", "objects", "China", "Helen of Sparta", "meat", "peace sign", "Morrie Schwartz", "English Monarchs These 2", "India", "Ben Kingsley", "Lobsters' Jug", "NFL", "samt ar-ras", "How shall he cut it", "Rules Process for handling a Main Motion", "Wordsworth", "brushes", "a", "Arabian Nights", "Vincent Price", "Rugrats in Paris", "Middle Eastern alchemy", "London, England", "Isle of Wight", "Peppercorn class", "Queen In-hyun's Man", "Oneida Limited", "James Worthy", "Libreville, Gabon.", "tickets", "the station", "Cahawba, Dallas County"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5540178571428571}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false], "QA-F1": [0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9923", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-14560", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1744", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-3322", "mrqa_naturalquestions-validation-9626", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-6557", "mrqa_newsqa-validation-824", "mrqa_triviaqa-validation-888"], "SR": 0.453125, "CSR": 0.5285326086956521, "EFR": 1.0, "Overall": 0.6907065217391304}, {"timecode": 46, "before_eval_results": {"predictions": ["their actual social power and wealth", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "a torture chamber", "a faggot", "a skein", "California Chrome", "Pluto", "Route 66", "the Taklamakan Desert", "Punjab", "Astronauts", "the Gobi Desert", "Germany", "the British pop band Go West", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Neptune", "Birmingham", "snakes", "Sedgefield", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "a trenches exhibition", "South Korea", "pigs", "definitely, maybe", "Carmen", "Kenya", "Stephen Potter", "Casa di Giulietta", "Anwar Sadat", "a hundred", "potomac", "Argentina", "Luke Skywalker", "Frankfurt", "chipmunk", "Goldie Hawn", "a pulsar", "Belgium", "horses", "liqueurs", "Benfica", "Sun Lust Pictures", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "the Louvre.", "Speed Racer", "Henry Holt", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6641369047619048}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-445", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-2953", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.609375, "CSR": 0.5302526595744681, "EFR": 0.96, "Overall": 0.6830505319148935}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "Palazzo delle Prigioni,", "Sinclair Lewis", "toms, the bear and The Andy", "Renard", "tempera", "jodie Foster", "Vaclav Havel", "Dick Van Dyke", "Isabella", "Tina Turner", "2010", "Coleraine", "glasses", "perfume", "duke orsino", "iron", "spain", "The Apprentice", "winter", "Cubism for Kids", "sahara desert", "Commonwealth Scientific and Industrial Research Organisation", "eukharistos", "The Real Miracle of Charlotte's Web", "Octopussy", "fresh fruits and vegetables", "William Randolph Hearst", "Adam, Hoss, and Little Joe", "rowing", "cin Redgrave", "Call My Bluff", "a", "Argentina", "Frank McCourt", "milk or water", "Caroline Aherne", "(Afterwards Home Guard)", "oxygen", "Pears soap", "Donna Summer", "a balustrade", "nottingham", "Poland", "the Welcome Stranger", "taggart", "April", "Chechnya", "a police janitor in an unnamed city", "a-teamautos", "football", "801,200", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough, Massachusetts", "Speedway World Championship", "it's historical, empowering, creative, romantic and beautiful.", "Eleven people", "Michelle Obama", "kbenhavn", "the Proletariat", "saara", "fluoroquinolone"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5372159090909091}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, true, true, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-5096", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6956", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-7020", "mrqa_searchqa-validation-15651", "mrqa_newsqa-validation-1804"], "SR": 0.484375, "CSR": 0.529296875, "EFR": 1.0, "Overall": 0.6908593749999999}, {"timecode": 48, "before_eval_results": {"predictions": ["East Lothian", "Caesars Entertainment Corporation", "Supergirl", "king \u00c6thelred the Unready", "creature comforts", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air", "Mineola, New York", "dziga Vertov", "Strange Interlude", "Julia Compton Moore", "Olivia Newton-John", "1986", "early Romantic period", "The Gettysburg Address", "Harold Edward Holt", "Washington Street", "Lauren Lane", "Babylon", "Ford Falcon", "New York State Route 907E", "The Company", "1827", "Kim Bauer", "United States Food and Drug Administration (FDA)", "Edward James Olmos", "Suffolk", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard H or HD blister gas", "The 45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "Westminster, London", "Boyd Gaming", "August 14, 1848", "Texas Tech University", "John McClane", "Larry Wayne Gatlin", "the 924", "267.6 days", "North Carolina", "Selinsgrove,", "Augusta Ada King-Noel, Countess of Lovelace (\"n\u00e9e\" Byron; 10 December 1815 \u2013 27 November 1852)", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "space shuttle", "basil", "Clio Awards", "The Rosie Show", "North Korea", "over 1,000 pounds", "Julius Caesar", "a volcano's lava flow", "Library of Congress", "the thylakoid membranes"], "metric_results": {"EM": 0.59375, "QA-F1": 0.675677730331263}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.8695652173913043, 0.19999999999999998, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-775", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.59375, "CSR": 0.5306122448979591, "EFR": 0.9615384615384616, "Overall": 0.6834301412872841}, {"timecode": 49, "UKR": 0.7109375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2339", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5755", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-2999", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-60", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3155", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5788", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6000", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-888", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-92"], "OKR": 0.8359375, "KG": 0.459375, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John W. Henry", "Mos Def", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Love Hina", "eastern", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five aerial victories", "Alain Robbe-Grillet", "the Seasiders", "Musicology", "TVB", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1928", "1969", "February 20, 2011", "North Greenwich Arena", "1614", "Canadian author Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Taio Cruz", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "the EN World web site", "Charles Russell", "Kj\u00f8benhavns Boldklub", "Colonel Patrick John Mercer", "Golden Globe Award", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec fox", "Dutch", "Terry Malloy", "Golden Calf for Best Actor in 2013", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "Everywhere", "the birth centenary of Pandit Jawaharlal Nehru", "Honda", "J. M. W. Turner", "Republic of Upper Volta", "56", "Nkepile Mabuse", "Eintracht Frankfurt", "U.S. Marines", "the god of fire", "Amherst College", "two courses"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6770258387445887}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-1198", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-1259", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-2296", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-12141", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.546875, "CSR": 0.5309375000000001, "EFR": 1.0, "Overall": 0.7074375}]}