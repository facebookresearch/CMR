{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4260, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "the Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "8.0", "the end of the 19th century", "peace", "$40,000", "the Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "about 3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings as well as structures dating from the 15th\u201318th centuries", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "10%", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis", "Uncle Tom's Cabin", "the liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8738095238095238}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-2798", "mrqa_squad-validation-1775", "mrqa_squad-validation-7552", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.84375, "CSR": 0.859375, "EFR": 1.0, "Overall": 0.9296875}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "the evolution of the German language and literature", "the Qur'an", "the Brotherhood", "high demand", "Tolui (1190\u20131232)", "human law", "the object's weight", "50%", "1960s", "two months", "his friends", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "a Qara-Khitay (Khitan)", "1960", "Captain America: Civil War", "political divisions", "linear", "Alta California", "The Book of Common Prayer", "14", "Charleston, South Carolina", "fear of their lives", "warmest regions", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford, California", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food", "plasmas", "their low ratio of organic matter to salt and water", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "time goes", "guardian", "guardian", "black", "50 feet"], "metric_results": {"EM": 0.5625, "QA-F1": 0.633881222943723}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7408", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-4405", "mrqa_squad-validation-2547", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-2809", "mrqa_squad-validation-5893", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-164", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-8402", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3857"], "SR": 0.5625, "CSR": 0.7604166666666666, "EFR": 1.0, "Overall": 0.8802083333333333}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double membrane", "August 1967", "German", "27-30%", "four", "50 fund", "Arizona Cardinals", "Peanuts", "comb rows", "calcitriol", "Krak\u00f3w", "time", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Luther", "English", "a lack of remorse", "the fundamental means by which forces are emitted and absorbed", "A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "John Houghton", "February 2015", "draftsman", "Mollusca", "Orestes", "the Galapagos Islands", "the \"Today\" show host did a terrible job", "a gas (like water vapor) changes state to become a liquid", "the Travel Detective: How to Get the Best Service", "a cocoa favorite", "a major raw", "the Mycenaean civilization", "a biological process that displays an endogenous, entrainable", "the Belasco Theatre", "the Normandy Landings", "John Dillinger", "fibula l pin", "Il Trovatore", "1911", "the East Coast Main Line"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6853693181818181}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-3673", "mrqa_squad-validation-2132", "mrqa_squad-validation-6737", "mrqa_squad-validation-10310", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-6338", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.65625, "CSR": 0.734375, "EFR": 0.9090909090909091, "Overall": 0.8217329545454546}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box design", "to spearhead the regeneration of the North-East", "the Gaulish name as *R\u012bnaz, via Old Frankish giving Old English R\u00edn, Old High German R\u012bn, Dutch Rijn (formerly also spelled Rhijn)", "gambling", "secular powers", "applied mathematics to the construction of calendars", "Zhongtong", "11.1%", "1538", "Deacons", "the New Testament from Greek", "experience, ideology, and weapons", "25 percent", "May 2013", "Torchwood", "capturing prey", "C4 mesophyll cells", "livestock pasture", "Ford, Toyota and Holden", "1,300,000", "it has trouble distinguishing between carbon dioxide and oxygen, so at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "two tumen (20,000 soldiers)", "eight", "computational complexity theory", "WWSB and WOTV", "Orange", "tentilla (\"little tentacles\"", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "the Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empires", "domestic legislation of the Scottish Parliament", "passing the smooth muscle in the gut and relieve cramping", "Michael Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers set to appear all over the world over the next 10 years.", "a lump in Henry's nether regions was a cancerous tumor", "the war years", "semiconductors", "Matt Kuchar and Bubba Watson", "fastest circumnavigation of the globe in a powerboat", "a large concrete block is next to his shoulder, with shattered pieces of it around him. Blood trickles down the road", "the foyer of the BBC building in Glasgow, Scotland", "Buddhism", "Manchester City", "Noriko Savoie", "three men with suicide vests who were plotting to carry out the attacks", "change course", "Tsvangirai", "Wicked", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "sweetener", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6662682116876091}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true, false, false, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8571428571428571, 1.0, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.4, 1.0, 0.7058823529411764, 0.4, 1.0, 0.4, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913045, 0.6666666666666666, 0.2666666666666667, 0.375, 0.4, 0.2, 0.0, 0.8333333333333333, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.5, 0.15384615384615385, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7606", "mrqa_squad-validation-9250", "mrqa_squad-validation-2272", "mrqa_squad-validation-7626", "mrqa_squad-validation-8874", "mrqa_squad-validation-4258", "mrqa_squad-validation-2984", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-1643", "mrqa_squad-validation-6092", "mrqa_squad-validation-4943", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-862", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.515625, "CSR": 0.690625, "EFR": 0.967741935483871, "Overall": 0.8291834677419355}, {"timecode": 5, "before_eval_results": {"predictions": ["with money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "a seal illegally is broken", "Philip Howard", "King Ethelred II of England", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "French", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical and highly refractive bodies", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two", "George Westinghouse", "by disrupting their plasma membrane", "internal combustion engines", "elementary particles", "gurus, mullahs, rabbis, pastors/youth pastors and lamas", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Goa", "How I Met Your Mother", "Louvre museum", "Leo Frank", "Thessaloniki and Athens", "Graziano Transmissioni", "opposition parties", "more than 1.2 million people", "Newcastle retained fourth place with a 3-1 victory over Blackburn, who remained in the relegation zone.", "the release of the four men", "first lady Michelle Obama is weighing in on the issue by focusing on how health care can affect families.", "Ed McMahon", "at least $20 million to $30 million", "the Democratic VP candidate", "Friday", "Obama", "paper ballots", "Sodra nongovernmental organization,", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium", "promotes fuel economy and safety while boosted the economy.", "a resting heart rate over 100 beats per minute", "a small draught horse, around three-fourths of a ton, and is without feathered legs.", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6716899981146305}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.7000000000000001, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.25, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 0.13333333333333333, 1.0, 0.5, 0.0, 0.4444444444444445, 0.0, 0.0, 0.4, 0.6666666666666666, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.15384615384615385, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-3408", "mrqa_squad-validation-1090", "mrqa_squad-validation-3087", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-8826", "mrqa_squad-validation-6644", "mrqa_squad-validation-1852", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.53125, "CSR": 0.6640625, "EFR": 1.0, "Overall": 0.83203125}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "a protestor who attempts to escape punishment by committing the crime covertly and avoiding attribution, or by fleeing the jurisdiction, is generally viewed as not being a civil disobedient.", "the University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational resource", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "a straight line", "1991", "William Smith", "William Pitt", "a geochemical component called KREEP", "Theory of the Earth to the Royal Society of Edinburgh", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "A horizontal force pointing northeast can therefore be split into two forces, one pointing north, and one pointing east", "issues under their jurisdiction", "unsuccessful", "human", "medications are requested and received", "a modified version of the sieve that considers 1 as prime would eliminate all multiples of 1", "nerves", "1671", "the Reichstag", "a double sugar or a disaccharide", "DNC", "the heart, blood, and cardiac muscle.", "Troggs", "six", "Slovakia", "Princess Diana", "slave-trade", "aorta", "Virginia's", "bullseye", "Tartarus", "cyclorama - Search-ID.com", "Si-Tchun", "Achaemenid", "LAP", "Zeppelins", "San Francisco", "George IV", "Datson, H., Birch,... plus assorted small iron and slag particles.", "New York Police Department", "Judas", "a group of characters who have safely gotten off the Island and are given", "a comic book series by Robert Kirkman, Tony Moore, and Charlie Adlard", "Love Is All Around", "Los Angeles Dance Theater", "Somalia", "a form of liquid morphine used by terminally ill patients will remain on the market even though it is an \"unapproved drug,\"", "18"], "metric_results": {"EM": 0.5, "QA-F1": 0.5579861111111111}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.11111111111111112, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.20000000000000004, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6773", "mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_squad-validation-9064", "mrqa_squad-validation-3113", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-14782", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.5, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs and the wetter climate", "oxygen", "reduce growth in relatively poor countries but encourage growth in richer countries", "K-9 and Company", "9.1 million", "a lower level of economic mobility than all the continental European countries for which data is available.", "individual countries", "cattle", "Western Xia", "semantical problems and grammatical niceties", "five", "a \"gold standard\" of religion", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway/Eisenhower Freeway", "Thanksgiving", "874.3 square miles (2,264 km2)", "Two thirds", "the Privy Council", "well into the nineteenth century", "\u201ccapability deprivation\u201d", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Bryant", "Earth", "a tornado", "Rodeo", "hoo-hoo", "John Sexton", "Breathless", "a coffee is usually served in this small cups, from the French for \"half-cup\"", "a peacock unitard", "Annapolis", "Spring", "a monkey", "bark beetles", "Allah", "bones", "Boa Constrictor Python Rainforest", "the Bible", "a 2003 American epic war drama film", "Faith Hill", "Ben Affleck", "a hurricane is a large-scale, low-pressure weather system.", "V", "a Fine Time", "a jazz saxophonist and composer", "Sweden", "Vietnam", "hydrogen", "Alexandria", "Perfume: The Story of a Murderer", "New Jersey Economic Development Authority's 20% tax credit on TV shows filmed or produced in the state,", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5898672462406015}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.3157894736842105, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7468", "mrqa_squad-validation-7399", "mrqa_squad-validation-1938", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-7473", "mrqa_squad-validation-8189", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_hotpotqa-validation-4891", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.53125, "CSR": 0.626953125, "EFR": 1.0, "Overall": 0.8134765625}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes or an antibody-based humoral response", "producers", "BSkyB", "Kawann Short", "Daidu", "silent film", "22", "the park", "1965", "tidal currents", "an exlposion", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement", "Irish", "Red Army", "20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "six series of theses", "Body of Proof", "seven-eighths", "the cardinal de Richelieu", "the Atlas Mountains", "Madrid", "the Danube", "Viking god", "leather", "George Pullman", "red", "the Messiah", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "the tonka bean", "the divisor", "a Greek god of dreams", "Texas", "IHOP", "a black breed and a white breed mingled to produce this type of cow named for a German region; today, it produces 90% of U.S. milk", "the Constitution", "a standardized college entrance exam", "Brasilia", "Henry David Thoreau", "California", "Dick Cheney", "an axis that runs through you", "Gustave Eiffel", "Edward Hopper", "the CIA", "D'Artagnan", "a green substance", "1985", "apple", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6566972373188407}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.33333333333333337, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.08695652173913045, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6559", "mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-1169", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.59375, "CSR": 0.6232638888888888, "EFR": 1.0, "Overall": 0.8116319444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["Provisional Registration", "August 15, 1971", "Levi's Stadium", "Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61 per cent", "During the Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "Exploration is still continuing to determine if there are more reserves", "prep schools", "soft power", "strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes, the most characteristic musical instrument in the region", "the Dutch Republic", "Alex Haley", "three", "the helmeted honeyeater", "4:51", "Khrushchev", "Hera", "the vine", "Elton John", "Cuba", "King Leonidas", "the Preamatians", "Kroc", "bowling", "white", "Wash.", "Carmen", "Genoa", "15", "tarn", "Fahrenheit 451", "Buffalo", "Ann Widdecombe", "Isosceles", "a square", "Tuesday", "copper sulfate", "Monsoon", "Massachusetts", "Preamble", "California", "the Susquehanna River", "Kajagoogoo", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "Janet Napolitano", "J. Crew outfits", "Mitt Romney", "Bea Benaderet"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6137152777777779}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.2666666666666667, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8784", "mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-8273", "mrqa_squad-validation-9870", "mrqa_squad-validation-5376", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-7509"], "SR": 0.53125, "CSR": 0.6140625, "EFR": 1.0, "Overall": 0.80703125}, {"timecode": 10, "before_eval_results": {"predictions": ["tenggis", "environmental determinism", "4 August 2010", "King George III", "a radio network", "Dongshan Dafo Dian", "League of Augsburg", "Duarte Barbosa", "the Inner Mongolia region", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "single all-encompassing definition of the term", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "the faecal-oral route", "stone", "Ken Russell", "Dan Dare", "Crassus", "Smiths", "Mike Tyson", "Armenia", "Passover", "Brian Deane", "kaleidoscope", "Uranus", "Apollon", "Carlin", "Ukraine", "Sydney", "Mount Hollywood", "Underground Railroad", "Puck", "UVB", "passion fruit", "Portugal", "cricket", "Mariah Carey", "144 inches", "Titanic", "William Tell", "Christian Dior", "a shaggy dog", "Mendip", "Wichita", "the Passover", "New Croton Reservoir", "andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "Monty Python", "Marina Zenovich"], "metric_results": {"EM": 0.625, "QA-F1": 0.6721387987012987}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 0.4, 0.5714285714285715, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-5083", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-8589"], "SR": 0.625, "CSR": 0.6150568181818181, "EFR": 1.0, "Overall": 0.8075284090909091}, {"timecode": 11, "before_eval_results": {"predictions": ["the method by which the medications are requested and received", "salvation", "jugs and candlesticks", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju", "administration", "Chivas", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "a large public network that supported dial-up users and a private network business that allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "public service", "Guy de Lusignan", "tiger team", "b cells", "The European Commission", "p-adic", "impossible view of the nature of natural motion", "Mongol and Turkic", "hizbullah", "four", "Whist", "morocco", "tuscany", "achromatopsia", "black", "Pluto", "iron", "copper", "The Hague", "city of los angeles", "eagles", "Smiley", "nizhny Novgorod", "black spots", "Beyonce", "Wordsworth", "Man V Food", "tectonic uplift of land and volcanic eruptions", "Samuel Johnson", "Michael Jackson", "Mary Poppins", "Bennett Cerf", "black leaf", "julius", "julius", "julius", "Oslo", "lions", "rhododendron", "sweden", "Franklin D. Roosevelt", "Shanghai", "julie Forbush", "eiffel Tower", "Snake River Valley", "17 October 2006", "beer", "Kingman Regional Medical Center", "sweden", "julius caesar", "Edgar Allan Poe", "a policeman"], "metric_results": {"EM": 0.46875, "QA-F1": 0.4997860863095238}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-4870", "mrqa_squad-validation-6530", "mrqa_squad-validation-8957", "mrqa_squad-validation-10338", "mrqa_squad-validation-8226", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-6278", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-2059", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.46875, "CSR": 0.6028645833333333, "EFR": 1.0, "Overall": 0.8014322916666666}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "he broadened the foundations of the Reformation placing them on prophetic faith.", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "A majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadine", "Newcastle Eagles", "cholera", "The GPhC", "relative units", "AD 14", "orogenic wedges", "Daniel Boone", "The Handmaid's Tale", "the bonobo", "The Fault in Our Stars", "Vigor", "a puzzle video game", "1898", "400 MW", "Total Nonstop Action Wrestling", "Galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort", "David Villa", "Red and Assiniboine", "Alpine, New Jersey", "Continental Army", "Robert Noyce", "darryl", "Umar S. Israilov", "July 16, 1971", "1933", "What's Up", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel Comics", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point du Sable", "in England", "glenn johnson", "a basilica", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "Afghan forces in destroying drug labs, markets and convoys", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "elizabeth johnson", "dapple-grey", "pre-Columbian times"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6167410714285715}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.09999999999999999, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2249", "mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-9658", "mrqa_squad-validation-6320", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-990", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-5019", "mrqa_hotpotqa-validation-1843", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.53125, "CSR": 0.5973557692307692, "EFR": 1.0, "Overall": 0.7986778846153846}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "impossible", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "partial funding", "boarding schools", "NCAA Division II", "Adrian Lyne", "his most brilliant student", "Las Vegas", "Ranulf de Gernon", "2017", "Dallas", "Rudolf Schenker", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Michael Redgrave", "6th", "Highlands Course", "Hawaii", "a moth of the Gracillariidae family", "Marie-Joseph Paul Yves Roch Gilbert du Motier", "Gujarat", "three", "Winter Haven Mall", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio L\u00f3pez", "\"My Beautiful Dark Twisted Fantasy\" (2010)", "FCI Danbury", "a few", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Anna Mae Aquash", "Rwandan genocide of 1994", "Johnny Cash", "the U.S. Senate", "2011", "1982", "16.5 feet", "Chris Robinson", "gossip Girl", "aerodynamics", "dwindle or fizzle out", "Creation", "Jerry Leiber and Mike Stoller"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5845170454545454}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 0.4, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.8, 0.9090909090909091, 1.0, 0.6666666666666666, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_squad-validation-7036", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-3990", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.484375, "CSR": 0.5892857142857143, "EFR": 1.0, "Overall": 0.7946428571428572}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "1970", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "a plague", "the kilogram-force", "ten times their own weight", "Quaternary", "1887", "ctenophores", "a symbiotic relationship with vitamin D", "mathematical models of computation", "Vistula River", "100 to 150", "Apple announcing plans that could move iTunes into the cloud.", "a dorm parent", "March 8", "Democrats and Republicans", "the Catholic League", "over 1,000 pounds", "a rumor, not a fact.", "Friday", "Majid Movahedi", "stories of different women coping with breast cancer in five vignettes.", "\"black rain\" of drilling fluid and a roar of escaping gas", "a smile on her face", "$40 and a quarter of bread", "Lance Cpl. Maria Lauterbach", "Hyundai Steel", "London", "more than 4,000 commercial farmers", "Val d'Isere, France", "the results by a chaplain about 1:45 p.m., per jail policy.", "two soldiers and two civilians", "$14.1 million", "1616", "Sky", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J.Crew", "U.N. Secretary of State Hillary Clinton", "\"I always kind of admired him, oddly.\"", "\"Empire of the Sun,\"", "suppress the memories and to live as normal a life as possible", "4 meters (13 feet) high", "the Irish capital", "Democrat", "a Utah jail", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "the toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "giant", "mercury"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5099831135604161}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7777777777777778, 0.15789473684210525, 0.0, 0.8000000000000002, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.0, 0.1818181818181818, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-6565", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191"], "SR": 0.421875, "CSR": 0.578125, "EFR": 0.972972972972973, "Overall": 0.7755489864864865}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "Mercury", "prime", "50 fund", "Camisards", "$40 million", "GTE.", "1,100", "spin", "Oligocene", "Melodie Rydalch", "Christopher Columbus", "a Little Rock military recruiting center.", "March 24,", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "a dozen gunshot rang out across the plaza, and ambulances darted in and out of the square as the fighting continued.", "\"She had a smile on her face, like she always does when she comes in here,\"", "56", "the National Football League", "\"The Lost Symbol\"", "one of its diplomats", "intravenous vitamin \"drips\" are part of the latest quick-fix, health fad catching on in Japan", "12", "Seoul.", "resources", "\"We say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well,", "two", "\"scared I won't be able to go home", "Dean Martin, Katharine Hepburn and Spencer Tracy", "Rwanda", "75.", "eradication of the Zetas cartel", "closing these racial gaps.", "gun charges", "President Bush", "a hospital in Amstetten,", "African National Congress Deputy President Kgalema Motlanthe", "lost his job as the supermarket chain he worked for cut staff.", "\"The Kirchners have been weakened by this latest economic crisis,\"", "attended the Democratic National Convention", "sharia law", "warning to management.", "Prime Minister Benjamin Netanyahu", "20% tax credit", "July 23.", "70,000", "fear led people to behave that way.", "Robert Remak", "Tim McGraw", "Prussian", "cabbage", "a fictional world", "Beno\u00eet Jacquot", "topaz", "the Capitol", "The Left Book Club", "holography"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5118745289401039}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.17391304347826086, 0.0, 0.0, 1.0, 0.0, 0.0, 0.10526315789473685, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.5, 0.4444444444444445, 0.0, 0.09523809523809525, 0.0, 0.08, 0.0, 0.0, 1.0, 1.0, 0.1111111111111111, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3293", "mrqa_squad-validation-9016", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_hotpotqa-validation-5305", "mrqa_triviaqa-validation-6296"], "SR": 0.484375, "CSR": 0.572265625, "EFR": 1.0, "Overall": 0.7861328125}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30%", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "President Robert Mugabe", "voluntary neglig after witnesses identified him and he was interviewed by police.", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "1979", "murder", "next year", "\"China is a different matter", "Christopher Savoie", "Anil Kapoor", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear weapon", "brutal choice", "Matthew Fisher", "cancer,", "Courtney Love,", "tapped into our greatest resources: the character and resolve of the American people.", "\"Perfidia,\" \"Walk Don't Run\" and \"Diamond Head.", "your environmental efforts", "two women", "Queen Elizabeth's birthday", "Monday,", "male veterans struggling with homelessness and addiction.", "Yusuf Saad Kamel", "Lilla Torg.", "11 healthy eggs", "Russia and some European countries have expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "around the United States", "1950s,", "U.S. troops working in support of Iraqi soldiers killed two snipers, two other men firing rocket-propelled grenades and \"multiple others from a nearby building where soldiers were taking RPG and machine gun fire,\"", "a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "More than 120 groups across six continents are holding vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's security team", "Oxbow, a town of about 238 people,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "French Revolutionary ideals of liberty, equality, and fraternity", "2001", "vingtaines", "Ingemar Johansson", "George Blake", "Bogota"], "metric_results": {"EM": 0.5, "QA-F1": 0.57147591991342}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714285, 0.27272727272727276, 0.22222222222222224, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.36363636363636365, 0.057142857142857134, 0.2857142857142857, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3455", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.5, "CSR": 0.5680147058823529, "EFR": 1.0, "Overall": 0.7840073529411764}, {"timecode": 17, "before_eval_results": {"predictions": ["lower levels of inequality.", "a pharmacy practice residency", "questions and answers in the catechism", "wakes (sed vigilat) and experiences visions", "Captain Francis Fowke,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich", "\"Sesame Street's\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's restive provinces", "fled Zimbabwe and found his qualifications mean little as a refugee.", "guerrillas", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "two other women who complained about his conduct.", "Matthew Fisher", "Peppermint oil, soluble fiber, and antispasmodic drugs can indeed help people with irritable bowel syndrome,", "Helmand province", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "urging more help for military members, especially for those returning from war.\"", "$250,000", "first or second week in April.", "boogeyman", "scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "kite boards", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22-year-old", "One of Osama bin Laden's sons", "putting a personal and human face on the issue... there's nothing more crucial,\"", "U.N. officials", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps in the Mohmand agency", "planned inside Pakistan,", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "hid his money,", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "7", "sake", "Halifax"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5433322715931411}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, true, false, false, false, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.22222222222222224, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.15384615384615385, 0.5217391304347826, 0.0, 1.0, 0.25, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-2338", "mrqa_squad-validation-2408", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-2583", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3206", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695"], "SR": 0.453125, "CSR": 0.5616319444444444, "EFR": 1.0, "Overall": 0.7808159722222222}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "circular", "Advanced Steam", "Defensive ends", "\"the dot\"", "chastity", "European Court of Justice", "a bronze medal in the women's figure skating final,", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "UK", "\"Gandhi,\"", "Argentina", "Congress", "28", "New Haven, Connecticut, firefighter Frank Ricci,", "Kurdish Region of Iraq", "made one of his strongest statements to date on the sex abuse scandal sweeping the Roman Catholic Church,", "industrialized nations", "$106,482,500 to an unidentified telephone bidder in February, 2010.", "people give the United States abysmal approval ratings.", "not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "North Korea", "slowing movement to a crawl after the inauguration of Barack Obama as the 44th president of the United States.", "the mammoth's fossil", "recognizes the importance of Turkey and wants to engage with it from the start.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "\"wildcat\" strikes,", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally,", "Lindsey Vonn", "Paul McCartney and Ringo Starr", "organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "President Obama's race", "Brazil", "Malmo", "trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "1998", "a leak in a Dike", "\"Taxman,\"", "Che Guevara", "Miller Brewing", "Elizabeth Tudor", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.46875, "QA-F1": 0.535894149019149}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, true, false, false, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.09523809523809522, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.9696969696969697, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0909090909090909, 1.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.16, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_squad-validation-8746", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-900", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254", "mrqa_searchqa-validation-11385"], "SR": 0.46875, "CSR": 0.5567434210526316, "EFR": 0.9705882352941176, "Overall": 0.7636658281733746}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Danny Trevathan", "11", "unless he were removed from the school, Tesla would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012,", "Pittsburgh Steelers", "apartment building in Cologne, Germany,", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah.", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "most of those who managed to survive the incident hid in a boiler room and storage closets", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to the coming days.\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book", "he was diagnosed with skin cancer.", "stand down.", "Ashley \"A.J. Jewell,", "17", "Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "rural California,", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "a floating National Historic Landmark,", "individual pieces.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "Rod Blagojevich", "Flint, Michigan,", "patrolling the pavement in protective shoes", "100,000 workers", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "it was split 10-2.", "often discard beer bottles on pebbled walkways.", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International", "\"Grandmasters\"", "Suffragist", "Canterbury", "Tunisia", "Silver", "Some day they'll go down together"], "metric_results": {"EM": 0.5, "QA-F1": 0.6646783929678666}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.10810810810810811, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.5, 0.28571428571428575, 0.888888888888889, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.8, 0.0, 0.5714285714285715, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1326", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-416", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-413", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_searchqa-validation-3783"], "SR": 0.5, "CSR": 0.55390625, "EFR": 0.96875, "Overall": 0.761328125}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "materia medica", "Marshall Field", "four", "mistreatment from government officials.", "Beijing, China,", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "100,000", "proxy wars", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50", "Argentine composer Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhism", "1978", "1927, 1934, 1938, 1956", "1969", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "team", "September 2014", "Archduke Franz Ferdinand of Austria", "a central place in Christian eschatology", "October 1941", "peace between two entities", "Shalimar Gardens ( Lahore ), Lalbagh Fort at Dhaka, and Shalimar Bagh ( Srinagar )", "Cee - Lo", "before they kill him", "tomato pur\u00e9e generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Conservative Party", "three times", "November 25, 2002,", "October 29, 2015,", "Peter Greene", "31 March 1909", "Ed Sheeran", "two", "Alberto Salazar", "live animals", "American", "Hoosick,", "CEO of an engineering and construction company with a vast personal fortune.", "1.2 million", "the wolf", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "approximately 600 square miles of south-central Washington,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6754937770562771}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.25, 1.0, 0.4, 0.0, 0.0, 0.0, 0.9696969696969697, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5714285714285715, 1.0, 0.5, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-6314", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-156", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.546875, "CSR": 0.5535714285714286, "EFR": 0.9655172413793104, "Overall": 0.7595443349753694}, {"timecode": 21, "before_eval_results": {"predictions": ["about 515 million years ago", "Spanish", "an attack on New France's capital, Quebec", "the Fresno Traction Company", "Westminster", "blue-green algae", "four", "their bearers", "Washington metropolitan area", "acidity or basicity of an aqueous solution", "the breast or lower chest of beef or veal", "the ruling city of the Northern Kingdom of Israel", "Tagalog or English", "around 1600 BC", "by October 1986", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford,", "the 2nd century", "in positions Arg15 - Ile16", "Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "a foreign exchange option", "Introduced in 1957", "1776", "1963", "Gustav Bauer", "2018", "Ireland", "Kit Harington", "her boyfriend Lance", "an anembryonic gestation", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Swedish figure skater Gillis Grafstr\u00f6m", "Sophocles", "Tim Allen", "the stratum lucidum", "a Genoise sponge base, a layer of orange flavoured jam and a coating of chocolate", "India", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay", "cricket", "the Major General of the Navy", "Marktown", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "Pardon of Richard Nixon", "Ellen DeGeneres", "12 April 1961", "punk rock", "Westfield"], "metric_results": {"EM": 0.375, "QA-F1": 0.5724799455038425}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.9333333333333333, 0.0, 0.30769230769230765, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 0.8, 0.16666666666666666, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 1.0, 0.4, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.30769230769230765, 1.0, 0.0, 1.0, 0.6666666666666666, 0.08333333333333333, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-4472", "mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_hotpotqa-validation-427", "mrqa_hotpotqa-validation-3984", "mrqa_hotpotqa-validation-5755"], "SR": 0.375, "CSR": 0.5454545454545454, "EFR": 1.0, "Overall": 0.7727272727272727}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16, and Acts 1 : 13 )", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island on August 27,", "American electronic music duo The Chainsmoker", "2015, in the United States, the poverty threshold for a single person under 65 was an annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "a single particle in a plane two coordinates define its location", "John Adams of Massachusetts, Benjamin Franklin of Pennsylvania, Thomas Jefferson of Virginia, Robert R. Livingston of New York, and Roger Sherman of Connecticut", "Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "Burbank, California", "Ricardo Chavira as Dan Palmer", "2009", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas as Matt Morgan   Anthony Quinn as Craig Belden", "Jodie Foster", "February 27, 2007", "Malina Weissman", "8ft", "Owen Vaccaro", "food", "on the lateral side", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff / \ufefb\ufffd 90 \u00b0N - 0 \u00b0 E", "London to Canterbury", "in the bloodstream or surrounding tissue following surgery, disease, or trauma", "2005", "February 28 or March 1", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "Burmese", "\u00ef\u00bf\u00bd", "Pearl Jam", "March 28, 1970", "Dan Tyminski", "The 19-year-old woman", "Karachi", "at least nine", "Hafez al-Assad", "New Revised Standard Version", "Biathlon"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5668032700544857}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, false, true, false, false, false, false, true, true], "QA-F1": [0.9473684210526316, 1.0, 1.0, 1.0, 0.25, 1.0, 0.34782608695652173, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.21052631578947367, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 1.0, 0.19999999999999998, 0.19999999999999998, 0.16, 1.0, 0.4444444444444445, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8148148148148148, 0.5, 0.0, 0.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3636363636363636, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_hotpotqa-validation-1458", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.4375, "CSR": 0.5407608695652174, "EFR": 0.9722222222222222, "Overall": 0.7564915458937198}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "its many castles and vineyards", "0 \u00b0C (32 \u00b0F)", "Denver linebacker Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "The Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd", "during prenatal development in the central part of each developing bone", "Ali", "Tanvi Shah", "Article 1, Section 2", "the Constitution of India", "Richard Bremmer", "Dick Rutan", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "James P. Flynn", "detritus", "September 27, 2017", "Twenty - seven different countries", "1978", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando", "February 10, 2017", "Alex Skuby", "the Colony of Virginia", "March 2016", "1922", "Edward Hyde", "Bacon", "in an explosion", "Heather Stebbins", "Redenbacher family", "a sometimes ambiguous designation of two classes of organic compounds", "9 or 10 national ( significant ) numbers", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "to ensure its ratification and lead to the adoption of the first ten amendments, the Bill of Rights", "U.S. Bank Stadium in Minneapolis, Minnesota", "the forces of Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "female", "John Garfield", "1871", "eye", "The History Boys", "caviar", "White Knights of the Ku Klux Klan", "five", "Darkthrone", "U.S. 93 in White Hills, Arizona,", "Phillip A. Myers", "Osama bin Laden", "Antarctica", "axon", "portobello"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5814863616154378}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, true, false, false, false, true, false, false, true, false, true, true, false, false, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.7499999999999999, 0.888888888888889, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.8, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.3333333333333333, 0.0, 0.5, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6956521739130436, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_squad-validation-8990", "mrqa_squad-validation-2914", "mrqa_squad-validation-44", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_hotpotqa-validation-395", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.4375, "CSR": 0.5364583333333333, "EFR": 0.9722222222222222, "Overall": 0.7543402777777777}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange,", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "1996", "the onset and progression of Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "McKinsey's offices in Silicon Valley and India", "New York", "Charles Whitman", "C. H. Greenblatt", "Robin R. Bottin", "the A55 road", "Corendon Dutch Airlines", "86 ft", "Minneapolis, Minnesota", "Loch Duich", "Fatih Ozmen", "U.S.", "Pacific Place", "served as the Attorney General of Michigan from 1999 to 2003", "Flamingo Las Vegas", "Westminster, London", "2016", "Wildhorn", "New York University School of Law", "the Crips", "Queen's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Guadalcanal Campaign", "Bishop's Stortford Football Club", "The Hungry Hustlerz:", "Barbara Lee Alexander", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "the Teutonic Knights", "Australia", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland, OR", "Yoruba", "\"Lucky\"", "Charlie Puth", "2007 and 2008", "2001", "1966", "The Stig", "Ryan Harris", "Medellin", "his father", "Lawmakers eyeball one of several alternative-energy vehicles parked this week", "2004", "genes", "Olive", "Stockholm"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6557787698412698}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.5, 0.8571428571428571, 1.0, 0.7499999999999999, 0.4444444444444445, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 0.6666666666666666, 0.4, 0.4, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.4, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-979", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.46875, "CSR": 0.53375, "EFR": 0.9705882352941176, "Overall": 0.7521691176470588}, {"timecode": 25, "UKR": 0.6953125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-2250", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2289", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2988", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-3901", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-4461", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-5382", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10227", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-1123", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2380", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-4562", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5539", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-6851", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-7609", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8023", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-9001", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9505", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-1258", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-1733", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-1800", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-2583", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2727", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2944", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3206", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3410", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3654", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-3745", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-39", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4046", "mrqa_newsqa-validation-4095", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-65", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-660", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-94", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-11385", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-12624", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-1335", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-14663", "mrqa_searchqa-validation-14883", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-16181", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3783", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-4857", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-7702", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-9090", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-9705", "mrqa_searchqa-validation-9756", "mrqa_squad-validation-10045", "mrqa_squad-validation-10069", "mrqa_squad-validation-10074", "mrqa_squad-validation-10086", "mrqa_squad-validation-10216", "mrqa_squad-validation-10228", "mrqa_squad-validation-10254", "mrqa_squad-validation-10310", "mrqa_squad-validation-10324", "mrqa_squad-validation-10338", "mrqa_squad-validation-10353", "mrqa_squad-validation-1036", "mrqa_squad-validation-10378", "mrqa_squad-validation-10477", "mrqa_squad-validation-1090", "mrqa_squad-validation-1320", "mrqa_squad-validation-1450", "mrqa_squad-validation-1603", "mrqa_squad-validation-1636", "mrqa_squad-validation-1672", "mrqa_squad-validation-1694", "mrqa_squad-validation-178", "mrqa_squad-validation-1802", "mrqa_squad-validation-1852", "mrqa_squad-validation-1855", "mrqa_squad-validation-1857", "mrqa_squad-validation-1938", "mrqa_squad-validation-1967", "mrqa_squad-validation-2040", "mrqa_squad-validation-2126", "mrqa_squad-validation-2153", "mrqa_squad-validation-2216", "mrqa_squad-validation-2289", "mrqa_squad-validation-2384", "mrqa_squad-validation-2400", "mrqa_squad-validation-2436", "mrqa_squad-validation-2460", "mrqa_squad-validation-2477", "mrqa_squad-validation-255", "mrqa_squad-validation-2577", "mrqa_squad-validation-2602", "mrqa_squad-validation-2619", "mrqa_squad-validation-268", "mrqa_squad-validation-2693", "mrqa_squad-validation-2773", "mrqa_squad-validation-2782", "mrqa_squad-validation-2798", "mrqa_squad-validation-282", "mrqa_squad-validation-2824", "mrqa_squad-validation-285", "mrqa_squad-validation-2929", "mrqa_squad-validation-3019", "mrqa_squad-validation-3041", "mrqa_squad-validation-3135", "mrqa_squad-validation-3185", "mrqa_squad-validation-320", "mrqa_squad-validation-3337", "mrqa_squad-validation-3476", "mrqa_squad-validation-353", "mrqa_squad-validation-3589", "mrqa_squad-validation-3709", "mrqa_squad-validation-383", "mrqa_squad-validation-3931", "mrqa_squad-validation-3948", "mrqa_squad-validation-3955", "mrqa_squad-validation-397", "mrqa_squad-validation-3993", "mrqa_squad-validation-4005", "mrqa_squad-validation-4079", "mrqa_squad-validation-4140", "mrqa_squad-validation-415", "mrqa_squad-validation-4181", "mrqa_squad-validation-427", "mrqa_squad-validation-4291", "mrqa_squad-validation-4305", "mrqa_squad-validation-4333", "mrqa_squad-validation-4338", "mrqa_squad-validation-4472", "mrqa_squad-validation-462", "mrqa_squad-validation-4686", "mrqa_squad-validation-4704", "mrqa_squad-validation-4835", "mrqa_squad-validation-4856", "mrqa_squad-validation-4870", "mrqa_squad-validation-5054", "mrqa_squad-validation-5088", "mrqa_squad-validation-5096", "mrqa_squad-validation-5154", "mrqa_squad-validation-5176", "mrqa_squad-validation-5238", "mrqa_squad-validation-5302", "mrqa_squad-validation-5326", "mrqa_squad-validation-5376", "mrqa_squad-validation-550", "mrqa_squad-validation-5537", "mrqa_squad-validation-5541", "mrqa_squad-validation-5588", "mrqa_squad-validation-5616", "mrqa_squad-validation-5672", "mrqa_squad-validation-5703", "mrqa_squad-validation-5767", "mrqa_squad-validation-5777", "mrqa_squad-validation-5913", "mrqa_squad-validation-60", "mrqa_squad-validation-60", "mrqa_squad-validation-607", "mrqa_squad-validation-6099", "mrqa_squad-validation-6126", "mrqa_squad-validation-6143", "mrqa_squad-validation-6178", "mrqa_squad-validation-6220", "mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6362", "mrqa_squad-validation-6395", "mrqa_squad-validation-6414", "mrqa_squad-validation-6564", "mrqa_squad-validation-660", "mrqa_squad-validation-6641", "mrqa_squad-validation-6737", "mrqa_squad-validation-6754", "mrqa_squad-validation-6782", "mrqa_squad-validation-68", "mrqa_squad-validation-6817", "mrqa_squad-validation-6915", "mrqa_squad-validation-696", "mrqa_squad-validation-7018", "mrqa_squad-validation-703", "mrqa_squad-validation-7069", "mrqa_squad-validation-707", "mrqa_squad-validation-7150", "mrqa_squad-validation-7161", "mrqa_squad-validation-7180", "mrqa_squad-validation-7198", "mrqa_squad-validation-7260", "mrqa_squad-validation-7399", "mrqa_squad-validation-754", "mrqa_squad-validation-7552", "mrqa_squad-validation-7597", "mrqa_squad-validation-7640", "mrqa_squad-validation-765", "mrqa_squad-validation-7678", "mrqa_squad-validation-7770", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-7856", "mrqa_squad-validation-7882", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-804", "mrqa_squad-validation-8056", "mrqa_squad-validation-8104", "mrqa_squad-validation-8115", "mrqa_squad-validation-8189", "mrqa_squad-validation-8226", "mrqa_squad-validation-8226", "mrqa_squad-validation-8285", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8527", "mrqa_squad-validation-8629", "mrqa_squad-validation-8735", "mrqa_squad-validation-8760", "mrqa_squad-validation-8765", "mrqa_squad-validation-8832", "mrqa_squad-validation-884", "mrqa_squad-validation-8867", "mrqa_squad-validation-890", "mrqa_squad-validation-8957", "mrqa_squad-validation-898", "mrqa_squad-validation-9031", "mrqa_squad-validation-9066", "mrqa_squad-validation-9135", "mrqa_squad-validation-9186", "mrqa_squad-validation-9227", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9391", "mrqa_squad-validation-9392", "mrqa_squad-validation-9465", "mrqa_squad-validation-9504", "mrqa_squad-validation-9541", "mrqa_squad-validation-9552", "mrqa_squad-validation-9652", "mrqa_squad-validation-9658", "mrqa_squad-validation-9771", "mrqa_squad-validation-979", "mrqa_squad-validation-9818", "mrqa_squad-validation-987", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2626", "mrqa_triviaqa-validation-2685", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-3051", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-4107", "mrqa_triviaqa-validation-4171", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-4440", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-5568", "mrqa_triviaqa-validation-5671", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6290", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-6909", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-71", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-7548", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-776"], "OKR": 0.84765625, "KG": 0.428125, "before_eval_results": {"predictions": ["A progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater", "Anna Clyne", "Terence Winter,", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Jonghyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "Sharyn McCrumb", "acid house", "at the end of the 18th century", "\"Redemption of the Five Boroughs\"", "Miranda Leigh Lambert", "Shenandoah National Park", "Allan McNish", "10 Years", "Haleiwa,", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "Timmy Sanders", "PBS", "second largest", "Citric acid", "in 1911", "Lola Dee", "the group known as \"The Five\"", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "torpedo boats", "1972", "Geographical Indication", "Buck Owens and the Buckaroos", "the Celtics", "World Championship Wrestling", "1994", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "the following year", "Tenochtitlan", "before 1986", "Lou Gehrig", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram", "michael andrew at Trinil", "to become more sustainable", "purple"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6438368055555556}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.75, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5750", "mrqa_hotpotqa-validation-2056", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4737", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-2854", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240", "mrqa_searchqa-validation-1374"], "SR": 0.5625, "CSR": 0.5348557692307692, "EFR": 0.9642857142857143, "Overall": 0.6940470467032968}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu tribe", "The Ruhr", "Nairobi, Kenya", "Heinkel Flugzeugwerke", "Victor Garber", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "Sleeping Beauty", "Orchard Central", "Scarlett Johansson", "late eighteenth century", "\"The Snowman\"", "1979", "Premier League club", "port city of Aden", "British", "Prince Louis of Battenberg", "1985", "Archie Andrews", "before", "1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Joseph Travolta", "Hall & Oates", "Mazatl\u00e1n", "racehorse breeder", "Summerlin", "1919", "Jon Hamm", "\"Love Streams\"", "Eddie \"The Eagle\" Edwards", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "Pantone Matching System (PMS)", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Obi - Wan Kenobi", "1963", "a palla", "Car", "Thorn", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan", "Japan", "postcards"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6603308150183149}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-5102", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143"], "SR": 0.59375, "CSR": 0.537037037037037, "EFR": 1.0, "Overall": 0.7016261574074074}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Christian", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "WWE 2K18", "Kolkata", "\"Dumb and Dumber\"", "EA-18G Growler", "IT products", "Paper", "Sir Matthew Alistair Grant", "Whitney Houston", "Sumitomo Rubber Industries", "Bonkyll Castle", "Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "due to a leg injury", "Antonio Salieri", "American", "Europe", "Chiltern Shakespeare Company", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Primettes", "Cersei Lannister", "Kalokuokamaile", "Brigadier General Raden Panji", "Don Bluth", "December 8, 1970", "Chief of the Operations Staff", "Hong Kong Disneyland", "London", "Double Crossed", "February 17, 2017", "FBI", "Christine MacIntyre", "Virginia", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914", "David Victor and David J. O'Connell", "Prussian army general", "January 2004", "co-founder and lead guitarist", "ten", "seven", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus", "Equatorial Guinea", "glycerol", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "Massachusetts", "bromide", "a deviated septum", "Warp Drive"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6031498015873016}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_squad-validation-1075", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-873", "mrqa_hotpotqa-validation-739", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-281", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_triviaqa-validation-2051", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.484375, "CSR": 0.53515625, "EFR": 1.0, "Overall": 0.70125}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "hanover", "Henry Mancini", "tenno", "Gordon Ramsay", "Gorbachev", "ragging on the weather and the civilian authorities and giving voice to all the concerns of the men in the trenches", "sub rosa", "Charlton Heston", "Anna (Julia Roberts)", "scythe", "cedar", "Paddy Doherty", "pustular bump", "colossus of Rhodes", "Libya", "Chubby Checker", "bagatelle no. 25 in A minor", "Khomeini", "Who\u2019s Who", "These Names Make News", "c. 1595", "April", "Eric Morley", "hypertension", "the Garrick Club", "Beauty turning into a human", "Fabio Capello", "New York", "Tom Stoppard", "\"The Greatest\"", "colonel", "Tyne", "a Scotsman\u2019s bonnet", "tenor saxophonist", "Seattle", "Ty Ganol", "Cardiff", "Baton Rouge", "colossus", "Tahrir Square", "Romanian", "bathtub curve", "Michael Caine", "Snooty", "Alexander Borodin", "Jesse James", "muzzles", "Greek", "passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "Leviathan", "Denmark and Norway", "1966", "North America", "Florida's Everglades", "Garth Brooks", "glamorous, sexy and international.", "drive", "Glengarry Glen Ross", "shark"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5565972222222222}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, false, false, true, false, true, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, true, false, true, false, true, false, true, true, true], "QA-F1": [0.0, 0.5, 0.39999999999999997, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.33333333333333337, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2216", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-4432", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-2313", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-6701", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-1004"], "SR": 0.484375, "CSR": 0.5334051724137931, "EFR": 1.0, "Overall": 0.7008997844827587}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Bob Pettit and Kobe Bryant", "James W. Marshall", "in florida it is illegal to sell alcohol before 1 pm on any sunday", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Watson and Dan Stevens", "between 8.7 % and 9.1 %", "on Friday, 16 February", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "in Pyeongchang County, Gangwon Province, South Korea", "the status line", "innermost in the eye", "jimmy williams", "Triple Alliance of Germany", "Andrew Lloyd Webber", "May 1960", "Charles Frederickson ( Nick Sager )", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar", "the original Star Trek television series", "1960", "Bumblebee", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "iran faris", "between 2004 and 2007", "Tango in the Night", "technological advances in printing", "Cairo, Illinois", "in the 1970s and'80s", "in the books of Exodus and Deuteronomy", "Chandler", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century.", "January 2, 1971", "The Miracles", "a domain ( Latin : regio )", "forearm", "jimmy caesar", "Charlie Sheen", "\"Twice in a Lifetime\"", "Orwell", "Bardot", "teenager", "Long Island convenience store", "the most likely candidate to see through \"knee-jerk, ideological\" perspectives and \"bridge the political divide in Washington.\"", "Peter", "stomach", "dancing with the stars"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5886492673992674}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 0.5454545454545454, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.56, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-5069", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-2682", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1958", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426"], "SR": 0.46875, "CSR": 0.53125, "EFR": 0.9705882352941176, "Overall": 0.6945863970588235}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "cultural tourism and sports tourism", "a circle", "( Sequoia sempervirens)", "Tara Lyn Charendoff", "the Spanish Republic", "taximeter", "coyote", "The Sun Also Rises", "Harry Reid", "Ray", "Axis", "forge", "The Kinetoscope", "Rmi Lebret", "corey", "The Beatles", "Footprints", "Caliban", "L.A. Kings", "In a UZA that has more than one DR,", "Tommy Lee Jones", "(Luke 19:1-10)", "The Memory Keeper's daughter", "(1819-1880)", "hubris", "Yahtzee", "Tony Danza", "HTML", "hives", "74.3", "William S. Hart", "Joshua", "Pride and Prejudice", "The Secret Family of Jesus", "Kosher Wines", "Munich", "Michael Jordan", "February 2, 1887", "Prospero", "Hikaru Sulu", "parrots", "pastry", "honshu", "hula", "Boston", "Fisher Price", "Arctic Ocean", "pizze Napoletane", "squash", "Spain", "Thomas Chisholm", "May 2002", "1997", "Newfoundland", "Will Success Spoil Rock Hunter?", "Monty Python and the Holy Grail", "1911", "Harlow Cuadra and Joseph Kerekes", "Newtonian mechanics", "Israel", "Adidas", "anti-trust laws."], "metric_results": {"EM": 0.53125, "QA-F1": 0.5651041666666666}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2965", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-5162", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-10080", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-391"], "SR": 0.53125, "CSR": 0.53125, "EFR": 1.0, "Overall": 0.70046875}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Ferengi cocktails Quark", "Christian Kern", "June 26, 1970", "Bloomingdale Firehouse", "elizabeth Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge Aharon Barak", "Bangkok", "Oklahoma Sooners", "Merrimack", "Charlie Wilson", "\"The Late Late Show\"", "Mark Anthony \"Baz\" Luhrmann", "two", "The Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "January 19, 1943", "The Worm", "Eliot Cutler", "Mercury Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland", "\"Slaughterhouse-Five\"", "Adventures of Huckleberry Finn", "wineries", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "The Highwaymen", "Madrid", "Kevin Spacey", "Arizona State University", "Blue Grass Airport", "Kenneth Hood \"Buddy\" MacKay Jr.", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Lenny Jacobson", "Hathi Jr", "1935", "Geryon", "\"foreigner,\"", "The Miracles", "the 6.2-mile Moffat Tunnel", "Microsoft", "Friday", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6698517628205127}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-2088", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-4268", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.578125, "CSR": 0.53271484375, "EFR": 1.0, "Overall": 0.70076171875}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 5", "jellyfish", "March", "a clogs", "fauntleroy", "the World Health Organization", "Eat porridge", "Kofi Annan", "oxygen", "pamphlets, posters, ballads", "Taggart", "i second that Greedo managed to slip away while the family gunned down the rest of Che's captors", "the Gulf of Mexico", "Ladee-Lo", "Sven Goran Eriksson", "the College of Arms", "Route 66", "Brussels", "Flora MacDonald", "John Poulson", "Orly", "the euro", "i second that emotion", "Saskatchewan", "Laurent Planchon", "the wind", "vomiting", "the Red Lion", "Bristol Aeroplane Company", "lettuce", "Steve Davis", "i second that emotion", "Libra", "Surrey", "1971", "chippenham", "Budapest", "Chile", "Inca Garcilaso de la Vega", "sodium tetraborate decahydrate", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "Rigor mortis is very important in meat technology", "United States customary units", "Miller Brewing", "Liguria", "Sydney", "music, street dancing and revelry", "her decades-long portrayal of Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\"", "Peter Bogdanovich", "a dove", "Cyprus"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5132551476301477}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 0.12121212121212123, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7197", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-4986", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-7262", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539"], "SR": 0.46875, "CSR": 0.5307765151515151, "EFR": 1.0, "Overall": 0.7003740530303031}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "Lana Del Rey", "1,228 km / h ( 763 mph )", "New England Patriots", "Ph. D.", "Antarctica", "Mitch Murray", "blue", "`` Ultra Hand ''", "John Bull", "775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "a long line, called the main line", "Jesus'birth", "a habitat", "Kirsten Simone Vangsness", "Mitteldeutschland", "Andrew Johnson", "Bart Cummings", "Aegisthus", "electors", "Julia Ormond", "Sauron's assistance", "1961", "ste\u026and / STAYND", "2013", "February 28", "movie", "a usually red oxide formed by the redox reaction of iron and oxygen in the presence of water or air moisture", "Spain", "Taylor Hayes", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "paid monument", "erosion", "March 2, 2016", "cranberry sauce", "1996", "Ray Charles", "16", "the Ramones", "1800", "Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "Pittsburgh", "July 31, 2010", "France", "Heath Ledger", "The Young Rascals", "a centaur", "music lover who must work for a kingpin", "cricket fighting", "Luis Resto", "drama that pulls in the crowds", "a Ukrainian --", "Islamabad", "Tunisia", "RAND Corporation", "apoplexy"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5264913896705068}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 0.0, 0.06451612903225806, 1.0, 1.0, 0.0, 0.18181818181818182, 0.6666666666666666, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-7802", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-9972", "mrqa_triviaqa-validation-5607", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2118", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.46875, "CSR": 0.5289522058823529, "EFR": 1.0, "Overall": 0.7000091911764705}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Cal", "in Brahmagupta's Brahmasputha Siddhanta ( 7th century )", "July 22, 2017", "her abusive husband", "September 29, 2017", "interstellar space", "transmission and final drive", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions forms the joint venture Bullwinkle Studios", "Tanvi Shah", "March 14, 1942", "Nick Sager", "London boroughs, Metropolitan Boroughs, unitary authorities, and district councils", "a biblical title of respect", "the state legislators of Assam", "digestion of proteins", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "temperature at which the phase transition occurs", "Mind your Ps and Qs is an English expression meaning `` mind your manners '', '' mind your language '', `` be on your best behaviour '' or similar", "Germany", "20 November 1989", "Tom\u00e1s de Torquemada", "the Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "first published in the United States", "2003", "Sebastian Lund ( Rob Kerkovich )", "Sunday, 2 September to Wednesday, 5 September 1666", "California State Route 1", "The management team", "antigen from the lumen and deliver it to the lymphoid tissue", "actionScript 3.0 programming language", "Steveston Outdoor pool", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1840", "brake to a full stop", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Derrick Henry", "ice cap climate", "a cliffhanger showing the first few moments of Sam's next leap ( along with him again uttering `` Oh, boy! '' on discovering his situation )", "on a bronze plaque and mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "hard rock/blues rock band", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "this week", "Henry Ford", "Toyota", "Abraham Lincoln", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread, so they're usually classed as benign."], "metric_results": {"EM": 0.390625, "QA-F1": 0.538349791565911}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.7692307692307692, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.13793103448275862, 1.0, 0.5, 1.0, 0.3636363636363636, 0.0, 0.3333333333333333, 0.19999999999999998, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.7428571428571429, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.125, 0.11764705882352941, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666665, 0.2758620689655173, 0.0, 0.0, 0.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-1480", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.390625, "CSR": 0.525, "EFR": 0.9230769230769231, "Overall": 0.6838341346153847}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "euphoric", "James McConkey", "Venezuela", "Croatia", "The Ring", "Peter Pan", "Andrea del Sarto", "the Arctic Ocean", "the flame going out causes a vacuum effect, so the egg is sucked in by the differential in this between the inside & outside of the bottle", "dams", "Lafayette", "Elijah Muhammad", "depressed", "the Royal Marines Band", "Alexander Pushkin", "Australia", "Munich Crisis", "Puebla", "a night shift", "the papacy", "the Mississippi Alluvial Plain", "hanellaco - How to Pass the HP HP0-J11 Brainit dumps Online Store", "Pierre-August Renoir", "aussi banc, dent, [w], quando, uomo", "libretti", "Innsbruck", "Charles Keating Jr.", "Microsoft", "a fern", "The co-founder of this respected organization", "a Viking chieftain's", "Atlantic City's", "Blackwater USA", "elephants", "American Airlines", "a bachary sheep", "Odysseus", "Geronimo", "Kensington Palace", "the Wild Bunch", "the Netherlands", "Pocahontas", "the Lion, the Witch, and the Wardrobe", "John Galt", "a chalkboard", "the Chicago Mercantile Exchange", "Las Vegas", "\"Danskins Are Not Just For Dancing,\"", "wheat", "Pablo Casals", "an ostrich or common ostrich (Struthio camelus)", "1943", "Payaya Indians", "beneath the liver", "James I", "Penrhyn", "psychological horror", "John Morgan", "Hungarian Rhapsody No. 2", "Henry II", "Sen. Debbie Stabenow (D- Michigan)", "63", "\"We are resetting, and because we are resetted, the minister and I have an overload of work.\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.5561011904761904}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-10308", "mrqa_searchqa-validation-5473", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.46875, "CSR": 0.5234375, "EFR": 1.0, "Overall": 0.6989062500000001}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "northwards at a speed of about 15 metres ( 49 feet ) per year", "Lucknow", "2014", "National Industrial Recovery Act", "The User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "between 2 world Trade Center and 3 World Trade Center", "Southend Pier", "Santa Monica", "sovereignty", "William first encounters on the planet that his family crash lands on", "31 January 1934", "Filipino", "1773", "modern random - access memory ( RAM )", "2012", "April 1917", "Bart Cummings", "October 27, 1904", "Kusha", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean", "2016", "Frankie Muniz", "The stratum lucidum", "60", "Hasmukh Adhia", "the Four Seas", "one retina", "1980s", "in soils", "card verification value", "`` rebuke with all authority ''", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in formal education during the Roman Empire", "Mike Czerwien", "103", "Vienna", "English", "Mexico", "Stalin", "$10.5 million", "Al Horford", "Andrew Johnson", "$22 million", "leftist Workers' Party", "his mother", "cotton", "dennis haysbert", "Quinn", "Towcester"], "metric_results": {"EM": 0.5625, "QA-F1": 0.681344637635756}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.10526315789473685, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9523809523809523, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.888888888888889, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.1, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_hotpotqa-validation-4351", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161"], "SR": 0.5625, "CSR": 0.5244932432432432, "EFR": 0.9285714285714286, "Overall": 0.6848316843629344}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "the United States", "South Africa", "first among equals", "Scott Hicks", "a cappella", "albinism", "Henry Hunt", "aglet", "Saturday Night Live", "FC Bayern", "winter", "Bonnie and Clyde", "English", "copper", "Dawn French", "Blackstar", "Florentius", "Doris Lessing", "Scooby-Doo", "Swaziland", "b Britannia", "Kent", "the Humber", "points based scoring system", "automobile", "Kent", "Rodgers and Hammerstein", "Boy George", "Galileo Galilei", "Zelle", "Lee Ingleby", "Marilyn Manson", "Medellin", "shakespeare", "a piston", "brazil", "Boulder Dam", "bhang, Dope, draw, ganja, grass, hash, hashish, herb, Marijuana", "iran", "Belle de Jour", "Morecambe", "Abba", "rain", "blue", "Asaph Hall", "France", "Snowbell", "Kunsky", "other scientific fields", "David Graham", "Hugh de Cressingham", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "Washington", "heavy turbulence", "different women coping with breast cancer in five vignettes.", "Blaine", "a sunflower", "Madonna", "March 24,"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6220238095238095}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-69", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-541", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.59375, "CSR": 0.5263157894736843, "EFR": 1.0, "Overall": 0.6994819078947369}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "Tyne", "the liver", "40", "water", "a pet", "Bolivia", "ch.1, p. 49-50", "Colin Cant", "Stevie Wonder", "the head", "dog", "hanover", "the moon", "Charles", "work", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "Montezuma", "a 1934 Austin seven box saloon", "Paul Anka", "Carthage", "Bath", "prince Duncan", "Blade Runner", "Jay-Z", "leopons", "drum", "air Bud", "La traviata", "Norman Tebbit", "fidelio", "South Africa", "Christian Dior", "scrobb's fort", "a killer whale", "Krubera", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "Duke", "lizard", "cuba", "frauds", "fish", "30", "Tony Blair", "quartz", "54 Mbit / s", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Lynn", "piano", "an impromptu memorial for the late singer", "former U.S. President Bill Clinton", "French Guiana", "AOL", "a second son", "Tiger Woods"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6183035714285714}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2224", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-2097", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_hotpotqa-validation-2852", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.5625, "CSR": 0.5272435897435898, "EFR": 0.9642857142857143, "Overall": 0.6925246108058608}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Aldi", "Midnight Cowboy", "charles", "dandruff", "Amanda Barrie", "a hoy of dordrecht", "Niger", "central Stockholm", "Tangled", "dog", "James Douglas", "Bulls Eye", "georgia", "bach", "Timothy Carroll", "charles Darwin", "pembrokeshire coast", "georgia", "peppers", "geologic era", "Jimmy Boyd", "Isambard Kingdom Brunel", "georgia", "1957", "Devonport", "moselle", "salt", "micelles", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "Pyotr Ilich Tchaikovsky", "Shanghai", "Spain", "farms the world\u2019s supply", "Tuesday", "Guru Nanak", "bleak house", "Inigo Montoya", "phosphorus", "Little Jack Horner", "Indianapolis", "lolita", "cuckoo", "Dame Margaret Rutherford", "Ford", "Alice Cooper", "Majorca (Mallorca)", "a person's", "Royal Bengal Tiger", "a circular orbit", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "The Cycle of Life", "forgery and flying without a valid license", "183", "a log cabin", "St. Patrick's Day", "defensive backs", "Marshall"], "metric_results": {"EM": 0.46875, "QA-F1": 0.529985119047619}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-2142", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-777", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.46875, "CSR": 0.52578125, "EFR": 0.9705882352941176, "Overall": 0.6934926470588235}, {"timecode": 40, "before_eval_results": {"predictions": ["the 19th Century", "Famous Players", "Pacific Northwest", "smith", "pestis", "horse", "bison", "jane jane", "a raven", "Sarajevo", "the Bill of Rights", "dust", "Neighbours", "smith", "trumpet", "Westminster Abbey", "origami", "resistance", "Arabian Gulf", "secretary", "smith", "avunculicide", "jack Nicholson", "\u201cMy dear, I don\u2019t give a damn\u201d", "steam", "Tomorrow Never Dies", "Sudan", "a Great Dane", "norway", "norway", "New Hampshire", "James I", "Terry Bates", "the Philippines", "purple rain", "smith", "a warblers", "a 965-foot ocean liner", "rome", "2", "Southwest Airlines", "a jimmy", "Jeffery Deaver", "The Comedy of Errors", "Chicago", "glyn Jones", "President Ford", "cheese", "a epeiric (or \"shelf\") sea", "political violence", "smith", "Kitty Softpaws", "August 18, 1998", "Tanvi Shah", "the EN World web site", "the 100th anniversary of the first \" Tour de France\"", "the Mach number", "Janet and La Toya", "2.5 million", "scientists", "keanu Reeves", "seinfeld", "terror", "Inequality of opportunity"], "metric_results": {"EM": 0.5, "QA-F1": 0.5221354166666666}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-5371", "mrqa_triviaqa-validation-2275", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519"], "SR": 0.5, "CSR": 0.5251524390243902, "EFR": 1.0, "Overall": 0.6992492378048781}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "angola", "hula hoops", "nippon Sangyo", "chobus", "roddy dixon", "an abacus", "Robin Hood's Holy Grail", "aeolus", "Velazquez", "South African", "caracas", "angola", "tchaikovsky", "henry wrayburn", "angola", "not Private Eye", "david Bowie", "alex aldrin", "Jean-Paul Sartre", "european", "dennis turpin", "rust", "jane krakowski", "pembroke", "tbilisi", "mel Gibson", "othello", "fabric", "glenn close", "cholderton", "alex b'Stard", "domestic cat", "anita Brookner", "james vii", "Golda Meir", "Black Sea", "bagram", "Susie Dent", "a power surge", "Vienna", "The Archers", "shylock", "james philip sousa", "henry roodee", "james b Boyd", "shakespears Sister", "spencer", "aire", "habsburg Monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "2001", "from 1993 to 1996", "james Gandolfini", "September 29, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones.", "a bassoon", "doc Holliday", "butternut squash", "thomasarna"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5594572368421052}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.10526315789473685, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-5080", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-14680", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.484375, "CSR": 0.5241815476190477, "EFR": 0.9696969696969697, "Overall": 0.6929944534632034}, {"timecode": 42, "before_eval_results": {"predictions": ["the lack of reliable statistics from this period", "some work rule issues", "Borussia Monchengladbach", "villa", "revolution of values", "near Garacad, Somalia", "40", "his chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "27,", "British Prime Minister Gordon Brown", "Peru's ex-president", "Salt Lake City, Utah", "dancy-Power Automotive", "the \" Michoacan Family,\"", "64", "New Delhi, India", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career", "on the set at \"E! News\"", "off Haiti's coast", "Madeleine K. Albright", "a residential dike", "breast cancer", "benazir Bhutto", "July", "U.S. senators", "South Africa", "Larry Ellison", "Mrs. Graham", "her fianc\u00e9", "cal Ripken Jr.", "Johannesburg", "cancer", "acid attack", "forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m.", "former Mobile County Circuit Judge Herman Thomas", "\"We say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well,", "a man's lifeless, naked body", "\"release\" civilians", "Trevor Rees", "the catamaran", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc and Tenochtitlan", "danzig", "Misery", "Ernest Hemingway", "Italo Balbo", "Thorgan", "River Clyde", "angola", "marx", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5593026125920864}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8000000000000002, 0.0, 0.7272727272727273, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4210526315789474, 0.28571428571428575, 0.0, 0.6, 0.14545454545454548, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-30", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-5687", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.453125, "CSR": 0.5225290697674418, "EFR": 1.0, "Overall": 0.6987245639534885}, {"timecode": 43, "before_eval_results": {"predictions": ["the twelfth most populous city in the United States", "the House of Borromeo", "Washington, D.C.,", "1943", "a facelifted 850 saloon", "the Mountain West Conference", "the Boston Celtics", "Western Europe", "political thriller", "Continental AG", "English", "1989 until 1994", "Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown,", "Lollywood and Pollywood", "Emmanuel ofosu Yeboah", "Attack the Block", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "the last Roman Catholic Archbishop of Canterbury", "Galway", "Lynyrd Skynyrd", "2008\u201309", "coaxial", "Philip Pullman's", "three different covers", "Malayalam cinema", "held in Kingdom of Dalmatia", "August 11, 1946", "John Malkovich", "May 26, 2010", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Brian A. Miller", "Nicolas Vanier", "1985", "Wonder Woman", "Meghan Markle", "Boeing B-17 Flying Fortress", "Marco Da Silva", "Joe Scarborough", "Crimea", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Sony Studio Liverpool", "Brig Gen Augustine Warner Robins,", "United Nations", "Lewis Carroll", "two", "the UK\u2019s Trade Mark Registration Act 1875,", "blue", "the elbow", "Citizens are picking members of the lower house of parliament,", "the Employee Free Choice act", "the release of the four men", "baseball", "Jack the Ripper", "a carriage", "Teak"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6559641596326379}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, true, false, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.888888888888889, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-2081", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1464", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070", "mrqa_searchqa-validation-260"], "SR": 0.5625, "CSR": 0.5234375, "EFR": 1.0, "Overall": 0.6989062500000001}, {"timecode": 44, "before_eval_results": {"predictions": ["British Prime Minister Edward Heath", "Sean Yseult", "Washington, D.C.", "5.3 million", "Dulce Maria Garc\u00eda Rivas", "Conservatorio Verdi", "President of the United States", "\"the backside.\"", "Angelo Bruno", "Miranda July", "Newton Knight", "Andrew Joseph", "Denmark", "2015 Orange Bowl", "Margarine Unie", "death", "Fort Valley, Georgia", "Tom Hanks", "Vladimir Valentinovich Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "2017 Major League Baseball draft", "Douglas Jackson", "the Federal Construction Company", "Blackpool Football Club", "William Lyon Mackenzie King", "\"Ted\"", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Chrysler", "Bruce Grobbelaar", "Honda Ballade", "Ascona community", "Jacques Dominique Wilkins", "Austrian", "the Division of Fawkner", "Socrates", "American singer Toni Braxton", "Hindi", "Richard Masur", "Brian Patrick Friel", "311", "\"Dr. Gr\u00e4sler, Badearzt\"", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "6,012,331", "Roscoe Lee Browne", "1972", "John Goodman", "216", "The Spectator", "Easter Parade", "Elgar\u2019s \u2018Enigma\u2019 Variations", "last summer.", "almost 100", "into the Southeast,", "the jeffersons tv show", "Great Balls of Fire", "the advance,", "One Direction"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6299479166666666}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.33333333333333337, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-3913", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-2525", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1917", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-2104", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-12050"], "SR": 0.53125, "CSR": 0.5236111111111111, "EFR": 1.0, "Overall": 0.6989409722222223}, {"timecode": 45, "before_eval_results": {"predictions": ["the American Revolution", "a proof reader", "Queen Elizabeth II", "the Aquitani", "Northern Exposure", "cocoa butter", "Cocktail", "Esther", "Warren Harding", "Maurice Halperin", "miniature golf", "CNN", "Punxsutawney, Pennsylvania", "bordered by two other... of Austria-Hungary", "yellow fever", "a sea otter", "a \"seeing it in your mind's eye.\"", "a submarine sandwich", "a rod", "Nixon", "horse", "astronomy", "Mickey Mouse", "a bud or eye", "associate professor", "a fruit snack", "a statue", "a staircase", "Prince Attab", "a \"piece of instructions for a sequence of events in time\"", "Voyager 1", "Farsi (Persian)", "insulin", "a CD player", "China", "Helen of Sparta", "Vegetarianism", "a \"peace sign\"", "The Five People You Meet in Heaven", "English Monarchs", "India", "sexy Beast", "a \"dirty blizzard\"", "Oklahoma Sooners Football", "a samt ar-ras", "White bread and butter", "a \" meeting when the vote takes place, or a short retention period for ballots can be\"", "William Wordsworth", "a drumstick", "a \"dwarf planet\"", "a wish", "Vincent Price", "soundtrack to Rugrats in Paris", "Middle Eastern alchemy", "London,", "Isle of Wight", "Peppercorn Pioneer", "\"Queen In-hyun's Man\"", "Oneida Limited", "Michael Jordan", "Libreville, Gabon.", "tickets", "Christopher Barbour,", "tuscaloosa"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4744791666666667}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666665, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-6832", "mrqa_searchqa-validation-7347", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-3132", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-15141", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14560", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-11722", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-3322", "mrqa_naturalquestions-validation-9626", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3949", "mrqa_triviaqa-validation-888"], "SR": 0.390625, "CSR": 0.5207201086956521, "EFR": 0.9743589743589743, "Overall": 0.6932345666109253}, {"timecode": 46, "before_eval_results": {"predictions": ["social power and wealth", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "winston", "a faggot", "a plump", "California Chrome", "Pluto", "Route 66", "the Kunlun Mountains", "Sindh", "a genie", "the Great Victoria Desert", "German state of North Rhine-Westphalia", "\"I Was Kaiser Bill\\'s Batman\"", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "Daedalus", "Sedgefield", "Coral Sea", "Prime Minister Abd al-Karim Qasim", "Nadia Comaneci", "a trenches exhibition", "North Korea", "a pig", "'Oasis'", "Carmen", "Kenya", "Stephen Potter", "Casa di Giulietta", "Anwar Sadat", "6", "Susquehanna River", "Colorado", "Luke Skywalker", "Frankfurt", "chipmunk", "Goldie Hawn", "pulsars", "Belgium", "horses", "honey", "Benfica", "Sunny Leone", "a number of games where the player played, in whole or in part", "her arranged marriage to Chino, a friend of Bernardo's", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "Carrousel du Louvre", "Speed Racer", "Henry Holt", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5704326923076923}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-2974", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-716", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.53125, "CSR": 0.5209441489361701, "EFR": 1.0, "Overall": 0.698407579787234}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "to escape the dark and dingy confines of the Palazzo delle Prigioni,", "Sinclair Lewis", "a bear", "a fictional nuclear physicist", "tempera", "Jonathan Demme", "Vaclav Havel", "Dick Van Dyke", "Sir John Everett Millais", "Tina Turner", "2010", "toadstewart", "glasses", "perfume", "Duke Orsino", "iron", "Copenhagen", "Apprentice", "toadstool", "Analytical Cubism", "sahara desert", "the Advisory Council of Science and Industry", "bread and wine", "Charlotte\\'s Web", "Octopussy", "clothes", "William Randolph Hearst", "Lorne Greene", "rowing", "Corin Redgrave", "Call My Bluff", "a", "Argentina", "Frank McCourt", "oats", "Caroline Aherne", "LDV", "carbon dioxide", "soap", "Donna Summer", "Pillar", "nottingham", "Poland", "the Welcome Stranger", "taggart", "April", "Chechnya", "Spot", "the A- Team", "football", "801,200", "Sir Ronald Ross", "Emperor Shenzong of Song", "bioelectromagnetics", "Foxborough", "Speedway World Championship", "a city of romance, of incredible architecture and history.", "36", "Michelle Obama", "Copenhagen", "the Communist Manifesto", "\"Sara Smile\"", "Floxin"], "metric_results": {"EM": 0.5625, "QA-F1": 0.618465909090909}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, true, true, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6892", "mrqa_triviaqa-validation-1730", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-6308", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-15651"], "SR": 0.5625, "CSR": 0.5218098958333333, "EFR": 1.0, "Overall": 0.6985807291666666}, {"timecode": 48, "before_eval_results": {"predictions": ["East Lothian", "Caesars Entertainment Corporation", "Supergirl", "\u00c6thelred the Unready", "shaun the sheep", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air", "Mineola, New York", "dziga Vertov", "Strange Interlude", "Julia Compton Moore", "roger Shannon", "1986", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Lou Diamond Phillips", "Babylon", "Ford Falcon", "Southern State", "Roman \u00e0 clef", "1827", "Kim Bauer", "United States Food and Drug Administration", "Edward James Olmos", "Suffolk", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard", "the 45th Infantry Division", "2009", "5", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "August 14, 1848", "Texas Technological College", "John McClane", "Larry Gatlin Brothers", "the 924", "Edward Michael \" Mike\"/\"Spanky\" Fincke", "North Carolina", "Selinsgrove", "the Analytical Engine", "2001", "a cake", "Jineet Rath", "Space Shuttle Challenger", "basil", "clio Awards", "\"The Rosie Show,\"", "California-based Current TV", "well over 1,000 pounds", "Brutus", "desert", "the Library of Congress", "the thylakoid membranes"], "metric_results": {"EM": 0.625, "QA-F1": 0.685479797979798}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, true], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-4008", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-775", "mrqa_hotpotqa-validation-3513", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-115", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-2595", "mrqa_searchqa-validation-1028"], "SR": 0.625, "CSR": 0.5239158163265306, "EFR": 0.9583333333333334, "Overall": 0.6906685799319728}, {"timecode": 49, "UKR": 0.662109375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2339", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5755", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-2999", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-60", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3155", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5788", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6000", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-888", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-92"], "OKR": 0.78515625, "KG": 0.4578125, "before_eval_results": {"predictions": ["baseball, oin\u0103, ( Italy) and pes\u00e4pallo", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John W. Henry", "Michael J. Fox", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Love Hina", "eastern", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five aerial victories", "Alain Robbe-Grillet", "the Seasiders", "research-based study of music", "TVB", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "the EN World web site that has hosted the awards since their inception in 2001", "Charles Russell", "kj\u00f8benhavns Boldklub", "Robert Jenrick", "Golden Globe Award", "Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "The fennec fox or fennc (\"Vulpes zerda\")", "Netherlands", "Terry Malloy", "Golden Calf for Best Actor in 2013", "tomorrow May Never Come", "Thorgan Ganael Francis Hazard", "Cee - Lo", "Everywhere", "the Department of Science and Technology of the Government of India", "Honda", "J. M. W. Turner", "the Republic of Upper Volta", "56", "Nkepile Mabuse", "Eintracht Frankfurt", "the fort at the Derna harbor", "Hephaestus", "Amherst College", "two courses"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6418078092250886}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, true, true, false, false, false, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.25, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.7272727272727273, 0.0, 1.0, 0.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-1198", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2701", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-928", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.515625, "CSR": 0.5237499999999999, "EFR": 1.0, "Overall": 0.6857656249999999}]}