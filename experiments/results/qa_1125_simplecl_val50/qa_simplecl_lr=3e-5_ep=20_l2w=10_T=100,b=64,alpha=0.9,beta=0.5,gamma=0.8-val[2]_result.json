{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4040, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange Counties", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange County", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "the Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis on 2nd December 1936", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.859375, "QA-F1": 0.8760416666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.859375, "CSR": 0.8671875, "EFR": 1.0, "Overall": 0.93359375}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "the evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "demographics and economic ties", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "warmest regions", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "the city's beaches are artificial and... Three major Spanish cities that are located on the Mediterranean coast are... on both the Atlantic Ocean and the Mediterranean Sea", "guardian", "guardian", "guardian", "1787 he represented his state at the Constitutional Convention, and...   Roger Sherman - Constitution Day  Founding Father Roger Sherman from the State of Connecticut", "guardian", "guardian", "time goes", "guardian", "guardian", "abolitionists", "5562 feet"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6811350108225108}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0909090909090909, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.640625, "CSR": 0.7916666666666666, "EFR": 0.9565217391304348, "Overall": 0.8740942028985508}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double membrane", "August 1967", "German", "27-30%", "four", "50 fund", "Arizona Cardinals", "Peanuts", "comb rows", "calcitriol", "Warsaw", "time", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail", "Orestes", "the Galapagos Islands", "gerrymandering", "the process by which water changes from a liquid to a gas", "Airlines", "a bag of 1,000 grains of rice", "a major raw", "the Mycenaean kingdoms", "a biological process that displays an endogenous, entrainable", "a friendly little guy like Casper", "a fourth brother, Private James Ryan", "John Dillinger", "fibula", "Il Trovatore", "Amundsen", "the Royal Border Bridge"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7288961038961039}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.703125, "CSR": 0.76953125, "EFR": 0.9473684210526315, "Overall": 0.8584498355263157}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25 percent", "May 2013", "K-9 and Company", "capturing prey", "rubisco", "pasture for cattle", "Ford", "1,300,000", "it has trouble distinguishing between carbon dioxide and oxygen, so at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "two tumen (20,000 soldiers)", "eight", "A computational problem", "WZM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "states today are viewed as empires due to their political and economic authority over other nations.", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "Michael Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "the war years", "semiconductors", "Tim Clark, Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "pictures", "the foyer of the BBC building", "Buddhism", "Manchester City", "Noriko Savoie", "three", "change course", "Tsvangirai", "cowardly lion", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a 100% pure and natural sweetener", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7294768191367456}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7058823529411764, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.6666666666666666, 0.2666666666666667, 1.0, 0.0, 0.2, 0.0, 1.0, 0.25, 0.0, 0.7272727272727273, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-8874", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-6092", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-862", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.640625, "CSR": 0.74375, "EFR": 1.0, "Overall": 0.871875}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven classes", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium", "QuickBooks", "surface condensers", "clinical pharmacists", "a seal", "Philip Howard", "King Ethelred II of England", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "British", "10\u20137", "Polish Academy of Sciences", "spherical and highly refractive bodies", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Goa", "D, E or F.", "the Louvre", "Leo Frank", "as he tried to throw a petrol bomb", "Graziano Transmissioni", "opposition parties", "1.2 million", "Newcastle retained fourth place with a 3-1 victory over Blackburn, who remained in the relegation zone.", "the release of the four men", "putting a personal and human face on the issue... there's nothing more crucial,\"", "Ed McMahon", "the Magna Carta is expected to fetch at least $20 million to $30 million, Redden said.", "Hillary Clinton", "at the University of Alabama in Huntsville", "Obama", "paper ballots", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "promotes fuel economy and safety while boosted the economy.", "resting heart rate over 100 beats per minute", "heavy breeds", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6578989718356978}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.4, 0.6666666666666666, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-7260", "mrqa_squad-validation-8715", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-8826", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.5625, "CSR": 0.7135416666666667, "EFR": 0.9285714285714286, "Overall": 0.8210565476190477}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "unfairly biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational resource", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "straight line", "In the autumn of 1991, talks were held for the broadcast rights for Premier League for a five-year period, from the 1992 season.", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1", "nerves", "1700", "Christo", "polysaccharides (poly = many)", "Howard Dean III", "cardiovascular system", "The Troggs", "six literal ordinary days", "Gustav Malr.", "Diana the Princess", "slave-trade", "vena cava", "bivalve Scallop", "bull's-eye", "Tartarus", "\"cyc\"", "New York", "the Persian Achaemenid Empire", "LAP", "Count Ferdinand von Zeppelin", "net worth", "Duke of Clarence", "Datson, H., Birch,... plus assorted small iron and slag particles.", "\"Popeye\" Doyle", "Judas", "Hurley", "comic book", "Love Is All Around", "Los Angeles Dance Theater", "United States", "the FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6199092574092575}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-2921", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-14782", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.53125, "CSR": 0.6875, "EFR": 1.0, "Overall": 0.84375}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "reduce growth", "Torchwood", "9.1 million", "little support", "individual countries", "cattle and citrus", "Western Xia", "semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Eisenhower Freeway", "Thanksgiving", "86.66%", "Two thirds", "the Privy Council", "well into the nineteenth century", "Capability deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rodeo", "hog", "John Sexton", "Keith G", "a serious effort like the Japanese Tea", "chazz Michael Michaels", "Annapolis", "Spring", "klammeraffe", "bark beetles", "Allah", "bones", "Boa Constrictor Python", "Bible: In the Beginning", "Inman", "Faith Hill", "Matt Damon", "U.S.", "V", "Eon", "Yardbird", "Sweden", "Thailand", "hydrogen", "destroyed", "Perfume", "20%", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5859375}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, true, false, true, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7626", "mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-7473", "mrqa_squad-validation-8189", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-8971", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_triviaqa-validation-3911", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.53125, "CSR": 0.66796875, "EFR": 0.9666666666666667, "Overall": 0.8173177083333334}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes or an antibody-based humoral response", "producers of the show", "BSkyB", "Kawann Short", "Daidu in the north", "silent film", "22 miles", "the park", "1965", "tidal currents", "Concentrated O2 will allow combustion to proceed rapidly and energetically", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "Red Army", "middle of the 20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "six series of theses", "Body of Proof", "seven-eighths", "Franois Girardon", "the Anti-Atlas", "Madrid", "the Danube at Passau", "Yahweh", "leather", "George Pullman", "plums", "Messiah", "Sappho", "property", "frangipanis", "the dividend", "Hypnos", "Texas", "IHOP", "a black breed", "Bill of Rights", "SAT", "Brazil", "Walden", "Los Angeles", "Harry Whittington", "a solar day", "William Donald Scherzer", "Jack B Yeats", "the CIA", "d'Artagnan", "painted Caves", "1985", "apples, blueberries, bananas", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.5, "QA-F1": 0.5452938988095237}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6559", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-13837", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-14640", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.5, "CSR": 0.6493055555555556, "EFR": 0.96875, "Overall": 0.8090277777777778}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61 per cent", "During the Second World War", "integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "exploration", "prep schools", "soft power", "strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Khrushchev", "Hera", "nymphs", "Reginald Dwight", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Wash.", "Carmen", "Giglio Island", "3", "C14", "972", "buffalo", "Ann Widdecombe", "isosceles", "the Old Kent Road", "Tuesday", "(CuSO4)", "Ab Fab", "Massachusetts", "Barrow", "California", "the Susquehanna River", "Kajagoogoo", "a reddish-purple berry", "Singapore", "Pangaroos", "Davos", "eight", "an an amalgamation of several Hoffa associates over the years", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "What Price", "Bea Benaderet"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6187499999999999}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, false, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-9870", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.546875, "CSR": 0.6390625, "EFR": 1.0, "Overall": 0.81953125}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the Inner Mongolia region", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent\u2013Terneuzen Canal", "mulberry", "feces", "stone", "Ken Russell", "Dan Dare", "mucia", "the Smiths", "Mike Tyson", "barbarian", "Pesach", "Brian Deane", "kaleidoscope", "Uranus", "Apollon", "George Carlin", "Ukraine", "Sydney", "Los Angeles", "Underground Railroad", "puca", "\"beyond violet\"", "passion fruit", "Portugal", "football", "Somya Abrol", "63 to 144 inches", "Titanic", "William Tell", "Christian Dior", "a blue jack-in-the-box-like creature", "Mendip", "Wichita", "eukharistos", "New Croton Reservoir", "andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "Ponty Mython", "barbarian"], "metric_results": {"EM": 0.625, "QA-F1": 0.6501893939393939}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-4371", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-4926", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-8589"], "SR": 0.625, "CSR": 0.6377840909090908, "EFR": 0.9583333333333334, "Overall": 0.7980587121212122}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network headquartered in San Jose, CA that utilized virtual call packet switched technology", "public service", "Guy de Lusignan", "tiger team", "B cells", "The European Commission", "completed (or local) fields", "fundamental error", "Mongol and Turkic tribes", "puck", "five", "Whist", "Nile River", "Toscana", "achromatopsia", "blood", "Pluto", "iron", "copper", "The Hague", "Vancouver Island", "Ironside", "George Smiley", "gorky", "trout", "Beyonce", "Wordsworth", "Man V Food", "Queen Elizabeth II", "J. Dodsley", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "vitamin A and K", "hudd", "sea of Azov", "Shrek", "Oslo", "horses", "rhododendron", "\"All That Jazz\"", "morocco", "Changjiang", "julie de Becque", "Boat lifts", "coonhound", "17 October 2006", "beer", "Kingman Regional Medical Center", "Saturday's Hungarian Grand Prix", "Capuchin Church of the Immaculate Conception, Rome, Italy", "Edgar Allan Poe", "puck"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6175744047619047}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-8252", "mrqa_squad-validation-4870", "mrqa_squad-validation-6530", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.5625, "CSR": 0.6315104166666667, "EFR": 1.0, "Overall": 0.8157552083333334}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "the International Association of Methodist-related Schools, Colleges, and Universities", "one", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "Daniel Boone", "The Handmaid's Tale", "pygmy chimpanzee", "The Fault in Our Stars", "CR-X", "puzzle", "1961", "400 MW", "tag team", "Galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen", "the Continental Army", "Jack Kilby", "Ryan Babel", "Umar S. Israilov", "July 16, 1971", "1933", "What's Up", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point du Sable", "England", "Paul W. S. Anderson", "a Christian church", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "drug trafficking is a transnational threat, and therefore national initiatives have their limitations", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "dr. Dre", "a spider", "in pre-Columbian times, the American Bison, is difficult to domesticate and was never domesticated by Native Americans"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6726190476190477}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-3896", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.65625, "CSR": 0.6334134615384616, "EFR": 1.0, "Overall": 0.8167067307692308}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "impossible", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold", "\u00c9mile Girardeau", "Brownlee", "partial funding", "relatively low in Ireland compared to the rest of the world", "NCAA Division II", "Adrian Lyne", "Mikhail Aleksandrovich", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Tony Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "Liquidambar styraciflua", "Gilbert du Motier", "Gujarat", "three", "Winter Haven", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "a few", "US Naval Submarine Base New London", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Larnelle Harris", "the Secretary of State and ambassadors are appointed by the President", "2011", "1982", "rod", "Chris Robinson", "gossip Girl", "fluid dynamics", "out", "NUT", "Richie Unterberger"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6745248538011696}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9473684210526316, 0.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-7036", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.578125, "CSR": 0.6294642857142857, "EFR": 0.9629629629629629, "Overall": 0.7962136243386243}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "1970", "religious freedom", "Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30\u201360% of Europe's total population", "the kilogram-force (kgf)", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "time and storage", "Vistula River", "100 to 150", "Apple's new iOS5 operating system,", "at the school.", "March 8", "Democrats and Republicans", "the Catholic League", "well over 1,000 pounds", "\"He is obviously very relieved and grateful that the pardon was granted,\" Dean said.", "Friday", "Majid Movahedi", "different women coping with breast cancer in five vignettes.", "\"black rain\" of drilling fluid and a roar of escaping gas erupted from the doomed Deepwater Horizon shortly before the explosion that sank the oil rig,", "she always seemed to have a smile on her face when her kids were around.", "a quarter of bread", "Lance Cpl. Maria Lauterbach", "South Korea's", "London", "more than 4,000", "Val d'Isere, France earlier this year.", "the test results by the medical examiner's office, Garavaglia said.", "two soldiers and two civilians", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J. Crew", "Japanese", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "British author J.G. Ballard, whose boyhood experience in a World War II internment camp became the novel and film \"Empire of the Sun,\"", "suppress the memories and to live as normal a life as possible", "about 4 meters (13 feet) high", "the Irish capital", "Republican", "Spanishfork", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "the foot corresponding to which hand you intend to throw with perpendicular to the line", "Two Pi\u00f1a Coladas", "England", "Yemen", "Domenikos Theotokopoulos", "a nice and jumbly giant", "mercury"], "metric_results": {"EM": 0.375, "QA-F1": 0.4856383701594299}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8571428571428571, 0.27272727272727276, 1.0, 1.0, 0.8750000000000001, 0.11999999999999998, 0.0, 0.5, 0.0, 0.0, 0.0, 0.5, 0.0, 0.4, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.2608695652173913, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-1672", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.375, "CSR": 0.6125, "EFR": 0.925, "Overall": 0.76875}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "prime", "50 fund", "the Camisards", "over $40 million", "GTE.", "1,100", "spinat", "Oligocene", "Wanda Eileen Barzee", "Charles Darwin", "Conway, Arkansas,", "March 24,", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"She had a smile on her face, like she always does when she comes in here,\"", "56,", "the National Football League", "\"The Lost Symbol,\"", "Heshmat Tehran Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Atlanta", "resources", "highest ranking former member of Saddam Hussein's regime still at large", "two Emmys", "\"scared I won't be able to go home,\"", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "a bond hearing Friday, a federal magistrate said Monday.", "South African President Thabo Mbeki, as a representative of the Southern African Development Community, and Jean Ping, chairman of the African Union Commission.", "a hospital in Amstetten,", "African National Congress Deputy President Kgalema Motlanthe", "lost his job as the supermarket chain he worked for cut staff.", "resigned as leader of the ruling political party", "Ralph Cifaretto", "sharia law", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "\"homebrew\" settings or worlds.", "Beno\u00eet Jacquot", "topaz", "Thomas Jefferson", "The Left Book Club", "holography"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5842009140453792}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.4, 0.6428571428571429, 0.28571428571428575, 1.0, 1.0, 0.42857142857142855, 0.0, 0.10526315789473685, 0.5, 1.0, 1.0, 0.25, 1.0, 0.0, 0.08695652173913045, 0.5, 0.4444444444444445, 0.0, 0.10526315789473685, 0.0, 0.08, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.46875, "CSR": 0.603515625, "EFR": 0.9705882352941176, "Overall": 0.7870519301470589}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand people", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Kris Allen, the guy next door", "Brian Smith", "\"Hillbilly Handfishin'\"", "President Robert Mugabe", "voluntary voluntary manslaughter", "foreplay, sexual conquests and how he picks up women, all taboo subjects in deeply conservative Saudi Arabia.", "his injuries,", "30 years ago.", "murder", "next year", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire, does that mean it would use it against Israel?", "\"whole ethos is one of violence\" and that it had \"made a brutal choice to step up attacks against innocent civilians", "Matthew Fisher", "cancer,", "Courtney Love,", "to step up.", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "your environmental efforts", "two women", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Monday,", "women.", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs", "Russia and some European countries have expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "UC Irvine Medical Center,", "World War I", "1950s,", "heavy fighting between U.S.-backed Iraqi troops and al-Sadr's Mehdi Army militia.", "Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "More than 120 groups across six continents are holding vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow, a town of about 238 people,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "French Revolutionary ideals of liberty, equality, and fraternity", "2001", "vingtaines", "Joe Louis", "George Blake", "Bogota"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6291948027817593}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4000000000000001, 1.0, 1.0, 0.0, 0.8, 0.6923076923076924, 0.22222222222222224, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.16, 0.4615384615384615, 1.0, 1.0, 1.0, 0.8571428571428571, 0.4444444444444445, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.17391304347826086, 0.06666666666666667, 0.2857142857142857, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-2041", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3455", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_triviaqa-validation-6739"], "SR": 0.484375, "CSR": 0.5965073529411764, "EFR": 0.9696969696969697, "Overall": 0.7831021613190731}, {"timecode": 17, "before_eval_results": {"predictions": ["relatively equal distributions of wealth", "a pharmacy practice residency", "questions and answers", "(sed vigilat)", "Captain Francis Fowke, Royal Engineers,", "12 January", "roughly 60,000 European settlers,", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich", "\"Mad Men\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's restive provinces", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends", "\"executioners\"", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Matthew Fisher,", "Peppermint oil, soluble fiber, and antispasmodic drugs can indeed help people with irritable bowel syndrome,", "in the north and west of the country,", "forcibly injecting them with psychotropic drugs", "introduce legislation Thursday to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "kite boards", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22-year-old", "UNHCR", "how health care can affect families.\"", "Appathurai", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps", "Lashkar-e-Tayyiba (LeT)", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "slashed open his left eyebrows.", "congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger", "Arlene Phillips", "23 July 1989", "Uchinaanchu", "surrealism", "C. S. Lewis", "square root of 81", "rice wine", "Halifax"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6261381796308267}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3529411764705882, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 1.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.5625, "CSR": 0.5946180555555556, "EFR": 1.0, "Overall": 0.7973090277777778}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "Fort Edward and Fort William Henry", "linear", "Advanced Steam", "Defensive ends", "the dot", "chastity", "The European Court of Justice", "bronze medal in the women's figure skating final,", "U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "UK", "\" Teen Patti\"", "Argentina", "Congress", "28", "Frank Ricci,", "\"Kurdistan Gas City.\"", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "\"I get positive feedback because everybody around me likes Obama,\"", "the FDA is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.\"", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Bahrain", "Al Shabaab may have been plotting an attack timed to coincide with the event,", "the mammoth's skull,", "can play an important role in Afghanistan as a reliable NATO ally.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "because they were being discriminated against on the basis of nationality.", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally,", "Kathrin Hoelzl", "\"They were nothing,\"", "Amnesty International.", "President Obama's race", "Los Ticos", "Drottningtorget", "AbdulMutallab, accused of trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "outside the Iranian consulate in Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger", "\"Sunny Afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.546875, "QA-F1": 0.643806869978745}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.125, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.9714285714285714, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0909090909090909, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.21428571428571427, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611"], "SR": 0.546875, "CSR": 0.5921052631578947, "EFR": 0.9655172413793104, "Overall": 0.7788112522686026}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "would be killed through overwork", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah.", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid", "most of those who managed to survive the incident hid in a boiler room and storage closets during the", "that the Bainbridge would be getting backup shortly.\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book.", "he was diagnosed with skin cancer.", "to stand down.", "Ashley \"A.J.\" Jewell", "at least 17", "Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "rural California,", "knocking the World Cup off the front pages for the first time in days.", "Old Trafford", "Preah Vihear temple", "steam-driven, paddlewheeled overnight passenger boat.", "the Haeftling range.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "CNN's \"Larry King Live,\" ABC's \"Good Morning America\" and \"The View.\"", "Flint, Michigan", "protective shoes", "public-sector labor", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "glass shards", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International", "\"Grandmasters\"", "Suffragette", "Canterbury", "Tunisia", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6828011626531363}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.27272727272727276, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.8, 1.0, 1.0, 0.28571428571428575, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.4, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_searchqa-validation-383"], "SR": 0.53125, "CSR": 0.5890625, "EFR": 0.8666666666666667, "Overall": 0.7278645833333334}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Fort Caroline", "the Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000 write / erase cycles", "the United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50 feet", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956 ) and four since the advent of the Super Bowl ( Super Bowls XXI ( 1986 ), XXV ( 1990 ), XLII ( 2007 ), and XLVI ( 2011 )", "The first message was sent over the ARPANET in 1969", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Gavrilo Princip", "a central place in Christian eschatology", "October 1941", "either peace between two entities ( especially between man and God or between two countries )", "b\u0101gh, baug, bageecha or bagicha", "Cee - Lo", "After Shawn's kidnapping", "lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour", "three times", "November 25, 2002", "October 29, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two degrees of freedom", "Alberto Salazar", "a collection of live animals", "American", "Hoosick, Rensselaer County", "CEO of an engineering and construction company with a vast personal fortune.", "more than 1.2 million people.", "the third pig", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "approximately 600 square miles of south-central Washington,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6407070665794923}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.08695652173913045, 0.2222222222222222, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8421052631578948, 0.0, 0.25, 1.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.9333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.8, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3167", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.5, "CSR": 0.5848214285714286, "EFR": 0.9375, "Overall": 0.7611607142857143}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "the Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "the One Ring", "the Washington metropolitan area", "the molar concentration", "the breast or lower chest of beef or veal", "Samaria", "Tagalog or English", "around 1600 BC", "By mid-1988, all 50 states and the District of Columbia had raised their purchase ages to 21", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "Janie Crawford", "by the early 3rd century", "in positions Arg15 - Ile16", "Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "1957", "1776", "1963", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "Scarlett Johansson", "embryo", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Swedish figure skater Gillis Grafstr\u00f6m", "Sophocles", "Tim Allen", "thick skin", "a cake", "India", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "the Major General of the Navy", "Clayton Mark's", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "the actual pen", "Ellen DeGeneres", "12 April 1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5332388965201464}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.2222222222222222, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.16666666666666666, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.7777777777777778, 1.0, 0.0, 0.0, 0.6666666666666666, 0.08333333333333333, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_searchqa-validation-843", "mrqa_hotpotqa-validation-427", "mrqa_hotpotqa-validation-3984"], "SR": 0.390625, "CSR": 0.5759943181818181, "EFR": 0.9487179487179487, "Overall": 0.7623561334498834}, {"timecode": 22, "before_eval_results": {"predictions": ["the mouth of the Monongahela River", "Stanford University", "linebacker", "the Mongol and Turkic tribes of the steppes", "between 1859 and 1865", "Danny Lane", "in the New Testament", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "the Chainsmoker", "an annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "the namesake town of Manchester - by - the - Sea, Massachusetts", "two", "Thomas Jefferson", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "on a sound stage in front of a live audience in Burbank, California", "Ricardo Chavira", "2009", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas", "Jodie Foster", "February 27, 2007", "Neil Patrick Harris", "8ft", "Owen Vaccaro", "bacteria", "on the lateral side of the tibia", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff / \ufefe 90 \u00b0N - 0 \u00b0 E", "London", "into the bloodstream or surrounding tissue", "in 2005, against the Chicago White Sox", "March 1", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "if he was not named Romeo he would still be handsome and be Juliet's love", "Hotel California", "Queen Elizabeth II", "insect\u00ef\u00bf\u00bd", "vocalist Eddie Vedder", "2005", "Dan Tyminski", "the oldest daughter of an incestuous relationship", "the southern port city of Karachi", "at least nine", "Bashar al-Assad", "the Bible", "biathlon"], "metric_results": {"EM": 0.515625, "QA-F1": 0.61918026996152}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.25, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.8, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8148148148148148, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8226", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-3470", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-4138"], "SR": 0.515625, "CSR": 0.5733695652173914, "EFR": 0.9354838709677419, "Overall": 0.7544267180925666}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "by the early - to - mid fourth century", "2002", "The Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2", "the Constitution of India", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "closing of the atrioventricular valves and semilunar valves", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Johnny Logan", "1978", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "February 10, 2017", "Alex Skuby", "Jamestown settlement in the Colony of Virginia", "March 2016", "from 1922 to 1991", "Terry O'Neill", "Bacon", "an explosion", "Heather Stebbins", "Glen W. Dickson", "two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "The Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield as Al Schmid", "1871", "eye", "The History Boys", "aprimitive type of fish", "White Knights of the Ku Klux Klan", "five", "Mot\u00f6rhead", "Kingman Regional Medical Center", "Phillip A. Myers", "Osama bin Laden", "Antarctica", "axon", "gourmet Mushrooms"], "metric_results": {"EM": 0.5, "QA-F1": 0.6928198537573538}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.4615384615384615, 1.0, 0.5714285714285715, 0.9333333333333333, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.3333333333333333, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.2222222222222222, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.4, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.5, "CSR": 0.5703125, "EFR": 0.96875, "Overall": 0.76953125}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "James Francis Thorpe", "2000", "the onset and progression of Alzheimer's disease", "Disco", "\"Regno di Dalmazia\"", "the Indian School of Business", "New York", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin Button\"", "A55", "Corendon Dutch Airlines", "86", "Capella University", "Eilean Donan", "Fatih Ozmen", "U.S.", "Pacific Place", "served as the Attorney General of Michigan from 1999 to 2003", "Flamingo Las Vegas", "City of Westminster, London", "2016", "Wildhorn", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "the Guadalcanal Campaign", "Bishop's Stortford", "The Hungry Hustlerz: Starvation Is Motivation", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "the Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland", "Yoruba", "\"Lucky\"", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "The Tenth Planet ( 1966 )", "a handsome father of three", "Jehan Mubarak", "Medellin", "Joe", "alternative-energy vehicles", "2004", "genes", "olive", "Tjejmilen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6162822420634921}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 0.4, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-4328", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_triviaqa-validation-2659", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-5511"], "SR": 0.515625, "CSR": 0.568125, "EFR": 0.967741935483871, "Overall": 0.7679334677419355}, {"timecode": 25, "UKR": 0.73828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-2250", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2289", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2988", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-3901", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-4461", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-5382", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10227", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-1123", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2380", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-4562", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5539", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-6851", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-7609", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8023", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-9001", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9505", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-1258", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-1733", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-1800", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-2583", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2727", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2944", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3206", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3410", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3654", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-3745", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-39", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4046", "mrqa_newsqa-validation-4095", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-65", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-660", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-94", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-11385", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-12624", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-1335", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-14663", "mrqa_searchqa-validation-14883", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-16181", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3783", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-4857", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-7702", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-9090", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-9705", "mrqa_searchqa-validation-9756", "mrqa_squad-validation-10045", "mrqa_squad-validation-10069", "mrqa_squad-validation-10074", "mrqa_squad-validation-10086", "mrqa_squad-validation-10216", "mrqa_squad-validation-10228", "mrqa_squad-validation-10254", "mrqa_squad-validation-10310", "mrqa_squad-validation-10324", "mrqa_squad-validation-10338", "mrqa_squad-validation-10353", "mrqa_squad-validation-1036", "mrqa_squad-validation-10378", "mrqa_squad-validation-10477", "mrqa_squad-validation-1090", "mrqa_squad-validation-1320", "mrqa_squad-validation-1450", "mrqa_squad-validation-1603", "mrqa_squad-validation-1636", "mrqa_squad-validation-1672", "mrqa_squad-validation-1694", "mrqa_squad-validation-178", "mrqa_squad-validation-1802", "mrqa_squad-validation-1852", "mrqa_squad-validation-1855", "mrqa_squad-validation-1857", "mrqa_squad-validation-1938", "mrqa_squad-validation-1967", "mrqa_squad-validation-2040", "mrqa_squad-validation-2126", "mrqa_squad-validation-2153", "mrqa_squad-validation-2216", "mrqa_squad-validation-2289", "mrqa_squad-validation-2384", "mrqa_squad-validation-2400", "mrqa_squad-validation-2436", "mrqa_squad-validation-2460", "mrqa_squad-validation-2477", "mrqa_squad-validation-255", "mrqa_squad-validation-2577", "mrqa_squad-validation-2602", "mrqa_squad-validation-2619", "mrqa_squad-validation-268", "mrqa_squad-validation-2693", "mrqa_squad-validation-2773", "mrqa_squad-validation-2782", "mrqa_squad-validation-2798", "mrqa_squad-validation-282", "mrqa_squad-validation-2824", "mrqa_squad-validation-285", "mrqa_squad-validation-2929", "mrqa_squad-validation-3019", "mrqa_squad-validation-3041", "mrqa_squad-validation-3135", "mrqa_squad-validation-3185", "mrqa_squad-validation-320", "mrqa_squad-validation-3337", "mrqa_squad-validation-3476", "mrqa_squad-validation-353", "mrqa_squad-validation-3589", "mrqa_squad-validation-3709", "mrqa_squad-validation-383", "mrqa_squad-validation-3931", "mrqa_squad-validation-3948", "mrqa_squad-validation-3955", "mrqa_squad-validation-397", "mrqa_squad-validation-3993", "mrqa_squad-validation-4005", "mrqa_squad-validation-4079", "mrqa_squad-validation-4140", "mrqa_squad-validation-415", "mrqa_squad-validation-4181", "mrqa_squad-validation-427", "mrqa_squad-validation-4291", "mrqa_squad-validation-4305", "mrqa_squad-validation-4333", "mrqa_squad-validation-4338", "mrqa_squad-validation-4472", "mrqa_squad-validation-462", "mrqa_squad-validation-4686", "mrqa_squad-validation-4704", "mrqa_squad-validation-4835", "mrqa_squad-validation-4856", "mrqa_squad-validation-4870", "mrqa_squad-validation-5054", "mrqa_squad-validation-5088", "mrqa_squad-validation-5096", "mrqa_squad-validation-5154", "mrqa_squad-validation-5176", "mrqa_squad-validation-5238", "mrqa_squad-validation-5302", "mrqa_squad-validation-5326", "mrqa_squad-validation-5376", "mrqa_squad-validation-550", "mrqa_squad-validation-5537", "mrqa_squad-validation-5541", "mrqa_squad-validation-5588", "mrqa_squad-validation-5616", "mrqa_squad-validation-5672", "mrqa_squad-validation-5703", "mrqa_squad-validation-5767", "mrqa_squad-validation-5777", "mrqa_squad-validation-5913", "mrqa_squad-validation-60", "mrqa_squad-validation-60", "mrqa_squad-validation-607", "mrqa_squad-validation-6099", "mrqa_squad-validation-6126", "mrqa_squad-validation-6143", "mrqa_squad-validation-6178", "mrqa_squad-validation-6220", "mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6362", "mrqa_squad-validation-6395", "mrqa_squad-validation-6414", "mrqa_squad-validation-6564", "mrqa_squad-validation-660", "mrqa_squad-validation-6641", "mrqa_squad-validation-6737", "mrqa_squad-validation-6754", "mrqa_squad-validation-6782", "mrqa_squad-validation-68", "mrqa_squad-validation-6817", "mrqa_squad-validation-6915", "mrqa_squad-validation-696", "mrqa_squad-validation-7018", "mrqa_squad-validation-703", "mrqa_squad-validation-7069", "mrqa_squad-validation-707", "mrqa_squad-validation-7150", "mrqa_squad-validation-7161", "mrqa_squad-validation-7180", "mrqa_squad-validation-7198", "mrqa_squad-validation-7260", "mrqa_squad-validation-7399", "mrqa_squad-validation-754", "mrqa_squad-validation-7552", "mrqa_squad-validation-7597", "mrqa_squad-validation-7640", "mrqa_squad-validation-765", "mrqa_squad-validation-7678", "mrqa_squad-validation-7770", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-7856", "mrqa_squad-validation-7882", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-804", "mrqa_squad-validation-8056", "mrqa_squad-validation-8104", "mrqa_squad-validation-8115", "mrqa_squad-validation-8189", "mrqa_squad-validation-8226", "mrqa_squad-validation-8226", "mrqa_squad-validation-8285", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8527", "mrqa_squad-validation-8629", "mrqa_squad-validation-8735", "mrqa_squad-validation-8760", "mrqa_squad-validation-8765", "mrqa_squad-validation-8832", "mrqa_squad-validation-884", "mrqa_squad-validation-8867", "mrqa_squad-validation-890", "mrqa_squad-validation-8957", "mrqa_squad-validation-898", "mrqa_squad-validation-9031", "mrqa_squad-validation-9066", "mrqa_squad-validation-9135", "mrqa_squad-validation-9186", "mrqa_squad-validation-9227", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9391", "mrqa_squad-validation-9392", "mrqa_squad-validation-9465", "mrqa_squad-validation-9504", "mrqa_squad-validation-9541", "mrqa_squad-validation-9552", "mrqa_squad-validation-9652", "mrqa_squad-validation-9658", "mrqa_squad-validation-9771", "mrqa_squad-validation-979", "mrqa_squad-validation-9818", "mrqa_squad-validation-987", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2626", "mrqa_triviaqa-validation-2685", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-3051", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-4107", "mrqa_triviaqa-validation-4171", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-4440", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-5568", "mrqa_triviaqa-validation-5671", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6290", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-6909", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-71", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-7548", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-776"], "OKR": 0.84375, "KG": 0.45625, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater", "Anna Clyne", "Terence Winter", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "American", "Acid house", "at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles of Timmy Sanders and Jack", "PBS stations nationwide,", "second largest", "Citric acid", "in 1911", "Tony Bennett", "\"The Five\"", "Walt Disney Feature Animation", "UEFA Super Cup", "torpedoes", "1972", "Geographical Indication tag", "Buck Owens and the Buckaroos", "Cleveland Celtics", "World Championship Wrestling", "2003", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Cuauhtemoc and Tenochtitlan", "Tax Reform Act of 1986", "Henry Louis", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram", "chimedus", "to earn the nickname Super Eli", "green"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6952380952380952}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.609375, "CSR": 0.5697115384615384, "EFR": 0.88, "Overall": 0.6975985576923076}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu tribe", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X.", "Harold Holt", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Anthony Mackie", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool and the England national team", "port city of Aden", "British", "second cousin", "1985", "Archie Andrews", "before", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Travolta", "Hall & Oates", "Mazatl\u00e1n", "racehorse breeder and owner", "Summerlin", "1919", "Kevin Spacey", "\"Love Streams\"", "stunt jumping", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "Old Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "CMYKOG", "1600 BC", "Obi - Wan Kenobi", "1963", "a peplos", "Herald of Free Enterprise", "Lyrical Ballads", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan", "gumi", "potp0urri"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6460078983516484}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, false, false, false, true, false, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.923076923076923, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-3515", "mrqa_searchqa-validation-13669"], "SR": 0.546875, "CSR": 0.5688657407407407, "EFR": 1.0, "Overall": 0.7214293981481481}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "\"Dumb and Dumber\"", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "British Overseas Territories", "most awarded female act of all-time", "Dunlop Tyres", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "due to a leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Primettes", "Cersei Westerister", "Kalokuokamaile", "Raden Panji", "Don Bluth", "1970", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "Jim Diamond", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914 machine gun", "James Brolin", "Prussian army general", "January 2004", "co-founder and lead guitarist", "ten", "seven", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "glycerol", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "salt", "nasal septum", "wavelengths"], "metric_results": {"EM": 0.59375, "QA-F1": 0.686812082289056}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.59375, "CSR": 0.5697544642857143, "EFR": 1.0, "Overall": 0.7216071428571429}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "Hanover", "Henry Mancini", "a.", "Gordon Ramsay", "Gorbachev", "a comic", "a rose", "Charlton Heston", "Anna (Julia Roberts)", "a scythe", "orchid", "Paddy Doherty", "smallpox", "the pyramids", "Libya", "Chubby Checker", "a bia 515", "Khomeini\u2019s Iran", "Dora Spenlow", "William Hickey", "a father figure", "April", "Eric Morley", "hypertension", "the Garrick Club", "Belle", "David Beckham", "Manhattan", "Tom Stoppard", "The Greatest", "a singer and performer", "the Tyne", "a chilies", "tenor saxophonist", "Seattle", "The Cross Foxes Inn", "Cardiff", "Baton Rouge", "stromberg", "Tahrir Square", "Romanian", "bathtub curve", "Joseph V. Amodio", "Lord Snooty", "Alexander Borodin", "Jesse James", "a foraging mammal", "Greek", "passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "June 4, 1931", "North America", "Florida's Everglades", "Garth Brooks", "consistent and accessible", "driving", "Glengarry Glen Ross", "Sebastian Stark"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5995659722222222}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, false, false, true, false, true, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, false, true, false], "QA-F1": [0.0, 0.5, 0.39999999999999997, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-1045", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-15919"], "SR": 0.515625, "CSR": 0.5678879310344828, "EFR": 1.0, "Overall": 0.7212338362068965}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Tim Duncan", "James W. Marshall", "in florida it is illegal to sell alcohol before 1 pm on any sunday", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw", "between 8.7 % and 9.1 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "the status line", "the retina", "jimmy adherson", "Triple Alliance of Germany", "Andrew Lloyd Webber", "1955", "Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar", "the original Star Trek television series", "in 1936, when she was 10 years old", "Meg Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "Anna Faris", "early to mid-2000s", "tango in the Night", "technological advances in printing", "Cairo, Illinois", "in the 1970s and'80s", "in the Hebrew Bible, in the books of Exodus and Deuteronomy", "Wyatt", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "The Miracles", "Eukarya", "elbow", "hershey Hurricane", "Charlie Sheen", "\"Twice in a Lifetime\"", "Nineteen Eighty-Four", "Bardot", "27", "Long Island", "Romney", "rock", "heart disease", "bronchitis"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5857074175824175}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.5454545454545454, 0.45454545454545453, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.0, 0.56, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.53125, "CSR": 0.5666666666666667, "EFR": 1.0, "Overall": 0.7209895833333333}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "tourism", "a circle", "redwood fern", "Marvel's Guardians of the Galaxy", "the Spanish Republic", "taxicab", "(Panthera onca)", "(PVM)", "Harry Reid", "Ray", "Axis", "forge", "Wolfgang", "No Country for Old Men", "frugal Lady", "Blackbird", "Footprints", "Caliban", "LA Kings", "(well, it better have)", "Tommy Lee Jones", "a chief tax collector", "The Memory Keeper's daughter", "(1876)", "hubris", "Yahtzee", "Tony Danza", "markup language", "hives", "74.3", "William S. Hart", "michael", "Pride and Prejudice", "Gamershood.com", "kosher wine", "Munich", "Michael Jordan", "Candlemas", "Prospero", "Hikaru Sulu", "parrots", "dough", "kyushu", "honey", "Boston", "Fisher- Price", "Arctic Ocean", "the Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "1995", "Harlow Cuadra and Joseph Kerekes", "her translation of and commentary on Isaac Newton's book \"Principia\"", "Israel", "Adidas", "anti-trust laws."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6106770833333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-3963", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-391"], "SR": 0.53125, "CSR": 0.5655241935483871, "EFR": 1.0, "Overall": 0.7207610887096774}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Kramer's caddy Stan", "Christian Kern", "January 21, 2016", "Bloomingdale Firehouse", "elise Marie Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge Aharon Barak", "Bangkok", "Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland", "\"Slaughterhouse-Five\"", "Adventures of Huckleberry Finn", "wine", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Lawton Chiles", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Lenny Jacobson", "Hathi Jr", "1935", "fable", "\"Slow\"", "\"Just to See Her\"", "Moffat Tunnel", "AMD", "Friday", "Oregon", "Donald Trump", "Ukraine"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6925681089743589}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6898", "mrqa_searchqa-validation-6055"], "SR": 0.609375, "CSR": 0.56689453125, "EFR": 0.92, "Overall": 0.7050351562499999}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\"", "jellyfish", "March", "a clogs", "Mickey Mouse", "the World Health Organization", "Eat porridge", "Kofi Annan", "chlorophyll", "a second journal of record and the newspaper of the Crown", "Taggart", "Che", "the Gulf of Mexico", "Manfred Mann", "Sven Goran Eriksson", "the BBC", "The Road Wanderer", "Brussels", "Flora MacDonald", "John Poulson", "(orly, is the older and smaller of the two major international airports. RATP Bus No 351 links CDG to the eastern side of Paris at Place de la Nation", "the euro", "\"Jack\" Frost", "Saskatchewan (province)", "Laurent Planchon", "the Solent", "vomiting", "The Red Lion", "Bristol Aeroplane Company", "Spinach", "Steve Davis", "\u201cArgo\u201d", "Sun", "Surrey", "1971", "fosse Way", "London", "Chile", "William Shakespeare", "borax", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "Rigor mortis is very important in meat technology", "USCS or USC", "Miller Brewing", "northwestern Italian coast", "Sydney", "Carnival", "her decades-long portrayal of Alice Horton on the soap opera \" Days of our Lives,\"", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\" Kristal Kraft,", "Peter Bogdanovich", "a Mourning dove", "Germany"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5240349927849928}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.07142857142857144, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.0, 0.0, 0.0, 0.7000000000000001, 0.1142857142857143, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-7050", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.46875, "CSR": 0.5639204545454546, "EFR": 0.9705882352941176, "Overall": 0.7145579879679145}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "No Secrets", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown, Ph. D.", "Antarctica", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Longline", "Jesus'birth", "a habitat", "irsten Simone Vangsness", "Central Germany", "Andrew Johnson", "Etienne de Mestre", "Aegisthus", "electors", "Julia Ormond", "Sauron", "1961", "STAYND", "2013", "March 1", "novelization", "a usually red oxide formed by the redox reaction", "Spain", "Steffy Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "paid monument", "erosion", "March 2, 2016", "turkey", "1996", "Ray Charles", "16", "the Ramones", "1800", "Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "Kate lives in Los Angeles", "May 2010", "France", "Heath Ledger", "Wilson Pickett", "a centaur", "singer", "cricket fighting", "Luis Edgardo Resto", "The drama of the action in-and-around the golf course", "German authorities", "Islamabad", "Tunisia", "RAND", "p Pablo Escobar"], "metric_results": {"EM": 0.5, "QA-F1": 0.5809421472462644}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 0.5, 0.06451612903225806, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.7368421052631579, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.5, "CSR": 0.5620404411764706, "EFR": 1.0, "Overall": 0.720064338235294}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Cal", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions forms the joint venture Bullwinkle Studios", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "a biblical title of respect applied to prophets and beloved religious leaders", "state legislators of Assam", "digestion of proteins", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility", "Isabella Palmieri", "constant pressure", "`` mind your manners ''", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "20 November 1989", "Tom\u00e1s de Torquemada", "the Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "first published in the United States by Melvil Dewey in 1876", "2003", "Sebastian Lund", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "antigens passing through the mucosal epithelium", "business applications to be developed with Flash", "Steveston Outdoor pool", "Phillip Schofield and Christine Bleakley", "a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "braking to a full stop", "early Christians of Mesopotamia", "Tennessee Titan", "\u2212 93.2 \u00b0 C", "a cliffhanger showing the first few moments of Sam's next leap ( along with him again uttering `` Oh, boy! '' on discovering his situation )", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "a hard rock/blues rock band", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "this week", "Henry Ford", "Jaguar", "vice president", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread,"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5977714918582375}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.13793103448275862, 1.0, 0.5, 1.0, 1.0, 0.42857142857142855, 0.3333333333333333, 0.19999999999999998, 0.888888888888889, 1.0, 0.8, 1.0, 0.0, 0.375, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8333333333333333, 0.7000000000000001, 0.0, 0.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.5, 0.5, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-15783", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.4375, "CSR": 0.5584821428571429, "EFR": 0.8611111111111112, "Overall": 0.6915749007936508}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "a supposed mild euphoric", "The Colossus of Rhodes", "Venezuela", "Croatia", "boxing", "Finding Neverland", "Andrea del Sarto", "Arctic Ocean", "the egg", "fish ladders", "Lafayette", "Elijah Muhammad", "a tropical depression, tropical storm, or hurricane", "Punk Rock Fight Club", "Alexander Pushkin", "Australia", "Munich", "puebla", "night shift", "the papacy", "the Mississippi Alluvial Plain", "Watson", "Pierre-August Renoir", "de savoir", "operas", "Innsbruck - Tyrol", "Robert M Wurzelbacher", "Microsoft", "a fern", "The co-founder of this respected organization", "vikings", "Atlantic City's", "Blackwater USA", "elephant", "American Airlines", "ibex", "Odysseus", "Quizlet", "Kensington Palace", "Butch Cassidy", "Netherlands", "Pocahontas", "a British novelist, poet, academic, medievalist, literary critic, essayist, lay theologian", "Dagny Taggart", "a chalkboard", "Chicago Mercantile Exchange", "Las Vegas", "ballet shoes", "wheat", "Pablo Casals", "an ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "an ancient optical illusion toy", "John Morgan", "Hungarian Rhapsody No. 2", "Henry II", "Senate Democrats", "63", "\"We are resetting, and because we are resetted, the minister and I have an overload of work.\""], "metric_results": {"EM": 0.4375, "QA-F1": 0.5370535714285714}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-265", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-15160", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10308", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.4375, "CSR": 0.5551215277777778, "EFR": 0.9722222222222222, "Overall": 0.713125}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "north of the Equator", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act ( NIRA )", "The User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "under the National September 11 Memorial plaza", "Southend Pier", "Santa Monica", "sovereign states", "Will", "31 January 1934", "Filipino", "1773", "modern random - access memory ( RAM )", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Harishchandra", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean", "never made", "Frankie Muniz", "The stratum lucidum", "60", "Hasmukh Adhia", "four", "retinal", "the 1980s", "in soils", "card verification value ( CVV )", "`` rebuke with all authority ''", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum", "Mike Czerwien", "103", "Vienna", "English", "Australia", "Stalin", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "$22 million", "leftist Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities.", "cotton", "Dennis Haysbert", "Quinn", "The Weatherbys Novices' Hurdle Race"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6824213113275613}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.5454545454545454, 1.0, 0.18181818181818182, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.08333333333333334, 0.0, 0.5, 0.6666666666666666, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09523809523809523, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161", "mrqa_triviaqa-validation-5460"], "SR": 0.59375, "CSR": 0.5561655405405406, "EFR": 0.8461538461538461, "Overall": 0.6881201273388773}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "the United States", "South Africa", "first among equals", "shine", "a cappella", "albinism", "Henry Hunt", "aglets", "Saturday Night Live", "FC Bayern M\u00fcnchen", "winter", "Rachel, Rachel", "English", "copper", "Dawn French", "'Blackstar'", "brazil", "Doris Lessing", "Scooby-Doo", "Swaziland", "the elephants", "Kent", "Humber", "points based scoring system", "automobile", "Kent", "Von Trapps", "Boy George", "Galileo Galilei", "Zelle", "Scotland Yard", "Marilyn Manson", "Medellin", "William Shakespeare", "spark", "brazilia", "Boulder Dam", "long-term effects", "Iraq", "Belle de Jour", "Morecambe", "Abba", "rain", "blue", "Asaph Hall", "France", "chazz Palminteri", "Kunsky", "other human beings", "David Graham", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "heavy turbulence", "different women coping with breast cancer in five vignettes.", "Blaine", "a sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5751488095238095}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-541", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.546875, "CSR": 0.555921052631579, "EFR": 0.9310344827586207, "Overall": 0.7050473570780399}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "Tyne", "liver", "40", "table salt", "pet", "Cuba", "le", "denny Redmond", "Stevie Wonder", "head", "hound", "hanover", "a sun", "Earl of Strafford", "work", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "quetzalcoatl", "a 1934 Austin seven box saloon", "Paul Anka", "city-states", "Bath", "Macbeth", "Blade Runner", "Jay-Z", "leopons", "cymbals", "\u201cAir Bud\u201d", "la traviata", "norman tebbit", "Ticket Sarasota", "South Africa", "Christian Dior", "scrobb's fort", "killer whale", "Ukrainian", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "a Baron", "snakes", "brazil", "frauds", "a sea horse", "31", "Tony Blair", "quartz or feldspar", "54 Mbit / s, plus error correction code", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Lynn", "piano", "\"It didn't matter if you were 60, 40 or 20 like I am.", "the women", "French Guiana", "cuba", "arms", "Tiger Woods"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5261160714285714}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, true, false, false, true, false, false, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-2097", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6603", "mrqa_hotpotqa-validation-2852", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.484375, "CSR": 0.5540865384615384, "EFR": 0.9090909090909091, "Overall": 0.7002917395104895}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "aldi", "Midnight Cowboy", "alfa", "seborrheic dermatitis", "bristol baird", "steam engines", "Niger", "central Stockholm", "Tangled", "dogs", "bristol d Douglas", "Bulls Eye", "Adam Smith", "bajec-Lapajne", "Martin Clunes", "charles austen", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "john Mellencamp", "isambard Kingdom Brunel", "Great Britain", "1957", "Devon", "carles", "white wine, salt, pepper", "micelles", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "e. T. A. Hoffmann", "shanghai", "Spain", "growing", "Tuesday", "Guru Nanak", "bleak house", "Harry Potter", "phosphorus", "Little Jack Horner", "FIBA Zones", "dolores haze", "cuckoo", "Mr. Stringer", "Ford", "Alice Cooper", "Majorca (Mallorca)", "red blood cells", "Royal Bengal Tiger", "inward spiral", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "\"The Cycle of Life,\"", "forgery and flying without a valid license", "137", "a log cabin", "St. Patrick's Day", "defensive backs", "Sondheim"], "metric_results": {"EM": 0.4375, "QA-F1": 0.49248511904761905}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6153", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2738", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.4375, "CSR": 0.551171875, "EFR": 0.9444444444444444, "Overall": 0.7067795138888888}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players", "Pacific Northwest", "Thomas De Quincey", "the black death", "horse", "buffalo", "jane anonius", "a dove", "Sarajevo", "the Bill of Rights", "dust", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "wet-folding", "the value of unknown electrical resistance", "Arabian Gulf", "secretary", "jane of valence", "matricide", "jack Nicholson", "\u201cTonight Is Another Day\u201d or \u201cTote the weary Load\u201d", "diesel", "Tomorrow Never Dies", "Sudan", "Great Dane", "Washington", "indian", "New Hampshire", "James I", "charlie fenton", "the Philippines", "purple rain", "everyHit.com", "warblers", "a rogue wave", "rome", "10", "Southwest Airlines", "a person born within hearing distance of the sound of Bow bells", "Jeffery Deaver", "The Comedy of Errors", "charlie j. Kelly", "glyn Jones", "President Clinton", "chebert humbert", "epeiric (or \"shelf\") sea", "al-Qaeda", "rodinsons", "Kitty Softpaws", "1998", "Tanvi Shah", "EN World web site", "the 100th anniversary of the first \"Tour de France\" bicycle race", "Mach number", "Janet and La Toya", "more than 2.5 million", "researchers", "the Matrix", "windrice Arthur", "nibelung", "Inequality of opportunity was higher"], "metric_results": {"EM": 0.40625, "QA-F1": 0.46796875}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.33333333333333337, 0.5, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999]}}, "before_error_ids": ["mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5826", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.40625, "CSR": 0.5476371951219512, "EFR": 0.9473684210526315, "Overall": 0.7066573732349165}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "Rhea", "nippon Sangyo", "the Argonauts", "roddy doddy Doyle", "a counting table", "king Arthur", "aeolus", "Diego Velazquez", "South African", "nuevo Circo", "Norway", "tchaikovsky", "oliver Twist", "angola", "pomposity or self-importance", "David Bowie", "Buzz Aldrin", "jane paul sartre", "popowo", "dennis turpin", "rust", "jane aniston", "wales", "tbilisi", "mel Gibson", "othello", "time", "Glenn Close", "Lacock Abbey", "Jesus", "domestic cat", "anita Brookner", "shomron", "vii eshkol", "Black Sea", "bagram Theater", "miss dent", "a power surge", "Vienna", "The Archers", "shylock", "james james sousa", "henry gee", "jimmy boyd", "shakespears", "The Six Mascots", "vii", "habsburg monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "entire 18 - season career", "from 1993 to 1996", "James Gandolfini", "September 29, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "slip phones into the prison and hide them", "tuba", "o.K.", "butternut squash", "usistocles"], "metric_results": {"EM": 0.375, "QA-F1": 0.4878189792663477}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, true, true, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.10526315789473685, 1.0, 0.18181818181818182, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-5773", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-691", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-14680", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.375, "CSR": 0.5435267857142857, "EFR": 1.0, "Overall": 0.7163616071428571}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "a shortfall in their pension fund and disagreements on some work rule issues.", "Eintracht Frankfurt", "Comoros Islands", "\"revolution of values\"", "Jeddah, Saudi Arabia", "40", "his chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "Wednesday, at a house adjacent to the park", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "dancy-Power Automotive Group", "Michoacan Family", "64", "New Delhi, India", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career", "\"E! News\"", "South Florida", "Madeleine K. Albright", "ice jam", "toxic smoke from burn pits in Iraq and contaminated water.", "Benazir Bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "cal Ripken Jr.", "Johannesburg", "cancer", "acid attack", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m. at Terminal C when a man walked through an exit on the public side to the secure \"sterile\" side for passengers who had cleared screening", "Former Mobile County Circuit Judge Herman Thomas", "\"We say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well,", "man's lifeless, naked body", "\"release\" civilians", "Dodi Fayed", "the shipping industry", "in which there is a decline in population density", "Real Madrid", "emperor Cuauhtemoc", "scotland", "Misery", "Ernest Hemingway", "Italo Balbo", "Thorgan", "River Clyde", "chile", "jane jim", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5607085257578679}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2, 0.8000000000000002, 1.0, 0.923076923076923, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.28571428571428575, 0.0, 0.6, 0.14545454545454548, 1.0, 1.0, 0.3636363636363636, 0.0, 0.10526315789473685, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-7333", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-5687", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.46875, "CSR": 0.5417877906976745, "EFR": 1.0, "Overall": 0.7160138081395349}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.,", "1943", "facelifted 850 saloon", "the Mountain West Conference", "the National Basketball Association", "Western Europe", "political thriller", "Continental AG", "the Championship", "1989 until 1994", "the Distinguished Service Cross,", "\"50 best cities to live in.\"", "Bridgetown,", "Lollywood and Pollywood films", "Emmanuel Ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs.", "2008\u201309", "coaxial", "\"Northern Lights\",", "three different covers", "Malayalam cinema", "(1815\u20131867)", "August 11, 1946", "Vincent Landay", "September 6, 1967", "\"Estadio de L\u00f3pez Cort\u00e1zar\",", "Brian A. Miller", "Nicolas Vanier", "1985", "Gal Gadot", "Meghan Markle", "Texas Raiders", "Marco Da Silva", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins,", "United Nations", "Lewis Carroll", "two occasions", "the UK\u2019s Trade Mark Registration Act 1875,", "blue", "elbow", "Citizens are picking members of the lower house of parliament,", "the Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7052854980164763}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 0.6666666666666666, 0.5, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-7240", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070"], "SR": 0.609375, "CSR": 0.5433238636363636, "EFR": 0.92, "Overall": 0.7003210227272727}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "over 12 million", "sexy Star", "Conservatorio Verdi", "the 40th United States president", "the backside", "Angelo Bruno", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "January 11, 2016", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller roller", "Blackpool F.C.", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "The Division of Fawkner", "Socrates", "American singer Toni Braxton", "Hindi", "Richard Masur", "Irish Chekhov", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "The Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "1972", "John Goodman as James P. `` Sulley '' Sullivan", "over 38 million", "The Spectator", "Easter Parade", "Elgar\u2019s", "last summer.", "almost 100", "into the Southeast,", "the jeffersons tv show", "a stick to fish the filemot frith for treasures", "heresy", "One Direction"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6819750816993464}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.75, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10536", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-3263"], "SR": 0.5625, "CSR": 0.54375, "EFR": 1.0, "Overall": 0.71640625}, {"timecode": 45, "before_eval_results": {"predictions": ["a result of the American Revolution", "a proof", "Queen Elizabeth II", "a Belgae", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "minigolf", "CNN", "Punxsutawney, Pennsylvania", "Pressburg", "yellow fever", "a sea otter", "Jeopardy", "franchise", "a rod", "Nixon", "dressage", "astronomy", "Mickey Mouse", "the stigma", "Associate", "a fruit snack", "Medusa", "a spiral staircase", "Prince Attab", "a staff", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "Helen of Sparta", "Vegetarianism", "the peace sign", "A Detroit Free Press journalist and best-selling author", "English Monarchs These 2", "India", "sexy Beast", "a column", "NFL", "a \"road above\"", "White bread and butter", "a meeting when the vote takes place, or a short retention period for ballots can be", "Wordsworth", "brushes", "a planetary-mass object that is neither a planet nor a natural satellite", "a wish", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London", "Isle of Wight", "Tornado", "\"Queen In-hyun's Man\"", "Oneida Limited", "Michael Jordan", "Libreville, Gabon.", "tickets", "The station", "tuscaloosa"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6153409090909091}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true, true, false, false, true, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.1818181818181818, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-3132", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-3322", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_triviaqa-validation-888"], "SR": 0.546875, "CSR": 0.5438179347826086, "EFR": 0.9655172413793104, "Overall": 0.7095232852323837}, {"timecode": 46, "before_eval_results": {"predictions": ["social power and wealth", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "winston", "faggots", "a grey geese", "California Chrome", "Pluto", "Route 66", "the Altay, Gahats", "Sindh\u016b", "Astronaut", "desert", "German", "the British pop band Go West", "December 18, 1958", "in year 1752", "Portugal", "Operation Overlord", "Birmingham", "snakes", "Sedgefield in North East England", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "trenches", "North Korea", "a pigs", "definitely, maybe", "Holzi194", "Kenya", "Stephen Potter", "Casa di Giulietta", "Anwar Sadat", "three", "the Susquehanna River", "Bolivia", "Vader", "Frankfurt", "chipmunk", "Goldie Hawn", "a pulsar", "Belgium", "horses", "honey", "Benfica", "Penthouse Pet of the Month", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "the Carrousel du Louvre", "Speed Racer", "science fiction", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6183035714285714}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-3840", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-6115", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-2974", "mrqa_triviaqa-validation-3654", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.546875, "CSR": 0.5438829787234043, "EFR": 1.0, "Overall": 0.7164328457446809}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "Palazzo delle Prigioni", "Sinclair Lewis", "a bear", "The World is Not Enough", "tempera", "jodie Foster", "Vaclav Havel", "Dick Van Dyke", "Sir John Everett Millais", "Tina Turner", "2010", "lough", "glasses for reading things that are far away or for driving", "perfumer", "Duke Orsino", "magnetite", "Copenhagen", "BBC One's", "cargo", "Cubism for Kids", "sahara", "the Advisory Council of Science and Industry", "eucharist", "Charlotte's Web", "Octopussy", "fresh fruits", "William Randolph Hearst", "Lorne Greene", "rowing", "Michael Redgrave", "call my Bluff", "star", "Argentina", "Frank McCourt", "oats", "caroline aherne", "LDV", "starch", "pears soap", "Donna Summer", "a balustrade", "Nottingham", "gdansk Poland", "the Welcome Stranger", "taggart", "March", "chechnya", "a police janitor", "a-team", "football", "1,281,900 servicemembers", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough", "Speedway World Championship", "beautiful", "Eleven people", "Michelle Obama", "Copenhagen", "the Communist Manifesto", "saara", "Floxin"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5895833333333333}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, true, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-5096", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-3758", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-15651"], "SR": 0.53125, "CSR": 0.5436197916666667, "EFR": 1.0, "Overall": 0.7163802083333334}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "king \u00c6thelred the Unready", "creature comforts", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air", "Mineola", "dziga Vertov", "Strange Interlude", "Julia Compton Moore", "gymnastics", "argentina", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Babylon", "Ford Falcon", "New York State Route 908M", "The Company", "1827", "Kim Bauer", "United States Food and Drug Administration (FDA)", "Edward James Olmos", "Bury St Edmunds", "Prussian", "La Nouba", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard H or HD blister gas", "the 45th Infantry Division", "2009", "5", "Anita Dobson", "Westminster, London", "Boyd Gaming", "August 14, 1848", "Texas Tech University", "John McClane", "Larry Gatlin & the Gatlin Brothers", "Cayenne SUV", "371.6 days", "North Carolina", "Selinsgrove", "Augusta Ada King-Noel, Countess of Lovelace", "first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "space shuttle", "basil", "statuette", "The Rosie Show", "Current TV", "over 1,000 pounds", "Julius Caesar", "Desert", "the Library of Congress", "the thylakoid membranes"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6566468253968254}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, false, false, true, true], "QA-F1": [0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 0.0, 0.5, 1.0, 0.0, 0.0, 0.8571428571428571, 0.19999999999999998, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-775", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-1399", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-5844", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.578125, "CSR": 0.5443239795918368, "EFR": 0.9629629629629629, "Overall": 0.7091136385109599}, {"timecode": 49, "UKR": 0.701171875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2339", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5755", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-2999", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-60", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3155", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5788", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6000", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-888", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-92"], "OKR": 0.826171875, "KG": 0.4921875, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John W. Henry", "Mos Def", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "manga and anime \"Love Hina\"", "eastern", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five aerial victories", "Alain Robbe-Grillet", "the Seasiders", "musical research", "Dragon TV", "Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million passengers", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "Golden Globe Award", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf for Best Actor in 2013", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "the closing scene of the final episode of the first season", "Everywhere", "the birth centenary of Pandit Jawaharlal Nehru", "honda", "Adam Smith", "Republic of Upper Volta", "56", "Nkepile Mabuse", "Eintracht Frankfurt", "Fort Mandan", "Hephaestus", "Amherst College", "two courses"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7273492132867133}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-1498", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.59375, "CSR": 0.5453125, "EFR": 1.0, "Overall": 0.71296875}]}