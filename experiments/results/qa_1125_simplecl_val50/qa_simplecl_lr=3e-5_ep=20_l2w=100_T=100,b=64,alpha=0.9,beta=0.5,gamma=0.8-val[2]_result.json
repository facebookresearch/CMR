{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=100.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4160, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange County", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normans, Viking", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis on 2nd December 1936", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia, Belarus, and Moldova"], "metric_results": {"EM": 0.859375, "QA-F1": 0.8859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.859375, "CSR": 0.8671875, "EFR": 0.6666666666666666, "Overall": 0.7669270833333333}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "civil disobedience", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "historical political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "warmest regions", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "the city's beaches are artificial and... Three major Spanish cities that are located on the Mediterranean coast are... on both the Atlantic Ocean and the Mediterranean Sea", "it is well written", "'Twas the Night Before Christmas", "guardian", "Constitution Day  Founding Father Roger Sherman from the State of Connecticut is a signer to the U.S. Constitution in September 17, 1787", "the first... a ticket from Panama to San Francisco in the steamer Oregon", "guardian", "time goes", "Reviews, discussion, Bookclubs, lists", "the division of the...   Department of Chemistry -UPMC - University Pierre and Marie...  Head of the Chemistry Department", "abolitionists", "5562"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7031520562770562}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.65625, "CSR": 0.796875, "EFR": 0.8636363636363636, "Overall": 0.8302556818181819}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double", "August 1967", "German", "27-30%", "four", "philanthropic initiative", "Arizona Cardinals", "Peanuts", "comb rows", "calcitriol", "Warsaw", "time and space", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail and a carnivorous octopus", "Orestes", "Some grow to an immense size", "the term \"act of terror\"", "the process by which water changes from a liquid to a gas", "the Travel Detective: How to Get the Best Service and the Best deals from Airlin", "a really liquid cereal", "Inks, in which colour is imparted by... the replacement of many inorganic pigments such as chrome yellow,... alloy powder (gold bronze) are used in novel silver and gold inks", "the Mycenaean kingdoms, the Hittite Empire", "a biological process that displays an endogenous, entrainable", "the Belasco Theatre 111 W. 44th Street", "the Normandy Landings, a group of U.S. soldiers go behind enemy lines to", "Evelyn \"Billie\" Frechette", "fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6637919372294372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-397", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-1775", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.640625, "CSR": 0.7578125, "EFR": 0.8695652173913043, "Overall": 0.8136888586956521}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Latin Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25", "May 2013", "K-9 and Company", "capturing prey", "C4", "pasture for cattle", "Victorian", "1,300,000", "the end result of ATP energy being wasted and CO2 being released, all with no sugar being produced", "two tumen", "eight", "A computational problem", "WZM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer", "50-yard line", "3D printing technology", "Malkin Athletic Center", "24\u201310", "6.7+", "empire", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "Michael Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "the war years", "Intel (or any company) based on 10% of global annual revenues", "Tim Clark, Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "a large concrete block is next to his shoulder, with shattered pieces of it around him", "the foyer of the BBC building in Glasgow, Scotland", "Christianity", "Manchester United", "Noriko Savoie", "three", "change course", "Tsvangirai", "cowardly lion", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a 100% pure and natural sweetener made and stored in honeycombs by the honey bees", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.625, "QA-F1": 0.6866802647783251}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.06896551724137931, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.2666666666666667, 1.0, 0.0, 0.2, 0.0, 1.0, 0.25, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.4, 0.0, 0.14285714285714288, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-8874", "mrqa_squad-validation-2984", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-6092", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-862", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.625, "CSR": 0.73125, "EFR": 0.875, "Overall": 0.803125}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "seal", "Philip Howard", "King Ethelred II", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "British", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant", "Goa", "D, E or F", "the Louvre", "Leo Frank", "as he tried to throw a petrol bomb", "Graziano Transmissioni", "opposition parties", "204,000", "Newcastle", "the release of the four men", "putting a personal and human face on the issue", "Johnny Carson", "This will be the first time any version of the Magna Carta has ever gone up for auction, according to David Redden, vice chairman of Sotheby's.", "No. 2 man (or woman)", "end of a biology department faculty meeting at the University of Alabama in Huntsville", "Ali Larijani", "policing the world and Africa", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "supporting fuel economy and safety while boosted the economy", "heart rate that exceeds the normal resting rate", "a jolly, solid, nutritious character, which describes the Suffolk perfectly.", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6760374050936164}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.609375, "CSR": 0.7109375, "EFR": 0.6, "Overall": 0.65546875}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "straight line", "the autumn of 1991", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1.", "nerves", "1700", "the New Germany", "polyhydroxy aldehydes and ketones", "Howard Dean III (born November 17, 1948) is an American politician who served as the 79th Governor of Vermont from 1991 to 2003 and Chair of the Democratic National Committee (DNC) from 2005 to 2009.", "the heart, blood, and blood vessels.", "\"Wild Thing\", he played the ocarina as well", "six literal ordinary days", "Bratislava, this country's capital", "Diana, the Princess", "slave-trade", "pulmonary veins carry oxygenated blood from the lungs into the left atrium", "a fossil clam, now known as Chesapecten jeffersonius, which appeared in Lister's... to the fossil from Virginia", "Bullseye, or bull's-eye, is the centre of a shooting target,", "Tartarus", "\"cyc\" is short for this type of backdrop that suggests infinite space behind the performer.", "Nancy Reagan", "Bardiya, the king he killed & replaced, had been an impostor", "Fractional Ownership", "Count Ferdinand von Zeppelin", "huge", "Duke of Clarence, third son of George III and King of England", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas!", "Hurley", "The Walking Dead ( comic book ), a comic book series by Robert Kirkman, Tony Moore, and Charlie Adlard first published in 2003", "Love Is All Around", "Los Angeles Dance Theater", "United States", "the FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5327329048606623}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.125, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-8993", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-2340", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.484375, "CSR": 0.6785714285714286, "EFR": 0.8181818181818182, "Overall": 0.7483766233766234}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "reduce growth", "K-9 and Company", "9.1 million", "little support", "individual countries", "cattle and citrus", "Western Xia", "semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Eisenhower Freeway", "Thanksgiving", "86.66% (757.7 sq mi or 1,962 km2)", "Two thirds", "the Privy Council", "well into the nineteenth century", "capacity deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "The Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rodeo", "hog", "Barack Obama", "Kenny G", "a small, half size cup used for serving espresso", "puffalump", "Annapolis", "Spring Awakening", "klammeraffe", "Artificial female ones", "al- ilah", "child", "South American snake", "The Bible: In the Beginning", "Phillip", "Faith Hill & Tim McGraw", "Ben Affleck", "Sandy was not a hurricane when it made landfall.", "Germany", "geologic time", "Yardbird and Bird", "Sweden", "Thailand", "94 elements exist naturally, although some are found only in trace amounts and were synthesized in laboratories before being found in nature.", "destroyed", "Perfume: The Story of a Murderer", "the New Jersey Economic Development Authority's 20% tax credit on TV shows filmed or produced in the state,", "Georgetown", "Essex Eagles", "Alzheimer's"], "metric_results": {"EM": 0.5, "QA-F1": 0.5658717105263158}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.4, 0.3157894736842105, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-7473", "mrqa_squad-validation-8189", "mrqa_squad-validation-7565", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-3893", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-15487", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_naturalquestions-validation-10073", "mrqa_triviaqa-validation-3911", "mrqa_hotpotqa-validation-4891", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.5, "CSR": 0.65625, "EFR": 0.84375, "Overall": 0.75}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu in the north", "silent", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "Red Army", "middle of the 20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Body of Proof", "seven-eighths", "Pierre Puget", "the Anti-Atlas", "Madrid", "the Danube", "Yahweh", "leather", "George Mortimer Pullman", "plums", "Jesus Christ", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "Frangipanis", "Dividing", "Hypnos", "Texas", "International House of Pancakes", "a white breed", "the Bill of Rights", "an optional writing test", "Brazil", "Walden", "Southern California", "Harry Whittington", "the Earth", "William Donald Scherzer", "Jack B Yeats", "the Central Intelligence Agency", "d'Artagnan", "Vnus impudique", "1985", "apples", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5147081500172532}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.4, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-13837", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-14640", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.4375, "CSR": 0.6319444444444444, "EFR": 0.7777777777777778, "Overall": 0.7048611111111112}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "Second World War", "integer factorization problem", "Scottish independence", "exploration", "prep schools", "soft power", "Islamist", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Alexei Kosygin", "Hera", "the vine", "Elton John", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Washington State", "Carmen", "Genoa", "15", "tarn", "972; 451; 100; or 25", "buffalo", "Ann Widdecombe", "scalene", "Old Kent Road", "Tuesday", "anhydrous copper sulfate (CuSO4)", "Ab Fab", "Massachusetts", "Barrow, Carlisle, Whitehaven and Workington", "California", "the Susquehanna River", "Kajagoogoo", "maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "What Price", "Grover"], "metric_results": {"EM": 0.609375, "QA-F1": 0.690922619047619}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9870", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.609375, "CSR": 0.6296875, "EFR": 0.84, "Overall": 0.73484375}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "Lord's Enclosure", "League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult, if not impossible", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "eyes", "stone", "Ken Russell", "Dan Dare", "Sulla", "Smiths", "Mike Tyson", "Morocco", "Pesach", "Brian Deane", "oscope", "Uranus", "Apollo", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "the Underground Railroad", "pouk", "\"beyond violet\"", "passion fruit", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "the New Haven Railroad", "The Marriage Contract", "Christian Dior", "a shaggy, candy-loving dog", "Mendip", "Wichita", "communion", "New Croton Reservoir in Westchester and Putnam counties", "Andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "a \"independent jurist\" with a \"sharp and agile mind\" who would bring \"a wealth of unique experience\" to the high court.", "\"Ni!\"", "Roman Polanski"], "metric_results": {"EM": 0.640625, "QA-F1": 0.65625}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6263", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-4371", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-3860", "mrqa_triviaqa-validation-2022", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.640625, "CSR": 0.6306818181818181, "EFR": 0.782608695652174, "Overall": 0.7066452569169961}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network headquartered in San Jose, CA that utilized virtual call packet switched technology", "public service", "Guy de Lusignan", "tiger team", "B cells", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "hez-bah-lah", "five", "Whist", "Nile River", "Toscana", "vision loss, especially in bright light, to which they are extremely sensitive.", "choroid", "Pluto", "iron", "copper", "Hague", "Victoria", "Ironside", "John le Carr\u00e9", "g Gorky", "brown trout", "Beyonce Knowles", "Wordsworth", "Man V Food", "Queen Elizabeth II", "J. Dodsley", "Ed Chernoff", "Mary Poppins", "Bennett Cerf", "calcium, magnesium, phosphorus and potassium", "hudd", "Crimea", "Shrek", "Oslo", "horses", "rhododendron", "\"All That Jazz\"", "Franklin D. Roosevelt", "Shanghai", "gile de Becque", "boat lifts", "Billy Colman", "17 October 2006", "beer", "Kingman Regional Medical Center", "Saturday's Hungarian Grand Prix", "tituchin", "Edgar Allan Poe", "titular"], "metric_results": {"EM": 0.5, "QA-F1": 0.6110639880952382}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.9166666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-4510", "mrqa_squad-validation-8252", "mrqa_squad-validation-4870", "mrqa_squad-validation-6530", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-2059", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.5, "CSR": 0.6197916666666667, "EFR": 0.75, "Overall": 0.6848958333333334}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "a majority in Parliament, a minority in the Council, and a majority of the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas.", "The Handmaid's Tale", "bonobo", "The Fault in Our Stars", "CR-X", "puzzle", "1961", "400 MW", "Total Nonstop Action Wrestling", "Galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen", "Continental Army", "Jack Kilby", "Ryan Babel", "Ramzan Kadyrov", "July 16, 1971", "1933", "\"The Heirs\" (2013), \"Descendants of the Sun\" (2016) and \"Fight for My Way\" ( 2017)", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca Hopkins", "Daniel Hale Williams Preparatory School of Medicine", "England", "Paul W. S. Anderson", "a basilica", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "opium poppies in Taliban-controlled Helmand province", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "dr. Dre", "little Miss Muffet", "pre-Columbian times, the American Bison, is difficult to domesticate and was never domesticated by Native Americans"], "metric_results": {"EM": 0.703125, "QA-F1": 0.724546568627451}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7200000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.11764705882352942, 0.04761904761904762, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_naturalquestions-validation-8227"], "SR": 0.703125, "CSR": 0.6262019230769231, "EFR": 0.8421052631578947, "Overall": 0.7341535931174089}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000 years", "Huguenot", "ABC News Now", "sold", "\u00c9mile Girardeau", "Brownlee", "The Five Doctors", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "a psychophysical training or the method of physical action", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Firestorm\", \"The Spectre\", and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "Liquidambar styraciflua", "Gilbert du Motier", "Indian", "three", "Winter Haven", "four", "The Process", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "6", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Johnny Cash", "Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "2015", "1982", "rod", "Chris Robinson", "g gossip Girl", "euler equations", "angno or Lorre", "Big Blue Woman", "London Festival Orchestra"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6367708333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.4, 0.4, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7200000000000001, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-7020", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.5625, "CSR": 0.6216517857142857, "EFR": 0.7857142857142857, "Overall": 0.7036830357142857}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "2009 onwards", "religious freedom", "Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30\u201360% of Europe's total population.", "the kilogram-force", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "time and storage", "Vistula River", "100 to 150", "Apple's new iOS5 operating system, meaning its ability to run apps, surf the Web and the like will maintain its unofficial status as the iPhone-without-a-phone.", "a dormitory parent mistreated students at the school.", "March 8", "Democrats and Republicans", "Catholic League", "Half Moon Bay", "\"He is obviously very relieved and grateful that the pardon was granted,\" Dean said.", "Friday", "Movahedi", "different women coping with breast cancer in five vignettes", "\"We essentially closed the wheelhouse doors. I went to the port side, and I looked out up at the derrick.", "she also told FBI agents Lisa's parents never mentioned anyone wanting to harm them", "milk", "Lance Cpl. Maria Lauterbach", "South Korea's newest plant claims it is designed to go green.", "London", "400", "Val d'Isere, France earlier this year", "the results by a chaplain about 1:45 p.m., per jail policy.", "a municipal building in Baghdad's Sadr City", "21 percent", "1616", "Sky", "Chile", "Half Moon Bay", "Buddhism", "J. Crew", "Japanese", "mood-shifter", "British author J.G. Ballard, whose boyhood experience in a World War II internment camp became the novel and film \"Empire of the Sun,\"", "get on with his life", "4 meters (13 feet) high", "the Irish capital", "Democrat", "Spanishfork", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "roald Dahl", "mercury"], "metric_results": {"EM": 0.3125, "QA-F1": 0.38799507595363575}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.08333333333333334, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 0.27272727272727276, 1.0, 0.6666666666666666, 0.8750000000000001, 0.7555555555555554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1818181818181818, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2608695652173913, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-1672", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.3125, "CSR": 0.6010416666666667, "EFR": 0.6818181818181818, "Overall": 0.6414299242424242}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "the Quaternary period", "1870", "water", "a prime number", "50 fund", "Camisards", "over $40 million", "GTE.", "1,100 tree species", "spinat", "Oligocene", "Melodie Rydalch,", "Charles Darwin", "at a Little Rock military recruiting center", "March 24", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"We are here to cooperate with anyone and everyone that will help us find the guilty party, and return Lisa home safely,\"", "56", "Fred Bright, the district attorney in Milledgeville, Georgia,", "\"The Da Vinci Code\"", "Heshmatullah Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Atlanta", "resources", "highest ranking former member of Saddam Hussein's regime still at large, salutes the \"People of Palestine\" and calls on them to fight back against Israel in Gaza.", "two", "\"To all of our valiant men and women, know that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.\"", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"  - the central attraction of golf remains at all the film's core.", "Rwanda", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "a bond hearing Friday, a federal magistrate said Monday.", "President Bush", "a hospital in Amstetten, where staff grew suspicious and called police, who opened an investigation and uncovered the abuse.", "African National Congress Deputy President Kgalema Motlanthe", "spiral into economic disaster.", "resigned as leader of the ruling political party Monday following a poor showing in Sunday's elections, the official news agency Telam reported.", "The security is less kinetic", "a strict interpretation of the law, which forbids girls from attending school, requires veils for women and beards for men, and bans music and television.", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit on TV shows filmed or produced in the state,", "July 23.", "70,000 or so", "The surveillance-camera video, shot May 11, shows a man wearing a baseball cap, dark jersey, blue jeans and running shoes entering a store, walking to the back and looking around, then walking out.", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a published campaign setting or a homebrew campaign setting", "Beno\u00eet Jacquot", "topaz", "Library of Congress", "The Left Book Club", "holography"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5902805224761504}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.07407407407407407, 1.0, 0.4444444444444445, 1.0, 0.5, 0.6428571428571429, 0.28571428571428575, 1.0, 1.0, 0.20689655172413793, 0.0, 0.13333333333333333, 0.24000000000000002, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.11764705882352941, 0.4444444444444445, 1.0, 0.06451612903225808, 0.0, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.3, 0.045454545454545456, 1.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-4349", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2608", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.484375, "CSR": 0.59375, "EFR": 0.696969696969697, "Overall": 0.6453598484848485}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "housing bubble", "137", "Adam Lambert and Kris Allen", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary misdemeanor", "foreplay, sexual conquests and how he picks up women, all taboo subjects in deeply conservative Saudi Arabia.", "injuries,", "30 years ago", "murder", "next year", "Despite Gration's comments, the Obama administration has not yet articulated a Sudan policy.", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "The 19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire, does that mean it would use it against Israel?", "brutal", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up", "\"Perfidia,\" \"Walk Don't Run '64\" and \"Diamond Head.\"", "tears of a Native American Indian", "1 million", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Monday", "women", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "in July she laid 11 healthy eggs and, this week, all 11 of them hatched", "have expressed concerns about the missile defense system. While Poland and the Czech Republic have agreed to host parts of the system, others in Europe share Russian concerns that the defensive shield could be used for offensive aims.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "Fullerton, California,", "World War I", "1950s", "U.S. troops", "Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "More than 120 groups across six continents are holding vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed", "Oxbow,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "\"Three Colours\" Trilogy, themed on the French Revolutionary ideals of liberty, equality, and fraternity;", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "Joe Louis", "George Blake", "Bogota"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6185201343795095}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6923076923076924, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.16, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.125, 0.3, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.06666666666666667, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_triviaqa-validation-6739"], "SR": 0.546875, "CSR": 0.5909926470588236, "EFR": 0.6896551724137931, "Overall": 0.6403239097363084}, {"timecode": 17, "before_eval_results": {"predictions": ["lower", "in hospitals", "questions and answers", "(sed vigilat)", "Captain Francis Fowke, Royal Engineers, who was appointed by Cole.", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "an initial report outlining its findings and recommendations", "\"Mad Men\"", "Windsor, Ontario,", "$50", "Afghanistan's restive provinces", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends to secure a visitor's visa and bus ticket to Johannesburg.", "killings of Indians", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Matthew Fisher", "The exact cause of IBS remains unknown,", "in the north and west of the country,", "forcibly drugging", "introduce legislation Thursday, to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "a fair and independent manner and ratify successful efforts.", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22", "Spain", "how health care can affect families.", "Appathurai", "U.S. Food and Drug Administration", "Dominican Republic", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps", "Lashkar-e-Tayyiba (LeT)", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "beat", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bky\u016b people", "surrealism", "C. S. Lewis", "281 8 1 2", "sake", "Halifax"], "metric_results": {"EM": 0.53125, "QA-F1": 0.597372153989801}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3529411764705882, 0.25, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 0.4, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-6359", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695"], "SR": 0.53125, "CSR": 0.5876736111111112, "EFR": 0.7666666666666667, "Overall": 0.6771701388888889}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam", "Defensive ends", "the dot", "chastity", "The European Court of Justice", "bronze", "\"trying to steal the election\" and \"intimidating the population and election officials as well.\"", "British", "\" Teen Patti\" (\"Card Game\")", "Argentina", "Congress", "28", "Frank Ricci", "the project, which is designed to promote private sector investment in a variety of gas-related industries, on September 21.", "saying Tuesday the reality he has seen is \"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "requiring the label warnings and a medication guide for fluoroquinolone drugs, which include Cipro, Levaquin, Avelox, Noroxin and Floxin.", "political and religious", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Bahrain", "a violent and brutal extremist group with a number of individuals affiliated with al Qaeda.", "skull", "providing the basic securities that Turkey can be a great partner.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "because they were being discriminated against on the basis of nationality.", "Ben Roethlisberger", "Dr. Christina Romete,", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally,", "Lindsey Vonn", "Paul McCartney and Ringo Starr, to celebrate the anniversary of Cirque du Soleil's \"Love,\" which uses the Beatles' music.", "prisoners' rights and better conditions for inmates, like Amnesty International.", "President Obama's race in 2008.", "Brazil", "Saluhallen,", "burned genitals", "two people", "40", "Iranian consulate in Peshawar", "Casey Anthony, 22,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger.", "\"Taxman,\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "Kirk Lazarus", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.484375, "QA-F1": 0.582054288930004}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.8571428571428571, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.08695652173913043, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.45454545454545453, 0.33333333333333337, 0.10810810810810811, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.8, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3410", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-2165", "mrqa_newsqa-validation-1603", "mrqa_newsqa-validation-1000", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254", "mrqa_searchqa-validation-9338"], "SR": 0.484375, "CSR": 0.5822368421052632, "EFR": 0.6060606060606061, "Overall": 0.5941487240829346}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "Tesla would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid", "most of those who managed to survive the incident hid in a boiler room and storage closets", "that the Bainbridge would be getting backup shortly.\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones.", "a book", "reports he was diagnosed with skin cancer.", "stand down", "Ashley \"A.J.\" Jewell", "17", "Satsuma, Florida", "southern city of Naples", "Hugo Chavez", "London", "rural California,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "Preah Vihear temple", "The Delta Queen will go out of service if Congress does not grant the ship another exemption from a 1960s federal law, the Safety at Seas Act, which bans boats made largely out of wood because of fire hazards.", "Haeftling range.", "Alaska or Hawaii.", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "Blagojevich", "America's infrastructure.", "patrolling the pavement in protective shoes", "public-sector labor unions launching a general strike,", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "discard beer bottles on pebbled walkways.", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International Airport", "GZA, \"Grandmasters\"", "Suffragette", "Cobblestone", "Brazil", "The Lone Ranger", "Bonnie and Clyde"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6090360318567556}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.27272727272727276, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.5, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.1081081081081081, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.5, 1.0, 0.5714285714285715, 0.0, 1.0, 0.2857142857142857, 0.4, 0.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-416", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-413", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2805", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-14663"], "SR": 0.453125, "CSR": 0.57578125, "EFR": 0.7142857142857143, "Overall": 0.6450334821428572}, {"timecode": 20, "before_eval_results": {"predictions": ["Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000 write / erase cycles", "United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50 feet", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956", "The first message was sent over the ARPANET in 1969 from computer science Professor Leonard Kleinrock's laboratory at University of California, Los Angeles ( UCLA ) to the second network node at Stanford Research Institute ( SRI )", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Yale University", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Archduke Franz Ferdinand of Austria", "Koine Greek : apokalypsis", "October 1941", "to refer to either peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "b\u0101gh, baug, bageecha or bagicha", "Cee - Lo", "after Shawn's kidnapping", "in consistency and content", "Labour", "1933", "November 25, 2002", "October 29, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "for a single particle in a plane two coordinates define its location so it has two degrees of freedom", "Alberto Salazar", "a collection of live animals", "American", "Hoosick,", "CEO of an engineering and construction company with a vast personal fortune.", "more than 1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "approximately 600 square miles of south-central Washington,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6419506472290992}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0625, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8421052631578948, 1.0, 0.0, 1.0, 0.5365853658536585, 0.0, 0.0, 0.0, 0.1, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.4, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3167", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.53125, "CSR": 0.5736607142857143, "EFR": 0.7333333333333333, "Overall": 0.6534970238095238}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "bearers", "Washington metropolitan area", "molar concentration", "the breast or lower chest of beef or veal", "Samaria", "Tagalog or English", "The Edwin Smith Papyrus was written around 1600 BC", "By mid-1988, all 50 states and the District of Columbia had raised their purchase ages to 21", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Giancarlo Stanton", "Orangeville, Ontario, Canada", "medical abnormalities, activation level, or recruitment order, or to analyze the biomechanics of human or animal movement", "Janie Crawford, an African - American woman in her early forties,", "6th century AD", "in positions Arg15 - Ile16", "Elk and Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "1957", "1776", "1995", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "Scarlett Johansson", "Transvaginal ultrasonography", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Swedish figure skater Gillis Grafstr\u00f6m", "Sophocles", "Julie Gonzalo", "thick skin", "a cake", "India", "Brazil, Turkey and Uzbekistan", "waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "batsman", "Rear-Admiral of the Navy", "Marktown, Clayton Mark's", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduras", "Pardon of Richard Nixon", "Ellen DeGeneres", "12 April 1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5114399948499213}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.2222222222222222, 0.0, 0.22222222222222224, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 0.3333333333333333, 0.16666666666666666, 0.4, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.8235294117647058, 0.0, 0.0, 0.5, 0.6666666666666666, 0.08333333333333333, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-5168", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3883", "mrqa_hotpotqa-validation-427", "mrqa_hotpotqa-validation-3984"], "SR": 0.359375, "CSR": 0.5639204545454546, "EFR": 0.6341463414634146, "Overall": 0.5990333980044347}, {"timecode": 22, "before_eval_results": {"predictions": ["the mouth of the Monongahela River", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "Coldplay", "annual income of US $11,770", "al - khimar", "prenatal development", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "Massachusetts", "two", "John Adams", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "on a sound stage in front of a live audience in Burbank, California", "Grace Zabriskie", "2009", "Yuzuru Hanyu", "Glenn Close", "Kanawha", "flawed democracy", "China", "Kirk Douglas as Matt Morgan", "Jodie Foster", "February 27, 2007", "Malina Weissman", "8ft", "Owen Vaccaro", "detritus", "on the lateral side of the tibia", "Lynda Carter", "erosion", "90 \u00b0 N 0 \u00b0 W", "London", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "2005", "February 29", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "Queen Elizabeth II", "an insect in one part of the country and to a completely different insect", "Pearl Jam", "2005", "Dan Tyminski", "the oldest daughter of an incestuous relationship", "the southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "at least nine", "Bashar al-Assad", "New Revised Standard Version", "biathlon"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6738549933862434}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.28571428571428575, 0.14814814814814814, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.578125, "CSR": 0.5645380434782609, "EFR": 0.7037037037037037, "Overall": 0.6341208735909822}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas currently has the longest streak of consecutive NCAA tournament appearances of all - time ( 29 )", "Thaddeus Rowe Luckinbill", "by the early - to - mid fourth century", "2002", "China", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2, Clause 3", "Constitution of India", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "closing of the atrioventricular valves and semilunar valves", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Ireland", "1981", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "September 28, 2017", "Alex Skuby", "Jamestown settlement in the Colony of Virginia", "March 2016", "1922 to 1991", "Edward Hyde", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "the `` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "The Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield as Al Schmid", "1871", "eye", "The History Boys", "aprimitive type of fish", "White Knights of the Ku Klux Klan", "five books, with a cumulative total of 528 aphoristic sutras, about rules of reason, logic, epistemology and metaphysics", "Mot\u00f6rhead", "Kingman Regional Medical Center", "Phillip A. Myers", "Osama", "Antarctic", "spinal cord", "chanterelle mushrooms, or Cantharellus"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6148593274415644}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.5714285714285715, 0.9333333333333333, 1.0, 0.4, 1.0, 1.0, 0.4, 0.0, 0.5, 1.0, 1.0, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.2222222222222222, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.4, 0.5, 0.21052631578947367, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-13614", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.453125, "CSR": 0.5598958333333333, "EFR": 0.7142857142857143, "Overall": 0.6370907738095237}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "the first hole of a sudden-death playoff with Kentucky native Kenny Perry", "Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "Indian School of Business, American India Foundation, New Silk Route and Scandent Solutions.", "Radio City Music Hall", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin button\"", "A55", "Corendon Dutch Airlines", "86", "Capella University", "Eilean Donan", "Fatih Ozmen", "U.S.", "Pacific Place", "writing for \"The New York Times\" and \"Popular Mechanics\", and is a regular contributor to various CNBC shows such as \"On the Money\"", "Flamingo Las Vegas", "City of Westminster, London", "2016", "Wildhorn, Bricusse and Cuden", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Operation Watchtower", "Bishop's Stortford", "Starvation Is Motivation", "Michael Burger", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "the Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland, OR", "Yoruba", "Lucky", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "The Tenth Planet ( 1966 )", "The Stig", "Jehan Mubarak", "Medellin", "Joe Jackson", "alternative-energy vehicles", "2004", "genes", "Olive", "Stockholm"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6576140873015872}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.0, 0.4, 1.0, 0.7499999999999999, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.578125, "CSR": 0.5606249999999999, "EFR": 0.7777777777777778, "Overall": 0.6692013888888888}, {"timecode": 25, "UKR": 0.75390625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-2250", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2289", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2988", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-3901", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-4461", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-5382", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10227", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-1123", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2380", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-4562", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5539", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-6851", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-7609", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8023", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-9001", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9505", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-1258", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-1733", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-1800", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-2583", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2727", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2944", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3206", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3410", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3654", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-3745", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-39", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4046", "mrqa_newsqa-validation-4095", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-65", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-660", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-94", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-11385", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-12624", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-1335", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-14663", "mrqa_searchqa-validation-14883", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-16181", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3783", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-4857", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-7702", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-9090", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-9705", "mrqa_searchqa-validation-9756", "mrqa_squad-validation-10045", "mrqa_squad-validation-10069", "mrqa_squad-validation-10074", "mrqa_squad-validation-10086", "mrqa_squad-validation-10216", "mrqa_squad-validation-10228", "mrqa_squad-validation-10254", "mrqa_squad-validation-10310", "mrqa_squad-validation-10324", "mrqa_squad-validation-10338", "mrqa_squad-validation-10353", "mrqa_squad-validation-1036", "mrqa_squad-validation-10378", "mrqa_squad-validation-10477", "mrqa_squad-validation-1090", "mrqa_squad-validation-1320", "mrqa_squad-validation-1450", "mrqa_squad-validation-1603", "mrqa_squad-validation-1636", "mrqa_squad-validation-1672", "mrqa_squad-validation-1694", "mrqa_squad-validation-178", "mrqa_squad-validation-1802", "mrqa_squad-validation-1852", "mrqa_squad-validation-1855", "mrqa_squad-validation-1857", "mrqa_squad-validation-1938", "mrqa_squad-validation-1967", "mrqa_squad-validation-2040", "mrqa_squad-validation-2126", "mrqa_squad-validation-2153", "mrqa_squad-validation-2216", "mrqa_squad-validation-2289", "mrqa_squad-validation-2384", "mrqa_squad-validation-2400", "mrqa_squad-validation-2436", "mrqa_squad-validation-2460", "mrqa_squad-validation-2477", "mrqa_squad-validation-255", "mrqa_squad-validation-2577", "mrqa_squad-validation-2602", "mrqa_squad-validation-2619", "mrqa_squad-validation-268", "mrqa_squad-validation-2693", "mrqa_squad-validation-2773", "mrqa_squad-validation-2782", "mrqa_squad-validation-2798", "mrqa_squad-validation-282", "mrqa_squad-validation-2824", "mrqa_squad-validation-285", "mrqa_squad-validation-2929", "mrqa_squad-validation-3019", "mrqa_squad-validation-3041", "mrqa_squad-validation-3135", "mrqa_squad-validation-3185", "mrqa_squad-validation-320", "mrqa_squad-validation-3337", "mrqa_squad-validation-3476", "mrqa_squad-validation-353", "mrqa_squad-validation-3589", "mrqa_squad-validation-3709", "mrqa_squad-validation-383", "mrqa_squad-validation-3931", "mrqa_squad-validation-3948", "mrqa_squad-validation-3955", "mrqa_squad-validation-397", "mrqa_squad-validation-3993", "mrqa_squad-validation-4005", "mrqa_squad-validation-4079", "mrqa_squad-validation-4140", "mrqa_squad-validation-415", "mrqa_squad-validation-4181", "mrqa_squad-validation-427", "mrqa_squad-validation-4291", "mrqa_squad-validation-4305", "mrqa_squad-validation-4333", "mrqa_squad-validation-4338", "mrqa_squad-validation-4472", "mrqa_squad-validation-462", "mrqa_squad-validation-4686", "mrqa_squad-validation-4704", "mrqa_squad-validation-4835", "mrqa_squad-validation-4856", "mrqa_squad-validation-4870", "mrqa_squad-validation-5054", "mrqa_squad-validation-5088", "mrqa_squad-validation-5096", "mrqa_squad-validation-5154", "mrqa_squad-validation-5176", "mrqa_squad-validation-5238", "mrqa_squad-validation-5302", "mrqa_squad-validation-5326", "mrqa_squad-validation-5376", "mrqa_squad-validation-550", "mrqa_squad-validation-5537", "mrqa_squad-validation-5541", "mrqa_squad-validation-5588", "mrqa_squad-validation-5616", "mrqa_squad-validation-5672", "mrqa_squad-validation-5703", "mrqa_squad-validation-5767", "mrqa_squad-validation-5777", "mrqa_squad-validation-5913", "mrqa_squad-validation-60", "mrqa_squad-validation-60", "mrqa_squad-validation-607", "mrqa_squad-validation-6099", "mrqa_squad-validation-6126", "mrqa_squad-validation-6143", "mrqa_squad-validation-6178", "mrqa_squad-validation-6220", "mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6362", "mrqa_squad-validation-6395", "mrqa_squad-validation-6414", "mrqa_squad-validation-6564", "mrqa_squad-validation-660", "mrqa_squad-validation-6641", "mrqa_squad-validation-6737", "mrqa_squad-validation-6754", "mrqa_squad-validation-6782", "mrqa_squad-validation-68", "mrqa_squad-validation-6817", "mrqa_squad-validation-6915", "mrqa_squad-validation-696", "mrqa_squad-validation-7018", "mrqa_squad-validation-703", "mrqa_squad-validation-7069", "mrqa_squad-validation-707", "mrqa_squad-validation-7150", "mrqa_squad-validation-7161", "mrqa_squad-validation-7180", "mrqa_squad-validation-7198", "mrqa_squad-validation-7260", "mrqa_squad-validation-7399", "mrqa_squad-validation-754", "mrqa_squad-validation-7552", "mrqa_squad-validation-7597", "mrqa_squad-validation-7640", "mrqa_squad-validation-765", "mrqa_squad-validation-7678", "mrqa_squad-validation-7770", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-7856", "mrqa_squad-validation-7882", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-804", "mrqa_squad-validation-8056", "mrqa_squad-validation-8104", "mrqa_squad-validation-8115", "mrqa_squad-validation-8189", "mrqa_squad-validation-8226", "mrqa_squad-validation-8226", "mrqa_squad-validation-8285", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8527", "mrqa_squad-validation-8629", "mrqa_squad-validation-8735", "mrqa_squad-validation-8760", "mrqa_squad-validation-8765", "mrqa_squad-validation-8832", "mrqa_squad-validation-884", "mrqa_squad-validation-8867", "mrqa_squad-validation-890", "mrqa_squad-validation-8957", "mrqa_squad-validation-898", "mrqa_squad-validation-9031", "mrqa_squad-validation-9066", "mrqa_squad-validation-9135", "mrqa_squad-validation-9186", "mrqa_squad-validation-9227", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9391", "mrqa_squad-validation-9392", "mrqa_squad-validation-9465", "mrqa_squad-validation-9504", "mrqa_squad-validation-9541", "mrqa_squad-validation-9552", "mrqa_squad-validation-9652", "mrqa_squad-validation-9658", "mrqa_squad-validation-9771", "mrqa_squad-validation-979", "mrqa_squad-validation-9818", "mrqa_squad-validation-987", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2626", "mrqa_triviaqa-validation-2685", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-3051", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-4107", "mrqa_triviaqa-validation-4171", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-4440", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-5568", "mrqa_triviaqa-validation-5671", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6290", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-6909", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-71", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-7548", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-776"], "OKR": 0.765625, "KG": 0.42890625, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater in Dessau", "Anna Clyne", "Terence Winter, based on the memoir of the same name by Jordan Belfort.", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Jonghyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "American", "Acid house", "end of the 18th century", "Capture of the Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage on TV, radio and online.", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles", "PBS", "second largest", "Citric acid", "1989", "Lola Dee", "\"The Five\"", "Walt Disney Feature Animation", "The club will participate in the Premier League, FA Cup, EFL Cup (as holders), UEFA Champions League and UEFA Super Cup.", "torpedoes", "1972", "Geographical Indication tag", "Ringo Starr", "Cleveland Celtics", "World Championship Wrestling", "2003", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "Tax Reform Act of 1986", "Henry Louis", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram", "Homo erectus", "In honor of the man who made the generous gifts,", "green"], "metric_results": {"EM": 0.671875, "QA-F1": 0.70546875}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.671875, "CSR": 0.5649038461538461, "EFR": 0.8095238095238095, "Overall": 0.6645730311355311}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "Sleeping Beauty", "Orchard Central", "Robert Downey, Jr.", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool and the England national team", "port city of Aden", "British", "Prince Louis of Battenberg", "1985", "Archie Andrews", "before", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cleveland", "goalkeeper", "Debbie Harry", "media for the 65.8 million", "John Joseph Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "racehorse breeder and owner", "Summerlin, Nevada", "1919", "Kevin Spacey", "Love Streams", "Michael Edwards", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "New Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music and English folk-song", "Hexachrome", "1600 BC", "Frank Oz", "1963", "a palla", "Car ferry", "the Wye", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan", "Japan", "postcards"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6503977793040292}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-1617", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_newsqa-validation-4143"], "SR": 0.5625, "CSR": 0.5648148148148149, "EFR": 0.7142857142857143, "Overall": 0.6455076058201058}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "particular skills", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "Fall 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Sir Matthew Alistair Grant", "her most awarded female act of all-time", "Player's No 10, Skol, Leyland Cars,auntlet, Daily Mirror, TNT Sameday and Dunlop", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "\"40 Days and 40 Nights\"", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Westerister", "Kalokuokamaile", "Raden Panji Nugroho Notosusanto", "Itchy Itchiford", "2007", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "Double Crossed", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch Kiss M1914 machine gun", "Steve Kiley, M.D.", "Prussian army general, adjutant to Frederick William IV of Prussia", "January 2004", "co-founder and lead guitarist", "\"# HappyHolograms\"", "seven species", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "syrupy", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "bromide", "nasal septum", "American"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6472537239806977}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, false], "QA-F1": [0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 0.923076923076923, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-873", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_triviaqa-validation-2520", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.5625, "CSR": 0.5647321428571428, "EFR": 0.8214285714285714, "Overall": 0.6669196428571429}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools and day schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF) beginning in 1985 to promote advanced research and education networking in the United States", "Herrenhausen Palace, Hanover", "Henry Mancini", "altaic", "Gordon Ramsay", "Ronald Reagan", "Adrian Cronauer", "surreptitiously, discreetly, furtively, clandestinely,", "Rameses II (Yul Brynner)", "Anna (Julia Roberts)", "a scythe", "balsam fir (Abies balsamea)", "Paddy Doherty", "severest", "efore C ommon E ra", "Libya", "Etta James", "WoO", "Khomeini", "Daniel Peggotty", "William Hickey", "Count de La F\u00e8re", "April", "Eric Morley", "hypertension", "the Garrick Club", "Belle", "Fabio Capello", "Fort George", "Marc Norman", "The Greatest", "a Dutchman", "the British charts", "a habanero", "tenor saxophone", "Seattle", "The Cross Foxes Inn", "Llanishen", "Baton Rouge", "a 'Weber', or a 'Zenith", "Tahrir Square", "Romanian", "a bathtub curve", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "a small species of foraging mammal", "Greek", "Passion fruit", "Grace Zabriskie", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "December 6, 1941", "North America", "Florida's Everglades", "Michael Jackson", "consistent and accessible", "a street or", "Glengarry Glen Ross", "Sharks"], "metric_results": {"EM": 0.328125, "QA-F1": 0.4084201388888889}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.28571428571428575, 0.21428571428571427, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.888888888888889, 0.7499999999999999, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-3804", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2216", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-2313", "mrqa_triviaqa-validation-6096", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-1222", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-15919"], "SR": 0.328125, "CSR": 0.556573275862069, "EFR": 0.7441860465116279, "Overall": 0.6498393644747393}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Cleveland Celtics", "James W. Marshall", "in florida it is illegal to sell alcohol before 1 pm on any sunday", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Thompson", "between 8.7 % and 9.1 %", "2018, the first day of the Lunar New Year was on Friday, 16 February, initiating the year of the Dog", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "status line", "retina", "tom Brady", "Triple Alliance of Germany, Austria - Hungary, and Italy", "Andrew Lloyd Webber", "1955", "Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar worth close to 5,770 guaranies", "the original Star Trek television series", "1936, when she was 10 years old", "Meg Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "jennie calvano", "in 1995, California was the first state to enact a statewide smoking ban ; throughout the early to mid-2000s, especially between 2004 and 2007", "Everywhere", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Cairo, Illinois", "in the 1970s and'80s, primarily in wind turbines and photovoltaics and increased use of hydroelectricity, presented some of the first sustainable alternatives to fossil fuel and nuclear energy generation", "Hebrew Bible", "Earl ( John Doe )", "one of the seven heavenly virtues typically said to date back to", "January 2, 1971", "The Miracles", "Eukarya", "elbow", "hershey Hurricane", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "27", "Pakistan", "Romney", "rock", "breastbone (sternum), or in your neck, arms, abdomen or chest in lung, liver, kidney or heart", "bronchitis"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5891198165869218}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.45454545454545453, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09523809523809523, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.546875, "CSR": 0.55625, "EFR": 0.7931034482758621, "Overall": 0.6595581896551723}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "tourism", "a circle", "fern", "Marvel's Guardians of the Galaxy", "the Spanish Republic", "taxicab", "coyote", "(PVM)", "Harry Mason Reid", "Ray", "axis", "forge", "Wolfgang", "julmi lebret", "floweringbomb", "\"Blackbird\"", "footprints", "Caliban", "LA Kings", "enumerations", "Tommy Lee Jones", "zacchaeus", "(9780786276929)", "(1876)", "hubris", "Yahtzee", "Tony Danza", "XML", "hives", "74.3", "William S. Hart", "(Sahih al-Bukhari, Volume 1, Book 8, Number 367)", "Pride and Prejudice", "The Secret Family of Jesus", "kosher brand", "Munich", "Michael Jordan", "feria Marmotae Monacis", "Prospero", "Zefram Cochrane", "parrots", "dough", "kyushu", "honey", "Boston", "Mattel", "Arctic Ocean", "the Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "1935", "Harlow Cuadra and Joseph Kerekes", "Newton's book \"Principia\"", "Israel", "ceo Herbert Hainer", "Intel is not the first tech company to be hit by the European Commission."], "metric_results": {"EM": 0.5, "QA-F1": 0.5619791666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, false, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-5655", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-5162", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3915"], "SR": 0.5, "CSR": 0.5544354838709677, "EFR": 0.875, "Overall": 0.6755745967741935}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Kramer's caddy Stan", "Christian Kern", "January 21, 2016", "Bloomingdale Firehouse", "elise Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge", "Bangkok, Thailand", "Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "17 September 1962", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Mercury Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland County", "Slaughterhouse-Five", "Shohola Falls", "wine", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Massapequa, New York", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University", "Blue Grass Airport", "Kenneth Hood \"Buddy\" MacKay Jr.", "1952", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Air Force", "Isabella Palmieri", "Hathi Jr", "1935", "geryon", "slow", "The Miracles", "the Moffat Tunnel", "Microsoft", "Friday", "the High Plains area", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.625, "QA-F1": 0.6747996794871796}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, false, false, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-2088", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_hotpotqa-validation-2554", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6898", "mrqa_searchqa-validation-6055"], "SR": 0.625, "CSR": 0.556640625, "EFR": 0.9166666666666666, "Overall": 0.6843489583333333}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "American Gangster (2007)", "Argentina", "Apollo 7", "jellyfish", "March", "a leather shoe", "fauntleroy", "the World Health Organization", "Eat porridge", "Kofi Annan", "chlorophyll", ", there were twelve London newspapers and 24 provincial papers by the 1720s (the Daily Courant was the first daily newspaper in London).", "Taggart", "Han Solo", "the Gulf of Mexico", "Manfred Mann", "Frank Keogh", "Barry Taylor", "the Mississippi River", "Brussels", "Flora MacDonald", "John Poulson", "Orly", "the euro", "Superintendent Norman Mullet", "Saskatchewan (province)", "Laurent Planchon", "the Solent", "vomiting", "Basketball Page 30", "Bristol Aeroplane Company", "Spinach", "Jason Rissman", "\u201cArgo\u201d", "Libra", "Surrey", "1969", "fosse Way", "In Budapest, a 2.5-mile (4-kilometre) electric subway was opened in 1896", "Chile", "William Shakespeare", "borax (sodium tetraborate decahydrate, Na2B4O7\u221910H2O)", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Diana Dors", "Kent", "Vickers-Armstrong's", "Ray Charles", "Rigor mortis is very important in meat technology", "United States customary units", "Miller Brewing", "northwestern Italian coast", "the Peninsula in Melbourne", "without loved ones, without homes, without life's belongings.", "her decades-long portrayal of Alice Horton on the soap opera \" Days of our Lives,\"", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\" Kristal Kraft, a real estate agent in Denver, says.", "Peter Bogdanovich", "the mourning dove", "Germany"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5331926351933974}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, true, false, true, true, false, false, true, true, false, false, false, false, false, true, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 0.0, 0.0, 0.7000000000000001, 0.0975609756097561, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7108", "mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-2177", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.46875, "CSR": 0.5539772727272727, "EFR": 0.6764705882352942, "Overall": 0.6357770721925133}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "No Secrets", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown, Ph. D.", "the Arctic Ocean", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "swordfish, tuna, halibut, sablefish", "Jesus'birth", "a habitat", "irsten Simone Vangsness", "Central Germany ( German : Mitteldeutschland ) is an economic and cultural region in Germany", "Andrew Johnson", "Bart Cummings, regarded as the best Australian horse trainer of all time, went on to win 12 Melbourne Cups to 2008", "Aegisthus", "electors", "Julia Ormond", "Sauron", "1961", "Mike Mushok", "2013", "March 1", "novelization", "iron ( III ) oxide - hydroxide ( FeO (OH )", "Spain disputes the legality of the constitution and claims that it does not change the position of Gibraltar as a colony of the UK with only the UK empowered to discuss Gibraltar matters on the international scene", "Steffy Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "paid monument", "erosion", "March 2, 2016", "turkey", "1996", "Ray Charles", "16", "the Ramones", "The original building was completed in 1800", "Anglo - Norman French waleis", "Ted '' Levine", "New Jersey", "May 2010", "France", "Heath Ledger", "Wilson Pickett", "a centaur", "music lover who must work for a kingpin", "cricket fighting", "Luis Edgardo Resto", "The drama of the action in-and-around the golf course", "German authorities", "Islamabad", "Tunisia", "RAND Corporation", "alberta"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5533414926924849}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 0.5, 0.125, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 0.6666666666666666, 0.3076923076923077, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.06451612903225806, 0.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.46875, "CSR": 0.5514705882352942, "EFR": 0.6764705882352942, "Overall": 0.6352757352941176}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Zeebo", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions forms the joint venture Bullwinkle Studios", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "prophets and beloved religious leaders", "state legislators of Assam", "enzymes break down the long chains of amino acids", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "constant pressure", "`` mind your manners ''", "Germany", "20 November 1989", "Tom\u00e1s de Torquemada", "Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "first published in the United States by Melvil Dewey in 1876", "2003", "Sebastian Lund ( Rob Kerkovich )", "Wednesday, 5 September 1666", "Pebble Beach", "The management team", "in various submucosal membrane sites", "business applications to be developed with Flash", "Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "braking to a full stop", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Tennessee Titan", "21 July 1983", "a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "future AC/DC founders Angus Young and Malcolm Young", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "just before her", "Henry Ford", "Toyota", "a politician", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread, so they're usually classed as benign."], "metric_results": {"EM": 0.484375, "QA-F1": 0.6241676501778872}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.13793103448275862, 1.0, 0.5, 1.0, 1.0, 0.7499999999999999, 0.3333333333333333, 0.45714285714285713, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.375, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.3571428571428571, 0.7000000000000001, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.2758620689655173, 0.5, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.484375, "CSR": 0.5495535714285714, "EFR": 0.5757575757575758, "Overall": 0.6147497294372294}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "a supposed mild euphoric,", "James McConkey", "Venezuela", "Mexico", "boxing", "Peter Pan", "ilkymandias", "Arctic Ocean", "a thermos bottle", "dams", "Gilbert du Motier", "Louis Farrakhan", "doldrums", "Village People", "Alexander Pushkin", "Australia", "the Munich Crisis", "Mexico", "8-hour", "papacy", "Arkansas River Valley", "a typical day in the life of the Beatles", "Pierre-August Renoir", "alex", "libretti", "Innsbruck", "L Angeles Superior Court Judge Lance A. Ito", "Microsoft", "petticoat", "Sony and Japanese Business Leader", "Norse seafarers", "Atlantic City's Boardwalk", "Blackwater USA", "elephants", "American Airlines", "ibex", "Odysseus", "Quizlet", "Kensington Palace", "the Overland Flyer", "Netherlands", "Pocahontas", "schools", "Dagny Taggart", "a sound augmented fabric", "Chicago Mercantile Exchange", "Las Vegas", "ballet shoes", "wheat", "Madrid Symphony Orchestra", "ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn Castle", "psychological horror", "John Morgan", "second", "Eleanor of Aquitaine", "Senate Democrats", "63", "we are resetting"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5143105158730159}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, false, false, true, false, true, false, true, false], "QA-F1": [0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.16666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-10308", "mrqa_searchqa-validation-16094", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3372", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.4375, "CSR": 0.5464409722222222, "EFR": 0.8888888888888888, "Overall": 0.6767534722222222}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "the Earth's axial tilt, which fluctuates within a margin of 2 \u00b0 over a 40,000 - year period, due to tidal forces resulting from the orbit of the Moon", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act", "User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "the National September 11 Memorial plaza", "Southend Pier", "Santa Monica", "layered systems of sovereignty", "Will", "31 January 1934", "Filipino American", "1773", "RAM", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Raghuwanshi dynasty", "Olivia Olson", "1990", "Nickelback", "Bill Pullman", "BC Jean and Toby Gad", "never made", "Frankie Muniz", "stratum lucidum", "60 by West All - Stars", "Hasmukh Adhia", "four", "retinal ganglion cell axons and glial cells", "the 1980s", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "card verification value", "commands Titus to ordain presbyters / bishops and to exercise general oversight, telling him to `` rebuke with all authority '' ( Titus 2 : 15 )", "bohrium", "Germany", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum", "Mike Czerwien", "As of July 2017, there were 103 national parks encompassing an area of 40,500 km ( 15,600 sq mi )", "Vienna", "English", "Africa", "French Foreign Minister Pierre Laval", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities", "cotton", "Dennis Haysbert", "Quinn", "The Weatherbys Novices' Hurdle Race"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6415575153153639}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.12903225806451613, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.22222222222222224, 1.0, 0.21052631578947367, 0.1, 0.5517241379310345, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-6237", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-1028", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161", "mrqa_triviaqa-validation-5460"], "SR": 0.5625, "CSR": 0.546875, "EFR": 0.7142857142857143, "Overall": 0.6419196428571429}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "b\u00e2ton", "South Africa", "first among equals", "shine", "a cappella", "albinism", "st Peter's Field", "aglets", "Saturday Night Live", "FC Bayern M\u00fcnchen", "equinoxes and solstices", "Bonnie and Clyde", "brazil", "copper", "Dawn French", "Stars Gone Too Soon", "Latin", "Doris Lessing", "Scooby-Doo", "Swaziland", "the Sidgwick Avenue arts faculty buildings", "Kent", "Humber", "points based scoring system", "a new dimension in seating", "Kent", "Rodgers and Hammerstein", "the British public", "Galileo Galilei", "Mata Hari", "Scotland Yard detective", "Marilyn Manson", "Medellin", "The Tempest", "spark-ignition", "brazilia", "Boulder Dam", "the long-term effects of using drugs", "Iraq", "Belle de Jour", "bognor Regis", "Abba", "a geologic episode, change, process, deposit, or feature that is the result of the action or effects of rain", "white", "Asaph Hall", "France", "geena Davis", "kunsky", "death and dying", "Bryan Anderson", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "heavy turbulence", "different women coping with breast cancer in five vignettes.", "Blaine", "a sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5769870448179272}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false, false, true, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-3349", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6503", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.546875, "CSR": 0.546875, "EFR": 0.7586206896551724, "Overall": 0.6507866379310345}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "tyne", "the liver", "40", "table salt", "water", "Bolivia", "ch.1, p. 49-50", "gulliway", "Stevie Wonder", "mesocephalic", "hound", "hanover", "stars", "Earl of Strafford", "work", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "a man of gold", "a 1934 Austin seven box saloon", "Paul Anka", "Carthage", "bristol", "the king Duncan", "Blade Runner", "Jay-Z", "leopons", "cymbals", "\u201cSanta Buddies\u201d", "La traviata", "Tory MP Andrew Mitchell", "flore", "South Africa", "Christian Dior", "scrobbesbyrig", "killer whale", "Ukrainian", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "baron", "lizard", "a submarine", "frauds", "a sea horse", "even numbers", "Tony Blair", "quartz or feldspar", "54 Mbit / s", "Manley", "Stacey Kent", "\"Traumnovelle\" (\"Dream Story\")", "Anthony Lynn", "piano", "tribute", "the women without feeling that its legal system has been slighted, according to analyst Mike Chinoy.", "French Guiana", "AOL", "arms belonging to members of the same family", "tournament leader Jean Van de Velde"], "metric_results": {"EM": 0.5, "QA-F1": 0.5401785714285714}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, false, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-2097", "mrqa_triviaqa-validation-1112", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_hotpotqa-validation-2852", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.5, "CSR": 0.5456730769230769, "EFR": 0.84375, "Overall": 0.6675721153846153}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Olivo", "Midnight Cowboy", "alfa", "seborrheic dermatitis", "nepothea", "steam engines", "Niger", "central Stockholm", "Tangled", "dogs", "James Douglas", "Bulls Eye", "barry Edward O'Meara", "Laurent Planchon", "Martin Clunes", "charles Darwin", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "John Mellencamp", "isambard Kingdom Brunel", "greece", "1957", "watcher", "carles", "butter and oil", "moctes", "Ralph Vaughan Williams", "musical scale", "cats", "heart", "e. T. A. Hoffmann", "Shanghai", "Spain", "grow", "Tuesday", "Guru Nanak", "ch.1, p. 49-50", "Harry Potter", "phosphorus", "little Jack Horner", "in Indianapolis", "humbert Humbert", "cuckoo", "Mr. Stringer", "Ford", "Alice Cooper", "minorca", "red blood cells", "Royal Bengal Tiger", "inward spiral where it would eventually cross the event horizon", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "\"The Cycle of Life,\"", "forgery and flying without a valid license", "137", "a log cabin", "St. Patrick's Day", "defensive backs", "Sondheim"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4654017857142857}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6497", "mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-2142", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2738", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.40625, "CSR": 0.5421875, "EFR": 0.8157894736842105, "Overall": 0.6612828947368421}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players-Lasky", "Washington", "Thomas De Quincey", "black death", "a small draught horse, around three-fourths of a ton, and is without feathered legs", "buffalo", "devian", "a dove", "Sarajevo", "the Bill of Rights", "fine", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "origami", "resistance of an unknown resistor", "Arabian Gulf", "secretary", "devon", "matricide", "christian tj smith (3)", "\u201cthat\u201d to a \u201cwhich,\u201d", "a linesider", "Tomorrow Never Dies", "Sudan", "a Great Dane", "Washington", "Angola", "New Hampshire", "James I", "charlie Fenton", "Philippines", "purple", "everyhit", "warblers", "a 965-foot ocean liner", "Rome", "10", "Southwest Airlines", "phone", "Jeffery Deaver", "The Comedy of Errors", "charlie j. Kelly", "Glyn Jones", "President Clinton", "cheviles", "devian", "radicalization", "Frederic Robinson Ltd", "his friends, Humpty Dumpty and Kitty Softpaws", "August 18, 1998", "Tanvi Shah", "EN World web site", "the 100th anniversary of the first \" Tour de France\" bicycle race", "Mach number", "Janet and La Toya", "more than 2.5 million", "researchers", "the Matrix", "Curb Your Enthusiasm", "nibelung", "inequality of opportunity related to gender was low in Europe and Central Asia but medium to high in respect of labour practices, employment and entrepreneurship and in access to finance"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4981266996891997}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.5, 0.0, 1.0, 1.0, 0.15384615384615385, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.18181818181818182]}}, "before_error_ids": ["mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-4171", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7346", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.421875, "CSR": 0.5392530487804879, "EFR": 0.7027027027027027, "Overall": 0.6380786502966381}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "hula hoops", "nippon", "chobus", "roddy Doyle", "a counting table", "Robin Hood Men in Tights", "\u00c6olus", "Diego Velazquez", "South African", "maracaibo", "ottiania", "tchaikovsky", "Oliver Twist", "Scotland", "ching", "David Bowie", "Buzz Aldrin", "jean-Paul sartre", "mojcie", "vince Hawkins", "roost", "Jennifer Aniston", "wales", "tbilisi", "chlub-turned-superhero Chris Pratt", "othello", "a leak", "Glenn Close", "Lacock Abbey", "alex b'Stard", "cat", "Anita Brookner", "manasseh", "Margaret Thatcher", "the Black Sea", "bagram Theater Internment Facility", "Susie Dent", "a power surge", "Vienna", "The Archers", "shylock", "s. ochs", "henry gee", "John Mellencamp", "soprano voice provided lead vocals", "Marx Brothers", "aire", "pracy/Habsburg Monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "18 - season", "1993 to 1996", "James Gandolfini", "September 29, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones", "tuba", "the o.K. Corral", "butternut squash", "a walled, high area containing fortifications"], "metric_results": {"EM": 0.40625, "QA-F1": 0.48073699874686715}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.3333333333333333, 0.10526315789473685, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-2886", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-2625", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.40625, "CSR": 0.5360863095238095, "EFR": 0.8947368421052632, "Overall": 0.6758521303258145}, {"timecode": 42, "before_eval_results": {"predictions": ["epidemiological account", "some work rule issues", "HSH Nordbank Arena", "Comoros Islands", "a public-television show", "Jeddah, Saudi Arabia", "40", "sad", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "when he left behind a fortune that was estimated in the millions", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "Dancy-Power Automotive Group showroom", "Michoacan Family", "64", "house arrest", "fastest circumnavigation of the globe in a powerboat", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career at his original club of Argentinos Juniors in 2007 and has been coaching at Independiente.", "\"E! News\"", "Washington", "Madeleine K. Albright", "ice jam", "toxic smoke from burn pits", "zulfikar Ali Bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "cal Ripken Jr.", "at a relative's house", "cancer", "acid", "former boxing champion Vernon Forrest", "if drugs are funding the insurgency, NATO has a self-interest in supporting Afghan forces in destroying drug labs, markets and convoys", "one", "comfort those in mourning", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m.", "former Mobile County Circuit Judge Herman Thomas", "we say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well", "body", "\"release\" civilians", "Dodi Fayed", "one day we will have no more oil and we'll have to find another way to live", "there is a decline in population density", "Barcelona", "emperor Cuauhtemoc", "korea", "misery", "kenn purdy", "Antonio Lippi", "Thorgan", "River Clyde", "chile", "jim", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.34375, "QA-F1": 0.46380620014931073}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8000000000000002, 1.0, 0.923076923076923, 0.4, 1.0, 1.0, 0.0, 0.2857142857142857, 0.4444444444444445, 1.0, 0.08333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.13333333333333333, 1.0, 1.0, 0.28571428571428575, 0.0, 0.6, 0.14545454545454548, 0.4, 1.0, 0.3636363636363636, 0.08695652173913045, 0.11764705882352942, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4897", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-588", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-30", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-3948", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-5597", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.34375, "CSR": 0.5316133720930232, "EFR": 0.8095238095238095, "Overall": 0.6579149363233665}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.", "1943", "Volvo 850", "the Mountain West Conference", "the National Basketball Association", "Western Europe", "political thriller", "Schaeffler Technologies AG & Co.  KG", "the Championship", "1989 until 1994", "Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown", "Lollywood and Pollywood films", "Emmanuel Ofosu Yeboah", "Attack the Block", "Bhushan Patel", "1986", "1964", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs.", "1988", "coaxial", "Northern Lights", "three different covers", "Malayalam cinema", "Regno di Dalmazia", "1946", "Vincent Landay", "September 6, 1967", "Estadio de L\u00f3pez Cort\u00e1zar", "Brian A. Miller", "Nicolas Vanier", "1985", "Gal Gadot", "Amy Jessicaup", "Texas Raiders", "Bremen, Germany", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "Trade Mark Registration Act 1875", "blue", "elbow", "members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6806403514963297}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.6, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5714285714285715, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-2823", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070"], "SR": 0.609375, "CSR": 0.5333806818181819, "EFR": 0.72, "Overall": 0.6403636363636364}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "1954", "sexy Star", "Conservatorio Verdi", "President of the United States", "the backside", "Angelo Bruno", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "January 11, 2016", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kiss", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool F.C.  Blackpool Football Club", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Division of Fawkner", "Socrates", "American singer Toni Braxton", "Hindi", "Michael Manasseri", "Irish Chekhov", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "1972", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Variations", "last summer", "almost 100", "the Southeast", "the jeffersons tv show", "Myra", "her own account of her life, still exists,", "One Direction"], "metric_results": {"EM": 0.578125, "QA-F1": 0.670343137254902}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-3263", "mrqa_searchqa-validation-12050"], "SR": 0.578125, "CSR": 0.534375, "EFR": 0.8518518518518519, "Overall": 0.6669328703703703}, {"timecode": 45, "before_eval_results": {"predictions": ["American Revolution", "a proof reader", "Elizabeth II", "the Belgae", "Northern Exposure", "sugar", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "putt-putt", "Wolf Blitzer", "Punxsutawney, Pennsylvania", "Pressburg", "yellow fever", "sea otter", "MMs", "\"franchise\"", "rod", "the Nixon scandal", "dressage", "astronomer", "Mickey Mouse", "stigma", "Associate Professor", "a measuring stick", "Medusa", "a spiral", "Prince Attab", "staff", "Voyager 1", "Farsi (Persian)", "insulin", "objects", "China", "Menelaus", "fish", "Peace Sign", "An Old Man, a Young Man", "English Monarchs These 2", "Rajasthan", "Ben Kingsley", "lobsters", "NHL", "zenith", "White bread and butter", "chairperson", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London", "Isle of Wight", "a Peppercorn class", "Queen In-hyun's Man", "Oneida Limited", "James Ager", "Libreville, Gabon", "tickets to Italy", "the station", "Cahawba"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6149553571428571}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1744", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_triviaqa-validation-888"], "SR": 0.53125, "CSR": 0.5343070652173914, "EFR": 0.8, "Overall": 0.6565489130434783}, {"timecode": 46, "before_eval_results": {"predictions": ["\"degrees of privilege\" to which they were entitled institutionally and legally,", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "room the book store", "faggots", "a skein, a team, or a wedge", "Zenyatta", "Pluto", "Jackson Street", "the Taklamakan Desert", "Arabian Sea", "Astronaut", "the Great Victoria Desert", "German state of North Rhine-Westphalia", "Carole King", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "snakes", "Sedgefield in North East England", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "a trenches exhibition", "South Korea", "pig", "sequel, maybe", "surreal", "Kenya", "Stephen Potter", "Casa di Giulietta", "Anwar Sadat", "a hundred", "the Susquehanna River", "Bolivia", "darth vader", "Frankfurt", "chipmunk", "Goldie Hawn", "pulsar", "Belgium", "a horses life, and the friendships", "maple", "Benfica", "Sun Lust Pictures", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Harvard Law School", "11 healthy eggs", "Twilight", "the Carrousel du Louvre", "Speed Racer", "the Time Machine", "Queen Elizabeth II", "Sir Walter Scott"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5968005952380953}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, false, false, true, true, false, false, false, true], "QA-F1": [0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-6115", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-3654", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_hotpotqa-validation-1392", "mrqa_newsqa-validation-4025", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788", "mrqa_searchqa-validation-14284"], "SR": 0.515625, "CSR": 0.5339095744680851, "EFR": 0.8387096774193549, "Overall": 0.664211350377488}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "at Sunset", "Sinclair Lewis", "Buck James", "The World is Not Enough", "pigments", "Anthony Hopkins", "V\u00e1clav Havel", "Dick Van Dyke", "isabella", "Tina Turner", "2010", "portrush", "glasses", "perfumer", "Duke Orsino", "magnetite", "Copenhagen", "Lord Sugar", "cargo", "orphism", "sahara", "Commonwealth Scientific and Industrial Research Organisation", "eukharistos", "Charlotte's Web", "Octopussy", "silks", "William Randolph Hearst", "Lorne Greene", "rowing", "Corin Redgrave", "call my Bluff", "star", "Argentina", "Frank McCourt", "milk or water", "Debbie McGee", "LDV", "starch", "Pears soap", "Donna Summer", "balustrade", "nottingham", "Poland", "the Welcome Stranger", "taggart", "April", "Chechnya", "a police janitor", "a-team", "football", "1,281,900 servicemembers", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough", "South Australian Championships", "beautiful", "Eleven people", "Michelle Obama", "kbenhavn", "Communist Manifesto", "saara", "Floxin"], "metric_results": {"EM": 0.5, "QA-F1": 0.5338541666666666}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-5096", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-366", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-15651"], "SR": 0.5, "CSR": 0.533203125, "EFR": 0.96875, "Overall": 0.690078125}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "Thored, Earl of southern Northumbria", "creature comforts", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air", "Mineola", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "physical", "1988", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Ishtar Gate", "Ford Falcon", "Southern State Parkway", "The Company", "17 December 177026 March 1827", "Kim Bauer", "approximately $700 million", "Edward James Olmos", "Bury St Edmunds", "Prussian", "O", "Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard", "45th Infantry Division", "2009", "5", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "1848", "Texas Tech University", "John McClane", "Larry Gatlin & the Gatlin Brothers Band", "924", "371.6 days", "Piedmont", "Selinsgrove", "Countess of Lovelace", "first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "Challenger", "basil", "clio Awards", "The Rosie Show", "Current TV", "well over 1,000 pounds", "octavian", "Desert basin", "Congress", "thylakoid membranes"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7193241654179154}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, true], "QA-F1": [0.25, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.5, 0.0, 0.0, 0.0, 0.8571428571428571, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-515", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-4119", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028", "mrqa_searchqa-validation-5430"], "SR": 0.640625, "CSR": 0.5353954081632653, "EFR": 0.8695652173913043, "Overall": 0.6706796251109138}, {"timecode": 49, "UKR": 0.7578125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2339", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5755", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-2999", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-60", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3155", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5788", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6000", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-888", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-92"], "OKR": 0.728515625, "KG": 0.48125, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Sam Roberts Band, The Trews, someKinda Wonderful, and Saintseneca", "joined the utopian Ascona community", "John W. Henry", "Mos Def", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Love Hina", "Odisha", "novelty songs, comedy, and strange or unusual recordings dating from the early days of phonograph records to the present.", "OutKast", "five aerial victories", "Alain Robbe-Grillet", "the Seasiders", "musical research", "Dragon TV", "Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "February 20, 2011", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Eminem, Bad Meets Evil, Akon, Christina Aguilera and Taio Cruz", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "Golden Globe Award", "Avoca Lodge", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "Fleetwood Mac", "the birth centenary of Pandit Jawaharlal Nehru", "Honda", "Adam Smith", "Republic of Upper Volta", "56", "Nkepile M abuse", "Eintracht Frankfurt", "fort at the Derna harbor", "Hephaestus", "Amherst College", "200 registered players"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6263418196225858}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.21052631578947367, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-1259", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.546875, "CSR": 0.535625, "EFR": 0.7931034482758621, "Overall": 0.6592613146551725}]}