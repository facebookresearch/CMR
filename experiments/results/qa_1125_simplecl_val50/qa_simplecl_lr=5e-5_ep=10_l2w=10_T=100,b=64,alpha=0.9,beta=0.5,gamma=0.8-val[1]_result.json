{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 2040, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "the 1970s", "Sunni Arabs from Iraq and Syria", "Graph isomorphism", "Daniel Burke", "the highest terrace", "major national and international patient information projects", "three", "net force", "12 January", "1976\u201377", "The E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "One could wish that Luther had died before ever", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "fossils", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.75, "QA-F1": 0.800077322595705}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_squad-validation-5178", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.75, "CSR": 0.7578125, "EFR": 0.9375, "Overall": 0.84765625}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "beat so that the propulsion stroke is away from the mouth, although they can also reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "the United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "Warsaw Stock Exchange", "390 billion individual trees divided into 16,000 species", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "the geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025 housing units", "13 May 1899", "Lunar Module Pilot", "citizenship", "immediately north of Canaveral at Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification that occurs following sequential proteolytic activation of complement molecules", "Lituya Bay in Alaska", "120 m ( 390 ft ) at its widest part", "the eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "Merrimac", "the Atlantic Ocean, the Gulf of Mexico and the Straits of Florida"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7875312811764793}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.375, 0.3076923076923077, 1.0, 0.6153846153846154, 0.4444444444444445, 1.0, 0.4, 1.0, 0.5853658536585366, 0.38095238095238093, 0.0, 0.5, 1.0, 0.16666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-4725", "mrqa_squad-validation-1454", "mrqa_squad-validation-3840", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.7291666666666667, "EFR": 0.9523809523809523, "Overall": 0.8407738095238095}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive; therefore, the defects justifying rebellion must be much more serious than those justifying disobedience", "the principle of inclusions and components", "They also spread beyond Europe to the Dutch Cape Colony in South Africa, the Dutch East Indies, the Caribbean, and several of the English colonies of North America, and Quebec, where they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "an enzyme called rubisco", "Abercrombie was recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "his extensive spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle which uses rubisco", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw), who may sign them into law", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "town of the Ubii", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "December 1971", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "James G. Kiernan", "horror fiction", "26,000"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7631917432710531}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4347826086956522, 1.0, 0.3720930232558139, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.5714285714285715, 1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6798", "mrqa_squad-validation-3023", "mrqa_squad-validation-4108", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-8833", "mrqa_squad-validation-962", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433"], "SR": 0.671875, "CSR": 0.71484375, "EFR": 1.0, "Overall": 0.857421875}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle", "wireless", "Beyonc\u00e9 and Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "1960s", "the court of Justice held that the freedom to provide services applied, it was directly effective, and the rule was probably unjustified", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot (3.7 million cubic meter)", "the 50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15 Saturn V rockets", "James Gamble & Reuben Townroe", "struggle, famine, and bitterness among the populace", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "NDS, a Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "their parent thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "the spirit of protest should be maintained all the way, whether it is done by remaining in jail, or by evading it", "the kettle and the Cricket, at one and the same", "Gandhi", "Vlad the Impaler", "The Little Foxes", "Betamax", "Leonard Nimoy", "Earth's orbital period is 365 & this fraction of a day", "Tiger Woods", "the University of Arizona", "Marshal Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali", "The new nightspot Teddy's made this presidential Hollywood hotel a happening # Quiz # Question.", "LASER abbreviation", "Hans Christian Andersen", "Jupiter", "Habenaria radiata, the egret flower of the Far East", "why", "Andrew Taggart, Emily Warren and Scott Harris", "Amaxophobia- Fear of riding in a car", "American", "Mexican military"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6569932671495171}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5714285714285715, 0.25, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.15384615384615385, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-2804", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.5625, "CSR": 0.684375, "EFR": 0.9642857142857143, "Overall": 0.8243303571428571}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "fell from his horse while hunting", "the member state cannot enforce conflicting laws", "J. F. D. Shrewsbury", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "it is weighted inversely to member state size", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center in San Jose", "Variable lymphocytes receptors", "the Edict of Fontainebleau", "Levi's Stadium", "ten million people", "the Lippe", "Video On Demand content", "time and storage", "semester calendar beginning in early September and ending in mid-May", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "The Jewish Star", "the League of the Three Emperors", "the field of science awarded by universities in many countries", "143,007", "Bill Clinton", "Waltham Abbey", "Secretariat", "coaxial cables", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "drawing the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy", "Woolsthorpe-by-Colsterworth", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Br'er Rabbit", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8239163614163614}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-6218", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-9753", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.71875, "CSR": 0.6901041666666667, "EFR": 0.9444444444444444, "Overall": 0.8172743055555556}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the Court of Justice of the European Union", "the dot", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools", "leverage the accumulation of wealth", "Spanish", "Structural geologists", "vice-chairman of the board", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "Sinclair Oil Corporation", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "Jasenovac concentration camp", "Rabat", "aged between 11 or 13 and 18", "Heather Elizabeth Langenkamp", "Henry Gwyn Jeffreys Moseley", "paracyclist", "Vilnius Airport", "Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "Liverpool and England international player", "Philadelphia Eagles", "Ricky Skaggs", "48,982", "Ashanti", "79", "Algeria", "a novel", "Biafra", "Polar Bear", "Atlantic City"], "metric_results": {"EM": 0.625, "QA-F1": 0.7303084935897436}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.2, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.8, 0.6666666666666666, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3939", "mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7543", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-5300", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-1971"], "SR": 0.625, "CSR": 0.6808035714285714, "EFR": 1.0, "Overall": 0.8404017857142857}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic", "the working fluid", "suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "the solution", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "a modern canalized section", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "the northern (German) shore of the lake", "computer programs", "The General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "deterministic", "Bart Starr", "allotrope", "Karluk Kara-Khanid ruler", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "Alfred Edward Housman", "the capital of the Socialist Republic of Vietnam", "Sevens", "fennec fox", "Bart Conner", "fantasy role-playing game", "Martin \"Marty\" McCann", "Black Mountain College", "a historic house museum in Ankara, Turkey", "Bothtec", "Cody Miller", "140 to 219 passengers", "the \"Father of Liberalism\"", "Garth Jennings", "Pablo Escobar", "Afro-Russian", "Mexico City", "Sleeping Beauty", "2005", "8 December 1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Ali Bongo", "Wheat Chex", "Ray Harroun", "Emily Blunt", "David Tennant"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7785962301587301}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-9287", "mrqa_squad-validation-1819", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2127", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-3885", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.734375, "CSR": 0.6875, "EFR": 1.0, "Overall": 0.84375}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Revolutionary", "relatively little work is required to drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "the 5th Avenue laboratory fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "teachers through the web in order to earn supplemental income", "stratigraphic", "commensal flora", "a + bi", "the constituting General Conference in Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "jet-powered tailless delta wing high-altitude strategic bomber", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Ai-Ling Lee", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham", "A55 North Wales Expressway", "Ranulf de Gernon", "\u00c6thelstan", "Madras Export Processing Zone", "44", "Division I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "diastema", "Alison Krauss", "Iran", "Bigfoot", "Papua New Guinea", "Renoir", "Manchester"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7811079545454545}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.3636363636363636, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1501", "mrqa_squad-validation-2238", "mrqa_squad-validation-7643", "mrqa_squad-validation-5972", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_naturalquestions-validation-3553"], "SR": 0.703125, "CSR": 0.6892361111111112, "EFR": 1.0, "Overall": 0.8446180555555556}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "unpaired electrons", "Fontainebleau", "Museum of the Moving Image in London", "sent missionaries", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients' use of force and violence and refusal to submit to arrest", "25 May 1521", "essentially holy people", "diplomacy or military force", "an increase in the land available for cultivation", "the value of the spin", "pivotal event in the Arab Muslim world", "an American YouTube personality, spokesmodel, television personality, and LGBT rights activist", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marko Tapani \" Marco\" Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "4145 ft above mean sea level", "Central Park", "Robert John Day", "Tifinagh", "James Tinling", "Italy", "2015 Masters Tournament", "Kristoffer Rygg", "Sullivan University College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "CouscousCouscous", "more than 22 million people in sub-Saharan Africa", "morphine sulfate oral solution 20 mg/ml", "The Firm (1993)", "walking catfish"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6849669908285896}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.13333333333333336, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.609375, "CSR": 0.68125, "EFR": 0.92, "Overall": 0.800625}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Owen Daniels", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "rose to higher political office", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and Daleks", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "Standard Model", "Tolui", "Rhine-Ruhr region", "a course of study and lesson plan", "Prevenient grace", "Kansas State", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "Russell Humphreys", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Massachusetts", "Ector County", "Jim Davis", "Buck Owens and the Buckaroos", "World Health Organization", "Emmanuel Ofosu Yeboah", "California", "Heather Stebbins", "Caviar", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "One Hundred Dollars a Month"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7214422145199761}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7502", "mrqa_squad-validation-6927", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_hotpotqa-validation-5743", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-7415", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.640625, "CSR": 0.6775568181818181, "EFR": 0.9565217391304348, "Overall": 0.8170392786561265}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "100\u2013150 species", "Philo of Byzantium", "cooler", "marine waters worldwide", "$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor", "his mother's genetics and influence", "shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "a new element to the standard Christian suspicion of Judaism", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "it is not just $3 billion of new money into the economy", "a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "deciding the duties of the new prime minister has been a sticking point in the negotiations", "lack of a cause of death and the absence of any soft tissue", "200", "pizza", "opposition party members", "Missouri", "he to step down as majority leader", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "KARK", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "Employee Free Choice", "Bush", "more than 200", "This is not a project for commercial gain", "best-of-three series", "Kaka", "Christopher Savoie", "Dan Parris, 25, and Rob Lehr, 26", "Fayetteville apartment", "two", "nearly $2 billion", "Jacob", "Molotov cocktails, rocks and glass", "250,000", "Winehouse", "the Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 )", "Thomas Hardy", "Richmond", "1994", "The Conjuring", "The Gallipoli Campaign", "Georgian Bay", "Nowhere Boy"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6530515491452992}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.8666666666666666, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.7692307692307693, 1.0, 0.0, 1.0, 0.8, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-4611", "mrqa_squad-validation-1257", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-2344", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.53125, "CSR": 0.6653645833333333, "EFR": 0.9666666666666667, "Overall": 0.8160156249999999}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "Christ who is the victor over sin, death, and the world.", "Napoleon", "new technology and machinery", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation,", "1227", "lower lake", "three", "Elders", "587,000", "Private Bill Committees", "Bruno Mars", "the Catechism", "the university's Stagg Field", "Ian Botham", "The Free Dictionary", "Vincent Motorcycle Company", "Sam", "Salvador Allende", "Harold Pinter", "Hawaii", "Jens Stoltenberg", "Apollo", "1940 Rodgers and Hart musical Pal Joey.", "Mary Seacole", "green", "French Polynesia", "supreme religious leader of all the subordinate priests", "Alessandro Stradivari", "The European Union", "Christine Keeler", "Jesus", "Nicholas Jackson", "four", "Netherlands", "\"Sugar Baby Love\"", "Coretta Scott King", "Sean", "Bill and Taffy Danoff", "Stage 1", "Travis", "The Show", "Robert Kennedy", "Q", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "Hobbies", "barber", "Rod Laver", "Murrah Federal Office Building", "Evita", "a litter of pipes on the mantelpiece", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley's", "\"It is very easy for comments to be taken out of context and create unnecessary drama -- especially between us women,\"", "a delegation of American Muslim and Christian leaders", "Royal Wives", "University of South Carolina", "Kim Clijsters."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5360863095238095}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 0.8571428571428571, 0.5, 0.05555555555555556, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-5431", "mrqa_squad-validation-7974", "mrqa_squad-validation-9418", "mrqa_squad-validation-7855", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_newsqa-validation-1150"], "SR": 0.46875, "CSR": 0.6502403846153846, "EFR": 0.9411764705882353, "Overall": 0.7957084276018099}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "aaron", "moles", "diogenes La\u00ebrtius", "kajalein", "Catherine of Aragon", "an election ultimately decided by congressional commission.", "Steve McQueen", "Portugal", "julius", "one", "kulang nama Dari Pada Gagal di Medan Tugas", "Carlisle", "a liquid form", "zanesville", "Chuck", "Antarctica", "mercury gilding", "aniridia", "Charles A. Carpenter", "River Forth", "woe", "NOW Magazine", "julius", "Italy", "Canada", "typhoid fever", "Tina Turner", "julius", "Walt Kowalski-Gran Torino", "2010", "einasto's law", "Venezuela", "albert", "temperature inversion", "40", "a certain science of human nature", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Christopher James", "Drillers Stadium", "one", "Virgin America", "julius", "fertilist", "Iran's parliament speaker", "Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory"], "metric_results": {"EM": 0.46875, "QA-F1": 0.48541666666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, false, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-3097", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.46875, "CSR": 0.6372767857142857, "EFR": 0.9117647058823529, "Overall": 0.7745207457983193}, {"timecode": 14, "before_eval_results": {"predictions": ["an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow", "public official", "the most cost efficient bidder", "acorn", "kung fu", "kung fu", "kung fu", "Chornobyl", "kung fu", "kung fu", "krakauer's Into the Wild", "amber", "high school graduating class", "The executioner's Song", "kung fu", "kazakhstan, Tajikistan, Kyrgyzstan", "anamosa", "grouchy o'Malley", "Ephesus", "kung fu", "jedoublen/jeopardy", "knife", "a harry potter", "Cologne", "kunglip", "an ingot", "Kosovo", "Kent Conrad", "Prague", "tennis", "kung fu", "buffalo", "aaron", "kung fu", "kung fu", "kung fu", "kofi Annan", "kung fu", "accordion", "monsieur", "George S. Klein", "Augusta", "counter clockwise direction", "March 31, 2013", "Tucker Crowe", "parachutes", "December 24, 1973", "David Diamond", "bikinis", "the Dalai Lama", "mother's memories of his mother", "Israel"], "metric_results": {"EM": 0.359375, "QA-F1": 0.44375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.33333333333333337, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-6335", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-4647", "mrqa_triviaqa-validation-224", "mrqa_triviaqa-validation-6129", "mrqa_hotpotqa-validation-7", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.359375, "CSR": 0.61875, "EFR": 0.9512195121951219, "Overall": 0.7849847560975609}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "Rhenus", "1996", "wine", "German", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "Word-Cross", "Paula Abdul", "Strongsville", "Flemish", "Mastercard", "Roger B. Smith", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "a tan or brown macule", "Graceland", "Toronto Maple", "Barbra Streisand", "konstantin Stanislavsky", "Delaware", "sugarcane", "rabbit", "Johann Strauss II", "joey", "pro bono", "Universit", "The Fun Factory", "ale", "Manfred von Richthofen", "Nacho Libre", "copper", "devils or demons", "carrots", "Dr. Wigand", "National Poetry Month", "cheese", "meager", "Casablanca", "blimps", "( Gustav Kirchhoff)", "a geisha", "Bigfoot", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a tin star", "dark", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6005208333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, false, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-13453", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-12150", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-14698", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.53125, "CSR": 0.61328125, "EFR": 0.9666666666666667, "Overall": 0.7899739583333334}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Weser", "Eva Peron", "Ho", "MedicineNet", "the Inuit", "Detroit Rock City", "the Blue Jays", "Abraham Lincoln", "Ray Bradbury", "hatred for someone's race", "(King Julien) XIII", "Pl Istvn Ern Srkzy de Nagy-Bcsa", "Rubicon", "(Montello)", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Clinton", "King Philip", "Bellerophon", "Balaam", "business", "The Caine Mutiny", "The Canada-born Robertson", "(founded 1932)", "Coltrane", "peace sign", "oxygen", "Sphinx", "Jan Hus", "The USA Network's original grassroots talent search", "Mavericks", "Eugene Onegin", "Macy's", "a spinning jenny", "Santa Claus", "Dennis Haysbert", "a nurse", "judges", "chromosome 21 attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "Michoacan Family", "prisoners", "his salary", "the punishment for the player"], "metric_results": {"EM": 0.59375, "QA-F1": 0.65625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-3051", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973"], "SR": 0.59375, "CSR": 0.6121323529411764, "EFR": 0.9230769230769231, "Overall": 0.7676046380090498}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Benjamin Vail", "Kenneth Swezey", "Party of National Unity", "22", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "The Crystal Method", "Puerto Rico", "The Mausoleum of Halicarnassus", "The Awl", "Switzerland", "Sabena", "The Old Man", "French", "Joe Louis", "lion", "d'Artagnan", "the Bayeux Tapestry", "Front Porch", "China", "Sunni", "notes", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "A Streetcar Named Desire", "Quilt", "FRAM", "House of Representatives", "Blue", "Michael Moore", "National Anthem Project", "Chevy", "Ingenue", "Pennsylvania", "Don Juan", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Summer", "Fiddler on The Roof", "Ethiopian", "16 episodes", "1992", "a solution", "Bromley-By- Bowden", "the Ruul", "Cartoon Network", "Caylee Anthony", "they know what is important in life", "the \"face of the peace initiative has been attacked.\"", "nuclear", "The Stooges"], "metric_results": {"EM": 0.671875, "QA-F1": 0.71875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-15593", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1920", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-14743", "mrqa_searchqa-validation-1396", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-4110"], "SR": 0.671875, "CSR": 0.6154513888888888, "EFR": 1.0, "Overall": 0.8077256944444444}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXI", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "computational", "same-gender marriages", "2006", "the mid-18th century", "orange", "A Raisin in the Sun", "Sistine Chapel", "Belarus", "a letter T", "a shovel", "Big Bang", "Sex Pistols", "endodontist", "Saturn", "Denmark", "Genoa", "Galt", "Jersey Boys", "the door of the Castle Church", "Indiana", "Sleepless", "polyantha", "the Hampton Inn", "21", "Leonidas Polk", "alevin", "Paul McCartney", "omega-3", "Paoletas", "Bachman Turner Overdrive", "ParaNorman", "Caddy Shack", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "Ulysses", "(William) Wordsworth", "Norway", "bears", "a large earthquake", "the Son of Man", "elephant", "Mazur", "Denmark", "a covert operation", "our country", "May 2010", "Camp David", "Guanabara Bay", "Thailand", "GQ", "Minister for Social Protection", "Berga", "the estate", "McFerrin", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5074048913043478}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, true, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_squad-validation-1696", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-11114", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-2870"], "SR": 0.421875, "CSR": 0.6052631578947368, "EFR": 0.9459459459459459, "Overall": 0.7756045519203414}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "transplastomic", "Earth", "53,000", "one", "poet", "two", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "the results show moved to Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "a specific population", "Charlene Holt", "Leland Stottlemeyer", "1991", "electron shells", "Cornett family", "acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Rick Rude", "Toledo, Bowling Green, and Mount Union", "a form of business network", "a cylinder of glass or plastic", "James Hutton", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Necator americanus and Ancylostoma duodenale", "February 28", "Lykan", "Abraham Lincoln's war goals", "a proton motive force drives protons down the gradient ( across the membrane ) through the proton channel of ATP synthase", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "Hermia", "Jupiter", "Latin", "15", "John Robert Cocker", "Israel", "a simple puzzle video game", "a palace", "nervus olfactorius", "eucalyptus", "a horse", "oxygen"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6238348890692641}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.2857142857142857, 1.0, 0.625, 1.0, 0.2, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.28571428571428575, 0.09090909090909091, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-3747", "mrqa_searchqa-validation-12372", "mrqa_triviaqa-validation-2227"], "SR": 0.53125, "CSR": 0.6015625, "EFR": 0.9666666666666667, "Overall": 0.7841145833333334}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "the death of a heretic", "choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "self-absorbed and uncaring youth", "Florida officials, who say they continue to plan for such an exodus only as a precaution.", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "over 1,000 pounds", "elite security", "Mutassim", "Oklahoma City's Will Rogers World Airport", "Polo", "Joe Jackson", "Amstetten", "computer problems", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus shifts", "prisoners", "September, Brazil", "consumer confidence", "5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Swat Valley", "Monday", "1979", "the United States", "in all of Lifeway's 100-plus stores nationwide", "Akio Toyoda", "there's no chance of it being open on time", "file papers shortly with an appeals court seeking an emergency stay of the judge's order in its tracks", "a place for another non-European Union player in Frank Rijkaard's squad.", "Michael Schumacher", "Gustav", "gun", "Henrik Stenson", "adoption", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "two years", "1966", "winter", "Whitsunday", "the mouths of two rivers", "Dumb and Dumber", "the 2004 Nokia Sugar Bowl", "Minton", "a converging lens", "autu", "Aqua ''", "The Force Fighters ( 2015 )"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6182240902414053}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, false, false, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.923076923076923, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.5, 0.6666666666666666, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 0.9032258064516129, 0.588235294117647, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-2301", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_triviaqa-validation-3226", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.484375, "CSR": 0.5959821428571428, "EFR": 0.9090909090909091, "Overall": 0.752536525974026}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers", "Combined Statistical Area", "chief electrician", "Newton", "static friction", "the assassination of US President John F. Kennedy", "Somalia's territorial sovereignty.", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "not the one to be dealt with by us.", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday.", "Venus Williams", "Mashhad", "Amanda Knox", "jazz", "$17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "Dr. Conrad Murray", "Sarah Brown", "getting out of the game,", "1981", "17 Again", "Nigeria", "$83,27014", "Republicans", "EU naval force", "Chris Robinson", "Bongo", "steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "skeletal dysplasia, a bone-growth disorder that causes dwarfism", "London Heathrow's Terminal 5.", "canceled the swimming privileges", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "China", "Steve Williams", "military action because we're getting frustrated", "The White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"Mortal Kombat X\"", "The Kingdom of Northumbria", "Ophelia", "a helicopter", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto von Bismarck"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5760865436646687}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 1.0, 0.125, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.5, 0.3333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1949", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-1873", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-251", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107", "mrqa_hotpotqa-validation-1056"], "SR": 0.453125, "CSR": 0.5894886363636364, "EFR": 0.9714285714285714, "Overall": 0.7804586038961039}, {"timecode": 22, "before_eval_results": {"predictions": ["X-ray imaging", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia, especially.", "two", "glowed even when turned off.", "five female pastors", "resources that could sustain future exploration of the moon and beyond.", "sovereignty over them.", "April 6, 1994", "\"Golden City,\"", "backbreaking labor", "a federal judge in Mississippi on March 22,", "the department has been severely affected by the earthquake, with thousands of officers injured, killed or unaccounted for.", "$22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need. We need Barack Obama as the next president of the United States.", "military trials for some Guant Bay detainees.", "Christos Winter", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain,", "male veterans struggling with homelessness and addiction.", "longest domestic torch relay in the games' history,", "in Harare.", "No. 1", "nine", "Four bodies", "Friday", "Kingdom City", "Rima Fakih", "the two-hour finale.", "al Qaeda leader Abu Zubaydah", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Damon Bankston", "researchers", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Fakih", "mainland greece", "Nalini Negi", "2017 - 12 - 10 )", "Runcorn", "collarbone", "the apparent horizon", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "A Fairy Tale of Home"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5750788340761966}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.20000000000000004, 1.0, 1.0, 0.0, 0.8235294117647058, 1.0, 0.5, 0.3636363636363636, 0.23529411764705882, 0.7272727272727273, 0.6086956521739131, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.6666666666666666, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.23529411764705882, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-379", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.40625, "CSR": 0.5815217391304348, "EFR": 0.8947368421052632, "Overall": 0.7381292906178489}, {"timecode": 23, "before_eval_results": {"predictions": ["phycobilin phycoerytherin", "was lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition", "Behind the Sofa", "Tulsa, Oklahoma", "56", "Yemen", "2005", "Karen Floyd", "Four Americans", "those missing", "Haiti", "Susan Boyle", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Spain", "Jared Polis", "Janet and La Toya,", "Hyundai", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding", "threatening messages", "if she would try to take the children and flee to Japan.", "constitution", "fake his own death", "Abrahamson", "martial arts", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "then-Sen. Obama", "Congress", "curfew", "Anne Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "once in June,", "the government in Islamabad \"has so far not received any information or evidence relating to the Mumbai incident from the government of India.\"", "Zuma", "haute, bandeau-style little numbers", "five", "Iraqi Prime Minister Nouri al-Maliki", "2000", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed's security team", "Desmond Tutu", "$1.4 million", "Toy Story", "$81,8709", "to provide school districts with federal funds", "a spiritual conversion", "Jason Lee", "phase of sleep", "substantive", "Kent", "beer and soft drinks", "five", "Cherokee River", "Thinkpad", "James A. Lovell, Jr.", "Florida"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5762447870347913}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.23999999999999996, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.15789473684210525, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.45161290322580644, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.53125, "CSR": 0.5794270833333333, "EFR": 0.9333333333333333, "Overall": 0.7563802083333333}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "Kathrin Hoelzl of Germany", "Venus Williams", "him to step down as majority leader.", "EU naval force", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "his club", "shows the world that you love the environment and hate using fuel", "1979", "Heshmatollah Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies", "Bangladesh", "Michael Arrington, founder and former editor of Tech Crunch, and Vivek Wadhwa,", "12 million", "President Sheikh Sharif Sheikh Ahmed", "Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "\"Britain's Got Talent\"", "military personnel", "all of Lifeway's 100-plus stores nationwide", "11", "one Iraqi soldier,", "Michael Partain,", "her fianc\u00e9", "racial intolerance.", "all animal products.", "an heirs to the criminal organization known as the Juarez Cartel, after the death of his father, Amado Carrillo Fuentes,\"", "Symbionese Liberation Army", "$8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "the ad would compromise the public broadcaster's appearance of impartiality.", "black is beautiful", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade", "$162 billion in war funding without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "two Metro transit trains that crashed the day before,", "eight", "Mark Obama Ndesandjo", "\"Dance Your Ass Off.\"", "Russian residents and worldwide viewers,", "\" Raiders of the Lost Ark.\"", "adultery", "nucleus", "Treaty of Paris between France and the Sixth Coalition, and the Treaty of Kiel", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Walt Disney World Resort in Lake Buena Vista, Florida", "Iceland", "out of wedlock", "platinum"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5486262709330143}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.2857142857142857, 0.5714285714285715, 0.33333333333333337, 0.06666666666666667, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 0.10526315789473684, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 1.0, 0.12500000000000003, 0.4, 1.0, 0.0, 0.0, 0.0, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3304", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8364", "mrqa_searchqa-validation-8678"], "SR": 0.4375, "CSR": 0.57375, "EFR": 0.9444444444444444, "Overall": 0.7590972222222222}, {"timecode": 25, "UKR": 0.74609375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1027", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1042", "mrqa_hotpotqa-validation-1095", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-1268", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-1781", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-2284", "mrqa_hotpotqa-validation-2315", "mrqa_hotpotqa-validation-2743", "mrqa_hotpotqa-validation-2927", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-305", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-3885", "mrqa_hotpotqa-validation-3952", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-4449", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4548", "mrqa_hotpotqa-validation-4552", "mrqa_hotpotqa-validation-4624", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-4924", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5165", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5227", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-729", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-3637", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-467", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5607", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7792", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8638", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-1812", "mrqa_newsqa-validation-1873", "mrqa_newsqa-validation-1915", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2036", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-209", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2421", "mrqa_newsqa-validation-2458", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3146", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3254", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-3634", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-49", "mrqa_newsqa-validation-496", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-729", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-88", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-968", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-105", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-10594", "mrqa_searchqa-validation-10787", "mrqa_searchqa-validation-11481", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-12150", "mrqa_searchqa-validation-12205", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-1272", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-13667", "mrqa_searchqa-validation-13756", "mrqa_searchqa-validation-1396", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-14282", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-14660", "mrqa_searchqa-validation-14700", "mrqa_searchqa-validation-14743", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-15593", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15784", "mrqa_searchqa-validation-15912", "mrqa_searchqa-validation-1706", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-2355", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-3420", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-6335", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6870", "mrqa_searchqa-validation-7227", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7584", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-8335", "mrqa_searchqa-validation-8343", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-858", "mrqa_searchqa-validation-8602", "mrqa_searchqa-validation-87", "mrqa_searchqa-validation-9270", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9991", "mrqa_squad-validation-10026", "mrqa_squad-validation-10026", "mrqa_squad-validation-10100", "mrqa_squad-validation-10254", "mrqa_squad-validation-10406", "mrqa_squad-validation-10418", "mrqa_squad-validation-1146", "mrqa_squad-validation-1166", "mrqa_squad-validation-1187", "mrqa_squad-validation-1218", "mrqa_squad-validation-126", "mrqa_squad-validation-1295", "mrqa_squad-validation-1313", "mrqa_squad-validation-1341", "mrqa_squad-validation-1407", "mrqa_squad-validation-1501", "mrqa_squad-validation-1549", "mrqa_squad-validation-159", "mrqa_squad-validation-1640", "mrqa_squad-validation-1662", "mrqa_squad-validation-1692", "mrqa_squad-validation-1758", "mrqa_squad-validation-1771", "mrqa_squad-validation-1775", "mrqa_squad-validation-1877", "mrqa_squad-validation-1906", "mrqa_squad-validation-1960", "mrqa_squad-validation-2049", "mrqa_squad-validation-2059", "mrqa_squad-validation-2105", "mrqa_squad-validation-2113", "mrqa_squad-validation-2136", "mrqa_squad-validation-2207", "mrqa_squad-validation-2435", "mrqa_squad-validation-2466", "mrqa_squad-validation-2518", "mrqa_squad-validation-2530", "mrqa_squad-validation-281", "mrqa_squad-validation-2833", "mrqa_squad-validation-2858", "mrqa_squad-validation-2941", "mrqa_squad-validation-298", "mrqa_squad-validation-3091", "mrqa_squad-validation-3100", "mrqa_squad-validation-3127", "mrqa_squad-validation-3132", "mrqa_squad-validation-3149", "mrqa_squad-validation-3259", "mrqa_squad-validation-3260", "mrqa_squad-validation-3312", "mrqa_squad-validation-3319", "mrqa_squad-validation-3440", "mrqa_squad-validation-3454", "mrqa_squad-validation-3524", "mrqa_squad-validation-3632", "mrqa_squad-validation-3716", "mrqa_squad-validation-3813", "mrqa_squad-validation-3862", "mrqa_squad-validation-3865", "mrqa_squad-validation-3918", "mrqa_squad-validation-3943", "mrqa_squad-validation-4010", "mrqa_squad-validation-4047", "mrqa_squad-validation-4075", "mrqa_squad-validation-4078", "mrqa_squad-validation-4083", "mrqa_squad-validation-4102", "mrqa_squad-validation-4175", "mrqa_squad-validation-4315", "mrqa_squad-validation-4429", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-457", "mrqa_squad-validation-4673", "mrqa_squad-validation-4706", "mrqa_squad-validation-4770", "mrqa_squad-validation-4775", "mrqa_squad-validation-4844", "mrqa_squad-validation-4973", "mrqa_squad-validation-498", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5023", "mrqa_squad-validation-5037", "mrqa_squad-validation-5102", "mrqa_squad-validation-5135", "mrqa_squad-validation-5178", "mrqa_squad-validation-5194", "mrqa_squad-validation-5213", "mrqa_squad-validation-5226", "mrqa_squad-validation-526", "mrqa_squad-validation-5486", "mrqa_squad-validation-549", "mrqa_squad-validation-5513", "mrqa_squad-validation-5581", "mrqa_squad-validation-5741", "mrqa_squad-validation-5784", "mrqa_squad-validation-5812", "mrqa_squad-validation-5863", "mrqa_squad-validation-5871", "mrqa_squad-validation-5876", "mrqa_squad-validation-5972", "mrqa_squad-validation-6029", "mrqa_squad-validation-6059", "mrqa_squad-validation-6080", "mrqa_squad-validation-6121", "mrqa_squad-validation-6154", "mrqa_squad-validation-6166", "mrqa_squad-validation-6177", "mrqa_squad-validation-6242", "mrqa_squad-validation-6430", "mrqa_squad-validation-6588", "mrqa_squad-validation-6598", "mrqa_squad-validation-6614", "mrqa_squad-validation-6676", "mrqa_squad-validation-6685", "mrqa_squad-validation-6694", "mrqa_squad-validation-6721", "mrqa_squad-validation-6741", "mrqa_squad-validation-6789", "mrqa_squad-validation-6789", "mrqa_squad-validation-6801", "mrqa_squad-validation-6875", "mrqa_squad-validation-6921", "mrqa_squad-validation-7135", "mrqa_squad-validation-7159", "mrqa_squad-validation-716", "mrqa_squad-validation-7173", "mrqa_squad-validation-7229", "mrqa_squad-validation-7273", "mrqa_squad-validation-7434", "mrqa_squad-validation-7458", "mrqa_squad-validation-7576", "mrqa_squad-validation-7596", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-7967", "mrqa_squad-validation-7981", "mrqa_squad-validation-80", "mrqa_squad-validation-8035", "mrqa_squad-validation-8151", "mrqa_squad-validation-8176", "mrqa_squad-validation-8343", "mrqa_squad-validation-8356", "mrqa_squad-validation-8397", "mrqa_squad-validation-8420", "mrqa_squad-validation-8439", "mrqa_squad-validation-8485", "mrqa_squad-validation-8503", "mrqa_squad-validation-855", "mrqa_squad-validation-855", "mrqa_squad-validation-8608", "mrqa_squad-validation-8616", "mrqa_squad-validation-8719", "mrqa_squad-validation-8733", "mrqa_squad-validation-880", "mrqa_squad-validation-880", "mrqa_squad-validation-8833", "mrqa_squad-validation-8896", "mrqa_squad-validation-8896", "mrqa_squad-validation-8896", "mrqa_squad-validation-890", "mrqa_squad-validation-8914", "mrqa_squad-validation-8924", "mrqa_squad-validation-9020", "mrqa_squad-validation-9066", "mrqa_squad-validation-913", "mrqa_squad-validation-9170", "mrqa_squad-validation-9173", "mrqa_squad-validation-9220", "mrqa_squad-validation-9237", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9299", "mrqa_squad-validation-9333", "mrqa_squad-validation-940", "mrqa_squad-validation-9406", "mrqa_squad-validation-9436", "mrqa_squad-validation-9470", "mrqa_squad-validation-9559", "mrqa_squad-validation-962", "mrqa_squad-validation-9665", "mrqa_squad-validation-9686", "mrqa_squad-validation-9752", "mrqa_squad-validation-9753", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_squad-validation-9931", "mrqa_squad-validation-9960", "mrqa_triviaqa-validation-1198", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-1644", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-2029", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-2227", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2522", "mrqa_triviaqa-validation-2794", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-316", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-339", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-4315", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-4945", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5964", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6753", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-7367", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-980"], "OKR": 0.814453125, "KG": 0.4515625, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "large scale", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "35", "a coffee house", "beetle", "phylum", "Wayne Allwine", "Westminster Abbey", "holography", "Pelias", "Joshua Radin.", "Northumbria", "Harvard", "leg- spin", "Seymour Hersh,", "a quant pole", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "dermatitis", "33", "elegant and restrained", "Joseph Smith,", "Huntington Beach, California", "palladium", "moon", "13", "a palla", "The Apartment", "Canada", "Clement Attlee", "Stockholm", "Peter Parker", "Goldie Myerson,", "Dirk Bikembergs,", "bullfight", "Sparks", "Ginger Rogers", "the Rock of Gibraltar", "Steptoe and Son,", "about 25 grams of citric acid", "Charles Darwin", "John", "Mrs. Boddy", "Marie Van Brittan Brown", "in southern California", "1995", "Bourbon", "Taylor Swift", "Adam Rex", "had his personal.40-caliber pistol,", "stripper's pole", "Amy Bishop,", "an ill-bred man,", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.484375, "QA-F1": 0.578125}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 0.6666666666666666, 0.5, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-147", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-7521", "mrqa_naturalquestions-validation-1399", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.484375, "CSR": 0.5703125, "EFR": 0.8484848484848485, "Overall": 0.6861813446969698}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Big Bang\"", "number eight", "affordable housing", "Mao Zedong", "casa di Giulietta", "Pontiac Silverdome", "elephants", "a charcoal powered grill, stove or hot plate", "Frank McCourt", "jules Verne", "julian foot", "sturgess", "Schengen Area", "red", "city of Sheffield, England", "Famous Players-Lasky Corporation", "the Monkees", "Gerald Durrell", "jzebel", "County Cork", "jason", "can eat and drink anything, has good,  strong feet and is happy being in a new place every day.", "Halifax", "mccartney", "jessica mccartney", "Stephen Potter", "one of the world's most notorious militants", "Edwina Currie", "tulia Lipnitskaya", "Robert Maxwell", "1768", "\u201cFor Gallantry;\u201d", "Tuesday's", "south Ossetia", "tuscaloosa", "The Good Life", "tahrir Square", "plutonium", "Count de Bragelonne", "27", "Jack Ruby", "tintoretto", "Eric Coates", "jeddah", "Lester", "Thailand", "Sydney", "a dove", "Tunisia", "Prince Philip", "grosvenor Crescent", "Tokyo", "Edgar Lungu", "49 cents", "exceeds the normal resting rate", "672", "Linda McCartney's Sixties: Portrait of an Era", "The Frost Place", "#notakidanymore", "Juan Martin Del Potro.", "27", "england", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5181818181818182}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-1354", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.46875, "CSR": 0.5665509259259259, "EFR": 1.0, "Overall": 0.7157320601851852}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "70", "He even lost control of the patents he had generated since he had assigned them to the company in lieu of stock.", "zulfikar Ali Bhutto", "Iran's nuclear program.", "at least 27 Awa", "(l-r)", "Daniel Cain", "acid", "Wally", "2008", "after Wood went missing off Catalina Island,", "Rima Fakih", "Pakistan", "Florida's Everglades", "made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos", "about $163 million (180 million Swiss francs)", "unwanted baggage from the 80s", "around 3.5 percent of global greenhouse emissions.", "ensenada", "Orbiting Carbon Observatory", "Switzerland", "Robert Redford", "Janet and La Toya", "11.4 million orphans", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "his injuries", "al-Shabaab", "posting a $1,725 bail", "sustain future exploration of the moon and beyond.", "his business dealings", "outlet mall", "Number Ones", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "Barack Obama", "\"gotten the balance right\"", "The oceans", "burned his back", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "1932", "between 1923 and 1925", "gilda", "j. armstrong", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Benjamin Disraeli", "a rising sun"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5904761904761904}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.5, 0.0, 1.0, 0.8, 0.28571428571428575, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_squad-validation-1302", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.453125, "CSR": 0.5625, "EFR": 0.9428571428571428, "Overall": 0.7034933035714286}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai", "Monday night", "Florida", "kidnapping the children and concealing their identities.", "40", "Illuminati", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "in Japan", "Arizona", "between South America and Africa.", "Tetris", "outside influences", "aid to Gaza,", "flipped and landed on its right side", "suppress the memories and to live as normal a life as possible", "Tuesday in Los Angeles.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "the area was sealed off,", "knocking the World Cup off the front pages for the first time in days.", "Cash for Clunkers", "project work", "one of the most influential, powerful and admired public figures of our time,", "80 percent of the woman's face", "in London", "try to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$50", "Australian officials", "Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "At least 38", "Argentina", "children of street cleaners and firefighters", "Somalia's piracy problem was fueled by environmental and political events.", "\"17 Again\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off,", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "Tonight", "The Fifth", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Jawaharlal Nehru", "stomata", "a bipolar episode"], "metric_results": {"EM": 0.5, "QA-F1": 0.6129941239316239}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.4444444444444445, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-4004", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-4465"], "SR": 0.5, "CSR": 0.5603448275862069, "EFR": 0.9375, "Overall": 0.7019908405172414}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "sex organs", "the Russian army", "interstellar medium", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "between 11000 and 9000 BC", "free up disk space", "July 4, 1776", "pick yourself up and dust yourself off and keep going", "John Garfield as Al Schmid", "trade routes to become established across the Atlantic and Pacific oceans", "1979", "Benzodiazepines", "the 2013 non-fiction book of the same name by David Finkel", "he takes the small parts home hidden in his unusually large lunch box", "Ethel `` Edy '' Proctor", "ranking used in combat sports,", "Husrev Pasha", "Jodie Sweetin", "ulnar nerve", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris", "the first four caliphs", "Lake Powell", "a star", "September 6, 2019", "its population", "substitute good", "veronica", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Prafulla Chandra Ghosh", "the United States economy first went into an economic recession", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "used their knowledge of Native American languages as a basis to transmit coded messages", "Donny Osmond", "Carthage", "George", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Russia", "White Castle"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5869140351328486}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, true, false, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3076923076923077, 0.5, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.7142857142857143, 0.5714285714285715, 0.7407407407407407, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.3846153846153846, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.2857142857142857, 0.4, 1.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 0.4, 0.0, 1.0, 1.0, 0.20689655172413793, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-5753"], "SR": 0.390625, "CSR": 0.5546875, "EFR": 0.9230769230769231, "Overall": 0.6979747596153847}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "North Carolina", "Chingachgook", "shoes.", "nine", "r Rashid Akmaev,", "acetylene", "obscure", "fiber", "gray fox", "What's", "Winston Rodney", "sand", "Nanjing", "Montana", "The Knight of Ni", "Louis XIV", "GILBERT & SullIVAN", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "Song of Norway", "Frida Kahlo", "served as the sixth President of the United States from 1825 to 1829.", "Jeopary Questions page 831", "Fat man, you shoot a great game of pool", "Hair", "William Randolph Hearst", "lava", "oatmeal Stout", "Hominidae", "telephone operator", "\"Year 3000\"", "Casey Jones", "The New Colossus", "yelp", "Richard Wagner", "Princess Beatrice of York", "\"I think you're the most attractive of all my parents' friends\"", "\"Tom Terrific\"", "bronchodilators", "Forty", "Neon and Argon Glow Lamps", "Devils Lake", "a Chenard", "Earl Long", "Neil Patrick Harris", "Wyatt", "1999", "vitamin D", "three", "Alberto juantorena", "Boyz II Men", "Awake", "Doctor of Philosophy", "Pakistan", "Atlanta", "an African-American woman"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4708333333333334}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, false, true, false, true, false, true, true, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-282", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-723"], "SR": 0.4375, "CSR": 0.5509072580645161, "EFR": 0.9722222222222222, "Overall": 0.7070477710573477}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the retina", "volume", "a crossword puzzle", "Breakfast at Tiffany's", "Diners' Club Card", "Christian Dior", "The Pittsburgh Cycle", "Juliet", "Notre Dame", "the Tablecloth", "Jamie", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "a glutamate poisoning,", "a card", "kozo", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "high school sports", "David Geffen", "Franklin D. Roosevelt", "Kate Middleton", "Ugly Betty", "an R", "a dairy cattle", "New Jersey", "Lake Ontario", "Matthew Perry", "Baltimore", "John Ford", "fortune", "Charlie and the Chocolate Factory", "the Rocks", "aluminum", "General McClellan", "Ned Kelly", "a piles of papers", "light", "Isis", "a bow", "Heroes", "on the two tablets", "the source of the donor organ", "seven", "Max Planck", "Duke Ellington", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Peretti", "two years", "Arsene Wenger", "as time goes on, it kind of becomes more and more of a phenomenon.\""], "metric_results": {"EM": 0.5, "QA-F1": 0.5770833333333334}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, true, true, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-9799", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-10042", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_triviaqa-validation-114", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-2123"], "SR": 0.5, "CSR": 0.54931640625, "EFR": 0.96875, "Overall": 0.70603515625}, {"timecode": 32, "before_eval_results": {"predictions": ["increased in weight", "Fresno Street and Thorne Ave", "the Black Death", "Elton John", "John Stuart Mill", "Emperor Norton", "the CIA", "piano", "Rickey Henderson", "Jawaharlal Bhutto", "D. carota ssp. maritimus", "John Grunsfeld", "Llados", "1976", "Galileo Descartes", "a quark", "the Bible", "Rudy Giuliani", "the Free Speech Clause of the First Amendment", "Virginia", "Sif", "New Jersey", "The Omega Man", "a pantry", "a barrel", "the Summer Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Jenna Davenport", "Los Angeles", "the north wind", "King Edward", "the Labour Party", "the pen", "Republic of Ireland", "Douglas Adams", "Krogstad", "Hawaii", "Stephen Crane", "Prussia", "Sophocles", "Mark Cuban", "the Thought Police", "a chest", "Central Park", "Alice", "Part 2", "Coconut Cove", "aeoline", "a trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6475694444444444}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-9313", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-11157", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767"], "SR": 0.578125, "CSR": 0.5501893939393939, "EFR": 1.0, "Overall": 0.7124597537878788}, {"timecode": 33, "before_eval_results": {"predictions": ["The BBC", "pathogens, an allograft", "a young man who appears to be dead, a pool of blood beneath his head.", "for hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"Something's wrong with this lady.\"", "Saturday,", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "women protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license,", "Conway, Arkansas", "fuel economy", "eco videos", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers,", "different women coping with breast cancer in five vignettes.", "a long-range missile test,", "Police", "a cancer-causing toxic chemical.", "Roger Federer", "Miami Beach, Florida", "over 1000 square meters in forward deck space, allowing for such features as a full garden and pool, a tennis court, or several heli-pads.", "CNN", "no chance", "a children's hospital in St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "Tuesday", "two", "a portrait of William Shakespeare", "a member of the self-styled revolutionary Symbionese Liberation Army -- perhaps best known for kidnapping Patricia Hearst --", "he acted in self defense in punching businessman Marcus McGhee.", "two tickets to Italy on Expedia.", "Colombia", "a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, relaxing near-black on red-eyes when it's time to sleep", "resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.India", "(Antonio Maria Costa,", "$40 and a loaf of bread", "Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "Bremen, Germany", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "Spokescandy", "\"The Land of the Free and the Home of theBrave\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6908496732026144}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 0.7058823529411765, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5333333333333333, 0.888888888888889, 0.0, 1.0, 0.4, 0.35294117647058826, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.4444444444444445, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.5625, "CSR": 0.5505514705882353, "EFR": 0.9642857142857143, "Overall": 0.7053893119747899}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "weren't taking it well.", "Washington State's decommissioned Hanford nuclear site,", "Yemen", "bankruptcy", "nearly $2 billion in stimulus funds", "is a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Bahrain", "the children of street cleaners and firefighters.", "Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers", "Honduras", "Brazil", "eco", "strife in Somalia,", "Roy", "WBO welterweight title from Miguel Cotto", "relatives of the five suspects,", "Meredith Kercher.", "former U.S. soldier Steven Green exhibited clear symptoms of acute stress disorder in Iraq and that a military psychiatric nurse-practitioner failed to diagnose the troubled infantryman and pull him out of combat.", "Aniston, Demi Moore and Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "a lump in Henry's nether regions was a cancerous tumor.", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "model of sustainability.", "glamour and hedonism", "a $158 green skirt and $298 bead and rhinestone cardigan", "Department of Homeland Security Secretary Janet Napolitano", "543", "The patient,", "Robert Gates", "Israel", "rural Tennessee.", "in critical condition", "in Seoul,", "Nicole", "desperately wanted to make her mother proud.", "next week", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "Her husband and attorney, James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1968", "Black Elk", "The Hogan Family", "the hippopotamus", "Peter"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5958057133838384}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, false, true, false, true, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.18181818181818182, 1.0, 0.19999999999999998, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_searchqa-validation-7879"], "SR": 0.515625, "CSR": 0.5495535714285714, "EFR": 1.0, "Overall": 0.7123325892857143}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts which they returned to Earth.", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position.", "sap", "Malibu", "Sisyphus", "sound absorption", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crab", "Prospero", "Purple", "the Aegean Sea", "The Battle of the Little Bighorn", "the Shakers", "a bellwether", "thinker", "chips", "Boxer", "The Spiderwick Chronicles", "Mabel", "Las Vegas", "Case's", "the Rose Bowl", "Norman Rockwell", "cut", "k Kuromaguro, or Blue Fin Tuna", "Napa", "Italy", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Nancy Pelosi", "cookbook", "Jupiter", "Sadat", "a sundae", "Grace Evans", "50 million cells per litre (quart)", "Volitan Lionfish", "Charlie Sheen", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Ra ther", "Lou Gehrig", "meaning and origin.", "1949", "Aamir Khan", "My Gorgeous Life", "Argentine", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6221813725490195}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true, false, true, true], "QA-F1": [0.35294117647058826, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.515625, "CSR": 0.5486111111111112, "EFR": 1.0, "Overall": 0.7121440972222223}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia", "nothing gained", "bullion", "Supernanny", "the Atlantic", "Cincinnati", "a mosque", "Henry Hudson", "the Peashooter", "dry ice", "Elihu Root", "Entourage", "eels", "Mariel", "The Museum of Modern Art", "the Unicorn", "(John C.) Fremont", "Russia", "(BRA STREISAND)", "Hermann Hesse", "the Taj Mittal", "English Monarchs", "Carmen", "Margaret Mitchell", "(Ismeralda)", "Sultans of Swing", "Pandarus", "a word", "The Longest Yard", "the Sphinx", "Satchmo Armstrong", "Tehran", "American New Wave band", "Arby\\'s", "coffee", "(Jack) Pershing", "Robert Burns", "The Incredible Hulk", "Winnipeg", "Memphis Belle", "Burkina Faso", "the Central Pacific", "(EGO) MANIAC", "Icelandic", "a domestic bull", "(HomerMcFanboy)", "Edith Piaf", "Ivan IV", "a chapter", "birch", "master carpenter Anthony Mayfield", "Jack Gleeson", "Phil Hurtt", "animals", "Massachusetts", "Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.6458333333333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, true, false, true, false, false, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-8275", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-15286", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-9131", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_searchqa-validation-14328", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_hotpotqa-validation-2162", "mrqa_newsqa-validation-3951"], "SR": 0.59375, "CSR": 0.5498310810810811, "EFR": 0.9615384615384616, "Overall": 0.7046957835239086}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "KFC", "oats", "Mitt Romney", "Ivan", "Sally Field", "1927", "Eritrea", "pi", "tin", "the Mississippi River", "Quaid", "w", "Marriott International", "Kimpton Hotel Monaco Portland", "Canada", "The Secret", "gold", "Collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Gulf of Mexico", "Stephen", "Euclid", "Eva Peron", "Cain", "Ed Asner", "X-Men", "the Louvre", "chinook", "Prison Break", "Mars", "Maine", "one", "Meg", "Rainer Maria Rilke", "deuce", "Hans", "Peter Bogdanovich", "Billy Joel", "Pilate", "(Britain redeemed and Canada preserved [microform]\"", "the Ice Age", "nolo contendere", "Junior Walker", "the Czech Republic", "Chicken of the Sea", "NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"Sausage Party\"", "Australian", "the sins of the members of the church", "$22 million", "\"State of Play\"", "Nelson County"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7171875}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-16789", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_newsqa-validation-1527"], "SR": 0.671875, "CSR": 0.5530427631578947, "EFR": 1.0, "Overall": 0.713030427631579}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Salinger", "Bill Hickok", "Leptospira", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "Marimba", "a ferry", "forgetting Sarah Marshall", "Witness", "Jack the Ripper", "3800", "Alan Shore", "taxonomy", "Spain", "the brain", "Captain EJ Smith", "William Shakespeare", "comedy", "Mary Poppins", "Casowasco Camp", "Fresh Prince of Bel-Air", "Nod", "watermelon", "a bathwater phrase", "bride & Groom", "Livin' On A Prayer", "Sherlock Holmes", "cotton candy", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "a diagonal", "Inuit", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "Harry Potter and the Philosopher Stone", "Manganese", "forests", "Olympia", "Waylon Jennings", "Doctor Zhivago", "Brazil", "British Columbia", "Platoon", "Scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "the different levels of importance of human psychological and physical needs", "one", "Norfolk Island", "Wright brothers", "sexual activity", "Sam tick,", "the L'Aquila earthquake,", "voluntary depletion", "\"deep sorrow\"", "Pygmalion"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6161458333333334}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.5625, "CSR": 0.5532852564102564, "EFR": 0.9642857142857143, "Overall": 0.7059360691391942}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "a peacock unitard", "Sweeney Todd", "The Bridge on the River Kwai", "the Ottoman Empire", "a feminist wedding", "Jefferson", "Ezra Pound", "the Orinoco River", "a ready-to-use cotton swab", "California", "Dixie", "a nonprofit institution that helps improve policy and decisionmaking through research and analysis", "Warren Harding", "engrave", "Shue", "Francis Crick", "Jay and Silent Bob", "Heath", "South Ossetia", "William Shakespeare", "Hawaii", "Marmaduke", "Tito", "Westies, Scotties, schnauzers", "Ratatouille", "neurons", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "26.2", "life", "a flowering perennial herb", "chess", "GIGO", "Johannes Brahms", "Florida State", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Anna Murphy", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "Alan Graham", "Bob Dole", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5415178571428572}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-15434", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11929", "mrqa_searchqa-validation-8155", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.46875, "CSR": 0.551171875, "EFR": 0.9411764705882353, "Overall": 0.7008915441176471}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "South Korean horror film", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000", "a genus of viruses in the family \"Flaviviridae\"", "Jane Hollander", "1934", "a record of 13\u20133", "Hark!", "Tsavo East National Park", "the New York Islanders", "Algirdas", "nearly 80 years", "Jean Acker", "the Championship", "The Gettysburg Address", "most awarded female act of all-time", "forwards", "Stravinsky's \"The Rite of Spring\"", "1", "26,000", "Kristin Scott Thomas", "Mayor Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "Lancashire, England", "the B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Hugh O'Brian", "Tevye", "Sir Tom Finney", "the Baka hunter-gatherers", "collecting samples of blood and other fluids from patients.", "by military personnel to hazardous materials in the United States, Japan and Iraq, including toxic smoke from burn pits in Iraq and contaminated water.", "two", "Iggy Pop invented punk rock.", "a pound of flesh", "a hay-trusser", "Leonardo DiCaprio", "a destructive ex-lover"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6692482155479746}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.41379310344827586, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_naturalquestions-validation-6326"], "SR": 0.578125, "CSR": 0.5518292682926829, "EFR": 1.0, "Overall": 0.7127877286585366}, {"timecode": 41, "before_eval_results": {"predictions": ["a touchdown", "10", "did not identify any of the dead.", "Les Bleus", "2005", "more than 4,000", "The Valley Swim Club", "an angry mob.", "normal maritime", "Sri Lanka", "death", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as many as 50,000", "piano", "$250,000", "a \"prostitute\"", "the mammoth's skull", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "Brazil", "acute stress disorder", "Russia and China", "Facebook and Google", "through a facility in Salt Lake City, Utah", "Manmohan Singh's Congress party", "Haiti", "Tuesday afternoon", "Pakistan", "23 years", "a head injury.", "Bahrain", "an open window", "Leo Frank", "Paul McCartney and Ringo Starr", "it has not intercepted any Haitians attempting illegal crossings", "President Robert Mugabe", "free", "one", "Diversity", "on-loan David Beckham claimed his first goal in Italian football.", "\"He is more American than German.\"", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died", "Authorities in Fayetteville, North Carolina,", "An Indonesian military transport plane crashed into a residential area in East Java early Wednesday, killing 98 people,", "al Qaeda", "Hillary Clinton", "Rihanna", "angular rotation", "from the right side of the heart to the lungs", "54 Mbit / s", "Gloucestershire", "the B-24 Liberator", "a product", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "DND International, Inc."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6895613501082252}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.8, 1.0, 1.0, 0.7272727272727273, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.888888888888889, 0.125, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-1549", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-2414", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-10945"], "SR": 0.578125, "CSR": 0.5524553571428572, "EFR": 1.0, "Overall": 0.7129129464285715}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Arizona", "Zimbabwe", "Italian Serie A", "Darrel Mohler", "dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "Morgan Tsvangirai", "42 years old", "crafts poems telling of the pain and suffering of children", "glaciers in the European Alps may melt as soon as 2050,", "80 percent of the woman's face", "1979", "Adam Sandler, Bill Murray, Chevy Chase and Will Smith", "Elena Kagan", "CNN's Campbell Brown", "an auxiliary lock", "2-0", "Tukel", "Myanmar", "Collier County Sheriff Kevin Rambosk", "Marcus Schrenker,", "Bienvenido Latag", "poems", "the program was made with the parents' full consent.", "(the Democratic VP candidate", "The Red Cross, UNHCR and UNICEF", "Russia", "debris", "not guilty of affray", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award", "state senators", "31 meters (102 feet)", "its nude beaches.", "how preachy and awkward cancer movies can get.", "a Florida girl", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill,", "estimates that \"theoretically\" Iran could develop a nuclear weapon within the next year.", "1940's", "March 22,", "think are the best.", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"Antichrist.\"", "a major fall in stock prices", "Thomas Jefferson", "Alexander Salkind", "Orion", "brown", "Selfie", "2002", "South Australia", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6816864125457875}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5333333333333333, 0.4, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-5989", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.578125, "CSR": 0.5530523255813953, "EFR": 1.0, "Overall": 0.713032340116279}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "the legitimacy of that race.", "25", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees of Immigration and Customs Enforcement", "33-year-old", "\"fusion teams,\" as they're being called, have come into effect.", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "$2 billion", "The National Infrastructure Program,", "After the war,", "\"The station", "Krishna Rajaram,", "The Arkansas weatherman", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Camp Lejeune, North Carolina", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "could be secretly working on a nuclear weapon", "that the teens were charged as adults.", "death squad killings carried out during his rule in the 1990s.", "Elena Kagan", "Hyundai Steel", "100 percent", "Saturday", "Afghanistan,", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Tribe", "Rima Fakih", "in a Johannesburg church that has become a de facto transit camp,", "Barack Obama,", "helicopters and unmanned aerial vehicles", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Salafist jihad group", "1,500", "Most of those who managed to survive the incident hid in a boiler room and storage closets", "$50 less,", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960", "Aston Villa Football Club", "peasants, small and medium-size farmers, landless people, women farmers, indigenous people, migrants and agricultural workers", "pool", "1822", "The Dressmaker", "Trilochanapala", "crote", "a buffalo", "ruby slippers", "the frontal lobe"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6381002641166043}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.5, 0.2105263157894737, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.08695652173913043, 0.923076923076923, 0.9523809523809523, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 1.0, 0.3333333333333333, 0.125, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.515625, "CSR": 0.5522017045454546, "EFR": 1.0, "Overall": 0.7128622159090909}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Christopher Livingstone \" Chris\" Eubank Jr.", "Duval County,", "Benj Pasek and Justin Paul", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Thomas Staubach", "1944", "Highlands", "Franconia, New Hampshire", "Operation Watchtower", "Dan Crow", "\"War & Peace\"", "Amberley Village", "What Are Little Boys Made Of", "Berea College", "the Chicago Bears", "Luca Guadagnino", "Charmian Carr", "Germany and other parts of Central Europe", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "jus sanguinis", "Radcliffe College", "Charles Guiteau", "Ford Motor Company", "If the citizen's heart was heavier than a feather", "India", "Lutheranism", "\"Charmed\"", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "British East India Company", "4,000", "Henry Luce's", "I'm Shipping Up to Boston", "American", "The Joshua Tree", "the dynasty", "the largest country comprising the mainland of the Australian continent, the island of Tasmania and numerous smaller islands", "the beginning of the American colonies", "Nicola Adams", "whale-watching", "Russia", "dependable Camry", "Steven Green", "Fayetteville, North Carolina,", "Chaucer", "rattlesnakes", "Riddles in the Dark", "healthy, wealthy, and wise"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6447679924242424}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986"], "SR": 0.59375, "CSR": 0.553125, "EFR": 1.0, "Overall": 0.7130468750000001}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder", "NATO member states, Russia and India", "30", "crocodile eggs", "a judge", "Jared Polis", "the annual White House Correspondents' Association dinner Saturday,", "on the family's blog", "in July", "sniff out cell phones.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "\"17 Again,\"", "Kim Jong Il seems to be \"testing the new administration.\"", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie", "Heshmatollah Attarzadeh", "the ireport form", "Iran,", "Nine out of 10 children", "police", "Sen. Joe Lieberman, I-Connecticut,", "a crocodile", "a bronze medal", "more than 200", "Congress", "Susan Boyle", "military ID cards", "Phillip A. Myers.", "Barack Obama's", "King Birendra,", "homicide.", "Casey Anthony, 22,", "officers at a Texas  airport", "10 municipal police officers", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers, ages 18 and 5,", "2004", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Arsene Wenger", "slavery", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ), and grandmother Mo ( Laila Morse )", "Latin liberalia studia", "Enid Blyton", "Johnny Mathis", "Beverly Hills Cop,", "Champion Jockey", "Luca Guadagnino", "Sleepy Brown", "the caged bird", "how timing shapes and supports brain function", "a jigger", "a Bristol Box Kite"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6093437218848403}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.33333333333333337, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.0, 0.6666666666666666, 1.0, 0.47619047619047616, 1.0, 1.0, 0.10526315789473685, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.15384615384615385, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.46875, "CSR": 0.5512907608695652, "EFR": 0.9705882352941176, "Overall": 0.7067976742327365}, {"timecode": 46, "before_eval_results": {"predictions": ["\"spectacular\"", "bipartisan", "Nirvana", "\"Dancing With the Stars\"", "without bail", "12.3 million", "Mexico", "United", "Michael Arrington,", "Brett Cummins,", "Indian army", "Saturday", "Nicole", "the legitimacy of that race.", "Adidas", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "\"Nothing But Love\"", "allegedly involved in forged credit cards and identity theft", "June 6, 1944,", "Iran,", "two", "October 19", "\"It was a wrong thing to say,", "Seoul,", "promotes fuel economy and safety", "ALS6", "eight", "Siri.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "\"Biscuit\" fire", "the children of street cleaners and firefighters", "North Korea intends to launch a long-range missile in the near future,", "that a U.S. helicopter crashed in northeastern Baghdad as", "not intercepted any", "The American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place,", "38", "Her husband and attorney, James Whitehouse,", "test scores and graduation rates", "two", "the most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "Discworld", "Japan", "fox hunting", "New York", "travel", "16,116", "\"Juno\"", "sugar", "the bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7377037384311091}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, true, true, false, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 0.0, 1.0, 0.9090909090909091, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 0.9333333333333333, 0.0, 1.0, 0.13793103448275862, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-11573"], "SR": 0.671875, "CSR": 0.5538563829787234, "EFR": 1.0, "Overall": 0.7131931515957447}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Airlines", "A Rush of Blood to the Head", "5", "Chicago", "\"The Ones Who Walk Away from Omelas\"", "child actor", "Dennis H. Kux", "by drawing the name out of a hat", "Brett Ryan Eldredge", "Hero Indian Super League", "two or three", "the Beatles", "Lady Frederick Windsor", "with a pale body and relatively darker extremities,", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1930 American Pre-Code musical film directed by John Francis Dillon and filmed entirely in Technicolor", "5,112", "1992", "residential", "14,673", "6'5\"", "Mickey Gilley", "Switzerland\u2013European Union relations", "German Shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London", "the Salzburg Festival", "Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "the Passion", "Bunker Hill", "the European or Eurasian cave lion", "the Royal Navy", "World War II", "Knoxville, Tennessee", "\"Three's Company\"", "P.O.S,", "Labour", "\"Linda McCartney's Life in Photography\"", "English", "September 14, 2008", "73", "Buffalo Bill", "Romania", "the James Gang", "Kenya", "Aung San Suu Kyi", "Afghan National Security Forces", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "cloakroom", "Lehman Bros International (Europe)"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6883612914862915}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, true, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.4, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-3675", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-2124", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_searchqa-validation-6735", "mrqa_triviaqa-validation-2701"], "SR": 0.609375, "CSR": 0.5550130208333333, "EFR": 0.92, "Overall": 0.6974244791666667}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "Helsinki", "gari", "offensive", "Augustus", "mating", "Fawn Hall", "waive", "Wanda", "Barnum", "Peter John", "negative electrode", "torque screw", "gold", "Maria Schneider", "Middle High German", "Renoir, Degas, Monet, and his sister-in-law", "University of Kentucky", "a ruddy fool", "Brussels", "Macbeth", "General Thomas Jonathan \"Stonewall\" Jackson", "piracy", "the death vestments", "Martin Luther", "Clue", "Edgar Allan Poe", "German", "Andrew Johnson", "seventh", "Mike Connors", "\"J Jungle Jim\"", "Jim Inhofe", "sancire", "Corpus Christi", "Cilliers, Jakkie, Julia Schnemann", "an ostrich", "independence", "slow-starting night owls", "mug", "Desperate Housewives", "Galileo Galilei", "Canada's", "Anne Hathaway", "a strike", "the Grail", "West Virginia", "James Monroe", "movie house", "Seaworld", "critic", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambilevous", "chariots", "Humberside Airport", "more than 265 million", "over 100 million", "freezing gasoline prices for the rest of the year and lowering natural gas prices by 10 percent.", "a head injury.", "Pope Benedict XVI refused", "Charles II"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4956295289855072}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.08695652173913045, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-10470", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-14219", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-5735", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_hotpotqa-validation-2171", "mrqa_hotpotqa-validation-1209", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.421875, "CSR": 0.5522959183673469, "EFR": 1.0, "Overall": 0.7128810586734694}, {"timecode": 49, "UKR": 0.765625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1056", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1258", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-211", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4683", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-4840", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5640", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-785", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-1805", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1597", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2009", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2949", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4123", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-526", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12777", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6003", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8428", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_squad-validation-9931", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.814453125, "KG": 0.49140625, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Colorado River", "Pamela Anderson", "carnaval", "Treasure Island", "Pocahontas", "Drew", "(Whizzer) White", "an ukulele", "a push-button valve", "the magnum opus", "Ferris B Mueller's", "Joseph Campbell", "Margaret Mitchell", "(Charles) Busch", "a draft horse", "Ernest Lawrence", "rodeo", "Ceiling", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "a melon", "the mouth", "Cuba", "Lord of the Rings", "Have You Neverbeen Mellow", "repellents", "60 Dutch", "February 2", "Leontyne Price", "compost", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "Sarah Jessica Parker", "the Pierian spring", "Warsaw", "a burnoose", "Philadelphia", "peanut butter", "Invisible Man", "leather", "Lex Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "bowlenbeath", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "The security breach", "three", "poems telling of the pain and suffering of children just like her;", "Mechte Navstrechu"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5072916666666667}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.13333333333333333, 0.16666666666666669, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-3349", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-15005", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14796", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-2904", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073", "mrqa_hotpotqa-validation-116"], "SR": 0.4375, "CSR": 0.55, "EFR": 0.9444444444444444, "Overall": 0.7131857638888889}]}