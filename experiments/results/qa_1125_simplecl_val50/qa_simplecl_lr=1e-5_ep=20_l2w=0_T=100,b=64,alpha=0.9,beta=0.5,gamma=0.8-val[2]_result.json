{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 3980, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange County", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail", "Uncle Tom\u2019s Cabin", "The liver", "No man", "No.1", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8604166666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-71", "mrqa_naturalquestions-validation-646"], "SR": 0.84375, "CSR": 0.859375, "EFR": 1.0, "Overall": 0.9296875}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "demographics and economic ties", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "warmest regions", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "the city's beaches are artificial", "guardian", "guardian", "guardian", "in 1787 he represented his state at the Constitutional Convention", "guardian", "guardian", "time goes", "guardian", "guardian", "black", "5562 feet"], "metric_results": {"EM": 0.625, "QA-F1": 0.6640895562770562}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3857"], "SR": 0.625, "CSR": 0.78125, "EFR": 0.9583333333333334, "Overall": 0.8697916666666667}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "a group that included priests, religious leaders, and case workers as well as teachers", "Vistula River", "1290", "21 October 1512", "427,652", "double", "August 1967", "German", "27-30%", "four", "50 fund", "Arizona Cardinals", "Peanuts", "comb plates", "calcitriol", "Krak\u00f3w", "time", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail and a carnivorous octopus", "Orestes", "Some grow to an immense size", "the \"Today\" show host did a terrible job", "the process by which water changes from a liquid to a gas", "the Travel Detective: How to Get the Best Service and the Best deals from Airlin", "a leg of about a gram, so a bag of 1,000 grains of rice has", "Inks, in which colour is imparted by... the replacement of many inorganic pigments such as chrome yellow,... alloy powder (gold bronze) are used in novel silver and gold inks", "the Mycenaean civilization", "a biological process that displays an endogenous, entrainable", "before the ghost of noted impresario David Belasco is said to no longer haunt it", "a fourth brother, Private James Ryan, and decides to send out 8 men", "a bank robber John Dillinger", "fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge was built to the east and to get the railway moving across the river without having to wait for the permanent structure to be completed"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7028544372294372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-2192", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.671875, "CSR": 0.75390625, "EFR": 1.0, "Overall": 0.876953125}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue", "to spearhead the regeneration of the North-East", "Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25", "May 2013", "K-9 and Company", "capturing prey", "a four-carbon compound", "pasture for cattle", "Ford", "1,300,000", "the end result of ATP energy being wasted and CO2 being released, all with no sugar being produced", "two tumen", "eight", "algorithm", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empire", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "New York City Mayor Michael Bloomberg", "the oceans are growing crowded", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "World War II", "Microsoft", "Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "a large concrete block", "the foyer of the BBC building in Glasgow, Scotland", "Christianity", "Manchester City", "his son, Isaac, and daughter, Rebecca", "three", "change course", "Tsvangirai", "cowardly lion", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a miracle food", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.625, "QA-F1": 0.6927476349081952}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.06896551724137931, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.6666666666666666, 1.0, 0.0, 0.5454545454545454, 0.0, 0.8333333333333333, 0.25, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7606", "mrqa_squad-validation-9250", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-1643", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-862", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.625, "CSR": 0.728125, "EFR": 1.0, "Overall": 0.8640625}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "chloroplasts are surrounded by a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "seal", "Philip Howard", "King Ethelred II of England", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Goa", "\"How I Met Your Mother,\"", "France's famous Louvre museum", "Leo Frank", "Athens", "Graziano Transmissioni", "opposition parties", "1.2 million", "United's", "the release of the four men", "first lady Michelle Obama is weighing in on the issue by focusing on how health care can affect families.", "Johnny Carson", "the Magna Carta is expected to fetch at least $20 million to $30 million,", "Evan Bayh", "at the University of Alabama in Huntsville", "Ali Larijani", "ballots", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "promoting fuel economy and safety while boosted the economy.", "resting heart rate over 100 beats per minute", "Suffolk Punch", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7398394884269497}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.2666666666666667, 0.0, 0.0, 0.0, 1.0, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-8715", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.65625, "CSR": 0.7161458333333333, "EFR": 1.0, "Overall": 0.8580729166666666}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum.", "computational", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "a straight line", "autumn of 1991", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1", "nerves", "1671", "New Germany", "polyhydroxy aldehydes and ketones.", "Governor of Vermont from 1991 to 2003 and Chair of the Democratic National Committee (DNC) from 2005 to 2009.", "heart, blood, and blood vessels.", "\"Wild Thing\", he played the ocarina as well", "He could have created the whole universe, the earth and all it contains in no time at all.", "Gustav Malr.", "Diana the Princess", "slave trade.", "vena cava", "a fossil clam, now known as Chesapecten jeffersonius, which appeared in Lister's", "bullseye", "Tartarus", "c( mid now crt>ss boundaries ot Matu^, space, and...", "New York", "Bardiya, the king he killed & replaced, had been an impostor", "LAP", "Count Ferdinand von Zeppelin", "San Francisco", "Duke of Clarence", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas", "Dr. Jack Shephard, Kate Austen, Sayid Jarrah, Hugo \" Hurley\"", "comic book", "Love Is All Around", "Los Angeles Dance Theater", "United States", "the FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5759901556776557}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_squad-validation-3113", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-14782", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.515625, "CSR": 0.6875, "EFR": 0.967741935483871, "Overall": 0.8276209677419355}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "encourage growth in richer countries", "Torchwood", "9.1 million", "little", "individual countries", "cattle and citrus", "Western Xia", "semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "capacity deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rod Steiger", "hog", "Barack Obama", "Keith", "a small, half size cup used for serving espresso", "a tutu", "Annapolis", "Spring", "klammeraffe", "bark beetles", "Allah", "bones", "Python", "The Bible", "Ada Monroe", "Faith Hill", "Matt Damon", "U.S.", "V", "Earth", "Yardbird", "Sweden", "Thailand", "hydrogen", "destroyed", "Perfume", "New Jersey Economic Development Authority's 20% tax credit", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.5, "QA-F1": 0.5598620129870129}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7468", "mrqa_squad-validation-7626", "mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_squad-validation-7565", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-8971", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_triviaqa-validation-3911", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.5, "CSR": 0.6640625, "EFR": 1.0, "Overall": 0.83203125}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes or an antibody-based humoral response", "producers", "BSkyB", "Kawann Short", "Daidu", "silent film", "22 miles", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "Red Army", "middle of the 20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Body of Proof", "seven-eighths", "Franois Girardon", "the Atlas Mountains", "Madrid", "the Danube", "Yahweh", "leather", "George Pullman", "a dark red-purple plum", "Jesus Christ", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "the tonka bean", "the divisor", "Hypnos", "Texas", "the Rooty Tooty Fresh 'N Fruity", "a black breed", "Bill of Rights", "the ACT", "Rio de Janeiro", "Henry David Thoreau", "Southern California", "Harry Whittington", "the Earth", "Gustave Eiffel", "Edward Hopper", "the CIA", "d'Artagnan", "painted Caves", "1985", "apples, blueberries, bananas", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.5, "QA-F1": 0.5928331500172532}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.33333333333333337, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.4, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6559", "mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.5, "CSR": 0.6458333333333333, "EFR": 1.0, "Overall": 0.8229166666666666}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "During the Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence", "Exploration", "prep schools", "Cultural imperialism", "strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Khrushchev", "Hera", "phylloxera", "Reginald Dwight", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Wash.", "Carmen", "Italy", "15", "tarn", "972", "buffalo", "Ann Widdecombe", "scalene", "the Old Kent Road", "Tuesday", "sodium pyroborate", "Ab Fab", "Massachusetts", "Barrow, Carlisle, Whitehaven and Workington", "California", "the Susquehanna", "Kajagoogoo", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "Deval Patrick", "Grover"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6716517857142856}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.59375, "CSR": 0.640625, "EFR": 0.9615384615384616, "Overall": 0.8010817307692308}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "a radio network", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the Inner Mongolia region", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "stomach", "stone", "Ken Russell", "Dan Dare", "Gnaeus Junior", "Smiths", "Mike Tyson", "Brazil", "Pesach", "Brian Deane", "kaleidoscope", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "Underground", "pouk", "\"beyond violet\"", "passion fruit", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "Titanic", "William Tell", "Christian Dior", "a snail", "Mendip Hills", "Wichita", "the sacrament of Holy Communion", "New Croton Reservoir in Westchester and Putnam counties", "Andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "\"Ni!\"", "Roman Polanski"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7354166666666666}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-4371", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.71875, "CSR": 0.6477272727272727, "EFR": 1.0, "Overall": 0.8238636363636364}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network", "public service", "Guy de Lusignan", "tiger team", "sub-group of T cells", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "hizbullah", "five", "Whist", "Nile River", "Toscana", "achromatopsia", "cqueous humor", "Pluto", "chromium", "copper", "The Hague", "Vancouver Island", "Ironside", "gollancz", "g Gorky", "brown trout", "Beyonce", "Wordsworth", "Man V Food", "Queen Elizabeth II", "sweden", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "lettuce", "James Bellamy", "caesar", "shrek", "Oslo", "dogs", "rhododendron", "Bob Fosse", "sweden", "Shanghai", "emile de Becque", "boat lifts", "Billy Colman", "17 October 2006", "beer", "Hoover Dam", "Saturday's Hungarian Grand Prix", "cauchin Church of the Immaculate Conception", "Edgar Allan Poe", "morocco"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6780133928571428}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.9166666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-4510", "mrqa_squad-validation-8252", "mrqa_squad-validation-6530", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.578125, "CSR": 0.6419270833333333, "EFR": 1.0, "Overall": 0.8209635416666666}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "a majority in Parliament, a minority in the Council, and a majority of the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas", "The Handmaid's Tale", "The bonobo", "The Fault in Our Stars", "CR-X", "puzzle", "1961", "400 MW", "Total Nonstop Action Wrestling", "galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen", "Continental Army", "Jack St. Clair Kilby", "Ryan Babel", "Akhmadovich Kadyrov", "July 16, 1971", "1933", "The Heirs", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point du Sable", "England", "Paul W. S. Anderson", "a Christian church", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "cinnabar", "phobias", "drug trade is a transnational threat, and therefore they poison economies and governments, and it is in everyone's interest to stop this proliferation.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "andrew johnson", "andrew johnson", "pre-Columbian times"], "metric_results": {"EM": 0.625, "QA-F1": 0.6706588203463204}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7200000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2, 0.0, 0.0, 0.12121212121212123, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-3896", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-7560", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.625, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "partial funding", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "Mikhail Aleksandrovich \" Michael\" Chekhov", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Imperial War Museum", "Minnesota's 8th congressional district", "Highlands Course", "Hawaii", "Liquidambar styracif", "Gilbert du Motier", "Bharatiya Janta Party (BJP)", "three", "Winter Haven, Florida", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "6", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Johnny Cash", "Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "2015, 2017", "1982", "rod", "Chris Robinson", "gossip Girl", "fluid dynamics", "out", "a sky goddess", "The Moody Blues"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6648958333333335}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7200000000000001, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-4359", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414"], "SR": 0.5625, "CSR": 0.6350446428571428, "EFR": 1.0, "Overall": 0.8175223214285714}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular", "Inherited wealth", "December 1963", "2009 onwards", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "Spreading throughout the Mediterranean and Europe", "kilogram-force", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "mathematical models of computation", "Vistula River", "100 to 150", "iPod Nano and iPod Touch", "at the school.", "March 8", "Democrats and Republicans", "the Catholic League", "well over 1,000 pounds", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "Friday", "Majid Movahedi", "different women coping with breast cancer in five vignettes", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills -- began falling onto the stern of his ship", "a smile on her face", "$40 and a quarter of bread", "Lance Cpl. Maria Lauterbach", "Hyundai Steel", "London", "400", "Val d'Isere, France", "the test results by a chaplain", "two soldiers and two civilians", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls", "Buddhism", "J. Crew", "U.S. Secretary of State Hillary Clinton", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "boyhood experience in a World War II internment camp", "suppress the memories and to live as normal a life as possible", "about 4 meters (13 feet) high", "the Irish capital", "Democrat", "Spanish forks", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "the toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "a bamboo cane", "mercury"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5109467528998779}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8571428571428571, 0.3, 1.0, 1.0, 0.8750000000000001, 0.23999999999999996, 0.0, 0.8000000000000002, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.390625, "CSR": 0.61875, "EFR": 1.0, "Overall": 0.809375}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "prime", "50 fund", "Camisards", "over $40 million", "GTE.", "1,100", "spinat", "Oligocene", "Melodie Rydalch,", "Charles Darwin", "Conway, Arkansas,", "March 24,", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"She had a smile on her face, like she always does when she comes in here,\"", "56", "National Football League", "\"The Da Vinci Code\"", "Heshmatullah Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Seoul.", "resources", "highest ranking former member of Saddam Hussein's regime still at large", "two Emmys for work on the 'Columbo' series starring Peter Falk.", "\"To all of our valiant men and women, know that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.\"", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75.", "eradication of the Zetas cartel", "closing these racial gaps.", "a bond hearing", "President Bush", "a hospital in Amstetten,", "African National Congress Deputy President Kgalema Motlanthe,", "spiral into economic disaster.", "resigned", "Ralph Cifaretto", "a strict interpretation of the law,", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000 or so are estimated to be there now.", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "topaz", "Capitol", "The Left Book Club", "holography"], "metric_results": {"EM": 0.5, "QA-F1": 0.6198409518722019}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.5, 0.6428571428571429, 0.28571428571428575, 0.0, 1.0, 0.42857142857142855, 0.0, 0.13333333333333333, 0.5, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.5, 0.4444444444444445, 1.0, 0.0, 0.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.6923076923076924, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_triviaqa-validation-6296"], "SR": 0.5, "CSR": 0.611328125, "EFR": 1.0, "Overall": 0.8056640625}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand people", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary negligence", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "30 years ago.", "murder", "next year", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire, does that mean it would use it against Israel?", "\"whole ethos is one of violence\" and that it had \"made a brutal choice to step up attacks against innocent civilians", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.\"", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "your environmental efforts make even more impact than Harrison Ford's chest.", "two women", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Monday,", "male veterans struggling with homelessness and addiction.", "Yusuf Saad Kamel", "modern and classic designs at the shop at the Form Design Center.", "11 healthy eggs", "have expressed concerns about the missile defense system. While Poland and the Czech Republic have agreed to host parts of the system, others in Europe share Russian concerns that the defensive shield could be used for offensive aims.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "1918-1919.", "1950s,", "U.S. forces of attacking Sadr City on Friday,", "a government-run health facility that provides her with free drug treatment.", "vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow, a town of about 238 people,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "\"Three Colours\"", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "Joe Louis", "George Blake", "Bogota"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6270643245643246}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.27272727272727276, 0.22222222222222224, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.16, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.13333333333333333, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 0.5, 0.3, 0.0, 1.0, 1.0, 1.0, 0.1, 0.0, 0.5, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3455", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_triviaqa-validation-6739"], "SR": 0.515625, "CSR": 0.6056985294117647, "EFR": 1.0, "Overall": 0.8028492647058824}, {"timecode": 17, "before_eval_results": {"predictions": ["lower levels of inequality.", "in hospitals", "questions and answers", "(sed vigilat)", "Captain Francis Fowke, Royal Engineers,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Illinois Reform Commission", "\"Mad Men\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's restive provinces", "fled Zimbabwe and found his qualifications mean little as a refugee.", "collaborating with the Colombian government", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Matthew Fisher,", "remains unknown,", "north and west of the country,", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "introduce legislation Thursday, improve the military's suicide-prevention programs.\"", "$250,000", "this week", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "a fair and independent manner and ratify successful efforts.", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22", "UNHCR", "how health care can affect families.", "Appathurai", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "checkposts and military camps", "Lashkar-e-Tayyiba (LeT), an Islamic militant group based in Pakistan.", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "slapped out his eye and slashed open his left eyebrows.", "congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "9", "rice", "Halifax"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6177710706413152}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [0.22222222222222224, 0.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 0.6666666666666666, 1.0, 0.33333333333333337, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25000000000000006, 0.5217391304347826, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-6359", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.515625, "CSR": 0.6006944444444444, "EFR": 1.0, "Overall": 0.8003472222222222}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam", "Defensive ends", "the dot", "chastity", "European Court of Justice", "bronze medal in the women's figure skating final,", "U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "UK", "\" Teen Patti\"", "Argentina", "Congress", "28", "New Haven, Connecticut, firefighter Frank Ricci", "Kurdish Gas City.", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "FDA is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Bahrain", "\"a violent and brutal extremist group with a number of individuals affiliated with al Qaeda.", "\"Zed,\"", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "\"wildcat\" strikes,", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally,", "Lindsey Vonn", "\"Larry King Live.\"", "prisoners' rights and better conditions for inmates, like Amnesty International.", "President Obama's race", "Brazil", "Saluhallen,", "\"explosive device\" or \"bomb\"", "two people", "40-year-old", "outside the Iranian consulate in Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "a leak in a Dike", "\"Sunny Afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth Tudor", "Kirk Lazarus", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.515625, "QA-F1": 0.619104489026364}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, false, false, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.125, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.9714285714285714, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_searchqa-validation-11385", "mrqa_searchqa-validation-9338"], "SR": 0.515625, "CSR": 0.596217105263158, "EFR": 0.967741935483871, "Overall": 0.7819795203735145}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah.", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "most of those who managed to survive the incident hid in a boiler room and storage closets", "that the Bainbridge would be getting backup shortly.\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones.", "a book.", "he was diagnosed with skin cancer.", "to stand down.", "Ashley \"A.J.\" Jewell,", "at least 17 people", "Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "rural California,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "a floating National Historic Landmark,", "Haeftling range.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "CNN's \"Larry King Live,\" ABC's \"Good Morning America\" and \"The View.\"", "America's infrastructure.", "protective shoes", "100,000 workers", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "glass shards", "Sedimentary rock", "3.45 billion years ago ( 2.45 Ga )", "London", "Colorado", "Bangor International Airport", "Pain Language  Pain Language", "Suffragist", "Cobblestone.", "Tunisia", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6930252906815407}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.27272727272727276, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.8, 1.0, 0.8571428571428571, 0.28571428571428575, 0.888888888888889, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.4, 1.0, 1.0, 0.47619047619047616, 0.0, 1.0, 0.25, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2805", "mrqa_searchqa-validation-7700"], "SR": 0.53125, "CSR": 0.59296875, "EFR": 0.9666666666666667, "Overall": 0.7798177083333333}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment from government officials.", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhism", "1978", "1927, 1934, 1938, 1956", "1969", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Wolfgang Hochstetter", "Branford College", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Archduke Franz Ferdinand of Austria", "the New Testament", "October 1941", "peace between two entities ( especially between man and God or between two countries )", "b\u0101gh, baug, bageecha or bagicha", "Cee - Lo", "after Shawn's kidnapping", "lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour", "three times", "November 25, 2002", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two degrees of freedom", "Alberto Salazar", "a collection of live animals", "American", "Hoosick,", "CEO of an engineering and construction company with a vast personal fortune.", "more than 1.2 million people.", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "approximately 600 square miles of south-central Washington,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6663448987050961}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.8421052631578948, 1.0, 0.8, 1.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.9333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.0, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3167", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.53125, "CSR": 0.5900297619047619, "EFR": 0.9, "Overall": 0.7450148809523809}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Westminster", "blue-green algae", "24", "the One Ring", "the Washington metropolitan area", "the molar concentration", "the breast or lower chest of beef or veal", "Sargon II", "the Philippines", "around 1600 BC", "July 2010", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford,", "the 2nd century", "in the pancreas", "Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "Introduced in 1957", "1776", "1995", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "the teenage porcupine punk rocker", "anembryonic gestation", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Swedish figure skater Gillis Grafstr\u00f6m", "Sophocles", "Tim Allen", "thick skin", "biscuit - sized", "Pakistan", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "the Major General of the Navy", "Marktown", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "the actual pen", "Ellen DeGeneres", "1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5344629277993249}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.7777777777777778, 1.0, 0.0, 1.0, 0.6666666666666666, 0.08333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_searchqa-validation-843", "mrqa_hotpotqa-validation-3984"], "SR": 0.390625, "CSR": 0.5809659090909092, "EFR": 0.9743589743589743, "Overall": 0.7776624417249418}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16 )", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "The Chainsmoker", "annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "two", "Thomas Jefferson", "Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "Burbank, California", "Grace Zabriskie", "2014", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas as Matt Morgan   Anthony Quinn as Craig Belden", "Jodie Foster", "February 27, 2007", "Malina Weissman", "8ft", "Owen Vaccaro", "bacteria", "on the lateral side", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff /\ufeff 90 \u00b0N - 0 \u00b0 E", "London", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "2005", "February 29", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "if he was not named Romeo he would still be handsome and be Juliet's love", "Hotel California", "Queen Elizabeth II", "\u00ef\u00bf\u00bdbeetle", "vocalist Eddie Vedder", "2005", "Dan Tyminski", "Elisabeth,", "southern port city of Karachi,", "at least nine", "Bashar al-Assad", "the Bible", "biathlon"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6341216455936851}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true], "QA-F1": [0.9473684210526316, 1.0, 1.0, 1.0, 0.25, 1.0, 0.4210526315789474, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.4444444444444445, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-3470", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-4138"], "SR": 0.53125, "CSR": 0.5788043478260869, "EFR": 0.9666666666666667, "Overall": 0.7727355072463769}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "the Emperor", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2", "the Constitution of India came into effect on 26 January 1950", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Johnny Logan", "1978", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "September 28, 2017", "Alex Skuby", "Virginia", "March 2016", "1991", "Sean Connery", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "The Massachusetts Compromise", "Justin Timberlake", "the forces of Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield", "1871", "eye", "The History Boys", "aprimitive type of fish", "White Knights of the Ku Klux Klan", "five books", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "A staff sergeant in the U.S. Air Force,", "Osama bin Laden", "Antarctica", "axon", "gourmet Mushrooms"], "metric_results": {"EM": 0.546875, "QA-F1": 0.661656746031746}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, false, true, true, false, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.2222222222222222, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.546875, "CSR": 0.5774739583333333, "EFR": 0.9655172413793104, "Overall": 0.7714955998563218}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "the first hole of a sudden-death playoff", "the onset and progression of Alzheimer's disease.", "Disco", "the \"Cisleithanian\" half of Austria-Hungary", "the Indian School of Business", "New York", "Texas Tower Sniper", "C. H. Greenblatt", "\"The Curious Case of Benjamin Button\" (2008)", "A55", "Corendon Dutch Airlines", "86", "Minneapolis", "sea lochs", "Fatih Ozmen", "U.S.", "Pacific Place", "political commentator", "the Donny & Marie Showroom, at the Flamingo Las Vegas", "City of Westminster, London", "2016", "Wildhorn", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Guadalcanal Campaign", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "Teutonic Knights.", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "musical research", "Tennessee", "Yoruba", "Lucky", "Wiz Khalifa", "2007 and 2008", "2001", "1966", "The Stig", "Jehan Mubarak", "Medellin", "his father", "Lawmakers", "in the first near-total face transplant in the United States,", "genes", "Olive", "Stockholm"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6842843788156288}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.0, 0.8571428571428571, 1.0, 0.22222222222222224, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4112", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-1676"], "SR": 0.578125, "CSR": 0.5775, "EFR": 0.9629629629629629, "Overall": 0.7702314814814815}, {"timecode": 25, "UKR": 0.740234375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1164", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-2250", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2289", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2586", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2988", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-3901", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-4461", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-5382", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-10057", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10227", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-1123", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2380", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-33", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-4562", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5539", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-6851", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-6952", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-7609", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8023", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8227", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-9001", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9505", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-1258", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-1532", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-1733", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-1800", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-2583", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2727", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2944", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3206", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3410", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3654", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-3745", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-39", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4046", "mrqa_newsqa-validation-4095", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-65", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-660", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-94", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-11385", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-12624", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-1335", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-14663", "mrqa_searchqa-validation-14883", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-16181", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-3783", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-4857", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7700", "mrqa_searchqa-validation-7702", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-9090", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-9705", "mrqa_searchqa-validation-9756", "mrqa_squad-validation-10045", "mrqa_squad-validation-10069", "mrqa_squad-validation-10074", "mrqa_squad-validation-10086", "mrqa_squad-validation-10216", "mrqa_squad-validation-10228", "mrqa_squad-validation-10254", "mrqa_squad-validation-10310", "mrqa_squad-validation-10324", "mrqa_squad-validation-10338", "mrqa_squad-validation-10353", "mrqa_squad-validation-1036", "mrqa_squad-validation-10378", "mrqa_squad-validation-10477", "mrqa_squad-validation-1090", "mrqa_squad-validation-1320", "mrqa_squad-validation-1450", "mrqa_squad-validation-1603", "mrqa_squad-validation-1636", "mrqa_squad-validation-1672", "mrqa_squad-validation-1694", "mrqa_squad-validation-178", "mrqa_squad-validation-1802", "mrqa_squad-validation-1852", "mrqa_squad-validation-1855", "mrqa_squad-validation-1857", "mrqa_squad-validation-1938", "mrqa_squad-validation-1967", "mrqa_squad-validation-2040", "mrqa_squad-validation-2126", "mrqa_squad-validation-2153", "mrqa_squad-validation-2216", "mrqa_squad-validation-2289", "mrqa_squad-validation-2384", "mrqa_squad-validation-2400", "mrqa_squad-validation-2436", "mrqa_squad-validation-2460", "mrqa_squad-validation-2477", "mrqa_squad-validation-255", "mrqa_squad-validation-2577", "mrqa_squad-validation-2602", "mrqa_squad-validation-2619", "mrqa_squad-validation-268", "mrqa_squad-validation-2693", "mrqa_squad-validation-2773", "mrqa_squad-validation-2782", "mrqa_squad-validation-2798", "mrqa_squad-validation-282", "mrqa_squad-validation-2824", "mrqa_squad-validation-285", "mrqa_squad-validation-2929", "mrqa_squad-validation-3019", "mrqa_squad-validation-3041", "mrqa_squad-validation-3135", "mrqa_squad-validation-3185", "mrqa_squad-validation-320", "mrqa_squad-validation-3337", "mrqa_squad-validation-3476", "mrqa_squad-validation-353", "mrqa_squad-validation-3589", "mrqa_squad-validation-3709", "mrqa_squad-validation-383", "mrqa_squad-validation-3931", "mrqa_squad-validation-3948", "mrqa_squad-validation-3955", "mrqa_squad-validation-397", "mrqa_squad-validation-3993", "mrqa_squad-validation-4005", "mrqa_squad-validation-4079", "mrqa_squad-validation-4140", "mrqa_squad-validation-415", "mrqa_squad-validation-4181", "mrqa_squad-validation-427", "mrqa_squad-validation-4291", "mrqa_squad-validation-4305", "mrqa_squad-validation-4333", "mrqa_squad-validation-4338", "mrqa_squad-validation-4472", "mrqa_squad-validation-462", "mrqa_squad-validation-4686", "mrqa_squad-validation-4704", "mrqa_squad-validation-4835", "mrqa_squad-validation-4856", "mrqa_squad-validation-4870", "mrqa_squad-validation-5054", "mrqa_squad-validation-5088", "mrqa_squad-validation-5096", "mrqa_squad-validation-5154", "mrqa_squad-validation-5176", "mrqa_squad-validation-5238", "mrqa_squad-validation-5302", "mrqa_squad-validation-5326", "mrqa_squad-validation-5376", "mrqa_squad-validation-550", "mrqa_squad-validation-5537", "mrqa_squad-validation-5541", "mrqa_squad-validation-5588", "mrqa_squad-validation-5616", "mrqa_squad-validation-5672", "mrqa_squad-validation-5703", "mrqa_squad-validation-5767", "mrqa_squad-validation-5777", "mrqa_squad-validation-5913", "mrqa_squad-validation-60", "mrqa_squad-validation-60", "mrqa_squad-validation-607", "mrqa_squad-validation-6099", "mrqa_squad-validation-6126", "mrqa_squad-validation-6143", "mrqa_squad-validation-6178", "mrqa_squad-validation-6220", "mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6362", "mrqa_squad-validation-6395", "mrqa_squad-validation-6414", "mrqa_squad-validation-6564", "mrqa_squad-validation-660", "mrqa_squad-validation-6641", "mrqa_squad-validation-6737", "mrqa_squad-validation-6754", "mrqa_squad-validation-6782", "mrqa_squad-validation-68", "mrqa_squad-validation-6817", "mrqa_squad-validation-6915", "mrqa_squad-validation-696", "mrqa_squad-validation-7018", "mrqa_squad-validation-703", "mrqa_squad-validation-7069", "mrqa_squad-validation-707", "mrqa_squad-validation-7150", "mrqa_squad-validation-7161", "mrqa_squad-validation-7180", "mrqa_squad-validation-7198", "mrqa_squad-validation-7260", "mrqa_squad-validation-7399", "mrqa_squad-validation-754", "mrqa_squad-validation-7552", "mrqa_squad-validation-7597", "mrqa_squad-validation-7640", "mrqa_squad-validation-765", "mrqa_squad-validation-7678", "mrqa_squad-validation-7770", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-7856", "mrqa_squad-validation-7882", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-804", "mrqa_squad-validation-8056", "mrqa_squad-validation-8104", "mrqa_squad-validation-8115", "mrqa_squad-validation-8189", "mrqa_squad-validation-8226", "mrqa_squad-validation-8226", "mrqa_squad-validation-8285", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8527", "mrqa_squad-validation-8629", "mrqa_squad-validation-8735", "mrqa_squad-validation-8760", "mrqa_squad-validation-8765", "mrqa_squad-validation-8832", "mrqa_squad-validation-884", "mrqa_squad-validation-8867", "mrqa_squad-validation-890", "mrqa_squad-validation-8957", "mrqa_squad-validation-898", "mrqa_squad-validation-9031", "mrqa_squad-validation-9066", "mrqa_squad-validation-9135", "mrqa_squad-validation-9186", "mrqa_squad-validation-9227", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9391", "mrqa_squad-validation-9392", "mrqa_squad-validation-9465", "mrqa_squad-validation-9504", "mrqa_squad-validation-9541", "mrqa_squad-validation-9552", "mrqa_squad-validation-9652", "mrqa_squad-validation-9658", "mrqa_squad-validation-9771", "mrqa_squad-validation-979", "mrqa_squad-validation-9818", "mrqa_squad-validation-987", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2626", "mrqa_triviaqa-validation-2685", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-3051", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-4107", "mrqa_triviaqa-validation-4171", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-4440", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-5568", "mrqa_triviaqa-validation-5671", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6290", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-6909", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-71", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-7548", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-776"], "OKR": 0.84765625, "KG": 0.42421875, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater", "Anna Clyne", "Terence Winter, based on the memoir of the same name by Jordan Belfort.", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "Sharyn McCrumb", "Acid house", "at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage on TV, radio and online", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles of Timmy Sanders", "PBS stations nationwide, on November 13, 2007,", "second largest", "Citric acid", "1989", "Lola Dee", "The Five", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "torpedo boats", "1972", "Geographical Indication tag", "Buck Owens", "Cleveland Celtics", "World Championship Wrestling", "2003", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "The Tax Reform Act of 1986", "Henry Louis (Heinrich Ludwig),", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League.", "Krishna Rajaram,", "javA MAN", "to earn the nickname Super Eli", "green"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7032151875901875}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.5454545454545454, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-4240"], "SR": 0.640625, "CSR": 0.5799278846153846, "EFR": 0.9565217391304348, "Overall": 0.709711799749164}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Tom Hiddleston", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool and the England national team", "port city of Aden, on the southern coast", "British", "Prince Louis of Battenberg", "1985", "Archie Andrews", "before", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Joseph Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "racehorse breeder and owner", "Las Vegas", "1919", "Kevin Spacey", "Love Streams", "Michael Edwards", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "CMYKOG", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Ewan McGregor", "1963", "a peplos", "Car ferry", "Nutshell", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "Japan", "postcards"], "metric_results": {"EM": 0.5625, "QA-F1": 0.650472184065934}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268"], "SR": 0.5625, "CSR": 0.5792824074074074, "EFR": 1.0, "Overall": 0.7182783564814815}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Sir Matthew Alistair Grant", "most awarded female act of all-time", "Dunlop Tyres", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Westerister", "Kalokuokamaile", "Brigadier General Raden Panji", "Don Bluth", "December 8, 1970", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "Jim Diamond", "September 8, 2017", "FBI", "Christine MacIntyre", "April 25, 1995", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914 machine gun", "James Brolin", "Prussian army general, adjutant to Frederick William IV of Prussia", "January 2004", "Michael Stipe", "ten", "seven species", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "c3H8O3", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "bromide", "nasal septum", "wavelengths"], "metric_results": {"EM": 0.578125, "QA-F1": 0.681840491379965}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.4000000000000001, 0.0, 0.18181818181818182, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.578125, "CSR": 0.5792410714285714, "EFR": 1.0, "Overall": 0.7182700892857142}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "Herrenhausen Palace, Hanover", "Henry Mancini", "Jap\u00b7a\u00b7nese", "Gordon Ramsay", "Gorbachev", "Adrian Cronauer", "the rose", "Rameses II (Yul Brynner)", "Anna (Julia Roberts)", "a scythe", "orchid", "Paddy Doherty", "smallpox major", "The Colossus of Rhodes", "Libya", "Chubby Checker", "f\u00fcr elise", "Khomeini\u2019s Iran", "Daniel Peggotty", "wry, compassionate, and brimm[ing] with... open-minded intelligence", "Count de La F\u00e8re", "Tax Day", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "Belle", "David Beckham", "Manhattan", "Tom Stoppard", "The Greatest", "the manager", "the British charts", "a habanero", "tenor saxophonist", "Seattle", "The Cross Foxes Inn", "Cardiff", "Baton Rouge", "a 'Weber', or a 'Zenith", "Tahrir Square", "Romanian", "the \"useful life period\"", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "a foraging mammal", "Greek", "Passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "June 4, 1931", "North America", "Florida's Everglades.", "Trisha Yearwood", "glamorous, sexy and international", "a street or", "Glengarry Glen Ross", "Sebastian Stark"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5266493055555554}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false], "QA-F1": [0.0, 0.5, 0.39999999999999997, 0.5, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-1670", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-15919"], "SR": 0.421875, "CSR": 0.5738146551724138, "EFR": 0.972972972972973, "Overall": 0.7117794006290774}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Tim Duncan", "James W. Marshall", "Blue laws", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Thompson", "between 8.7 % and 9.1 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "status line", "retina", "jimmy johnson", "Triple Alliance of Germany, Austria - Hungary, and Italy", "Andrew Lloyd Webber", "1955", "Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar", "the original Star Trek television series", "1960", "Meg Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "Allison Janney", "1995", "i want to be with you everywhere", "improved economics of distribution", "Illinois", "in the 1970s and'80s", "in the books of Exodus and Deuteronomy", "George Strait", "Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "The Miracles", "Eukarya", "elbow", "jimmy caesar", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "27", "Long Island convenience store", "Romney", "Peter", "knee", "The Bachelor"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6714657738095238}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.5454545454545454, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.6666666666666666, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-3412", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1979", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.59375, "CSR": 0.5744791666666667, "EFR": 1.0, "Overall": 0.7173177083333333}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "tourism", "a circle", "( Sequoia sempervirens)", "The Fairly Odd Parents", "Spanish Republic", "taxicab", "coyote", "(PVM) yra fiziniai ir juridiniai asmenys (Lietuvos ir usienio)", "Harry Reid", "Ray", "axis", "forge", "(the Kinetoscope", "No Country for Old Men", "Flowerbomb", "Blackbird", "Footprints", "Caliban", "LA Kings", "(UZA)", "Tommy Lee Jones", "Zacchaeus", "The Memory Keepers daughter", "(1876)", "hubris", "Yahtzee", "Tony Danza", "markup language", "hives", "74.3", "William S. Hart", "bibEonITES", "Pride and Prejudice", "The Secret Family of Jesus", "kosher", "Munich", "Michael Jordan", "(St.) Andrew's Day", "Prospero", "Hikaru Sulu", "tropical rainforests", "crusts", "kyushu", "honey", "Boston", "Fisher- Price", "Arctic Ocean", "the Italian flag", "squash", "Spain", "Thomas Chisholm", "May 2002", "1997", "Newfoundland and Labrador", "The Odd Couple", "Monty Python's Spamalot", "1911", "Harlow Cuadra and Joseph Kerekes", "Newton's book \"Principia\"", "Israel", "Adidas", "anti-trust laws."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6354166666666667}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-391"], "SR": 0.578125, "CSR": 0.5745967741935484, "EFR": 1.0, "Overall": 0.7173412298387097}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Ferengi bartender Quark", "Christian Kern", "June 26, 1970", "Bloomingdale Firehouse", "Elise Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge Aharon Barak", "Bangkok, Thailand", "Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland County", "Slaughterhouse-Five", "The Adventures of Huckleberry Finn", "wine and cellar door region", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Kenneth Hood \"Buddy\" MacKay Jr.", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Isabella Palmieri", "Hathi Jr.", "1935", "geryon", "slow", "\"Cruisin'\"", "Union Station in Denver,", "the European Commission.", "Friday", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.625, "QA-F1": 0.7011017628205127}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.625, "CSR": 0.576171875, "EFR": 1.0, "Overall": 0.71765625}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\"", "jellyfish", "March", "a shoe", "Fauntleroy", "the World Health Organization", "Eat porridge", "Kofi Annan", "glucose", "the right to print was strictly controlled in England", "Taggart", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "Manfred Mann", "Sepp Blatter", "Barry Taylor", "the Union Train Station", "Brussels", "Charles Edward Stuart", "John Poulson", "A\u00e9roport de Paris-Beauvais-Till\u00e9", "the Treaty on European Union", "\"Jack\" Frost", "The Precambrian Shield", "Laurent Planchon", "the Solent", "vomiting", "the Red Lion", "Bristol Aeroplane Company", "Spinach", "Tony Meo", "\u201cArgo\u201d took the best picture Oscar on Sunday night at the 85th Academy Awards", "Gemini", "Surrey", "1971", "the Fosse Way", "London", "The Coquimbo Region", "William Shakespeare", "borax (sodium tetraborate decahydrate, Na2B4O7\u221910H2O)", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Diana Dors", "Kent", "Vickers-Armstrong's", "Ray Charles", "The onset of rigor mortis and its resolution partially determine the tenderness of meat", "United States customary units", "Miller Brewing", "northwestern Italian coast", "the Peninsula in Melbourne", "the earthquake's devastation", "Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\" Kristal Kraft, a real estate agent in Denver,", "Peter Bogdanovich", "the chivalry", "the Federal Republic of Cyprus"], "metric_results": {"EM": 0.421875, "QA-F1": 0.49661458333333336}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.1, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-2177", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.421875, "CSR": 0.5714962121212122, "EFR": 0.9459459459459459, "Overall": 0.7059103066134316}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "Lana Del Rey", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown", "Antarctica", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms", "eusebeia", "waiting tables", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Longline", "Jesus'birth", "a habitat", "Kirsten Simone Vangsness", "Central Germany ( German : Mitteldeutschland ) is an economic and cultural region in Germany", "Andrew Johnson", "Etienne de Mestre", "Atreus, Agamemnon's father", "electors", "Julia Ormond", "Sauron", "1961", "STAYND", "2013", "March 1", "novelization", "a usually red oxide formed by the redox reaction", "Spain disputes the legality of the constitution and claims that it does not change the position of Gibraltar as a colony of the UK", "Steffy Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "entrance to the 1889 World's Fair", "erosion", "March 2, 2016", "stuffing", "1996", "Ray Charles", "marriageable age is set at 16 for females and 18 for males", "Ramones", "1800", "Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "Kate lives in Los Angeles", "May 2010", "France", "Heath Ledger", "Wilson Pickett", "a centaur", "actor", "cricket fighting", "Luis Edgardo Resto", "drama that pulls in the crowds", "a Nazi German death camp in Poland.", "Islamabad", "Tunisia", "RAND", "alberta"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5339633447987119}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.06451612903225806, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.7368421052631579, 0.6666666666666666, 0.0, 0.0, 1.0, 0.3076923076923077, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.1, 0.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.25, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2118", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.453125, "CSR": 0.5680147058823529, "EFR": 1.0, "Overall": 0.7160248161764706}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Cal", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission and final drive", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "prophets", "state legislators of Assam", "a key role in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "constant pressure", "Mind your Ps and Qs", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "20 November 1989", "Tom\u00e1s de Torquemada", "Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "a four - page pamphlet in 1876", "2003", "Sebastian Lund", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "antigen from the lumen and deliver it to the lymphoid tissue", "enterprise application development", "Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "If the car is slowed initially by manual use of the automatic gear box", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Derrick Henry", "ice cap climate ( K\u00f6ppen EF )", "a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "future AC/DC founders", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday", "Olympic medal", "Henry Ford", "Toyota", "Abraham Lincoln", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread, so they're usually classed as benign."], "metric_results": {"EM": 0.453125, "QA-F1": 0.5746938569195299}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.16666666666666669, 1.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 0.9811320754716981, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.26666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.125, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2758620689655173, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.453125, "CSR": 0.5647321428571428, "EFR": 0.9428571428571428, "Overall": 0.7039397321428571}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "mild euphoric", "Game of HBO Season 6", "Venezuela", "Mexico", "boxing", "Finding Neverland", "Andrea del Sarto", "Arctic Ocean", "air pressure", "man-made obstructions", "marquis - Sesli Szlk", "Elijah Muhammad", "doldrums", "Village People", "Alexander Pushkin", "Australia", "Munich", "banderas", "a night shift", "papacy", "the Delta", "watson", "Pierre-August Renoir", "mister", "Les Huguenots", "Innsbruck", "Lance Ito", "Microsoft", "basket Asparagus", "sesame Street", "Viking", "Atlantic City's", "Blackwater USA", "elephant", "American Airlines", "alberta", "Odysseus", "Quizlet", "Kensington Palace", "charles Bassett", "Netherlands", "Pocahontas", "C.S. Lewis", "John Galt", "chalkboard", "Chicago Mercantile Exchange", "Las Vegas", "danskin", "bounty", "Pablo Casals", "an ostrich or common ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "an ancient optical illusion toy", "John Morgan", "Hungarian Rhapsody No. 2", "Eleanor of Aquitaine", "Sen. Debbie Stabenow", "63", "\"perezagruzka\""], "metric_results": {"EM": 0.484375, "QA-F1": 0.5956473214285714}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, false], "QA-F1": [0.5714285714285715, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-265", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-5219", "mrqa_searchqa-validation-5473", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.484375, "CSR": 0.5625, "EFR": 0.9696969696969697, "Overall": 0.7088612689393939}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "the Earth's axial tilt, which fluctuates within a margin of 2 \u00b0 over a 40,000 - year period, due to tidal forces resulting from the orbit of the Moon", "Lucknow", "2013 -- 14", "National Industrial Recovery Act ( NIRA )", "The User State Migration Tool ( USMT )", "the Battle of Antietam", "William DeVaughn", "New Jersey's formal name for the new PATH station and the associated transit and retail complex that opened on March 3, 2016", "Southend Pier", "Santa Monica", "layered systems of sovereignty", "Will", "31 January 1934", "Filipino", "1773", "modern random - access memory ( RAM )", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Harishchandra", "Olivia Olson", "1990", "Nickelback", "Bill Pullman", "BC Jean", "never made", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "the retinal ganglion cells of one retina", "the 1980s", "in soils", "card verification value ( CVV )", "exercise general oversight, telling him to `` rebuke with all authority '' ( Titus 2 : 15 )", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum -- the enkuklios paideia or `` education in a circle ''", "Mike Czerwien", "As of July 2017, there were 103 national parks encompassing an area of 40,500 km ( 15,600 sq mi ), comprising 1.23 % of India's total surface area", "Vienna", "Bajan", "the Democratic Republic of  Congo", "\u201cThe Pope? How many divisions does the Pope of Rome have?", "$10.5 million", "Al Horford", "Andrew Johnson", "$22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities.", "cotton", "Denzel Washington", "Quinn", "Towcester"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6638027306474887}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.12903225806451613, 1.0, 0.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.12903225806451613, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.09523809523809523, 0.380952380952381, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 0.07999999999999999, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-1028", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_hotpotqa-validation-4351", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953"], "SR": 0.546875, "CSR": 0.5620777027027026, "EFR": 0.9310344827586207, "Overall": 0.7010443120922647}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "brazil", "South Africa", "first among equals", "shine", "a cappella", "albinism", "Henry Hunt", "an aglet", "Saturday Night Live", "Bayern M\u00fcnchen", "winter", "bbc", "english", "copper", "Dawn French", "brazil", "b Benedict", "Doris Lessing", "Scooby-Doo", "Swaziland", "the boston house at London Zoo", "Kent", "the Humber", "points based scoring system", "automobile", "Kent", "Rodgers and Hammerstein", "Boy George", "Galileo Galilei", "gertrud Margarete", "Scotland Yard detective", "Marilyn Manson", "Medellin", "William Shakespeare", "spark-ignition", "brazilia", "Boulder Dam", "the long-term effects of using drugs", "Saudi Arabia", "Belle de Jour", "Morecambe", "abba", "rain", "blue", "Asaph Hall", "France", "geena Davis", "kunsky", "death", "David Graham", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "heavy turbulence", "women and breast cancer", "Blaine", "a sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6144903273809523}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.375, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-541", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.59375, "CSR": 0.5629111842105263, "EFR": 1.0, "Overall": 0.7150041118421053}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "tyne", "the liver", "40", "sodium bicarbonate", "pets", "cuba", "chancery", "Phil Redmond", "Stevie Wonder", "head", "hound", "hanover", "moon", "Charles I", "worked", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "quetzalcoatl", "a 1934 Austin seven box saloon", "Paul Anka", "phoenicians", "cuba", "the king Duncan", "Blade Runner", "Jay-Z", "leopons", "drums", "\u201cSanta Buddies\u201d", "San Diego Opera", "norman tbbit", "Ticket Sarasota", "South Africa", "Marie Trepanier", "scrobbesbyrig", "Killer whales", "cuba", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "a Baron", "snakes", "cuba", "frauds", "a sea horse", "even numbers", "Tony Blair", "quartz or feldspar", "54 Mbit / s", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Ray Lynn", "piano", "paid tribute to pop legend Michael Jackson,", "former U.S. President Bill Clinton", "French Guiana", "cuba", "a shield", "Tiger Woods"], "metric_results": {"EM": 0.4375, "QA-F1": 0.48236607142857146}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2224", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-856", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5730", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.4375, "CSR": 0.5596955128205128, "EFR": 0.9166666666666666, "Overall": 0.6976943108974358}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Aldi", "Midnight Cowboy", "alfa", "seborrheic dermatitis", "norman hughson", "a burthen of about 60 tons", "Niger", "central Stockholm", "Tangled", "strong instincts to chase and jump, and other fleeing creatures, including deer and livestock", "dennis Douglas", "Bulls Eye", "vieuzac", "bach", "Martin Clunes", "Charles Darwin", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "john Mellencamp", "isambard Kingdom Brunel", "georgia", "1957", "Devon", "vienne", "white wine, salt, pepper", "moctes", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "e. T. A. Hoffmann", "hanzhou", "Spain", "grow", "Tuesday", "Guru Nanak", "bleak house", "Harry Potter", "phosphorus", "nursery rhyme", "Indianapolis", "norma", "cuckoo", "argatha Christie", "Dodge Ram", "Alice Cooper", "Majorca", "hemoglobin", "Royal Bengal Tiger", "inward spiral", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "Body Works", "forgery and flying without a valid license", "137", "the log cabin", "St. Patrick's Day", "defensive backs", "Sondheim"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5044642857142857}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, false, true, false, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-1080", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.453125, "CSR": 0.55703125, "EFR": 0.9714285714285714, "Overall": 0.7081138392857143}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players", "Washington", "Thomas de quincey", "chicago pestis", "horse", "bison", "ptolemy Philadelphus", "a swallow", "Sarajevo", "the Bill of Rights", "fin\u00b7ing", "Neighbours", "b Bounty", "trumpet", "Westminster Abbey", "paperfolding", "the value of unknown electrical resistance", "the Arabian Gulf", "secretary", "jane de valence", "matricide", "jack Nicholson", "\u201cTote the weary Load,\u201d", "diesel", "Tomorrow Never Dies", "Sudan", "a Great Dane", "Washington", "Angola", "New Hampshire", "James I", "Terry Bates", "the Philippines", "blue", "every one", "warblers", "a rogue 70-foot wave", "rome", "10", "Southwest Airlines", "phone", "Jeffery Deaver", "The Comedy of Errors", "bridgeport", "glyn Jones", "President Clinton", "chile", "the dogger bank", "al-Qaeda", "rodinsons", "Kitty Softpaws", "1998", "Tanvi Shah", "the EN World web site", "the 100th anniversary of the first \"Tour de France\" bicycle race", "Mach number", "Janet and La Toya", "more than 2.5 million", "researchers have developed technology that makes it possible to use thoughts to operate a computer, maneuver a wheelchair or even use Twitter", "the Matrix", "seinfeld", "merena", "high inequality of opportunity related to gender was low"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4744791666666667}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-2275", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5826", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.421875, "CSR": 0.553734756097561, "EFR": 1.0, "Overall": 0.7131688262195122}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "hula hoops", "nixon", "a Golden fleece", "roddy dixon", "a counting table", "Robin Hood Men in Tights", "sisyphus", "Velazquez", "South African", "caracas", "oregon", "tchaikovsky", "if", "oregon", "usborne", "david Bowie", "Buzz Aldrin", "jane paul sartre", "chalin", "dennis turpin", "rust", "jane aniston", "pembroke", "tbilisi", "jane jane smith", "othello", "if you wait until late, things   will get worse, and it will take much longer to deal", "glenn close", "lacock Abbey", "alex b'Stard", "domestic cat", "anita Brookner", "shomron", "golda meyerson", "the Black Sea", "bagram Theater Internment Facility", "miss dent", "a power outage Sunday", "Vienna", "The Archers", "shylock", "sousa ochs", "chicago", "jimmy boyd", "shakespears", "Marx", "avon", "habsburg monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "2001", "from 1993 to 1996", "James Gandolfini", "March 23, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones.", "a double reed", "the o.K. Corral", "butternut squash", "usistocles"], "metric_results": {"EM": 0.5, "QA-F1": 0.5897399749373433}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5, 0.8, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473685, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-5773", "mrqa_triviaqa-validation-2332", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.5, "CSR": 0.5524553571428572, "EFR": 0.96875, "Overall": 0.7066629464285714}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics", "some work rule issues.", "Eintracht Frankfurt", "Comoros Islands", "a public-television show", "Jeddah, Saudi Arabia", "40", "chest", "\"Big change is hard,\"", "Manny Pacquiao", "$250,000", "Wednesday,", "Britt Lintner", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "dancy-Power Automotive Group showroom", "Michoacan Family", "64", "in prison.", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career", "\"E! News\"", "Washington", "Madeleine K. Albright", "ice jam", "toxic smoke from burn pits", "benazir butto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "cal Ripken Jr.", "a relative's house", "cancer", "acid attack", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "only one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "100% of its byproducts", "about 5:20 p.m.", "former Mobile County Circuit Judge Herman Thomas", "\"A salute to the martyrs of the massacre, and our condolences to their families.\"", "a man's lifeless, naked body", "\"release\" civilians", "Trevor Rees", "the shipping industry", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc", "norwegian", "Misery", "william purdy", "Antonio Lippi", "Thorgan", "River Clyde", "chile", "johnny weissmuller", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.46875, "QA-F1": 0.561800635402609}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.923076923076923, 0.4, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4210526315789474, 1.0, 0.0, 0.6, 0.05714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-588", "mrqa_newsqa-validation-1745", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881"], "SR": 0.46875, "CSR": 0.5505087209302326, "EFR": 0.9705882352941176, "Overall": 0.7066412662448701}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.", "1943", "Volvo V70", "the Mountain West Conference", "the National Basketball Association", "Western Europe", "political thriller", "Schaeffler AG", "English football", "1989 until 1994", "the Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown", "Lollywood and Pollywood", "Emmanuel Ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs", "1988", "coaxial", "Northern Lights", "three different covers", "Malayalam cinema", "Regno di Dalmazia", "August 11, 1946", "Charlie Kaufman", "1967", "Estadio de L\u00f3pez Cort\u00e1zar", "Brian A. Miller", "Nicolas Vanier", "1985", "Wonder Woman", "Meghan Markle", "a Boeing B-17 Flying Fortress", "by a family of Portuguese descent", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "the UK\u2019s Trade Mark Registration Act 1875", "blue", "wrist", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "the Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6858032152529435}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5, 1.0, 0.0, 0.29629629629629634, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-2070"], "SR": 0.59375, "CSR": 0.5514914772727273, "EFR": 1.0, "Overall": 0.7127201704545455}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "over 12 million", "Lucha de Apuesta", "Conservatorio Verdi in Milan", "President of the United States", "the backside", "Angelo Bruno", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "2015 Orange Bowl", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer guitars", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool Football Club", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Chrysler", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Australian Electoral Division", "50 Cent", "American singer Toni Braxton", "Hindi", "Richard Masur", "Irish Chekhov", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "The Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "Super Bowl VIII", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Elgar/Enigma Variations", "last summer.", "almost 100", "into the Southeast,", "the pie", "Great Balls of Fire", "heresy", "One Direction"], "metric_results": {"EM": 0.609375, "QA-F1": 0.737530637254902}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.8, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766"], "SR": 0.609375, "CSR": 0.5527777777777778, "EFR": 1.0, "Overall": 0.7129774305555556}, {"timecode": 45, "before_eval_results": {"predictions": ["American Revolution", "a proof reader", "a crown", "the Belgae", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "\"The Young and the\"", "Monty Hall", "putt-putt", "CNN Daybreak", "Punxsutawney, Pennsylvania", "Pannonia", "yellow fever", "a sea otter", "M&M's", "a franchise", "rod", "Nixon's", "dressage", "astronomer", "Mickey Mouse", "a bud", "Associate", "a fruit snack", "Medusa", "a spiral staircase", "a tabby coat", "a staff", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "Helen of Sparta", "beef, poultry, fish, or their by-products", "the peace sign", "Morrie Schwartz", "English Monarchs These 2", "Rajasthan", "\"retired\" safecracker Gal for one last job, but it...", "The New York Times", "Portland Thorns", "a \"road above\"", "White bread and butter", "a second is not necessarily an endorsement of the", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "New York City", "Isle of Wight", "The Peppercorn Pioneer", "Queen In-hyun's Man", "Oneida Limited", "Michael Jordan", "Libreville, Gabon.", "two tickets to Italy", "The station", "Cahawba"], "metric_results": {"EM": 0.484375, "QA-F1": 0.562797619047619}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1744", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_triviaqa-validation-888"], "SR": 0.484375, "CSR": 0.5512907608695652, "EFR": 1.0, "Overall": 0.7126800271739131}, {"timecode": 46, "before_eval_results": {"predictions": ["their actual social power and wealth", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "room the book store", "faggot", "a skein", "California Chrome", "Pluto", "Route 66", "the Taklamakan Desert", "Sindh", "Astronaut", "the Great Victoria Desert", "German", "Carole King", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Neptune", "Birmingham", "snakes", "Sedgefield", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "a trenches exhibition", "South Korea", "pig", "definitely, maybe", "carmen", "Kenya", "Stephen Potter", "Casa di Giulietta", "Anwar Sadat", "a hundred", "Potomac", "Argentina", "Luke", "Frankfurt", "Mouse", "Goldie Hawn", "pulsar", "Belgium", "horses", "sugar", "Benfica", "Sun Lust Pictures", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "Twilight", "the Carrousel du Louvre", "Speed", "H.G. Wells", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6520833333333333}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-445", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_searchqa-validation-4652"], "SR": 0.609375, "CSR": 0.5525265957446808, "EFR": 0.96, "Overall": 0.7049271941489361}, {"timecode": 47, "before_eval_results": {"predictions": ["aqaba", "at Sunset", "Sinclair Lewis", "the bear", "Denise Richards", "pigments", "Jonathan Demme", "v\u00e1clav Havel", "Dick Van Dyke", "millais", "Tina Turner", "2010", "portrush", "glasses", "perfumer", "Duke Orsino", "magnetite", "klampenborg", "The Apprentice", "a ship\u2019s hull", "Cubism", "sahara desert", "the Advisory Council of Science and Industry", "eucharist", "Charlotte's Web", "Octopussy", "silks", "William Randolph Hearst", "lorne Greene", "rowing", "Corin Redgrave", "call my Bluff", "a", "Argentina", "Frank McCourt", "salt or sugar", "Caroline Aherne", "germany", "starch", "soap", "Donna Summer", "a balustrade", "Nottingham", "Poland", "the Welcome Stranger", "taggart", "April", "Chechnya", "a police janitor", "a-team", "football", "801,200", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough", "South Australian Championships", "\"I didn't understand the whole concept of communism because I was only 11 when communism fell down and when the Velvet Revolution happened.", "people", "Michelle Obama", "kbenhavn", "the Communist Manifesto", "sARA", "floxin"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5809659090909091}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, true, true, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_searchqa-validation-11990"], "SR": 0.546875, "CSR": 0.5524088541666667, "EFR": 1.0, "Overall": 0.7129036458333334}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "Thored, Earl of southern Northumbria", "shaun the sheep", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air", "Mineola, New York", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "mash-Up", "short Circuit", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "kneeland Street", "Mathew Sacks", "Babylon", "Ford Falcon", "Southern State Parkway", "The Company", "1827", "Kim Bauer", "$700 million", "Edward James Olmos", "Suffolk", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard H or HD blister gas", "The 45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "Westminster", "Boyd Gaming", "1848", "Texas Tech University", "John McClane", "Larry Gatlin & the Gatlin Brothers Band", "924", "371.6 days", "Piedmont", "Selinsgrove", "Augusta Ada King-Noel, Countess of Lovelace (\"n\u00e9e\" Byron; 10 December 1815 \u2013 27 November 1852)", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "Space Shuttle Challenger", "basil", "clio Awards", "The Rosie Show", "California-based Current TV", "over 1,000 pounds", "Octavius", "desert", "the Library of Congress", "the thylakoid membranes"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6595051875962202}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true], "QA-F1": [0.25, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.5, 0.0, 0.0, 0.0, 0.8695652173913043, 0.19999999999999998, 0.0, 0.5, 1.0, 1.0, 1.0, 0.8, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-4008", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-3233", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-4119", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.5625, "CSR": 0.5526147959183674, "EFR": 0.9642857142857143, "Overall": 0.7058019770408164}, {"timecode": 49, "UKR": 0.755859375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2339", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5755", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-870", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-5726", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6806", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-2999", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-60", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3155", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-5788", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6000", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-888", "mrqa_triviaqa-validation-890", "mrqa_triviaqa-validation-92"], "OKR": 0.83984375, "KG": 0.49609375, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "the utopian Ascona community", "John W. Henry", "Michael J. Fox", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Power Rangers Turbo", "eastern", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five aerial victories", "Jean Cayrol", "the Seasiders", "Musicology", "Dragon TV", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1928", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "Golden Globe Award", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "the closing scene of the final episode of the first season", "`` Everywhere ''", "the birth centenary of Pandit Jawaharlal Nehru", "honda", "Adam Smith", "Republic of Upper Volta", "56", "Nkepile M abuse", "Eintracht Frankfurt", "U.S. Marines", "Hephaestus", "Amherst College", "two courses"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7122653388278388}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 0.8571428571428571, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-1498", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-5896", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.578125, "CSR": 0.553125, "EFR": 0.9629629629629629, "Overall": 0.7215769675925926}]}