{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=100.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 2060, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection", "Los Angeles Times", "the Broncos", "anticlines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end", "1894", "Rhenus", "Pacific", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "corpses", "United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "squared integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Taoism", "Matthew 16:18", "U.S.-flagged Maersk Alabama", "Rwanda", "revelry", "his health", "Hugo Vihlen", "the outskirts of a small Southern town"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7909722222222222}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.5, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-5112", "mrqa_squad-validation-2969", "mrqa_squad-validation-7566", "mrqa_squad-validation-9243", "mrqa_squad-validation-9655", "mrqa_squad-validation-7763", "mrqa_squad-validation-4772", "mrqa_squad-validation-7728", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.71875, "CSR": 0.7734375, "EFR": 0.8333333333333334, "Overall": 0.8033854166666667}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "the coast of Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "presidential representative democratic republic", "allows those tainted by sin to nevertheless make a truly free choice to accept or reject God's salvation in Christ", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "Arizona Cardinals", "1991", "Mercury/Gemini", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "to become more integral within the health care system", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "The Spice Girls", "Documents", "the company's factory in Waterford City, Ireland", "nitrogen", "Nolan, WB Reteam for Sci-Fi Actioner Inception", "the Florida current feeds the Gulf Stream that flows east of Cape Hatteras;  (3) the looping motion in Buoy ID 30688", "6 Academy Awards", "It always begins with the music", "conductor", "Illinois", "Rafael Palmeiro Corrales", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.765625, "QA-F1": 0.8089502125347714}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16216216216216214, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.22222222222222224, 0.19999999999999998, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-9805", "mrqa_squad-validation-235", "mrqa_squad-validation-3967", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936"], "SR": 0.765625, "CSR": 0.7708333333333334, "EFR": 0.9333333333333333, "Overall": 0.8520833333333333}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "monumental size", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "beautiful voice", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "The Commission's President", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "Edict of Nantes", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "multiple revisions", "philanthropic initiative", "integer factorization problem", "necessity", "Isel", "adapted quickly and often married outside their immediate French communities", "former Pakistani Prime Minister Benazir Bhutto", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "the late 19th century", "Channel Islands", "honoring their different epistemological spheres", "Alberich", "9", "How Emeril Really Feels About the Word 'Bam'", "Churchill Downs", "The port of Terneuzen is the third largest in the Netherlands, after those of Rotterdam and Amsterdam.", "less than number of sides of the three that make up fire air and water", "the infamous shower scene", "India", "study insects and their relationship to humans, other organisms, and the environment", "the limbic system", "trahan Mubarak", "George Fox", "Maryland", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorgate", "\"Krabby Road\""], "metric_results": {"EM": 0.625, "QA-F1": 0.6611979166666666}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-801", "mrqa_squad-validation-9286", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_hotpotqa-validation-437", "mrqa_hotpotqa-validation-3821"], "SR": 0.625, "CSR": 0.734375, "EFR": 0.75, "Overall": 0.7421875}, {"timecode": 4, "before_eval_results": {"predictions": ["higher plants", "Parliament of Victoria", "Zaha Hadid", "the Marquis de Vaudreuil", "Science and Discovery", "Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "The Skirmish of the Brick Church", "the port city of Kaffa in the Crimea", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "1985", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "Sandro Bondi", "22", "planned attacks in the southern port city of Karachi", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "disposable income", "Muslim", "This will be the first time any version of the Magna Carta has ever gone up for auction", "\"a fantastic five episodes.\"", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "a woman who may have been contacted through a Craigslist ad", "one", "most popular baby names", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "bull"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7043582887700535}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.15999999999999998, 1.0, 0.0, 0.0, 0.32, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_squad-validation-166", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2965", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.6875, "CSR": 0.725, "EFR": 0.9, "Overall": 0.8125}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "Connectional Table", "Deformational", "a high-level marketing manager, was given the job of turning the business around", "roughly 500,000", "Ofcom", "Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches", "2011", "algae", "part of a rule connected with civil disobedience", "June 1978", "Milton Latham", "1914", "the Philippines", "the Broncos", "the 1970s", "the spoils of the war", "German Te Deum", "1795", "Bermuda 419", "compressing and cooling", "Infinity Broadcasting Corporation", "semi-legal", "1972", "rudimentary", "1957", "mother-of-pearl", "Gene Barry", "President of the United States negotiates treaties with foreign nations", "It is mainly for the purpose of changing display or audio settings quickly", "from an Ohio newspaper on 8 February 1925", "President since Woodrow Wilson, with the notable exception of Herbert Hoover, has made at least one State of the Union report as a speech delivered before a joint session of Congress", "radius R", "Panning", "Justin Timberlake", "Brazil, China, France, Germany, India, Indonesia, Italy, Japan, South Korea, Mexico, Russia, Turkey, the United Kingdom", "the un security council get troops for military actions", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's opened its first three stores in Canada", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "infant, schoolboy, lover, soldier, justice, Pantalone and old age", "most episodes feature a storyline taking place in the present ( 2016 -- 2018, contemporaneous with airing )", "Morgan Freeman reprising his role as detective Alex Cross", "David Gahan", "it includes a restaurant, spa, and bed - and - breakfast", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "people prepare for the long Lenten fast", "Jaipur", "Johan Persson and Martin Schibbye", "a small and fast naval ship designed to carry torpedoes into battle", "Newport"], "metric_results": {"EM": 0.625, "QA-F1": 0.6879324114393874}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7142857142857143, 0.38888888888888895, 0.0, 0.13793103448275862, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 0.3636363636363636, 0.5, 0.0, 0.5833333333333334, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4836", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-9908", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.625, "CSR": 0.7083333333333333, "EFR": 0.75, "Overall": 0.7291666666666666}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "social and political action", "1936", "the New Birth", "gold", "a 3\u20130 lead", "Vivienne Westwood", "reduction", "disease", "TGIF", "Confucian propriety and ancestor veneration", "Luther's rediscovery of \"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "a chain or screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "members", "end of the season", "10", "Jacob", "African-Americans", "will not support the Stop Online Piracy Act", "Marvin Chase", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Stuttgart on Sunday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "North Korea's reclusive leader Kim Jong- Il", "first five Potter films", "know what's important in life", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "Her husband and attorney, James Whitehouse", "we want to ensure we have all the capacity that may be needed over the course of the coming days", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "Mike Gatting", "Colgate University", "a charter for the Church of Christ, Scientist,", "unsaturated fats are comprised of lipids that contain?", "Luke 6 : 67 -- 71"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7425379308191808}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.2666666666666667, 1.0, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.0, 0.75]}}, "before_error_ids": ["mrqa_squad-validation-800", "mrqa_squad-validation-2133", "mrqa_squad-validation-486", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.671875, "CSR": 0.703125, "EFR": 0.8571428571428571, "Overall": 0.7801339285714286}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism in the Small Catechism", "Jim Gray", "unequal", "July 1969", "Hitler's secret police demanded to know if they were hiding a Jew in their house.", "yellow chlorophyll precursor", "spontaneous", "the courts of member states and the Court of Justice of the European Union", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "up to \u00a339,942", "21 October 1512", "James O. McKinsey", "dance Your Ass Off", "\"Freshman Year\" experience", "India", "Zulfikar Ali Bhutto", "Lindsey oil refinery", "April 24 through May 2", "Krishna Rajaram", "early detection and helping other women cope", "250,000", "Timothy Masters", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jared Polis", "William S. Cohen", "\"Dance Your Ass Off\"", "a comprehensive detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify", "Gary Brooker", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian.", "seeking help", "Japan", "condition", "sonhood experience in a World War II internment camp", "Norman given name Robert", "Olympics", "Matt Winer", "Doc Holliday", "opposite R\u00fcgen island", "Mustique", "green"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6700236938240971}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, false, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.9032258064516129, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 0.0, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6799999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-2448", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-1556", "mrqa_squad-validation-2091", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-417", "mrqa_newsqa-validation-3281", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4367", "mrqa_triviaqa-validation-2858"], "SR": 0.59375, "CSR": 0.689453125, "EFR": 0.6923076923076923, "Overall": 0.6908804086538461}, {"timecode": 8, "before_eval_results": {"predictions": ["2009", "The British provided medical treatment for the sick and wounded French soldiers", "Roman Catholic", "archenemy", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday afternoon", "\"Journey's End\"", "immediate", "Levi's Stadium", "Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan", "Einstein", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington Railway", "autonomy", "Islamic", "$12.9 million", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic is the reason for his longevity in the movie business.", "finance", "terminal brain cancer", "attracted some U.S. senators who couldn't resist taking the vehicles for a spin.", "Employee Free Choice act", "separated", "Animal Planet", "crashing his private plane into a Florida swamp.", "FAA said.Flights at Atlanta's Hartsfield-Jackson International Airport were delayed Tuesday afternoon.", "54 bodies", "early detection and helping other women cope with the disease", "Diversity", "$250,000", "making sure water continues flow through the river channel and not spread out over land", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president", "2050", "Alfredo Astiz, a former Navy captain whose boyish looks and deceitful ways", "Abdullah Gul", "Carl Froch", "The Everglades, known as the River of Grass,", "when the cell is undergoing the metaphase of cell division", "Gibraltar", "New Orleans, Louisiana", "Tulip mania", "MIBs mission statement", "If your child has a stuffy nose, you can buy saline nose sprays and drops over-the-counter.", "Get up-to-date St. Louis Blues statistics, schedules, rosters and much more on Hockey-Reference.com."], "metric_results": {"EM": 0.609375, "QA-F1": 0.6885911724727515}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 0.3076923076923077, 1.0, 0.0, 0.2857142857142857, 0.2222222222222222, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3910", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.609375, "CSR": 0.6805555555555556, "EFR": 0.6, "Overall": 0.6402777777777777}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "His wife Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "\"hoos\"", "30%\u201350%", "very badly disposed towards the French, and are entirely devoted to the English.", "United States", "CRISPR sequences", "six", "about 300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "issues related to the substance of the statement.", "Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "providing the basic securities that Turkey can be a great partner.", "average of 25 percent", "a gym", "Jennifer Arnold and husband Bill Klein,", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "two and a half hours.", "Elin Nordegren", "Europe, Asia, Africa and the Middle East", "6,000", "banned substance cortisone.", "President Clinton.", "delivered three machine guns and two silencers to the hip-hop star, according to a Justice Department statement.", "Morgan Tsvangirai.", "policing the world and Africa", "future relations between the Middle East and Washington.", "canyon in the path of the blaze", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school, their books burned,", "strife in Somalia", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia Police Department", "violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "the area was sealed off, so they did not know casualty figures.", "London", "after Shawn's kidnapping", "the immediate physical and social setting in which people live or in which something happens or develops.", "William Tell", "OutKast", "Groundhog Day", "t", "fairground"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6236106254856255}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.08, 0.4, 0.0, 0.923076923076923, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 0.5, 1.0, 0.09090909090909091, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0, 0.0, 0.0, 0.4, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-9194", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3854", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.53125, "CSR": 0.665625, "EFR": 0.7, "Overall": 0.6828125}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Cathedral of Saint John the Divine", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction", "Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "within the premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "primary endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "broken pelvis", "issued his first military orders as leader of North Korea", "snow, sleet, freezing drizzle or rain.", "Willem Dafoe", "Maude", "Phillip A. Myers.", "Korea", "two weeks after Black History Month", "58", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Spc. Megan Lynn Touma,", "Dangjin", "\"novel that you would be embarrassed to buy\"", "Chinese President Hu Jintao", "magazine", "his injuries,", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next.", "President Bush", "Jeffrey Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "American Airlines are true or not doesn't really matter", "16 August 1975", "Bonnie Aarons", "one", "kabinett - Wines made with fully ripened grapes.", "Lionsgate.", "James Lofton", "meditation", "hair-like structures that help paramecium move around."], "metric_results": {"EM": 0.640625, "QA-F1": 0.701886047979798}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7230", "mrqa_squad-validation-1299", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-7134", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.640625, "CSR": 0.6633522727272727, "EFR": 0.782608695652174, "Overall": 0.7229804841897234}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "The combination of hermaphroditism and early reproduction", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company under the Office of Alien Property (OAP) seal. John G. Trump,", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching.", "Elway", "Philo", "36 acres", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "sum of divisors", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "David Copperfield", "pink mouse", "antelope", "nipples", "Triassic Periods", "cooperative", "Anastasia Dobromyslova", "Lady Gaga", "9", "The Female Brain", "radish", "Robert Ludlum", "a great power", "(.mov) or (.avi)", "The Donington Grand Prix Collection is, quite simply, the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live.", "Hebrew", "The London Underground Piccadilly Line", "Wisconsin", "orangutan", "Manet", "The Magic Finger", "Wyoming", "2005", "1969", "Dodge", "bawdy", "Venice", "a peplos.", "Enrico Caruso", "Elizabeth Arden", "lightweight baby buggy with a collapsible support assembly", "Sir Hardy Amies", "Liechtenstein", "separately in England and Wales", "Cathy Dennis and Rob Davis", "Cody Miller", "Brown Square Station", "Israel's vice prime minister compared Iran to Nazi Germany", "Golden Gate Yacht Club of San Francisco", "fl flickr... dreamy oasis in which to admire the works of the master shoemaker.... She's so beloved by Italians they've even named a rose in her honor.", "Jamaica", "Buddhism"], "metric_results": {"EM": 0.609375, "QA-F1": 0.693374418873089}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 1.0, 0.23076923076923078, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.9090909090909091, 1.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-2092", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-3759", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983"], "SR": 0.609375, "CSR": 0.6588541666666667, "EFR": 0.6, "Overall": 0.6294270833333333}, {"timecode": 12, "before_eval_results": {"predictions": ["Southern Border Region", "70-50's", "Panini", "new laws or amendments to existing laws as a bill; a committee of the Parliament can present a bill in one of the areas under its remit", "anti-colonial movements", "the Rhine Valley", "A", "by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship.", "in the case of an express wish of the people to withdraw from the EU.", "1788", "2006", "Roman Catholic", "Navarre", "John Wesley", "because the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "Ness Point", "John Mayer", "Sue Ryder", "Don Wayne", "Virgil", "France", "T.S. Eliot", "Nick Boles", "Sir Hugo Drax", "Vladivostok", "Sheryl Crow", "TESLAR Satellite", "\"The basics\"", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "cosmology", "gin", "George Clooney", "Eric Coates", "James Chadwick", "\"No one was saved\"", "Monopoly", "champagne", "an extended period of abundant rainfall lasting many thousands of years.", "the U.S.", "Brigit Forsyth", "Baron of Kilmore", "\"Land of the Rising Sun\"", "The History of Troilus and Cressida", "Thomas Edward Lawrence", "Kent", "Renoir\u00b4s", "Phase III", "white", "Switzerland", "lime juice, sugar, soda water", "people of France to the people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "The short version of my version was I heard they were doing a new \"Friday the 13th,\" and I've never tried to pursue a role before and I went, I really want to do this.", "bremen", "The Goat Amalthea", "\"The Screening Room\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.5216510343618513}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8387096774193548, 0.08695652173913043, 1.0, 1.0, 1.0, 0.5, 1.0, 0.9600000000000001, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9452", "mrqa_squad-validation-6655", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_squad-validation-3161", "mrqa_squad-validation-4590", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-302", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-2446", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_triviaqa-validation-3503", "mrqa_naturalquestions-validation-594", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_newsqa-validation-3207", "mrqa_searchqa-validation-8450", "mrqa_searchqa-validation-9647", "mrqa_newsqa-validation-3860"], "SR": 0.46875, "CSR": 0.6442307692307692, "EFR": 0.7058823529411765, "Overall": 0.6750565610859729}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "\"it would appear to be some form of the ordinary Eastern or bubonic plague\"", "their own militia", "days, weeks and months", "Over 61", "quality of a country's institutions", "cilia", "friction", "Sky Digital", "2005", "force", "business", "John Connally", "saffron", "hymenaeus", "Zeus", "a chemical", "the Suez Canal", "Brigit Forsyth", "Call My Bluff", "March 10, 1997", "crazed Holiday", "The Battle of the Three Emperors", "Velazquez", "Ashe", "lizards", "strong cold southwest wind", "table tennis", "cMAJ", "penhaligon", "Gandalf", "monsieur C. Auguste Dupin", "Jinnah International", "Monday", "capital of Venezuela", "beads", "soap", "highball", "Avro Lancaster", "india", "konnie Huq", "melon balm", "harrods", "2007", "Christina Ricci", "scarface", "pale yellow", "aluminium", "bubba", "June 12, 2018", "Filipino American", "London", "Lambic", "Nook", "Steven Green", "semicolons", "cunY-CoLAG", "cesse", "\"Every Breath You Take\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.5958333333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, false, true, false, true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-6933", "mrqa_squad-validation-2920", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-3807", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-6708", "mrqa_triviaqa-validation-4981", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-8598", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-13371"], "SR": 0.515625, "CSR": 0.6350446428571428, "EFR": 0.8709677419354839, "Overall": 0.7530061923963134}, {"timecode": 14, "before_eval_results": {"predictions": ["seven months old", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "sleep", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "a declining state of mind", "1898", "The Deadly Assassin and Mawdryn undead", "radioisotope thermoelectric generator", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat in the hat", "2020", "1974", "332", "1997", "Authority", "senior", "Spanish moss", "Chinese cooking for over 400 years", "Vienna", "2 World Trade Center", "Kevin Spacey", "1 November", "2.5", "lymph", "International Border", "President", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "October 1, 2014", "United States", "Claims adjuster", "nucleus", "Darlene Cates", "Atlanta", "homicidal thoughts of a troubled youth", "infection, irritation, or allergies", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column", "three", "nee", "long", "Kew Gardens", "Nikita Khrushchev", "million dollars", "Alexandros Grigoropoulos", "reaper", "NYPD", "BBC building in Glasgow, Scotland", "lyre King Live"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6809466575091574}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.5333333333333333, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.5, 0.2857142857142857, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7649", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-121", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.5625, "CSR": 0.6302083333333333, "EFR": 0.7857142857142857, "Overall": 0.7079613095238095}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "late night talk shows", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "ESPN Deportes", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 ) in the Philippines or $60 abroad", "60", "Seattle, Washington", "Battle of Antietam", "Nicolas Anelka", "In Time", "by the early 3rd century", "Glenn Close", "four times", "Agostino Bassi", "The first five seasons of Prison Break have been released on DVD and Blu - ray in Regions 1, 2, and 4", "Malibu, California", "the church at Philippi", "the Dutch", "September 2017", "Professor Kantorek", "1546", "Jane Fonda", "Bhupendranath Dutt", "a warrior, Mage, or rogue coming from an elven, human, or Dwarven background", "Dr. Lexie Grey ( Chyler Leigh )", "Majandra Delfino", "December 19, 1971", "Uruguay", "Alex Skuby", "Thomas Middleditch", "The National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "Director of National Intelligence", "Defence Against the Dark Arts", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira hatches from the stone", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal. The Man", "burt Hammersmith", "Rachel Kelly Tucker", "Bohemia", "Earwigs", "Code 02PrettyPretty", "musician", "opposition group, also known as the \"red shirts,\"", "the abduction of minors", "Nevada", "Isabel Allende", "Stage Stores, Inc.", "1881"], "metric_results": {"EM": 0.5, "QA-F1": 0.6192254360223111}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.2, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.6666666666666666, 1.0, 0.09523809523809523, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 1.0, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.375, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_searchqa-validation-5103", "mrqa_hotpotqa-validation-1852"], "SR": 0.5, "CSR": 0.6220703125, "EFR": 0.71875, "Overall": 0.67041015625}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "Arizona Cardinals", "Robert Watson", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Khitan", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland", "Office", "SAVE", "SAS Technical Services", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award Best Actor", "Jello Biafra drew on Nardwuar's face with a marker pen", "1745 rebellion of Charles Edward Stuart", "Burny Mattinson, David Michener, and the team of John Musker and Ron Clements", "Sir William McMahon", "North Sea", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "the Chengdu Aircraft Corporation (CAC) of China", "Delacorte Press", "Neighbourhoods", "Secretariat", "Wake Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of France", "\"Southern Living\" Reader's Choice Awards", "William Shakespeare", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Alticor", "Parlophone Records", "Durban", "Surrey", "\"That Bizarre Girl\"", "Charles Russell", "Boyd Gaming", "three different covers", "1991", "Glenn Close", "Florence Glenda Ballard", "Neighbours", "Ewan McGregor", "2011", "pippa passes", "an enslaved African American who led", "new government \"that reflects the will of the Zimbabwean people,\" as well as one individual.\"", "Brown-Waite"], "metric_results": {"EM": 0.578125, "QA-F1": 0.663670183982684}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.3636363636363636, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8509", "mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-5514", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.578125, "CSR": 0.6194852941176471, "EFR": 0.8888888888888888, "Overall": 0.754187091503268}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "inner chloroplast membrane", "Charlie Harper", "Stevie Wonder", "Beaver", "La Boh\u00e8me", "formic acid", "Puente del Arzobispo", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Xenophon", "Fuller's", "Fresh Water Load Line", "Nick Hornby", "The Comedy of Errors", "Charles V", "England", "Lagertha", "weight plates", "\"big house\"", "Hadrian", "France", "human flea", "Moonee Ponds, a suburb in Melbourne, Victoria", "Essen", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "Manchester United", "Robert Cummings", "Jessica Simpson", "Boy George", "In 1906, Finland became the first country in the world,", "3000m", "Scotland", "Russia", "Travis Tritt and Marty Stuart", "It was a Confederate victory, followed by a disorganized retreat of the Union forces", "New Jewel Movement", "sub-Saharan Africa", "U.S. 93", "Anjuna beach", "L'Aventure d'une fille de...", "Oshkosh", "two", "jeopardy/1870_Qs.txt", "a special edition of a newspaper that is published when something important happens"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6348958333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_triviaqa-validation-2812", "mrqa_naturalquestions-validation-767", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.578125, "CSR": 0.6171875, "EFR": 0.7777777777777778, "Overall": 0.6974826388888888}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "Coppolas and, technically, the Farrow / Previn / Allens", "Anna Faris", "peninsular mainland", "ability to comprehend and formulate language", "Splodgenessabounds", "Tyrion", "electron donors", "Alison", "1985", "19 state rooms", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Alice", "20 November 1989", "Coton", "55 -- 69 %", "Ella Eyre", "1995", "Identification of alternative plans / policies", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "arterioles", "July 21, 1861", "Dr. Addison Montgomery", "capital and financial markets", "empty line", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "universal significance", "September 2017", "moral", "Rising Sun Blues", "Part 2", "Dumbo", "the duke of Monmouth", "Christian", "Robert L. Stone", "2008", "Yemen", "telemachus", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6761189892623716}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 0.2857142857142857, 0.0, 0.6666666666666666, 0.8, 1.0, 0.19999999999999998, 1.0, 0.0, 0.6666666666666666, 0.4, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6242", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-7111", "mrqa_hotpotqa-validation-4735"], "SR": 0.5625, "CSR": 0.6143092105263157, "EFR": 0.8571428571428571, "Overall": 0.7357260338345863}, {"timecode": 19, "before_eval_results": {"predictions": ["everything that is used to work sorrow over sin is called the law, even if it is Christ's life, Christ's death for sin, or God's goodness experienced in creation", "black", "Illinois Country, hugging the east side of the Mississippi River and its tributaries", "Jaime Weston", "1978", "high art and folk music", "warming", "the mid-sixties", "270,000", "Long troop deployments in Iraq, above, and Afghanistan have been cited in the rise in military suicides.\"We must find ways to relieve some of this stress,\" said Gen. Peter W. Chiarelli,", "Joe Pantoliano", "a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "32 percent", "natural resources around the islands should be protected, and Britain must accept international resolutions labeling the Falklands a disputed area.", "Tuesday in Los Angeles. Cole said she underwent chemotherapy in an aggressive way to fight the virus. Within four months of getting chemotherapy, both of Cole's kidneys failed.\"I couldn't breathe.", "forgery and flying without a valid license", "Anil Kapoor", "a 19-year-old boy is sleeping in your bed, with your wife... \".I totally understand O.J. I get it.\"", "President Obama's surge plan to head to Afghanistan's restive provinces to support Marines and soldiers fighting a dug-in Taliban force.", "unwanted baggage from the 80s", "The Louvre", "snowstorm", "sports cars", "11 healthy eggs", "Mutassim", "two Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18, the publicist said.The Glasgow, Scotland concert has been shifted from this Sunday to May 1", "\"Pain is temporary, film is forever\"", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic, the defense ministry said Wednesday.", "Al alcohol", "Atlantic Ocean", "Ahmed", "cortisone", "fast cars, drink and celebrity parties", "Kingman Regional Medical Center", "current TV -- media venture launched by Clinton's former vice president, Al Gore.", "Manmohan Singh", "Michael Jackson", "Tuba Sahaab has a dream to meet her hero.", "40 militants and six Pakistan soldiers dead", "Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list, had been released.", "governor, if the president had actually delivered the targeted temporary stimulus package that he described, I think you'd see a lot more money in the private sector.", "Southeast", "\"Misty Cummings, then known asMisty Croslin, was the last person known to have seen Haleigh the night she disappeared from the family's rented mobile home.", "Carol Browner", "we give guidance. We give an ear to listen. And, again, I don't get caught up in gossip.", "a tracheotomy", "back at work", "necropsy or animal autopsy", "27", "Karina Smirnoff", "John Adams, a leader in pushing for independence, had persuaded the committee to select Thomas Jefferson to compose the original draft of the document, which Congress edited to produce the final version", "onions", "Zager & Evans", "Bobby Hurley", "At-large", "\"adult Theatre - You must be 21 and able to prove it.", "(Oliver) Cromwell", "Lapland", "1937", "Emad Hashim"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5301813293603788}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, false, false, false, false, true, false, true, true], "QA-F1": [0.6, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0689655172413793, 1.0, 1.0, 0.0, 0.1904761904761905, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.10526315789473684, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.923076923076923, 0.6666666666666666, 0.7407407407407407, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.13793103448275862, 0.0, 0.8, 0.4, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-1760", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_triviaqa-validation-7208", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-2013", "mrqa_searchqa-validation-328", "mrqa_hotpotqa-validation-2922"], "SR": 0.40625, "CSR": 0.60390625, "EFR": 0.7894736842105263, "Overall": 0.6966899671052631}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "Rhenus", "1331", "Death wish Coffee", "L", "Cameroon", "1994", "ballots", "clothes that are consistent and accessible", "three empty vodka bottles,", "\"There is no silver bullet and no quick, cheap or easy solutions. There is no substitute for more resources and sacrifice,\"", "1959", "Nico Rosberg", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "\"Ms. Hamlin did not want to remove her breast piercings,\"", "composer of \"Phantom of the Opera\" and \"Cats\"", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony, 2,", "Amanda Knox's aunt", "well over 1,000 pounds", "Iran's nuclear program.", "bright blue-purple", "pulling on the top-knot of an opponent,", "ceo Herbert Hainer", "Brett Cummins,", "a nearby day care center whose children are predominantly African-American.", "inmates", "Cameron-Ritchie", "E! News", "Most of the 103 children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans,", "jobs up and down the auto supply chain: from dealers to assembly workers and parts markers.", "saying Tuesday the reality he has seen is \"terrifying.\"", "waterboarding at least 266 times on two top al Qaeda suspects,", "Mexican's attorney general's office responded with a statement saying that it would investigate the video and any group that tries to take justice into its own hands.", "Republicans", "\"They left without me,' which is what I thought I would do.\"", "Alexandros Grigoropoulos, whose death", "deciding the duties of the new prime minister has been a sticking point in the negotiations.", "know what's important in life", "Kim Jong Il seems to be \"testing the new administration.\"", "Angola", "Matthew Fisher", "jund Ansar Allah, or Soldiers of the Partisans of God,", "boogeyman Jason Voorhees", "This was not any one particular act; this was just a combination of things that had a medical impact on him, that hurt his health.", "Sea World in San Antonio", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "about 50 formal applications for speed attempts during 2008.", "the Ku Klux Klan", "1939", "Branford College", "Bury, Oldham, Rochdale, Stockport, Tameside, Trafford, Wigan, and the cities of Manchester and Salford.", "husbands", "Malayalam movies", "August 17, 2017", "a jacket, gloves or a briefcase", "mice followed, in the '80s | clone. right: Dave.", "Hodel", "access to US courts", "Coldplay"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4610407228005912}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.07407407407407407, 0.0, 0.0, 1.0, 0.9523809523809523, 0.0, 0.25, 0.23076923076923078, 0.8, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.07692307692307693, 0.09523809523809522, 0.8571428571428571, 0.0, 0.14814814814814814, 1.0, 0.1, 0.0, 1.0, 0.0, 0.10526315789473685, 1.0, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.19047619047619047, 0.19999999999999998, 1.0, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.22222222222222224, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-1888", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-3783"], "SR": 0.359375, "CSR": 0.5922619047619048, "EFR": 0.6097560975609756, "Overall": 0.6010090011614402}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "Splash", "Nicola Adams", "copper and zinc", "Austria, Prussia, Russia, France, and also Poland,", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "breast", "Madonna's", "Glasgow", "a satellite-based navigational system that can tell users exactly where they are on Earth.", "Australia", "gizzard", "Pearson PLC.", "Irish Setter", "American Civil War,", "Loch Lomond", "Jesacomaro", "Queensland", "a gentle cat with a somewhat shy nature around strangers.", "Republic of China", "Harrisburg", "Mustela erminea,", "glockenspiel", "Dr John Sentamu", "Baka hunter-gatherers", "Cruella de Vil", "Anne Boleyn", "Pye", "Holly Johnson", "Emma Chambers", "Charles V", "the community", "Russell Crowe", "Theodore Roosevelt", "Grant Elliott, Luke Ronchi and Martin Guptill.", "Puck", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "Atlantic", "Albert Square", "Newbury", "the Old Testament", "70 million people, at that time 21 % of the world's entire population", "Target Corporation", "Sister, Sister", "Michelle Rounds", "\"No one on our end was ever contemplating pulling the plug,\"", "Oxfam, concerned with poverty alleviation,.... The Global Fund to Fight AIDS, Tuberculosis and Malaria", "Swamp Fox", "better conditions for inmates, like Amnesty International.", "talk show queen Oprah Winfrey.", "his mother."], "metric_results": {"EM": 0.546875, "QA-F1": 0.5935229700854701}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.0, 0.0, 1.0, 0.06666666666666667, 0.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-3498", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2484", "mrqa_newsqa-validation-2971", "mrqa_searchqa-validation-11802", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.546875, "CSR": 0.5901988636363636, "EFR": 0.8275862068965517, "Overall": 0.7088925352664577}, {"timecode": 22, "before_eval_results": {"predictions": ["coughing and sneezing", "1765", "primarily along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "Vicodin, generically known as hydrocodone", "reed", "Robert Peary", "pearls", "charlie", "Carrie Underwood", "drambuie", "Nero", "University of Michigan", "Langston Hughes", "self-torture", "charlie kramm", "Tito Puente", "riata", "norma", "USS LST 325", "prey drive", "Real Madrid", "Arturo Toscanini", "biology", "Miracle in the Andes: 72 Days on the Mountain", "triumphal arch", "Montenegro", "discus", "thick slice of bread", "basidiomycota", "james", "norman", "Idi Amin", "Commercial Mowing & Agriculture Equipment", "a body, or a personal item associated with a saint", "terracotta", "Plutarch", "jerry", "masa harina", "two-minute", "the Vikings.", "fairfield Street", "champs-Elyses", "typhoid fever", "a drowned river valley.", "baviere-quebec.org", "jenestown", "The telegraph", "University Post Office", "hydrogen peroxide & yeast creates foam, steam & notably causes heat to be given off in this type of 10-letter chemical reaction", "John Knox", "internal reproductive anatomy", "$657.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "The Epidemiologists help with study design, collection, and statistical analysis of data, amend interpretation and dissemination of results ( including peer review and occasional systematic review )", "jape", "Tesco", "A4", "Graham Hill", "Battelle Energy Alliance", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services.", "debris", "$10 billion", "out in the woods"], "metric_results": {"EM": 0.390625, "QA-F1": 0.45868470893141944}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.6666666666666666, 0.8, 0.0, 0.0, 1.0, 0.0, 0.09090909090909091, 1.0, 0.5, 0.21052631578947367, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-13026", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-2327", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-5091", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-1118", "mrqa_hotpotqa-validation-68"], "SR": 0.390625, "CSR": 0.5815217391304348, "EFR": 0.7435897435897436, "Overall": 0.6625557413600892}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "the Gulf of Mexico", "cat", "the daughter of Tony Richardson and Vanessa Redgrave", "Basel, Switzerland", "The Argonauts", "prometheus", "Altamont Speedway Free Festival", "John F. Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a multi-user dungeon", "Italy", "khaki", "magma", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "the Mendip Hills", "Barack Obama", "the Earth", "Nafea Faa Ipoipo", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the colony of Suriname", "Justin Trudeau", "aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations", "Denis Law", "Love Is All Around", "Mr. Golding", "Sally Ride", "Cyclone; Influenza; or Computer virus", "Fife", "Money Saving", "Adidas", "the Snark", "Elizabeth Arden", "Buxton", "woe", "Octopussy.", "all pieces capture opponent's pieces by moving to the square that the opponent's piece occupies.", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "The Wall Street Journal Europe", "fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7359834558823529}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848"], "SR": 0.6875, "CSR": 0.5859375, "EFR": 0.75, "Overall": 0.66796875}, {"timecode": 24, "before_eval_results": {"predictions": ["limited coercion", "the chosen machine model", "Fox", "1997", "a suite of network protocols", "Noriko Savoie", "15", "the first home series defeat on Australia in almost 16 years as they wrapped up a nine-wickets win over the world's number one ranked Test nation in Melbourne on Tuesday.", "Pyongyang and Seoul", "killed a man, the latter cheated on his wife.", "11", "fly to Australia", "Alwin Landry's supply vessel Damon Bankston", "Chaffetz is a conservative Republican married father of three who is sleeping on a cot in his congressional office to save money.", "money or other discreet aid for the effort if it could be made available,", "Sarah", "normal maritime traffic", "environmental", "Los Ticos", "Afghan police", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "38", "70,000 or so", "climatecare", "E! News", "coach", "Steve Williams", "McDonald's", "writing her short stories (she has already published one book) and shows me a cartoon character she has created called \"Tomato Man.\"", "pastor Paula White", "2008", "Diego Maradona", "Dog patch Labs", "The Stooges", "two", "Itawamba County School District", "Romney", "EU naval force", "Plymouth Rock", "Liza Murphy", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "police", "former U.S. secretary of state", "At least 33", "five", "improve health and beauty.", "a growing number of state governments going after them.", "the most powerful form of prevention is believing that students can help stop crime from happening.", "Alwin Landry's", "Krishna Rajaram", "December 1", "killing", "feminine", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "Northern Ireland", "radar", "art", "the 16th season", "23", "South America", "freestyle", "the Nightingale Training School", "the Crystal Skull"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5876374012219396}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.09090909090909091, 0.5555555555555556, 1.0, 0.8, 0.0, 0.0, 0.0, 0.13333333333333333, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.12121212121212123, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2222222222222222, 0.19354838709677422, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.4444444444444445]}}, "before_error_ids": ["mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3338", "mrqa_newsqa-validation-3169", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.4375, "CSR": 0.5800000000000001, "EFR": 0.7222222222222222, "Overall": 0.6511111111111112}, {"timecode": 25, "UKR": 0.78125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1085", "mrqa_hotpotqa-validation-1324", "mrqa_hotpotqa-validation-1494", "mrqa_hotpotqa-validation-1658", "mrqa_hotpotqa-validation-1869", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2314", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-2839", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3025", "mrqa_hotpotqa-validation-3629", "mrqa_hotpotqa-validation-3870", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-4806", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5120", "mrqa_hotpotqa-validation-5340", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5853", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-955", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-10295", "mrqa_naturalquestions-validation-10574", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-1735", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-2650", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-3516", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-3964", "mrqa_naturalquestions-validation-4014", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-6140", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-6786", "mrqa_naturalquestions-validation-7025", "mrqa_naturalquestions-validation-703", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7683", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-938", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9733", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-9991", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-1367", "mrqa_newsqa-validation-14", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-1493", "mrqa_newsqa-validation-1501", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-1550", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1888", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-2048", "mrqa_newsqa-validation-2083", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2965", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-3207", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3281", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-3368", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3519", "mrqa_newsqa-validation-3539", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3571", "mrqa_newsqa-validation-3618", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3750", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-445", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-474", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-704", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-830", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-12513", "mrqa_searchqa-validation-12564", "mrqa_searchqa-validation-1273", "mrqa_searchqa-validation-13120", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-1439", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-3582", "mrqa_searchqa-validation-5103", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-574", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-8011", "mrqa_searchqa-validation-8325", "mrqa_searchqa-validation-8598", "mrqa_searchqa-validation-9016", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-9467", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9843", "mrqa_squad-validation-10033", "mrqa_squad-validation-10066", "mrqa_squad-validation-10139", "mrqa_squad-validation-1018", "mrqa_squad-validation-10406", "mrqa_squad-validation-1083", "mrqa_squad-validation-111", "mrqa_squad-validation-1174", "mrqa_squad-validation-1255", "mrqa_squad-validation-1268", "mrqa_squad-validation-1291", "mrqa_squad-validation-133", "mrqa_squad-validation-1454", "mrqa_squad-validation-1632", "mrqa_squad-validation-1637", "mrqa_squad-validation-164", "mrqa_squad-validation-164", "mrqa_squad-validation-1739", "mrqa_squad-validation-1763", "mrqa_squad-validation-1776", "mrqa_squad-validation-1817", "mrqa_squad-validation-1848", "mrqa_squad-validation-1893", "mrqa_squad-validation-2078", "mrqa_squad-validation-2087", "mrqa_squad-validation-2126", "mrqa_squad-validation-2137", "mrqa_squad-validation-2232", "mrqa_squad-validation-2239", "mrqa_squad-validation-2347", "mrqa_squad-validation-2400", "mrqa_squad-validation-2402", "mrqa_squad-validation-2448", "mrqa_squad-validation-2460", "mrqa_squad-validation-248", "mrqa_squad-validation-2520", "mrqa_squad-validation-2622", "mrqa_squad-validation-2643", "mrqa_squad-validation-2659", "mrqa_squad-validation-2731", "mrqa_squad-validation-2732", "mrqa_squad-validation-2844", "mrqa_squad-validation-2858", "mrqa_squad-validation-2910", "mrqa_squad-validation-2948", "mrqa_squad-validation-2948", "mrqa_squad-validation-2995", "mrqa_squad-validation-3043", "mrqa_squad-validation-3085", "mrqa_squad-validation-3180", "mrqa_squad-validation-3259", "mrqa_squad-validation-3280", "mrqa_squad-validation-3349", "mrqa_squad-validation-3370", "mrqa_squad-validation-3390", "mrqa_squad-validation-3418", "mrqa_squad-validation-3518", "mrqa_squad-validation-356", "mrqa_squad-validation-3567", "mrqa_squad-validation-3632", "mrqa_squad-validation-366", "mrqa_squad-validation-3667", "mrqa_squad-validation-3679", "mrqa_squad-validation-3711", "mrqa_squad-validation-378", "mrqa_squad-validation-3790", "mrqa_squad-validation-3889", "mrqa_squad-validation-3909", "mrqa_squad-validation-392", "mrqa_squad-validation-3957", "mrqa_squad-validation-3959", "mrqa_squad-validation-3967", "mrqa_squad-validation-4058", "mrqa_squad-validation-4067", "mrqa_squad-validation-4070", "mrqa_squad-validation-4116", "mrqa_squad-validation-4128", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4276", "mrqa_squad-validation-4289", "mrqa_squad-validation-4328", "mrqa_squad-validation-436", "mrqa_squad-validation-4607", "mrqa_squad-validation-4673", "mrqa_squad-validation-4691", "mrqa_squad-validation-470", "mrqa_squad-validation-4708", "mrqa_squad-validation-4760", "mrqa_squad-validation-4772", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4834", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-492", "mrqa_squad-validation-4927", "mrqa_squad-validation-4986", "mrqa_squad-validation-5034", "mrqa_squad-validation-5100", "mrqa_squad-validation-516", "mrqa_squad-validation-516", "mrqa_squad-validation-5161", "mrqa_squad-validation-5256", "mrqa_squad-validation-5418", "mrqa_squad-validation-5436", "mrqa_squad-validation-5485", "mrqa_squad-validation-551", "mrqa_squad-validation-565", "mrqa_squad-validation-5702", "mrqa_squad-validation-5762", "mrqa_squad-validation-5874", "mrqa_squad-validation-5929", "mrqa_squad-validation-5936", "mrqa_squad-validation-597", "mrqa_squad-validation-6001", "mrqa_squad-validation-6029", "mrqa_squad-validation-6035", "mrqa_squad-validation-6043", "mrqa_squad-validation-6129", "mrqa_squad-validation-6300", "mrqa_squad-validation-6332", "mrqa_squad-validation-639", "mrqa_squad-validation-6437", "mrqa_squad-validation-6450", "mrqa_squad-validation-6463", "mrqa_squad-validation-6592", "mrqa_squad-validation-6637", "mrqa_squad-validation-6949", "mrqa_squad-validation-7089", "mrqa_squad-validation-7110", "mrqa_squad-validation-7126", "mrqa_squad-validation-7201", "mrqa_squad-validation-7230", "mrqa_squad-validation-7261", "mrqa_squad-validation-7333", "mrqa_squad-validation-7351", "mrqa_squad-validation-736", "mrqa_squad-validation-7364", "mrqa_squad-validation-7488", "mrqa_squad-validation-7527", "mrqa_squad-validation-7599", "mrqa_squad-validation-7656", "mrqa_squad-validation-7698", "mrqa_squad-validation-7717", "mrqa_squad-validation-7722", "mrqa_squad-validation-7728", "mrqa_squad-validation-7763", "mrqa_squad-validation-7805", "mrqa_squad-validation-7837", "mrqa_squad-validation-7897", "mrqa_squad-validation-7950", "mrqa_squad-validation-7951", "mrqa_squad-validation-7960", "mrqa_squad-validation-7972", "mrqa_squad-validation-800", "mrqa_squad-validation-8014", "mrqa_squad-validation-8109", "mrqa_squad-validation-811", "mrqa_squad-validation-8125", "mrqa_squad-validation-8182", "mrqa_squad-validation-823", "mrqa_squad-validation-8324", "mrqa_squad-validation-8440", "mrqa_squad-validation-8509", "mrqa_squad-validation-859", "mrqa_squad-validation-864", "mrqa_squad-validation-8806", "mrqa_squad-validation-882", "mrqa_squad-validation-8906", "mrqa_squad-validation-893", "mrqa_squad-validation-9008", "mrqa_squad-validation-9063", "mrqa_squad-validation-9162", "mrqa_squad-validation-9194", "mrqa_squad-validation-9254", "mrqa_squad-validation-9318", "mrqa_squad-validation-9364", "mrqa_squad-validation-9460", "mrqa_squad-validation-9486", "mrqa_squad-validation-9530", "mrqa_squad-validation-9541", "mrqa_squad-validation-9552", "mrqa_squad-validation-9600", "mrqa_squad-validation-9623", "mrqa_squad-validation-9655", "mrqa_squad-validation-9896", "mrqa_squad-validation-9908", "mrqa_squad-validation-9990", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1182", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1211", "mrqa_triviaqa-validation-1262", "mrqa_triviaqa-validation-1306", "mrqa_triviaqa-validation-1309", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1710", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-2022", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2684", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-300", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-3164", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-363", "mrqa_triviaqa-validation-3679", "mrqa_triviaqa-validation-3688", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-372", "mrqa_triviaqa-validation-3759", "mrqa_triviaqa-validation-3807", "mrqa_triviaqa-validation-3831", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4202", "mrqa_triviaqa-validation-4222", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-4440", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4675", "mrqa_triviaqa-validation-4835", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5393", "mrqa_triviaqa-validation-5427", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5898", "mrqa_triviaqa-validation-5936", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-6067", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6151", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-6311", "mrqa_triviaqa-validation-6315", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-6506", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-6708", "mrqa_triviaqa-validation-6780", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-7177", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7316", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7462", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-7561", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-975", "mrqa_triviaqa-validation-977"], "OKR": 0.802734375, "KG": 0.48828125, "before_eval_results": {"predictions": ["its 50th anniversary special.", "Thomas Savery", "Vicodin", "Eastern crops", "22,000 years ago onward", "separatist", "Eleven", "269,000", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "38 feet", "Eintracht Frankfurt", "150", "a pool of blood beneath his head.", "Russian bombers have landed at a Venezuelan airfield", "41", "Los Alamitos Joint Forces Training Base", "Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "the shoreline of the city of Quebradillas.", "the Russian air force", "34", "President Obama ordered the eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "around 3.5 percent of global greenhouse emissions.", "Amanda Knox's aunt", "\"several pieces of aircraft equipment were at fault or had broken down.\"", "ensuring that all prescription drugs on the market are FDA approved", "customers", "Tom Baer.", "Pakistan", "The oceans are growing crowded, and governments are increasingly trying to plan their use.", "bikinis", "Brian Mabry", "changed the way the world consumed media", "Sunday", "60 euros", "American Civil Liberties Union", "\"His treatment met the legal definition of torture. And that's why I did not refer the case\" for prosecution.", "truly mind-blowing structures are being planned for the Middle East.", "first name", "he was one of 10 gunmen who attacked several targets in Mumbai", "2006", "San Diego", "Debora Harris, Joyce Mims, Tonya Miller, Quithreaun Stokes, Sheila Farrior.", "Bergdahl, 23, was captured June 30 from Paktika province in southeastern Afghanistan,", "keystroke", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "order and its tactics", "heart", "Hyderabad", "Sinai Peninsula ( / \u02c8sa\u026ana\u026a / ; Arabic : \u0633\u064a\u0646\u0627\u0621\u200e S\u012bn\u0101\u02bc", "to stay, abide", "Las Vegas", "Jackson Pollock", "Lyrical", "Mississippi", "October 4, 1970", "King Duncan", "Brasstown Bald", "the thimble", "taking a walk"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4911855295758328}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, false, false], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.0, 0.8571428571428571, 0.6666666666666666, 0.0, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.27027027027027023, 1.0, 1.0, 0.0, 0.07407407407407408, 0.6666666666666666, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_squad-validation-9432", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_triviaqa-validation-1677", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-1982", "mrqa_searchqa-validation-11832", "mrqa_searchqa-validation-9476"], "SR": 0.390625, "CSR": 0.5727163461538461, "EFR": 0.6666666666666666, "Overall": 0.6623297275641026}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "The military fired warning shots into the air and sprayed water cannons to disperse the crowd.", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot", "Hong Kong's Victoria Harbor", "2002", "seven", "the legitimacy of that race.", "carbon footprint", "more than a dozen", "Monday", "Scarlett Keeling", "two years", "since 1980, the 84-year-old Mugabe has been the country's only ruler.", "regulators in the agency's Colorado office", "Military commission judges also will be able to establish the jurisdiction of their own courts.", "July for A Country Christmas,", "Akshay Kumar", "Alan Graham", "FARC were not targeting indigenous populations but took the action \"against people who independent of their race, religion, ethnicity, social condition etc. accepted money and put themselves at the service of the army", "\"disagreements\" with the Port Authority of New York and New Jersey,", "June 2004", "Michelle Rounds", "David Bowie,", "the death of Prince George's County police Cpl. Richard Findley, who died Friday after being struck by a truck.", "Phil Spector", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "Izzat Ibrahim al-Douri, the highest ranking former member of Saddam Hussein's regime still at large,", "dependable", "sexual assault", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "in his 60s, is incarcerated at the Supermax prison in Florence, Colorado, as is Zayed.", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "same-sex civil unions,", "fallen comrades lost in the heat of battle.", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units", "6 - 6 with one win against a team from the lower Football Championship Subdivision ( FCS )", "Matt Monro", "David Jason", "the innermost digit of the forelimb; thumb.", "1974", "25 million", "Peoria, Illinois", "Hawaii", "KID-FRIendly 4- LETTER", "incense", "Ottoman Empire"], "metric_results": {"EM": 0.546875, "QA-F1": 0.601161488145983}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.1714285714285714, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6086956521739131, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.5, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-891", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-4159", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.546875, "CSR": 0.5717592592592593, "EFR": 0.896551724137931, "Overall": 0.708115321679438}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "John Dillinger,", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen", "Brazil's response to the HIV/AIDS fight has been widely praised and adopted as a model around the world.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Angels", "Indian army", "there's no chance", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "a Starbucks", "BADBUL", "98", "2008", "near the Somali coast", "Paul Ryan", "state senators who will decide whether to remove him from office", "Dr. Jennifer Arnold and husband Bill Klein,", "Pakistan's combustible Swat Valley,", "South Dakota State Penitentiary", "Iran", "last month's Mumbai terror attacks", "know what's important in life,", "in July", "Swiss journalists, a seven-member Spanish flight crew and one Belgian", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death", "Formagruppen", "broken pelvis", "Wednesday at the age of 95.", "the abduction of minors", "gun", "Aniston, Demi Moore and Alicia Keys", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "apteka", "largest", "beta blockers"], "metric_results": {"EM": 0.609375, "QA-F1": 0.754877190766483}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38095238095238093, 1.0, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5714285714285715, 0.8, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.3076923076923077, 1.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 1.0, 0.8421052631578948, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.5, 0.0, 0.3333333333333333, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-560", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2108", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-14535"], "SR": 0.609375, "CSR": 0.5731026785714286, "EFR": 0.88, "Overall": 0.7050736607142858}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "ownership of private industries", "1981", "forgery and flying without a valid license,", "his former caddy, telling reporters Steve Williams apologized and is not a racist.\"", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "Genocide Prevention Task Force.", "shoot down the satellite", "Intel has systematically given PC makers and stores rebates to keep computers with AMD chips off the shelves. AMD (another American company and Intel's only competitor) first raised the red flag in 2000.", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "seven", "\"face of the peace initiative has been attacked,\"", "misdemeanor assault", "one day we will have no more oil and we'll have to find another way to live.", "Anil Kapoor.", "the eradication of the Zetas cartel", "\"The Rosie Show,\"", "Form Design Center.", "collaborating with the Colombian government,", "Christianity and Judaism", "the Dalai Lama's", "Russia", "8 p.m. local time Thursday", "Passers-by", "one day, Nicole noticed a UPS delivery box where it shouldn't be. \"I would just come home, you know, and almost feel nauseaous,\"", "executive director of the Americas Division of Human Rights Watch,", "750", "nearly 100", "Matthew Fisher", "The Ski Train", "Boys And Girls alone", "Ozzy Osbourne", "AbdulMutallab,", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "inconclusive", "5:20 p.m. at Terminal C when a man walked through an exit on the public side to the secure \"sterile\" side for passengers who had cleared screening,", "environmental and political events.", "$250,000", "byproducts emitted during the process of burning and melting raw materials.", "School-age girls", "5,600 people every year, and about 10 percent of those cases are hereditary.", "a million", "the club's board", "Deutschneudorf,", "would let prisons jam cell-phone signals within their walls.", "a deceased organ donor,", "bragging about his sex life on television", "have a vertebral column ( spine ) ; invertebrates don't", "December 11, 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "Festival of Britain on London's South Bank.", "Douglas Hofstadter", "\"The Dark Tower\" series", "American", "Little Women", "Castle Rock", "anchovy"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7030980572895162}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9655172413793104, 1.0, 0.0, 0.0, 1.0, 0.4, 0.9565217391304348, 0.5, 0.0, 1.0, 0.8, 0.08695652173913045, 1.0, 0.4, 1.0, 1.0, 0.125, 1.0, 0.5, 1.0, 0.9090909090909091, 1.0, 0.5333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.14285714285714285, 1.0, 0.1, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-3253", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-229", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_hotpotqa-validation-5376", "mrqa_searchqa-validation-9830"], "SR": 0.5625, "CSR": 0.5727370689655172, "EFR": 0.75, "Overall": 0.6790005387931035}, {"timecode": 29, "before_eval_results": {"predictions": ["stagnant", "poison", "438,000", "Marty Ingels", "coaxial", "Pakistan A in their two-day match against England in October 2015.", "Everbank Field.", "7 members appointed by the chief executive.", "Battle of Dresden", "King James II of England by Arabella Churchill, sister of the 1st Duke of Marlborough.", "1965", "Charles de Gaulle Airport.", "fifth", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Province of Syracuse", "1963", "coca wine", "puzzle", "Knoxville, Tennessee", "Washington, D.C.", "Oryzomyini", "Tom Kartsotis", "2017", "Wayman Lawrence Tisdale", "Mexico", "Srinagar", "Northern Ireland.", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Shohola Falls", "small forward", "ARY Films.", "Erinsborough", "Marine Corps", "Robert A. Iger", "Major Charles White Whittlesey.", "Floridians", "Virginia", "1996 NBA Slam Dunk Contest.", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes,", "IB Diploma Program and the IB Career - related Program for students aged 15 to 18", "Bengal tiger", "off the southernmost tip of the South American mainland", "Cecil B. De Mille", "allergic reaction", "Peter Townsend.", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "The Swiss art heist follows the recent theft in Switzerland of two paintings by Pablo Picasso,", "Russia", "peel and devein Sh shrimp", "Australia"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6487936491612962}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.6666666666666666, 1.0, 0.15384615384615383, 0.35294117647058826, 0.0, 0.33333333333333337, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8164", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4048", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-4935", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-2701", "mrqa_naturalquestions-validation-8450", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-4033", "mrqa_searchqa-validation-2585", "mrqa_searchqa-validation-6793"], "SR": 0.5625, "CSR": 0.5723958333333333, "EFR": 0.7857142857142857, "Overall": 0.6860751488095238}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "effects of deforestation", "Prussian army general, adjutant to Frederick William IV of Prussia", "London", "Dave Thomas", "a farmers' co-op,", "Danish", "1903", "the attack on Pearl Harbor.", "other individuals, teams, or entire organizations.", "ten years of probation", "In Pursuit", "Bolton", "Monty Python's Flying Circus", "Kansas City crime family", "Werner Nowitzki", "the Cecil B. DeMille Award honoree", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E.", "New Jersey", "Norse mythology", "86,112", "Scottish national team", "Ouse and Foss", "United States and Canada", "British comedian", "Apatosaurus", "1885", "American", "Frank Thomas' Big Hurt", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "national and international media,", "The Seduction of Hillary Rodham", "2005", "Lambic", "Tom Clancy's The Division", "Argentina", "Larry Alphonso Johnson Jr.", "Mike Mills", "veto power", "Joseph E. Grosberg", "Chelsea Does", "276,170", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "New York", "Discus thrower", "Aston Villa Football Club", "2005", "228", "NASA's latest missions indicate the moon is much more than a dead, unchanging satellite orbiting Earth.", "Post Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6737784090909091}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4446", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.5625, "CSR": 0.5720766129032258, "EFR": 0.8571428571428571, "Overall": 0.7002970190092166}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "a short story centering on the thoughts of a... At lunch one day, he ignores his mother when she asks him to pass a plate.", "Log Ride", "Iowa", "A People's History of the United States", "Nassau", "a pearl oyster", "Dr. Robert Gallo", "Thomas Beekman", "a network of rail lines", "Rigoletto", "aardwolf", "Beijing", "Roger Bannister", "Rich Clune", "georgia", "Yves Saint Laurent", "Unlike horns, antlers are shed each year.", "Norway", "the War of 1812", "Anna Mary Robertson", "Luna", "char-Broil", "The New York Times Fiction Best Sellers", "giant panda bear", "a charleston", "geonson Lavis", "The Holy Grail", "cherries", "Milton Berle", "george herbert walker bush", "Congolese independence", "lunar module", "a Spanish conquistador", "Dan Marino", "Mars", "a clownfish", "total mass decreases", "The Love Guru", "Las Vegas", "soy", "a butterfly", "Camelot", "orangutan", "New Mexico", "death of Caesar", "Yitzhak Rabin", "David Becomes Israel's King", "Gettysburg", "Jack Gleeson", "Plank", "Buddhism", "Jean du Pucheu dite de La Place", "Portugal", "Tom Evans", "Johnson & Johnson", "acidic", "20 March to 1 May 2003", "\"has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\"", "knocking the World Cup off the front pages for the first time in days.", "12.3 million people worldwide"], "metric_results": {"EM": 0.453125, "QA-F1": 0.4844262206694272}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.17391304347826084, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08333333333333333, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-1768", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-12657", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-7151", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2051", "mrqa_triviaqa-validation-3265", "mrqa_triviaqa-validation-4765", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-3574"], "SR": 0.453125, "CSR": 0.568359375, "EFR": 0.8285714285714286, "Overall": 0.6938392857142858}, {"timecode": 32, "before_eval_results": {"predictions": ["Second World War", "62", "Herbert Henry Asquith", "40", "Libya", "Shania Twain", "Hillsborough", "glucagon", "New York Yankees", "rapid eye movement", "green, red, white", "Ann Dunham", "Saddam Hussein", "French", "Jim Branning", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New", "Sarah Ferguson", "Mercury", "proportional power", "Peter Butterworth", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "S\u00e3o Paulo", "optimism", "aged 75 or older", "Jennifer Lopez", "1664", "Eurythmics", "Fred Perry", "Downton Abbey", "Martina Hingis", "a painter", "Cyclopes", "Watch with Mother", "Michael Miles", "Sheryl Crow", "Gulliver's Travels", "Pomona", "Milan", "Mike Skinner", "The Great Appalachian Valley", "a black Ferrari", "algebra", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "Campbell's", "Kirkcudbright", "the soldiers", "anaphylactic shock", "providing the basic securities", "Juno", "a hermit", "lungs"], "metric_results": {"EM": 0.484375, "QA-F1": 0.54375}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, false, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-778", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-6378", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-7689", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-6656", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.484375, "CSR": 0.5658143939393939, "EFR": 0.7272727272727273, "Overall": 0.6730705492424243}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "Knutsford", "insulin", "a Caesar salad", "Hudson Bay", "florida", "allergic rhinitis, or a combination of both.", "abigail Masham", "getafix", "Brighton", "Belfast", "wind", "fire insurance", "Robin Hood Men in Tights", "West Point", "Andy Warhol", "Spain", "John Cable", "paz", "the solar system", "tomato and eggplant", "Moldova", "Mitsubishi", "warblers", "Franz Liszt", "Estimate", "a boudeur-rouleur", "calcium", "Pet Sounds", "Madness", "Buxton", "discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "Philippines", "beaver", "Mel Blanc", "a dog", "Moffitt", "Ellen Morgan", "phil Woolas", "5000 meters", "racing", "casein", "Newfoundland and Labrador", "crow", "Yellowstone National Park", "St. Thomas", "luzon", "Hugh Laurie", "Buddhism", "lead guitar", "Ohio", "Port Melbourne", "\u00c6thelthryth", "Scarface", "forgery and flying without a valid license,", "Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory", "Liza Murphy", "Spock", "almaty", "Andorra, Belgium, Germany, Italy, Luxembourg"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6287202380952381}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-1395", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-1620", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-11382"], "SR": 0.59375, "CSR": 0.5666360294117647, "EFR": 0.8846153846153846, "Overall": 0.70470340780543}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business", "prairies prairies", "Bologna, Italy", "George Santayana", "opossum", "Alice Cooper", "diastolic", "trumpet", "Peter Kay.", "sky", "shildon", "Appalachian Trail", "Herald of Free Enterprise", "ballet", "philippian Schell", "phyclin", "lizard", "city of Blackburn Lancashire", "Frankie Laine", "The Mystery of Edwin Drood", "pommel horse", "bird", "Dick Van Dyke", "Egremont", "Numb3rs Show", "Francisco de Goya", "phrixus", "Basil Feldman", "Canada", "ink sac", "soap", "Some Like It Hot", "Mull", "Ireland", "Mike Meyers", "sea horse", "plutonium", "magma", "Passepartout", "welcome", "Norway", "Estonia", "shrek", "26 miles", "Cleveland Brown", "Heston Blumenthal", "One Direction", "Flint", "Uranus", "Stringer Davis", "Charles Lindbergh", "September 2001", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "beer", "Pittsburgh", "Pakistan's High Commission in India", "shock, quickly followed by speculation about what was going to happen next,\"", "Hunter S. Thompson", "Peter Tchaikovsky", "Howard Carter"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.0, 0.5, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-1724", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-3837", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-5976", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-4664", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.46875, "CSR": 0.5638392857142858, "EFR": 0.9117647058823529, "Overall": 0.7095739233193277}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "Leonardo da Vinci", "Matlock", "American Civil War", "Ethiopia", "cetaceans", "turcan Sea", "wooden Cow", "Tigris", "Bavarian", "to make wrinkles in one's face", "Spain", "carousel", "bullfighting", "brady bunch", "Countertenor", "alpo", "fidelio", "Guys and Dolls", "Julian Fellowes", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "india", "delamere", "L. Pasteur", "fonda", "rachmaninoff", "Finland", "stars with gravity", "Mille Miglia", "caves", "Bill Haley & His comets", "spain", "Muriel Spark", "happy birthday to You", "seven", "opossum", "Pickwick Papers", "presliced bread", "Saga Noren", "raven", "Jordan", "bPA", "blackhall", "Etruscan", "Ken Burns", "grosvenor crescent", "Great Britain", "Pyotr Ilich Tchaikovsky", "Mujib", "libras", "Donna", "season four", "atrioventricular node", "yubin, Yeeun", "tomato", "2002", "many workers were being discriminated against on the basis of nationality.", "L'Aquila earthquake", "March 24", "duke anlam", "equinox", "Pocahontas"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5830882352941176}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.11764705882352941, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-4328", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_naturalquestions-validation-1091", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.515625, "CSR": 0.5625, "EFR": 0.8064516129032258, "Overall": 0.6882434475806452}, {"timecode": 36, "before_eval_results": {"predictions": ["Americans", "Kim", "Acacias", "branson", "Gordon Ramsay", "luton Town", "Robert Kennedy", "nitrogen oxides", "Margot Betti Frank", "Manchester Airport", "Portuguese", "Travelocity", "The Avengers", "Richmondshire", "Criminally Insane", "Paul Simon", "woman", "Rapeseed", "Tina Turner", "Benjamin Barker", "Preston North End", "Bolivia", "John Donne", "Uranus", "Rio Grande", "Percheron", "The Graduate", "Greek", "Ginger Rogers", "James I", "One Foot in the Grave", "Bronx Mowgli", "Bob Anderson", "George Santayana", "Finger Tab", "Windermere", "Krankies", "muy Reverendo Se\u00f1or Fray Thomas de Torquemada", "Daniel Barenboim", "Canada", "rum and cola with a slice of optional lime", "seattlepi.com", "ghee", "George III", "Justin Bieber", "Hyperbole", "oldpatricktoe-end", "June", "robin pike", "Ceylon", "Screwdrivers", "Kansas City Chiefs", "G minor", "My Summer Story", "2004", "\"The Outsiders\"", "Amberley Village", "if you don't have a cause of death, even claiming witnesses spotted Caylee since her disappearance.", "President Obama", "kerstin Fritzl", "tzu hsi", "Brigham Young", "June", "chalk quarry"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5821333741830066}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true, false, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.25, 1.0, 1.0, 0.2222222222222222, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-422", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_hotpotqa-validation-2330", "mrqa_newsqa-validation-995", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-2849"], "SR": 0.546875, "CSR": 0.5620777027027026, "EFR": 0.7241379310344828, "Overall": 0.6716962517474371}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "the roofs of the choir side - aisles", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "49 cents", "1876", "geologist James Hutton", "N 17 \u00b0 26 \u2032 34 ''", "joy of living", "42", "John Prine and Roger Cook", "to describe the six nations that have had sovereignty over some or all of the current territory of the U.S. state of Texas", "1990", "Shawn", "Kiss", "January to May 2014", "Los Angeles", "February 10, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "By 1770 BC", "Niveditha, Diwakar, Shruti", "freehold", "Ed Wynn", "cell nucleus", "Anakin", "Travis Tritt and Marty Stuart", "1983", "Bee Gees", "Matt Czuchry", "Pradyumna", "register with churches", "A line joining Isle Vierge ( 48 \u00b0 38 \u2032 23 '' N 4 \u00b0 34 \u2032 13 ''", "Psychomachia", "Devils", "two", "0.30 in ( 7.6 mm )", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Los Angeles", "1978", "Nicki Minaj", "exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Gloria", "Canadian Rockies continental divide", "The Maginot Line", "France", "dumbo", "purple", "Charles Guiteau", "Gettysburg Address", "iTunes, iTunes Radio, and iTunes Music", "$273 million", "India", "Al Nisr Al Saudi", "Desperate Housewives", "Cannonball Run", "emilia", "Tuesday"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6282363387802166}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, false, false, false, false, true, false, true, false, true, true, false, true, true, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.4615384615384615, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4411764705882353, 0.25, 0.2222222222222222, 1.0, 0.3333333333333333, 1.0, 0.782608695652174, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2334", "mrqa_naturalquestions-validation-8514", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-7642", "mrqa_hotpotqa-validation-5119", "mrqa_newsqa-validation-2554", "mrqa_searchqa-validation-2335"], "SR": 0.515625, "CSR": 0.5608552631578947, "EFR": 0.7741935483870968, "Overall": 0.6814628873089983}, {"timecode": 38, "before_eval_results": {"predictions": ["Isaac Newton", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in the pancreas", "Charles Crozat Converse", "Lady Gaga", "Chicago metropolitan area", "president", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "Notts County ( 1894 )", "a nobiliary particle indicating a noble patrilineality", "Stephen A. Douglas", "1984", "a loanword of the Visigothic word guma", "Pakistan", "The ladies'single figure skating competition of the 2018 Winter Olympics was held at the Gangneung Ice Arena", "Tagalog or English", "Bryan Cranston", "thylakoid membranes", "a mental disorder characterized by at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "Wake County, it lies just north of the state capital, Raleigh", "1922", "the final play of the 2017 / 18 Divisional Round game against the New Orleans Saints", "602", "stable", "Membership is believed to cost between $10,000 and $30,000", "September 1980", "1931", "University of Oxford", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "southern whites", "Randy", "the Infamy Speech of US President Franklin D. Roosevelt", "Joseph Stalin", "into the intermembrane space", "a divergent tectonic plate boundary", "Idaho", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "Sir John Major", "roddy doddy Doyle", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below", "Henry Ford", "David McCullough", "Rendezvous with Rama", "CERN", "Lisbon"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5974192394349044}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, false, true, true, false, true, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 0.09523809523809525, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8695652173913044, 0.0, 0.2857142857142857, 1.0, 0.0, 0.4666666666666666, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2512", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-2743", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_triviaqa-validation-5582", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.515625, "CSR": 0.5596955128205128, "EFR": 0.6774193548387096, "Overall": 0.6618760985318445}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "active absorption", "Philippe Petit", "September 1980", "January 2004", "southwest and along the Yangtze", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "heavy metal", "Set six months after Kratos killed his wife and child,", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "XXXX", "the Berlin School of experimental psychology", "53", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Rachael Harris", "Richard Crispin Armitage", "Brooks & Dunn", "Faceman '' Peck", "Bonnie Aarons", "late 2018 or early 2019", "diffuse nebulae", "effectively overturned the Plessy v. Ferguson decision of 1896", "McKim Marriott", "Secretary of Homeland Security", "Santiago Ram\u00f3n y Cajal", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "1960s", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Tad '' Stone", "Mark Jackson", "Michael Buffer", "one faith, one baptism, one God and Father of all, who is over all and through all and in all", "on location", "federal government", "New England", "Cody Fern", "questions about the name of the war, the tariff", "prophets and beloved religious leaders", "4.5", "Juan Manuel de Ayala", "Prophet Joseph Smith, Jr.", "funny Folks", "1909", "John Duigan", "179", "Princess Diana", "Carl Froch", "curfew", "Pearl", "spiny dogfish", "Fast Food Nation: The Dark Side of the All-American Meal", "ABBA"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5440318985415692}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.4347826086956522, 0.3076923076923077, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.47058823529411764, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.17142857142857143, 1.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5454545454545454, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-5299", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-302", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-4731"], "SR": 0.421875, "CSR": 0.55625, "EFR": 0.7837837837837838, "Overall": 0.6824598817567568}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants", "Joan Rivers", "early detection and helping other women cope with the disease.", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "the Zimbabwe Electoral Commission, after a long delay, ruled that neither candidate had won the required majority of votes, and scheduled a runoff election for June 27.", "since 2004", "coalition troops", "Switzerland", "Monday", "second time since the 1990s", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "he wants to spend billions to revitalize the nation's economy, a plan the campaign of his likely Republican opponent said would slow economic growth with higher taxes, fair trade and reform.", "Clifford Harris,", "state of Oaxaca, Mexico", "Robert Barnett", "a class A traffic violation that can command a fine of $627,", "41", "Nick Adenhart", "a strict interpretation of the law,", "Derek Mears", "sylt", "about 30 miles southwest of Nashville", "Tuesday afternoon", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "all faiths", "The son of Gabon's former president", "Allred", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Two pages -- usually high school juniors who serve Congress as messengers", "A Brazilian supreme court judge", "Derek Mears", "Operation Crank Call", "help poor families buy more energy-efficient electrical appliances", "East Java", "SSM Cardinal Glennon Children's Medical Center", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2007", "P.V. Sindhu", "Mexico", "Snickers bar", "narwhal", "abbot", "Anaheim, California", "uncle", "Bergen", "embalming", "Cartagena to Soledad", "a graphical user interface", "German Kennel Club"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6273082635980658}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.08333333333333333, 0.6666666666666666, 0.0, 1.0, 1.0, 0.25, 0.3870967741935484, 0.1702127659574468, 1.0, 0.4, 1.0, 0.19999999999999998, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 0.0, 0.0, 0.9523809523809523, 0.3076923076923077, 0.4, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3472", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.453125, "CSR": 0.553734756097561, "EFR": 0.7428571428571429, "Overall": 0.6737715047909407}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "1890s", "Stephen A. Douglas", "1998", "Directed distance is a positive, zero, or negative scalar quantity", "sovereign states", "Megan Park", "The euro", "Kate Walsh", "September 14, 2008", "Trace Adkins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51 war against Khmelnytsky Uprising in Ukraine", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "pour point of a liquid", "increases the life of the pump, allows a smaller and lighter device to be used, and reduces electrical load", "international aid as one of the largest financial inflows to developing countries", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "1902", "Kris Kringle", "Yuzuru Hanyu", "provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "collect menstrual flow", "pigs", "General George Washington", "Spanish", "Howard Ellsworth Rollins Jr.", "an integral membrane protein that builds up a proton gradient across a biological membrane", "the sinoatrial node", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements ) episodes", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Monsoons from the south atlantic ocean arrives in central Nigeria in July bringing with it high humidity, heavy cloud cover and heavy rainfall", "Missouri River", "the right to vote", "brain", "10 June 1940", "Tandi", "alberich", "the ear canal", "Brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "the Iraq's autonomous region of Kurdish.", "Denver, Colorado.", "the Sadr City and Adhamiya districts of Baghdad City", "\"24\"", "Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6914406931250761}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, true, false, true, true], "QA-F1": [1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.08333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.8, 0.6666666666666666, 0.17391304347826086, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.0, 0.14285714285714288, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-5368", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_triviaqa-validation-2114", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-1237"], "SR": 0.578125, "CSR": 0.5543154761904762, "EFR": 0.8518518518518519, "Overall": 0.6956865906084656}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization of water", "in Middlesex County, Province of Massachusetts Bay, within the towns of Lexington, Concord, Lincoln, Menotomy ( present - day Arlington ), and Cambridge", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "its population", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "to bring", "Foreign minister Hermann M\u00fcller and colonial minister Johannes Bell", "Ceramic art", "the Soviet Union", "Covington, Kentucky", "New Mexico", "reduces the back pressure, which in turn reduces the steam consumption, and thus the fuel consumption", "December 15, 2017", "on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "L.K. Advani", "differential erosion", "Glenn Close", "Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "Southampton ( 1902, then in the Southern League ) being the last finalist from outside the top two tiers", "2018", "Puerto Rico Electric Power Authority ( PREPA )", "Tsetse fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "compasses", "Charlotte Thornton", "Northeast Monsoon or Retreating Monsoon", "March 16, 2018", "President Lyndon Johnson", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "by producing an egg through parthenogenesis", "1926", "South Korea", "starting in 1560s", "Erik Per Sullivan", "Lou Rawls", "between 1765 and 1783", "Alfheim", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "won two awards.", "prostate cancer", "wyvern", "Cedric Errol", "a key ring or a decorative key fob", "yellow"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6359580264158753}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 0.9, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.09090909090909093, 1.0, 0.92, 0.14814814814814814, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 0.9767441860465117, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.484375, "CSR": 0.5526889534883721, "EFR": 0.6060606060606061, "Overall": 0.6462030369097956}, {"timecode": 43, "before_eval_results": {"predictions": ["1985", "February 27, 2007", "pick yourself up and dust yourself off and keep going", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "Blue with a harp of gold", "Miami Heat", "1981", "As late as the 1890s, building regulations in London did not require working - class housing to have indoor toilets", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Augustus Waters", "\u00e9tienne - Jules Marey", "Virgil Ogletree", "a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus", "SURFACE", "Alex Ryan", "habitat", "2018", "Advanced Systems Format ( ASF )", "100", "Toledo", "Transvaginal ultrasonography", "current day Poole Harbour towards mid-Channel", "Haikou on the Hainan Island", "Robert Irsay", "about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "Alicia Vikander", "annually in late January or early February", "Ashoka", "the name of a work gang", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority ( PREPA )", "Bumblebee", "into the Christian biblical canon", "New England ( Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont )", "AMX - 30", "honey bees", "Mary Chapin Carpenter", "permanent display at the Louvre Museum in Paris since 1797", "over two days in July 2011", "during the winter of the 2017 -- 18 network television season on CBS", "Florida", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "the island of Puerto Rico", "usually in a way considered to be unfair", "winter", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bonauto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"It was perfect work, ready to go for the stimulus package,\"", "\"We are going to systematically go through each and every one of them,\"", "America's infrastructure.", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6395246541845806}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.8333333333333333, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.5714285714285715, 0.4444444444444444, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.3076923076923077, 0.0, 0.0, 1.0, 0.823529411764706, 0.0, 0.18181818181818182, 1.0, 0.9189189189189189, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.09523809523809525, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-151", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-9723", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-9079", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352"], "SR": 0.46875, "CSR": 0.55078125, "EFR": 0.7647058823529411, "Overall": 0.6775505514705882}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "aluminum foil", "Laurel, Mississippi", "mountain-climbing.", "Indianola", "life insurance", "Jean Baptiste Point Du Sable", "1992", "Cher", "Alabama", "James Harrison", "Toronto", "Tomorrowland", "fennec fox", "United States Army", "stop motion animation", "Jean Acker", "5,656", "Leucippus", "Caesars Entertainment Corporation", "Mary Ellen Mark", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "Northrop P-61 Black widow", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony awards.", "1991\u201392", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "OutKast", "Richard Street", "Zaire", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer.", "South America", "2007", "perjury and obstruction of justice", "Operation Overlord", "Mary Elizabeth Hartman", "over 9,000 employees", "Malcolm Terris", "potential of hydrogen", "San Antonio", "Carrie", "The Finger Tab", "Kent", "almost 9 million", "Kenya", "2008", "terrorism", "Moses", "Chapter 5", "Jeff Barry and Andy Kim"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5885359432234432}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-4527", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-4762", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-1449", "mrqa_triviaqa-validation-6953", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.515625, "CSR": 0.55, "EFR": 0.8709677419354839, "Overall": 0.6986466733870967}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "1903", "the power to regulate interstate commerce", "John Duigan", "Jenson (born 19 January 1980)", "Tufts University", "the People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "James VII of Scotland", "\"God Save the King\"", "526", "Scotland", "a heavy metal band, although they have always dubbed their music simply \"rock and roll\"", "Gesellschaft", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Sullenberger III", "Manhattan Project", "Asia-Pacific War", "Romantic", "Hugh Dowding", "AMC Entertainment Holdings, Inc.", "the New York Islanders", "fennec", "1978", "six different constructors taking the first six positions.", "French", "Pacific Place", "the Female Socceroos", "\"1989\"", "\"SexyBack\"", "5320 km", "Francesco Maria Piave", "Chief Minister of Tamil Nadu", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Faisal Qureshi", "the British Army", "exercise power directly or elect representatives from among themselves to form a governing body, such as a parliament.", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Judy Garland", "Switzerland", "Model A", "ISAF", "2,000", "Cyprus", "Maroon 5", "Jeddah", "Ambassador Ferraro", "two"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5880650448585232}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.08695652173913043, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-851", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-4880", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-2129", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_triviaqa-validation-3592", "mrqa_newsqa-validation-282", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-8327", "mrqa_searchqa-validation-2897"], "SR": 0.484375, "CSR": 0.5485733695652174, "EFR": 0.8181818181818182, "Overall": 0.6878041625494071}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican National Committee", "1996", "five", "Greenland shark", "The Word", "President Abraham Lincoln", "St Jude Thaddeus", "Anthoonij van Diemenslandt", "the Death Penalty", "annual", "Jackie Robinson", "Staten Island", "Dian Fossey", "MI5", "harrow", "creme anglaise", "a sauce of lemon juice, parsley, salt, pepper, and drawn butter", "pork", "curling", "Victoria Coren Mitchell", "Gettysburg Civil War", "Chile", "Majorca", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck", "Mercury", "Venus", "Barack Obama", "Canada", "F-O-R-G-T-E-N", "Cuban Revolution", "Bowie", "Stephen King", "Hindu", "caryatid", "feet", "Great Britain returned Manila and Havana to Spain while Spain granted Florida to Great Britain.", "Mary Poppins", "Glyn Jones", "Port Moresby", "Connecticut", "Quentin Blake", "whooping cough", "The Sun", "(1939\u20131945)", "kosher", "2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1987", "Daniel Nestor, from Canada,", "Jeddah, Saudi Arabia", "death", "Beatrix Potter", "Dan Eggen and Elizabeth Williamson", "Reader's Digest", "\"Divide the living child in two, and give half to the one"], "metric_results": {"EM": 0.5, "QA-F1": 0.5894531249999999}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, true, false, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.125, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-6789", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-1660", "mrqa_triviaqa-validation-2816", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-1584", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_hotpotqa-validation-252", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-6488"], "SR": 0.5, "CSR": 0.5475398936170213, "EFR": 0.75, "Overall": 0.6739611037234042}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "allergic reaction", "tom finney", "on a nearby moor at Culloden", "Runic", "florida", "cricketer", "Max Planck", "rotherham United", "radiant Heat Barrier", "Misery", "Styal", "stately tempo", "blind beggar", "Brainwash", "l Leroy Burrell", "parlophone", "Wild Atlantic Way", "John Denver", "an Unseen University football team", "noddy Goes To Toyland", "Lackawanna 6", "Brazil", "backyard Kerplunk", "muezzin", "a window", "a ship", "bovary", "Apollo 11", "flit gun", "Stanford White", "jockey Barry Geraghty", "evita", "sperm whale", "royman", "east fife", "st Pancras International Station", "individual", "presliced bread", "Dilbert", "Aristotelian Tragedy", "nunc dimittis", "French", "Medea", "Burgundy", "cribbage", "ringo Starr", "Johannesburg", "France", "Muffin Man", "Seoul", "Prince James, Duke of York and of Albany ( later King James II & VII )", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Galveston, Texas, to Veracruz, Mexico,", "if the airline doesn't perform, the credit card company still has your money and can give it right back to you.", "Robert Lee Frost", "King Richard III", "Tucker", "2002 Mitsubishi Lancer OZ Rally"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5797619047619047}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.4, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.8, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-1189", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5914", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618"], "SR": 0.515625, "CSR": 0.546875, "EFR": 0.8387096774193549, "Overall": 0.691570060483871}, {"timecode": 48, "before_eval_results": {"predictions": ["sixty-six", "sesame Street", "saut\u00e9eing onions, carrots, celery and garlic", "cabbage", "south", "Mr. Magoo", "the Golden fleece", "Ash tree", "marsupials", "New Zealand", "Distin family", "60", "goldfinger", "1984", "frog", "mongols", "1875", "tax collector", "penny", "maria Maria", "Wars of the Roses", "bagram", "maggie Gilkeson", "Chrysler", "hat", "dandy", "Civil Law", "United States", "Brazil", "pei Tang", "biathlon", "Idaho Falls", "Charlie Chan", "Vienna", "white", "jaws", "Dewey Cox", "rabbit", "Scotland", "henpecked Jerry Leadbetter", "Orson Welles", "hindu Wisdom", "menorah", "Dutch", "Texas", "Super Bowl Sunday", "quant pole", "little Tommy Stout", "henna", "Rhododendron", "Ireland", "Chuck Noland", "Colony of Virginia", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park", "2010", "British Columbia,", "10 below", "Nearly all of Britain's troops in Iraq will have left by the week's end.", "coins", "Babu", "Omaha", "George Jones"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5729166666666666}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-2687", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-6306", "mrqa_naturalquestions-validation-4803", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-6607", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.515625, "CSR": 0.5462372448979591, "EFR": 0.8064516129032258, "Overall": 0.6849908965602369}, {"timecode": 49, "UKR": 0.763671875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2824", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-4056", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-5593", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-816", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5566", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6564", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-744", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1649", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3088", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-610", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7763", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1189", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2833", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3831", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-6575", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-6738", "mrqa_triviaqa-validation-6789", "mrqa_triviaqa-validation-6813", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6978", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7204", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7469", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.646484375, "KG": 0.44140625, "before_eval_results": {"predictions": ["Quin Ivy", "Dasht-e kavir", "alcohol", "Francis of Assisi", "Matthew", "Daniel Boone", "Thames Street", "John F Kennedy", "satyrs", "crabs", "la Boh\u00e8me", "MS-DOS", "a wishbone", "Garrick Club", "Lackawanna 6", "Barnaby Rudge", "jesus bullock", "American Civil War", "dark", "jean conchita Alonso", "Bobby Tambling", "Florence", "Basil", "willy Wonka", "Severn", "Australia", "South Africa", "plants that will do well with the sun, soil, and water", "Somoza", "Churchill", "Wars of the Roses", "Chemnitz", "aggregating individual player projections and summing them up and trying, based on kind of proven mathematical models,", "chubs, whitefish, squawfish, rainbows, cutthroats, and bull trout", "Joseph Dubonnet", "lee foreman", "Belize", "the Library of Congress", "hair loss", "cycling", "Charlie Drake", "Robin Hood Men in Tights", "Chris Martin", "flinstone", "(Lee Ingleby)", "Rugby", "honda", "deacon Blues", "11", "tobacco", "a heifer", "free floating and depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "Tom Selleck", "New Orleans", "abilities after being bitten by radioactive/genetically-altered spiders.", "Texas Tech University Health Sciences Center", "Loughborough Technical Institute", "Herman Cain", "the United States", "provide with gainful employment by allowing them to do jobs that Arizonans wouldn't do.", "George Babbitt", "Oklahoma", "a vodka stinger", "four"], "metric_results": {"EM": 0.359375, "QA-F1": 0.45108246927803375}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, false, true, false, false, false, false, true, false, false, true, true, false, true], "QA-F1": [0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.06451612903225806, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-2309", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-6699", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-6060", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-115", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-3615"], "SR": 0.359375, "CSR": 0.5425, "EFR": 0.5609756097560976, "Overall": 0.5910076219512195}]}