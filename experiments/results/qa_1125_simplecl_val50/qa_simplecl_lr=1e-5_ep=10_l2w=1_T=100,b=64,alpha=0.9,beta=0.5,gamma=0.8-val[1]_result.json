{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 1980, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "isomorphic", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Stanford University Professor of Comparative Literature Richard Rorty", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8181801079682272}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.9333333333333333, "Overall": 0.8494791666666667}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "P", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "September 1969", "Mansfeld", "Warsaw Stock Exchange", "390 billion individual trees divided into 16,000 species", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "13 May 1899", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification that occurs following sequential proteolytic activation of complement molecules", "Lituya Bay in Alaska", "120 m ( 390 ft ) at its widest part", "the eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books have been released, plus one do - it - yourself book and two movie diaries", "Hal David and Burt Bacharach", "five points", "The Monitor and Merrimac", "the Atlantic Ocean, the Gulf of Mexico and the Straits of Florida"], "metric_results": {"EM": 0.671875, "QA-F1": 0.774634455779654}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 0.3076923076923077, 1.0, 0.6153846153846154, 0.4444444444444445, 1.0, 0.4, 1.0, 0.5853658536585366, 1.0, 0.0, 0.5, 0.5, 0.16666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1759", "mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-5788", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1454", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.734375, "EFR": 0.9047619047619048, "Overall": 0.8195684523809523}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "Abercrombie was recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "John Elway", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Bud '' Bergstein", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "the surly librarian who looks after his alcoholic sister Mary Elizabeth ( Margaret Hoard )", "In December 1971, the `` Smithsonian Agreement '' was reached. In this agreement, the dollar was devalued from $35 per troy ounce of gold to $38", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7768601190476191}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.5, 0.0, 0.13333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.6875, "CSR": 0.72265625, "EFR": 1.0, "Overall": 0.861328125}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Presque Isle", "wireless", "Coldplay", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "1960s", "that narcotic drugs were controlled in all member states, and so this differed from other cases where prostitution or other quasi-legal activity was subject to restriction", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot", "50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "NDS, a Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "their parent thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "evading it", "the kettle and the Cricket", "Gandhi", "The first written mention of this capital's name was in a 1459 document of Vlad the Impaler", "\"Take us the foxes, the little... Alexandra - first cousins - as a means of getting Horace's money", "the 1982 Sony SL-2000 portable", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "8/4 x 365 = 730 days", "1994", "1867 to 1877", "Marshal Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali", "The new nightspot Teddy's made this presidential Hollywood hotel a happening", "LASER abbreviation", "Incomprehensible", "Juno", "Hundreds of species of peat mosses are found in bogs throughout Canada", "why", "Daya", "fear of meat", "American", "Mexican military"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6366284756909757}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.2666666666666667, 0.0, 0.3076923076923077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.1818181818181818, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.33333333333333337, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-10204", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-2804", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.53125, "CSR": 0.684375, "EFR": 0.9666666666666667, "Overall": 0.8255208333333333}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center", "Variable lymphocytes receptors (VLRs)", "Edict of Fontainebleau", "Levi's Stadium", "ten million", "the Lippe", "Video On Demand content", "time and storage", "semester", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "League of the Three Emperors", "science", "143,007", "Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "drawn the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Br'er Rabbit", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.75, "QA-F1": 0.820332532051282}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-4919", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-6676", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.75, "CSR": 0.6953125, "EFR": 0.9375, "Overall": 0.81640625}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the courts of member states", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "A vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "Spanish", "Structural geologists", "president and CEO of ABC", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Burwell Johnston, Jr.", "a large green dinosaur", "Taylor Swift", "Eric Edward Whitacre", "Joint Chiefs of Staff", "Linux Format", "Jasenovac concentration camp", "Rabat", "between 11 or 13 and 18", "Heather Langenkamp", "Henry Gwyn Jeffreys Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "It is based in Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "English former international footballer", "the Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Ashanti", "79", "Algeria", "a novel", "the Eastern part", "Polar Bebe", "Atlantic City"], "metric_results": {"EM": 0.65625, "QA-F1": 0.793686537114846}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 0.6666666666666666, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.5, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971"], "SR": 0.65625, "CSR": 0.6897321428571428, "EFR": 0.9090909090909091, "Overall": 0.799411525974026}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "the working fluid", "a suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "output", "those who already hold wealth", "center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "canalized section", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "along the entire length of the lake", "computer programs", "General Conference", "1996", "dreams", "The Judiciary", "deterministic", "Bart Starr", "oxygen that is damaging to lung tissue", "Karluk Kara-Khanid", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "A. E. Housman", "capital of the Socialist Republic of Vietnam", "Sevens", "fennec fox", "Bart Conner", "fantasy", "Martin \"Marty\" McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Cody Miller", "140 to 219", "the \"Father of Liberalism\"", "Christophe Lourdelet", "Pablo Escobar", "African", "Mexico City", "Sleeping Beauty", "2005", "1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Ali Bongo", "Wheat Chex", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7217013888888889}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-1771", "mrqa_squad-validation-9287", "mrqa_squad-validation-1819", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.671875, "CSR": 0.6875, "EFR": 0.9047619047619048, "Overall": 0.7961309523809523}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "higher efficiency", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "General Conference in Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "tailless", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Harvard University", "Fulham", "A55", "Maud of Gloucester", "\u00c6thelstan", "Special economic zone", "44", "NCAA's Division I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "A diastema ( plural diastemata )", "Shirley", "Israel", "Bigfoot", "Papua New Guinea", "Edgar Degas", "Manchester"], "metric_results": {"EM": 0.703125, "QA-F1": 0.758204816017316}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 0.6666666666666666, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-3391", "mrqa_squad-validation-9859", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_triviaqa-validation-3170", "mrqa_newsqa-validation-1268", "mrqa_triviaqa-validation-1423"], "SR": 0.703125, "CSR": 0.6892361111111112, "EFR": 0.7368421052631579, "Overall": 0.7130391081871346}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "its unpaired electrons", "French", "Museum of the Moving Image in London", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "pivotal event", "an American YouTube personality, spokesmodel, television personality, and LGBT rights activist", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "American actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia, the Disneyland Monorail, and the Motor Boat Cruise", "Yasir Hussain", "USC Marshall School of Business", "Stephen Ireland", "Marko Tapani", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "2500 ft", "Central Park", "Robert John Day", "Tifinagh", "James Tinling", "Italy", "the 79th Masters Tournament", "Kristoffer Rygg", "University of Kentucky College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "couscousCouscous", "more than 22 million", "morphine sulfate oral solution 20 mg/ml", "The Firm (1993 film)", "freshwater"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6462785438588925}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.88, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-5477", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.5625, "CSR": 0.6765625, "EFR": 0.7857142857142857, "Overall": 0.7311383928571429}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "Timucuan", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "tight end Owen Daniels", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and Daleks in series 1, Cybermen in series 2", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "Standard Model", "Tolui", "Rhine-Ruhr region", "pedagogy", "Prevenient grace", "Kansas State", "the Queensland Heritage Register", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The The The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "the RATE project's results", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Bath, Maine", "Ector County", "Jim Davis", "Buck Owens", "World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the Halle Orchestra", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "The Londoner"], "metric_results": {"EM": 0.625, "QA-F1": 0.7080493573771189}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7269", "mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.625, "CSR": 0.671875, "EFR": 0.9166666666666666, "Overall": 0.7942708333333333}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "Spanish", "100\u2013150 species", "Philo of Byzantium", "cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "new element", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "a clunker that has no airbags, anti-lock brakes", "planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "Markland Locks and Dam", "Arthur E. Morgan III", "April 2010", "Paul McCartney and Ringo Starr", "does not involve MDC head Morgan Tsvangirai", "an accident", "200", "The drug is legal for medical use, but it is trafficked into Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally", "opposition party members", "Missouri", "Obama's race in 2008", "executive director of the Americas Division of Human Rights Watch", "Dominican Republic", "90", "KARK", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "Employee Free Choice act", "Bush administration", "more than 200", "The show allows 10 boys and 10 girls between the age of eight and 11 to create their own mini-societies, organizing everything from what they eat to how they should entertain themselves", "best-of-three series", "Kaka", "Japanese ex-wife", "Dan Parris, 25, and Rob Lehr, 26", "apartment near Fort Bragg in North Carolina", "two", "$2 billion", "Jacob", "Molotov cocktails, rocks and glass", "250,000", "Winehouse", "Ark of the Covenant ( the Aron Habrit in Hebrew )", "Jean F Kernel ( 1497 -- 1558 ), a French physician,", "Thomas Hardy\u2019s novel", "Richmondshire Museum", "1994", "The Conjuring", "The Gallipoli Campaign", "Georgian Bay", "Nowhere Boy"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5986111111111112}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8666666666666666, 0.4444444444444445, 0.0, 0.4, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.8333333333333333, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.6, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4611", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-6176", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.46875, "CSR": 0.6549479166666667, "EFR": 0.9117647058823529, "Overall": 0.7833563112745099}, {"timecode": 12, "before_eval_results": {"predictions": ["C\u00e9loron threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "every good work designed to attract God's favor is a sin.", "Napoleon", "new technology and machinery", "James O. McKinsey", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states.", "1227", "lower lake", "three", "Elders", "587,000", "Private Bill Committees", "Bruno Mars", "the Catechism", "Stagg Field", "Ian Botham", "E. T. A. Hoffmann", "Vincent Motorcycle Company", "\"Frenchie\"", "Salvador Allende", "Marie Antoinette", "United States", "Erik Thorvaldson", "Apollo", "the 1940 Rodgers and Hart musical Pal Joey.", "Mary Jane Grant", "green", "\"French Polynesia", "Moses", "Antonio", "European Economic Community", "Christine Keeler", "Jesus", "Jack Nicholson Easy Rider", "four", "Netherlands", "\"Sugar Baby Love\"", "Coretta Scott King", "Sean", "Bill and Taffy Danoff", "early", "Travis", "Blue Peter", "Robert Kennedy", "Q", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "Hobbies", "barber", "Harry Hopman", "Murrah Federal Office Building", "Evita", "an old, unsavoury, and oily black clay pipe", "fortified complex", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley", "\"It is very easy for comments to be taken out of context and create unnecessary drama", "a delegation of American Muslim and Christian leaders", "Royal Wives", "the Greek Village", "Juan Martin Del Potro"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5507946841931217}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, true, false, true, false, false, true], "QA-F1": [0.962962962962963, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0625, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10141", "mrqa_squad-validation-2262", "mrqa_squad-validation-5431", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6696", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_searchqa-validation-5929"], "SR": 0.484375, "CSR": 0.6418269230769231, "EFR": 0.8181818181818182, "Overall": 0.7300043706293706}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "julian", "moles", "Democritus", "kawajalein Atoll", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "jazz tenor saxophonist", "one", "komando Pasukan Khusus", "Carlisle", "a liquid form", "clawicothe and Zanesville", "Lucas McCain", "Antarctica", "mercury gilding", "aniridia", "t.S. Eliot", "River Forth", "woe", "NOW Magazine", "j Jesse James", "Italy", "Canada", "typhoid fever", "Tina Turner", "action figure", "Joe Willie Kirk", "2010", "probability", "Venezuela", "rothel Cecile Rosalie Allen", "temperature inversion", "40", "phrenology", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Chris Weidman", "Drillers Stadium", "one", "Virgin America", "John Grisham", "a rosy poppy", "Iran's parliament speaker", "In Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5880208333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.546875, "CSR": 0.6350446428571428, "EFR": 0.6896551724137931, "Overall": 0.662349907635468}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary civil disobedience", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow, and to the University of Aberdeen", "public official", "the most cost efficient bidder", "acorn tree", "globe", "thighbone", "Olympia", "Ukraine", "shrews", "Lois & Clark: The New Adventures of Superman", "fire", "amber", "stanley Basmati", "The executioner's Song", "germany", "bishkek Tajikistan", "anamosa", "grouchy", "The Comedy of Errors", "asylum", "film", "rope", "germany", "Cologne", "ganley", "an ingot", "Kosovo", "James Jeffords", "Prague", "tennis", "silk", "cowboys", "Sir Winston Churchill", "Key deer", "Japan", "alamo", "thant", "boys", "windjammer", "columbus", "germany", "Augusta", "counter clockwise", "2013", "Nick Hornby", "parachutes", "December 24, 1973", "David Weissman", "bikinis", "Tibet", "memories of his mother", "Israel"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5130208333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7000000000000001, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-3084"], "SR": 0.4375, "CSR": 0.621875, "EFR": 0.9166666666666666, "Overall": 0.7692708333333333}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "Rhenus", "1996", "wine", "the German-Swiss border", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "a violinist", "Jerry Maguire", "Strongsville, Ohio", "Flemish", "Mastercard Worldwide", "Roger B. Smith", "Nashville", "cranial nerve", "Ivan the Terrible", "Nancy Astor", "lentigo senilis", "a casino", "Toronto Maple", "Zsa Zsa Gabor", "acting", "Utah", "liquor made from molasses or sugar cane", "(Rabbit) Angstrom", "Johann Strauss II", "joey", "pro bono", "Atenei", "The Fun Factory", "a beer relative", "Manfred von Richthofen", "Nacho Libre", "copper", "black magic or of dealings with the devil", "the hemlock", "Dr. Jeffrey Wigand", "National Poetry Month", "The Runza Way", "a meager allowance", "Casablanca", "blimps", "the Bunsen burner", "a geisha", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a tin star", "\"black\"", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6265624999999999}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-9248", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-14722", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_newsqa-validation-2036"], "SR": 0.515625, "CSR": 0.615234375, "EFR": 0.967741935483871, "Overall": 0.7914881552419355}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Weser", "Eva Peron", "Ho Chi Minh", "circumference", "the Inuit", "Detroit Rock City", "the Toronto Blue Jays", "President Lincoln", "R.L. Stine", "crimes committed out of hatred for someone's race", "King Julien XIII", "Nicolas Sarkozy", "Rubicon", "Sanjaya", "17", "Louisa May Alcott", "Modeling Compound", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Rodham Clinton", "King Philip", "(Bellerophon)", "Balaam", "the Wharton School of the University of Pennsylvania", "The Caine Mutiny", "(The Allman Brothers Band)", "(founded 1932)", "(John) Coltrane", "the peace sign", "oxygen", "the Sphinx", "Jan Hus", "The USA Network's original grassroots talent search", "Mavericks", "Onegin", "Macy's Christmas Parade", "a spinning jenny", "(H0H 0H0)", "(Denzel) Washington", "negligence", "the courts", "attached to another chromosome", "Whittingham", "Australia", "The Jefferson Memorial", "aged between 11 or 13 and 18", "Michoacan Family", "prisoners", "his salary", "the punishment"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6464915293040293}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.8, 0.5, 0.0, 0.2, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-8945", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-8100", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13667", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_hotpotqa-validation-3410", "mrqa_newsqa-validation-1759"], "SR": 0.515625, "CSR": 0.609375, "EFR": 0.967741935483871, "Overall": 0.7885584677419355}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Robert Lane and Benjamin Vail", "a telephone ring", "Party of National Unity", "22", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "the Crystal Method", "Puerto Rico", "The Mausoleum", "Million Dollar Baby", "Syria", "World Airlines", "The Old Man", "French", "Joe Louis", "lion", "The Three Musketeers", "the Bayeux Tapestry", "Front Porch", "China", "Sunni", "notes placed at the bottom of a page", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "Blanche DuBois", "a binding technique", "FRAM", "the House of Representatives", "Labatt", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "El burlador de Sevilla", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Ronald Reagan", "Fiddler on the Roof", "Ethiopian", "six", "1992", "a base", "Bromley-By- Bowen", "the Ruul", "Cartoon Network", "Caylee Anthony", "know what's important in life", "a Taliban member who had come for the talks about peace and reconciliation, and detonated the explosives as he entered the home.", "nuclear", "The drama of the action in-and-around the golf course"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6861458333333332}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.08, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1920", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-14873", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7140", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-4110"], "SR": 0.65625, "CSR": 0.6119791666666667, "EFR": 0.9545454545454546, "Overall": 0.7832623106060607}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXXIII", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity", "same-gender marriages", "2006", "mid-18th century", "hollandaise", "A Raisin in the Sun", "Sistine Chapel", "Belarus", "a spread formation", "a trowel", "Big Bang", "Sex Pistols", "endodontist", "Saturn", "White Cliffs of Dover", "Genoa", "Galt", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Seattle", "little. White Pet", "the Hampton Inn", "21", "the Civil War", "Copeina arnoldi", "Paul McCartney", "omega-3", "Raphael", "Bachman Turner Overdrive", "a horror network", "Caddy Shack", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "the Bear family", "a quake", "Judas", "elephants", "Mazur", "Sweden", "a covert operation", "Our Country", "May 2010", "in the majority of the markets the company has entered", "Rio de Janeiro", "Thailand", "gender queer", "Minister for Social Protection", "Berga", "the estate", "Bill Irwin", "ase", "North America"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5998819163292848}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, false, true, false, false, true, false, false, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.15384615384615383, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.10526315789473684]}}, "before_error_ids": ["mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-2870"], "SR": 0.515625, "CSR": 0.606907894736842, "EFR": 0.8387096774193549, "Overall": 0.7228087860780985}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "transplastomic", "Earth", "53,000", "one", "poet", "two points", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "Saturday", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "Arousal regulation", "Charlene Holt", "Ted '' Levine", "1991", "electron shells", "Cornett family", "acid rain", "October 22, 2017", "resources", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Rick Rude", "Ohio", "a form of business network", "a cylinder of glass or plastic that runs along the fiber's length", "James Hutton", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Necator americanus", "February 29", "the Lykan", "disagreements involving slavery and states'rights", "oxygen", "Cecil Lockhart", "Mara Jenna", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "Lysander", "Jupiter", "east", "15", "John Robert Cocker", "Silvan Shalom", "a simple puzzle video game", "a palace", "the olfactory nerve", "Eucalyptus", "a horse", "oxygen"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6784970238095238}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428572, 1.0, 0.2, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-8339", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_triviaqa-validation-2227"], "SR": 0.59375, "CSR": 0.60625, "EFR": 0.9230769230769231, "Overall": 0.7646634615384615}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape", "Florida officials, who say they continue to plan for such an exodus only as a precaution.", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer in five vignettes.", "well over 1,000 pounds", "peace with Israel", "Mutassim", "from Texas and Oklahoma to points east", "Polo", "Joe Jackson", "locked in a basement", "computer problems", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus", "prisoners", "September, 2004", "consumer confidence", "about 5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "behind the counter", "chief executive officer", "\"There's no chance of it being open on time.", "\"I have issued an order. I don't want these people interfered with in any way,\"", "Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "the journalists and the flight crew will be freed, his chief of staff, Mahamat Hissene, said Thursday.", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "two years", "1966", "winter", "Pentecost Sunday", "Aberdeen", "\"Dumb and Dumber\"", "Nokia Sugar Bowl", "Earl Warren", "focal point", "autumnus", "season five", "Revenge of the Sith"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6747345102813853}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.8750000000000001, 1.0, 1.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.4, 0.0, 1.0, 0.18181818181818182, 0.5, 1.0, 0.2857142857142857, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.3636363636363636, 0.19999999999999998, 0.05555555555555555, 1.0, 1.0, 1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 1.0, 0.5, 0.0, 0.3333333333333333, 0.25]}}, "before_error_ids": ["mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3477", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.515625, "CSR": 0.6019345238095238, "EFR": 0.8709677419354839, "Overall": 0.7364511328725039}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress", "Southern Border Region", "chief electrician", "Newton", "static friction", "the assassination of US President John F. Kennedy", "the Kenyan forces crossing of the joint border as \"an affront to Somalia's territorial sovereignty.\"", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "in a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offset,", "Wednesday", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad", "Amanda Knox's aunt", "jazz", "$17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "a nurse who tried to treat Jackson's insomnia with natural remedies", "Sarah", "\"They left without me,' which is what I thought I would do.\"", "1981", "17 Again", "Nigeria", "$81,88010", "Republicans", "EU naval force", "Chris Robinson", "Bongo", "steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "a pregnancy could pose to her health.", "London Heathrow's Terminal 5.", "canceled the swimming privileges", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "The White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\" (2012)", "The Kingdom of Northumbria", "\"Get thee to a nunnery\"", "Elena Ceausescu", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Eduard Leopold"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5945232412603736}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 1.0, 0.11764705882352941, 0.5454545454545454, 0.0, 0.0, 0.9, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 0.25, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-251", "mrqa_searchqa-validation-7642", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107", "mrqa_hotpotqa-validation-1056"], "SR": 0.484375, "CSR": 0.5965909090909092, "EFR": 0.8787878787878788, "Overall": 0.737689393939394}, {"timecode": 22, "before_eval_results": {"predictions": ["X-rays", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia, especially. The English welcomed the French refugees, providing money from both government and private agencies to aid their relocation.", "two", "glowed even when turned off.", "a number of celebrities and ministers, ranging from Yolanda Adams to Bishop T.D. Jakes to Kirk Franklin.", "resources that could sustain future exploration of the moon and beyond.", "sovereignty over them.", "April 6, 1994", "Prague", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "a federal judge in Mississippi", "the department has been severely affected by the earthquake, with thousands of officers injured, killed or unaccounted for.", "$22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Rany Freeman, an Egyptian living in Canada,", "Larry King", "Obama", "racially motivated.", "Michael Partain,", "women.", "ancient rituals in Olympia,", "Zimbabwe's dire economic situation.", "No. 1", "nine", "Four bodies", "Friday", "The tower will be built in the Saudi town of Jeddah and will be part of a larger project that will cost $26.7 billion, (100 billion Saudi riyals)", "Rima Fakih", "the two-hour finale.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Damon Bankston", "researchers", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning -- the FDA's strongest -- to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Fakih", "Isthmus of Corinth", "Nalini Negi", "2017 - 12 - 10", "Runcorn", "collarbone", "geographic horizon", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "A Fairy Tale of Home"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5869805612867114}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.07692307692307693, 1.0, 1.0, 0.11764705882352941, 0.8235294117647058, 1.0, 0.5, 0.19999999999999998, 0.967741935483871, 1.0, 0.6086956521739131, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.23529411764705882, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.421875, "CSR": 0.5889945652173914, "EFR": 0.918918918918919, "Overall": 0.7539567420681552}, {"timecode": 23, "before_eval_results": {"predictions": ["phycoerytherin", "scientific data, tools, photographs, valued at $50,000\u2014was lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma.", "56", "Yemen", "2005", "Karen Floyd", "Four Americans", "those missing", "Haiti", "Susan Boyle", "Saturday", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy", "Dangjin", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding", "threatening messages", "if she would try to travel to Japan for summer vacation.", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "\"in the interest of justice.\"", "martial arts, which he taught upon his return to India before becoming a male model.", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Anne Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "Queen Elizabeth's birthday", "the government in Islamabad \"has so far not received any information or evidence relating to the Mumbai incident from the government of India.\"", "Zuma", "made out of either heavy flannel or wool", "five", "Iraqi Prime Minister Nouri al-Maliki", "September 11, 2001", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed", "Desmond Tutu", "$530 million", "Toy Story", "$81,8709", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "repudiation, change of mind, repentance, and atonement", "Jason Lee", "stage of sleep", "nouns which can occur with articles and attributive adjectives and can function as the head of a noun phrase.", "Kent", "beer and soft drinks", "five aerial victories", "Cherokee River", "Snowball", "James A. Lovell", "Florida"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6151780401615928}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.6666666666666666, 0.72, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.56, 0.08333333333333333, 0.5, 0.0, 0.25, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15789473684210525, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_squad-validation-1506", "mrqa_squad-validation-10100", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-1876", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.515625, "CSR": 0.5859375, "EFR": 0.8709677419354839, "Overall": 0.728452620967742}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "American Lindsey Vonn", "Williams' scalp to her earlier surprise victories over former world number one's Junstine Henin and Jelena Jankovic.", "him to step down as majority leader.", "EU naval force", "gang rape of a 15-year-old girl", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "club", "shows the world that you love the environment and hate using fuel", "1979", "Heshmat Tehran Attarzadeh", "great jazz", "an antihistamine and an epinephrine auto-injector for emergencies,", "Bangladesh", "Michael Arrington, founder and former editor of Tech Crunch, and Vivek Wadhwa,", "one out of every 17 children under 3 years old in America", "President Sheikh Sharif Sheikh Ahmed", "a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent", "military personnel", "on the shelves in all of Lifeway's 100-plus stores nationwide and had been placed behind the counter.", "11", "one Iraqi soldier,", "Michael Partain,", "her fianc\u00e9,", "racial intolerance.", "all animal products.", "one of the heirs to the criminal organization known as the Juarez Cartel, after the death of his father, Amado Carrillo Fuentes,", "Symbionese Liberation Army", "$8.8 million", "work together to stabilize Somalia and cooperate in security and military operations.", "compromise the public broadcaster's appearance of unbiasedity.", "black is beautiful", "$104,327,006", "Picasso's muse and mistress, Marie-Therese Walter.", "\"Drug trafficking is a transnational threat, and therefore national initiatives have their limitations,\"", "provides nearly $162 billion in war funding without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "27 Awa", "Mark Obama Ndesandjo", "\"Dance Your Ass Off.\"", "famous faces like NHL hockey star Alexander Ovechkin, Russian Vogue editor in chief Aliona Doletskaya, \"Russian Madonna\" singer Valeriya, and London-based Russian art collector Nonna Materkova", "\"The Screening Room\"", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "Treaty of Paris between France and the Sixth Coalition, and the Treaty of Kiel", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Walt Disney World Resort in Lake Buena Vista, Florida", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.421875, "QA-F1": 0.578099053213943}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, true, true, false, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.5714285714285715, 0.18181818181818182, 1.0, 0.5, 1.0, 1.0, 0.4, 0.6666666666666666, 0.8, 1.0, 0.2857142857142857, 0.23529411764705882, 0.33333333333333337, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 0.09523809523809525, 1.0, 1.0, 0.15384615384615385, 0.0, 1.0, 1.0, 1.0, 0.0, 0.375, 1.0, 0.0, 0.0, 0.4, 0.5, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-568", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3304", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.421875, "CSR": 0.579375, "EFR": 0.918918918918919, "Overall": 0.7491469594594595}, {"timecode": 25, "UKR": 0.794921875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1027", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1042", "mrqa_hotpotqa-validation-1095", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-1268", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-1781", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-2284", "mrqa_hotpotqa-validation-2315", "mrqa_hotpotqa-validation-2743", "mrqa_hotpotqa-validation-2927", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-305", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-3885", "mrqa_hotpotqa-validation-3952", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-4449", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4548", "mrqa_hotpotqa-validation-4552", "mrqa_hotpotqa-validation-4624", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-4924", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5165", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5227", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-729", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-3637", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-467", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5607", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7792", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8638", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-1812", "mrqa_newsqa-validation-1873", "mrqa_newsqa-validation-1915", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2036", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-209", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2421", "mrqa_newsqa-validation-2458", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3146", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3254", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-3634", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-49", "mrqa_newsqa-validation-496", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-729", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-88", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-968", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-105", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-10594", "mrqa_searchqa-validation-10787", "mrqa_searchqa-validation-11481", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-12150", "mrqa_searchqa-validation-12205", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-1272", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-13667", "mrqa_searchqa-validation-13756", "mrqa_searchqa-validation-1396", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-14282", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-14660", "mrqa_searchqa-validation-14700", "mrqa_searchqa-validation-14743", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-15593", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15784", "mrqa_searchqa-validation-15912", "mrqa_searchqa-validation-1706", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-2355", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-3420", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-6335", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6870", "mrqa_searchqa-validation-7227", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7584", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-8335", "mrqa_searchqa-validation-8343", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-858", "mrqa_searchqa-validation-8602", "mrqa_searchqa-validation-87", "mrqa_searchqa-validation-9270", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9991", "mrqa_squad-validation-10026", "mrqa_squad-validation-10026", "mrqa_squad-validation-10100", "mrqa_squad-validation-10254", "mrqa_squad-validation-10406", "mrqa_squad-validation-10418", "mrqa_squad-validation-1146", "mrqa_squad-validation-1166", "mrqa_squad-validation-1187", "mrqa_squad-validation-1218", "mrqa_squad-validation-126", "mrqa_squad-validation-1295", "mrqa_squad-validation-1313", "mrqa_squad-validation-1341", "mrqa_squad-validation-1407", "mrqa_squad-validation-1501", "mrqa_squad-validation-1549", "mrqa_squad-validation-159", "mrqa_squad-validation-1640", "mrqa_squad-validation-1662", "mrqa_squad-validation-1692", "mrqa_squad-validation-1758", "mrqa_squad-validation-1771", "mrqa_squad-validation-1775", "mrqa_squad-validation-1877", "mrqa_squad-validation-1906", "mrqa_squad-validation-1960", "mrqa_squad-validation-2049", "mrqa_squad-validation-2059", "mrqa_squad-validation-2105", "mrqa_squad-validation-2113", "mrqa_squad-validation-2136", "mrqa_squad-validation-2207", "mrqa_squad-validation-2435", "mrqa_squad-validation-2466", "mrqa_squad-validation-2518", "mrqa_squad-validation-2530", "mrqa_squad-validation-281", "mrqa_squad-validation-2833", "mrqa_squad-validation-2858", "mrqa_squad-validation-2941", "mrqa_squad-validation-298", "mrqa_squad-validation-3091", "mrqa_squad-validation-3100", "mrqa_squad-validation-3127", "mrqa_squad-validation-3132", "mrqa_squad-validation-3149", "mrqa_squad-validation-3259", "mrqa_squad-validation-3260", "mrqa_squad-validation-3312", "mrqa_squad-validation-3319", "mrqa_squad-validation-3440", "mrqa_squad-validation-3454", "mrqa_squad-validation-3524", "mrqa_squad-validation-3632", "mrqa_squad-validation-3716", "mrqa_squad-validation-3813", "mrqa_squad-validation-3862", "mrqa_squad-validation-3865", "mrqa_squad-validation-3918", "mrqa_squad-validation-3943", "mrqa_squad-validation-4010", "mrqa_squad-validation-4047", "mrqa_squad-validation-4075", "mrqa_squad-validation-4078", "mrqa_squad-validation-4083", "mrqa_squad-validation-4102", "mrqa_squad-validation-4175", "mrqa_squad-validation-4315", "mrqa_squad-validation-4429", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-457", "mrqa_squad-validation-4673", "mrqa_squad-validation-4706", "mrqa_squad-validation-4770", "mrqa_squad-validation-4775", "mrqa_squad-validation-4844", "mrqa_squad-validation-4973", "mrqa_squad-validation-498", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5023", "mrqa_squad-validation-5037", "mrqa_squad-validation-5102", "mrqa_squad-validation-5135", "mrqa_squad-validation-5178", "mrqa_squad-validation-5194", "mrqa_squad-validation-5213", "mrqa_squad-validation-5226", "mrqa_squad-validation-526", "mrqa_squad-validation-5486", "mrqa_squad-validation-549", "mrqa_squad-validation-5513", "mrqa_squad-validation-5581", "mrqa_squad-validation-5741", "mrqa_squad-validation-5784", "mrqa_squad-validation-5812", "mrqa_squad-validation-5863", "mrqa_squad-validation-5871", "mrqa_squad-validation-5876", "mrqa_squad-validation-5972", "mrqa_squad-validation-6029", "mrqa_squad-validation-6059", "mrqa_squad-validation-6080", "mrqa_squad-validation-6121", "mrqa_squad-validation-6154", "mrqa_squad-validation-6166", "mrqa_squad-validation-6177", "mrqa_squad-validation-6242", "mrqa_squad-validation-6430", "mrqa_squad-validation-6588", "mrqa_squad-validation-6598", "mrqa_squad-validation-6614", "mrqa_squad-validation-6676", "mrqa_squad-validation-6685", "mrqa_squad-validation-6694", "mrqa_squad-validation-6721", "mrqa_squad-validation-6741", "mrqa_squad-validation-6789", "mrqa_squad-validation-6789", "mrqa_squad-validation-6801", "mrqa_squad-validation-6875", "mrqa_squad-validation-6921", "mrqa_squad-validation-7135", "mrqa_squad-validation-7159", "mrqa_squad-validation-716", "mrqa_squad-validation-7173", "mrqa_squad-validation-7229", "mrqa_squad-validation-7273", "mrqa_squad-validation-7434", "mrqa_squad-validation-7458", "mrqa_squad-validation-7576", "mrqa_squad-validation-7596", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-7967", "mrqa_squad-validation-7981", "mrqa_squad-validation-80", "mrqa_squad-validation-8035", "mrqa_squad-validation-8151", "mrqa_squad-validation-8176", "mrqa_squad-validation-8343", "mrqa_squad-validation-8356", "mrqa_squad-validation-8397", "mrqa_squad-validation-8420", "mrqa_squad-validation-8439", "mrqa_squad-validation-8485", "mrqa_squad-validation-8503", "mrqa_squad-validation-855", "mrqa_squad-validation-855", "mrqa_squad-validation-8608", "mrqa_squad-validation-8616", "mrqa_squad-validation-8719", "mrqa_squad-validation-8733", "mrqa_squad-validation-880", "mrqa_squad-validation-880", "mrqa_squad-validation-8833", "mrqa_squad-validation-8896", "mrqa_squad-validation-8896", "mrqa_squad-validation-8896", "mrqa_squad-validation-890", "mrqa_squad-validation-8914", "mrqa_squad-validation-8924", "mrqa_squad-validation-9020", "mrqa_squad-validation-9066", "mrqa_squad-validation-913", "mrqa_squad-validation-9170", "mrqa_squad-validation-9173", "mrqa_squad-validation-9220", "mrqa_squad-validation-9237", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9299", "mrqa_squad-validation-9333", "mrqa_squad-validation-940", "mrqa_squad-validation-9406", "mrqa_squad-validation-9436", "mrqa_squad-validation-9470", "mrqa_squad-validation-9559", "mrqa_squad-validation-962", "mrqa_squad-validation-9665", "mrqa_squad-validation-9686", "mrqa_squad-validation-9752", "mrqa_squad-validation-9753", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_squad-validation-9931", "mrqa_squad-validation-9960", "mrqa_triviaqa-validation-1198", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-1644", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-2029", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-2227", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2522", "mrqa_triviaqa-validation-2794", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-316", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-339", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-4315", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-4945", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5964", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6753", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-7367", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-980"], "OKR": 0.84765625, "KG": 0.4859375, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "35", "a coffee house", "beetle", "arthropoda", "Ub Iwerks", "St Pauls", "holography", "Pelias", "Barry White", "Northumbria", "Harvard", "cricketer", "Seymour Hersh,", "a long pole", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "an excessive amount of scaly material composed of dead, keratinized epithelium", "50", "a Rh\u00f4ne Grape Varietal Grown at Tablas Creek Vineyard", "Joseph Smith,", "Huntington Beach, California", "palladium", "moon", "13", "a palla", "The Virgin Spring", "Canada", "Churchill", "Stockholm", "Peter Parker", "Goldie Myerson,", "Diorgio Armani,", "bullfight", "Sparks", "Ginger Rogers", "Rock of Gibraltar", "Comedy Playhouse", "about 25 grams of citric acid per liter, or 1,000 grams, of juice,", "Charles Darwin", "John  Denver,", "Miss Scarlet, Mrs. Peacock", "Marie Van Brittan Brown", "Southern California Timing Association ( SCTA )", "1995", "Bourbon", "Taylor Swift", "Adam Rex.", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "was like a class to help women \" learn how to dance and feel sexy,\"", "Amy Bishop", "cactus", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.5, "QA-F1": 0.5890668767507002}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.2666666666666667, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.0, 0.1764705882352941, 0.7000000000000001, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-7521", "mrqa_naturalquestions-validation-1399", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.5, "CSR": 0.5763221153846154, "EFR": 0.78125, "Overall": 0.697217548076923}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Space Museum\"", "number eight", "affordable housing", "Mao Zedong", "Verona", "Pontiac Silverdome", "elephants", "a charcoal powered grill, stove or hot plate", "Frank McCourt", "Harry Burton", "Hugh Gaitskell", "Margo Leadbetter", "Schengen Area", "\u201cA\u201d", "city of Sheffield, England", "Famous Players-Lasky Corporation", "the Monkees", "Gerald Durrell", "Jezebel", "County Cork", "jason", "Arabian", "Halifax", "Noises Off", "stanley carter", "Frank Wilson", "Carlos the Jackal", "Edwina Currie", "st Moritz Winter Olympics in 1928, Gillis Grafstr\u00f6m", "Robert Maxwell", "1768", "\"For Gallantry;\u201d", "Wednesday's child", "Georgia in Search of an Anchor of Stability", "Tuscaloosa", "The Good Life", "Tahrir Square", "uranium", "d'Artagnan", "27", "Jack Ruby", "Tintoretto", "Eric Coates", "Dubai", "Lester", "Thailand", "Sydney", "a dove", "Tunisia", "Prince Philip", "Apsley House", "Tokyo", "Edgar Lungu", "49 cents", "heart rate that exceeds the normal resting rate", "672", "Linda McCartney's Sixties: Portrait of an Era", "The Frost Place Advanced Seminar", "an @ to your name", "Juan Martin Del Potro.", "27", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5259943181818182}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8026", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-2797", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.46875, "CSR": 0.572337962962963, "EFR": 0.9117647058823529, "Overall": 0.7225236587690632}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "more than 70", "forced Tesla out leaving him penniless.", "Zulfikar Ali Bhutto", "Iran's nuclear program.", "at least 27 Awa Indians", "(l-r)", "Daniel Cain", "acid attack by a spurned suitor.", "Wally", "2008", "after Wood went missing off Catalina Island, near the California coast,", "Rima Fakih", "Afghanistan", "The Everglades", "dilshan made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos,", "about $163 million (180 million Swiss francs)", "baggage from the 80s and has grown beyond a resort town into something more substantial.", "around 3.5 percent of global greenhouse emissions.", "Ensenada, Mexico", "Orbiting Carbon Observatory", "Switzerland", "Kenneth Cole", "Janet and La Toya", "more than 22 million people in sub-Saharan Africa", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "burns badly on the backs of his knees", "al-Shabaab", "posting a $1,725 bail", "sustain future exploration of the moon and beyond.", "his business dealings", "Opry Mills", "Number Ones", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "Obama", "\"gotten the balance right\"", "The oceans", "stomized him with a broomstick, a pair of scissors and a wooden dowel", "doctors", "off the coast of Dubai", "Bill Haas", "Talisa Maegyr", "1932", "1923 and 1925", "Gilda", "Nahum Tate", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Benjamin Disraeli", "a rising sun"], "metric_results": {"EM": 0.515625, "QA-F1": 0.637504917556103}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.25, 0.0, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.06896551724137931, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.125, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.515625, "CSR": 0.5703125, "EFR": 0.9354838709677419, "Overall": 0.7268623991935483}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai Steel", "Monday night", "Bailey, Colorado", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "40", "Illuminati was this secret society which was brutalized by the Catholic Church in the 1600s.", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "in Japan", "Arizona", "between South America and Africa.", "Tetris", "outside influences in next month's run-off election,", "aid to Gaza,", "flipped and landed on its right side,", "suppress the memories and to live as normal a life as possible", "Tuesday in Los Angeles.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "the area was sealed off, so they did not know casualty figures.", "knocking the World Cup off the front pages for the first time in days.", "Cash for Clunkers program", "\"project work\"", "Oprah: A Biography", "80 percent of a woman's face", "London's 20,000-capacity O2 Arena.", "to make life a little easier for these families by organizing the distribution of wheelchair, donated and paid for by his charity, Wheelchair for Iraqi Kids.", "Ozzy Osbourne", "$50", "Australian officials", "Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "At least 38", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "17 Again", "Kabul", "22", "Steven Gerrard", "12.3 million people worldwide", "the area was sealed off, so they did not know casualty figures.", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "West Side Story", "Fifth", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6167963113275613}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.21428571428571427, 1.0, 1.0, 1.0, 0.9090909090909091, 0.4444444444444445, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-3575", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.484375, "CSR": 0.5673491379310345, "EFR": 0.8484848484848485, "Overall": 0.7088699222831766}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "sex organs", "the Russian army", "diffuse nebulae", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "Iran", "a computer maintenance utility", "July 4, 1776", "pick yourself up and dust yourself off and keep going", "John Garfield as Al Schmid", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "salami", "Ethel `` Edy '' Proctor", "a ranking used in combat sports, such as boxing or mixed martial arts, of who the better fighters are relative to their weight", "Husrev Pasha", "Stephanie Judith Tanner", "ulnar nerve", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris", "the Rashidun Caliphs", "Lake Powell", "ornament", "September 6, 2019", "population", "substitute good", "Marries", "over 74", "1987", "fingers", "October 2000", "New York City", "Mamata Banerjee", "the United States economy first went into an economic recession", "the closing of the atrioventricular valves and semilunar valves", "Hermann Ebbinghaus", "Marvin Gaye", "used their knowledge of Native American languages as a basis to transmit coded messages", "Donny Osmond", "Rome and Carthage", "George Herbert Walker Bush", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "the two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Lake Baikal", "the adventure park"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5562299350553661}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3076923076923077, 0.5, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.7142857142857143, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.5, 0.5, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.9333333333333333, 1.0, 0.0, 0.20689655172413793, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.40625, "CSR": 0.5619791666666667, "EFR": 0.8421052631578947, "Overall": 0.7065200109649122}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "pioneers.", "Hutter", "shoes.", "nine", "Rashid Akmaev,", "acetylene", "ebulliate", "fiber.", "gray fox", "a rose", "Winston Rodney", "sand", "Nanjing", "Montana", "John Cleese", "the Sun", "GILBERT & SullIVAN.", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon.", "fibreboard", "tin", "the 1970 box office and critical disaster Song of Norway", "Frida Kahlo", "son of John and Abigail Adams, served as the sixth President of the United States from 1825 to 1829.", "\"Y\" 2 \"K\": An Eskimo", "Fat man, you shoot a great game of pool", "Hair", "William Randolph Hearst", "pumice", "ale", "Homo sapiens", "telephone", "a song performed by English pop punk band Busted.", "Luther", "The New Colossus", "yelp", "Richard Wagner", "the younger daughter of Prince Andrew, Duke of York,", "Braddock", "middleweight champion", "bronchodilators", "Forty", "fluorescent lights.", "Red", "a Chenard", "Earl Long", "Neil Patrick Harris", "Wyatt and Dylan Walters", "1999", "vitamin D", "five", "Alberto juantorena", "R&B vocal group", "Awake", "Doctor of Philosophy", "Pakistan", "in Seoul.", "an African-American woman for the job."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5186011904761905}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_triviaqa-validation-7493", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.484375, "CSR": 0.5594758064516129, "EFR": 0.9090909090909091, "Overall": 0.7194164681085045}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the macula", "the volume", "a crossword puzzle clue", "Joseph Conrad", "Diners' Club Card", "Christian Dior", "The Pittsburgh Cycle", "Juliet", "Notre Dame", "Tablecloth", "Tate", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "a", "a deck of cards", "kozo", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Kate Middleton", "Betty Suarez", "R", "a dairy cattle", "New Jersey", "Lake Ontario", "Matthew Perry", "the musical Hairspray", "John Ford", "kismet", "the Chocolate Factory", "artillery", "aluminum", "General McClellan", "Ned Kelly", "an assemblage", "gravitational", "Isis", "a quiveir", "Heroes", "on the two tablets", "the organ transplant of a kidney into a patient with end - stage renal disease", "seven units", "Geheimrat Dr. Max", "Thomas Hauser", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "February 20, 1978", "two years", "Arsene Wenger", "as time goes on, it kind of becomes more and more of a phenomenon."], "metric_results": {"EM": 0.46875, "QA-F1": 0.578125}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, false, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-12751", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-10042", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-10526", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-114", "mrqa_newsqa-validation-2123"], "SR": 0.46875, "CSR": 0.556640625, "EFR": 0.9117647058823529, "Overall": 0.7193841911764706}, {"timecode": 32, "before_eval_results": {"predictions": ["the same as the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "the Black Death", "Kenneth", "John Stuart Mill", "Herman Melville", "CIA", "piano", "Rickey Henderson", "Jawaharlal Nehru", "D. carota ssp. maritimus", "John Grunsfeld", "Llados", "1976", "Galileo Descartes", "a quark", "the Lamentations of Zeno", "Rudy Giuliani", "the First Amendment", "Virginia", "Sif", "New Jersey", "The Omega Man", "a walk-in pantry", "a barrel, cask, or tun", "the 1984 Summer Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Jenna Davenport", "Los Angeles", "the East Wind", "Richard III", "the policies", "the pen", "Mexico", "Douglas Adams", "Strindberg", "Hawaii", "Stephen Crane", "Prussia", "Sophocles", "Mark Cuban", "the Thought Police", "a bust", "Central Park", "Alice", "Part 2", "Coconut Cove", "aeoline", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.578125, "QA-F1": 0.648983134920635}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767"], "SR": 0.578125, "CSR": 0.5572916666666667, "EFR": 0.9629629629629629, "Overall": 0.7297540509259259}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "pathogens, an allograft", "a large concrete block is next to his shoulder, with shattered pieces of it around him. Blood trickles down the road.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"I think she's wacko.\"", "the second she got back from Mexico,", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "Hundreds of women protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license,", "Arkansas", "Cash for Clunkers", "environmental", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers,", "different women coping with breast cancer in five vignettes.", "a missile", "Police", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space, allowing for such features as a full garden and pool, a tennis court, or several heli-pads.", "CNN", "no chance", "a children's hospital in St. Louis, Missouri.", "he and the other attackers were from Pakistan and asked for a meeting with Pakistan's High Commission.", "two years ago", "two", "a bald Bard with a small beard, and bags under his eyes.", "Symbionese Liberation Army", "he acted in self defense in punching businessman Marcus McGhee.", "two tickets to Italy on Expedia.", "Colombia", "in-cabin lighting system", "resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1,", "Appathurai", "$40 and a loaf of bread.", "African National Congress Deputy President Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "Bremen, Germany", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "Spokescandy", "the Star-Spangled Banner"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7045034996321761}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7058823529411765, 0.5, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5333333333333333, 0.07407407407407407, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-2897", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.640625, "CSR": 0.5597426470588236, "EFR": 0.9565217391304348, "Overall": 0.7289560022378516}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "union members; Philadelphia is a union city.", "nuclear site,", "Yemen", "bankruptcy", "nearly $2 billion in stimulus funds", "a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Bahrain", "children of street cleaners and firefighters.", "Joan Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers", "Honduran", "Brazil", "three different videos", "strife in Somalia,", "Roy", "WBO welterweight title", "relatives of the five suspects,", "Meredith Kercher.", "that former U.S. soldier Steven Green exhibited clear symptoms of acute stress disorder in Iraq and that a military psychiatric nurse-practitioner failed to diagnose the troubled infantryman and pull him out of combat.", "Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "cancerous tumor.", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "a model of sustainability.", "glamour and hedonism", "J. Crew", "Department of Homeland Security Secretary Janet Napolitano", "543", "The woman who received the first-ever near-total face transplant in the United States", "Robert Gates", "Israel", "on 112 acres about 30 miles southwest of Nashville", "in critical condition", "Seoul,", "Nicole", "a school test score of 98 with a \"What about those other two points?\"", "next week", "Adam Lambert", "officials in the agency's Colorado office", "early detection and helping other women cope with the disease.", "Her husband and attorney, James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1972", "Black Elk", "The Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6184291377535863}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, false, false, true, true, true, true, true, false, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.17647058823529413, 0.5, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.18181818181818182, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.07142857142857144, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_searchqa-validation-7879"], "SR": 0.53125, "CSR": 0.5589285714285714, "EFR": 0.7333333333333333, "Overall": 0.684155505952381}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position.", "Canada", "Malibu", "Sisyphus", "measure of sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Prospero", "pizzazz", "the Aegean Sea", "Battle of the Little Bighorn", "Shakers", "a bellwether", "time and Free Will", "chips", "Boxer", "The Spiderwick Chronicles", "Florence Mabel Harding", "Las Vegas", "Case", "the Rose Bowl", "Degas", "short cropped", "light tunais", "Napa", "Eurail France-Germany-Spain Pass", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "Grease", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Begin", "National Ice Cream Day", "Grace Evans", "50 million cells per litre (quart)", "Volitan Lionfish", "Charlie Sheen", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Seth", "Lou Gehrig", "meaning and origin", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.46875, "QA-F1": 0.575}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1389", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-7041", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.46875, "CSR": 0.5564236111111112, "EFR": 0.9411764705882353, "Overall": 0.7252231413398692}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "a scallop", "risky", "bullion", "Supernanny", "Atlantic", "Cincinnati", "a mosque", "Henry Hudson", "the Peashooter", "dry ice", "Elihu Root", "Entourage", "eels", "Philadelphia", "The Museum of Modern Art", "the Unicorn", "John C. Frmont", "Russia", "(Barbara) STREISAND", "Hermann Hesse", "the Taj Mittal", "English Monarchs", "Carmen", "Margaret Mitchell", "Frollo", "Sultans of Swing", "Pandarus", "(a gloomy landscape)", "Burt Reynolds", "Sphinx", "Louis Armstrong", "Saudi Arabia", "American new wave band", "Arby's", "coffee", "The Lgion", "Robert Burns", "Hulk", "Winnipeg", "Memphis Belle", "Burkina Faso", "Central Pacific", "Attorney General", "Icelandic", "a bison (Bos taurus)", "Sunday", "Edith Piaf", "Ivan III", "a prologue", "birch", "an investor couple", "Jack Gleeson", "(Phil) Hurtt", "animals", "Massachusetts", "Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "17 Again"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6860119047619048}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_hotpotqa-validation-2162", "mrqa_newsqa-validation-3951"], "SR": 0.640625, "CSR": 0.5586993243243243, "EFR": 0.8695652173913043, "Overall": 0.7113560333431257}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "John Y. Brown Jr.", "oats", "Romney", "Ivan the Terrible", "Sally Field", "Charles Lindbergh", "Egypt", "pi", "tin", "Lake Maurapas", "Cousin Eddie", "w", "Marriott", "France", "Canada", "The Secret", "gold", "Collagen", "the Soviet Union", "compound", "the cranes", "Jesse James", "Alzheimer", "the Gulf of Mexico", "Austin", "the axiomatic system", "Eva Peron", "Cain", "Edward Asner", "X-Men", "the Louvre", "coho salmon", "Prison Break", "Mars", "Maine", "sheep's milk", "Meg", "Sonnet to Orpheus", "deuce", "Hans", "Peter Bogdanovich", "Billy Joel", "Pilate", "\"Britain redeemed and Canada preserved [microform]\"", "the Quaternary Period", "no contest", "Junior Walker", "Czech Republic", "chicken", "NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"The Disaster Artist\"", "Australian", "the sins of the members of the church,", "$22 million", "17 Again", "Nelson"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6572916666666666}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-12000", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-8387", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-5774"], "SR": 0.578125, "CSR": 0.5592105263157895, "EFR": 1.0, "Overall": 0.7375452302631579}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospira", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "M1 Abrams", "a ballad", "a canoe", "forgetting Sarah Marshall", "Witness", "Jack the Ripper", "3800", "Rene Auberjonois", "taxonomy", "Spain", "the brain", "Francesco Schettino", "Macbeth", "comedy", "Mary Poppins", "Casowasco", "Fresh Prince of Bel-Air", "Land of Nod", "watermelon", "bathwater", "married", "Livin' On A Prayer", "Sherlock Holmes", "a lollipop", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "a double triangle", "German", "Katamari Damacy", "Bill Murray", "Margaret Thatcher", "the Duke of Wellington", "manganese", "forests", "Olympia", "Waylon Jennings", "Lawrence of Arabia", "Brazil", "British Columbia", "Out of Africa", "pan rabbit", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "the different levels of importance of human psychological and physical needs.", "one", "Norfolk Island", "Wright brothers", "jurisdiction", "Sam tick", "the L'Aquila earthquake,", "voluntary voluntary misdemeanor", "\"deep sorrow\" at the death of two women killed in a stampede at one of his events in Angola", "Pygmalion"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5969551282051282}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.8717948717948718, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_searchqa-validation-402", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.515625, "CSR": 0.5580929487179487, "EFR": 0.9354838709677419, "Overall": 0.7244184889371381}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "Wikis", "the Byzantine Empire", "Independence", "Jefferson", "Ford Madox Ford", "The Orinoco", "a q-tip", "California", "Dixie", "RAND", "Warren Harding", "engrave", "Casa", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "conformation", "Ratatouille", "circadian fluctuations", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "a tailor", "26", "life", "hollyhocks", "chess", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Tara", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer", "Bob Dole", "a pair of mathematical geniuses.", "managing his time"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5732886904761905}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.515625, "CSR": 0.55703125, "EFR": 0.9032258064516129, "Overall": 0.7177545362903225}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "South Korean horror film", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000", "Yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133", "The Andy Williams Christmas Album", "Tsavo East National Park", "New York Islanders", "1345 to 1377", "nearly 80 years", "Jean Acker", "Premier League", "The Gettysburg Address", "most awarded female act of all-time.", "Tottenham", "Daphnis et Chlo\u00e9", "1", "26,000", "Kristin Scott Thomas", "Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "a prototype of the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mase Dinehart", "Tevye", "Sir Tom Finney", "Cameroon", "obtaining and proper handling of human blood.", "toxic smoke from burn pits", "two", "he checked himself into a Los Angeles mental institution in an effort to kick the habit.", "Portia", "a man", "DiCaprio", "a destructive ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7283817693744165}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 0.35294117647058826, 0.4, 0.0, 1.0, 0.0, 0.22222222222222224, 0.0, 1.0, 0.761904761904762, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-16547", "mrqa_searchqa-validation-13997", "mrqa_naturalquestions-validation-6326"], "SR": 0.609375, "CSR": 0.5583079268292683, "EFR": 1.0, "Overall": 0.7373647103658537}, {"timecode": 41, "before_eval_results": {"predictions": ["a touchdown", "10", "did not identify any of the dead.", "Les Bleus", "2005", "more than 4,000", "the club's board", "an angry mob.", "normal maritime", "Sri Lanka", "death", "average of 25 percent", "fatally shooting a limo driver", "The Al Nisr Al Saudi", "as many as 50,000", "piano", "$250,000", "itute", "the skull", "tax", "Los Ticos", "acute stress disorder", "Russia", "Twitter", "through a facility in Salt Lake City, Utah", "Manmohan Singh's Congress party", "Haiti", "Tuesday afternoon.", "militants", "23 years.", "a head injury.", "Tim Cahill", "an open window that fits neatly around him", "Leo Frank", "Paul McCartney", "off Haiti's coast", "President Robert Mugabe", "free", "three", "Diversity", "on-loan David Beckham claimed his first goal in Italian football.", "his son is fighting an unjust war for an America that went too far when it invaded Iraq", "Twilight", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died,", "Fayetteville, North Carolina,", "Suwardi, the plane had a crew of 14 people and was carrying an additional 98 passengers,", "al Qaeda", "Hillary Clinton", "Rihanna", "angular rotation", "from the right side of the heart to the lungs", "54 Mbit / s", "in the County of Gloucestershire", "the B-24 Liberator", "an Incredible, Edible... breakfast cereals.", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "U.S. Department of Transportation"], "metric_results": {"EM": 0.5, "QA-F1": 0.641609832935264}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, true, true, false, true, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.5, 0.0, 0.7272727272727273, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.5714285714285715, 0.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.8571428571428571, 0.20689655172413793, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.28571428571428575, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3857", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-2414", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-10945"], "SR": 0.5, "CSR": 0.5569196428571428, "EFR": 0.90625, "Overall": 0.7183370535714285}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Las Vegas to Arizona.", "Zimbabwe", "Italian Serie A", "Darrel Mohler", "dancing against a stripper's pole.", "Michoacan Family", "WTA Tour titles", "Morgan Tsvangirai.", "42", "takes on the swords of the Taliban.", "people with snorkels typically launch into the reefs from Cairns, Queensland.", "80 percent", "1979", "\"Follow the Sun,\"", "Elena Kagan", "CBS, CNN, Fox and The Associated Press.", "an auxiliary lock", "1-1", "AbdulMutallab", "Myanmar's military government,", "Collier County Sheriff Kevin Rambosk", "Marcus Schrenker,", "Filipino-American woman", "poems", "the program was made with the parents' full consent.", "Sen. Barack Obama", "The Red Cross, UNHCR and UNICEF", "Moscow", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "not guilty of affray by a court in his home city on Friday.", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award", "state senators who will decide whether to remove him from office", "31 meters (102 feet)", "its nude beaches.", "how preachy and awkward cancer movies can get.", "a Florida girl who disappeared in February,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill.", "\"theoretically\" Iran could develop a nuclear weapon", "1940's", "March 22,", "celebrity pontificating about the plight of the environment", "at a depth of about 1,300 meters in the Mediterranean Sea.", "Antichrist", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Orion", "brown", "Selfie", "2002", "South Australia", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6667835764113338}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.11764705882352941, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.5, 1.0, 0.3076923076923077, 0.5333333333333333, 0.4, 0.4, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-564", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.546875, "CSR": 0.5566860465116279, "EFR": 0.896551724137931, "Overall": 0.7163506791299118}, {"timecode": 43, "before_eval_results": {"predictions": ["north,", "legitimacy of that race.", "At least 88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "that these \"fusion teams,\" as they're being called, have come into effect.", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "nearly $2 billion", "The National Infrastructure Program, as he called it,", "1941", "The station", "an MBA in finance but appeared to have been unemployed for several months and had worked for major accounting firms, such as Price Waterhouse.", "The Arkansas weatherman", "Robert Mugabe", "the state's first lady,", "Afghanistan's restive provinces", "Saturday.", "$1.5 million", "violent government crackdown seeped out.", "could be secretly working on a nuclear weapon", "that the teens were charged as adults.", "death squad killings carried out during his rule in the 1990s.", "Elena Kagan", "Hyundai", "100 percent", "Saturday", "Pakistan's", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole", "a Muslim with Lebanese heritage,", "South Africa", "Barack Obama", "helicopters and robotic surveillance craft", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "a receptionist with a gunshot wound in her stomach", "more focused on the book-reading experience than the Apple iPad", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960", "Aston Villa", "peasants, small and medium-size farmers, landless people, women farmers, indigenous people, migrants and agricultural workers", "pool", "1822", "The Dressmaker", "Trilochanapala", "crote", "a buffalo", "red olives", "the occipital lobe"], "metric_results": {"EM": 0.484375, "QA-F1": 0.572534004718108}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.08695652173913043, 0.923076923076923, 0.9523809523809523, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4000000000000001, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 1.0, 0.5, 0.125, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-13511", "mrqa_searchqa-validation-2281"], "SR": 0.484375, "CSR": 0.5550426136363636, "EFR": 0.9090909090909091, "Overall": 0.7185298295454545}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Duval County", "Benj Pasek and Justin Paul,", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Atlanta Athletic Club", "Franconia, New Hampshire,", "Operation Watchtower", "Dan Crow", "War & Peace", "Amberley Village", "What Are Little Boys Made Of?", "Berea College", "Chicago Bears", "Luca Guadagnino", "Liesl", "Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "jus sanguinis", "Radcliffe College", "Charles Guiteau", "Ford Motor Company", "If the citizen's heart was heavier than a feather they would face torment in a lake of fire.", "India", "Lutheranism", "armed", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "Robert Grosvenor", "3,672", "Henry Luce", "I'm Shipping Up to Boston", "American", "British singer and \"Britain's Got Talent\" winner Jai McDowall", "Zhou", "Australia's capital is Canberra, and its largest urban area is Sydney", "first to develop lethal injection as a method of execution", "Nicola Adams", "\"bay of geese,\"", "Russia", "know what's important in life,", "Steven Green", "Fayetteville, North Carolina,", "Chaucer", "rattlesnakes", "Riddles", "healthy, wealthy, and wise"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6167443347953216}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2105263157894737, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986"], "SR": 0.578125, "CSR": 0.5555555555555556, "EFR": 0.7777777777777778, "Overall": 0.6923697916666667}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "the Indian Ocean waters near the Gulf of Aden,", "30", "crocodile eggs", "A Colorado prosecutor", "Polis", "on Saturday.", "in Haiti", "in July for A Country Christmas,", "sniff out cell phones.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "17 Again", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "a diet for a few months and lose weight and then go back to exactly how you were living before and then was a challenge.", "Heshmatollah Attarzadeh", "the ireport form", "government", "Nine out of 10 children", "police", "Sen. Joe Lieberman, I-Connecticut,", "a crocodile", "a bronze medal in the women's figure skating final,", "more than 200.", "Congress", "Susan Boyle", "a law signed Tuesday by President Obama.", "Phillip A. Myers.", "Obama's", "Gyanendra", "the cause of the child's death will be listed as homicide by undetermined means,", "Casey Anthony, 22,", "officers at a Texas  airport", "10 municipal police officers", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers, ages 18 and 5,", "since 2004.", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Arsene Wenger", "slavery, especially Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ), and grandmother Mo ( Laila Morse )", "Latin liberalia studia", "a British children's writer", "Johnny Mathis", "The Golden Child (1986)", "Champion Jockey", "Luca Guadagnino", "Freddie Jackson", "unknown", "timing shapes and supports brain function", "a jigger", "a Bristol Box Kite"], "metric_results": {"EM": 0.515625, "QA-F1": 0.640265376984127}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, false, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.6666666666666666, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 0.09523809523809523, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.515625, "CSR": 0.5546875, "EFR": 0.9354838709677419, "Overall": 0.7237373991935484}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "phone calls or by text messaging,", "the Orange County District Attorney's Office.", "12.3 million", "Mexico", "Argentine", "Vivek Wadhwa,", "Brett", "eight Indian army troopers, including one officer, and 17 militants,", "Saturday", "Nicole", "legitimacy of that race.", "Adidas,", "Dennis Davern, the captain of yacht owned by Wood and her then-husband, actor Robert Wagner.", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "Nothing But Love", "allegedly involved in forged credit cards and identity theft", "June 6, 1944,", "[Middle East and North Africa]", "twice", "October 19,", "\"I apologize for comments I made last night at the Annual Caddy Awards dinner in Shanghai,\"", "Seoul,", "promotes fuel economy and safety while boosted the economy.", "ALS6", "eight", "Siri", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback Forestry in Medford, Oregon,", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "that a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "blacks, Hispanics and whites", "five", "the most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel ( 1497 -- 1558 )", "Discworld", "Japan", "fox hunting", "New York", "travel", "16,116", "\"Juno\"", "sukkar", "a bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7415058032245533}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5333333333333333, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 0.15384615384615388, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3956", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3968", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1764", "mrqa_naturalquestions-validation-5769", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-11573"], "SR": 0.65625, "CSR": 0.5568484042553192, "EFR": 0.9090909090909091, "Overall": 0.7188909876692456}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Airlines", "A Rush of Blood to the Head", "5", "Chicago", "\"The One Who Walk Away from Omelas\"", "child actor", "Dennis H. Kux", "drawing the name out of a hat", "Brett Ryan Eldredge", "I-League", "two or three", "Badfinger", "Lady Frederick Windsor", "point-coloration", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue between Corinthian Avenue and North 22nd Street in the Fairmount section of the city,", "1946 and 1947", "5,112", "1992", "many artists' lofts and art galleries, but is now better known for its variety of shops ranging from stylish upscale boutiques to national and international chain store outlets.", "14,673", "6'5\"", "Mickey Gilley's", "Swiss Confederation has adopted various provisions of European Union law in order to participate in the Union's single market.", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London Luton Airport", "the Salzburg Festival", "Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "Messiah Part II", "Bunker Hill", "lion", "Royal", "World War II", "Knoxville, Tennessee", "Three's Company", "P.O.S,", "Labour", "\"Linda McCartney's Life in Photography\"", "Erich Maria Remarque", "September 14, 2008", "79", "Buffalo Bill", "Romania", "Zephyr, Billy Cobham, Alphonse Mouzon, the James Gang, Deep Purple, and Moxy.", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces at the site.", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "rooms", "Bank of England"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7161172161172161}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.6666666666666666, 1.0, 0.13333333333333333, 0.0, 1.0, 0.5, 0.16666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5349", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-744", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.59375, "CSR": 0.5576171875, "EFR": 0.8076923076923077, "Overall": 0.6987650240384615}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "sUSHI CULTURE", "offensive", "Vulcan", "the Pilgrims", "Fawn Hall", "waived", "Shakespearean Heroines", "Barnum", "Peter John", "cathode", "a torque screw", "gold", "Marlon Brando", "Middle High German", "Monet", "University of Kentucky", "the ruddy", "Brussels", "Macbeth", "General Lee", "piracy", "Fyodor Dostoevsky", "Martin Luther", "Clue", "Edgar Allan Poe", "Norway", "Andrew Johnson", "the Feast of Tabernacles", "Mike Connors", "JUNGLE JIM", "Jim Inhofe", "sancire", "Corpus Christi", "Mali", "an ostrich", "a \"rigid\" constitution", "8-hours per day", "mug", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "a strike", "the Grail", "West Virginia", "Thomas Jefferson", "movie house", "the family chain of Amusement Parks", "critic", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambidevous", "chariots", "Humberside Airport", "265 million", "100 million", "help rebuild the nation's highways, bridges and other public-use facilities.", "a head injury.", "the Vatican's policy on condom use", "Charles II"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5652267156862745}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.515625, "CSR": 0.5567602040816326, "EFR": 0.8709677419354839, "Overall": 0.7112487142034233}, {"timecode": 49, "UKR": 0.78125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1056", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1258", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-211", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4683", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-4840", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5640", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-785", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-1805", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1597", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2009", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2949", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4123", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-526", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12777", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6003", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8428", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_squad-validation-9931", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.833984375, "KG": 0.51015625, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Colorado", "Pammer Anderson", "carnaval", "Treasure Island", "Pocahontas", "improv", "(Whizzer) White", "an octave", "an inert gas or other activating agent", "Great American Novel", "Matthew Broderick", "Joseph Campbell", "Margaret Mitchell", "Our Leading Lady", "a draft horse", "Ernest Lawrence", "a rodeo", "a technique called fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "a melon", "the mouth", "Key West", "the Fellowship of the Ring", "Have You Neverbeen Mellow", "scalpels", "Manhattan", "February 2", "Leontyne Price", "a compost", "BUNNY", "Christopher Columbus", "Phil Mickelson", "(Carrie) Bradshaw", "the Pierian spring", "(1982)", "a burnoose", "Philadelphia", "peanut butter", "Ralph Ellison's Invisible Man", "cork", "Alexander \"Lex\" Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "(Scottish) League", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "Sunday evening", "three out of four", "poems telling of the pain and suffering of children just like her", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.453125, "QA-F1": 0.5559027777777779}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-3349", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-15005", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-12067", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073"], "SR": 0.453125, "CSR": 0.5546875, "EFR": 0.8857142857142857, "Overall": 0.7131584821428572}]}