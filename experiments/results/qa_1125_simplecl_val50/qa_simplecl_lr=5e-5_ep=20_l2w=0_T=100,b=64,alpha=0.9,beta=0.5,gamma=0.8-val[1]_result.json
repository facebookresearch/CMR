{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=25, kg_eval_mode='metric', kr_eval_freq=25, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=50, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=50, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4640, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "the 1970s", "Sunni Arabs from Iraq and Syria", "graph isomorphism", "Thomas Murphy", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "the net force", "12 January", "1976\u201377", "The E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "the Council of Chalcedon", "complicated definitions", "coordinating lead author of the Fifth Assessment Report", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation of a drug treatment for an individual", "2014", "late 1970s", "30% less steam", "1983", "Happy Days", "1,230 kilometres", "Saturday, 23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "fossils in sedimentary rocks", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act, commonly referred to as the Cat and Mouse Act, was an Act of Parliament passed in Britain under Herbert Henry Asquith's Liberal government in 1913", "Howard Wolowitz", "Daenerys", "Raabta"], "metric_results": {"EM": 0.75, "QA-F1": 0.783077061373245}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 0.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.06451612903225806, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-5952", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-9931", "mrqa_squad-validation-2611", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_squad-validation-5178", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.75, "CSR": 0.7578125, "EFR": 0.9375, "Overall": 0.84765625}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "Smith and Jones", "1767", "53,000", "Fu\u00dfach", "leptin", "have a supporting function", "7 West 66th Street", "patent archives", "All members of Parliament", "4-week period", "six", "Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "The Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "the geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "1898", "Commander (CDR) Command Module Pilot", "citizenship", "Merritt Island", "physician, lawyers, engineers", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Lituya Bay", "120 m ( 390 ft )", "The Winds of Winter", "100 members", "photo-electric", "Welch, West Virginia", "Independence", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "The Monitor and Merrimac", "Spain"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7868785294566545}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 0.6666666666666666, 0.888888888888889, 0.0, 1.0, 0.4, 1.0, 0.06666666666666667, 0.38095238095238093, 0.0, 0.5, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-9559", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-4072", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.7291666666666667, "EFR": 0.9523809523809523, "Overall": 0.8407738095238095}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "a civil disobedients' use of force and violence and refusal to submit to arrest", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six teams", "redistributive taxation", "rubisco", "recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "Yam route systems", "Stairs", "genetically modified crops", "around 300,000", "three sites", "DeMarcus Ware", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Bruno Mars", "the Calvin cycle", "the Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown San Bernardino", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "the Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "the optic chiasma", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "September 1973", "the One Ring", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.625, "QA-F1": 0.7584334935897435}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 0.5714285714285715, 0.7142857142857143, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6798", "mrqa_squad-validation-4108", "mrqa_squad-validation-180", "mrqa_squad-validation-8830", "mrqa_squad-validation-10293", "mrqa_squad-validation-4759", "mrqa_squad-validation-8584", "mrqa_squad-validation-8763", "mrqa_squad-validation-126", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_squad-validation-384", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.625, "CSR": 0.703125, "EFR": 0.9583333333333334, "Overall": 0.8307291666666667}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the use of outbreaks during the Middle Ages gave it the name that has become the medical term.", "approximately 80 avulsions", "15", "Presque Isle (near present-day Erie, Pennsylvania) on Lake Erie's south shore", "wireless", "Beyonc\u00e9 and Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "the 1960s", "the freedom to provide services applied, it was directly effective, and the rule was probably unjustified", "Napoleon", "Immunology", "geophysical surveys", "topographic", "130 million cubic foot (3.7 million cubic meter)", "The committee created the 50 fund as its philanthropic initiative and focuses on providing grants to aid with youth development, community investment and sustainable environments", "force, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "struggle, famine, and bitterness among the populace", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "the Jews and in diatribes against \"Turks\" (Muslims) and Catholics", "six", "the Big Ten Conference", "Thames River", "Cisco Systems", "shipping toxic waste, Franco Frattini, the Justice, Freedom and Security Commissioner, proposed with Dimas to create criminal sentences for \"ecological crimes\"", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "linked groups or chains, still always anchored to a thylakoid", "motorway underpass without pedestrian access", "use of remote sensing for the conservation of the Amazon is also being used by the indigenous tribes of the basin to protect their tribal lands from commercial interests", "religious beliefs", "the spirit of protest should be maintained all the way, whether it is done by remaining in jail, or by evading it", "the use of these \"on the hearth is the luckiest thing in all the world!\"", "the Natal Advertiser", "the Impaler", "The Little Foxes by Lillian Hellman", "the 1982 Sony SL-2000 portable", "Leonard Nimoy", "8/4 x 365 = 730 days", "1994", "the University of Arizona", "the title \"Marshal Dillon\"", "Wannabe\" and \"Say You'll Be There\"", "the Best Hotels on Bali: Legian Resort on Seminyak Beach; 2.", "The new nightspot Teddy's made this presidential Hollywood hotel a happening # Quiz # Question. 0:29", "LASER", "the Kids on a magical journey through this author's fairy tales on the Flying Trunk ride at Tivoli", "Jupiter", "the egret flower of the Far East - Botany Boy", "use the word \"non\" to indicate \"not\" it is", "Andrew Taggart, Emily Warren and Scott Harris", "use in a car", "American", "Enrique Torres"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5161039365579008}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.11764705882352941, 0.5, 1.0, 0.6666666666666665, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16, 0.2, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 0.5714285714285715, 0.48484848484848486, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4876", "mrqa_squad-validation-9357", "mrqa_squad-validation-10204", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-390", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-2526", "mrqa_squad-validation-4157", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-4315", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073", "mrqa_newsqa-validation-496"], "SR": 0.390625, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "a Turing machine operating in time f(n) that solves the problem", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans' Mercedes-Benz Superdome", "fell from his horse while hunting and died because of the injury", "the member state cannot enforce conflicting laws", "British bacteriologist J. F. D. Shrewsbury", "a mouth that can usually be closed by muscles; a pharynx (\"throat\")", "inversely to member state size", "Europe", "to help him leave Gospi\u0107 for Prague where he was to study", "a substantial number of colonies had been designed to provide economic profit and to ship resources to home ports in the seventeenth and eighteenth centuries", "$37.6 billion", "Kenyan athletes (particularly Kalenjin)", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "the Golden Gate Bridge", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau (1685)", "Levi's Stadium in the San Francisco Bay Area at Santa Clara, California", "ten million", "the Lippe", "HD channels and Video On Demand content", "time and storage", "four half-courses per term", "the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Nassau Herald", "the League of the Three Emperors", "the field of science awarded by universities in many countries", "143,007", "Bill Clinton", "Waltham Abbey, Essex", "Secretariat", "a type of Russian made RF connector", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.", "Thomas Christopher Ince", "American Choppers", "drawing the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy (TV series)", "Woolsthorpe-by-Colsterworth", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia and broadcast on ITV in the United Kingdom", "Br'er Rabbit or Brer Rabbit or Bruh Rabbit", "corruption", "a doctor still up and working after 24 hours", "Dover Beach"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7543342465677025}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16666666666666669, 1.0, 1.0, 0.6060606060606061, 0.9090909090909091, 1.0, 0.18181818181818182, 0.14814814814814817, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.75, 0.8571428571428571, 0.9523809523809523, 1.0, 1.0, 0.923076923076923, 0.0, 0.0, 0.7058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.5, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5882352941176471, 0.0, 1.0, 0.2222222222222222, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-127", "mrqa_squad-validation-6218", "mrqa_squad-validation-4517", "mrqa_squad-validation-4210", "mrqa_squad-validation-1187", "mrqa_squad-validation-9928", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-2941", "mrqa_squad-validation-12", "mrqa_squad-validation-2865", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_squad-validation-3943", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-5227", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-2315", "mrqa_naturalquestions-validation-1692", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.59375, "CSR": 0.6328125, "EFR": 1.0, "Overall": 0.81640625}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "courts of member states", "the dot", "three", "a negative long-term impact", "fear of their lives", "80", "1521", "Gibraltar and the \u00c5land islands", "a plant's free phosphate supply", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "to force certain laws ineffective, to cause their repeal, or to exert pressure to get one's political wishes on some other issue", "entertainment", "vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "the Silk Road", "San Diego", "a German Nazi colonial administration", "the Council on Advanced Studies in the Social Sciences and Humanities", "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "Spanish", "Structural", "president and CEO", "indulgences for the living", "BSkyB", "a terrorist organisation", "Cam Newton", "U2", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "a large green dinosaur", "She has co-written twenty of Swift's officially-released songs and singles, including \"White Horse,\" \"Teardrops on My Guitar,\" and \"You Belong with Me", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "the Jasenovac concentration camp", "Rabat", "between 11 or 13 and 18", "Heather Langenkamp", "Thomas Henry Moray", "Toyota Grand Prix of Long Beach", "(IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk", "Charmed", "Cleopatra \" Cleo\" Demetriou", "Liverpool and England international player", "Oregon", "Rickie Lee Skaggs", "48,982", "the Ashanti Region", "73", "Algeria", "a Wall Street executive", "Biafra", "Polar", "Atlantic City"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7265000318309142}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9545454545454546, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 0.4, 1.0, 0.5, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-5213", "mrqa_squad-validation-8914", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_hotpotqa-validation-4317", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-226", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_naturalquestions-validation-2159", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-1971"], "SR": 0.609375, "CSR": 0.6294642857142857, "EFR": 1.0, "Overall": 0.8147321428571428}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "the Duchy of Prussia, the Channel Islands, and Ireland", "the working fluid", "suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "solution", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "papacy", "homologous recombination", "a modern canalized section", "protest against the occupation of Prussia by Napoleon", "improved markedly", "northern", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "single-tape", "Bart Starr", "oxygen that is damaging to lung tissue", "Karluk Kara-Khanid ruler", "Perth", "Ian James Rush", "Gerry Adams", "New Orleans Saints", "1974", "four", "Harris Museum, Art Gallery & Preston Free Public Library", "A. E. Housman", "the capital of the Socialist Republic of Vietnam", "Sevens", "fennec", "Bart Conner", "fantasy role-playing game", "Martin McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Ray Looze", "140 to 219", "Father of Liberalism", "Christophe Lourdelet", "Pablo Escobar", "Afro-Russians", "Mexico City", "Sleeping Beauty", "Tomorrowland", "2006", "Noddy Goes To Toyland", "Omar Bongo", "Raphael Chex Cereal", "Ray Harroun", "Charlie's Angels", "David Tennant"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6996031746031746}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, false, false, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 0.8, 1.0, 0.0, 0.6666666666666666, 0.2222222222222222, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-3091", "mrqa_squad-validation-9287", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-1898", "mrqa_hotpotqa-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-3510", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.59375, "CSR": 0.625, "EFR": 0.9615384615384616, "Overall": 0.7932692307692308}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "radiant energy of \"invisible\" kinds", "arms", "two independent mechanisms", "minor", "Fringe or splinter", "17", "lower", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "Dallas, Texas", "Han Chinese and Khitans", "bought prints for broadcast, or by private individuals who acquired them by various means", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "imp My Ride", "Don Johnson", "Good Kid, M.A.D City", "25 million", "8,515", "13 October 1958", "Avro Vulcan", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Ai-Ling Lee", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham, Greater London, England", "A55", "Ranulf de Gernon", "Olaf Guthfrithson", "West Tambaram", "44", "NCAA's Division I", "Harriet Tubman", "Crawley Town", "Dragon TV", "Greek-American", "diastema", "Alison Krauss", "Iran", "Bigfoot", "Papua New Guinea", "Renoir\u00b4s", "Manchester"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7001736111111111}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-3391", "mrqa_squad-validation-1501", "mrqa_squad-validation-3405", "mrqa_squad-validation-9859", "mrqa_squad-validation-8356", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-5165", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-1423"], "SR": 0.609375, "CSR": 0.6232638888888888, "EFR": 1.0, "Overall": 0.8116319444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["$159 million", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules, which have paired electron spins; this prevents spontaneous combustion", "Edict of Fontainebleau", "Museum of the Moving Image in London", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "force and violence and refusal to submit to arrest", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin,", "a pivotal event in the Arab Muslim world", "transgender teenage girl", "John Alexander", "David Michael Bautista Jr.", "Thanksgiving Day", "American actor", "Prince Amedeo", "Lambic", "the port of Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "U.S. states of Kentucky, Virginia, and Tennessee", "Disneyland Monorail, and the Motor Boat Cruise", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marco Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "500 ft", "Central Park", "Robert John Day", "Tifinagh", "James Tinling", "Italy", "79th Masters Tournament", "vocalist Kristoffer Rygg", "Sullivan University", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "couscous", "1.5 million", "morphine sulfate", "renoir", "renoir"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6283961993888465}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, true, true, false, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.88, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7173", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4624", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-1061", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.546875, "CSR": 0.615625, "EFR": 0.9310344827586207, "Overall": 0.7733297413793103}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "Timucuan Ecological and Historic Preserve", "Tesco store", "vertebrates", "Because of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Owen Daniels", "Anderson", "other greater inequality and potential economic instability", "Gamal Abdul Nasser", "immune responses beginning to decline at around 50 years of age due to immunosenescence", "counterflow", "John B. Goodenough, mathematician and Fields Medal recipient Paul Joseph Cohen, and geochemist Clair Cameron Patterson", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and the Daleks", "he was profoundly influenced by a math teacher Martin Sekuli\u0107.:32 The classes were held in German, as it was a school within the Austro-Hungarian Military Frontier", "a Standard Model", "Tolui", "Rhine-Ruhr region", "pedagogy", "It is that power which enables us to love and motivates us to seek a relationship with God through Jesus Christ", "Kansas State 52\u201321", "Gladstone Region, Queensland, Australia", "James T. Kirk", "Yoo Seung-ho", "the Battle of the Philippines", "NCAA Division I", "The satirical news Network", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Naruto", "Tom Jones", "Russell Humphreys", "Barbara Niven (born February 26, 1953)", "13\u20133", "Eliot Spitzer", "5,042", "European culture", "Texas Instruments (TI)", "Tianhe Stadium", "1952", "the fourth Thursday", "William Shakespeare", "Germany", "New Jersey", "Bath, 1820", "Ector County, Texas, United States", "Jim Davis", "Buck Owens", "the World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana and South Africa", "Heather Stebbins", "Caviar", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "the Comoros Islands off Africa", "Onomastic Sobriquets In The Food And Beverage Industry", "the bin"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5784895202843872}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.0, 0.08, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.5, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.9600000000000001, 0.0, 1.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7269", "mrqa_squad-validation-5010", "mrqa_squad-validation-2032", "mrqa_squad-validation-940", "mrqa_squad-validation-7502", "mrqa_squad-validation-6495", "mrqa_squad-validation-8072", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_squad-validation-9803", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3072", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_hotpotqa-validation-1036", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-7415", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.46875, "CSR": 0.6022727272727273, "EFR": 1.0, "Overall": 0.8011363636363636}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "to pressure the lazy, inspire the bored, deflate the cocky", "Battle of Olustee", "French", "100\u2013150", "Philo of Byzantium", "The climate is cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "second oil shock", "cytotoxic natural killer cells", "violence", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh and a small number of trains extended to Glasgow, Aberdeen and Inverness", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "$700 billion", "a planned training exercise designed to help the prince learn to fly in combat situations", "U.S. 93", "on the Ohio River near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "he still is involved with the talks, and that the power-sharing deal with the MDC offshoot is part of larger deal that has not been signed by anyone", "there's no evidence as to the cause of death,", "200", "a very small number of young people taking drugs", "a \"prostitute\" and threatening to oust another from his country.", "Missouri", "the case is closed", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a 'frat house for geeks'", "her home", "the Employee Free Choice act", "Bush administration", "a day after near-simultaneous bomb attacks in the ancient Indian city killed at least 63 people and wounded more than 200", "This is not a project for commercial gain", "their own", "Kaka", "Japanese ex-wife", "U.S. filmmakers", "near Fort Bragg in North Carolina", "two", "$2 billion", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "the singer", "Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 ), a French physician", "The truth was, that as she now stood excited, wild, and honest as the day", "Richmond", "1994", "The Conjuring", "the Gallipoli Campaign", "a large bay that protrudes northeast from Lake Huron into Ontario, Canada", "Nowhere Boy"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5887547676610176}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8666666666666666, 0.0, 0.5, 0.4, 1.0, 0.0, 0.16216216216216217, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 0.15384615384615383, 0.8, 1.0, 0.0, 0.2727272727272727, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1919", "mrqa_squad-validation-3087", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-3637", "mrqa_squad-validation-6588", "mrqa_squad-validation-5287", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.4375, "CSR": 0.5885416666666667, "EFR": 1.0, "Overall": 0.7942708333333334}, {"timecode": 12, "before_eval_results": {"predictions": ["ignored the warning.", "more wealth than half of all Americans combined.", "every good work designed to attract God's favor", "Napoleon", "mass production", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation,", "1227", "lower lake", "three", "Elders", "587,000 square kilometres", "Private Bill Committees", "Mark Ronson", "the Catechism", "Stagg Field", "Ian Botham", "E. T. A. Hoffmann", "Vincent Motorcycle Company", "Frenchie", "C\u00e9sar Mendoza", "Harold Pinter", "Hawaii", "Jens Stoltenberg", "Apollon", "Pal Joey", "Mary Seacole", "green", "Indonesia", "Jesus", "Antonio Stradivari", "The EU", "Christine Keeler", "Hell", "Nicholson", "four", "Germany", "Sugar Baby Love", "Rosa Parks Bus", "Sean", "John Denver", "Stage 1", "Travis", "The Show", "Robert Kennedy", "Q is the only letter in the alphabet that does not appear in the name of any of the United States.", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "a French author", "barber", "Rod Laver", "Murrah Federal Office Building", "Evita", "oldpatricktoe-end", "a fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Duchess Eleanor of Aquitaine", "Gilley's Club", "hardly ever", "a delegation of American Muslim and Christian leaders", "bath & his own son", "University of South Carolina", "Juan Martin Del Potro."], "metric_results": {"EM": 0.421875, "QA-F1": 0.49055059523809524}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, false, true, true], "QA-F1": [0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.1111111111111111, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10141", "mrqa_squad-validation-7458", "mrqa_squad-validation-2262", "mrqa_squad-validation-7974", "mrqa_squad-validation-4257", "mrqa_squad-validation-9418", "mrqa_squad-validation-670", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6727", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-7367", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120"], "SR": 0.421875, "CSR": 0.5757211538461539, "EFR": 0.9459459459459459, "Overall": 0.7608335498960499}, {"timecode": 13, "before_eval_results": {"predictions": ["Cram\u00e9r", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "anton", "moles", "phoebus", "Diego Garcia", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "salvador tatum", "one", "komando Pasukan Khusus", "the county in the northwest of England", "carbon dioxide", "zanesville", "julius Connors", "Antarctica", "julius gilding", "aniridia", "t.S. Eliot", "River Forth", "woe", "spider-Man", "julius", "salvador Mussolini", "Canada", "typhoid fever", "lady antonada", "salvador", "al Bundy", "2010", "einasto", "Venezuela", "fred stooge", "aaron", "40", "phrenology", "San Francisco", "Fall 1998", "Xanthippus", "Christopher James \" Chris Weidman", "Drillers Stadium", "one", "Cathay Pacific Airways", "julius phelan", "Administrative Professionals Day", "Iran", "Group E winners AS Roma in the last 32 of Europe's second-tier club competition."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5020833333333333}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8994", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_hotpotqa-validation-1390", "mrqa_newsqa-validation-605", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-49", "mrqa_newsqa-validation-2281"], "SR": 0.46875, "CSR": 0.5680803571428572, "EFR": 1.0, "Overall": 0.7840401785714286}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically bonded to each other", "Aristotle", "St. George's Church", "Matt Smith", "the General Assembly Hall of the Church of Scotland on the Royal Mile in Edinburgh", "private citizen", "the most cost efficient bidder", "kung fu grip", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "Olympia", "kung fu grip", "gaius caesar augustus thumpadori", "gaius caesar augustus germanicus", "kung fu grip", "amber", "andrew johnson", "The executioner's Song", "gaius caesar augustus germanicus", "kung fu grip", "anamosa's famous artist", "andrew johnson", "The Comedy of Errors", "gaius caesar kung fu grip", "gaius caesar", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "Cologne", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "Kosovo", "andrew johnson", "Paris", "tennis", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "andrew johnson", "gaius caesar augustus germanicus", "kung fu grip", "kung fu grip", "kung fu grip", "boogity", "gaius caesar germanicus", "andrew johnson", "gaius caesar augustus germanicus", "Augusta", "clockwise", "March 31, 2013", "gaius caesar augustus germanicus", "gaius caesar augustus germanicus", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama's", "goblin's Market", "kuntar"], "metric_results": {"EM": 0.328125, "QA-F1": 0.37916666666666665}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.1, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-3488", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-405", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-14700", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-4647", "mrqa_triviaqa-validation-224", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-3084", "mrqa_newsqa-validation-1406"], "SR": 0.328125, "CSR": 0.5520833333333333, "EFR": 1.0, "Overall": 0.7760416666666666}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling", "around 28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "Deabolis", "April 20", "the Gaulish name", "1996", "wine", "Switzerland", "Melbourne", "enter the priesthood", "the Seattle Seahawks", "IBM", "crossword", "Jerry Maguire", "Cleveland", "Flemish", "Mastercard", "General Motors Corporation", "Heinz Field", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "supplementary", "Kurt Russell", "Toronto Maple Leaf", "Zsa Zsa Gabor", "Vladimir Nemirovich-Danchenko", "Utah", "sugarcane", "(Rabbit) Angstrom", "Johann Strauss II", "a fox", "pro bono", "Italy", "one", "a brown beer", "Anthony Fokker", "Nacho Libre", "copper", "black magic or of dealings with the devil", "the hemlock", "Jeffrey Wigand", "poetry", "lettuce", "supplementary", "Casablanca", "supplementary", "the Bunsen burner", "a Geiko", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "Brandon Jennings", "a tin star", "noir", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.484375, "QA-F1": 0.575}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7041", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-10571", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-12729", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-5713", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.484375, "CSR": 0.5478515625, "EFR": 1.0, "Overall": 0.77392578125}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "gaseous", "1997", "late 1920s", "\u00a34.2bn", "27 July 2008", "unequal", "October 1973", "military troops", "Isiah Bowman", "an assembly center", "Ominde Commission", "the Weser", "Eva Peron", "Ho Chi Minh", "circum", "the Inuit", "Detroit", "the (Montreal) Blue Jays", "Walt Whitman", "Ray Bradbury", "hate crimes", "Madagascar", "Nicolas Sarkozy", "Rubicon", "(Roger) Costello", "Six Flags", "(Louisa) May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The two went and stood side by side before a great mirror", "Crystal Pepsi", "Hillary Clinton", "King Philip", "(Roger) Bellerophon", "Balaam", "Wharton", "The Caine Mutiny", "100 Greatest Guitarists", "Biggly Wiggly supermarkets", "(John) Coltrane", "peace symbol", "oxygen", "the Sphinx", "Jan Hus", "Cowboy Troy", "the Mavericks", "Onegin", "Macy's", "a spinning machine", "Santa Claus", "(Roger) Antony", "a nurse", "the United Kingdom", "another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "(Cesar) Duarte", "( Brad) Blauser", "his salary", "the punishment"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5956330128205127}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-3785", "mrqa_squad-validation-1796", "mrqa_squad-validation-3132", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-15912", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-1759"], "SR": 0.515625, "CSR": 0.5459558823529411, "EFR": 0.967741935483871, "Overall": 0.7568489089184061}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "Curia Maior", "Stratigraphers", "trade unions", "94.1", "earn as much as a healthy young man;", "Centrum", "Robert Lane and Benjamin Vail", "Swezey", "the Orange Democratic Movement", "22", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "The Crystal Method", "Puerto Rico", "The Mausoleum", "Million Dollar Baby", "preston", "The Viscounts", "The Old Man and the Sea", "French", "Joe Louis", "the lion", "The Three Musketeers", "the Bayeux Tapestry", "Porch", "Inner Mongolia", "Sunni", "notes", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "A Streetcar Named Desire", "Quilt", "FRAM", "the House of Representatives", "Blue", "Michael Moore", "Oman", "Chevy", "Ingenue", "Lake Erie", "El burlador de Sevilla", "Ian Fleming", "Headless Horseman", "preston", "Yellowstone", "Ronald Reagan", "Fiddler on the Roof", "Ethiopian", "six 50 minute", "the Boomerang soundtrack", "preston", "Bromley", "the Ruul", "Courage the Cowardly Dog", "a small child", "the Challenger", "\"Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "a nuclear weapon", "\"Three Little Beers,\""], "metric_results": {"EM": 0.53125, "QA-F1": 0.5736019736842105}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2105263157894737, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-990", "mrqa_squad-validation-7273", "mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_squad-validation-8420", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-14282", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7227", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-5971", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-7811", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-3449", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-4110"], "SR": 0.53125, "CSR": 0.5451388888888888, "EFR": 1.0, "Overall": 0.7725694444444444}, {"timecode": 18, "before_eval_results": {"predictions": ["matching white pants", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity", "same-gender marriages", "2006", "the mid-18th century", "orange", "A Raisin in the Sun", "Moses", "White Russia", "a flanker", "a trowel", "\"Big Bang\"", "the Monkees", "endodontist", "a bathtub", "Denmark", "Genoa", "Fanchette", "Jersey Boys", "a door", "Kansas", "Jaclyn Day", "six", "rice", "21", "the Civil", "Copeina arnoldi", "Paul McCartney", "omega-6", "\"Disputa\"", "TCOB", "horror", "Bill Murray", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "riverrun", "Wordsworth", "Norway", "Bear", "a tremors", "Judas", "an elephant", "Mazurek Dbrowskiego", "Sweden", "a covert operation", "\"All for Our Country\"", "May 2010", "Camp David", "a bay", "Thailand", "gender queer", "Minister for Social Protection", "Elster", "the home", "Robin Williams", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4876132246376811}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, false, true, false, false, true, false, true, false, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-3420", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-11114", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_newsqa-validation-3343", "mrqa_naturalquestions-validation-2870"], "SR": 0.40625, "CSR": 0.537828947368421, "EFR": 0.9736842105263158, "Overall": 0.7557565789473684}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified", "Mars", "53,000", "one", "Israeli poet", "two", "20,000", "kip", "in skeletal muscle and the brain", "2014", "two peptide bonds", "the Ottawa Senators 7 - 4", "Saturday", "a zygote with n pairs of chromosomes", "volcanic activity", "Montgomery", "a speakeasy", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "mindfulness", "Charlene Holt", "Captain Leland Stottlemeyer", "1991", "electron shells", "The Cornett family", "acid rain", "October 22, 2017", "unattainable", "he cheated on Miley", "2001", "democracy", "735 feet", "1871", "Lex Luger", "Toledo, Bowling Green, and Mount Union", "business network", "a cladding of a different glass, or plastic", "Abraham Gottlob Werner", "in Wakanda and the Savage Land", "unfair", "Necator americanus and Ancylostoma duodenale", "February 28 or March 1", "the Middle East", "the American Civil War", "an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "she eventually marry", "British and French Canadian fur traders", "semi-autonomous", "Lou Rawls", "Hermia", "Jupiter", "Europe", "15", "John Robert Cocker", "Israel", "video game", "a palace", "olfactory", "Eucalyptus", "a lionish mane", "oxygen"], "metric_results": {"EM": 0.390625, "QA-F1": 0.545220455606485}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.4, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.2857142857142857, 0.6666666666666666, 0.4705882352941177, 0.0, 0.1818181818181818, 0.0909090909090909, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.19999999999999998, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_squad-validation-3581", "mrqa_squad-validation-880", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-1502", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-8339", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-2379", "mrqa_searchqa-validation-12372", "mrqa_triviaqa-validation-2227"], "SR": 0.390625, "CSR": 0.53046875, "EFR": 0.9743589743589743, "Overall": 0.7524138621794871}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "Cloth of St Gereon", "Thomas Sowell", "more than 70 pioneers in science and engineering, including Albert Einstein", "celibacy", "His Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\"", "Jacob Zuma", "gang rape", "Florida", "7,000", "Wednesday", "201-2800", "different women coping with breast cancer", "1,000 pounds", "\"no need to fight the oppression of the former Mubarak regime.\"", "Saadi", "Texas", "Polo", "\"The Jacksons: A Family Dynasty\"", "Amstetten", "computer problems left travelers across the United States waiting in airports", "Silvan Shalom", "Jonathan Breeze", "Steve Jobs", "12-hour", "prisoners", "September", "consumer confidence", "5:20 p.m.", "North vs. South", "India", "1964", "Davidson", "Swat Valley", "month of three people with ties to the U.S. Consulate in Ciudad Juarez", "1979", "Kim Jong Il", "The Tom Joyner Morning Show", "Akio Toyoda", "\"There's no chance of it being open on time. Work has basically stopped.\"", "the immediate release into the United States of 17 Chinese Muslims", "Frank Rijkaard's squad.", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "adoption", "40", "\"Friday the 13th\"", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter festivals", "Pentecost", "Aberdeen", "\"Dumb and Dumber\"", "The Tigers", "Chief Justice Earl Warren", "a converging lens", "Etruscan root autu", "season six", "The Force Wars film in 1977"], "metric_results": {"EM": 0.375, "QA-F1": 0.48381028693528694}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.6153846153846153, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.923076923076923, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.2666666666666667, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 0.20000000000000004]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_squad-validation-2757", "mrqa_squad-validation-2466", "mrqa_squad-validation-7937", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-526", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-2383", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-209", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-3209", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.375, "CSR": 0.5230654761904762, "EFR": 1.0, "Overall": 0.7615327380952381}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers", "San Diego-Carlsbad-San Marcos metropolitan area", "chief electrician position", "Newton", "the applied force is opposed by static friction, generated between the object and the table surface", "death of US President John F. Kennedy", "\"a common enemy to both countries.\"", "Winter Park at Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Awearness Fund", "on his land.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"mentally deranged person steeped in the inveterate enmity towards the system\" in the North.", "\"The View\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers program", "\"I'm certainly not nearly as good of a speaker as he is.\"", "9:20 p.m. ET Wednesday.", "Venus Williams", "Mashhad, Iran.", "Amanda Knox", "\"Mexican Venice,\"", "more than $17,000", "Barney Stinson,", "Luiz Inacio Lula da Silva", "father's parenting skills.", "two contestants.", "Bill,", "J.G. Ballard", "doctors", "Sarah,", "choosing for retirement long before his career neared its end.", "October 6, 1981", "\"17 Again,\"", "Nigeria", "$81,88010.", "Republicans", "EU naval force", "Allison Bridges", "son of Gabon's former president", "last running steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "skeletal dysplasia,", "London Heathrow's Terminal 5.", "strongly denied charges of racism after his club canceled the swimming privileges of a nearby day care center whose children are predominantly African-American.", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military action", "the First Family", "Cliff's father, Russell Huxtable", "Willy Russell", "London", "\"Mortal Kombat X\"", "Northumbrian", "Ophelia", "Romania", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto Eduard Leopold"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5639399662837162}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.25, 0.8, 1.0, 0.2666666666666667, 0.15384615384615383, 0.0, 0.4, 1.0, 0.0, 0.0, 0.5454545454545454, 0.42857142857142855, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.5, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-1285", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-4038", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1949", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-913", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-4584", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-107"], "SR": 0.40625, "CSR": 0.5177556818181819, "EFR": 0.9736842105263158, "Overall": 0.7457199461722488}, {"timecode": 22, "before_eval_results": {"predictions": ["Tesla devised several experimental devils to produce X-rays.", "WMO Executive Council and UNEP Governing Council", "northern and southern Germans", "New York and Virginia", "two", "glowed even when turned off.", "a number of celebrities and ministers,", "scientists know about Earth's closest neighbor.", "sovereignty over them.", "April 6, 1994", "Prague", "backbreaking labor,", "a federal judge in Mississippi", "\"is responsible for security on the streets,", "$22 million", "severe flooding", "music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewife of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Sachina Verma", "Larry King", "Steven Chu", "racially motivated.", "Marines", "male veterans", "longest domestic torch relay", "Harare.", "No. 1 slot", "four", "four bodies", "Friday,", "to be over a kilometer (3,281 feet) high.", "Rima Fakih", "Tuesday night", "CIA interrogators", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "brain signals", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning about tendon problems.", "84-year-old", "Kim Jong Il.", "Fakih", "paris", "Nalini Negi", "2017 - 12 - 10 )", "Runcorn", "paris", "paris", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "The Cricket on the Hearth"], "metric_results": {"EM": 0.375, "QA-F1": 0.5179125280268183}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.3333333333333333, 0.22222222222222224, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.5, 0.19999999999999998, 0.23529411764705882, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 0.75, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-88", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1109", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-3239", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.375, "CSR": 0.5115489130434783, "EFR": 1.0, "Overall": 0.7557744565217391}, {"timecode": 23, "before_eval_results": {"predictions": ["chlorophyll a and phycobilins", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma.", "19,600", "in Yemen,", "2005.", "Karen Floyd", "Four Americans", "the missing person,", "Haiti", "Susan Boyle", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Omar bin Laden", "Jared Polis", "Janet and La Toya,", "Hyundai Steel", "30", "Michael Krane,", "lightning strikes", "Evans", "Sabina Guzzanti", "the flooding was so fast that the thing flipped over,\"", "threatening messages", "Christopher Savoie", "drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "\"in the interest of justice.\"", "\"Kambakkht Ishq,\"", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Anne Frank,", "April", "The alleged surviving attacker from last month's Mumbai terror attacks is seeking help from Pakistani", "Zuma", "oldest documented bikinis -- haute, bandeau-style little numbers", "nine", "al-Maliki", "2000", "50", "15-year-old", "in body bags on the roadway near the bus,", "Trevor Rees and the back of Princess Diana's head", "Desmond Tutu", "$17,000", "Toy Story", "$81,880", "provide school districts with federal funds", "a spiritual conversion", "Jason Lee", "REM sleep", "nounA", "Kent", "beer and soft drinks", "five aerial victories", "Cherokee River", "The U.S. Founders and Cyrus the Great of Persia", "NASA Astronaut", "Florida"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5305071447649573}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.125, 0.0, 0.5, 0.0, 0.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0625, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.4, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_squad-validation-10100", "mrqa_newsqa-validation-968", "mrqa_newsqa-validation-1493", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-1876", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3039", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.46875, "CSR": 0.509765625, "EFR": 1.0, "Overall": 0.7548828125}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great.", "the Yuan dynasty", "manually suppress the fire.", "compound", "Nigeria", "American Lindsey Vonn", "WTA Tour titles at Strasbourg and Bali prior to Madrid", "him to step down as majority leader.", "United Nations World Food Program", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "his club", "to best your own fuel economy achievements,\"", "1979", "one of its diplomats in northwest Pakistan", "jazz", "an antihistamine and an epinephrine", "Bangladesh,", "Michael Arrington,", "17 children under 3 years old in America", "U.N. High Commissioner for Refugees", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "\"I Dreamed a Dream,\"", "military personnel", "placed behind the counter.", "11", "one", "Michael Partain,", "her fianc\u00e9", "racial intolerance.", "a vegan diet to some of the flavorful foods they can eat.", "Carrillo Leyva", "the self-styled revolutionary Symbionese Liberation Army", "$8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "would compromise the public broadcaster's appearance of impartiality.", "it -- you know -- black is beautiful,\"", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade after a new survey showed how the drug dominates Afghanistan's economy.", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks,", "the coast of Dubai", "military veterans", "two Metro transit trains that crashed the day before,", "eight", "Mark Obama Ndesandjo", "the plus-sized.", "Russia, South Korea, China, South Africa, Brazil, Beirut and Poland.", "\"The Screening Room\"", "adultery,", "the control center of the cell", "Vienna", "a fictional team of Naval Criminal Investigative Service ( NCIS ) agents stationed out of New Orleans, Louisiana and led by Special Agent Dwayne Cassius Pride ( Scott Bakula )", "President Woodrow Wilson", "Tom Watson", "Sandi Toksvig", "The Spyker F1 Team", "prime minister", "Anaheim, California,", "Faxa Bay", "wedlock", "carbon"], "metric_results": {"EM": 0.375, "QA-F1": 0.5144720193341517}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4615384615384615, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.4, 0.11764705882352941, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.3076923076923077, 0.0, 0.05555555555555555, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.7499999999999999, 1.0, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 1.0, 0.08, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.14814814814814814, 0.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8428", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4128", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-970", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-13756"], "SR": 0.375, "CSR": 0.504375, "EFR": 1.0, "Overall": 0.7521875}, {"timecode": 25, "UKR": 0.673828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1027", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1042", "mrqa_hotpotqa-validation-1095", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-1268", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-1781", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-2284", "mrqa_hotpotqa-validation-2315", "mrqa_hotpotqa-validation-2743", "mrqa_hotpotqa-validation-2927", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-305", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-3885", "mrqa_hotpotqa-validation-3952", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-4449", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4548", "mrqa_hotpotqa-validation-4552", "mrqa_hotpotqa-validation-4624", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-4924", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5165", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5227", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-729", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-1653", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-3637", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-467", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5607", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7792", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8638", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-1150", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-1812", "mrqa_newsqa-validation-1873", "mrqa_newsqa-validation-1915", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2036", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-209", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2421", "mrqa_newsqa-validation-2458", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3112", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3146", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3254", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-3634", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-49", "mrqa_newsqa-validation-496", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-729", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-88", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-968", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-105", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-10594", "mrqa_searchqa-validation-10787", "mrqa_searchqa-validation-11481", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-12150", "mrqa_searchqa-validation-12205", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-1272", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-13667", "mrqa_searchqa-validation-13756", "mrqa_searchqa-validation-1396", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-14282", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-14660", "mrqa_searchqa-validation-14700", "mrqa_searchqa-validation-14743", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-15593", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15784", "mrqa_searchqa-validation-15912", "mrqa_searchqa-validation-1706", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-2355", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-3420", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-6335", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6870", "mrqa_searchqa-validation-7227", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7584", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-8335", "mrqa_searchqa-validation-8343", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-858", "mrqa_searchqa-validation-8602", "mrqa_searchqa-validation-87", "mrqa_searchqa-validation-9270", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9991", "mrqa_squad-validation-10026", "mrqa_squad-validation-10026", "mrqa_squad-validation-10100", "mrqa_squad-validation-10254", "mrqa_squad-validation-10406", "mrqa_squad-validation-10418", "mrqa_squad-validation-1146", "mrqa_squad-validation-1166", "mrqa_squad-validation-1187", "mrqa_squad-validation-1218", "mrqa_squad-validation-126", "mrqa_squad-validation-1295", "mrqa_squad-validation-1313", "mrqa_squad-validation-1341", "mrqa_squad-validation-1407", "mrqa_squad-validation-1501", "mrqa_squad-validation-1549", "mrqa_squad-validation-159", "mrqa_squad-validation-1640", "mrqa_squad-validation-1662", "mrqa_squad-validation-1692", "mrqa_squad-validation-1758", "mrqa_squad-validation-1771", "mrqa_squad-validation-1775", "mrqa_squad-validation-1877", "mrqa_squad-validation-1906", "mrqa_squad-validation-1960", "mrqa_squad-validation-2049", "mrqa_squad-validation-2059", "mrqa_squad-validation-2105", "mrqa_squad-validation-2113", "mrqa_squad-validation-2136", "mrqa_squad-validation-2207", "mrqa_squad-validation-2435", "mrqa_squad-validation-2466", "mrqa_squad-validation-2518", "mrqa_squad-validation-2530", "mrqa_squad-validation-281", "mrqa_squad-validation-2833", "mrqa_squad-validation-2858", "mrqa_squad-validation-2941", "mrqa_squad-validation-298", "mrqa_squad-validation-3091", "mrqa_squad-validation-3100", "mrqa_squad-validation-3127", "mrqa_squad-validation-3132", "mrqa_squad-validation-3149", "mrqa_squad-validation-3259", "mrqa_squad-validation-3260", "mrqa_squad-validation-3312", "mrqa_squad-validation-3319", "mrqa_squad-validation-3440", "mrqa_squad-validation-3454", "mrqa_squad-validation-3524", "mrqa_squad-validation-3632", "mrqa_squad-validation-3716", "mrqa_squad-validation-3813", "mrqa_squad-validation-3862", "mrqa_squad-validation-3865", "mrqa_squad-validation-3918", "mrqa_squad-validation-3943", "mrqa_squad-validation-4010", "mrqa_squad-validation-4047", "mrqa_squad-validation-4075", "mrqa_squad-validation-4078", "mrqa_squad-validation-4083", "mrqa_squad-validation-4102", "mrqa_squad-validation-4175", "mrqa_squad-validation-4315", "mrqa_squad-validation-4429", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-457", "mrqa_squad-validation-4673", "mrqa_squad-validation-4706", "mrqa_squad-validation-4770", "mrqa_squad-validation-4775", "mrqa_squad-validation-4844", "mrqa_squad-validation-4973", "mrqa_squad-validation-498", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5023", "mrqa_squad-validation-5037", "mrqa_squad-validation-5102", "mrqa_squad-validation-5135", "mrqa_squad-validation-5178", "mrqa_squad-validation-5194", "mrqa_squad-validation-5213", "mrqa_squad-validation-5226", "mrqa_squad-validation-526", "mrqa_squad-validation-5486", "mrqa_squad-validation-549", "mrqa_squad-validation-5513", "mrqa_squad-validation-5581", "mrqa_squad-validation-5741", "mrqa_squad-validation-5784", "mrqa_squad-validation-5812", "mrqa_squad-validation-5863", "mrqa_squad-validation-5871", "mrqa_squad-validation-5876", "mrqa_squad-validation-5972", "mrqa_squad-validation-6029", "mrqa_squad-validation-6059", "mrqa_squad-validation-6080", "mrqa_squad-validation-6121", "mrqa_squad-validation-6154", "mrqa_squad-validation-6166", "mrqa_squad-validation-6177", "mrqa_squad-validation-6242", "mrqa_squad-validation-6430", "mrqa_squad-validation-6588", "mrqa_squad-validation-6598", "mrqa_squad-validation-6614", "mrqa_squad-validation-6676", "mrqa_squad-validation-6685", "mrqa_squad-validation-6694", "mrqa_squad-validation-6721", "mrqa_squad-validation-6741", "mrqa_squad-validation-6789", "mrqa_squad-validation-6789", "mrqa_squad-validation-6801", "mrqa_squad-validation-6875", "mrqa_squad-validation-6921", "mrqa_squad-validation-7135", "mrqa_squad-validation-7159", "mrqa_squad-validation-716", "mrqa_squad-validation-7173", "mrqa_squad-validation-7229", "mrqa_squad-validation-7273", "mrqa_squad-validation-7434", "mrqa_squad-validation-7458", "mrqa_squad-validation-7576", "mrqa_squad-validation-7596", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-7967", "mrqa_squad-validation-7981", "mrqa_squad-validation-80", "mrqa_squad-validation-8035", "mrqa_squad-validation-8151", "mrqa_squad-validation-8176", "mrqa_squad-validation-8343", "mrqa_squad-validation-8356", "mrqa_squad-validation-8397", "mrqa_squad-validation-8420", "mrqa_squad-validation-8439", "mrqa_squad-validation-8485", "mrqa_squad-validation-8503", "mrqa_squad-validation-855", "mrqa_squad-validation-855", "mrqa_squad-validation-8608", "mrqa_squad-validation-8616", "mrqa_squad-validation-8719", "mrqa_squad-validation-8733", "mrqa_squad-validation-880", "mrqa_squad-validation-880", "mrqa_squad-validation-8833", "mrqa_squad-validation-8896", "mrqa_squad-validation-8896", "mrqa_squad-validation-8896", "mrqa_squad-validation-890", "mrqa_squad-validation-8914", "mrqa_squad-validation-8924", "mrqa_squad-validation-9020", "mrqa_squad-validation-9066", "mrqa_squad-validation-913", "mrqa_squad-validation-9170", "mrqa_squad-validation-9173", "mrqa_squad-validation-9220", "mrqa_squad-validation-9237", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9299", "mrqa_squad-validation-9333", "mrqa_squad-validation-940", "mrqa_squad-validation-9406", "mrqa_squad-validation-9436", "mrqa_squad-validation-9470", "mrqa_squad-validation-9559", "mrqa_squad-validation-962", "mrqa_squad-validation-9665", "mrqa_squad-validation-9686", "mrqa_squad-validation-9752", "mrqa_squad-validation-9753", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_squad-validation-9931", "mrqa_squad-validation-9960", "mrqa_triviaqa-validation-1198", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1616", "mrqa_triviaqa-validation-1644", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-2029", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-2227", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2522", "mrqa_triviaqa-validation-2794", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-316", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-339", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-4315", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-4945", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5964", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6753", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-7367", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-980"], "OKR": 0.853515625, "KG": 0.43828125, "before_eval_results": {"predictions": ["\"theo-democracy,\"", "Treaty of Logstown", "Mario Addison", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale", "Anthony Hopkins", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "phylum Arthropoda", "jimmy carter", "Ub Iwerks", "England Cathedrals", "holography", "Pelias", "Daniel Boaventura", "Northumbria", "Yale", "cricket", "Seymour Hersh,", "quant", "copper and zinc", "the Tigris River", "Cordelia", "many kinds of publications that told both news and rumours.", "jimmy carter", "33", "Rh\u00f4ne Grape Varietal", "Joseph Smith", "Huntington Beach, California", "gold", "the moon", "13.", "jimmy carter", "The Apartment", "Canada", "Winston Churchill", "Stockholm", "Spider-Man", "Golda Meir", "Rodd & Gunn,", "bullfight", "\"The Number One Song in Heaven\"", "Ginger Rogers", "Plymouth Rock", "Comedy Playhouse", "citric", "Charles Darwin", "Denver", "I run a specialized hotel and a telephone service which provides gentlemen with the company of a young lady,", "Marie Van Brittan Brown", "southern California", "1995", "Bourbon County", "Taylor Swift", "Rihanna", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "The Detroit, Michigan,", "Amy Bishop,", "calastrally", "the Louvre", "7300"], "metric_results": {"EM": 0.421875, "QA-F1": 0.47202818627450976}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.8, 0.9, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.1764705882352941, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9661", "mrqa_squad-validation-825", "mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-6456", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-7678", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-6038", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-7521", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.421875, "CSR": 0.5012019230769231, "EFR": 0.972972972972973, "Overall": 0.6879599792099793}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\"", "third", "affordable housing", "Mao Zedong", "Verona", "Detroit stadium", "elephants", "charcoal powered grill", "Frank McCourt", "jules Verne", "jonathan parker", "harvard", "Schengen Area", "red", "city of Louisiana", "radioactive Players-Lasky Corporation", "Gary Puckett", "john denver", "Jezebel", "Ireland", "jason", "Arab", "Halifax", "noises Off", "jonathan parker", "Frank Wilson", "canterbury", "Edwina Currie", "tina Lipinski", "clement park", "1768", "\u201cacts of the greatest bravery or of the most conspicuous courage in circumstances of extreme danger.", "woe", "peninsula", "Montgomery", "The Good Life", "Tahrir Square", "plutonium", "d'Artagnan", "27", "Jack Ruby", "tintoretto", "jonathan Coates", "Saudi Arabia", "Lester", "Thailand", "Sydney", "a dove", "Tunisia", "Prince Philip", "england", "Tokyo", "Edgar Lungu", "49 cents", "over 100 beats per minute", "672", "\"Linda McCartney's Life in Photography\"", "Franconia,", "bard", "Juan Martin Del Potro", "27,", "pym of nantucket", "Richard johnson", "Buddhism"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-7240", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829", "mrqa_searchqa-validation-3602"], "SR": 0.4375, "CSR": 0.49884259259259256, "EFR": 1.0, "Overall": 0.6928935185185185}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80 percent", "more than 70", "showed little interest in Tesla's ideas for new types of motors and electrical transmission equipment", "Benazir Bhutto", "nuclear program", "Awa", "Yoko Ono Starr", "Daniel Cain", "acid", "Wally", "1993", "after Wood went missing off Catalina Island,", "mrs fakih", "Afghanistan", "south of the everglades", "dilshan scored his sixth Test century of a remarkable year to give Sri Lanka a fine start to the third match of their series against India", "the 1950s", "64,", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos", "about $4.5 million", "unwanted baggage from the 80s", "carbon neutral", "oaxaca", "Orbiting Carbon Observatory", "Switzerland", "Kenneth Cole", "Janet and La Toya", "more than 22 million people in sub-Saharan Africa", "approximately 35 million passengers a year.", "combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "his injuries,", "dadaab", "booked on an outstanding arrest warrant relating to a domestic violence case,", "sustain future exploration of the moon and beyond.", "his business dealings", "Opry Mills", "#1", "attempting illegal crossings", "producers can't be ready in time for the July debut,", "dadaab", "louis armstrong", "should have met with the Dalai Lama.", "The oceans", "burned", "a nurse", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "December 23, 1942", "1925", "gilda", "jeremy wilson", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "d.W. Griffith", "black"], "metric_results": {"EM": 0.359375, "QA-F1": 0.46716477966477965}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.22222222222222224, 0.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1302", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2233", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2051", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-2229", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-2976", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.359375, "CSR": 0.4938616071428571, "EFR": 1.0, "Overall": 0.6918973214285715}, {"timecode": 28, "before_eval_results": {"predictions": ["a high enough quality to host a Super Bowl", "25-foot", "manipulates symbols", "Hyundai", "Monday night", "Florida to Colorado", "kidnapping the children and concealing their identities.", "40", "brutalized by the Catholic Church in the 1600s", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "World-renowned security expert Gavin de Becker", "a nuclear weapon", "Japan", "Arizona", "in the Intertropical Convergence Zone", "simple puzzle video", "outside influences", "aid to Gaza,", "two people and injuring more than a dozen,", "suppress the memories and to live as normal a life", "February 2008", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "UH-60 Blackhawk helicopters collided in northeastern Baghdad as a result of clashes between U.S.-backed Iraqi forces and gunmen.", "Lucky Dube, one of South Africa's most famous musicians, was killed in an attempted car-jacking", "Cash for Clunkers program", "Oregon Fire Lines", "\"Oprah: A Biography,\"", "80 percent of the woman's face", "London", "to try to make life a little easier for these families by organizing the distribution of wheelchairs,", "Ozzy Osbourne", "$50 less,", "Australian officials", "the iconic Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "38", "Argentine", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "\"17 Again,\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "Two UH-60 Blackhawk helicopters collided Saturday night while landing in northern Baghdad,", "Rima Fakih", "Old Trafford", "to `` help bring creative projects to life ''", "first season of NCIS", "Mary Elizabeth Patterson", "melodic lines", "The Fifth Amendment", "Nepal", "Merck and Co", "Fort Orange", "Knoxville, Tennessee", "Jawaharlal Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5502252675233619}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.15384615384615383, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13793103448275862, 0.6666666666666666, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-445", "mrqa_squad-validation-1789", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1178", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-2380", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-9595", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-7116", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_hotpotqa-validation-2284", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.390625, "CSR": 0.49030172413793105, "EFR": 0.9743589743589743, "Overall": 0.6860571396993811}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "oxygen", "Betty Meggers", "priests and virgins", "primarily in Polk County, Florida", "reproductive system", "the commander of the 1st Army", "near the end of their main sequence lifetime", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "in the central plains", "al - Mamlakah al -", "Southport, North Carolina", "ancient Mesopotamia", "free up disk space", "July 4, 1776", "`` kind of a'pick yourself up and dust yourself off and keep going ', female - empowerment song ''", "Ann Doran", "to cross the world's oceans for centuries", "October 12, 1979", "Lorazepam", "on the 2013 non-fiction book of the same name by David Finkel", "`` steal '' a Cadillac by way of using their assembly line jobs to obtain the parts via salami sliced", "Shakur and `` Brenda ''", "a ranking used in combat sports,", "Husrev Pasha", "Stephanie Judith Tanner", "the palmar aspect of these fingers", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii", "`` Rightly Guided Caliphs", "with a meticulous attention to detail", "a decorative ornament", "September 6, 2019", "single state in its entirety", "substitute goods or substitutes", "Marries Betty", "over 74", "1987", "cunnilingus", "October 2000", "on the 1997 book of the same name by Candace Bushnell", "Prafulla Chandra Ghosh of the Indian National Congress", "a sudden and general loss of confidence in the economic future", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "people in the 20th century who used obscure languages as a means of secret communication during wartime", "Donny Osmond", "Carthage", "\"George Bush Sr.\"", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday", "Rickey Henderson", "lake Baikal", "\"Harold & Kumar Go to White Castle\""], "metric_results": {"EM": 0.28125, "QA-F1": 0.4571951353871677}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.1111111111111111, 0.5, 0.0, 0.5, 0.4, 0.8, 0.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.8484848484848485, 1.0, 0.1739130434782609, 0.4, 0.0, 0.0, 0.11764705882352941, 0.0, 0.3846153846153846, 1.0, 0.0, 0.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.13333333333333336, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.1818181818181818, 0.0, 1.0, 1.0, 0.19354838709677422, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.2857142857142857]}}, "before_error_ids": ["mrqa_squad-validation-3937", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-7880", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.28125, "CSR": 0.4833333333333333, "EFR": 0.9565217391304348, "Overall": 0.6810960144927536}, {"timecode": 30, "before_eval_results": {"predictions": ["a setup phase in each involved node before any packet is transferred to establish the parameters of communication", "Pleurobrachia, Beroe and Mnemiopsis", "1953", "AT&T", "the first settlers of a region pioneers.", "the Delaware nation", "shoes", "on the third day before the November Kalends = 30 October", "Rashid Akmaev,", "acetylene", "an illegal substance", "fiber", "a fox's primary enemies are large predators including eagles, large owls", "a name", "Winston Rodney", "sand", "Nanjing", "Montana", "the Holy Grail", "the Sun King", "GILBERT & SULLIVAN", "The Online Dolly Parton Newsmagazine", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "Florence Henderson", "Frida Kahlo", "the sixth President of the United States", "Jeopary Questions", "\"Fat man, you shoot a great game of pool.\"", "Hair", "the Hearst newspaper chain", "the crustal rocks", "ale", "hominids", "the first female telephone operator", "Year 3000", "Casey Jones", "The New Colossus", "the bee stung.", "Wagner", "Princess Beatrice of York", "the Graduate", "the middleweight champion", "bronchoconstriction", "four", "mercury vapor", "the Sangamon River", "Le Mans", "Earl Long", "Neil Patrick Harris", "Greg and Rodrick's younger brother", "1999", "vitamin D", "three", "Juantorena", "R&B vocal group", "Awake", "Doctor of Philosophy", "Pakistan's", "in Seoul.", "Sonia Sotomayor"], "metric_results": {"EM": 0.34375, "QA-F1": 0.41299994778613197}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, false], "QA-F1": [0.052631578947368425, 0.4, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.5, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-4455", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-11243", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-3579", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-282", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-2436", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.34375, "CSR": 0.47883064516129037, "EFR": 1.0, "Overall": 0.6888911290322581}, {"timecode": 31, "before_eval_results": {"predictions": ["traditional Mongol shamans", "Prospect Park", "the cornea", "a volume", "a squint", "Breakfast at Tiffany", "Diners' Club", "Christian Dior", "The Pittsburgh Cycle", "Romeo", "Notre Dame", "a huge tourist attraction", "Peter Piper", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "monosodium glutamate", "a stella", "mulberry", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Prince William", "Ugly Betty", "an R", "a crossword puzzle", "New Jersey", "the Elbow River", "Matthew Perry", "Tracy Turnblad", "John Ford", "kismet", "Willy Wonka", "a battery", "aluminum", "General McClellan", "Ned Kelly", "a piles of papers", "a gravitational force", "Isis", "a quiver", "Heroes", "the ark of the covenant", "a kidney into a patient with end - stage renal disease", "seven", "Max Planck", "Rocky Marciano", "Stevie Wonder", "Ludwig van Beethoven", "in Omaha, Nebraska", "Michelle Peralta", "two years,", "Arsene Wenger", "as time goes on, it kind of becomes more and more of a phenomenon."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6505208333333333}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8204", "mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-12751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-16714", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_hotpotqa-validation-453", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-2123"], "SR": 0.578125, "CSR": 0.48193359375, "EFR": 1.0, "Overall": 0.6895117187500001}, {"timecode": 32, "before_eval_results": {"predictions": ["no overall increase in weight when tin and air were heated in a closed container", "Fresno Street and Thorne Ave", "Black Death", "Elton John", "John Stuart Mill", "Define Oblivion", "CIA", "piano", "Rickey Henderson", "Sirimavo Bandaranaike", "Grilled Cheese", "John Grunsfeld", "Angkor Wat", "Canada", "Matteo Pericoli", "a quarks", "The Thomas Berryman", "Giuliani", "the Firsts", "Virginia", "Thor", "Pennsylvania", "The Omega Man", "a pantry", "a pupil", "the Summer Olympics", "Caldera", "Shamir", "Hinduism", "tin", "Dirty Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Aidan Quinn", "Tiger Woods", "Los Angeles", "the east wind", "Richard III", "Labour Party", "the pen", "Kansas", "Douglas Adams", "Hrik Ibsen", "Hawaii", "Herbert Waring", "Russia", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "in 15 parks across the five boroughs", "Lewis Carroll", "Part 1", "Coconut Cove", "a piano", "trumpet", "Mel Gibson", "2.1 million", "William Adama", "Lynyrd Skynyrd", "Omar Bongo,", "Graeme Smith", "Ignazio La Russa"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5620140775966183}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, false, true, false, true], "QA-F1": [0.43750000000000006, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.08695652173913042, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-1755", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-5516", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-15655", "mrqa_searchqa-validation-8063", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-4767", "mrqa_newsqa-validation-4090"], "SR": 0.484375, "CSR": 0.4820075757575758, "EFR": 1.0, "Overall": 0.6895265151515152}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "immunity and the self/nonself vocabulary", "a pool of blood beneath his head.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "he regret describing her as \"wacko.\"", "Saturday", "Saddam Hussein\\'s Revolutionary Command Council", "drugs", "the Dalai Lama", "Ma Khin Khin Leh,", "the station", "Hundreds of women protest child trafficking and shout anti-French slogans", "a fake pilot's license,", "Jacksonville, Arkansas", "Cash for Clunkers", "environmental", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship", "different women coping with breast cancer in", "a missile strike or confrontation between the two countries at sea.", "Police", "a cancer-causing toxic chemical.", "Roger Federer", "Brooklyn, New York,", "100 meter", "CNN", "no chance", "Joseph Maraachli", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "in the end of the month", "two", "William Shakespeare", "Symbionese Liberation Army", "a fracas in a nightclub bar in the north-western of England", "two tickets to Italy on Expedia.", "Colombia", "a softer violet hue", "resources", "1981,", "Los Angeles", "16", "Pope Benedict XVI", "South Africa", "NATO", "$40 and a bread.", "President Thabo Mbeki", "Ming", "King of Great Britain and Ireland", "March 14, 1988", "1919", "Javier Bardem", "Scotland", "a family of Portuguese descent", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "a Chocolate Candies", "the pitch"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5834945436507937}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, false, false, false, true, false, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.6666666666666666, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.2222222222222222, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7999999999999999, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.2, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6585", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-1063", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-2953", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.453125, "CSR": 0.48115808823529416, "EFR": 1.0, "Overall": 0.6893566176470589}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "its rights.", "nearly $2 billion", "Yemen,", "worry about an airline going out of business for one reason or another,", "nearly $2 billion", "is a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spanish Davis Cup hero Fernando Verdasco,", "South African", "children of street cleaners and firefighters.", "Piers Morgan", "$3 billion", "hardship for terminally ill patients and their caregivers,", "Honduran", "Brazil", "three different videos", "violence, food shortages and widespread drought", "Roy", "WBO welterweight title", "a sixth member of a Missouri family", "Amanda Knox's aunt Janet Huff", "trying to save their client from the death penalty", "Demi Moore", "military action in self-defense", "Friday", "a lump in Henry\\'s nether regions was a cancerous tumors.", "20", "Matthew Fisher", "$1.5 million", "Matt Kuchar and Bubba Watson", "40", "a model of sustainability.", "glamour and hedonism", "J. Crew.", "returning combat veterans", "543", "the patient,", "Robert Gates", "Israel", "rural Tennessee.", "in critical condition", "Seoul", "Nicole", "Holding the Olympic medal", "next week.", "Ryan Seacrest", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "James Whitehouse,", "journalists and the flight crew will be freed,", "Gentry Buddhism", "Geoffrey Dyson Palmer", "Stephen Lang", "Dick Van Dyke", "Bokm\u00e5l", "a spirit", "Revengers Tragedy", "1754", "Black Elk Speaks", "New York", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5609211534992786}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, false, false, true, false, true, true, true, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, false, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.0, 0.5, 0.4, 1.0, 0.2, 0.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 0.375, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.5, 0.5714285714285714, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-2628", "mrqa_newsqa-validation-3213", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2038", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-4378", "mrqa_searchqa-validation-16463", "mrqa_searchqa-validation-7879"], "SR": 0.453125, "CSR": 0.4803571428571428, "EFR": 1.0, "Overall": 0.6891964285714286}, {"timecode": 35, "before_eval_results": {"predictions": ["removed some parts which they returned to Earth.", "Border Reiver", "July 4,", "rum", "Nantucket", "Islamic leadership position", "Kentucky.", "Malibu", "Sisyphus", "sound", "Australia", "Ayla.", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "a crab", "Prospero", "Purple", "the Black Sea", "The Battle of the Little Bighorn", "The United Society of Believers in Christ's Second Appearing,", "a bellwether", "Hermeneutics", "a potato chip", "Boxer", "The Spiderwick Chronicles", "Mabel Harding", "Mexico City", "the process of choosing", "the Rose Bowl", "Norman Rockwell", "Jackie Kennedy", "tunacanned light tunais", "Napa Valley", "Eurail France-Spain Pass", "Washington, D.C.", "Atlanta, Georgia", "klezmer", "Japan", "Grease: The Original Soundtrack", "12 men.", "Nancy Pelosi", "journal", "Jupiter", "Sadat", "whipped cream", "Mary Shelley", "50 million", "Volitan Lionfish", "Charlie Sheen", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Seth", "Lou Gehrig", "'procrastination is the thief of time'", "1949", "Aamir Khan", "Dame Edna Everage", "Argentina", "Dismissing the charges,", "antibiotics"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5606060606060606}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false], "QA-F1": [0.5454545454545454, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-15861", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-10498", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-7041", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-5561", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1807"], "SR": 0.484375, "CSR": 0.48046875, "EFR": 1.0, "Overall": 0.68921875}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia State Fossil", "definition", "bullion", "Supernanny", "the Atlantic", "Cincinnati", "a muezzin", "Columbia River", "a Peashooter", "dry ice", "Elihu Root", "Entourage", "eel", "Philadelphia", "MoMA", "the unicorns", "John C. Frmont", "Russia", "The Peabodys", "Hermann Hesse", "the Taj Mahal", "The 2", "Escamillo", "Margaret Mitchell", "La Esmerelda", "Sultans of Swing", "Troilus", "cheerful", "(Burt) Reynolds", "the Sphinx", "Louis Armstrong", "Mecca", "Burning Down the House", "Arby\\'s Restaurant Group", "coffee", "Lgion", "(Robert) Burns", "the Hulk", "Winnipeg Jets", "Memphis Belle", "Burkina Faso", "The First Transcontinental Railroad", "the office of solicitor general", "Icelandic", "a bull", "(Michael) Lewan", "Piaf", "Ivan I", "a narrator summarizes the main action of the work", "clay", "master carpenter Anthony Mayfield", "Jack Gleeson", "The Motown-Philly connection Boyz II Men", "snakes (Kastaridaphobia)", "Massachusetts", "Eastern Bloc", "Charles Laughton", "1987", "Democratic National Convention", "meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.40625, "QA-F1": 0.4830729166666667}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, true, false, false, false, true, false, true, false, false, false, true, false, false, true, false, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-2964", "mrqa_searchqa-validation-10272", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-14918", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-11595", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-14520", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-3131", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-2683", "mrqa_searchqa-validation-9131", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-1409", "mrqa_searchqa-validation-5571", "mrqa_searchqa-validation-14328", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_triviaqa-validation-1125", "mrqa_hotpotqa-validation-2162", "mrqa_hotpotqa-validation-2000", "mrqa_hotpotqa-validation-5726", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-3951"], "SR": 0.40625, "CSR": 0.47846283783783783, "EFR": 1.0, "Overall": 0.6888175675675676}, {"timecode": 37, "before_eval_results": {"predictions": ["Switzerland", "Impressionism", "KFC", "oats", "Mitt Romney", "Ivan the Terrible", "Sally Field", "(Charlie) Lindbergh", "Eritrea", "Pi", "tin", "the Mississippi River", "Clark Griswold\\'s", "a vowel", "Marriott", "French Principality of Monaco", "Canada", "The Secret", "the gold rush", "collagen", "China", "a compound", "a crane", "Jesse James", "Alzheimer", "the Mississippi River", "(Henry)", "Euclid\\'s", "Evita", "Cain", "Lou Grant", "X- men", "the Louvre", "Alaskan", "Prison Break", "Mercury", "Maine", "sheep\\'s", "Meg", "the Sonnets", "one", "Hans Christian Andersen", "Bogdanovich", "Billy Joel", "Jerusalem", "Streis", "the Huronian Ice Age", "nolo contendere", "(Henry) Walker", "Prague", "Chicken of the Sea", "stimulus funds for the WPA", "Chuck Connors", "beta", "France", "Helen", "Mariette", "Ike Barinholtz", "\"Milk\"", "Australian", "the sins of the members of the church,", "$22 million", "\"Hairspray,\"", "Bardstown"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5151041666666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-7541", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-6003", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-2766", "mrqa_searchqa-validation-6358", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-12168", "mrqa_searchqa-validation-6997", "mrqa_naturalquestions-validation-2918", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-1824", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6487", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_newsqa-validation-1527", "mrqa_hotpotqa-validation-5774"], "SR": 0.453125, "CSR": 0.477796052631579, "EFR": 1.0, "Overall": 0.6886842105263158}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden", "Bill Hickok", "Leptospirosis", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "Marimba", "ferry", "Forapple Sarah Marshall", "Witness", "a whitechapel", "3800", "Henry Gibson", "phylum", "Spain", "the brain", "\"I am really sorry and deeply ashamed,\"", "Macbeth", "old comedy", "Mary Poppins", "Casowasco", "The Fresh Prince of Bel-Air", "Abel", "watermelon", "with the bathwater", "a wedding", "Livin", "Sherlock Holmes", "chocolate", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "diagonals", "Flensburg", "Katamari", "Mark Twain", "Margaret Thatcher", "the Philosopher Stone", "pyrolusite", "the Tongass National Forest", "Olympia", "Waylon Jennings", "Doctor Zhivago", "Brazil", "British", "Marlee Matlin", "a copple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "different levels of importance of human psychological and physical needs", "one", "Norfolk Island", "Wright brothers", "jurisdiction", "Sam tick", "Sandro Bondi refused to attend", "voluntary manslaughter", "the need for reconciliation in a country that endured a brutal civil war lasting nearly three decades.", "Pygmalion"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5821180555555555}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1, 1.0, 0.05555555555555555, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6033", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-4043", "mrqa_searchqa-validation-1961", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_searchqa-validation-402", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-600"], "SR": 0.515625, "CSR": 0.47876602564102566, "EFR": 1.0, "Overall": 0.6888782051282052}, {"timecode": 39, "before_eval_results": {"predictions": ["South America", "\"Boogie Woogie Bugle Boy\"", "Europe", "Charlton Heston", "Glory", "Sweeney Todd", "The Bridge on the River Kwai", "the Fall of Constantinople", "Havisham", "Jefferson Davis", "Ford Madox Ford", "the equator", "a toothpick", "California", "Dixie", "the Vietcong", "Warren Harding", "engrave", "Shue", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Josip Broz Tito", "conformation", "Ratatouille", "neurons", "Calvin Coolidge", "Mark Cuban", "Rudolph Giuliani", "eyes", "Tony Dungy", "the Danube at Passau", "Damascus Steel Blade", "26", "Electric word life", "precipitation", "chess", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "F5", "Led Zeppelinthe", "a Tesla coil", "Germany", "Tara / Ghost of Christmas Past", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "Mrs. Graham", "Bob Dole", "Ben Kingsely", "managing his time."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5342261904761905}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, false, false, true, false, false, false, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-4408", "mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-9240", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_searchqa-validation-11250", "mrqa_searchqa-validation-9903", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.46875, "CSR": 0.478515625, "EFR": 1.0, "Overall": 0.688828125}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Breisgau", "James Weury Johnson", "a 2003 South Korean horror film", "Oakdale", "Missouri", "FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000", "Yellow fever", "Pitch Perfect 2", "1934", "a record of 13\u20133", "We Need a Little Christmas", "panthera leo melanochaita", "New York Islanders", "1345 to 1377", "nearly 80 years", "Jean Acker", "English", "Gettysburg Address", "Whitney Houston", "Marcus Rashford", "Daphnis et Chlo\u00e9", "1 draw", "26,000", "Kristin Scott Thomas", "Mayor Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "The Second City", "Pinellas County", "beer", "London", "Ployer Peter Hill", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mason Alan Dinehart", "Golde", "Sir Tom Finney", "Cameroon", "collecting samples of blood and other fluids from patients", "by military personnel to hazardous materials in the United States, Japan and Iraq,", "nine", "Iggy Pop invented punk rock.", "a pound of flesh", "Mayor of Casterbridge", "Leonardo DiCaprio", "a kiss - off to a destructive ex-lover who did the protagonist wrong,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6388491665605636}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, false, true, false, true, true, false, true, false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, false, true, true, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.25, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1556", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-2352", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-3874", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-3705", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_naturalquestions-validation-6326"], "SR": 0.5, "CSR": 0.47903963414634143, "EFR": 1.0, "Overall": 0.6889329268292683}, {"timecode": 41, "before_eval_results": {"predictions": ["a fumble", "10", "\"The Angels family has suffered a tremendous loss today,\"", "Les Bleus", "2005.", "more than 4,000", "the club president", "people are angry.", "normal maritime", "Sri Lanka", "death of a pregnant soldier", "25 percent", "fatally shooting a limo driver", "Greek", "as", "piano", "$250,000", "\"prostitute\" and threatening to oust another from his country.", "the mammoth\\'s skull", "tax", "Los Ticos", "some three months before the crimes \"had the answers in front of her", "President Bush", "Google,", "Salt Lake City, Utah,", "Manmohan Singh\\'s Congress party,", "Haiti", "on March 21.", "Pakistan", "23 years.", "her father hit a line drive that landed just above Morgan\\'s left temple.", "Tim Cahill", "an open window", "Leo Frank", "Beatles", "normal maritime traffic around Haiti", "President Robert Mugabe", "free", "two", "The group", "on Sunday", "his son is fighting an unjust war for an America that went too far when it invaded Iraq", "\"Twilight\"", "forgery and flying without a valid license,", "11", "A third beluga whale belonging to the world\\'s largest aquarium", "Authorities in Fayetteville, North Carolina,", "The plane had a crew of 14 people and was carrying an additional 98 passengers,", "the Taliban", "North Korea", "Rihanna", "radius R of the turntable", "the right side of the heart", "54 Mbit / s", "Janet Royall", "Liberator", "most famous breakfast cereal", "Suffolk County", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python", "King of Sweden", "FMCSA"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5282862103174604}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, true, false, false, false, false, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.25, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.16666666666666669, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.888888888888889, 0.21428571428571427, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-190", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-2263", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-7297", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-376", "mrqa_hotpotqa-validation-2004", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-1519", "mrqa_searchqa-validation-10945"], "SR": 0.421875, "CSR": 0.4776785714285714, "EFR": 0.972972972972973, "Overall": 0.6832553088803089}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Arizona", "Zimbabwe", "Italian Serie A title", "a sixth member of a Missouri family", "showing her dancing against a stripper's pole.", "\"Michoacan Family,\"", "WTA Tour titles", "Zimbabwean President Robert Mugabe", "42", "taking on the swords of the Taliban.", "either stay home (which might be less depressing and won't add more airline emissions) or get a move on it and see the hot spots you just can't miss.", "80 percent", "1979", "\"Follow the Sun,\"", "Elena Kagan", "CBS, CNN, Fox and The Associated Press.", "an auxiliary lock", "1-1", "Umar Farouk AbdulMutallab,", "Myanmar", "Miami International Airport,", "his own death by crashing his private plane into a Florida swamp.", "The U.S. Embassy in Manila on Monday confirmed Lunsmann's release in Basilan after she was held hostage by a still unidentified group of bandits.", "poems telling of the pain and suffering of children just like her; girls banned from school,", "the program was made with the parents' full consent.", "Sen. Barack Obama", "The Red Cross, UNHCR and UNICEF", "Moscow", "debris", "he believed he was about to be attacked himself.", "capital murder and three counts of attempted murder in the shootings at the University of Alabama in Huntsville", "Basel", "17", "Daytime Emmy Lifetime Achievement Award.", "state senators", "31 meters (102 feet)", "its nude beaches.", "stories of different women coping with breast cancer", "Ronald and Crystal Sheffield,", "shark River Park in Monmouth County", "three", "Islamabad", "partying", "Capitol Hill.", "\"theoretically\"", "when he was young.", "March 22,", "think are the best.", "Beirut, Lebanon.", "\"Antichrist\"", "World War II", "John Adams and Benjamin Franklin", "Jeff East", "Blue-white", "brown", "Selfie", "2002", "England", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5663657650560223}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.5, 0.11764705882352941, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 0.125, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.5333333333333333, 0.4, 0.0, 0.0, 0.8, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-2624", "mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-2290", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1297", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-800", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-6789", "mrqa_triviaqa-validation-1492", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.453125, "CSR": 0.47710755813953487, "EFR": 1.0, "Overall": 0.688546511627907}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "the legitimacy of that race.", "28", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees of Immigration and Customs Enforcement", "33-year-old", "that the assassination program, not the 2007 increase in U.S. forces in the war zone known as \"the surge,\"", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "$2 billion", "pesos", "in 1937,", "The station", "Karthik Rajaram", "his face blue and purple and a chain around his neck,", "Robert Mugabe", "Jenny Sanford,", "Afghanistan's Helmand province,", "Saturday.", "$1.5 million", "censorship and self-censorship", "could be secretly working on a nuclear weapon", "the fact that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Dangjin", "100 percent", "Saturday", "Pakistan's", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Indian", "Rima Fakih", "in a Johannesburg church", "Barack Obama's", "requested helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "U.S. Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "104 feet long and 95 feet wide at the alcove.", "this will be the second time", "Jund Ansar Allah", "54 bodies", "the woman and her colleague", "$50", "$60 billion", "ALS6", "Malayalam Odakkuzhal", "Mad - Eye Moody and Hedwig", "in 1964", "Villa Park", "landless farmers", "eight-ball", "1822", "The Dressmaker", "Anandapala", "1-inch", "a buffalo", "$666,000", "the parietal"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5869026336220987}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.5, 0.2105263157894737, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.08695652173913043, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.5, 0.2857142857142857, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.7499999999999999, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2634", "mrqa_newsqa-validation-2642", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_naturalquestions-validation-6662", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-13511", "mrqa_searchqa-validation-2281"], "SR": 0.46875, "CSR": 0.47691761363636365, "EFR": 1.0, "Overall": 0.6885085227272728}, {"timecode": 44, "before_eval_results": {"predictions": ["hybrid Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Florida", "Benj Pasek", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Atlanta Athletic Club", "Franconia, New Hampshire", "Operation Watchtower", "Dan Crow", "\"War & Peace\"", "Amberley", "What Are Little Boys Made Of", "Berea College", "Chicago Bears", "Timoth\u00e9e Chalamet", "Charmian Carr", "Germany and other parts of Central Europe", "New York Islanders", "Amy Lysle Smart", "26,788", "ethno-nationalist", "1967", "Marktown", "Argentine professional footballer", "Radcliffe College", "James A. Garfield", "Ford", "negative confessions of Maat", "India", "German", "\"Charmed\"", "25 million", "The Snowman", "Ella Fitzgerald", "X-Men", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "Henry Luce's", "\"I'm Shipping Up to Boston\"", "American", "Believe", "`` central '' or `` middle ''", "Australia's capital is Canberra", "the beginning of the American colonies", "Nicola Adams", "whale", "Russia", "people have chosen their rides based on what their cars say about them.", "Steven Green", "Fayetteville, North Carolina,", "Chaucer", "rattlesnakes", "first", "Benjamin Franklin"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5442449044011544}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.4, 1.0, 0.0, 1.0, 0.8181818181818181, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-4454", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-4325", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-2355", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.46875, "CSR": 0.47673611111111114, "EFR": 0.9705882352941176, "Overall": 0.6825898692810458}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder", "the Indian Ocean", "three", "crocodile eggs", "Colorado prosecutor", "Polis", "on Saturday.", "Haiti", "in July", "sniff out cell phones.", "off the north coast of Puerto Rico.", "Cain", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "the Brundell family", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie", "Heshmatollah Attarzadeh near his home in Peshawar", "environmental", "the Middle East and North Africa,", "Nine out of 10 children", "police", "Soeoth of Indonesia and Amadou Diouf of Senegal in West Africa,", "a crocodile", "a bronze medal", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families,", "Phillip A. Myers.", "Obama's", "King Birendra,", "homicide by undetermined means,", "Casey Anthony, 22,", "the women at a Texas  airport", "Arnoldo Rueda Medina.", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers,", "two weeks ago", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "the Oaxacan countryside of southern Mexico", "Wenger", "slavery", "Kat (677 Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan )", "Latin liberalia", "Enid Blyton", "Johnny Mathis", "The Golden Child (1986)", "Champion Jockey", "Luca Guadagnino", "Sleepy Brown", "Maya Angelou", "the only month that is", "a jigger", "a Bristol Box Kite"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5948802933177932}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, false, true, false, false, false, true, false, true, true, true, true, false, false, false], "QA-F1": [1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.7499999999999999, 1.0, 0.5, 1.0, 0.9090909090909091, 0.0, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-2600", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.453125, "CSR": 0.47622282608695654, "EFR": 1.0, "Overall": 0.6883695652173913}, {"timecode": 46, "before_eval_results": {"predictions": ["\"spectacular\"", "\"I know we're at the Democratic Convention,", "Nirvana", "\"Dancing With the Stars.\"", "without bail", "12.3 million", "Mexico", "United", "Vivek Wadhwa,", "Brett Cummins,", "Two soldiers, a policeman and four militants", "Saturday", "Nicole", "the legitimacy of that race.", "the diversity the collaborations provide,", "Dennis Davern,", "Africa.", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "target a particular health ailment or beauty concern.", "Chinese", "Newcastle", "\"Nothing But Love\"", "forged credit cards and identity theft", "June 6, 1944,", "the Middle East and North Africa,", "1-0 draw", "October 19,", "\"It was a wrong thing to say,", "Seoul,", "fuel economy and safety", "Amyotrophic Lateral Sclerosis", "eight", "Siri.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "\"Biscuit\"", "the children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "they did not know how many people were onboard.", "attempting illegal crossings", "The rights group", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place,", "38,", "Her husband and attorney, James Whitehouse,", "\"Test scores and graduation rates", "three", "the most gigantic pumpkins in the world,", "cancer,", "two", "Schoenberg", "Brooklyn, New York", "Jean Fernel", "Terry Pratchett's", "Japan", "fox hunting", "New York", "travel", "16,116", "\"Cry-Baby\"", "a sugar base, natural or artificial", "bumblebee", "Sabrina Carpenter"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6132049427006958}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, false, true, true, false, true, true, false, true, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.13793103448275862, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-428", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-380", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_naturalquestions-validation-10525", "mrqa_triviaqa-validation-1729", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573", "mrqa_hotpotqa-validation-664"], "SR": 0.546875, "CSR": 0.4777260638297872, "EFR": 1.0, "Overall": 0.6886702127659575}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Airlines", "A Rush of Blood to the Head", "5", "Wilmette, Illinois", "A. E. Housman's \"A Shropshire Lad\"", "teen", "Dennis Kux", "Midnight Oil", "Brett Ryan Eldredge", "I-League", "two or three", "Nimbus School of Recording Arts", "Lady Frederick Windsor", "animal", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1930s and 1940s", "5,112 feet", "1992", "retail, office and residential", "14,677", "John Levell Starks", "Mickey Gilley", "quotas", "German shepherd", "Mexican", "1973", "2003", "the backside", "Kristoffer Rygg", "1730", "London Luton Airport", "the Salzburg Festival", "McComb, Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "a oratorio", "Bunker Hill", "p. spelaea", "Royal", "World War II", "Knoxville", "\"Three's Company\"", "Doomtree", "Labour", "Linda McCartney's", "Erich Maria Remarque", "2008", "79", "Buffalo Bill", "Romania", "Zephyr, Billy Cobham, Alphonse Mouzon,", "Mt Kenya", "Aung San Suu Kyi", "NATO-led troops", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "corridors", "Lehman Bros International"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5301339285714286}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1874", "mrqa_hotpotqa-validation-5349", "mrqa_hotpotqa-validation-3162", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-3675", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-1404", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5435", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-6586", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.453125, "CSR": 0.47721354166666663, "EFR": 1.0, "Overall": 0.6885677083333334}, {"timecode": 48, "before_eval_results": {"predictions": ["Citation", "Helsinki", "sushi", "a bronchodilator", "Vulcan", "Citation", "Fawn Hall", "Citation", "Citation", "Barnum & Bailey", "Johnny Weissmuller", "cathode", "Torque Wrench", "gold", "Marlon Brando", "Citation", "the Impressionist movement", "University of Kentucky", "ruddy", "Brussels", "Macbeth", "General Lee", "piracy", "Fyodor Dostoevsky", "Martin Luther", "Clue", "Sir Arthur Conan Doyle", "Norway", "Andrew Johnson", "the end of every seven years", "Mike Connors", "tarzan", "Jim Inhofe", "sancire", "Corpus Christi", "Nigeria", "Citation", "a preamble", "3 p.m.", "Citation", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "Citation", "the Grail", "West Virginia", "James Madison Jr", "theater", "Citation", "kritiks", "Khrushchev", "1904", "young girl", "Tottenham", "ambidevous", "the largest chariot battle ever fought", "Humberside Airport", "265 million", "100 million records", "funding to help poor families buy more energy-efficient electrical appliances.", "head injury.", "Pope Benedict XVI", "Charles II"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5161458333333333}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, false, false, true, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12777", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-6362", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-14589", "mrqa_searchqa-validation-15062", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-5887", "mrqa_hotpotqa-validation-1209", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.46875, "CSR": 0.4770408163265306, "EFR": 1.0, "Overall": 0.6885331632653061}, {"timecode": 49, "UKR": 0.626953125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1056", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1258", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-211", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4683", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-4840", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5640", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-785", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-1805", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1597", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2009", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2949", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4123", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-526", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12777", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6003", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8428", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_squad-validation-9931", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.837890625, "KG": 0.45234375, "before_eval_results": {"predictions": ["presidential order", "Heisman Trophy", "Brandi Chastain", "the Colorado River", "P.J. Parker", "carioca", "Treasure Island", "Pocahontas", "improv", "(Whizzer) White", "an octave", "a push-button valve", "the Swede", "Matthew Broderick", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "draft horse", "Ernest Lawrence", "a rodeo", "fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "the large intestine", "the mouthpiece", "Key West", "Lord of the Rings", "Olivia Newton-John", "bug spray", "Manhattan", "Feb 1, 2012", "Leontyne Price", "manure", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "(Stephen) Darlington", "a draughts", "Warsaw", "a headscarf", "City of Philadelphia", "peanut butter", "Edgar Allan Poe", "cork", "Lex Luthor", "food and clothing", "Queen Taramis", "Master Christopher Jones", "Hebrew", "frank saul", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "The incident Sunday evening", "three out of four", "poems", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.5850694444444444}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-5787", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-8315", "mrqa_searchqa-validation-1897", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301"], "SR": 0.515625, "CSR": 0.4778125, "EFR": 1.0, "Overall": 0.6789999999999999}]}