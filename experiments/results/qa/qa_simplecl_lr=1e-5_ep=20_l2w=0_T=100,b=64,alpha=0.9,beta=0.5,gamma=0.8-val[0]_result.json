{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8200, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "the Los Angeles Times", "the Broncos", "anticlines and synclines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "Rhenus", "Atlantic", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "the infected corpses", "the United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "a shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "two integers", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "by the market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Buddhism", "Matthew 16:18", "U.S. ship that was hijacked off Somalia's coast", "Rwanda", "revelry", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8001092657342657}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-4289", "mrqa_squad-validation-9655", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_squad-validation-8014", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.734375, "CSR": 0.78125, "EFR": 1.0, "Overall": 0.890625}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "the coast of Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "presidential representative democratic republic", "the grace that \"goes before\" us", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "Arizona Cardinals", "1991", "Chaffee", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "more integral", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "The Spice Girls", "the ten stages of corporate life cycle", "the company's factory in Waterford City, Ireland", "nitrogen", "Annemarie Moody", "Water currents", "six", "It always begins with the music", "musician", "Illinois", "Rafael Palmeiro", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.78125, "QA-F1": 0.8111076423576423}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-235", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-3629"], "SR": 0.78125, "CSR": 0.78125, "EFR": 1.0, "Overall": 0.890625}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "monumental size", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "charleston", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "President", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "Edict of Nantes", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "multiple revisions", "philanthropic initiative", "integer factorization problem", "inequality", "Isel", "adapted quickly and often married outside their immediate French communities", "former Pakistani Prime Minister Benazir Bhutto", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "the late 19th century", "Channel Islands", "charleston", "Alberich", "charleston", "charleston", "Churchill Downs", "The port of Terneuzen is the third largest in the Netherlands, after those of Rotterdam and Amsterdam", "charleston", "charleston", "christopher", "study insects and their relationship to humans, other organisms, and the environment", "the limbic system", "trahan Mubarak", "George Fox", "Maryland", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorgate", "\"Krabby Road\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.6364583333333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-801", "mrqa_squad-validation-9286", "mrqa_squad-validation-4293", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-7321", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_hotpotqa-validation-437", "mrqa_hotpotqa-validation-3821"], "SR": 0.59375, "CSR": 0.734375, "EFR": 0.8846153846153846, "Overall": 0.8094951923076923}, {"timecode": 4, "before_eval_results": {"predictions": ["in plants that contain them", "Parliament of Victoria", "Zaha Hadid", "the French", "Science and Discovery", "the Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "The Skirmish of the Brick Church", "the port city of Kaffa in the Crimea", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "1985", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "the Italian government", "22", "terror groups that have extended their reach outside Pakistan's volatile North West Frontier Province", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "a new model is simply out of their reach", "Muslim", "will be the first time any version of the Magna Carta has ever gone up for auction", "The Closer", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "a woman who may have been contacted through a Craigslist ad", "one", "christopher", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "gABRIEL ROSSETTI"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7173507130124777}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.15999999999999998, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_squad-validation-166", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.703125, "CSR": 0.728125, "EFR": 0.9473684210526315, "Overall": 0.8377467105263158}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a high-level marketing manager, was given the job of turning the business around", "500,000", "Ofcom", "Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "part of a rule connected with civil disobedience", "June 1978", "Milton Latham", "1914", "the Philippines", "the Broncos", "1950s to 2011", "the characteristics of the conquering peoples", "German Te Deum", "1795", "Bermuda 419", "evaporated to cool oxygen gas", "Infinity Broadcasting Corporation", "semi-legal", "1972", "rudimentary", "1957", "mother-of-pearl", "Gene Barry", "negotiates treaties with foreign nations, but treaties enter into force if ratified by two - thirds of the Senate", "It is mainly for the purpose of changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "( people ) were descended from apes", "Herbert Hoover, has made at least one State of the Union report as a speech delivered before a joint session of Congress", "radius R of the turntable", "Panning", "Justin Timberlake", "Brazil, China, France, Germany, India, Indonesia, Italy, Japan, South Korea, Mexico, Russia, Turkey, the United Kingdom", "The total size of the peacekeeping force is 98,200 police, troops, and military experts", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's has 62 locations in Canada", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "the seven ages of man : infant, schoolboy, lover, soldier, justice, Pantalone and old age", "most episodes feature a storyline taking place in the present ( 2016 -- 2018, contemporaneous with airing )", "Morgan Freeman reprising his role as detective Alex Cross", "David Gahan ( / \u0261\u0251\u02d0n / ; born David Callcott ; 9 May 1962 )", "the Overlook Hotel in his 1977 bestseller The Shining and its 1980 film adaption of the same name, as well as the location for the 1997 miniseries", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "The day before Ash Wednesday", "Jaipur", "Jonas Olsson,", "torpedo boat", "Newport"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6947768331814385}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.45454545454545453, 0.888888888888889, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.3157894736842105, 1.0, 0.0, 0.0, 0.3636363636363636, 0.8, 0.08333333333333334, 0.5833333333333334, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4836", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-7488", "mrqa_squad-validation-3473", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.609375, "CSR": 0.7083333333333333, "EFR": 0.96, "Overall": 0.8341666666666666}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "Serbian Orthodox priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "social and political action", "1936", "the New Birth", "gold", "a 3\u20130 lead", "Vivienne Westwood", "reduction", "disease", "TGIF", "Confucian propriety and ancestor veneration", "Luther's rediscovery of \"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live and 5 Live Sports Extra", "1876", "screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "members in good standing with the college, and private schools may also require their teachers to be college peoples", "end of the season", "10", "Jonas", "African-Americans", "will not support the Stop Online Piracy Act", "Chuck Bass", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Stuttgart on Sunday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "North Korea", "first five Potter films", "know what's important in life", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "Her husband and attorney, James Whitehouse,", "we want to ensure we have all the capacity that may be needed over the course of the coming days", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "Mike Gatting", "Colgate University", "The Church of Christ, Scientist", "A fatty acid chain is monounsaturated if it contains one double bond", "canonical gospels and the book of Acts"], "metric_results": {"EM": 0.625, "QA-F1": 0.7092062291692226}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473684, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2, 0.5, 1.0, 0.5, 0.25, 1.0, 0.0, 1.0, 0.16666666666666669, 0.2666666666666667, 1.0, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.37499999999999994, 0.2222222222222222]}}, "before_error_ids": ["mrqa_squad-validation-800", "mrqa_squad-validation-2133", "mrqa_squad-validation-486", "mrqa_squad-validation-3390", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.625, "CSR": 0.6964285714285714, "EFR": 1.0, "Overall": 0.8482142857142857}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased trade with poor countries", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism", "Jim Gray", "unequal", "July 1969", "Hitler's secret police demanded to know if they were hiding a Jew in their house.", "a yellow chlorophyll precursor", "spontaneous", "the courts of member states and the Court of Justice of the European Union", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "ricks for Warsaw", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "Belgrade", "up to \u00a339,942", "21 October 1512", "James O. McKinsey", "\"Dance Your Ass Off.\"", "their \"Freshman Year\" experience", "India", "Zulfikar Ali Bhutto, former president and prime minister of Pakistan", "at the Stanlow oil refinery in western England, Drax power station in the northeast, Petroplus", "April 24 through May 2", "Krishna Rajaram,", "early detection and helping other women cope", "250,000", "Timothy Masters", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "William S. Cohen", "\"Dance Your Ass Off\"", "leniency", "Matthew Fisher", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian.", "seeking help", "Japan", "patrolling", "\"Empire of the Sun,\"", "Norman", "at the Olympics", "Matthew Ward Winer", "5498, aired 2008-07-02", "opposite R\u00fcgen island", "Mustique", "green"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6684331489523022}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9032258064516129, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4615384615384615, 0.25, 1.0, 1.0, 0.4444444444444445, 0.0, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-872", "mrqa_squad-validation-2091", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-417", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-991", "mrqa_searchqa-validation-7977", "mrqa_triviaqa-validation-2858"], "SR": 0.578125, "CSR": 0.681640625, "EFR": 0.9629629629629629, "Overall": 0.8223017939814814}, {"timecode": 8, "before_eval_results": {"predictions": ["2009", "The British provided medical treatment for the sick and wounded French soldiers", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe.", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday", "Journey's End", "immediate", "Levi's Stadium.", "Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan, English Chinghiz, Chinghis, and Chingiz, Chinese: \u6210\u5409", "Einstein", "fast forwarding", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone, Caius Gabriel Cibber, Grinling Gibbons, John Michael Rysbrack, Louis-Fran\u00e7ois Roubiliac, Peter Scheemakers,", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington Railway", "autonomy", "Islamic", "$12.9 million", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic is the reason for his longevity in the movie business.", "finance", "terminal brain cancer.", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "the Employee Free Choice act", "separated", "Animal Planet", "fake his own death", "there were no radar outages and said it had not lost contact with any planes", "54 bodies", "early detection", "Diversity", "$250,000", "to break up ice jams", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president was declared the winner of the country's presidential elections on Thursday,", "2050", "Alfredo Astiz,", "Abdullah Gul,", "Briton Carl Froch", "The Everglades, known as the River of Grass,", "when the cell is undergoing the metaphase of cell division", "Gibraltar", "New Orleans, Louisiana", "early 1630s, a craze developed in Holland for this flower, with many investors paying huge sums for individual bulbs", "bistro", "it may mean if you miss a period when you're not expecting.", "it has to be the most difficult sport to be a play-by-play announcer."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6692267801642802}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.0909090909090909, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.2857142857142857, 0.2222222222222222, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-6300", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3910", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.59375, "CSR": 0.671875, "EFR": 1.0, "Overall": 0.8359375}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "the General Sejm", "Derek Jacobi", "net force", "hoos", "30%\u201350%", "very badly disposed towards the French, and are entirely devoted to the English.", "United States", "CRISPR", "six", "about 300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "issues related to the substance of the statement.", "Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "any kind of engagement with the Taliban -- either as part of NATO or bilaterally -- would have much worse long-term consequences.", "an average of 25 percent", "a trainer", "the couple's surrogate lost the pregnancy.", "environmental and political events.", "he fears a desperate country with a potential power vacuum that could lash out.", "at least two and a half hours.", "Elin Nordegren", "Europe, Asia, Africa and the Middle East.", "6,000", "a medicine that contained the banned substance cortisone.", "President Clinton.", "delivered three machine guns and two silencers to the hip-hop star,", "Morgan Tsvangirai.", "policing the world and Africa", "liquidity", "a canyon", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school,", "strife in Somalia,", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia, Illinois", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "the area was sealed off, so they did not know casualty figures.", "London", "Abigail '' that he loved her", "the immediate physical and social setting in which people live or in which something happens or develops.", "William Tell", "OutKast", "Groundhog Day", "he really didn't mean t", "a singer"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6199996745493068}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.742857142857143, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2, 1.0, 0.2857142857142857, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-9194", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.5625, "CSR": 0.6609375, "EFR": 0.9642857142857143, "Overall": 0.8126116071428571}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York,", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction", "The Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "premises of the hospital.", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO.", "Brazil", "Friday", "pelvis and sacrum -- the triangular bone within the pelvis.", "issued his first military orders as leader of North Korea", "precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,", "Gainsbourg", "Maude", "Phillip A. Myers.", "Korea", "two weeks after Black History Month was mocked in an off-campus party that was condemned by the school.", "58 people", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Cpl. Cesar Laurean", "Dangjin", "e-mails", "Hu Jintao", "magazine", "The teen faces a lifelong recovery from his injuries,", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next.", "President Bush", "Jeffrey Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "kabinett", "Lionsgate.", "James Lofton", "Sanskrit", "hair-like structures that help paramecium move around."], "metric_results": {"EM": 0.59375, "QA-F1": 0.7052624458874459}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5454545454545454, 0.18181818181818182, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.14285714285714285, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_squad-validation-1299", "mrqa_squad-validation-8655", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-4180", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.59375, "CSR": 0.6548295454545454, "EFR": 1.0, "Overall": 0.8274147727272727}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "hermaphroditism", "Victoria Department of Education", "seized", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching.", "Elway", "Philo of Byzantium", "36", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "Agnes Wickfield", "The Soup Dragon", "antelope", "nipples", "the Precambrian period", "cooperative", "Anastasia Dobromyslova", "Gagapedia", "9", "The Female Brain,", "radishes", "Robert Ludlum", "the Acromantula", "Shuttle Launch", "the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live", "Hebrew", "London Underground Piccadilly Line", "Wisconsin", "orangutan", "Manet", "The Magic Finger", "Massachusetts", "2005", "1971", "Chrysler", "dolt", "Rome", "a chiton", "Enrico Caruso", "Elizabeth Arden", "collapsible support assembly", "Sir Hardy Amies", "Liechtenstein", "the 14th most common surname in Wales", "Rob Davis", "Cody Miller", "Bloomingdale Firehouse", "Nazi Germany", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "Jamaica", "Buddhism"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6136269094380797}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, true, true], "QA-F1": [0.5, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6153846153846153, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-4642", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-1018", "mrqa_triviaqa-validation-3759", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983"], "SR": 0.53125, "CSR": 0.64453125, "EFR": 1.0, "Overall": 0.822265625}, {"timecode": 12, "before_eval_results": {"predictions": ["the Southern Border Region", "70-50's", "Panini", "new laws or amendments to existing laws", "anti-colonial movements", "the Rhine Valley", "surface proteins", "test everything himself by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "basic constitutional rights and principles (particularly democracy, the rule of law and the social state principles)", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "Ness Point", "Jessica Simpson", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "Eric Pickles", "Sir Hugo Drax", "Vladivostok", "Sheryl Crow", "hawthilly", "sinensis", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "cosmology", "gin", "George Clooney", "Eric Coates", "James Chadwick", "\"No one was saved\"", "Monopoly", "champagne", "an extended period of abundant rainfall lasting many thousands of years", "the United States", "Brigit Forsyth", "Lord Melbourne", "state of Japan", "What's Up With the Title?", "David Hogarth", "Kent", "Edgar Degas", "Standard Motor Company", "white", "Switzerland", "soda water", "the people of France", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Jason Voorhees", "bremen", "David", "\"Steamboat Bill, Jr.\""], "metric_results": {"EM": 0.546875, "QA-F1": 0.6098882636181023}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.8387096774193548, 0.3846153846153846, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9452", "mrqa_squad-validation-6655", "mrqa_squad-validation-2078", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-302", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_triviaqa-validation-3503", "mrqa_naturalquestions-validation-594", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_newsqa-validation-3207", "mrqa_searchqa-validation-8450"], "SR": 0.546875, "CSR": 0.6370192307692308, "EFR": 1.0, "Overall": 0.8185096153846154}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "it would appear to be some form of the ordinary Eastern or bubonic plague", "had their own militia", "months after it happened", "Over 61", "quality of a country's institutions", "cilia", "friction", "Sky Digital", "2005", "force", "mustelids", "John Connally", "saffron", "HYmenaeus", "god Zeus", "albinism", "the Suez Canal", "Brigit Forsyth", "call My Bluff", "March 10, 1997", "cuddly new pet", "the Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "reptile", "strong cold southwest wind", "table tennis", "the medical journal of the United States", "penhaligon", "aragorn, Gimli and Legolas", "thaddeus sholto", "Jinnah International", "Monday", "capital of Venezuela", "beads", "soap", "highball", "Avro", "Genesis", "Charlie Brooker", "melbourne chamomilla", "Harrods", "2007", "Christina Ricci", "Scarface", "pale yellow", "aluminium", "bubba", "June 12, 2018", "Filipino American", "London's West End", "Lambic", "Nook", "Steven Green", "commas", "fortune", "bridge Street, Huntsville, AL", "Synchronicity"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6357638888888888}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.4000000000000001, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-2875", "mrqa_squad-validation-2920", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-6547", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_hotpotqa-validation-5340", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-6628"], "SR": 0.5625, "CSR": 0.6316964285714286, "EFR": 1.0, "Overall": 0.8158482142857143}, {"timecode": 14, "before_eval_results": {"predictions": ["seven", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "sleep after it is separated from the body", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "a declining state of mind", "1898", "The Deadly Assassin and Mawdryn undead", "for scientific observation", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat in the hat", "2020", "1974", "332", "1997", "Authority", "senior", "Spanish moss", "Chinese cooking", "Vienna", "the World Trade Center complex", "Kevin Spacey", "All Hallows", "78", "in lymph", "Bangladesh -- India border", "the President", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "October 1, 2014", "the United States", "claims adjuster", "the neck", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection, irritation, or allergies", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column", "three", "nejm", "apron", "Kew Gardens", "Nikita Khrushchev", "$500,000", "young self-styled anarchists", "grain reaper", "a badge", "the BBC building in Glasgow, Scotland", "\"Larry King Live\""], "metric_results": {"EM": 0.53125, "QA-F1": 0.6805811036789298}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false], "QA-F1": [0.5, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.39999999999999997, 1.0, 0.5714285714285715, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 0.5, 0.2857142857142857, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-653", "mrqa_squad-validation-125", "mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.53125, "CSR": 0.625, "EFR": 0.9333333333333333, "Overall": 0.7791666666666667}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "The Late Late Show with Stephen Colbert", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "CBS", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "note number 60", "Seattle, Washington", "Battle of Antietam", "Dimitar Berbatov and Carlos Tevez", "In Time", "early 3rd century", "Glenn Close", "three", "Agostino Bassi", "five seasons", "a beach in Malibu, California", "the church at Philippi", "the Netherlands", "September 2017", "Professor Kantorek", "1546", "Jane Fonda", "Bhupendranath Dutt", "a warrior", "Dr. Lexie Grey ( Chyler Leigh )", "Majandra Delfino", "December 19, 1971", "Uruguay", "Alex Skuby", "Thomas Middleitch", "The National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "the Director of National Intelligence", "D. a.D.A.", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal", "burt Hammersmith", "Rachel Kelly Tucker", "Bohemia", "earwigs", "Code 02PrettyPretty", "Joe Dever", "opposition group, also known as the \"red shirts,\"", "the abduction of minors", "Nevada", "Chile", "Stage Stores", "1881"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5966063884032635}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 0.5, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_squad-validation-551", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-7084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870"], "SR": 0.46875, "CSR": 0.615234375, "EFR": 0.9411764705882353, "Overall": 0.7782054227941176}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "Arizona Cardinals", "Robert Watson", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Khitan Xiao Zhala", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland.", "Office", "SAVE", "Scandinavian Airlines System Aktiebolag", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award Best Actor winner in 1956", "Jello Biafra drew on Nardwuar's face with a marker pen", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson", "Sir William McMahon.", "the North Sea coast", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "Pakistan Aeronautical Complex (PAC)", "Delacorte Press.", "Neighbourhoods are often social communities with considerable face-to-face interaction among members.", "Secretariat", "Wake Atoll", "Hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth from 1573 to 1575", "\"Southern Living\" Reader's Choice Awards", "William Shakespeare", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Alticor", "Parlophone Records", "kwaZulu-Natal", "Surrey", "The Girl", "Charles Russell", "Boyd Gaming", "three different covers", "1991", "Glenn Close", "Mary Welch", "Neighbours", "Ewan McGregor", "2011", "Browning", "the leader of the late insurrection in Southampton, Va.", "power-sharing talks", "Brown-Waite"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6537670662670663}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 0.3636363636363636, 0.3636363636363636, 0.2857142857142857, 0.4, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3636363636363636, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8509", "mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-5514", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2396", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-2494", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.53125, "CSR": 0.6102941176470589, "EFR": 1.0, "Overall": 0.8051470588235294}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "the inner chloroplast membrane", "Charlie Harper", "steveland Hardaway Morris", "beaver", "La Boh\u00e8me Giacomo Puccini", "red itchy swelling, a burning or stinging sensation, itchy white bump, and, in some cases, a severe allergic reaction that leads to diarrhea, cramps and wheezing", "Talavera de la Reina", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Xenophon", "Fuller's", "a reference mark located on a ship\u2019s hull that indicates the maximum depth to which the vessel may be safely immersed when loaded with cargo", "Nick Hornby", "The Comedy of Errors", "Charles V", "England", "welch", "weight plates", "\"big house\"", "Hadrian", "US", "human flea", "Moonee Ponds, a suburb in Melbourne, Victoria", "Hamburg", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "In 2014/15, only six have won the title", "Robert Cummings", "Jessica Simpson", "Boy George", "In 1906, Finland became the first country in the world to grant women full political rights.", "3000m", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "It was a Confederate victory", "New Jewel Movement", "in sub-Saharan Africa", "U.S. 93", "Anjuna beach in Goa", "Lev Ivanov", "Oshkosh", "two", "jeopardy/1870_Qs.txt at master", "a newspaper that is published when something important happens"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6013586956521739}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.08695652173913042, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-6315", "mrqa_triviaqa-validation-3132", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-validation-767", "mrqa_hotpotqa-validation-1658", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.515625, "CSR": 0.6050347222222222, "EFR": 0.967741935483871, "Overall": 0.7863883288530467}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "extremely high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "new magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "the Coppolas", "Anna Faris", "peninsular mainland", "inability to comprehend and formulate language", "Splodgenessabounds", "Tyrion", "electron donors", "Laura Jane Haddock", "( 1985 -- 1993", "775 rooms", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Lewis Carroll", "20 November 1989", "Coton in the Elms", "55 -- 69 %", "Ella Eyre", "1995", "Definition of the problems and / or goals", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "the aortic valve", "July 21, 1861", "Dr. Addison Montgomery", "state or other organizational body", "An empty line", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "universal significance", "September 2017", "moral", "`` Rising Sun Blues ''", "Part 2", "dumbo", "the failure of the duke of Monmouth\u2019s rebellion", "Christian", "Robert L. Stone", "2008", "Yemen", "jegna", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6907217325335931}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.08695652173913042, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-25", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-7111", "mrqa_hotpotqa-validation-4735"], "SR": 0.609375, "CSR": 0.6052631578947368, "EFR": 0.96, "Overall": 0.7826315789473683}, {"timecode": 19, "before_eval_results": {"predictions": ["the law as the Holy Spirit's tool to work sorrow over sin in man's heart, thus preparing him for Christ's fulfillment of the law offered in the gospel", "black", "Illinois Country, hugging the east side of the Mississippi River and its tributaries", "Jaime Weston", "1978", "high art and folk music", "warming", "the mid-sixties", "270,000", "Long troop deployments", "Joe Pantoliano", "a Florida girl who disappeared in February, plans to file for divorce", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "nearly eight in 10", "sovereignty over them", "Tuesday", "forgery and flying without a valid license", "Anil Kapoor", "19", "President Obama", "baggage from the 80s", "The Louvre", "snowstorm", "sports cars", "eggs", "Mutassim", "Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18, the publicist said.The Glasgow, Scotland concert has been shifted from this Sunday to May 1,", "\"Stagecoach\" (William Wyler, 1959)", "Russia", "Al alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone.", "\u00a320 million ($41.1 million) fortune", "Kingman Regional Medical Center,", "Al Gore", "Manmohan Singh", "Michael Jackson", "be silent", "40 militants and six Pakistan soldiers dead", "Spaniard Carlos Moya", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Louisiana", "the Southeast", "the last person known to have seen Haleigh the night she disappeared from the family's rented mobile home.", "Carol Browner", "\"A Mother For All Seasons.\"", "Moe and Sana Maraachli", "back at work", "the initial necropsy or animal autopsy", "27", "Derek Hough", "Thomas Jefferson", "parsley", "Zager and Evans", "Robert Matthew Hurley", "his fourth term as At-large Chairman of the Board of Supervisors of Prince William County, Virginia", "\"electronic identification to which a communication may be sent\"", "(Oliver) Cromwell", "Lapland", "2000", "Emad Hashim"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5911364064856712}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, false, true, true, false, false, true, false, false, true], "QA-F1": [0.3333333333333333, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.923076923076923, 0.0, 0.8333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-1760", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-1783", "mrqa_triviaqa-validation-3831", "mrqa_hotpotqa-validation-2013", "mrqa_searchqa-validation-328", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-5120"], "SR": 0.484375, "CSR": 0.59921875, "EFR": 0.9696969696969697, "Overall": 0.7844578598484848}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "Rh- in English Rhine as well as in German Rhein and French Rhin is due to the influence of Greek orthography", "1331", "Death wish Coffee", "L", "Cameroon,", "just after midday on a cold December Monday in South Korea's capital", "ballots", "fabric", "three empty vodka bottles,", "secretary of defense on China, Taiwan, Hong Kong and Mongolia, and was deputy director for strategy, plans and policy on the Army staff.", "1959,", "Nico Rosberg", "16", "his former Boca Juniors teammate and national coach Diego Maradona,", "she was humiliated by last month's incident,", "composer of \"Phantom of the Opera\" and \"Cats\" and one of Britain's richest men,", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony, 2,", "Amanda Knox's aunt", "well over 1,000 pounds", "Iran's development of a nuclear weapon", "a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, soothing near-black on red-eyes when it's time to sleep.", "using recreational drugs", "ceo Herbert Hainer", "Brett Cummins,", "a nearby day care center whose children are predominantly African-American.", "inmates", "Col. Elspeth Cameron-Ritchie,", "E! News", "Most of the 103 children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans,", "jobs", "saying Tuesday the reality he has seen is \"terrifying.\"", "The controversial technique that simulates drowning -- and which President Obama calls torture -- was used at least 83 times in August 2002 on suspected al Qaeda leader Abu Zubaydah,", "Mexican's attorney general's office responded with a statement saying that it would investigate the video and any group that tries to take justice into its own hands.", "Republicans", "developing a youth ballpark in his hometown of Aberdeen, Maryland, financed in part by a $75,000 gift from the Major League Baseball Players Association.", "An undated photo of Alexandros Grigoropoulos,", "Ayran President Robert Mugabe signed a power-sharing deal with the opposition party's breakaway faction,", "a 57-year old male", "Kim Jong Il seems to be \"testing the new administration.\"", "Angola", "Gary Brooker", "Jund Ansar Allah, or Soldiers of the Partisans of God,", "The short version of my version was I heard they were doing a new \"Friday the 13th,\"", "The techniques they used were all authorized, but the manner in which they applied them was overly aggressive and too persistent,", "Sea World in San Antonio", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "about 50", "the Ku Klux Klan", "1939", "Branford College", "Bolton, Bury, Oldham, Rochdale, Stockport, Tameside, Trafford, Wigan, and the cities of Manchester and Salford.", "husbands", "Malayalam", "August 17, 2017", "a jacket, gloves or a briefcase", "mice", "Hodel", "access to US courts", "Coldplay"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4750306869526232}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.9523809523809523, 0.6, 0.14285714285714288, 0.23076923076923078, 0.8, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.07692307692307693, 0.0, 0.8571428571428571, 0.0851063829787234, 0.14814814814814814, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 0.10526315789473685, 1.0, 1.0, 0.0, 0.1875, 0.0, 0.0, 0.19047619047619047, 0.6666666666666666, 1.0, 1.0, 0.0, 0.13333333333333333, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.22222222222222224, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-3783"], "SR": 0.359375, "CSR": 0.5877976190476191, "EFR": 0.9512195121951219, "Overall": 0.7695085656213705}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "Splash", "Nicola Adams", "copper and zinc", "eagle", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "both shoulders", "Madonna's", "Glasgow", "satellite", "Australia", "Giblet", "Pearson PLC.", "Irish Setter", "American Civil War,", "Loch Lomond", "Jesuit", "Tasmania", "medium-sized", "capital of China", "Harrisburg", "mink mink,", "glockenspiel", "Dr John Sentamu", "national women's soccer team", "Cruella de Vil", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "emperor Charlemagne", "the community", "Russell Crowe", "Theodore Roosevelt", "ACC", "Robin Goodfellow", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "SS United States", "Albert Square", "Newbury", "a book of the Old Testament", "70 million people", "Target Corporation", "Sister, Sister (1982 film)", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "International NGO", "Swamp Fox", "support prisoners' rights and better conditions for inmates, like Amnesty International.", "talk show queen Oprah Winfrey.", "his mother"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6806261446886447}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-4805", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2484", "mrqa_searchqa-validation-11802", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.609375, "CSR": 0.5887784090909092, "EFR": 0.96, "Overall": 0.7743892045454546}, {"timecode": 22, "before_eval_results": {"predictions": ["The flushing action of tears and urine", "1765", "primarily along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "Vicodin", "Rome", "Robert Peary", "pearls", "Utah Territory", "Carrie Underwood", "liqueur liquor", "Nero", "Google", "Langston Hughes", "pain tolerance", "harding", "Tito Puente", "lasso", "unFINISHED", "LST", "prey drive", "David Beckham", "Arturo Toscanini", "economics", "Miracle", "lyceum", "Montenegro", "discus", "thick", "basidiomycota", "James Gandolfini", "Ally McBeal", "Idi Amin", "Deere", "physical", "terracotta", "Plutarch", "Rudy Giuliani", "masa", "half", "the Vikings.", "Mulberry Street", "champs Elysees", "typhoid fever", "fjord", "capital of Bavaria", "Williamsburg", "Jul 13, 2010", "University of tualatin", "The hydrogen peroxide & yeast creates foam, steam & notably causes heat to be given off in this type of 10-letter chemical reaction", "John Knox", "the internal reproductive anatomy", "$657.4 million", "statistical analysis of data, amend interpretation and dissemination of results ( including peer review and occasional systematic review )", "jockey", "Tesco", "Mallard", "Graham Hill", "the Battelle Energy Alliance", "IT products and services,", "debris", "$10 billion", "Bailey, Colorado,"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4877051767676768}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, false, true, true, true, true, true, true, true, false], "QA-F1": [0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.09090909090909091, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6437", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_newsqa-validation-1997"], "SR": 0.4375, "CSR": 0.5822010869565217, "EFR": 1.0, "Overall": 0.7911005434782609}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "the Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "the Atlantic", "cat", "the daughter of Tony Richardson and Vanessa Redgrave", "Switzerland", "The Argonauts", "prometheus", "Altamont Speedway Free Festival", "John F Kennedy,", "Tim Gudgin", "Rosslyn Chapel", "conducting", "multiplayer", "Libya", "khaki", "an igneous rock", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "the Mendip Hills", "Barack Obama,", "the Earth", "Nafea Faa Ipoipo?", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the colony of Suriname", "Justin Trudeau,", "aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations", "Denis Law", "Love Is All Around", "William Golding", "Sally Ride", "Influenza", "Fife", "Money Saving", "Adidas", "the Snark", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "one king, one queen, two bishops, two knights, and eight pawns", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "The Wall Street Journal Europe", "a fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7568167892156863}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-4882", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848"], "SR": 0.71875, "CSR": 0.587890625, "EFR": 0.9444444444444444, "Overall": 0.7661675347222222}, {"timecode": 24, "before_eval_results": {"predictions": ["they may find it necessary to employ limited coercion in order to get their issue onto the table", "the chosen machine model", "Fox", "1997", "a suite of network protocols", "his son, Isaac, and daughter, Rebecca.", "15", "South Africa inflicted the first home series defeat on Australia in almost 16 years", "Pyongyang and Seoul", "he was led away in handcuffs after being sentenced in a New Jersey court for fatally shooting a limo driver on February 14, 2002.", "11", "change course", "Alwin Landry's supply vessel Damon Bankston", "Chaffetz is a conservative Republican married father of three who is sleeping on a cot in his congressional office to save money.", "money or other discreet aid for the effort if it could be made available,", "Sarah Brown", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "environmental", "Italy in the quarterfinals", "Afghan security forces", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "38,", "70,000 or so", "Climatecare,", "E! News", "coach", "Steve Williams", "McDonald's", "she is wise and brave beyond her years.", "Pastor Paula White", "2008", "Diego Maradona", "Dog patch Labs Europe", "The drama of the action in-and-around the golf course", "two", "Itawamba County School District", "the former Massachusetts governor in an ad Sunday in Iowa's The Des Moines Register newspaper.", "EU naval force", "Plymouth Rock", "Liza Murphy,", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "police", "former U.S. secretary of state.", "33", "five", "improve health and beauty.", "contraband", "it is primarily students, the reputed problem, who can best prevent acts of violence on campus.", "Damon Bankston", "Krishna Rajaram,", "Sunday,", "the genocide", "an Irish feminine name", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "Northern Ireland", "radar", "art", "the 16th season for the Minnesota Timberwolves in the National Basketball Association.", "23", "South America", "freestyle", "the Nightingale Museum", "Belief"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5402235331679506}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.3, 1.0, 1.0, 1.0, 0.6153846153846153, 0.0, 1.0, 0.0, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 0.09090909090909091, 0.5555555555555556, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.13333333333333333, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3225806451612903, 0.0, 1.0, 0.25, 0.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6846", "mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3169", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.421875, "CSR": 0.58125, "EFR": 1.0, "Overall": 0.790625}, {"timecode": 25, "before_eval_results": {"predictions": ["The programme is listed in Guinness World Records as the longest-running science fiction show in the world,", "Thomas Savery", "Vicodin", "Eastern crops such as carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago", "separatist campaign", "Eleven", "269,000", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "38 feet", "Eintracht Frankfurt", "150", "a pool of blood beneath his head.", "Russian bombers", "41", "Los Alamitos Joint Forces Training Base", "Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "the Russian air force,", "34", "The eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "greenhouse emissions.", "Amanda Knox's aunt", "\"several pieces of aircraft equipment were at fault or had broken down.\"", "ensuring that all prescription drugs on the market are FDA approved", "new skin, burn fat and boost her energy.", "Tom Baer.", "Pakistan", "The oceans are growing crowded, and governments are increasingly trying to plan their use.", "bikinis", "Brian Mabry", "completely changed the business of music", "Sunday", "60 euros -- $89 --", "American Civil Liberties Union", "\"His treatment met the legal definition of torture. And that's why I did not refer the case\" for prosecution.", "Some truly mind-blowing structures are being planned for the Middle East.", "first name", "he was one of 10 gunmen who attacked several targets in Mumbai", "2006", "In San Diego,", "Debora Harris, Joyce Mims, Tonya Miller, Quithreaun Stokes, Sheila Farrior.", "The Taliban has threatened to kill Bergdahl if foreign troops continue targeting civilians in the name of search operations in Ghazni and Paktika provinces,", "@", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "National Police", "heart", "Hyderabad", "between the Mediterranean Sea to the north and the Red Sea", "to stay, abide", "Las Vegas", "Jackson Pollock", "wye", "Mississippi", "October 4, 1970", "King Duncan", "Brasstown Bald", "the thimble", "taking a walk"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5017613937686984}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, true, true, true, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.8750000000000001, 1.0, 0.5, 0.0, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.29411764705882354, 0.4444444444444445, 1.0, 0.0, 0.07407407407407408, 0.0, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.8, 1.0, 0.1818181818181818, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1434", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-1982", "mrqa_searchqa-validation-11832", "mrqa_searchqa-validation-9476"], "SR": 0.40625, "CSR": 0.5745192307692308, "EFR": 0.9736842105263158, "Overall": 0.7741017206477734}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "pro-democracy activists clashed Friday with Egyptian security forces", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot", "Hong Kong's Victoria Harbor", "2002", "six prostitutes and a runaway involved in the drug trade.", "the legitimacy of that race.", "think about saving the rainforests", "three", "Monday", "Scarlett Keeling", "two years,", "84-year-old", "regulators in the agency's Colorado office", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify. Military commission judges also will be able to establish the jurisdiction of their own courts.", "July", "The poster boy of Indian action films", "Graham's wife", "\"against people who independent of their race, religion, ethnicity, social condition etc. accepted money and put themselves at the service of the army in an area that is the object of military operations.\"", "\"disagreements\" with the Port Authority of New York and New Jersey,", "September,", "Michelle Rounds", "James Newell Osterberg", "strangulation and asphyxiation and had two broken bones in his neck,", "Phil Spector", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "Izzat Ibrahim al-Douri,", "dependable Camry", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March.", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "a Yemeni cleric and his personal assistant,", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "the repeal of the military's \"don't ask, don't tell\" policy", "military veterans", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units", "one", "Matt Monro", "Detective Inspector William Edward \"Jack\" Frost,", "the innermost digit of the forelimb", "1988", "25 million", "Peoria, Illinois", "Honolulu", "frogs", "Cordelia", "Ottoman Empire"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6517094017094017}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, false, true, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.5, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-1875", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-4905", "mrqa_hotpotqa-validation-5856", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.59375, "CSR": 0.5752314814814814, "EFR": 1.0, "Overall": 0.7876157407407407}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "John Dillinger,", "what caused the collapse of the building which contained the city's historical archives,", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen", "a government-run health facility that provides her with free drug treatment.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Angels", "eight Indian army troopers, including one officer, and 17 militants,", "There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "in a Starbucks this summer.", "BADBUL", "98", "2008", "near the Somali coast", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "Swat Valley,", "South Dakota State Penitentiary", "Iran", "last month's Mumbai terror attacks", "\"Buying a Prius shows the world that you love the environment and hate using fuel,\"", "in July", "103 children that a French charity attempted to take to France from Chad for adoption", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "Scardia", "fractured pelvis and sacrum", "Wednesday", "abduction of minors", "gun", "Jeanne Tripplehorn's", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "Missouri", "Vermont", "beta blockers"], "metric_results": {"EM": 0.6875, "QA-F1": 0.788623962842713}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5333333333333333, 0.3636363636363636, 0.4444444444444445, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.9090909090909091, 1.0, 0.08333333333333333, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-436", "mrqa_hotpotqa-validation-4117"], "SR": 0.6875, "CSR": 0.5792410714285714, "EFR": 1.0, "Overall": 0.7896205357142857}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "rule", "1981", "forgery and flying without a valid license,", "\"I wanted to shove it up that black a--.\"", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul", "Genocide Prevention Task Force.", "shoot down the satellite", "the European Commission", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "13", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has,\"", "Anil Kapoor.", "the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "The Rosie Show", "Form Design Center.", "collaborating with the Colombian government,", "Christianity and Judaism,", "the Dalai Lama's", "Russia", "around 8 p.m. local time Thursday", "Passers-by", "one day,", "executive director of the Americas Division of Human Rights Watch,", "750", "at least 300", "Matthew Fisher", "The Ski Train", "Big Brother.", "Ozzy Osbourne", "AbdulMutallab,", "some U.S. senators", "inconclusive", "about 5:20 p.m. at Terminal C", "environmental and political events.", "$250,000", "byproducts emitted during the process of burning and melting raw materials.", "School-age girls", "5,600", "a million", "Sen. Arlen Specter", "Deutschneudorf,", "bill that would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "a deceased organ donor,", "bragging about his sex life", "a vertebral column ( spine )", "January", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "the Royal Festival Hall", "Douglas Hofstadter", "The Dark Tower series", "American", "Little Women", "Castle Rock", "anchovies"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7570735329736689}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.9565217391304348, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.125, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9743589743589743, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9810", "mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_hotpotqa-validation-4809", "mrqa_hotpotqa-validation-5376"], "SR": 0.671875, "CSR": 0.5824353448275862, "EFR": 0.9047619047619048, "Overall": 0.7435986247947455}, {"timecode": 29, "before_eval_results": {"predictions": ["downward pressure on wages", "poison", "438,000", "Erick Avari, Michael McKean, Amy D. Jacobson,", "coaxial", "Pakistan A", "Everbank Field.", "7 members appointed by the chief executive", "the German Campaign of 1813", "John Churchill,", "1965", "Paris", "fifth", "Culiac\u00e1n, Sinaloa", "seven", "Province of Syracuse", "1963", "coca wine", "puzzle", "Knoxville, Tennessee", "Washington, D.C.", "Gal\u00e1pagos giant rat", "Tom Kartsotis", "2017", "Wayman Tisdale", "Mexico", "Srinagar", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Shohola Falls", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Major Charles White Whittlesey.", "The Indigenous peoples of Florida", "Virginia", "NBA Slam Dunk Contest", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "a field in Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes", "IB Diploma Program and the IB Career - related Program for students aged 15 to 18", "Richard Parker", "the southernmost tip of the South American mainland", "Cecil B. De Mille", "allergic reaction", "Peter Townsend,", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist", "Russia", "peel and devein shrimp before putting on a BBQ", "Australia"], "metric_results": {"EM": 0.578125, "QA-F1": 0.647666742979243}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, false, true, true, false, true, false, true, false, true, false, false, true], "QA-F1": [0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.5, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.15384615384615383, 1.0, 0.0, 0.2222222222222222, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_squad-validation-8164", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-708", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585", "mrqa_searchqa-validation-6793"], "SR": 0.578125, "CSR": 0.5822916666666667, "EFR": 1.0, "Overall": 0.7911458333333333}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "deforestation", "Prussian army general, adjutant to Frederick William IV of Prussia", "London", "Dave Thomas", "a farmers' co-op", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations.", "ten years of probation", "In Pursuit", "Bolton", "The Frost Report", "Kansas City crime family", "Dirk Werner Nowitzki", "the Cecil B. DeMille Award honoree", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E.", "New Jersey", "Norse mythology", "86,112", "Celtic", "Ouse and Foss", "United States and Canada", "British comedian", "Apatosaurus", "1885", "American", "Frank Thomas' Big Hurt", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "New York City.", "The Seduction of Hillary Rodham", "2005", "Lambic", "Massive Entertainment", "Argentina", "Larry Alphonso Johnson Jr.", "Michael Edward \" Mike\" Mills", "veto power", "Joseph E. Grosberg", "Chelsea Does", "the city proper", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "New York", "discus", "Aston Villa", "2005", "228 people", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.609375, "QA-F1": 0.723967803030303}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-672", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.609375, "CSR": 0.5831653225806452, "EFR": 1.0, "Overall": 0.7915826612903226}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "a short story centering on the thoughts of a... At lunch one day, he ignores his mother when she asks him to pass a plate.", "Log Ride", "a Senator from Iowa", "A People's History of the United States", "Nassau", "a mollusk", "HIV", "Martin Van Buren", "a network of seven Shinkansen passenger", "Rigoletto", "aardwolf", "Beijing", "Sir Roger Gilbert Bannister", "his first NHL point with an assist on a Dan Hamhuis goal against", "Death Valley", "Yves Saint Laurent", "Unlike horns, antlers are shed each year.", "Fortinbras", "the fleet", "Anna Mary Robertson Moses", "a \"Lunar\" Naoko Takeuchi creation", "Pompey's wife", "Dan Brown", "Spectacled bear", "a tornado", "Gilson Lavis", "Monty Python and the Holy Grail", "negative electrode", "(Milton) Berle", "George Herbert Walker Bush", "Patrice Lumumba", "a lunar module", "Santiago de la Nueva Extremadura", "Dan Marino", "Mars", "clownfish", "E = mc2", "Guru Pitka", "Las Vegas.", "millet", "a butterfly", "A Connecticut Yankee in King Arthur's Court", "a chimpanzee", "Baja California", "Soothsayer", "an Israeli ultranationalist", "Saul", "Gettysburg National Military Park", "Jack Gleeson", "Plank", "Buddhism", "Jean Bernadotte", "Portugal", "John Mayall, Cyril Davies, Long John Baldry and Alexis Korner", "Johnson & Johnson", "acidic bogs", "20 March to 1 May 2003", "has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\"", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "12.3 million people worldwide"], "metric_results": {"EM": 0.5, "QA-F1": 0.5690492365424431}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, false, false, true, true, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, true, false, true, true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.17391304347826084, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.08333333333333333, 0.42857142857142855, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-6655", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-12657", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-1602", "mrqa_searchqa-validation-4905", "mrqa_searchqa-validation-13033", "mrqa_triviaqa-validation-4765", "mrqa_hotpotqa-validation-187", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-3574"], "SR": 0.5, "CSR": 0.58056640625, "EFR": 1.0, "Overall": 0.790283203125}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62", "Herbert Henry Asquith", "40", "Libya", "Shania Twain", "Hillsborough", "glucagon", "The New York Yankees", "rapid eye movement", "green, red, white", "Ann Dunham", "Saddam Hussein", "French", "Jim Branning", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New", "Sarah Ferguson", "Mercury", "The wattage of an electrical component", "Peter Butterworth", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "Rio de Janeiro", "optimism", "aged 75 or older", "Jennifer Lopez", "1664", "Eurythmics", "P Baigneres", "Downton Abbey", "Martina Hingis", "septs", "cyclops", "The Woodentops", "Michael Miles", "Sheryl Crow", "Gulliver's Travels", "piers", "Italy", "The Streets", "Appalachian Trail", "a black Ferrari", "a branch of mathematics", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "The Campbell Soup Company", "Kirkcudbright", "the soldiers", "cortisone.", "the United States can learn much from Turkey's expertise on Afghanistan and Pakistan.", "Jennifer Aronofsky", "a typeface", "lungs"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6102163461538461}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.33333333333333337, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-778", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-14318", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.546875, "CSR": 0.5795454545454546, "EFR": 1.0, "Overall": 0.7897727272727273}, {"timecode": 33, "before_eval_results": {"predictions": ["hymns", "deadly explosives", "Knutsford", "insulin", "a Caesar salad", "Hudson Bay", "florida", "allergens like molds, pollen and animals", "stanley", "Asterix", "Brighton", "Belfast", "wind", "fire insurance", "Robin Hood's A Holy Grail", "West Point", "Andy Warhol", "Spain", "James Murphy", "smoky bay", "the solar system", "potatoes", "Moldova", "Mitsubishi A6M Zero Fighter", "the Dartford Warblers", "fridericus Franciscus", "Estimate", "clare", "clumbum", "pet Sounds", "Madness", "Buxton", "Discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "luzon", "beaver", "Mel Blanc", "a dog", "clement", "Ellen DeGeneres", "phil Woolas", "5000 meters", "racing", "casein", "Newfoundland and Labrador", "crow", "Yellowstone National Park", "St. Francis Xavier", "luzon", "Hugh Laurie", "Buddhism", "Guy Berryman", "Ohio", "Port Melbourne", "\u00c6thelred I", "Scarface", "forgery and flying without a valid license,", "Group D,", "Liza Murphy", "Spock", "Astana", "Andorra, Belgium, Germany, Italy, Luxembourg"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5760416666666667}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2399", "mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-786", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-6154", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-1699", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-11382"], "SR": 0.53125, "CSR": 0.578125, "EFR": 0.9333333333333333, "Overall": 0.7557291666666667}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business", "tundras tundra", "Bologna, Italy", "George Santayana", "opossum", "Alice Cooper", "beta-Blockers", "trumpet", "Peter Kay", "a person", "shildon", "appalachian mountain range", "MS Herald of Free Enterprise", "ballet", "philippine", "snakes", "lizard", "Blackburn", "man Without a Star", "The Mystery of Edwin Drood", "pommel horse", "bird", "Dick Van Dyke", "egrement", "manhunt", "Francisco de Goya", "Medea", "philipp pertin", "Canada", "ink", "pears soap", "Some Like It Hot", "mull", "Ireland", "Mike Meyers", "hippocampus", "plutonium", "magma", "Jules Verne", "welcome", "Iceland", "Spain", "shrek", "26 miles", "Cleveland Brown", "heston Blumenthal", "One Direction", "snakes", "Jupiter", "Stringer Davis", "Charles Lindbergh", "September 2001", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "stoneware", "Pittsburgh", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "ballet", "Howard Carter"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6034722222222222}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-5109", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-1530", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.546875, "CSR": 0.5772321428571429, "EFR": 1.0, "Overall": 0.7886160714285715}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "John Forster", "Matlock", "American Civil War", "armageddon", "beetles", "Arafura Sea", "The Labyrinth", "Tigris", "Bavarian Forest", "to make wrinkles in one's face", "Spain", "Carousel", "bullfighting", "Mike Brady", "Tenor", "alpo", "fidelio", "Guys and Dolls", "Julian Fellowes,", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "ghanians", "eddisbury", "G. Ramon", "jane merman", "rachmaninoff", "Finland", "massive stars", "Mille Miglia", "caves", "Bill Haley & His comets", "silver", "Muriel Spark", "happy birthday to You", "seven", "opossum", "pickwick", "presliced bread", "Saga Noren", "raven", "jordan", "genetically engineered", "jane abelsons", "Etruscans", "Ken Burns", "grosvenor crescent", "Heather Stanning and Helen Glover", "Pyotr Ilich Tchaikovsky", "Mujib,", "Sagittarius", "Donna", "season four", "the atrioventricular node", "Lee Sun-mi", "tomato", "November 5, 2002", "problems with the way Britain implements European Union employment directives.", "L'Aquila earthquake", "March 24,", "Duke of Edinburgh", "equinox", "Pocahontas"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5447916666666667}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, false, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5537", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3182", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_naturalquestions-validation-1091", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-1247", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.46875, "CSR": 0.57421875, "EFR": 1.0, "Overall": 0.787109375}, {"timecode": 36, "before_eval_results": {"predictions": ["Americans", "Kim", "city of acacias", "branson", "Gordon Ramsay", "moan city", "joan kennie", "sulfur dioxide", "Margot", "ringway", "Portuguese", "travelocity", "The Avengers", "usaresborough", "comets", "comets", "us", "rapeseed", "Tina Turner", "comets comets", "duttlenheim", "Bolivia", "joan donne", "Uranus", "Rio Grande", "us", "marty crawford", "ethiopia", "jane crawford", "king mecklenburg-Schwerin", "One Foot in the Grave", "joan crawgli", "peter evison", "George Santayana", "stalls", "borowdale", "crackerjack", "muy Reverendo se\u00f1or fray torquemada", "daul barenboim", "Canada", "rum and cola", "seattlepi.com", "ghee", "George III", "joan crawford", "hyperbole", "newpatrick", "June", "thumderbirds", "Ceylon", "screwdrivers", "the Kansas City Chiefs", "G minor", "My Summer Story", "1974", "The Outsiders", "Amberley Village", "lack of a cause of death and the absence of any soft tissue", "President Obama", "Elisabeth,", "Ci-xi", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4994791666666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.5, 1.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-6749", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-4817", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-6678", "mrqa_triviaqa-validation-5196", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-2834", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-422", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120"], "SR": 0.4375, "CSR": 0.5705236486486487, "EFR": 0.9444444444444444, "Overall": 0.7574840465465466}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "potential of hydrogen", "the roofs of the choir side - aisles", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "hyperarousal, or the acute stress response", "49 cents", "1876", "geologist James Hutton", "17.69278 \u00b0 N 17.44667 \u00b0 W", "joy of living", "420", "George Strait", "sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "British Columbia, Canada", "Los Angeles", "February 10, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "By 1770 BC", "Niveditha, Diwakar, Shruti", "two", "John C. Reilly", "DNA nucleus", "Anakin and Obi - Wan Amidala", "Travis Tritt and Marty Stuart", "1976", "Bee Gees", "Matt Czuchry", "Pradyumna", "1902", "Isle Vierge", "Psychomachia, '' an epic poem written in the fifth century", "the New Jersey Devils", "two", "0.30 in ( 7.6 mm )", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Lisa Stelly", "the Hudson Bay", "France", "Prussia", "dumbo", "purple", "Charles Guiteau", "Gettysburg Address", "iTunes, iTunes Radio, and iTunes Music", "$273 million", "India", "Al Nisr Al Saudi", "Desperate Housewives", "Cannonball Run", "Morelos", "Tuesday"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6987947580978271}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.3846153846153846, 0.0, 0.0, 1.0, 0.787878787878788, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.4, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.07272727272727272, 1.0, 0.5454545454545454, 1.0, 0.3333333333333333, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-5082", "mrqa_triviaqa-validation-7642", "mrqa_hotpotqa-validation-5119", "mrqa_newsqa-validation-2554", "mrqa_searchqa-validation-2335"], "SR": 0.578125, "CSR": 0.5707236842105263, "EFR": 0.9629629629629629, "Overall": 0.7668433235867447}, {"timecode": 38, "before_eval_results": {"predictions": ["Isaac Newton", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in positions Arg15 - Ile16", "Joseph M. Scriven", "Lady Gaga", "Chicago metropolitan area", "the president", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "Notts County", "nobiliary particle", "Stephen A. Douglas", "1984", "a loanword of the Visigothic word guma `` man ''", "Pakistan", "21 February", "Tagalog or English", "Bryan Cranston", "the thylakoid membranes", "at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "Wake County", "December 1922", "18 Divisional Round", "602", "average energy of 251 keV", "between $10,000 and $30,000", "the Sicob show in Paris", "1931", "University of Oxford", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "The Southern Cause", "Randy", "the Infamy Speech of US President Franklin D. Roosevelt", "Joseph Stalin", "into the intermembrane space", "a divergent tectonic plate boundary", "Idaho", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "Sir John Major", "roddy doddy dino", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below", "General Motors'", "David McCullough", "a science fiction novel", "CERN", "saudade"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6062565253374077}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 0.09523809523809525, 0.0, 1.0, 0.5, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8666666666666666, 1.0, 0.2666666666666667, 0.0, 0.4, 1.0, 0.0, 0.32, 0.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_triviaqa-validation-5582", "mrqa_newsqa-validation-3486", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.53125, "CSR": 0.5697115384615384, "EFR": 0.9666666666666667, "Overall": 0.7681891025641026}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "active osmotic water absorption", "Philippe Petit", "September 1980", "January 2004", "southwest and along the Yangtze", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "heavy metal", "Set six months after Kratos killed his wife and child,", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "XXXX", "Gestaltism", "83", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Cymbre Walk", "Richard Crispin Armitage", "Don Cook", "Dirk Benedict", "Bonnie Aarons", "either late 2018 or early 2019", "diffuse interstellar medium ( ISM ) of gas and dust", "the Court declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "irstjen Nielsen", "Charles Sherrington", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "1960s", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Ariel Winter", "Mark Jackson", "Michael Buffer", "one faith, one baptism, one God and Father of all, who is over all and through all and in all", "quite far, we built sets, and they spend a lot of time in a forest", "the federal government", "New England", "Cody Fern", "the nature of Abraham Lincoln's war goals", "prophets and beloved religious leaders", "about 0.04 mg / L several times during a day", "Juan Manuel de Ayala", "Prophet Joseph Smith, Jr.", "funny Folks", "1909", "John Duigan", "179", "Princess Diana", "Mikkel Kessler", "curfew", "Pearl", "shark", "Fast Food Nation", "ABBA"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6193926380328589}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.4210526315789474, 0.967741935483871, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.47058823529411764, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.17142857142857143, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-302"], "SR": 0.484375, "CSR": 0.567578125, "EFR": 1.0, "Overall": 0.7837890625}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants,", "Joan Rivers", "\"You're The One That I Want\"", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "Zimbabwe President Robert Mugabe", "2004", "NATO", "Switzerland", "Monday", "second", "\"Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "\"it is impossible to turn back the tide of globalization.\"", "Clifford Harris,", "Ensenada, Mexico", "Michael Holmes.", "$627", "41,", "Adenhart", "a strict interpretation of the law,", "Derek Mears", "Sylt", "about 30 miles southwest of Nashville", "Tuesday afternoon", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "on the headstones to show that a visitor had been to the grave.", "Ali Bongo", "Mandi Hamlin", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Two pages -- usually high school juniors who serve Congress as messengers", "Brazilian supreme court judge", "Derek Mears", "Operation Crank Call", "help rebuild the nation's highways, bridges and other public-use facilities.", "East Java", "St. Louis, Missouri.", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2007", "P.V. Sindhu", "Mexico", "Snickers candy bars", "monoceros", "capone", "Anaheim, California", "uncle", "Bergen", "embalming", "Cartagena", "a graphical user interface", "a two - layer coat"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6584393929114932}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.4, 0.3870967741935484, 0.07142857142857142, 1.0, 0.25, 0.0, 1.0, 1.0, 0.6666666666666666, 0.29629629629629634, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 1.0, 0.0, 0.9523809523809523, 0.3076923076923077, 0.4, 1.0, 1.0, 0.9411764705882353, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2031", "mrqa_newsqa-validation-3794", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.46875, "CSR": 0.5651676829268293, "EFR": 1.0, "Overall": 0.7825838414634146}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1998", "displacement", "the modern state system", "Megan Park", "the currency used by the institutions of the European Union", "Kate Walsh", "September 14, 2008", "American country music artist Trace Adkins", "on Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "international aid as one of the largest financial inflows to developing countries", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million customer accounts", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "In England, births were initially registered with churches, who maintained registers of births", "the Dutch figure of Sinterklaas", "Yuzuru Hanyu", "to provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "collect menstrual flow", "pigs", "General George Washington", "Spanish", "Howard Ellsworth Rollins Jr.", "an integral membrane protein that builds up a proton gradient across a biological membrane", "the sinoatrial node", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements )", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Jos Plateau", "Missouri River", "the right to be served in facilities which are open to the public", "frontal lobe", "10 June 1940", "at Tandi, in Lahaul", "alberich", "ear", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "on September 21.", "Denver, Colorado.", "a district advisory council, a neighborhood group that looks at local needs and passes on its assessments to the provincial government.", "the CTU", "King Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.59375, "QA-F1": 0.700719246031746}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518"], "SR": 0.59375, "CSR": 0.5658482142857143, "EFR": 0.8846153846153846, "Overall": 0.7252317994505495}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "asphyxia", "in Middlesex County, Province of Massachusetts Bay", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "its population", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "to bring", "Field Marshal Paul von Hindenburg", "Ceramic art", "Russia", "Covington, Kentucky", "New Mexico", "to condense the steam coming out of the cylinders or turbines", "December 15, 2017", "on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive", "L.K. Advani", "differential erosion", "Glenn Close", "the long form in the Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "electricity generation, power distribution, and power transmission on the island", "Tsetse fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "compasses", "Charlotte Thornton", "the Northeast Monsoon or Retreating Monsoon", "March 16, 2018", "President Lyndon Johnson", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "by producing an egg through parthenogenesis", "1926", "Durban, South Africa", "starting in 1560s", "Frankie Muniz", "Lou Rawls", "between 1765 and 1783", "Alfheim", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "won two", "prostate cancer,", "wyvern", "a little lord fauntleroy", "a key", "yellow"], "metric_results": {"EM": 0.515625, "QA-F1": 0.668686964144813}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.5384615384615384, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 0.9, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.14814814814814814, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 0.9767441860465117, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.515625, "CSR": 0.5646802325581395, "EFR": 0.8709677419354839, "Overall": 0.7178239872468117}, {"timecode": 43, "before_eval_results": {"predictions": ["2003", "February 27, 2007", "a'pick yourself up and dust yourself off and keep going ', female - empowerment song", "to provide jobs for young men", "Lynne", "2013", "le Roi d'Irlande", "Miami Heat", "1981", "After World War I", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Augustus Waters", "Pierre Mallet", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home three days earlier", "Edward Kenway ( Matt Ryan ), a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus", "rootlets", "Alex Ryan", "a habitat", "2018", "Advanced Systems Format ( ASF )", "100", "Toledo", "embryo", "the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "in Paradise, Nevada", "Alicia Vikander", "in late January or early February", "Ashoka", "the name of a work gang", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority", "Bumblebee", "into the Christian biblical canon", "New England", "AMX - 50", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "February 7, 2018", "New York City", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "in the southwestern part of the island", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "winter", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bonauto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "The federal government has set aside nearly $2 billion in stimulus funds to clean up Washington State's decommissioned Hanford nuclear site,", "\"peregruzka\"", "Michigan.", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.5, "QA-F1": 0.6311664180645442}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.7741935483870968, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 0.888888888888889, 1.0, 0.0, 0.5714285714285715, 0.4705882352941177, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.9189189189189189, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.3225806451612903, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-2425", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977"], "SR": 0.5, "CSR": 0.5632102272727273, "EFR": 1.0, "Overall": 0.7816051136363636}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "lightweight aluminum foil", "Laurel, Mississippi", "about the outdoors, especially mountain-climbing.", "Indianola", "life insurance", "Jean Baptiste Point DuSable", "1992", "Cher", "Alabama", "Jim Harrison", "Toronto", "Tomorrowland", "fennec fox", "United States Army", "stop motion animation", "Jean Acker", "4,530", "Leucippus", "Caesars Entertainment Corporation", "Mary Ellen Mark", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "the Northrop F-15 Reporter", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony awards", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "OutKast", "Richard Street", "Zaire", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer", "South America", "2006", "perjury", "Operation Overlord", "Mary Elizabeth Hartman", "over 9,000", "Malcolm Terris", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "Alamodome in San Antonio, Texas", "Carrie", "a tab", "Kent", "almost 9 million", "Bahrain", "2008", "terrorism", "Moses", "Chapter 5", "Wilson Pickett"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6050538003663004}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.8, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5593", "mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-8652", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.515625, "CSR": 0.5621527777777777, "EFR": 0.967741935483871, "Overall": 0.7649473566308244}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "1903", "the power to regulate interstate commerce", "Naomi Wallace", "McLaren-Honda", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "King James II of England", "God Save the Queen", "526", "Scotland", "\"rock and roll\"", "Gesellschaft", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Sully", "Manhattan Project", "the Asia-Pacific War", "Romantic", "Air Chief Marshal Hugh Caswall Tremenheere Dowding, 1st Baron Dowding", "AMC Entertainment Holdings, Inc.", "New York Islanders", "fennec", "1978", "six different constructors taking the first six positions", "French", "Pacific Place", "the Female Socceroos", "\"Bad Blood\"", "\"SexyBack\"", "about 5320 km", "Giuseppe Verdi", "Chief Minister of Tamil Nadu", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Faisal Qureshi", "the British Army", "power directly or elect representatives from among themselves to form a governing body, such as a parliament.", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Frances Ethel Gumm", "Switzerland", "Model T", "NATO's International Security Assistance Force", "2,000", "Cyprus", "Maroon 5", "Saudi Arabia", "Sabo", "two"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6444636093073594}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, false, true, false, true, false, false, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.09090909090909091, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-2129", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_triviaqa-validation-6575", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-8327", "mrqa_searchqa-validation-2897"], "SR": 0.5625, "CSR": 0.5621603260869565, "EFR": 0.9285714285714286, "Overall": 0.7453658773291926}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican", "1996", "5", "Greenland sharks", "The Word", "Abraham Lincoln's", "St Jude Thaddeus", "Anthoonij van Diemenslandt", "death penalty", "xerophyte", "Jackie Robinson", "Staten Island", "Dian Fossey", "MI5", "Harrow", "creme anglaise", "onions", "pork", "curling", "Victoria Coren Mitchell", "Gettysburg", "Chile\u2019s best wine producing regions", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck Schumann", "Mercury", "Venus", "Barack Obama", "Canada's Liberal Party", "Bologna Song Lyrics", "Castro and the Cuban Revolution", "Bowie", "Stephen King", "Hinduism", "caryatid", "feet", "most of its land in North America", "Mary Poppins", "glyn Jones", "Port Moresby", "Connecticut", "Quentin Blake", "whooping cough", "The Sun", "(1939\u20131945)", "kosher", "2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1944", "umpire Daniel Nestor, from Canada,", "Jeddah, Saudi Arabia,", "death", "Beatrix Potter", "George Stephanopoulos", "How to Keep Young Mentally", "\"Divide the living child in two"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5770833333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-1660", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-1584", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.515625, "CSR": 0.5611702127659575, "EFR": 1.0, "Overall": 0.7805851063829787}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "allergic reaction", "david Beckham", "florida", "Runic", "florida", "cricket", "Max Planck", "rotherham United", "heat transfer", "Misery", "Styal", "stately", "blind beggar", "Brainwash", "floroy Burrell", "parlophone", "Wild Atlantic Way", "john david hicks", "oscar", "noddy", "Lackawanna Six", "Brazil", "oscar", "muezzin", "a window", "a ship", "madame", "Apollo 11", "flit gun", "Nikola Tesla", "opham hurdle", "evita", "albino sperm whale", "roddy", "East Fife", "st Pancras International Station", "social environment", "sliced bread", "Dilbert", "mayor of casterbridge", "nunc dimittis", "francophone", "phrixus", "h Burgundy", "cribbage", "oscar hong", "Johannesburg", "France", "muffin man", "Seoul", "Prince James, Duke of York and of Albany", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Galveston, Texas,", "carrier based in Texas.", "Robert Frost", "King Henry VIII", "Pillsbury", "Turbo Charged Prelude"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6020833333333334}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-555", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-6813", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-4012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.5625, "CSR": 0.5611979166666667, "EFR": 0.9642857142857143, "Overall": 0.7627418154761905}, {"timecode": 48, "before_eval_results": {"predictions": ["highway sixty-six", "sesame Street", "minced tomatoes", "cabbage", "Tasmania", "jimmy", "fleece", "Ash tree", "opossum", "New Zealand", "jug band", "100-point", "auguric goldfinger", "1983", "pike", "mongols", "1875", "chief tax collectors", "pennies", "jimmy", "Wars of the Roses", "bagram", "maggie Gilkeson", "Chrysler", "fur hat", "mrigg", "arts", "the United States", "Brazil", "pei Tang", "biathlon", "victoria", "Charlie Chan", "Vienna", "white", "jaws", "Paul Rudd", "robits", "Scottish flag", "paul Eddington", "orson welles", "hindu Wisdom", "menorah", "post-impressionist", "texas", "Super Bowl Sunday", "long pole", "little Tommy Stout", "marmole king", "azalea", "Irish", "Chuck Noland", "Virginia", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park, Kenya", "2010", "Vancouver, British Columbia,", "10 below", "100 to 150", "silver", "the American Kennel Club", "Omaha", "George Jones"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5133680555555555}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-7507", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-1594", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-263", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-2158", "mrqa_hotpotqa-validation-2352", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-16460", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.4375, "CSR": 0.5586734693877551, "EFR": 0.9722222222222222, "Overall": 0.7654478458049887}, {"timecode": 49, "before_eval_results": {"predictions": ["jennifer henderson", "shanghai", "alcohol", "frenchman", "dutch", "daniel boone", "Thames Street", "jennifer roosevelt", "satyrs", "crabs", "la boheme", "maurice", "scapulae", "garrick club", "Lackawanna 6", "barnaby rodde", "britten", "the American Civil War", "dark", "Cybill Shepherd", "Jimmy Robertson", "Florence", "saint Basil", "veruca salt", "severn", "doris Pilkington Garimara", "South Africa", "droughts", "guinea", "c Clement Attlee", "Wars of the Roses", "chemnitz", "dutch", "trout", "an ap\u00e9ritif", "jennifer adan", "guinea", "shanghai", "hair loss", "sprint", "charles edward springall", "robin hood", "Chris Martin", "flinstone", "george gently", "rugby", "honda", "scotland", "11", "tobacco", "cows", "free floating", "Tom Selleck", "New Orleans", "superhuman abilities", "Texas Tech University", "leicestershire, in the East Midlands of England", "Sharon Bialek", "the United States", "that the National Guard reallocated reconnaissance helicopters and robotic surveillance craft to the \"border states\" to prevent illegal immigration.", "George Babbitt", "Oklahoma", "(1970)", "four"], "metric_results": {"EM": 0.3125, "QA-F1": 0.3919070512820513}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, true, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, true], "QA-F1": [0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-2309", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-2670", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-6840", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_triviaqa-validation-7243", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-3615"], "SR": 0.3125, "CSR": 0.55375, "EFR": 0.9772727272727273, "Overall": 0.7655113636363636}, {"timecode": 50, "UKR": 0.794921875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.865234375, "KG": 0.4875, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "Kansas", "the Docile Don", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland, California", "37", "Tufts University", "Owsley Stanley", "The Late Late Show", "Kongo language", "Lipshitz", "Spanish", "Ted", "1945", "69.7 million litres", "Neneh Mariann Karlsson", "Sunyani", "antelope", "Comodoro Arturo Merino Ben\u00edtez International Airport, Santiago, Chile", "Scotty Grainger", "9", "Prelude", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1898", "Nicolas Winding Refn", "devotional", "Fortunino Francesco Verdi", "Laban Movement Analysis", "Cecily Strong", "Julius Robert Oppenheimer", "invoice, bill or tab", "seasonal television specials, particularly its work in stop motion animation", "nearly 8 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "playback singer", "1901", "Pope John X", "Art Directors Guild's Excellence in Production Design Award", "VAQ-135", "Alex Skuby", "American country music group The Nitty Gritty Dirt Band", "English", "letter of the alphabet", "the U.S. Marshals", "a vessel", "EMI, owner of the recording studios.", "UNICEF", "9 a.m.", "George Byron", "Van Helsing", "Tigrinya", "a long-range missile"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6299107142857142}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, true, true, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false], "QA-F1": [0.8, 0.5, 0.5714285714285715, 0.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-5783", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5030", "mrqa_hotpotqa-validation-5173", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1652", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-217", "mrqa_triviaqa-validation-7487", "mrqa_triviaqa-validation-2358", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.46875, "CSR": 0.5520833333333333, "EFR": 1.0, "Overall": 0.7399479166666666}, {"timecode": 51, "before_eval_results": {"predictions": ["Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143th most populous city in India", "Atat\u00fcrk Museum Mansion", "\"Realty Bites\"", "24 NCAA sports", "Razor Ramon", "Morita therapy", "Forbes", "St. George, Maine", "Kramer Guitars", "Lithuania national team", "International Boxing Federation", "35", "Conservatorio Verdi", "Lester Ben \"Benny\" Binion", "Smoothie King Center", "World Outgames", "homebrewer", "Umberto II", "Presbyterian Church", "neuro-orthopaedic Irish veterinary surgeon", "Hookend Recording Studios in Checkendon, Oxfordshire", "North Sea", "2005", "67,575", "England", "OS DATA", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "English", "Eric Edward Whitacre", "largest Mission Revival Style building in the United States", "180 flights", "George Adamski", "\"Hand of Thrawn\"", "Switzerland", "Rahoneen", "Scunthorpe", "Canadian comedian", "Captain Cook's Landing Place", "Summer Olympic Games", "1936", "1970", "Royal Albert Hall and The Kennedy Center", "Budget Rent a Car", "Japan", "lion", "1959", "Donna Mills", "Is this the feeling I need to walk with / Tell me why I can't be there where you are", "1,149 feet", "bacall", "Blanche and Baby Jane", "maxillae", "AMD", "4.6 million", "Iran,", "tea rose", "John J. Pershing", "Colorado Bulldog", "Rear Window"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5700470102813853}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, false, true], "QA-F1": [0.3333333333333333, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.18181818181818182, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.0, 1.0, 0.125, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1254", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1260", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-1219", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-3576", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_triviaqa-validation-4184", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653", "mrqa_searchqa-validation-3934"], "SR": 0.4375, "CSR": 0.5498798076923077, "EFR": 1.0, "Overall": 0.7395072115384614}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "an organization that pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "non-voters", "3", "up to 100,000", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel", "once again be hosted by Camping World Stadium in Orlando", "Advanced Systems Format ( ASF )", "the Ramones", "Al Pacino", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "the Gospel of Matthew", "30 years after Return of the Wars", "a leonine contract, a take - it - or - leave - it contract, or a boilerplate contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1960", "The British military launched a campaign to capture the Colony of Canada ( part of New France )", "The 1972 Dolphins were the third NFL team to accomplish a perfect regular season, and won Super Bowl VIII", "Columbia River Gorge in the U.S. states of Oregon and Washington", "coercivity", "2010", "malicious software", "Cyndi Grecco", "ingredients", "1900", "dorsally on the forearm", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "Terry Kath", "birch", "one person", "The Parlement de Bretagne", "Microsoft Windows", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "September 1995", "late - September through early January", "currency option", "1623", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas", "the medulla oblongata", "2018", "Gibraltar", "Howard Caine", "May 3, 2005", "Newcastle United", "Harry patch", "Steptoe and Son", "Paul Maskey", "child actor", "Saoirse Ronan", "Revolution Studios", "The Kirchners", "north London rivals Tottenham", "Gordon Brown", "veterans", "yellow", "winter", "Netflix"], "metric_results": {"EM": 0.625, "QA-F1": 0.7109758895967294}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.9500000000000001, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.3137254901960785, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.21052631578947367, 0.4615384615384615, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-961", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-1203", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-10032", "mrqa_triviaqa-validation-4852", "mrqa_newsqa-validation-318", "mrqa_searchqa-validation-1420", "mrqa_searchqa-validation-4527"], "SR": 0.625, "CSR": 0.5512971698113207, "EFR": 0.875, "Overall": 0.7147906839622641}, {"timecode": 53, "before_eval_results": {"predictions": ["Alston", "theory of relativity", "Handel", "Green Acres", "Home Brew", "Clark Coconut Zagnut Candy bars", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Airlines", "her coronation", "Vermont", "Windsor County", "a candy store", "Salmon", "Pudd'nhead Wilson", "Osaka", "the tapir", "France", "Spam", "Dedalus Wagner", "early", "Camembert", "Friday", "The Union Flag", "centaur", "Mentor", "Emile Lahoud", "Manifest Destiny", "Al Gore", "disabilities", "Bali", "Bruce Springsteen", "Germany", "Glucosamine", "Madagascar", "a quick search", "celebration", "busby", "Susan Faludi", "Ice-T", "Al Lang Stadium", "Fidel Castro", "fudge", "Winnie the Pooh", "Laborers' International Union", "goldfish", "auxin", "a dive in which the diver bends in midair to touch the toe, keeping the legs straight, and then straightens out", "yellowtail", "Nitrides of boron & silicon are used to make crucibles", "between the Mediterranean Sea to the north and the Red Sea in the south", "Tokyo", "Zeus", "Van Morrison", "antelopes", "main and regular sodas, 100 percent juices, juice drinks, waters, sports and energy drinks, teas and coffees, and milk-and soy-based beverages", "Rocky Mountain Institute", "21", "a cobblestone-size (10x10 cm ) concrete cube bearing a brass plate inscribed with the name and life dates of victims of Nazi extermination or persecution", "three thousand", "insurgent small arms fire", "about 3,000 kilometers (1,900 miles),", "Lambic"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5899305555555555}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.888888888888889, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-7425", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1007", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-5611", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_searchqa-validation-379", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-7747", "mrqa_hotpotqa-validation-3325", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-3349"], "SR": 0.53125, "CSR": 0.5509259259259259, "EFR": 0.9666666666666667, "Overall": 0.7330497685185184}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "the state legislators of Assam", "in a nearby river bottom", "stems and roots of certain vascular plants", "Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew", "1987", "John F. Kennedy", "in teaching elocution", "Club Bijou on Chapel Street", "seven", "1999", "Rashida Jones", "Hook", "Bush", "tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai", "45 % of the light is in the photosynthetically active wavelength range", "handheld subscriber equipment", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "1998", "Chris Martin", "the Ming dynasty", "the red - bed country of its watershed", "Thomas Jefferson, John Adams and Thomas Paine", "The Intolerable Acts", "National Industrial Recovery Act ( NIRA )", "semi-autonomous organisational units within the National Health Service in England", "Jeff Gillen", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg", "1885", "the 1964 Republican National Convention in San Francisco, California", "the Finch family's African - American housekeeper", "( such as the muscles of the limbs, abdominal, and intercostal muscles ),", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps, McGregor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "the Philippines", "driving Miss Daisy", "Vengeance", "Marine Corps Air Station Kaneohe Bay", "PlayStation 4", "December 31, 2015", "Seminole Tribe", "the Defense of Marriage Act", "BMW Oracle", "the Eiffel Tower", "barnacles", "dog", "gerry adaption of Angels & Demons"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6677961579586342}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 0.19999999999999998, 0.0, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 0.06451612903225806, 1.0, 0.888888888888889, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-892", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.53125, "CSR": 0.5505681818181818, "EFR": 0.9666666666666667, "Overall": 0.7329782196969696}, {"timecode": 55, "before_eval_results": {"predictions": ["king Edward III", "golf", "purple", "aeoline", "ascot", "litas", "loretta nolan", "WrestleMania", "steppenwolf", "chop suey", "roosevelt mcManus", "victoria", "bill", "evevraj Singh", "Saddam Hussein", "New Zealand", "Tyrrhenian", "bacall", "mauritania", "hans lippershey", "Bolivia", "bob Giraldi", "the Mozambique Channel", "ash", "Edward VII", "christopher Cranmer", "testicles", "Guatemala", "muralitharan", "Caroline Aherne", "Byron", "s\u00e8vres", "mau", "kipps: The Story of a Simple Soul", "frankincense", "Serena Williams", "capital of togo", "Pegida", "wagner", "Utrecht", "1709", "maurford", "kansas", "miles bates", "vine", "skylab", "ostrich", "Hugh Quarshie", "a stern tube", "Batman", "korea", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Lynwood", "Linux Format", "Stage Stores", "26", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Shanghai", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6119791666666666}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, true, false, false, true, false, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-6552", "mrqa_triviaqa-validation-1051", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-3596", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-2148", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-4809", "mrqa_triviaqa-validation-6700", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-4792", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-4261"], "SR": 0.578125, "CSR": 0.5510602678571428, "EFR": 0.8518518518518519, "Overall": 0.7101136739417988}, {"timecode": 56, "before_eval_results": {"predictions": ["ireland", "bolivia", "Telegraph Media Group Limited", "the liver", "portugal", "Drunk Crosswords", "Galway", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "george elosevelt", "north-west corner of the central business district", "meatloaf", "benazir butto", "bowler", "Sam Mendes", "Tara king", "way back Attack", "ninth", "business", "godiva", "darius denesh", "mEXICO", "river Towy", "middle", "1984", "wyoming", "three", "shinto", "Sussex", "george IV", "Mickey Mouse", "oxygen", "prince albert", "toledo", "come quietly", "dodoma", "radiohead", "Wilson", "loch ness", "pyrenees", "south korea", "gelatine", "new guinea", "gulf of Aden", "ireland", "a\u00e9roport roissy-Charles de Gaulle", "sankt moitz", "the French Revolution", "old Kent road", "one of the Vikings nine realms", "An acetate / \u02c8\u00e6s\u026ate\u026at / is a salt formed by the combination of acetic acid with an alkaline, earthy, or metallic base", "iron", "creation of the office in 1789", "Chris Pine", "Yorgos Lanthimos", "Tottenham ( ) or Spurs", "Unseeded Frenchwoman", "off Somalia's coast.", "Shanghai", "peacock", "Pershing", "governess", "covering a large portion of rural Maine, published six days per week in Bangor, Maine"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5631944444444444}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.11111111111111112]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-4374", "mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-4296", "mrqa_triviaqa-validation-4984", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-5432", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4370", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_hotpotqa-validation-4052"], "SR": 0.484375, "CSR": 0.549890350877193, "EFR": 1.0, "Overall": 0.7395093201754386}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "demi holborn", "rennet", "lee", "Rudolf nureyev", "Jessica", "placebo", "weather", "lake placid", "papal state", "contractions", "david lee", "st Cecilia", "karolina mladenovic", "morecambe & wiseman", "tommy lee jones", "butcher", "cowpox", "fox hunting", "Stockholm", "France", "so Far Away", "anosmia", "celestial rocket", "chemnitz", "rue", "yellow", "raven", "caracas", "Quentin Tarantino", "bacoyne", "Spain", "timesigns", "Turandot", "algiers", "highest mountain in Asia", "eat porridge", "Howard Keel", "marriage", "boutros Ghali", "france", "Sinclair Lewis", "southern border", "garden of gethsemane", "decision tree", "3", "Bild", "maurice", "Kristiania", "keirin", "selenium", "vehicles designed for off - road use are known as `` four - wheel drives '', `` 4WDs '', or `` 4 \u00d7 4s ''", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "he was diagnosed with skin cancer.", "Shiza Shahid,", "Perseid meteor shower", "accordion", "bones", "Marky Mark"], "metric_results": {"EM": 0.5, "QA-F1": 0.5828125}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.1, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-5042", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-883", "mrqa_triviaqa-validation-5579", "mrqa_triviaqa-validation-4653", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-7431", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-7268", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-5750", "mrqa_triviaqa-validation-2743", "mrqa_triviaqa-validation-4990", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-4857", "mrqa_naturalquestions-validation-10066", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-16209"], "SR": 0.5, "CSR": 0.5490301724137931, "EFR": 0.9375, "Overall": 0.7268372844827586}, {"timecode": 58, "before_eval_results": {"predictions": ["Frottage", "Jonah", "Hughe", "Constantinople", "Jacqueline Susann", "the Amazon River Basin", "Hudson River", "spinal column", "Boxing Day", "Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "ruby", "scalpels", "Siberia", "James I", "five", "Friday the 13th", "Rotherham", "The Godfather", "vitamin D", "Nostradamus", "jihad", "harpoons", "Mandy Manilow", "finance", "Conrad Hilton Jr.", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "the Battle of Trafalgar", "the bald eagle", "meatball", "Panax", "hurricanes", "Home Improvement", "Kashmir", "Airport", "the Greek alphabet", "new orleans", "a single death", "Ariel", "Harvey Grant", "lethal", "college grants", "emerald", "a dome", "19 July 1990", "Incudomalleolar joint", "Louis XV", "zambia", "mansion house", "senior", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Auckland", "money"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5583333333333333}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, false, true, false, true, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3868", "mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-11218", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-1202", "mrqa_searchqa-validation-7736", "mrqa_searchqa-validation-5458", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-1938", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225"], "SR": 0.484375, "CSR": 0.5479343220338984, "EFR": 0.9696969696969697, "Overall": 0.7330575083461736}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "GTG", "whisky", "Leonard Bernstein", "magnesium", "Pisa", "the Danube", "the albatross", "Seinfeld", "The Smashing Pumpkins", "Syntax", "Ohio State", "William Tecumseh Sherman", "Pakistan", "Theology of God", "Leinster", "Sally Field", "Barbara Cartland", "rum", "a Pringles can", "Paul Hamm", "profundo", "East Siberia", "Nimble", "Tom Hanks", "Clue", "a black magpies", "#5367", "current", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "Marshall", "General Motors", "trade winds", "the United Nations", "silk", "W", "the Unicorn", "Scrabble", "humerus", "The Bodyguard", "Petruchio", "the Philippines", "mushrooms", "Che Guevara", "Yale", "Oscar Wilde", "Aulis", "Dian Fossey", "a map", "an iron -- nickel alloy and some other elements", "ABC", "a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court which gives rise to its judgment", "pear", "Melbourne", "big bopper", "Ringo Starr", "Do Kyung-soo", "Hanna", "Majid Movahedi,", "\"came under fire\" after admitting they learned of the death from TV news coverage,", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.", "valam"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6798924526707235}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.2758620689655173, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.47058823529411764, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-8167", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-116", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-5632", "mrqa_searchqa-validation-10544", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2745", "mrqa_triviaqa-validation-6487"], "SR": 0.59375, "CSR": 0.5486979166666667, "EFR": 1.0, "Overall": 0.7392708333333333}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Carlos Almeida da Cunha", "four", "Sippin' on Some Syrup", "Diary of the Dead", "Arnold M\u00e6rsk Mc- Kinney M\u00f8ller", "Los Angeles", "Karl-Anthony Towns", "five", "Charlie Wilson", "Sim Theme Park", "a facelifted 850 saloon", "its riverside location", "1858", "Julie Taymor", "actress", "James Edward Kelly", "Spanish", "Indiana University", "lower Manhattan", "Homeland", "2016", "American Airlines", "green and yellow", "Champion Jockey", "March 2012", "John Mills", "Erinsborough", "2015", "Vladimir Menshov", "The Birds", "Londonderry", "York County", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "25 August 1949", "Savannah River Site", "\u00c6thelwald Moll", "God and the just cause", "Swiss", "Augustus", "World War I", "at age 27", "Clayton Mark's", "five", "Rodney Crowell", "Mendel", "near major hotels and in the parking areas of major Chinese supermarkets", "scales", "d\u00fcsseldorf", "apollon", "Anil Kapoor", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "Arthur E. Morgan III", "quarantina", "Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6386389652014652}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4914", "mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3314", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3132", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-4752", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-1428", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.5625, "CSR": 0.5489241803278688, "EFR": 0.9285714285714286, "Overall": 0.7250303717798594}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaels", "Chicago Bears", "girls aged 11 to 18 in Boston, Lincolnshire, England", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Cartoon Network", "1983", "Rio Ferdinand", "247,597", "2,664", "841", "first and second segment", "Australian Broadcasting Corporation (ABC)", "MG Car Company Limited", "Walt Disney and Ub Iwerks", "1979", "15", "January 23, 1898", "John W. Henry", "Bolton, Greater Manchester", "Argentinian", "Them", "575 acres (2.08 km\u00b2) in Hamilton Village, Hamilton Township, Madison County, New York", "John Snow", "New York and New Jersey campaign", "2013\u201314", "Melbourne Storm", "University of Nevada, Las Vegas", "21", "Dovzhenko", "Friday", "Oklahoma Sooners", "2011", "7pm", "1866", "Gaahl", "Serie B", "1887", "Isabella (Belle) Baumfree", "RAF Tangmere, West Sussex", "North Holland", "Don Bluth", "Golden Calf", "Furious 7", "final of 2011 AFC Asian Cup", "Agatha Christie's Marple", "Mercer", "1951", "35,124", "21 years and 154 days", "March 29, 2018", "Jimmy Flynn", "the Western Bloc ( the United States, its NATO allies and others )", "finger", "Barack Obama", "One Thousand and One", "Long troop deployments", "fuel economy and safety while boosts the economy.", "forcibly drugging", "James Watt", "T.S. Eliot", "Anastasia", "Games"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6758323784059078}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, false, false, false, true, false, true, false, false, false, true, true, true, true], "QA-F1": [0.0, 0.6666666666666666, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.4, 0.3636363636363636, 1.0, 0.0, 1.0, 0.0, 0.1, 0.25, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1187", "mrqa_hotpotqa-validation-5870", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-5180", "mrqa_triviaqa-validation-7564", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129"], "SR": 0.578125, "CSR": 0.5493951612903225, "EFR": 1.0, "Overall": 0.7394102822580645}, {"timecode": 62, "before_eval_results": {"predictions": ["The Dayton Memorial Hall", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode", "Babylon", "a card (or cards) during a card game", "water sprite", "Sean Yseult", "a court which merely holds trials for cases of multiple locations in some rotation", "October 5, 1937", "Hillsborough County", "Charles Nungesser", "Burning Man", "Love Streams", "Group Captain Peter Wooldridge Townsend", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "Somerset County, Pennsylvania", "John Nicholas Galleher", "German", "Gareth Jones", "consulting", "April", "1978", "actor, producer, and director", "Melanie Owen", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "American jewelry designer", "Guns N' Roses", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "The Mountbatten family", "dice", "Kal Ho Naa Ho", "Dungeness crab", "Pendlebury, Lancashire", "25 October 1921", "Canadian comedian", "David Anthony O'Leary", "Stratfor", "Reginald Engelbach", "American", "Black Friday", "Minneapolis", "Jean Erdman", "5.7 million customer accounts", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "r Richard seddon", "the right atrium", "Sitka, Alaska", "to take the Rio Group to a new level by creating the organization.", "\"Now that we know Muhammad is an Ennis man, we will be back,\"", "Bob Bogle", "circumference", "The Hague", "a shooting brake", "2001"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6641376399868248}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2608695652173913, 0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7272727272727272, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-4838", "mrqa_hotpotqa-validation-5074", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-197", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-6338", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-12404"], "SR": 0.5625, "CSR": 0.5496031746031746, "EFR": 0.8571428571428571, "Overall": 0.7108804563492063}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "two weevils", "\"twenty times the value of the sum\"", "from the data set", "Beluga whale", "Nicholas II", "tuna", "Shalom", "Russia's", "a chimp", "The Larry Sanders Show", "mendoza", "Thor", "Saint Albans", "astride", "Borneo", "Versailles", "Shredded", "Raleigh", "whipped cream", "yellowfin", "Macbeth", "Jean-Michel Basquiat", "a song by Led Zeppelin", "War and Peace", "Dutchman", "The Talk of Tv", "outskirts of a small Southern town", "Peter Falk", "John Tyler", "Milwaukee", "a tranfgrelTion", "Wall Street", "sake", "Notre Dame", "Portland", "Charles-Franois de Broglie", "the Indianapolis 500", "Toy Story", "improv", "Sarah Jessica Parker", "13-letter collective name for any & all forms of water", "Nikolai Gogol", "David Hare", "Captain William Bligh", "weaving", "Pope John Paul II", "Greenland", "John", "The Marx Brothers", "watermelon", "Robin Cousins", "the duodenum", "Reverend J. Long", "violin", "a provocative and idiosyncratic feminist\u02bcs", "a mountain peak in the Karakorams 2", "Garrett Morris", "1966", "12 mi east-southeast of Bridgeport", "Susan Atkins", "almost 9 million", "three thousand", "al-Maliki"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6220238095238095}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-6211", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-10738", "mrqa_searchqa-validation-6512", "mrqa_searchqa-validation-1267", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-6528", "mrqa_searchqa-validation-14769", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-16930", "mrqa_searchqa-validation-8527", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-1825", "mrqa_searchqa-validation-9337", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.546875, "CSR": 0.549560546875, "EFR": 1.0, "Overall": 0.7394433593749999}, {"timecode": 64, "before_eval_results": {"predictions": ["some of the most gigantic pumpkins in the world,", "Seminole", "billions of dollars in Chinese products each year,", "green-card warriors", "228", "a traditional form of lounge music that flourished in 1940's Japan.", "2005", "Washington State's decommissioned Hanford nuclear site,", "consumer confidence", "Fernando Gonzalez", "the southern port city of Karachi,", "Dan Parris, 25, and Rob Lehr, 26,", "Jason Chaffetz", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah,", "the United States", "Barack Obama", "Sunday", "Bienvenido Latag", "France", "380,000", "be silent.", "iTunes", "Kenyan and Somali governments", "\"gotten the balance right\"", "a dozen", "10", "Quiet Nights", "his death cast a shadow over festivities", "Iran and Egypt.", "123 pounds of cocaine and 4.5 pounds of heroin", "engineering and construction", "grabbed the gun and took her own life.", "fractured pelvis and sacrum", "five", "to step up.", "first-degree murder", "Paris", "Mashhad", "summer", "one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda,", "Garth Brooks", "Oxbow,", "an Iranian court", "different women coping with breast cancer in five vignettes", "Michael Schumacher", "Lula da Silva", "the release of the four men", "2006", "12.9 - kilometre ( 8 mi )", "Jim Ruggiere", "Theodosius I", "David Pearson", "Estonia", "is our children learning?\"", "Princess Anne", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Ptolemy", "Woodrow Wilson", "a pirate"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6822110615079365}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.6, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8750000000000001, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1825", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-1644", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-10081", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-709"], "SR": 0.578125, "CSR": 0.55, "EFR": 0.9629629629629629, "Overall": 0.7321238425925926}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "North Korea", "February 12", "Mandi Hamlin", "United Nations", "\"falling space debris,\"", "an occupied building.", "voluntary homicide", "when someone needs medical attention after a head injury,", "Chris Robinson", "Grease", "Cipro", "34", "E. coli bacteria", "More than 15,000", "\"A good vegan cupcake has the power to transform everything for the better,\"", "The Sopranos", "government", "in September,", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "South Africa", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano,", "because the quantities are not regulated.", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "around 1610,", "Gulf of Aden,", "\"To the Muslim world, we seek a new way forward, based on mutual interest and mutual respect.\"", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee Anthony,", "the \"bystander effect\"", "Wednesday.", "managing his time.", "not including co-pays or deductibles.", "bipartisan", "us to step up.\"", "he acted in self defense in punching businessman Marcus McGhee.", "education about rainforests.", "as adults", "drug cartels", "state", "Trevor Rees-Jones,", "at least 28 passengers,", "the leader of a drug cartel that set off two grenades during a public celebration in September,", "Ed McMahon,", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "Genocide Prevention Task Force.", "243 days", "Kirstjen Nielsen", "1937", "17", "Madison, Wisconsin", "\"Mr Loophole\"", "Arlo Looking Cloud", "Piedmont", "1694", "the Golden Fleece", "Gustav", "Amish", "6teen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6332542425324933}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, false, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.5454545454545454, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0, 0.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 0.5, 1.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.10526315789473685, 1.0, 0.0, 1.0, 1.0, 0.5, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-2960", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-9728", "mrqa_naturalquestions-validation-3469", "mrqa_triviaqa-validation-1217", "mrqa_triviaqa-validation-122", "mrqa_hotpotqa-validation-4692"], "SR": 0.515625, "CSR": 0.5494791666666667, "EFR": 1.0, "Overall": 0.7394270833333334}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "ra(dio) d(etecting a(nd) r(anging)", "pete best", "Robert Taylor", "Vincent Van Gogh", "Castile", "about a mile north of the village of Dunvegan,", "arcelorMittal Orbit", "lodges", "stilwell", "george yachting", "the solar system", "coelacanth", "Belgium", "Dennis Potter", "Calcium", "george coates", "Geoffrey Cox", "Mel Brooks", "The California condor", "wisconsin", "wind turbines", "harridan Grizelda pugh,", "police drama The Bill", "0", "Hamlet", "Johannesburg", "crackerjack", "etoria", "cameron and Robert Rounsville", "Spain", "minder", "special sauce", "mavis from Coronation Street", "kansas city", "Hard Times", "Tuscany", "18 meters", "Singapore", "Scooby-Doo!", "paul Asia Airways", "gold, red, blue, black and white", "France", "Tomorrow Never Dies", "jennifer kennedy", "hong kong", "Chuck Yeager", "violet- Elizabeth Bott", "northern France", "stamp collecting", "Moby Dick", "Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "a sociological perspective", "21 July 2015", "Bern", "28 June 1945", "foreign Terrorist Organization", "25", "Pakistan's", "Yves Saint Laurent", "Rush", "Topix", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5965773809523809}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, false, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.09523809523809525, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-2091", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-6641", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-5331", "mrqa_triviaqa-validation-6089", "mrqa_triviaqa-validation-6792", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-1933", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-613", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_searchqa-validation-7017", "mrqa_searchqa-validation-11790", "mrqa_newsqa-validation-2682"], "SR": 0.53125, "CSR": 0.5492070895522387, "EFR": 0.9666666666666667, "Overall": 0.732706001243781}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "Department of the Interior", "Frank Langella", "August 9, 1945", "after obtaining the consent of the United Kingdom", "product's classification as a cake or biscuit", "Olivia Olson", "Tokyo", "Pyeongchang County, South Korea", "928", "April 7, 2016", "5.7 million", "first to Twickenham Stadium", "the President", "David Joseph Madden", "The Fixx", "at night", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "the Royal Air Force ( RAF )", "sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US privacy Act", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "18th century", "Mariah Carey", "Spektor", "H CO", "seven", "September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "Soviet Union", "elected", "sport utility vehicles", "Elk and Kanawha Rivers", "The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash in 1959", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand to New Guinea", "Frank Oz", "1954", "2010", "Missouri River", "alfred I", "lute", "phoebus", "John Churchill, 1st Duke of Marlborough", "Gregg Popovich", "Asiana Town", "Araceli Valencia,", "people", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi (Persian)", "metonymy"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6357609221918432}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, true, false], "QA-F1": [0.5263157894736842, 0.0, 1.0, 0.3333333333333333, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 0.5, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-1344", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1702", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-335", "mrqa_triviaqa-validation-4040"], "SR": 0.515625, "CSR": 0.5487132352941176, "EFR": 0.9354838709677419, "Overall": 0.7263706712523719}, {"timecode": 68, "before_eval_results": {"predictions": ["German state of North Rhine-Westphalia", "Roberta flack", "sesame seed", "eldest or heir apparent", "pirate day", "barnaby rudge", "Buddha", "shoa", "1963", "discus thrower", "tabloid", "france conder", "chester racecourse", "wyoming", "Jews of yiddish", "Romanian", "saint Basil the Blessed", "Peru", "the keel", "Evander Holyfield", "middies", "monastic stupas", "New Orleans", "soda", "fat like oil or lard", "Steve Hansen", "brashy", "Ken Burns", "paddy doherty", "yvonne", "phi", "Hungary", "so Solid Crew", "blues-rock", "Pennsylvania", "caucasus", "scotland", "olympics", "Jupiter", "watch with mother", "boy or girl", "two", "Queens Park Rangers", "Wide Area Augmentation System", "bulphemus", "flannel", "b\u00e9la bart\u00f3k", "Hugh Dowding", "Montpelier", "month of month", "john johnson", "annual income of US $11,770", "318", "Chris Rea", "Tomasz Adamek", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine.", "March 30, 2025", "Amanda Knox's", "Dubai", "rabbit hole, if you will,", "deep-rooted", "Russia", "Crackle", "Democratic National Convention"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5034474206349207}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.5, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2194", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-1649", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7645", "mrqa_triviaqa-validation-6027", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-6849", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-2964", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3236", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-361", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-10485", "mrqa_searchqa-validation-7826"], "SR": 0.421875, "CSR": 0.546875, "EFR": 0.918918918918919, "Overall": 0.7226900337837837}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey archer", "Chicago", "filly", "dar es salaam", "Sarah Keays", "miss marple", "elkie Brooks", "UPS", "Novak Djokovic", "piano", "c Cambridge", "Bennet", "spice girls", "glycerol", "addams", "doubting castle", "insect", "australian", "england", "harry shearer", "9-13 years", "pirate day", "farthings", "spice girls", "48 Hours", "AFC Wimbledon", "france", "Tombstone", "germany", "Cambridge", "South Africa", "bagram", "pygmalion", "bajan", "cassis", "Dieppe Raid", "dengue fever", "left book club", "triathletes", "customs agent Dave Kujan (Chazz Palminteri) and police sergeant Jeff Rabin", "dividing of cells into additional cell bodies", "strictly Come Dancing", "sound and light", "Par", "jack Russell Terrier", "prairie", "raclette", "denali", "magic Circle", "lyndon conference", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Lear", "London Luton Airport", "Sarah", "Antigua & Barbuda, Argentina, South Africa, Fernando P\u00f3, S\u00e3o Tom\u00e9, Madagascar, Mauritius, Mayotte, R\u00e9union, Seychelles, Cyprus, Israel, Cape Verde, Lebanon", "\"The workers should be dealt (with) with compassion and should not be pushed so hard that they resort to whatever that had happened in Nodia\"", "\"the evidence and investigatory effort has minimized the likelihood that Haleigh's disappearance is the work of a strangers.\"", "\"The deceased appeared to have been there for some time.\"", "Vanilla Ice", "Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5936453751221896}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5454545454545454, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 0.06451612903225806, 0.08333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2042", "mrqa_triviaqa-validation-3873", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-4970", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627", "mrqa_searchqa-validation-3002"], "SR": 0.515625, "CSR": 0.5464285714285715, "EFR": 0.9354838709677419, "Overall": 0.7259137384792627}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew - Somerville", "A complex sentence", "Australia", "Ashrita Furman", "No Secrets", "1994", "2010", "12 November 2010", "1 October 2006", "1977", "2018", "Missouri", "Swedien and Jones", "1966", "Frederick Chiluba", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "1999", "the Maryland Senate", "Latitude", "anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Steve Lukather", "U.S. dollar banknotes", "the referee", "Bonhomme Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032", "smacking a fly on her mirror and removes its corpse", "around 2011", "New Jersey Devils of the National Hockey League", "ulnar nerve", "2018", "British Indian Association", "indigenous to many forested parts of the world", "the majority coming from Western Australia", "Carol Worthington", "1830", "exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "thanksgiving for a good harvest", "28", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Anthony Hopkins", "Jesus Christ", "1996", "holography", "Spanish Army", "marty vinterberg", "Gillian Leigh Anderson", "the theory of direct scattering and inverse scattering", "45th Infantry Division", "\"one of the most magnificent expressions of freedom and free enterprise in history\" and says \"it should stay that way.\"", "2009", "an open window", "Dutchman", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6728888146167558}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.823529411764706, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9867", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-2623", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-1049", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_newsqa-validation-2658", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.578125, "CSR": 0.546875, "EFR": 0.8888888888888888, "Overall": 0.7166840277777777}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "inner core", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama Action", "on the table or, more formally, may be kept on a side table", "zinc silicate primer and vinyl topcoats", "off the rez", "either in front or on top of the brainstem", "March 14, 1942", "Aegisthus", "Epithelium", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Vincent Price", "Pakistan", "Tessa Peake - Jones", "connected behaviors, rights, obligations, beliefs, and norms as conceptualized by people in a social situation", "United Nations Peacekeeping Operations", "It is part of the normal flora of the human colon and is generally commensal, but can cause infection if displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "Noahic Covenant", "Shirley Mae Jones", "heat transfer by thermal radiation may be minimized by silvering flask surfaces facing the gap", "Luke 6 : 67 -- 71", "August 19, 2016", "Sets heart in mediastinum and limits its motion", "scrolls", "Terrell Suggs", "Cecil Lockhart", "August 22, 1980", "retinal ganglion cell axons and glial cells", "letter series", "August 21", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal, and the southern terminus is at an interchange with US 250 near Interstate 64 ( I - 64 ) in Rockfish Gap", "the Confederacy", "1955", "electrons from electron donors to electron acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions", "2", "Montreal Canadiens", "2008", "3 September", "three levels", "minimum viable product that addresses and solves a problem or need that exists", "George Strait", "last book", "In the 1920s", "ice giants", "on what became known to locals as `` Black Monday '', and continued into the mid-1980s", "Camellia sinensis", "European Economic Community", "Mumbai", "Frank Fertitta, Jr.", "Coronation Street", "Michael A. Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry", "complicated and deeply flawed", "Crandon, Wisconsin,", "butterflies", "Rocky Mountain spotted fever", "11:30 a.m.", "drug labs, markets and convoys."], "metric_results": {"EM": 0.484375, "QA-F1": 0.6045222538953592}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.35294117647058826, 0.75, 1.0, 1.0, 1.0, 0.9333333333333333, 0.0, 0.12903225806451613, 1.0, 1.0, 0.7272727272727273, 0.75, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6341463414634146, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-1617", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.484375, "CSR": 0.5460069444444444, "EFR": 0.9696969696969697, "Overall": 0.7326720328282829}, {"timecode": 72, "before_eval_results": {"predictions": ["Michigan's", "Afghanistan", "red sauce", "Suffragette", "Samwise", "Christopher Darden", "a gourmet jelly bean", "a cloudy day", "Daniel Berrigan", "wheat", "Carole King", "Iberia", "The Pro-Jig Clamp Set", "Christo Vladimirov Javacheff", "Wichita", "U.S. Department of Agriculture", "Gilligan's Island", "Penelope", "Tom Harkin", "The Channel Islands", "Hershey", "Penelope", "Pronouns", "Bonobos", "(Harry) Simone", "Veep", "an insect", "lullaby", "a ruby", "Pan's Labyrinth", "(Sir) James Matthew Barrie", "John Irving", "(singular)", "The Who", "Europe and Asia", "Xerox", "extra virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "World War II", "Beijing", "Lee Harvey Oswald", "(George) Armstrong Custer", "Newton's Second Law", "a breath", "Orlando", "Alaska", "a puff", "The Mausoleum at Halicarnassus", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew", "Genesis", "Saint Cecilia", "Germany", "1989", "Suzuki YZF-R6", "the nose, cheeks, upper jaw and facial tissue", "Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5869605654761905}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.8750000000000001, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1459", "mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-16049", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3351", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-16212", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-13584", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-6286", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681"], "SR": 0.484375, "CSR": 0.5451626712328768, "EFR": 0.9696969696969697, "Overall": 0.7325031781859692}, {"timecode": 73, "before_eval_results": {"predictions": ["Baltimore", "Happy Days", "Rita Mae Brown", "Bolivia", "New Hampshire", "a grasshopper", "the commander", "Sure", "1876", "to protect babies", "an onlooker", "Humphrey Bogart", "Maryland", "a Lion", "a pen", "Herod", "the Lone Ranger", "Malaysia", "Georgetown University", "Bruce Rauner", "Goofy", "the Chicago Bears", "Mount Everest", "(Winston) Garvey", "a pindar poem", "a bird", "the Tom Thumb", "the Island of Kent", "the Mad Hatter", "a tryptophan", "Cincinnati", "the Confederate flag", "the concert grand piano", "ketchup", "peanut butter", "soccer", "Tom Petty", "Tuscany", "Tunisia", "Rosa Parks", "an inch", "Paris", "William Henry Harrison", "Corinth", "a gram", "Bern", "Prada", "Chicago", "the umbilical cord", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "2015", "tipping Point", "Scotland", "the dogger Bank", "James Harden", "eworldly wave", "Nicole Brown Simpson", "\"Mad Men\"", "Fusion teams", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.609375, "QA-F1": 0.665625}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-16935", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-11051", "mrqa_searchqa-validation-12562", "mrqa_searchqa-validation-13507", "mrqa_searchqa-validation-16552", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-16213", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-4837", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-403", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-8077", "mrqa_searchqa-validation-15975", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-2410"], "SR": 0.609375, "CSR": 0.5460304054054055, "EFR": 1.0, "Overall": 0.738737331081081}, {"timecode": 74, "before_eval_results": {"predictions": ["Wholesale", "The Tyger", "Thunder Road", "The Last Supper", "Baccarat", "Rook", "Harlem", "(Den) Bosch", "a multi-hulled watercraft", "Drug Rehab & Treatment Center", "cricket", "India", "Children of Men", "Skagway", "a petition", "Hippolyta", "a species", "John Galt", "Spinach", "milk", "1,000 watts", "Fecund", "World War I", "Student Loans", "the Gateway Arch", "Itzhak Perlman", "Wolfgang Johannes Puck", "Dachshund", "the Monitor", "Cyprus", "Milwaukee", "Eclipse Coffee Syrup", "a baseball movie", "Hot Lips", "Isadora Duncan", "Pig Latin", "Little Debbie", "Richard Cheney", "Speed Racer", "The Beach Boys", "Aristotle", "ER", "the Eagles", "An American Tail", "a Starline Tour", "argyle", "Honda", "a Wallaby", "a leather feather", "Mark Twain", "Greg", "30 October 1918", "Mel Tillis", "Michael Moriarty", "James Bolam", "pawns", "India", "House of Habsburg-Lorraine", "highest commissioned SS rank", "Kansas\u2013Nebraska Act of 1854", "Orbiting Carbon Observatory,", "South Africa", "Tuesday,", "two"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7208333333333333}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, false, false, true, true, true, false, false, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12847", "mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-8228", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-9320", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-4180", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-1047", "mrqa_searchqa-validation-3857", "mrqa_naturalquestions-validation-4288", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-837"], "SR": 0.640625, "CSR": 0.5472916666666667, "EFR": 0.9130434782608695, "Overall": 0.7215982789855072}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "following the 2017 season", "China in modern times", "1908", "at specific locations, or origins of replication, in the genome", "Javier Fern\u00e1ndez", "Michael Crawford", "silk floss", "Hold On", "Allies", "November 2016", "Empiricism", "Identification of alternative plans / policies", "Augustus Waters, an ex-basketball player and amputee", "a part of the continent of North America", "Johnson", "Song of Songs", "Taron Egerton as Johnny", "its vast territory was divided into several successor polities", "acronym", "Sheev Palpatine", "Divyanka Tripathi and Karan Patel", "September 24, 2012", "Only two men", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "the homicidal thoughts of a troubled youth", "Dan Bern and Mike Viola", "Daniel A. Dailey", "Mickey Mantle", "addition, subtraction, multiplication, and division", "December 15, 2016", "Kid Creole and the Coconuts", "525", "2010", "a microfilament", "1983", "John Roberts", "the President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Sri Lanka Podujana Peramuna, led by former president Mahinda Rajapaksa, secured the most seats and local authorities.", "1773", "Buddhism", "Extroverted Thinking ( Te )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "st Pancras", "t. s. Eliot", "Russell Humphreys", "Lieutenant Colonel Horace Meek Hickam", "Rihanna", "not been taken out of context.", "fractured pelvis and sacrum", "2001", "income", "Blackbird", "Meredith Grey", "September 25, 2017"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6589486901986902}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0909090909090909, 0.0, 0.7142857142857143, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.923076923076923, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.578125, "CSR": 0.5476973684210527, "EFR": 0.8888888888888888, "Overall": 0.7168485014619883}, {"timecode": 76, "before_eval_results": {"predictions": ["bridal shop", "Walter Mondale", "state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "in 1942", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "at least 28", "Theodore Roosevelt", "23 hours, 56 minutes, and 4 seconds", "Universal Pictures and Focus Features", "multiple origins of replication on each linear chromosome that initiate at different times ( replication timing ), with up to 100,000 present in a single human cell", "restarting play after a minor infringement", "A footling breech", "Mockingjay -- Part 2 ( 2015 )", "the President of India", "fingers on either side of the mouth ( usually with the knuckles facing the observer ) and to stick the tongue out", "28 %", "Elvis Presley", "Native American nation from the Great Plains whose historic territory, known as Comancheria, consisted of present - day eastern New Mexico, southeastern Colorado, southwestern Kansas, western Oklahoma", "JackScanlon", "the eighth episode of Arrow's second season", "Elijah Wood", "head - up", "Doug Pruzan", "1984", "Donna Reed", "inside the cell nucleus", "pathology", "age of about 14", "introduced and elaborated as early as in 1651 by Thomas Hobbes in his Leviathan, though with a somewhat different meaning ( similar to the meaning used by the British associationists )", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Jourdan Miller", "Panzerkampfwagen VIII Maus ( `` Mouse '' )", "limited period of time", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "New England Patriots ( 5 - 4 )", "40 %", "Janie Crawford's `` ripening from a vibrant, but voiceless, teenage girl into a woman with her finger on the trigger of her own destiny", "in the west by the east coast of Queensland, in the east by Vanuatu ( formerly the New Hebrides ) and by New Caledonia", "April 2, 2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "St. Louis Blues", "around 1872", "Snake River Valley", "starch", "carbon", "on the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery Football Club", "Phelan Beale", "one", "Government Accountability Office report", "ethnic Somalis by rebels and Ethiopian troops are rampant.", "a double-breasted suit", "Heroes: Reborn", "a lush, plentiful version of the Egypt of the living", "since 1983."], "metric_results": {"EM": 0.359375, "QA-F1": 0.544570939253399}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.4444444444444445, 0.0, 0.25, 0.6666666666666666, 1.0, 0.0, 0.26666666666666666, 0.0, 0.2, 1.0, 0.5, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.3870967741935484, 0.0, 0.7692307692307692, 0.5714285714285715, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.32258064516129037, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.30769230769230765, 0.4615384615384615, 0.0, 0.0, 0.09090909090909091, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.4, 0.0, 1.0, 0.8571428571428571, 0.0, 0.6666666666666666, 0.6666666666666666, 0.2, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-1427", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-10195", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-2782", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-3250", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-3373", "mrqa_searchqa-validation-1664", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.359375, "CSR": 0.5452516233766234, "EFR": 0.8536585365853658, "Overall": 0.7093132819923978}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes virus, (Another name for shingles is herpes zoster.)", "zork", "roddy doyle", "jaggers", "spartoffelkrieg", "jennifer kipling", "Spongebob Squarepants", "Exile", "an enclave which is entirely enclosed by another nation.", "South Dakota", "Brian Close", "a caterpillar", "l Leeds", "edwards", "meter maid", "cricketer", "pholet", "nepotism", "VimtoVimto", "people or society.", "leicestershire", "carry On Cleo", "afro-Asiatic", "taste", "snare drum", "geologic time", "sesame seed", "hurdles", "centaur", "tallest building in the world", "American football", "phonies", "kitty", "Giglio Island", "czech republic", "hanight", "phoebus", "Harry patch", "nursery comics", "sight & sound", "inigo Jones", "sonar", "nelson Mandela", "Today", "trousseau", "bootleggers", "Mark Darcy", "reptilian", "supercontinent", "salyut 1", "british", "Evermoist", "62", "Matthew Gregory Wise", "1861", "voice actress", "Limbo", "12.3 million", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "fathom", "$4.5 million"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5230181277056277}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, true, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-7531", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-1256", "mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-2233", "mrqa_triviaqa-validation-7709", "mrqa_triviaqa-validation-2362", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-479", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-5170", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-57", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.453125, "CSR": 0.5440705128205128, "EFR": 0.8571428571428571, "Overall": 0.7097739239926739}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "he believed he was about to be attacked himself.", "1964", "\"the voice of change,\"", "\"momentous discovery\"", "Al-Aqsa mosque", "Sri Lanka back on top again in the final session with a 74 stand", "as soon as 2050,", "Sylt", "media", "in the southern city of Najaf.", "Sen. Barack Obama", "10 municipal police", "left his indelible fingerprints on the entertainment industry.", "ketamine.", "Brian David Mitchell,", "Defense of Marriage", "Jacob,", "Ronaldinho", "Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "people will be malicious and try to compromise peoples' health using computers, especially if neural devices become more widespread.", "1957", "start a dialogue of peace based on the conversations she had with Americans along the way.", "al Qaeda,", "Manmohan Singh's", "help the convicts find calmness in a prison culture", "J. Crew", "\"My gut started feeling like something just wasn't right,\"", "10,000", "Meira Kumar", "antihistamine and an epinephrine auto-injector", "CNN", "allegations that a dorm parent mistreated students", "Virgin America", "1940's", "Arthur E. Morgan III,", "million dollars", "bribing other wrestlers to lose bouts,", "Eleven", "they don't feelMisty Cummings has told them everything she knows.", "above zero (3 degrees Fahrenheit),", "Steven Gerrard", "$8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Obama", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Brazil", "10", "the return of a fallen U.S. service member", "models", "Horseshoe Bartender", "early Christians of Mesopotamia", "16 seasons", "pluribus unum", "well", "chile", "Capture of the Five Boroughs", "Double Crossed", "pornographicstar", "God", "Mineral", "Fannie Merritt Farmer", "democracy and personal freedom"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6153037067099567}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 0.0, 0.18181818181818182, 0.7499999999999999, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-3797", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-1390", "mrqa_naturalquestions-validation-4008", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-744", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-16904", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-7153"], "SR": 0.484375, "CSR": 0.5433148734177216, "EFR": 0.8484848484848485, "Overall": 0.707891194380514}, {"timecode": 79, "before_eval_results": {"predictions": ["Togus", "Grant", "Yangtze River", "Judah", "Queen Anne", "the New York Times", "Scotland", "Oklahoma", "the Communist Party", "the Nuclear Age", "Humphry Davy", "lice", "1/2 hours", "smallpox", "the Dead Sea", "the fairway", "Hill Street Blues", "elevation", "Mao Zedong", "Harriet", "Mickey Mouse", "Xerox", "a blitz", "Jamaica", "gossip", "an exothermic reaction", "the Chocolate Factory", "Morocco", "Surf's Up", "Yao Ming", "the Department of the Treasury", "reborns", "Andrew Marvell", "fruits", "Bollywood", "(Love Theme from \"Titanic\")", "Take Me Out to the Ballgame", "a parapet", "Joe Lieberman", "a diary", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Suriname", "Pearl", "Pirates of the Burning Sea", "Switzerland", "Vestal virgins", "The Lord of the Rings: The Return of the King", "President Raul Castro", "H CO ( equivalently OC (OH ) )", "in a thousand years", "W. Edwards Deming", "clara", "douglas Trendle", "Ricky Gervais", "Ricky Marco", "edith Cavell", "Forbes", "20 minutes of cardio five days a week.", "22", "John Demjanjuk,", "2,579"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6738636363636363}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true], "QA-F1": [0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.7272727272727272, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.4, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13653", "mrqa_searchqa-validation-14620", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-11663", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-8650", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-4078", "mrqa_newsqa-validation-2118"], "SR": 0.546875, "CSR": 0.543359375, "EFR": 0.8620689655172413, "Overall": 0.7106169181034482}, {"timecode": 80, "before_eval_results": {"predictions": ["Homebrewing", "the German Empire", "Tim Whelan", "Waimea Bay", "Virgin", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "nine", "Greek mythology", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "\"From Here to Eternity\"", "Manor of the More", "England, Scotland, and Ireland", "Workers' Party", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "his exploration and settlement", "six", "Mauthausen-Gusen", "9 February 1983, Kimberley, Cape Province, South Africa", "Distillery", "Ted Nugent", "New York", "Viscount Cranborne", "The Princess and the Frog", "Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Martins", "Boulder High School", "Dutch", "November of that year", "Boston, Massachusetts", "\"The Big Bang Theory\"", "Brendan O'Brien", "Delphine Software International", "Sullivan University College of Pharmacy", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31 - member Senate", "September 15, 2012", "Billie Jean King", "Vienna", "Malaysia", "I, the chief executive officer, the one on the very top,", "nuclear program.", "alternative-energy vehicles", "Bing Crosby", "(two)", "Court Jester", "M&M's"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7052083333333334}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, true], "QA-F1": [0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.5, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-1809", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5821", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-8992"], "SR": 0.640625, "CSR": 0.5445601851851851, "EFR": 0.8260869565217391, "Overall": 0.7036606783413848}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "Allies of World War I, or Entente Powers", "Acid house", "Esteban Ocon", "Lady Frederick Windsor", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham, Alabama", "half of the Nobel Prize in Physics", "Adam Karpel", "rock and roll", "1957", "Windermere Hotel", "Sir Frank P. Lowy", "Hermione Baddeley", "Metrolink", "South Australia", "1698", "Greenwood", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "Jenson Alexander Lyons button", "Ambroise Thomas", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Dar es Salaam", "English Electric Canberra", "1 September 1864", "Washington, D.C.", "Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoon Fridays", "The Company", "5", "Eleanor of Aquitaine", "Latium in central Italy, 12 mi southeast of Rome, in the Alban Hills", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Michael Redgrave", "Tyrann Devine Mathieu ( / \u02c8ta\u026ar\u0259n \u02c8m\u00e6\u03b8ju\u02d0 / ; born May 13, 1992 )", "1933", "British Columbia, Canada", "e Leonardo DiCarpio", "willow", "Cliff Thorburn", "Kim Clijsters", "Africa.", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "Rudimentarily", "Peter Martins", "voltage", "Willa Cather"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6093390735614201}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.5882352941176471, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.2608695652173913, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-2729", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_naturalquestions-validation-4611", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-873", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.46875, "CSR": 0.5436356707317074, "EFR": 0.9411764705882353, "Overall": 0.7264936782639885}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Harriet Walter", "Algernod Lanier Washington", "Conservative Party", "four", "November 29, 1895", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "2006", "Norwegian", "\"The Late Late Show\"", "Ry\u016bky\u016ban sailors", "Commanding General", "\"50 best cities to live in.\"", "Mike\" Mills", "Parlophone", "January 15, 2016", "IATA: VNO, ICAO: EYVI", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "The Worm", "Herman's Hermits", "Annapurna Devi", "810", "German", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Richard Price", "Novel", "Gabriel Iglesias", "3,384,569", "Gambaga", "2 March 1972", "Shenandoah National Park", "Teatro Carlo Felice", "every aspect of public and private life", "Gary Ross", "Hanford Site", "Commissioner", "Sam Tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epithelium ( / \u02cc\u025bp\u026a\u02c8\u03b8i\u02d0li\u0259m / )", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "ringo", "1882", "off the coast of Dubai", "The security breach", "not doing more since taking office.", "notebooks", "polio", "the treble clef", "gun charges,"], "metric_results": {"EM": 0.6875, "QA-F1": 0.746875}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-438", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-4899", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_naturalquestions-validation-7459", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732"], "SR": 0.6875, "CSR": 0.5453689759036144, "EFR": 0.9, "Overall": 0.7186050451807229}, {"timecode": 83, "before_eval_results": {"predictions": ["May 29, 1917", "Metacomet", "Chicago", "Leon Trotsky", "idle away", "a tree", "The New York Times", "Martin Van Buren", "Ugly Betty", "The Winnie-the-Pooh", "Rigoletto", "Alexander Graham Bell", "(Vijay) Singh", "fog", "a modem", "China", "the Boston Red Sox", "Comedy Central", "Hitler", "the human breast", "Jane's Electro-Optic Systems", "Christo", "a psychiatrist", "Ichiro Suzuki", "Frank Sinatra", "Africa", "the banjo", "the Army of Northern Virginia", "Belle Watling", "Mozart", "American alternative rock band", "Nellie Bly", "Lord Byron", "meningitis", "Douglas MacArthur", "3M", "The Rolling Stones", "Edie Falco", "The U.S.A.", "Oneonta College", "1936", "the CN Tower", "\"Black Beauty\" author", "inheritance", "Maryland", "the cardinal", "Japan", "the Bovine Spongiform Encephalopathy", "Prince Edward Island", "Hindu", "the pronghorn", "January 2, 1971", "San Francisco", "Moscazzano", "Cliff Thorburn", "chuanqing", "daedalus", "Conservatorio Verdi", "close range combat", "Paul John Mueller Jr.", "1959.", "Ali Bongo", "the United States", "in mid November"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6654017857142857}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-11538", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-4619", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-15564", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_naturalquestions-validation-8884"], "SR": 0.59375, "CSR": 0.5459449404761905, "EFR": 0.9230769230769231, "Overall": 0.7233356227106227}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "Peter Pan", "Jabez Stone", "the Washington Monument", "olives", "Pemmican", "Newton-John", "Oahu", "Joseph Smith", "Arthropoda", "Harry S. Truman", "Capricorn", "Diane Arbus", "Stuffed Poblano Chiles", "Thomas Jefferson", "legislation", "tofu", "Old School", "the \"Midway\" Line", "Henry VIII", "Bonn", "mathematical research", "the pope", "Variety", "Robert Bruce", "zirconium", "oxys", "Gargantua", "Elke Sommer", "hoof wall", "Robin Williams", "Philadelphia", "Ivory soap", "Giuseppe Garibaldi", "The Five People You Meet in Heaven", "the anglerfish", "the Big Cat", "Thomas Jeffersons", "Mahatma Gandhi", "Brazil", "Jim Thorpe", "The Office", "Dustin Hoffman", "Lear", "Frank", "Roy Ellsworth Harris", "Haunted Mansion", "Rembrandt", "Gilligan's Island", "a stride", "the Cowboy Artists of", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Atticus Finch", "Andy Serkis", "spain", "horizontal desire", "charlie drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun", "Asashoryu", "angry over the treatment of Muslims,", "United States Holocaust Memorial Museum, The American Academy of Diplomacy and the United States Institute of Peace.", "Newcastle Falcons"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5269097222222222}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6978", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-1240", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-14016", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-11112", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16304", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-5050", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-7461", "mrqa_triviaqa-validation-5201", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-2724"], "SR": 0.46875, "CSR": 0.5450367647058824, "EFR": 0.9705882352941176, "Overall": 0.73265625}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "\" Postcards from the Edge\"", "birds", "Virginia", "hot chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "\"The play's the thing\"", "\"The Carol Burnett Show\"", "a panic", "Gertrude Stein", "Pope John XXIII", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tippi", "an object oriented programming", "Nova Scotia", "cocoa", "tuna", "Absinthes", "Zeus", "a marsupial", "quid", "Lincoln", "Anthony Newley", "an ear infection", "Henry", "WLAN", "Greek", "Jeff Probst", "Hopelessly Devoted", "Nasser", "The Moment of Truth", "Laura", "Pisces", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "Bill & George Clinton", "the Black Sea", "May 12, 1907", "Abraham Lincoln", "Young Frankenstein", "Shout", "to form a higher alkane", "comprehend and formulate language", "Hellenic Polytheism", "chile", "shootist", "segas", "National Society of Daughters of the American Revolution", "Leonard", "44,300", "it has not intercepted any", "At least 88", "drowned in the Pacific Ocean on November 29, 1981,", "\"It appears that there was a struggle between the victim and the suspect in the threshold of the hotel room immediately prior to the shooting,\""], "metric_results": {"EM": 0.53125, "QA-F1": 0.640224358974359}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.5, 0.6666666666666666, 0.9743589743589743]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-13276", "mrqa_searchqa-validation-6865", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-9410", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-11816", "mrqa_searchqa-validation-10463", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-14465", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-13742", "mrqa_searchqa-validation-2063", "mrqa_triviaqa-validation-2690", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.53125, "CSR": 0.5448764534883721, "EFR": 0.8666666666666667, "Overall": 0.7118398740310077}, {"timecode": 86, "before_eval_results": {"predictions": ["Anthony Caruso", "at a given temperature", "season ten", "October 28, 2007", "seven units of measure", "absorbed the superhuman powers and the psyche of Carol Danvers", "Pewfik at the city of Suez", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "the First Epistle of John at 5 : 7 -- 8", "between the stomach and the large intestine", "Gupta Empire", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "Egypt", "the pulmonary arteries", "Lager", "Justin Timberlake", "Destiny's Child", "position in blackjack relative to the player", "Cliff's father", "Husrev Pasha", "Will", "The Osmonds", "1,149 feet ( 350 m )", "It acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Tex - Mex chili con carne", "September 8, 2017", "SURFACE AREA OF ROOTS", "Iowa ( 36.6 % )", "Matt Flinders", "1 October 2006", "Natya Shastra", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Hebrew : \u05de\u05db\u05d5\u05ea \u05de \u05e6\u05e8\u05d9\u05dd, Makot Mitzrayim", "nasal septum", "Session Initiation Protocol", "January 1, 1976", "parthenogenesis", "Identification of alternative plans / policies", "Ludacris", "Jack Scanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "the retina", "Donna Mills", "Donna", "annette Crosbie", "bobby kennedy", "minder", "leopard", "Patricia Arquette", "Bangalore University", "Symbionese Liberation Army", "101", "two", "\"Like a Rock\"", "a cat", "George III", "Norway"], "metric_results": {"EM": 0.625, "QA-F1": 0.7264041956495517}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, false, true, true, false, false, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.5454545454545454, 0.0, 1.0, 0.4, 0.761904761904762, 0.2857142857142857, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.11764705882352942, 0.0, 1.0, 0.0, 1.0, 0.0, 0.72, 0.6, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-10526", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-613", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_searchqa-validation-1808", "mrqa_searchqa-validation-366"], "SR": 0.625, "CSR": 0.5457974137931034, "EFR": 0.875, "Overall": 0.7136907327586206}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol. 2", "Arlo Looking Cloud", "Jyothika Sadanah", "The Franco-Prussian War", "Hirsch index rating", "Cody Miller", "1951", "Teenitans Go!", "The Ramna Stacks", "Book of Judges", "torpedo boats", "9 February 1971", "San Francisco, California", "\"Three's Company\"", "9,984", "Diondre Cole", "Marktown", "The Rose Theatre", "1 million", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "237 square miles", "timeline of Shakespeare criticism", "balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden", "Noel Gallagher", "James Gandolfini", "U2 360\u00b0 Tour", "Daniel Richard \" Danny\" Green, Jr.", "Scarface", "Austro-Hungarian Army", "St.George", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "his son Louis", "Vancouver", "Urijah Faber", "four operas", "3 May 1958", "The Thomas Crown Affair", "Bharat Ratna", "1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "those at the bottom of the economic government whom the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "the 1920s", "Blue laws", "james hargreaves", "Peter Paul Mary Song Meanings", "english", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "flooding", "composer", "the FontSpace", "Bath", "Atlanta", "the hope that a happy day being marked would recur many more times"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6999793320105819}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 0.5, 0.22222222222222224, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9166666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-2792", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-3809", "mrqa_triviaqa-validation-3147", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-2044", "mrqa_naturalquestions-validation-9361"], "SR": 0.59375, "CSR": 0.5463423295454546, "EFR": 1.0, "Overall": 0.7387997159090909}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus", "as", "Ameneh Bahrami", "40", "state senators", "in an Internet broadband deal with a Chinese firm.", "by text messaging", "Hawaii.", "Haiti", "Brazil's", "it's historical, inspiring, creative, romantic and beautiful.", "the Transportation Security Administration", "Her husband and attorney, James Whitehouse,", "helping to plan the September 11, 2001, terror attacks, and believe he may have sought to participate, possibly as the \"20th hijacker.\"", "\"Empire of the Sun,\"", "The local Republican Party called the billboard \"inappropriate,\" according to WFTV.", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Washington Redskins fan and loved to travel,", "time", "the earthquake's devastation.", "Jason Chaffetz", "summer", "in the southern port city of Karachi,", "stolen the personal credit information of thousands of American and European consumers,", "\"This is not something that anybody can reasonably anticipate,\"", "Ricardo Valles de la Rosa,", "Islamabad", "Toffelmakaren.", "Wednesday at home in Palo Alto, California,", "Microsoft.", "1995", "Jaime Andrade", "Casalesi Camorra", "Nigeria,", "201-262-2800", "South Africa", "lost future exploration of the moon and beyond.", "France,", "President Obama", "Tuesday", "to reach car owners who haven't complied fully with recalls.", "Mashhad, Iran.", "Plymouth Rock", "Alina Cho", "Federer", "last week", "treadmill", "AbdulMutallab", "10", "This will be the second", "Central Germany", "Rust", "gastrocnemius muscle", "Granada", "axes", "pugal", "June 17, 2007", "England", "Black Elk", "hollandaise", "Kwanzaa", "\"to look like\"", "leopard"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6607203993922744}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.125, 0.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.5, 0.16666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-368", "mrqa_newsqa-validation-3110", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2369", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-929", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-1201", "mrqa_newsqa-validation-2642", "mrqa_triviaqa-validation-4976", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749", "mrqa_hotpotqa-validation-855"], "SR": 0.546875, "CSR": 0.5463483146067416, "EFR": 0.7931034482758621, "Overall": 0.6974216025765207}, {"timecode": 89, "before_eval_results": {"predictions": ["Salt Lake City, Utah,", "(3 degrees Fahrenheit),", "judge Shemsu Sirgaga", "killing rampage.", "HSH Nordbank Arena", "they did not receive a fair trial.", "federal officers' bodies", "American Bill Haas", "Larry Ellison,", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "in the 20 years since the Berlin Wall has fallen there has been a renaissance of the game in the region.", "Joan Rivers", "The public endorsement", "Phoenix, Arizona, police", "KBR's", "Copts", "Jennifer Aniston, Marta Kauffman, co-creator of the series \"Friends\" and Kristin Hahn,", "two years", "the body of the aircraft", "United States, Japan, Russia, South Korea", "chairman of the House Budget Committee,", "pattern matching.", "Teen Patti", "almost 9 million", "U.S. senators", "American wielding a big stick", "London and Buenos Aires", "she returned to Pakistan in October after President Pervez Musharraf signed an amnesty lifting corruption charges.", "Hitler did to the Jewish people just 65 years ago,\"", "President Obama", "a bank", "two", "four people believed to be illegal immigrants", "At least 38", "Sri Lanka,", "The BBC", "\"wipe out\" the United States if provoked.", "Sunday,", "is a city of romance, of incredible architecture and history.", "Stella McCartney,", "clogs", "debris late Sunday night in the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Aniston, Demi Moore and Alicia Keys", "ALS6,", "The EU naval force", "well over 1,000 pounds", "Iran's Green Movement of protesters", "help make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "The supplemental spending bill also contains a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "Lindsey Vonn", "three", "the optic chiasm", "Hugo Weaving", "aragonite", "fire to or burned a structure, forest land, or property", "edmond", "Bruce R. Cook", "Los Angeles", "86,112", "Mahoney", "a soap opera", "CPI", "penrhyn castle"], "metric_results": {"EM": 0.5, "QA-F1": 0.6122919870162518}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [0.7272727272727273, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.1, 0.15384615384615385, 1.0, 1.0, 0.5, 0.0, 0.0, 0.23529411764705885, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0909090909090909, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.2222222222222222, 1.0, 0.1, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-906", "mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2657", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3058", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_searchqa-validation-6689", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.5, "CSR": 0.5458333333333334, "EFR": 0.90625, "Overall": 0.7199479166666667}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Neptune", "larynx", "the Surgeon", "Ebony", "Cook County", "Sartre", "Wordsworth", "St. Louis", "James K. Polk", "Harpy", "lacrosse", "Naples", "a Dormouse", "the Jews", "a cow pie", "'Paradise Lost'", "beautiful", "deepwater", "Doctor Dolittle", "Graceland", "Mitch Albom", "the beaver", "Earthquakes", "Donovan", "Supporting Actor", "The Bionic Woman", "the multitude", "wrinkles", "Narnia", "a comet", "Mount Sinai", "Kamehameha", "(Elbert) Gary", "corporality", "crowded", "\"Duke\"", "Orlans", "The Wall", "Pulp Fiction", "Hester Prynne", "pajama", "Dynasty Class", "a bagpipe", "a stork", "BOWLING", "Henry David Thoreau", "Encephalitis", "the Philippines", "Rookwood", "Hudson Bay", "restored to life", "The long - hair gene is recessive", "the Canaries", "Another Day in Paradise", "the Danelaw", "Don Johnson", "Robert Allen Iger", "Manchester\u2013Boston Regional Airport", "Iowa,", "16", "Korean Taepodong-2 missile", "financial gain,"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6916666666666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-15887", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-4827", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-11566", "mrqa_searchqa-validation-14572", "mrqa_naturalquestions-validation-9741", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-793", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-1662"], "SR": 0.65625, "CSR": 0.5470467032967032, "EFR": 1.0, "Overall": 0.7389405906593407}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff, Wales", "keirin", "welterweight", "christopher nolan", "Johann", "highball", "arthur conan doyle", "Godfigu", "brain", "six verses", "Bashir", "dog sport", "The Double", "arsenic", "omega", "Mickey Mouse", "clove", "welcome Stranger", "recorder", "n Oman", "nevah", "Ladysmith", "californium", "robin germany", "Arizona Diamondbacks,", "george Orwell", "Goldie Myerson", "martin Brunel", "to the tooth,\" meaning that it still has a little bite.", "William Shakespeare", "early 1960s", "some Like It Hot", "Beaujolais", "morphine", "gingerbread", "Sarajevo", "thomas heath", "the knight, some clergymen, members of the middle class, and a few peasants.", "bullfighting", "leicestershire", "cycling", "Crimean Tatar", "bedding", "Switzerland", "shanghai", "duke orsino", "\"Founder's Day\"", "fairey swordfish", "france", "australian", "france", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1898", "January 1923", "South Asian Games", "Ramanaidu Daggubati", "four", "1,500", "12", "38 feet", "Lafayette", "turquoise", "birds", "2010"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6230045995670995}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-5523", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-5567", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-307", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-2053", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7051", "mrqa_naturalquestions-validation-64", "mrqa_hotpotqa-validation-369", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-11134"], "SR": 0.5625, "CSR": 0.5472146739130435, "EFR": 0.75, "Overall": 0.6889741847826086}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Thomas Staubach", "1979", "two", "2001", "Meghan Markle", "2007", "alcoholic drinks", "Seoul, South Korea", "Dutch", "41st President of the United States from 1989 to 1993", "political correctness", "Russell Humphreys", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "November 23, 2011", "3 million", "Mazda", "Jack St. Clair Kilby", "\"My Father\"", "water", "more than 70", "a type of blood pudding", "Animorphs", "Francis", "two Nobel Peace Prizes", "Masahiko Takeshita", "\"Apatosaurus\"", "TD Garden", "gay sex, and the gay bear subculture", "Sam Kinison", "Melbourne Storm", "Hawaii", "2007", "Texas", "Prudence Jane Goward", "Vince Guaraldi", "\"What's My Line?\"", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Lauren Lane", "Charles II", "17 October 2006", "Memphis Minnie", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "The 2018 Unibet Premier League Darts", "first freshman to finish as the runner-up", "Canada", "often linked to high - ranking ( though not necessarily royalty ) in China", "the eurozone", "Jane Seymour", "Willie nelson", "1984", "Argentine", "15", "Ali Bongo", "Antietam National Battlefield", "your premium", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6855826465201466}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, false, true, true, true, false, true, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.6, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 0.8, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-4762", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1662", "mrqa_hotpotqa-validation-1237", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-2586", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.5625, "CSR": 0.5473790322580645, "EFR": 0.8214285714285714, "Overall": 0.7032927707373272}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "Bill Cosby", "one of WSU's most famous alumni, Edward R. Murrow", "Liesl", "Stage Stores, Inc.", "\" Training Day\"", "1998", "World Famous Gold & Silver Pawn Shop", "1972", "Argentina", "the Crab Orchard Mountains", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the Provisional Irish Republican Army", "Tel Aviv", "Chevy", "the nature of human sexual response", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "PEN America: A Journal for Writers and Readers", "Love Letter", "2013", "Jericho Union Free School District", "January 15, 1975", "Cartoon Network", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Scottish novelist and poet", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow", "George Martin", "Kevin Kur\u00e1nyi", "Adam Dawes", "Maasai phrase \"Enkare Nairobi\"", "Rockland, Maine", "2009", "Vietnam War", "Toto", "9 February 2018", "Cheap trick", "strait Byrne and Kevin Spacey", "funchal", "british", "Scudetto", "it would", "because a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.578125, "QA-F1": 0.720906279178338}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.5, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.2857142857142857, 0.4444444444444445, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2095", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-5586", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-960", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_newsqa-validation-2965", "mrqa_searchqa-validation-16694"], "SR": 0.578125, "CSR": 0.5477061170212766, "EFR": 0.8888888888888888, "Overall": 0.716850251182033}, {"timecode": 94, "before_eval_results": {"predictions": ["\"If a man does not keep pace with his companions, perhaps it is because he hears a different drummer.\"", "(Adolf) Hitler", "\"Mrs. Miniver\"", "Simon Cowell", "Eagles", "neon", "lifejackets", "Ian Fleming", "The Taming of the Shrew", "Anne Frank", "Bora Bora", "Earl", "Nassau", "a geisha", "France", "Barbarossa", "the CIA", "antimicrobial", "theBerry Pearl", "fasting", "Phonetics", "Crosby, Stills & Nash", "Frasier", "a garden", "a rocket", "the Constitutional Council", "Yucatan", "\"Jeopardy\"", "Afghanistan", "Australia", "water buffalo", "the seoul", "the College of Dental Medicine", "pitch", "Pete Rose", "Esther", "South Africa", "Bacall", "GoldenEye", "anthropology", "Dumbo", "Edith Wharton", "Aretha Franklin", "marsupials", "Italian", "The Crow", "Cal Ripken Jr.", "The Stranger", "mongoose", "Richard Dreyfuss", "Ecuador", "the New Testament", "four", "elected or appointed by means of a commission", "Friends", "guggul", "the solar system", "Ranulf de Gernon, 4th Earl of Chester", "Karolina Dean", "Pieter van Musschenbroek", "Seoul", "\"It feels great to be back at work,\"", "The Klan experienced a huge resurgence. Its membership was skyrocketing, and its political influence was increasing, so Kennedy went undercover to infiltrate the group.", "Krankies"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6537424740010946}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, false, false, true], "QA-F1": [0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.13793103448275862, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2367", "mrqa_searchqa-validation-4594", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-11593", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-12196", "mrqa_searchqa-validation-11108", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-1165", "mrqa_searchqa-validation-1101", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_triviaqa-validation-5428", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4503", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.59375, "CSR": 0.5481907894736842, "EFR": 0.8461538461538461, "Overall": 0.7084001771255061}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "Ninette de Valois", "Antnio Guterres", "Latin", "King Henry VIII", "San Francisco", "The Memory Keepers daughter", "Neptune", "Harry Potter and the Chamber of Secrets", "Brutus", "the wild-goose", "Joseph Haydn", "Willa Cather", "Dow Jones industrial average", "Aunt Jemima", "fowls", "Dynasties", "Homer", "Amanda Bynes", "Ted Danson", "O. Henry", "middle-aged", "B.B. King", "Kennedy", "Donovan", "plankton", "Candlestick Park", "a plane", "compensation", "Vodka", "pickled", "Adam", "Protestantism", "Ivy Dickens", "faint", "thunder", "Panopolis", "calamine", "Sicily", "Nelson's Column", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Norman", "1957", "Jurchen Aisin Gioro clan", "wilt", "little arrows", "Rotary", "Craig William Macneill", "William Adelin", "twenty", "after Sunday's security breach at Newark's Liberty International Airport,", "more than 4,000", "Lifeway Christian Stores", "Pakistan"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6555059523809523}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.28571428571428575, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-1558", "mrqa_searchqa-validation-503", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-12050", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-15970", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-417", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.59375, "CSR": 0.5486653645833333, "EFR": 0.8076923076923077, "Overall": 0.7008027844551281}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "Robert Browning", "Unbreakable", "Holy Week", "Tijuana", "the Codex Alera", "the kilobytes", "Planned Parenthood", "Jamie Lee Curtis", "\"King of the Hill\"", "Abduction", "Alexander Graham Bell", "the north-east", "baffle", "Hulking", "Herman", "Erin Go Bragh", "Queen Victoria", "giant", "Medusa", "zoology", "Lucia di Lammermoor", "a map", "cricket", "Stephen Hawking", "St. Francis of Assisi", "luminous intensity", "The Scarlet Letter", "2016", "a rehab facility", "pastries", "The Hundred Years' War", "the Met", "milk and honey", "3", "Stenosis", "The Beatles", "The Bronx", "a disaccharide", "King Kong", "Cubism", "Umbria", "Cheesy Spicy Popcorn", "Escher", "Oahu", "the kidney", "F. Scott Fitzgerald", "aria", "Ghostbusters II", "Marquette University", "the monk", "Fall 1998", "infection", "Bart Howard", "the Netherlands", "marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "we seek a new way forward, based on mutual interest and mutual respect.\"", "early 2008,", "acid attack", "number five"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7234375}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-3482", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-1885", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741"], "SR": 0.65625, "CSR": 0.5497744845360825, "EFR": 0.8636363636363636, "Overall": 0.7122134196344891}, {"timecode": 97, "before_eval_results": {"predictions": ["10 cm", "gold rings", "Gaston Leroux", "Concorde", "gold", "eec", "Canterbury and Lancaster", "vietnam", "florentia", "Wanderers", "emilia fox", "Amnesty International", "krak\u00f3w", "Shaft", "gal", "Ramadan", "bizet", "the Count Basie Orchestra", "Pegida", "uranium", "sheree Murphy", "edward hopper", "Einstein", "faversham", "Justin Trudeau", "kevin kline", "time team", "Thom Yorke", "carousel", "UNESCO", "chile", "Christian Wulff", "marinated dried fruits", "usk", "spider", "Malcolm Turnbull", "daily Herald", "nairobi", "Alan Turing", "bone", "the anterior interatrial septum", "Puck", "hula hoops", "dubonnet", "Jane Austen's Manuscript Letters", "Rocky Graziano", "sweater", "Today newspaper", "day care", "Vincent Eugene Craddock", "Midgard", "a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus", "USS Chesapeake", "Ben Faulks", "an infinite sum of terms that are calculated from the values of the function's derivatives at a single point", "the right bank of the Gomti River", "Art of Dying", "Jason Bendett", "Tuesday's iPhone 4S news,", "Christopher Savoie", "Euneos", "Ingenue", "World War I", "Joseph"], "metric_results": {"EM": 0.625, "QA-F1": 0.662828947368421}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.13333333333333333, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-2039", "mrqa_triviaqa-validation-1185", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947"], "SR": 0.625, "CSR": 0.5505420918367347, "EFR": 0.6666666666666666, "Overall": 0.6729730017006802}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "auld reekie", "mice", "cirrus uncinus", "procol harum", "river alt", "adare", "newquay", "Uganda", "midland", "lactic acid", "villefranche", "Robinson Crusoe", "once a week", "my Favorite martian", "whist", "fear of snakes", "Madagascar", "Wyatt", "March", "one Direction", "The West Wing", "prince Harry", "1994", "titanium", "leicestershire", "Pegasus", "alaskan", "Mark Twain", "brazil", "horseradish", "wood", "eyes", "olympia", "bowie knife", "river river", "rabbit", "Independence Day", "Tinie Tempah", "portugal", "pagan", "baby buggy", "beard", "Amy", "oldham, in Greater Manchester, England", "Sunday Post", "bobby", "emirate", "Debbie Abrahams", "Emma", "south africa", "Ian Harrowell", "drivers who meet more exclusive criteria", "Florida", "twenty-three", "Mexican War on Drugs", "her relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi and Hutu", "The Tempest", "Naples", "Solomon", "heavier than a feather"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5630456349206349}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, true, true, false, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.4444444444444445, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_triviaqa-validation-2636", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-4266", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-6169", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-4987", "mrqa_triviaqa-validation-2151", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_hotpotqa-validation-3713"], "SR": 0.453125, "CSR": 0.5495580808080809, "EFR": 0.7428571428571429, "Overall": 0.6880142947330448}, {"timecode": 99, "UKR": 0.798828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.84375, "KG": 0.51484375, "before_eval_results": {"predictions": ["\"The people kill him with the blocks,", "37", "dismissed all charges", "U.S. Defense Department", "11,", "inmates", "Kenyan and Somali", "prostate cancer,", "Philip Markoff,", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her; girls banned from school, their books burned,", "Red Lines", "The Kirchners", "an African-American woman for the job.", "Arsene Wenger", "Gary Coleman", "Carrousel du Louvre,", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "Marcus Schrenker,", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "June 25.", "Alejandro Peralta", "Kerstin Fritzl,", "Amnesty International.", "The Tinkler.", "\"Here Comes the Sun.\"", "overthrow the socialist government of Salvador Allende in Chile,", "a lump in Henry's nether regions", "reached an agreement late Thursday", "snow,", "\"Raiders of the Lost Ark.\"", "dogs who walk on ice in Alaska.", "45 minutes, five days a week.", "school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "as he tried to throw a petrol bomb", "al-Moayad", "\"I wanted to shove it up that black a--.\"", "3 thousand", "burning of a church.", "The cause of the child's death will be listed as homicide by undetermined means,", "Peruvian Supreme Court", "about 2,000", "park bench facing Lake Washington", "Cirque du Soleil", "9", "for the rest of the year", "94", "Bobby Darin", "foreign investors", "neck", "wrigley", "CBS", "in round five of the 2017 season", "North Dakota", "Tom Wolfe", "Charlie and the Chocolate Factory", "Death of a Salesman", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6630001243156485}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.7741935483870968, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.25, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-807", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4326", "mrqa_hotpotqa-validation-2793", "mrqa_hotpotqa-validation-34"], "SR": 0.59375, "CSR": 0.55, "EFR": 0.6538461538461539, "Overall": 0.6722536057692308}]}