{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4020, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.859375, "QA-F1": 0.8760416666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.859375, "CSR": 0.8671875, "EFR": 1.0, "Overall": 0.93359375}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "Brotherhood", "high demand", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "hot winds blowing from nearby semi-deserts", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "low ratio of organic matter to salt and water", "the city's beaches are artificial", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "time goes", "guardian", "guardian", "abolitionists", "one mile above sea level"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6771475919913419}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-7408", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.609375, "CSR": 0.78125, "EFR": 0.96, "Overall": 0.870625}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double membrane", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "comb plates", "calcitriol", "Warsaw", "time", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail and a carnivorous octopus", "Orestes", "the Galapagos Islands", "the \"Today\" show host did a terrible job", "the process by which water changes from a liquid to a gas", "the best minds in the travel industry", "before the world's first cold breakfast cereal", "inks, gel glaze, protecting wax, paint, gel medium and any other...", "the Mycenaean kingdoms, the Hittite Empire", "a biological process that displays an endogenous, entrainable", "before the ghost of noted impresario David Belasco is said to no longer haunt it", "the Normandy Landings", "Evelyn \"Billie\" Frechette", "fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7028544372294372}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.671875, "CSR": 0.75390625, "EFR": 0.9523809523809523, "Overall": 0.8531436011904762}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Latin Rhenus", "gambling", "the wing of the secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25", "May 2013", "K-9 and Company", "capturing prey", "C4", "pasture for cattle", "Ford", "1,300,000", "the end result of ATP energy being wasted and CO2 being released, all with no sugar being produced", "two tumen", "eight", "A computational problem", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empire", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "New York City Mayor Michael Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "the war years", "semiconductors", "Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "pictures", "the foyer of the BBC building", "Christianity", "Manchester United", "his son, Isaac, and daughter, Rebecca", "three", "change course", "Tsvangirai", "a lion Among Men", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a miracle food", "Chelsea Does", "Luxembourg"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7018385439991044}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.06896551724137931, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.2666666666666667, 1.0, 0.0, 0.2, 0.0, 0.8333333333333333, 0.25, 0.0, 0.7272727272727273, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-8874", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366"], "SR": 0.65625, "CSR": 0.734375, "EFR": 1.0, "Overall": 0.8671875}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "the host's cell membrane infolding to form a vesicle to surround the ancestral cyanobacterium", "QuickBooks", "surface condensers", "clinical pharmacists", "a seal", "Philip Howard", "Duke Richard II of Normandy", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "the constitutional traditions common to the member states", "euphoric", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "gurus, mullahs, rabbis, pastors/youth pastors and lamas", "B cells", "property", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Goa", "at the 61st Primetime Emmy Awards", "the Louvre", "Leo Frank", "as he tried to throw a petrol bomb at the officers", "Graziano Transmissioni", "opposition parties", "204,000", "Newcastle retained fourth place with a 3-1 victory over Blackburn, who remained in the relegation zone.", "the release of the four men", "putting a personal and human face on the issue... there's nothing more crucial,\" said Washington Post columnist Sally Quinn.", "Ed McMahon", "the Magna Carta is expected to fetch at least $20 million to $30 million, Redden said.", "the Democratic VP candidate", "at the University of Alabama in Huntsville", "Ali Larijani", "ballots", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "promotes fuel economy and safety while boosted the economy.", "heart rate that exceeds the normal resting rate", "heavy breeds", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6633677218356978}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.6666666666666666, 0.9166666666666666, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-8715", "mrqa_squad-validation-1090", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-1852", "mrqa_squad-validation-2531", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.578125, "CSR": 0.7083333333333333, "EFR": 1.0, "Overall": 0.8541666666666666}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "unfairly biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "straight line", "In the autumn of 1991, talks were held for the broadcast rights for Premier League for a five-year period, from the 1992 season.", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1", "nerves", "1700", "Christo's", "a double sugar or a disaccharide (di = two)", "Howard Dean", "the heart, blood, and blood vessels.", "Reg Presley", "God took millions of years to make everything.", "Bratislava, this country's capital", "Diana, the Princess", "slave trade.", "vena cava", "Chesapecten Jeffersonius", "bull's-eye", "Tartarus", "cyclorama - Search-ID.com", "Nancy Reagan", "Bardiya, the king he killed & replaced, had been an impostor", "a piece of Luxury", "Count Ferdinand von Zeppelin", "huge", "William IV, Duke of Clarence", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas", "Dr. Jack Shephard, Kate Austen, Sayid Jarrah, Hugo \" Hurley\"", "comic book", "Love Is All Around", "Los Angeles Dance Theater", "France", "the FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5995967574092573}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, false, false, false, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-2921", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-2340", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.515625, "CSR": 0.6808035714285714, "EFR": 0.967741935483871, "Overall": 0.8242727534562212}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "encourage growth in richer countries", "Torchwood", "9.1 million", "little support", "individual countries", "cattle", "Western Xia", "a maze of semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "Capability deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rod Steiger", "hog", "John Sexton", "Breathless", "coffee", "a tutu", "Annapolis", "Spring", "klammeraffe", "female", "Allah", "bones", "Python", "The Bible: In the Beginning", "Inman", "Faith Hill", "Ben Affleck", "U.S.", "V", "time", "Yardbird", "Sweden", "Southeast Asia", "hydrogen", "destroyed", "Perfume", "New Jersey Economic Development Authority's 20% tax credit", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5754870129870129}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7468", "mrqa_squad-validation-7626", "mrqa_squad-validation-1938", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_triviaqa-validation-3911", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.53125, "CSR": 0.662109375, "EFR": 0.9666666666666667, "Overall": 0.8143880208333334}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes or an antibody-based humoral response", "producers", "BSkyB", "Kawann Short", "Daidu in the north", "silent", "22 miles", "the park", "1965", "tidal currents", "an exlposion", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "Orange Democratic Movement (ODM-K)", "Irish", "Red Army", "20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Body of Proof", "seven-eighths", "Franois Girardon", "the Atlas Mountains", "Madrid", "the Danube", "Yahweh", "leather", "George Pullman", "plums", "Jesus Christ", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "a tonka bean", "a fraction", "Hypnos", "Texas", "International House of Pancakes", "a black breed", "Bill of Rights", "the ACT", "Brasilia", "chapter 5 \"Solitude\"", "Baja California", "Harry Whittington", "a solar day", "William Donald Scherzer", "Edward Hopper", "the CIA", "d'Artagnan", "a green substance", "1985", "apples, blueberries, bananas", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.5, "QA-F1": 0.5850206500172532}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.33333333333333337, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6559", "mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.5, "CSR": 0.6440972222222222, "EFR": 0.96875, "Overall": 0.8064236111111112}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "Exploration", "prep schools", "Cultural imperialism", "a strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes, the most characteristic musical instrument in the region", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Khrushchev", "Hera", "phylloxera", "Elton John", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Wash.", "Carmen", "Genoa", "15", "tarn", "972; 451; 100; or 25", "bison", "Ann Widdecombe", "an equilateral triangle", "the Old Kent Road", "Tuesday", "sodium pyroborate", "Ab Fab", "Massachusetts", "Barrow", "California", "the Susquehanna River", "Kajagoogoo", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "actor", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "Bain Capital", "Champion"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6489583333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-5376", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.5625, "CSR": 0.6359375, "EFR": 0.9642857142857143, "Overall": 0.8001116071428571}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult, if not impossible", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "a bacteria", "a tree with fragrant spring flowers", "Ken Russell", "Dan Dare", "mucia", "Smiths", "Mike Tyson", "Morocco", "Pesach", "Brian Deane", "alexidoscopes", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "Underground Railroad", "pouk", "nepotan", "passion fruit", "Portugal", "football", "Serena Williams", "63 to 144 inches", "Titanic", "William Tell", "Christian Dior", "a shaggy, candy-loving dog", "Mendip Hills", "Wichita", "the sacrament of Holy Communion", "New Croton Reservoir in Westchester and Putnam counties", "Andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "The Knights of Ni!", "Roman Polanski"], "metric_results": {"EM": 0.671875, "QA-F1": 0.6885416666666666}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6263", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-4371", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-4926", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.671875, "CSR": 0.6392045454545454, "EFR": 1.0, "Overall": 0.8196022727272727}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network", "public service", "Guy de Lusignan", "tiger team", "sub-group of T cells", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "party of God", "five", "Whist", "Nile River", "Toscana", "vision loss", "black", "Pluto", "chromium", "copper", "The Hague", "Vancouver Island", "Ironside", "George Smiley", "gorky", "trout", "Beyonce", "Wordsworth", "man V Food", "Queen Elizabeth II", "Samuel Johnson", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "lettuce", "huddsyn", "Ukraine", "Shrek", "Oslo", "horses", "rhodyman", "Bob Fosse", "sweden", "Shanghai", "gile de Becque", "boat lifts", "Billy Colman", "17 October 2006", "beer", "Las Vegas", "Saturday's Hungarian Grand Prix", "Capuchin Church of the Immaculate Conception", "Edgar Allan Poe", "creeler"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6662946428571428}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-8252", "mrqa_squad-validation-6530", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-6760", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.609375, "CSR": 0.63671875, "EFR": 1.0, "Overall": 0.818359375}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "pioneer", "The Handmaid's Tale", "bonobo", "The Fault in Our Stars", "CR-X", "video", "1961", "400 MW", "Total Nonstop Action Wrestling", "Galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen County", "Continental Army", "Jack St. Clair Kilby", "Ryan Babel", "Akhmadovich Kadyrov", "July 16, 1971", "1933", "\"The Heirs\"", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca Hopkins", "British military", "England", "Paul W. S. Anderson", "a Christian church", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "drug labs, markets and convoys", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "cather Mark Twain", "dapple-grey", "pre-Columbian times"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7064732142857143}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3896", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.640625, "CSR": 0.6370192307692308, "EFR": 0.9130434782608695, "Overall": 0.7750313545150502}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold", "\u00c9mile Girardeau", "Brownlee", "partial funding", "often run by a religious order, i.e., the Society of Jesus or Congregation of Christian Brothers,", "NCAA Division II", "Adrian Lyne", "Michael Chekhov", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\" from DC Comics", "16\u201321", "Vince Guaraldi", "Tony Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "Liquidambar styraciflua", "Marquis de Lafayette", "Gujarat", "three", "Winter Haven", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "6", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X.", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Johnny Cash", "President of the United States negotiates treaties with foreign nations", "2015", "1982", "rod", "Chris Robinson", "gossip Girl", "fluid dynamics", "dwindle or fizzle out", "Big Blue Woman", "Richie Unterberger"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6716906055900621}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, true, false, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.17391304347826086, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7142857142857143, 1.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_squad-validation-7036", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-7020", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.578125, "CSR": 0.6328125, "EFR": 1.0, "Overall": 0.81640625}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "1970", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30\u201360% of Europe's total population", "kilogram-force", "ten times their own weight", "Quaternary", "1887", "other ctenophores", "symbiotic", "mathematical models of computation", "Vistula River", "100 to 150", "iPod Nano and iPod Touch", "at the school.", "March 8", "Mike Meehan", "Catholic League", "well over 1,000 pounds", "\"He is obviously very relieved and grateful that the pardon was granted,\" Dean said.", "Friday", "Majid Movahedi", "different women coping with breast cancer in five vignettes", "\"black rain\" of drilling fluid and a roar of escaping gas erupted from the doomed Deepwater Horizon shortly before the explosion that sank the oil rig,", "depressed", "milk", "Lance Cpl. Maria Lauterbach", "Hyundai Steel", "London", "estimated 400", "Val d'Isere, France", "the results by a chaplain about 1:45 p.m., per jail policy.", "two soldiers and two civilians", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J. Crew", "Japanese Foreign Minister Hirofumi Nakasone", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "\"Empire of the Sun,\"", "suppress the memories and to live as normal a life as possible", "about 4 meters (13 feet) high", "Dublin", "Democrat", "Spanishfork,", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "The BFG", "mercury"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5083615256271506}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8571428571428571, 0.27272727272727276, 1.0, 1.0, 0.8750000000000001, 0.11999999999999998, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.1818181818181818, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.40625, "CSR": 0.6177083333333333, "EFR": 0.9210526315789473, "Overall": 0.7693804824561403}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "prime", "50 fund", "Camisards", "over $40 million", "GTE", "1,100", "spinat", "Oligocene", "Wanda Eessa Barzee.", "Christopher Columbus", "a Little Rock military recruiting center.", "March 24,", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher", "\"She had a smile on her face, like she always does when she comes in here,\"", "56", "Fred Bright, the district attorney in Milledgeville,", "\"The Da Vinci Code\"", "Heshmat Tehran Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "12 off-duty federal agents", "Seoul", "resources", "highest ranking former member of Saddam Hussein's regime still at large,", "he won two Emmys for work on the 'Columbo' series starring Peter Falk.", "\"It's like having one of our own kids in this situation.\"", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "gun charges", "Mugabe and Tsvangirai", "Amstetten,", "African National Congress Deputy President Kgalema Motlanthe,", "spiral into economic disaster.", "resigned", "The security is less kinetic [than] it was four years ago.", "a strict interpretation of the law,", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000 or so are estimated to be there now.", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "topaz", "Thomas Jefferson", "The Left Book Club", "holography"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6275114064176563}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.4, 0.6428571428571429, 0.28571428571428575, 0.0, 1.0, 0.42857142857142855, 0.0, 0.09090909090909091, 0.5, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.6923076923076924, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.53125, "CSR": 0.6123046875, "EFR": 0.9333333333333333, "Overall": 0.7728190104166667}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand people", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary negligence", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "30 years ago.", "murder", "next year", "the Obama administration has not yet articulated a Sudan policy.", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear weapon", "\"whole ethos is one of violence\" and that it had \"made a brutal choice to step up attacks against innocent civilians", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "environmental", "two women", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Monday", "male veterans struggling with homelessness and addiction.", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs", "have expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "1918-1919.", "1950s,", "U.S. troops", "Brazil's efforts to reverse the tide of the AIDS epidemic have become the object of admiration in the global health community, but the trailblazer is encountering new challenges.", "vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "French Revolutionary ideals of liberty, equality, and fraternity", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "United States", "George Blake", "Bogota,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6484426562551563}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.27272727272727276, 0.22222222222222224, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.5, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 0.14285714285714285, 0.05405405405405405, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.53125, "CSR": 0.6075367647058824, "EFR": 0.9666666666666667, "Overall": 0.7871017156862745}, {"timecode": 17, "before_eval_results": {"predictions": ["lower", "a pharmacy practice residency", "questions and answers", "Genesis", "Captain Francis Fowke, Royal Engineers,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich", "\"Mad Men\"", "Windsor, Ontario,", "$50", "Afghanistan's restive provinces", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends", "collaborating with the Colombian government,", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Gary Brooker", "the exact cause of IBS remains unknown,", "in the north and west of the country,", "forcibly injecting them with psychotropic drugs", "introduce legislation Thursday,", "$250,000", "this week", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "a fair and independent manner and ratify successful efforts.", "Virgin America", "Wellington, Florida,", "Daniel Wozniak,", "22", "the UNHCR", "how health care can affect families.\"", "U.N.", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "at checkposts and military camps", "Lashkar-e-Tayyiba (LeT)", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "slapped out his eye and slashed open his left eyebrows.", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "five - year time jump", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "7", "rice wine", "Halifax"], "metric_results": {"EM": 0.5, "QA-F1": 0.5882633374591095}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.5, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.125, 1.0, 1.0, 1.0, 0.0, 0.5, 0.3529411764705882, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-4124", "mrqa_newsqa-validation-841", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.5, "CSR": 0.6015625, "EFR": 1.0, "Overall": 0.80078125}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam", "Defensive ends", "the dot", "chastity", "European Court of Justice", "bronze medal in the women's figure skating final,", "\"trying to steal the election\" and \"intimidating the population and election officials as well.\"", "UK", "Teen Patti", "Argentina", "Congress", "28", "Frank Ricci,", "Kurdish Gas City.", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "the FDA is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "political and religious", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Saudi Arabia", "federal officials were reviewing an unspecified threat to disrupt the inauguration, according to the Department of Homeland Security.", "the mammoth's skull,", "could further assist with the reconstruction projects, such as building hospitals, schools, sanitation facilities and investment projects that would have direct impact on the socioeconomic development of the Afghan and Pakistani societies.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "hiring of hundreds of foreign workers for a construction project at the Lindsey oil refinery in eastern England.", "Ben Roethlisberger", "Winehouse", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally,", "Lindsey Vonn", "\"Larry King Live.\"", "Amnesty International.", "President Obama's race", "Brazil", "Saluhallen,", "AbdulMutallab, accused of trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger.", "\"Taxman,\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6152933514836321}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.9714285714285714, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.046511627906976744, 0.0, 1.0, 0.08695652173913043, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.21428571428571427, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254"], "SR": 0.53125, "CSR": 0.5978618421052632, "EFR": 0.9666666666666667, "Overall": 0.7822642543859649}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Danny Trevathan", "11", "if he were removed from the school, Tesla would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "most of those who managed to survive the incident hid in a boiler room and storage closets", "that the Bainbridge would be getting backup shortly.\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book.", "that Jackson was in good health, contrary to media reports he was diagnosed with skin cancer.", "stand down", "Ashley \"A.J.\" Jewell,", "17", "Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "home in rural California,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "steamboat", "Haeftling range.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "CNN's \"Larry King Live,\" ABC's \"Good Morning America\" and \"The View.\"", "home in Flint, Michigan,", "protective shoes", "public-sector labor", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "glass shards", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International", "\"Grandmasters\"", "Suffragist", "Canterbury", "Tunisia", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7102610291755029}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.5, 0.28571428571428575, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1326", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782"], "SR": 0.5625, "CSR": 0.59609375, "EFR": 0.8928571428571429, "Overall": 0.7444754464285714}, {"timecode": 20, "before_eval_results": {"predictions": ["Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment from government officials.", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhism", "1978", "1956", "1969", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Archduke Franz Ferdinand of Austria, heir presumptive to the Austro - Hungarian throne, and his wife", "Koine Greek", "October 1941", "peace between two entities", "mughal garden of rashtrapati bhavan", "Cee - Lo", "after Shawn's kidnapping", "tomato pur\u00e9e generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour Party", "three times", "November 25, 2002", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two", "Alberto Salazar", "a collection of live animals", "American", "Hoosick,", "CEO of an engineering and construction company with a vast personal fortune.", "1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "south-central Washington,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6944448004480899}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8421052631578948, 0.5263157894736842, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.9696969696969697, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.578125, "CSR": 0.5952380952380952, "EFR": 0.9259259259259259, "Overall": 0.7605820105820106}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "the One Ring to rule them all", "Washington metropolitan area", "10 logarithm of the molar concentration", "the breast or lower chest of beef or veal", "Sargon II", "Tagalog or English", "around 1600 BC", "By mid-1988", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Giancarlo Stanton", "Orangeville, Ontario, Canada", "electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford", "by the early 3rd century", "in the pancreas", "Elk and Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "1957", "1776", "1963", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "her boyfriend Lance", "embryo", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Gillis Grafstr\u00f6m", "Sophocles", "Tim Allen", "thick skin", "a cake", "India", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "Rear-Admiral of the Navy", "Marktown, Clayton Mark's", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "pardoning Richard Nixon", "Ellen DeGeneres", "1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5530641182755154}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 0.28571428571428575, 0.0, 0.4, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.7777777777777778, 1.0, 0.0, 0.5, 0.6666666666666666, 0.08333333333333333, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_searchqa-validation-843", "mrqa_hotpotqa-validation-3984"], "SR": 0.40625, "CSR": 0.5866477272727273, "EFR": 0.9736842105263158, "Overall": 0.7801659688995215}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16, and Acts 1 : 13 )", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "American electronic music duo The Chainsmoker", "an annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash", "Massachusetts", "two", "Thomas Jefferson", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "on a sound stage in front of a live audience in Burbank, California", "Tom Lennon", "2009", "Yuzuru Hanyu", "Glenn Close", "Kanawha", "flawed democracy", "China", "Kirk Douglas as Matt Morgan   Anthony Quinn as Craig Belden", "Jodie Foster", "February 27, 2007", "Neil Patrick Harris", "8ft", "Owen Vaccaro", "food", "on the lateral side", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff", "London", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "2005", "March 1", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "the Burmese Horse of Queen Elizabeth II", "insect\u00ef\u00bf\u00bd", "vocalist Eddie Vedder", "2005", "Dan Tyminski", "The 19-year-old woman", "southern port city of Karachi,", "at least nine", "Bashar al-Assad", "the Bible", "biathlon"], "metric_results": {"EM": 0.5, "QA-F1": 0.6295113289303078}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, true, false, true, false, false, false, true], "QA-F1": [0.9473684210526316, 1.0, 1.0, 1.0, 0.25, 1.0, 0.34782608695652173, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 0.4444444444444445, 0.4, 1.0, 1.0, 0.8, 0.4444444444444445, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-4138"], "SR": 0.5, "CSR": 0.5828804347826086, "EFR": 0.90625, "Overall": 0.7445652173913043}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "the Emperor", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Ali", "Vijay Prakash", "Article 1, Section 2, Clause 3", "the Constitution of India came into effect on 26 January 1950", "Ian Hart", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Isaac Newton", "Jimmy Flynn", "detritus", "September 27, 2017", "Ireland", "1978", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "September 28, 2017", "Alex Skuby", "Virginia", "March 2016", "1991", "Terry O'Neill", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "a single peptide bond or one amino acid with two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "investment bank Friedman Billings Ramsey", "New York City", "cutting", "Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "Al Schmid", "1871", "eye", "The History Boys", "aprimitive type of fish", "White Knights of the Ku Klux Klan", "five", "Darkthrone", "Kingman Regional Medical Center,", "Phillip A. Myers", "Osama", "Antarctica", "axon", "gourmet Mushrooms"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6174192994505495}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.4, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3076923076923077, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-7004", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_hotpotqa-validation-395", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.484375, "CSR": 0.5787760416666667, "EFR": 0.9696969696969697, "Overall": 0.7742365056818182}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "James Francis Thorpe", "1996", "the onset and progression of Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "the Indian School of Business", "New York", "Texas Tower Sniper", "C. H. Greenblatt", "\"The Curious Case of Benjamin Button\" (2010)", "A55", "Corendon Dutch Airlines", "86", "Minneapolis, Minnesota", "the village of Dornie", "Fatih Ozmen", "U.S.", "Pacific Place", "writing for \"The New York Times\" and \"Popular Mechanics\", and is a regular contributor to various CNBC shows such as \"On the Money\"", "Flamingo Las Vegas", "the City of Westminster, London", "2016", "Wildhorn", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "Ferrara", "Guadalcanal Campaign", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Lee Alexander", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland, OR", "Yoruba", "\"Lucky\"", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "The Tenth Planet ( 1966 )", "Piers Morgan", "Jehan Mubarak", "Medellin", "Joe Jackson", "alternative-energy vehicles", "2004", "genes", "olive", "Tjejmilen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6472718253968254}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 0.4, 0.5, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-4328", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_triviaqa-validation-2659", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-5511"], "SR": 0.515625, "CSR": 0.5762499999999999, "EFR": 0.967741935483871, "Overall": 0.7719959677419355}, {"timecode": 25, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater", "Anna Clyne", "Terence Winter,", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "DS Virgin Racing reserve driver", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "American", "acid house", "in  time which was popular in Austria, south Germany, German Switzerland, and Slovenia at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage on TV, radio and online", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles of Timmy Sanders", "PBS", "second largest", "Citric acid", "in 1989", "Lola Dee", "The Five", "Walt Disney Feature Animation", "UEFA Super Cup", "torpedoes", "1972", "Geographical Indication tag", "Ringo Starr", "Cleveland Celtics", "World Championship Wrestling", "1994", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "1986", "Lou Gehrig", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram,", "mai man", "\"Death, be not\"", "green"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7220914502164502}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.65625, "CSR": 0.5793269230769231, "EFR": 0.9090909090909091, "Overall": 0.744208916083916}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X.", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "Sleeping Beauty", "Orchard Central", "Gareth Johansson", "late eighteenth century", "The Snowman", "1898", "Premier League club Liverpool", "port city of Aden", "Native Americans", "Prince Louis of Battenberg", "1985", "Archie Andrews", "2 May 2015", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Joseph Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "racehorse breeder and owner", "Las Vegas", "1919", "Kevin Spacey", "Love Streams", "stunt jumping", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "Old Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "Pantone Matching System", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Mace Windu", "1963", "a palla", "Car ferry", "Lyrical Ballads", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "Kongo Gumi", "potp0urri"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6166180173992675}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268", "mrqa_searchqa-validation-3515", "mrqa_searchqa-validation-13669"], "SR": 0.53125, "CSR": 0.5775462962962963, "EFR": 0.9666666666666667, "Overall": 0.7721064814814815}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "\"Dumb and Dumber\"", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Alistair Grant", "most awarded female act of all-time", "Dunlop Tyres", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Westerister", "Kalokuokamaile", "Raden Panji", "Don Bluth", "December 8, 1970", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "\"I Should Have Known Better\"", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914 machine gun", "Steve Kiley", "Prussian army general", "January 2004", "co-founder and lead guitarist", "ten", "seven", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "Colossus of Rhodes", "Equatorial Guinea", "c3H8O3", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off Somalia's coast.", "salt", "nasal septum", "wavelengths"], "metric_results": {"EM": 0.609375, "QA-F1": 0.694624582289056}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.609375, "CSR": 0.5786830357142857, "EFR": 0.92, "Overall": 0.7493415178571429}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "prep schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation", "Herrenhausen", "Henry Mancini", "japn", "Gordon Ramsay", "Gorbachev", "an Air Force disc jockey", "a qu\u00e9 puede", "Rameses II", "Anna (Julia Roberts)", "binky", "balsam fir", "Paddy Doherty", "a milder disease, which was fatal in less than one percent of cases", "the pyramids", "Libya", "Chuck Berry", "bia 515", "Iran", "Who\u2019s Who", "wry, compassionate, and brimm[ing] with... open-minded intelligence", "a father figure", "Tax Day", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "Belle", "Fabio Capello", "Manhattan", "Marc Norman", "The Greatest", "a singer and performer", "the college circuit", "a Scotsman\u2019s bonnet", "tenor saxophonist", "Tacoma", "The Cross Foxes Inn", "Cardiff", "Baton Rouge", "a carburetors", "Tahrir Square", "Romanian", "bathtub curve", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "a small species of foraging mammal", "Greek", "passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "December 6, 1941", "North America", "Florida's Everglades", "Garth Brooks", "glamorous, sexy and international", "driving through a fast-food chain", "The Bad", "shark"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4750124007936508}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, true, false, false, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.4285714285714285, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-2216", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-1670", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-6096", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-3909", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-12186"], "SR": 0.40625, "CSR": 0.5727370689655172, "EFR": 0.9473684210526315, "Overall": 0.7600527450090744}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Tim Duncan", "James W. Marshall", "Blue laws", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Thompson", "between 8.7 % and 9.1 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "status line", "innermost in the eye", "jeff hanson", "Triple Alliance of Germany", "Andrew Lloyd Webber", "1955", "The president - elect and the love interest to Candace", "Buffalo Lookout", "his friends, Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar worth close to 5,770 guaranies", "the original Star Trek television series", "1960", "Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Donald Sutherland", "Anna Faris", "1995", "i want to be with you everywhere", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Cairo, Illinois", "in the 1970s and'80s", "Hebrew Bible", "Dusty", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "The Miracles", "a domain", "forearm", "hershey Hurricane", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "teenager", "Long Island", "Romney", "Peter", "heart disease", "dancing with the stars"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5918071338383839}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.25, 0.5, 1.0, 0.0, 0.0, 0.0, 0.56, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1958", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426"], "SR": 0.53125, "CSR": 0.5713541666666666, "EFR": 1.0, "Overall": 0.7856770833333333}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "cultural tourism and sports tourism", "a circle", "( Sequoia sempervirens)", "The Fairly Oddparents", "(Elegy to the Spanish Republic", "taximeter", "panthera onca", "The Sun Also Rises", "Harry Reid", "Ray (2004)", "Axis", "forge", "(the Kinetoscope", "white men who were buying drugs", "(Les Fleurs du mal)", "Blackbird", "Footprints", "Caliban", "Los Angeles Kings", "(St Brigantine", "Tommy Lee Jones", "Zacchaeus", "The Memory Keeper's daughter", "George Eliot", "hubris", "Yahtzee", "who's the Boss?", "markup language", "hives", "74.3", "William S. Hart", "joshua", "Pride and Prejudice", "GreeK ALPHABET", "Kosher Wines", "Munich", "Michael Jordan", "feria Marmotae Monacis Ground Hog Day", "Prospero", "Hikaru Sulu", "tropical rainforests", "(pte brise) for sweet and savory pies and tarts, 2) a... 2 Carefully empty the crumbly dough mixture", "kyushu", "honey", "Boston", "Fisher- Price", "Arctic Ocean", "the new Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1997", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "July 16, 1911", "Harlow Cuadra and Joseph Kerekes", "Newtonian mechanics", "Israel", "top designers", "anti-trust laws."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6130208333333333}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2965", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-3260", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-3963", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-5093", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3054"], "SR": 0.53125, "CSR": 0.5700604838709677, "EFR": 1.0, "Overall": 0.7850302419354839}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Kramer's caddy Stan", "Chancellor of Austria", "January 21, 2016", "Bloomingdale Firehouse", "elise Marie Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge", "Bangkok, Thailand", "Oklahoma Sooners", "Merrimack", "Charlie Wilson", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland", "\"Slaughterhouse-Five\"", "Adventures of Huckleberry Finn", "wine", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Massapequa, New York", "Sinngedichte", "The Highwaymen", "Madrid", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Kenneth Hood \"Buddy\" MacKay Jr.", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Lenny Jacobson", "Hathi Jr", "1935", "a serpent", "slow", "The Miracles", "the Rockies", "the anti-trust unit", "Friday", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6784455128205128}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-3320", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.609375, "CSR": 0.5712890625, "EFR": 0.92, "Overall": 0.74564453125}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 mission", "jellyfish", "March", "a blanks", "Fauntleroy", "the World Bank", "Eat porridge", "Kofi Annan", "oxygen", "pamphlets, posters, ballads", "Taggart", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "Manfred Mann", "sepp Blatter", "the BBC", "Route 66", "Brussels", "a group of Jacobites", "John Poulson", "A\u00e9roport de Paris \u2013 Orly", "the Treaty on European Union", "Jack Frost", "Saskatchewan (province)", "bajec-Lapajne", "the Solent", "vomiting", "Basketball", "Bristol Aeroplane Company", "Spinach", "Tony Meo", "\u201cArgo\u201d", "Sagittarius", "Surrey", "1971", "chippenham", "Budapest", "Chile", "William Shakespeare", "borax (sodium tetraborate decahydrate, Na2B4O7\u221910H2O)", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Diana Dors", "Kent", "Vickers-Armstrong's", "Ray Charles", "The onset of rigor mortis and its resolution partially determine the tenderness of meat", "USCS or USC", "Miller Brewing", "northwestern Italian coast", "Sydney, New South Wales, Australia", "without loved ones, without homes, without life's belongings.", "Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\" Kristal Kraft, a real estate agent in Denver,", "Peter Bogdanovich", "the Mourning dove", "Cyprus"], "metric_results": {"EM": 0.484375, "QA-F1": 0.561235119047619}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.4444444444444445, 0.1, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-2177", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539"], "SR": 0.484375, "CSR": 0.568655303030303, "EFR": 0.9090909090909091, "Overall": 0.738873106060606}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "No Secrets", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown, Ph. D.", "Antarctica", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms, and the garden is the largest private garden in London", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "a long line", "Jesus'birth", "a habitat", "Kirsten Simone Vangsness", "Central Germany", "Andrew Johnson", "Etienne de Mestre", "Atreus, Agamemnon's father", "electors", "Julia Ormond", "Sauron", "1961", "Staind", "2013", "March 1", "novelization", "red oxide", "Spain disputes the legality of the constitution and claims that it does not change the position of Gibraltar as a colony of the UK with only the UK empowered to discuss Gibraltar matters on the international scene", "Thorne Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "`` Everybody Dies in Their Nightmares ''", "abdicated in November 1918", "one of the most recognisable structures in the world", "erosion", "March 2, 2016", "stuffing", "1996", "Ray Charles", "16", "Ramones", "1800", "Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "Los Angeles", "May 2010", "France", "Heath Ledger", "Wilson Pickett", "centaur", "music lover who must work for a kingpin", "cricket fighting", "Luis Edgardo Resto", "The drama of the action in-and-around the golf course", "German authorities", "Islamabad", "Tunisia", "RAND", "alberta"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5338332245829063}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 0.5, 0.06451612903225806, 1.0, 1.0, 1.0, 0.18181818181818182, 0.15384615384615385, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.06451612903225806, 0.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.484375, "CSR": 0.5661764705882353, "EFR": 0.9696969696969697, "Overall": 0.7679367201426025}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Zeebo", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Universal Pictures", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "prophets and beloved religious leaders", "state legislators of Assam", "a key role in digestion of proteins", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "pickup trucks", "Isabella Palmieri", "constant pressure", "`` mind your manners '',`` mind your language '', `` be on your best behaviour '' or similar", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "20 November 1989", "Tom\u00e1s de Torquemada", "Bob Gaudio", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "first published in the United States by Melvil Dewey in 1876", "2003", "Sebastian Lund ( Rob Kerkovich )", "5 September 1666", "California State Route 1", "The management team", "various submucosal membrane sites", "enabled business applications to be developed with Flash", "Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "braking to a full stop", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Tennesseeitans", "lowest air temperature record", "a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "future AC/DC founders Angus Young and Malcolm Young", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "Olympic medal", "Henry Ford", "Toyota", "Vice President of the United States", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread, so they're usually classed as benign."], "metric_results": {"EM": 0.46875, "QA-F1": 0.6150806220041134}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.7499999999999999, 0.3333333333333333, 0.3636363636363636, 0.888888888888889, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.6666666666666666, 1.0, 0.29629629629629634, 0.761904761904762, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.2758620689655173, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.46875, "CSR": 0.5633928571428571, "EFR": 0.8823529411764706, "Overall": 0.7228728991596638}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "higher than normal O2 exposure for a fee", "Game of Throne Season 6", "Venezuela", "Mexico", "boxing News", "Finding Neverland", "sarto", "the Arctic Ocean", "\"Egg in a bottle\"", "dams", "Lafayette", "Elijah Muhammad", "the area of light winds & calms in equatorial regions", "the Village People", "Alexander Pushkin", "Australia", "Munich", "Mexico Newspapers", "working at night", "pope", "the Delta", "The AI Behind Watson", "Pierre-August Renoir", "mister", "Les Huguenots", "Innsbruck", "L Angeles Superior Court Judge Lance A. Ito", "Microsoft", "basket Asparagus", "the Trump Organization", "vikings", "Atlantic City's First Boardwalk", "Blackwater USA", "elephant", "American Airlines", "alberta ibex", "Odysseus", "december he got his name because Mexican victims of his attacks would cry out in terror to St. Jerome.", "Kensington Palace", "Butch Cassidy", "the Netherlands", "Pocahontas", "author of The Lion, the Witch, and the Wardrobe", "Dagny Taggart", "the amygdala", "the CME", "Las Vegas", "danskin", "bounty", "Madrid Symphony Orchestra", "an ostrich or common ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "an ancient optical illusion toy", "John Morgan", "Hungarian Rhapsody No. 2", "Louis VII of France", "Sen. Patty Murray (D-Washington),", "63", "we are resetting,"], "metric_results": {"EM": 0.375, "QA-F1": 0.5159102182539682}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [0.5714285714285715, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_squad-validation-3610", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-13449", "mrqa_searchqa-validation-5219", "mrqa_searchqa-validation-16094", "mrqa_searchqa-validation-5473", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.375, "CSR": 0.5581597222222222, "EFR": 0.95, "Overall": 0.754079861111111}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act ( NIRA )", "User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "New Jersey's formal name for the new PATH station", "`` the Pier is Southend Pier", "Santa Monica", "layered systems of sovereignty", "Will", "31 January 1934", "Filipino American", "1773", "modern random - access memory ( RAM )", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Raghu II", "Olivia Olson", "1990", "Nickelback", "Bill Pullman", "BC Jean", "in IMAX 3D", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "retinal ganglion cell axons and glial cells", "the 1980s", "in all land - living organisms", "card verification value", "`` rebuke with all authority ''", "bohrium", "Germany", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum", "Mike Czerwien", "As of July 2017, there were 103 national parks encompassing an area of 40,500 km ( 15,600 sq mi )", "Vienna", "English", "Mexico", "\u201cThe Pope? How many divisions does he have?", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "$22 million", "leftist Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities", "cotton", "Dennis Haysbert", "Quinn", "The Weatherbys Novices' Hurdle Race"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6372542388167388}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 0.0, 0.0, 0.5, 0.5, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.5, 0.1, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-2833", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-1028", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161", "mrqa_triviaqa-validation-5460"], "SR": 0.53125, "CSR": 0.5574324324324325, "EFR": 0.8666666666666667, "Overall": 0.7120495495495496}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "the United States", "South Africa", "first among equals", "shine", "a cappella", "albinism", "orator", "aglet", "Saturday Night Live", "FC Bayern M\u00fcnchen", "winter", "Bonnie and Clyde", "French", "copper", "Dawn French", "Blackstar", "boston", "Doris Lessing", "Scooby-Doo", "Swaziland", "the festival of Britain", "Kent", "the Humber", "points based scoring system", "automobile", "Kent", "the Von Trapp family", "Culture Club", "Galileo Galilei", "Gertrud Margarete", "Scotland Yard detective", "Marilyn Manson", "Medellin", "The Tempest", "spark plugs", "brazilia", "Boulder Dam", "the long-term effects of using drugs", "Iraq", "Belle de Jour", "Morecambe", "ballet", "rain", "blue", "Asaph Hall", "France", "geena Davis", "Kunsky", "death and dying", "Lady Penelope", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "heavy turbulence", "different women coping with breast cancer", "Blaine", "sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6877976190476192}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-330", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.65625, "CSR": 0.560032894736842, "EFR": 1.0, "Overall": 0.780016447368421}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "Tyne", "the liver", "40", "table salt", "cuba", "cuba", "Bleak House", "Phil Redmond", "Stevie Wonder", "head", "hound", "hanover", "a moon", "the Earl of Strafford", "work", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "a man of gold", "a 1934 Austin seven box saloon", "Paul Anka", "cuba", "cuba", "the king", "Blade Runner", "Jay-Z", "leopard", "cymbals", "\u201cAir Bud\u201d", "San Diego", "Tory MP Andrew Mitchell", "Ticket Sarasota", "South Africa", "Christian Dior", "scrobbesbyrig", "a toothed whale", "cuba", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "a Baron", "lizard", "cuba", "frauds", "a sea horse", "even numbers", "Tony Blair", "sandstone", "54 Mbit / s", "Manley", "Stacey Kent", "\"Traumnovelle\" (\"Dream Story\")", "Anthony Lynn", "piano", "paid tribute to pop legend Michael Jackson,", "sweden", "French Guiana", "AOL", "cuba", "Tiger Woods"], "metric_results": {"EM": 0.5, "QA-F1": 0.5323660714285714}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_hotpotqa-validation-2852", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.5, "CSR": 0.5584935897435898, "EFR": 0.9375, "Overall": 0.7479967948717949}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "aldi", "Midnight Cowboy", "norma", "seborrheic dermatitis", "carol Hawkins", "steam engines", "Niger", "central Stockholm", "Tangled", "dogs", "georgia tyson", "Bulls Eye", "m. barrry de Vieuzac", "bajec-Lapajne", "Martin Clunes", "charles Darwin", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "jimmy Boyd", "Isambard Kingdom Brunel", "georgia", "1957", "Devon", "carles", "butter", "coagulation", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "E. T. A. Hoffmann", "Shanghai", "Spain", "grew", "Tuesday", "Guru Nanak", "Bleak House", "Harry Potter and the Half Blood Prince", "phosphorus", "Little Jack Horner", "Indianapolis", "norman humbert", "cuckoo", "Stringer", "Dodge", "Alice Cooper", "Majorca", "transfusions", "Royal Bengal Tiger", "inward spiral", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "The Cycle of Life", "forgery and flying without a valid license", "137", "a log cabin", "St. Patrick's Day", "defensive backs", "Sondheim"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5331101190476191}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.484375, "CSR": 0.556640625, "EFR": 0.9393939393939394, "Overall": 0.7480172821969697}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "lasky", "Washington", "de quincey", "the black death", "horses", "buffalo", "ptolemy philadelphus", "a dove", "Sarajevo", "the Bill of Rights", "dust", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "origami", "resistance", "scuba", "secretary", "julian humbert", "matricide", "jack Nicholson", "\u201cToday Is Another Day\u201d", "a linesider", "Tomorrow Never Dies", "Sudan", "a Great Dane", "Washington", "afghan", "New Hampshire", "James I", "Terry Bates", "the Philippines", "purple", "one-thousandth", "warblers", "a wave", "Rome", "10", "Southwest Airlines", "phone", "Jeffery Deaver", "The Comedy of Errors", "chicago", "Glyn Jones", "President Ford and first lady Betty Ford", "a crossword clue", "a shelf", "radicalization", "rodinsons", "Humpty Dumpty", "1998", "Tanvi Shah", "the EN World web site", "the 100th anniversary of the first \" Tour de France\" bicycle race", "Mach number", "Janet and La Toya", "more than 2.5 million", "researchers", "the Matrix", "normb Your Enthusiasm", "nibelung", "inequality of opportunity related to gender was low"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5064393939393939}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5454545454545454]}}, "before_error_ids": ["mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.4375, "CSR": 0.553734756097561, "EFR": 0.9722222222222222, "Overall": 0.7629784891598916}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "hula hoops", "nippon Sangyo", "the Golden fleece", "Roddy Doyle", "a counting table", "Robin Hood", "aeolus", "Velazquez", "South African", "london", "Norwegian", "tchaikovsky", "oliver Twist", "Scotland", "usborne", "David Bowie", "Buzz Aldrin", "Jean-Paul sartre", "joseph", "Dick Turpin", "rust", "jane krakowski", "Wiltshire", "tbilisi", "mel Gibson", "othello", "a hole", "glenn close", "Lacock Abbey", "alex b'Stard", "domestic cat", "anita Brookner", "james", "golda meyerson", "Black Sea", "bagram Theater Internment Facility", "missie dent", "a power outage", "Vienna", "The Archers", "shylock", "james sousa", "henry gee", "james Boyd", "shakespears Sister", "the Marx Brothers", "tyne", "habsburg Monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "18 - season", "from 1993 to 1996", "Denzel Washington and John Travolta", "March 23, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones.", "a bassoon", "the o.K. Corral", "butternut", "usistocles"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6287280701754385}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, false, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, false, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.10526315789473685, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-5773", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_hotpotqa-validation-2003", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.578125, "CSR": 0.5543154761904762, "EFR": 1.0, "Overall": 0.7771577380952381}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics", "work rule issues", "Eintracht Frankfurt", "Comoros Islands", "Britney Spears", "Jeddah, Saudi Arabia", "40", "chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "27,", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "dancy-Power Automotive Group showroom", "Michoacan Family", "64", "New Delhi, India", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career at his original club of Argentinos Juniors in 2007", "\"E! News\"", "Haiti's capital, Port-au-Prince, and other severely stricken parts of the country.", "United States Holocaust Memorial Museum, The American Academy of Diplomacy and the United States Institute of Peace", "ice jam", "toxic smoke from burn pits", "Benazir Bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "cal Ripken Jr.", "Johannesburg", "cancer", "acid attack", "International Boxing Federation welterweight champion in 2001", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m.", "former Mobile County Circuit Judge Herman Thomas", "\"A salute to the martyrs of the massacre, and our condolences to their families.\"", "the meteorologist's shoulder", "\"release\" civilians", "Dodi Fayed", "if Planet Solar completes its mission, the crew says that will be proof that the sun, and solar power, is the answer.", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc", "Pyongyang", "Misery", "jenn purdy", "Italo Balbo", "Thorgan", "River Clyde", "Peru", "jungle Jim", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5093078504098241}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.8000000000000002, 1.0, 0.923076923076923, 0.4, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.1111111111111111, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4210526315789474, 0.28571428571428575, 0.0, 0.6, 0.05714285714285715, 0.0, 1.0, 0.3636363636363636, 0.08, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-30", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-3948", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-5687", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.40625, "CSR": 0.5508720930232558, "EFR": 0.9473684210526315, "Overall": 0.7491202570379436}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.,", "1943", "Volvo 850", "the Mountain West Conference", "the National Basketball Association", "Western Europe", "political thriller", "Continental AG", "English football", "1989 until 1994", "the Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown,", "Lollywood and Pollywood films", "Emmanuel Ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1964", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs", "1988", "coaxial", "Philip Pullman's", "three different covers", "Malayalam cinema", "Regno di Dalmazia", "August 11, 1946", "Vincent Landay", "born September 6, 1967", "Estadio de L\u00f3pez Cort\u00e1zar", "Nickelodeon Animation Studio", "Nicolas Vanier", "1985", "Gal Gadot", "Meghan Markle", "Boeing B-17 Flying Fortress", "Erika Girardi", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "the UK\u2019s Trade Mark Registration Act 1875,", "blue", "elbow", "members of the lower house of parliament,", "Employee Free Choice act", "the release of the four men", "Atonement", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6995684719869502}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.888888888888889, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-2081", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070", "mrqa_searchqa-validation-260"], "SR": 0.59375, "CSR": 0.5518465909090908, "EFR": 1.0, "Overall": 0.7759232954545454}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "over 12 million", "Lucha de Apuesta", "Conservatorio Verdi in Milan", "President of the United States", "the backside", "Angelo Bruno", "\"The Future\"", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "2015 Orange Bowl", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "2017", "Douglas Jackson", "wooden roller", "Blackpool Football Club", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Australian Electoral Division", "Sun Tzu", "American singer Toni Braxton", "Hindi", "Richard Masur", "Irish Chekhov", "311", "\"Dr. Gr\u00e4sler, Badearzt\"", "Alexandre Dimitri Song Billong", "The Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "1972", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Elgar\u2019s", "last summer", "almost 100", "into the Southeast,", "the jeffersons tv show", "Great Balls of Fire", "her own account of her life,", "One Direction"], "metric_results": {"EM": 0.5625, "QA-F1": 0.688311887254902}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1917", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-12050"], "SR": 0.5625, "CSR": 0.5520833333333333, "EFR": 1.0, "Overall": 0.7760416666666666}, {"timecode": 45, "before_eval_results": {"predictions": ["American Revolution", "a proof reader", "Queen Elizabeth II", "the Aquitani", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "miniature golf", "CNN", "Punxsutawney, Pennsylvania", "Pressburg", "yellow fever", "sea otters", "jedoublen/jeopardy", "Starbucks", "rod", "by a grand jury on March 1, 1974", "dressage", "astronomer", "Mickey Mouse", "a bud", "Associate", "Foot", "Medusa", "a spiral", "Prince Attab", "staff", "Voyager 1", "Farsi (Persian)", "insulin", "objects", "China", "Helen of Sparta", "Vegetarianism", "Peace Sign Flag", "An Old Man, a Young Man", "English Monarchs", "Rajasthan", "\"retired\" safecracker Gal for one last job, but it", "The New York Times", "NHL", "a samt ar-rs road", "White bread and butter", "Rules of Order Online", "Wordsworth", "brushes", "a planetary-mass object that is neither a planet nor a natural satellite", "Arabian Nights", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London,", "Isle of Wight", "Peppercorn class", "\"Queen In-hyun's Man\"", "Oneida Limited", "Michael Jordan", "Libreville, Gabon.", "tickets", "the station", "Cahawba"], "metric_results": {"EM": 0.5, "QA-F1": 0.5642992424242423}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.1818181818181818, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-4671", "mrqa_searchqa-validation-3132", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_triviaqa-validation-888"], "SR": 0.5, "CSR": 0.5509510869565217, "EFR": 1.0, "Overall": 0.7754755434782609}, {"timecode": 46, "before_eval_results": {"predictions": ["social power and wealth", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "a torture chamber", "Faggot", "a skein, a team, or a wedge", "California Chrome", "Pluto", "Route 66", "the Taklamakan Desert", "Sindh", "Astronaut", "the Great Victoria Desert", "Germany", "the band Go West", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "snakes", "Sedgefield in North East England", "Coral Sea", "Saddam", "Nadia Comaneci", "tanks", "South Korea", "pigs", "X-Men Origins: Wolverine", "Carmen", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "Alt", "Potomac", "Argentina", "Luke", "Frankfurt", "chipmunk", "Goldie Hawn", "a pulsar", "Belgium", "horse stories", "sugar", "Benfica", "Sun Lust Pictures", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "the museum itself", "Speed Racer", "H. G. Wells", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6786458333333334}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-6115", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-2953", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.609375, "CSR": 0.5521941489361701, "EFR": 0.96, "Overall": 0.756097074468085}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "at Sunset", "Sinclair Lewis", "toms andy griffith", "The World is Not Enough", "a binder", "Scott Glenn", "Vaclav Havel", "Dick Van Dyke", "Sir John Everett Millais", "Tina Turner", "2010", "Portrush", "contact lenses", "perfumer", "Duke Orsino", "magnetite", "Copenhagen", "The Apprentice", "a reference mark", "Cubism", "sahara", "the Advisory Council of Science and Industry", "eukharistos", "Charlotte's Web", "Octopussy", "silks", "William Randolph Hearst", "Lorne Greene", "rowing", "Michael Redgrave", "Call My Bluff", "a", "Argentina", "Frank McCourt", "salt or sugar", "Debbie McGee", "LDV", "starch", "Pears soap", "Donna Summer", "a balustrade", "Nottingham", "Poland", "the Welcome Stranger", "Taggart", "April", "Chechnya", "a police janitor", "maybe you can hire the A- Team", "football", "1,281,900", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough, Massachusetts", "1952 World Champion Jack Young", "beautiful", "Eleven people died and 36 were wounded", "Michelle Obama", "kbenhavn", "the Communist Manifesto", "sahara", "Floxin"], "metric_results": {"EM": 0.484375, "QA-F1": 0.520809659090909}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.16666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-366", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-15651"], "SR": 0.484375, "CSR": 0.55078125, "EFR": 0.9393939393939394, "Overall": 0.7450875946969697}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "Thored, Earl of southern Northumbria", "\"Shaun the sheep\"", "Stephen Mangan", "William McKinley", "1905", "Vanilla Air", "Mineola, New York", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "physical", "1986", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "the Processional Way", "Ford Falcon", "New York State Route 907E", "Roman \u00e0 clef", "1827", "Kim Bauer", "United States Food and Drug Administration (FDA)", "Edward James Olmos", "Bury St Edmunds, Suffolk, England", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard", "45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "August 14, 1848,", "Texas Tech University", "John McClane", "Larry Gatlin & the Gatlin Brothers", "Cayenne", "371.6 days", "North Carolina", "Selinsgrove,", "Augusta Ada King-Noel, Countess of Lovelace (\"n\u00e9e\" Byron; 10 December 1815 \u2013 27 November 1852)", "first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Anjana Om Kashyap", "Space Shuttle Challenger", "basil", "gold Georg Olden\u2013designed statuette", "The Rosie Show", "California-based Current TV", "well over 1,000 pounds", "Brutus", "a one-piece swimsuit", "the Library of Congress", "the stroma"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6537574404761904}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false], "QA-F1": [0.25, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 0.0, 0.5, 1.0, 0.0, 0.0, 0.8571428571428571, 0.19999999999999998, 0.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-4008", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-515", "mrqa_hotpotqa-validation-775", "mrqa_hotpotqa-validation-3513", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-1399", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-5844", "mrqa_newsqa-validation-2595", "mrqa_searchqa-validation-1028", "mrqa_naturalquestions-validation-4685"], "SR": 0.5625, "CSR": 0.5510204081632653, "EFR": 0.9642857142857143, "Overall": 0.7576530612244898}, {"timecode": 49, "before_eval_results": {"predictions": ["baseball, oin\u0103, ( Italy) and pes\u00e4pallo", "Jena Malone", "Washington, D.C.", "the utopian Ascona community", "John W. Henry", "Mike J. Fox and James Woods", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Love Hina", "eastern", "novelty songs, comedy, and strange or unusual recordings dating from the early days of phonograph records to the present", "OutKast", "five", "Alain Robbe-Grillet", "the Seasiders", "musical research", "Dragon TV", "Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem (Evil)", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "Kj\u00f8benhavns Boldklub or KB", "Robert Jenrick", "three Golden Globe Awards", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec fox", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "the closing scene of the final episode of the first season", "Everywhere", "the birth centenary of Pandit Jawaharlal Nehru", "honda", "J. M. W. Turner", "Republic of Upper Volta", "56", "Nkepile Mabuse", "Eintracht Frankfurt", "the fortress", "Hephaestus", "Amherst College", "two"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7035498903508772}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true], "QA-F1": [0.25, 1.0, 0.0, 0.8571428571428571, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.21052631578947367, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102"], "SR": 0.609375, "CSR": 0.5521875, "EFR": 0.88, "Overall": 0.71609375}, {"timecode": 50, "UKR": 0.728515625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.796875, "KG": 0.47890625, "before_eval_results": {"predictions": ["Sushant Singh Rajput", "\u00c6thelwald Moll", "Fife", "26,000", "Spain, Mexico and France", "1981", "Dragons", "February 26, 1948", "National Aviation Hall of Fame class of 2001", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "Epic Records", "IFFHS World's Best Goalkeeper", "shortest player ever", "Maud of Gloucester", "salary and wages", "July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "northern mockingbird", "Picric acid", "Las Vegas", "ESPN's \" SportsCenter\"", "pioneering New Zealand food writer", "fantasy", "feats of exploration", "Dolly Records", "Bergen County", "Marlon St\u00f6ckinger", "Newcastle United's Cheick Tiot\u00e9", "1994", "the superhero Birdman", "Biloxi", "New York Yankees", "1903", "King Kal\u0101kaua", "Mark \"Chopper\" Read", "subgenre", "IATA: VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Mercer University", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "between 27 July and 7 August 2022", "1800", "season seven", "glycerol", "an umbrella", "intestines", "is the most high-profile amalgamation of Indian and western talent yet,", "more than 1.2 million people", "84-year-old", "Genesis 45", "records", "Matt Damon", "Mitch Murray"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6156116452991452}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.25, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.25, 1.0, 0.8, 1.0, 1.0, 0.0, 0.30769230769230765, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4070", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-532", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-517", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_triviaqa-validation-1015", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770"], "SR": 0.484375, "CSR": 0.5508578431372548, "EFR": 0.9696969696969697, "Overall": 0.7049703375668449}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County", "Prince Antoni Radziwi\u0142\u0142", "Hordaland", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia and New Zealand", "Daniel Espinosa", "1942", "water", "Bury St Edmunds, Suffolk, England", "20 July 1981", "What You Will", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "Logan International Airport", "Blackpool Football Club", "Marvel Comics", "100 million", "James Gregory", "Volvo 850", "1978", "July 25 to August 4", "Sela Ann Ward", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II", "Oracle Corporation", "Pittsburgh, Pennsylvania", "John Andr\u00e9", "Three-card brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Alexandrovich Morozov", "their evocative music on indigenous flutes, panpipes and drums, as well as stringed instruments introduced since the Spanish conquest.", "Volksb\u00fchne Berlin", "two", "Outside", "Traumnovelle", "Chechen Republic", "actress and model", "from 1986 to 2013", "Granada", "Guangzhou, China", "British", "Jaguar Land Rover Limited", "Citgo Petroleum Corporation", "artist and graffiti writer", "B.R. Ambedkar, the chairman of the Drafting Committee, is widely considered to be its chief architect", "Presley Smith", "hydrological cycle or the hydrologic cycle", "Mungo Park", "Joe Meek", "Melissa", "in a tenement in the Mumbai suburb of Chembur,", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.\"", "their culture, religion and national identity.", "Popular Science", "a ton", "Latter-day Saints", "they were growing more and more suspicious of the way their business books were being handled."], "metric_results": {"EM": 0.46875, "QA-F1": 0.6388860098235098}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.4, 0.5, 0.4, 0.0, 0.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.15999999999999998, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.5, 0.8, 0.09999999999999999, 0.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.5, 0.4, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-823", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-5677", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-3348", "mrqa_hotpotqa-validation-5766", "mrqa_hotpotqa-validation-4565", "mrqa_naturalquestions-validation-3538", "mrqa_triviaqa-validation-5002", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.46875, "CSR": 0.5492788461538461, "EFR": 0.9411764705882353, "Overall": 0.6989504383484163}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "\"Physical\"", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "novel", "the National Society of Daughters of the American Revolution", "Timmy Sanders", "Japan", "St Augustine's Abbey", "The Washington Post", "Shusett", "Dizzy Dean", "UHF channel 44", "North Kesteven,", "Afro-Caribbean", "The Beatles", "\"Menace II Society\"", "September", "March 30, 2025", "Black Panther", "Pinellas", "Benjamin Burwell Johnston, Jr.", "Imagine", "Easy", "CBS", "\"Brickyard\"", "2012", "Candice Susan Swanepoel", "Benny Andersson", "Peter Yarrow", "Shepardson Microsystems, Inc.", "Blackstone", "the north bank of the North Esk", "Paris", "Hard rock", "Yubin, Yeeun, Hyerim", "Ecko Unlimited", "Muhammad Ali", "University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "Sister", "David Dunn", "William Bradford", "FieldTurf", "his fifth", "Benj Pasek and Justin Paul", "a hand injury", "the \u01c3ke e : \u01c0xarra \u01c1ke", "Johnny Cash", "the pulmonary arteries", "\u201cThe Pope? How many divisions does he have?", "France", "Taekwondo", "The Tinkler.", "the country's ethnic Tamil minority has been fighting for an independent homeland since 1983.", "the legitimacy of that race.", "the Dukes", "Italy", "a bell pepper", "star"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6325024801587302}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.8, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-2358", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-1813", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-2818", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-376", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5343", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_newsqa-validation-372", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.484375, "CSR": 0.5480542452830188, "EFR": 1.0, "Overall": 0.7104702240566038}, {"timecode": 53, "before_eval_results": {"predictions": ["stars", "Friedrich Nietzsche", "give up the ship", "Lord Carnarvon", "Ireland", "Glaciers", "bdellium", "Marie-Antoinette", "Aunt Bee", "Great Smoky Mountains National Park", "meadow grasshopper", "Ohiopyle", "Nostradamus", "Hodgkin's lymphoma", "Cannonball Run", "white", "Henry Wadsworth", "The Crow", "the plain of Attica", "John Keats", "(Scott) Peterson", "one of Central America's best kept", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "Fyodor Dostoyevsky", "Mike Rowe", "Resident Evil", "daughter", "Bastille Day", "the Trucial States", "Dramamine", "My Little Chickadee", "the May Ball", "Dred Scott", "Rose Tascher", "Theodore Roosevelt", "Staten Island", "Transformers", "Crystal Light", "the Yankees", "the declaration of saturated fat", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "an ear", "Indira Gandhi", "a rotating radar dome", "the Director of National Intelligence", "prevents any movement", "2018", "Peter Paul Rubens", "mink mink", "David Bowie", "1 December 1948", "Lester Ben \"Benny\" Binion", "three centuries", "forgery and flying without a valid license,", "Michoacan state,", "\"gotten the balance right\"", "Carpenter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6781250000000001}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-13330", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-15504", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-15589", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821"], "SR": 0.609375, "CSR": 0.5491898148148149, "EFR": 0.96, "Overall": 0.702697337962963}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "318/92", "Gary Havelock", "Anthony Joshua", "Kansas", "purple", "Thabo Mbeki", "John Denver", "George Blake", "Illinois", "panzer", "Adrian Cronauer", "Copenhagen", "the Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "le Carr\u00e9", "a googol", "Niagara Falls", "$SPX", "Mrs Merton", "blues", "Alamo", "Brazil", "bologna", "George Williams", "Michael Faraday", "George", "Montmorency", "haddock", "Happy Ever After", "Tim Peake", "Phil Redmond", "tamale", "Argentina", "St Moritz", "Good Neighbors", "a non-speaking character", "Jerry", "Sinclair Lewis", "mouse", "Australia", "Barry White", "Robin", "Parchman Farm", "Canada", "The Hague Conventions", "Portugal", "silver", "Moby Dick", "`` Fix You ''", "`` Killer Within ''", "prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "\"The Worm\"", "\"The Golden Girls,\"", "\"the most dangerous precedent in this country, violating all of our due process rights.\"", "sex scandal", "Easy Rawlins", "William McKinley", "Scripps National Spelling Bee", "Berlin"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7096920289855073}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.08695652173913043, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-3131", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187"], "SR": 0.671875, "CSR": 0.5514204545454545, "EFR": 0.9047619047619048, "Overall": 0.6920958468614719}, {"timecode": 55, "before_eval_results": {"predictions": ["detainees are not drugged unless there is a medical reason to do so.", "the man was dead,", "CNN's Larry King", "a vigilante group", "customers", "the United States", "in Iraq", "work at the Iranian consulate,", "parachuted to the ground.", "documents", "barbara chance", "the drug trade", "Bright Automotive", "NASCAR", "rapper T.I.", "Muslim", "a Coptic family", "is a new television show which looks at how children as young as eight would cope without their parents for two weeks.", "is", "new voters", "urged NATO to take a more active role in countering the spread of the", "1831", "the Ku Klux Klan", "President Obama", "pine beetles", "lower house of parliament,", "will make the case aggressively", "Iran", "his son", "publicly criticized his father's parenting skills.", "in the Ronald Reagan UCLA Medical Center,", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "Fifteen", "remains unknown,", "60 euros -- $89 --", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "American Hugo Vihlen", "acid", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy in Bangkok,", "Channel 4 said the program was made with the parents' full consent.", "top winds", "rwanda", "twice", "Bob Johnson", "the \"bystander effect\"", "\"Dancing With the Stars.\"", "his club", "Microsoft", "two years", "The American Civil War was fought in the United States from 1861 to 1865", "Sylvester Stallone", "1,228 km / h ( 763 mph )", "Edward Yorke", "Charlie Sheen", "silversmith", "Joseph Ruttenberg", "\"First Family of Competitive Eating\"", "Valley Falls", "the linen queen", "Australia", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5852473054439167}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, false, false, true, false, true, false, false, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [0.6666666666666666, 0.4, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.2857142857142857, 0.2608695652173913, 0.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.9, 0.8235294117647058, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-1877", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-766", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-1541", "mrqa_newsqa-validation-419", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_triviaqa-validation-1475", "mrqa_hotpotqa-validation-5224", "mrqa_searchqa-validation-1388"], "SR": 0.421875, "CSR": 0.5491071428571428, "EFR": 0.8648648648648649, "Overall": 0.6836537765444015}, {"timecode": 56, "before_eval_results": {"predictions": ["the B-52 Stratofortress", "peso", "the nucleus", "prednisone & prednisolone", "Robert Heinlein", "Stalin", "the Ogallala aquifer", "ovulation", "Python", "William Proxmire", "George Orwell.", "indigenous", "lazy Susan", "Coach Carter", "herbivore", "a giant leap", "Psycho", "a believer", "Athens", "Extreme", "zoo", "Olivia Newton-John", "Mickey Gilley", "Oral Roberts", "the staff", "John VIII", "tin", "Ganges", "Captain Nemo", "Dave Brubeck", "a Yellow Ribbon", "Stevie Wonder", "Danville, Virginia", "Jupiter", "arachnids", "Apple", "Winter Depression", "the Mausoleum", "Act One", "a violet-blue gem", "Rhapsody", "the Ziegfeld", "odka", "Ronald", "Mount Kilimanjaro", "militia", "Delaware", "Graceland", "a supersonic interceptor aircraft", "Don Michael Corleone", "the id", "John F. Kennedy", "Ishaan Anirudh Sinha", "in the pouring rain at a rest stop", "Munich", "is", "1123", "Margaret Groening", "Benedict of Nursia", "A Boltzmann machine", "Abbey Road", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5104166666666667}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, false, false, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2168", "mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-1616", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-2176", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-4868", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658", "mrqa_hotpotqa-validation-3559"], "SR": 0.46875, "CSR": 0.5476973684210527, "EFR": 1.0, "Overall": 0.7103988486842105}, {"timecode": 57, "before_eval_results": {"predictions": ["Russia", "bamboo", "Merlin", "sculpture", "Alien", "Think Big", "mariachi", "a bottle", "excruciating", "Kilimanjaro", "an opinion", "Francis Ford", "pardon", "the Pope", "Calais", "Twenty", "New York", "a tortoise", "Thomas Paine", "Isaac Newton", "American Wedding", "Anthony Michael Hall", "Tears for Fears", "Jamestown", "the Rhine", "blacksmith", "mohs scale", "Katharine McPhee", "October 7, 1913", "Purple Rain", "Cnut the Great", "spiral", "Dan Eggen", "the yolk", "(Vijay) Singh", "geometric", "Baton Rouge", "Daniel Boone", "Chariots of Fire", "notophthalmus", "Sweden", "pink", "eyelid", "Hong Kong", "The Addams Family", "viruses", "Sanders", "Bait-and-switch", "Churchill", "resolution", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "Timothy Dalton", "University of Oxford", "1,467", "Vision of Love", "allegations that a dorm parent mistreated students", "Paul Schlesselman", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15237", "mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-1930", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-5688", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803"], "SR": 0.640625, "CSR": 0.5492995689655172, "EFR": 1.0, "Overall": 0.7107192887931035}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "super-yacht", "engaging with the Taliban in Pakistan and Afghanistan.", "tells stories of different women coping with breast cancer in five vignettes.", "emergency aid", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty.", "school", "Asashoryu", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "China", "\"I never thought any of this was going to be easy,\"", "Akio Toyoda", "longest domestic relay in Olympic history,", "man's lifeless, naked body", "South Korea's National Intelligence Service, and Defense Minister Kim Kwan Jim", "military trial system", "183", "Nirvana", "Emmy-winning Patrick McGoohan,", "55-year-old", "Zimbabwe President Robert Mugabe", "new Touch,", "The woman who received the first-ever near-total face transplant in the United States", "International Polo Club Palm Beach in Florida.", "President Bush", "All three pleaded not guilty in an appearance last week in Broward County Circuit Court.", "a full garden and pool, a tennis court, or several heli-pads", "Turkey can play an important role in Afghanistan as a reliable NATO ally. The question is: How can Turkey best help?", "Polo because \"it was the sport of kings. It was glamorous, sexy and international.\"", "a three-story residential building in downtown Nairobi.", "cancer", "Hussein's Revolutionary Command Council.", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "people", "Rev. Alberto Cutie", "the group Daryeel Bulasho Guud", "magazine, GospelToday,", "FBI Special Agent Daniel Cain,", "Alan Graham", "February 12", "Baja California Language College in Ensenada, Mexico", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "women in Somalia's third-largest city, Baidoa, have been ordered to wear Islamic dress starting this week or face jail time.", "trading goods and services without exchanging money", "three people", "In addition to Mexico and the United States, the following countries have so far confirmed non-lethal cases", "Some of them told CNN they couldn't afford to pay for cable or satellite TV service.", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing.", "Ben Roethlisberger", "Taylor Michel Momsen", "Nick Grimshaw", "In November 2016", "m69. Coventry to Leicester Motorway", "Zaire", "pasta", "DreamWorks Animation", "Debbie Harry", "2004", "a cord", "Jude Law", "Existentialism", "William Windom"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5833239953484519}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.17391304347826086, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.4, 1.0, 0.18181818181818182, 1.0, 1.0, 0.4444444444444445, 0.8, 0.13333333333333333, 0.7000000000000001, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.30769230769230765, 0.2222222222222222, 0.07407407407407408, 1.0, 0.6666666666666666, 0.0, 0.0, 0.41666666666666663, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-535", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.453125, "CSR": 0.5476694915254237, "EFR": 1.0, "Overall": 0.7103932733050848}, {"timecode": 59, "before_eval_results": {"predictions": ["Archer", "Pakistan", "DTM", "Vernon Kay", "Florida", "ten episodes", "Tyler Posey", "Maxwell Atoms", "Scandinavian design", "Hugh Hefner", "Benj Pasek and Justin Paul", "Toxics Release Inventory", "Oregon", "Mrs. Eastwood & Company", "Blackpool Football Club", "southwest Denver, Colorado near Bear Creek", "Edward M. Kennedy", "Boeing EA-18G Growler", "21st Century Fox", "Pennsylvania's", "Danielle Fernandes", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "NATO", "Mansoor Ali Khan", "authoritarian tendencies", "AOL", "World War II", "non-alcoholic", "Thomas Perez", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "Golden Globe", "New Jersey", "Ian Rush", "Erich Maria Remarque", "Australian", "youngest TV director ever", "Arthur William Bell III", "Henry John Kaiser", "Delaware River", "Jean Acker", "Anheuser-Busch", "MG Car Company Limited", "Boston Celtics", "May 2008", "Hungarian Rhapsody No. 2", "24 hours later", "Brian Steele", "from 35 to 40 hours per week", "Ceefax", "Dieppe Raid", "hanover", "the Walk of Fame.", "228", "The son of Gabon's former president", "stocks.", "Thomas Alva Edison", "Harrison Ford", "Jeannie Longo-Ciprelli"], "metric_results": {"EM": 0.5, "QA-F1": 0.6356036324786325}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, false, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.8, 1.0, 0.923076923076923, 1.0, 0.6666666666666666, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-1512", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-5535", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-5066", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-2977", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-8673", "mrqa_triviaqa-validation-5185", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-10636", "mrqa_searchqa-validation-3660", "mrqa_newsqa-validation-153"], "SR": 0.5, "CSR": 0.546875, "EFR": 1.0, "Overall": 0.710234375}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "Russia's Tupolev TU-160, pictured here in 2003, is a long-range strategic bomber.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "Joan Rivers", "Russia invaded Georgia last August.", "Alison Sweeney,", "Carrousel du Louvre,", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "Pete Docter", "at least 25 dead", "269,000", "flooding was so fast that the thing flipped over,", "which type of guy you should avoid", "Patrick McGoohan,", "ambassadors", "NATO", "The Arkansas weatherman", "hanged in 1979", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "Inven people died and 36 were wounded in the Monday terror attack,", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell,", "economic and political engagement", "Best Picture winner \"Slumdog Millionaire\" (No. 4)", "Noida, located in the outskirts of the capital New Delhi.", "body bags on the roadway near the bus,", "south of Kabul in the eastern Afghan province of Logar,", "10 to 15 percent", "No reason was given for the denial.", "Annie Duke", "an engineering and construction company", "in the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "At least 15", "illegal immigrants", "one-of-a-kind navy dress with red lining", "a monthly allowance,", "Too many glass shards left by beer drinkers in the city center,", "legitimacy of that race.", "Nigeria", "Andrew Morris,", "the shipping industry -- responsible for 5% of global greenhouse gas emissions,", "Drottningtorget", "the driver", "the family's blog", "his cousin D\u00e1in", "Jesse McCartney", "the American Civil War", "T.S. Eliot", "White", "Australia and Ireland", "18 December 1975", "1970", "Copenhagen", "The Pacemakers", "Khartoum", "Stand by Me", "French"], "metric_results": {"EM": 0.5, "QA-F1": 0.6058357349886955}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.15, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.04761904761904762, 0.5, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.8333333333333333, 0.0, 0.923076923076923, 0.26666666666666666, 1.0, 0.5, 1.0, 1.0, 0.3, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-2599", "mrqa_hotpotqa-validation-4172", "mrqa_searchqa-validation-6409", "mrqa_hotpotqa-validation-2403"], "SR": 0.5, "CSR": 0.5461065573770492, "EFR": 0.96875, "Overall": 0.7038306864754099}, {"timecode": 61, "before_eval_results": {"predictions": ["allergic reaction to peanuts,", "retired Navy F-14", "Santaquin City, Utah,", "It has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "McMahon,", "Bob Bogle,", "183", "from the Arctic north of Murmansk down to the southern climes of Sochi by way of St Petersburg and Moscow,", "in a 4-1 Serie A win at Bologna on Sunday", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "Tuesday afternoon.", "Henry Ford", "Four Americans -- two soldiers and two civilians from the Defense and State departments --", "Mark Fields", "Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "the soldiers", "the body of the aircraft", "American third seed Venus Williams in the final of the Sony Ericsson Open in Miami on Saturday.", "onto the college campus.", "The cervical cancer vaccine, approved in 2006, is recommended for girls around 11 or 12.", "Bright Automotive,", "Kingdom City", "Europe,", "$7.8 million", "Polo because \"it was the sport of kings.", "The elections are slated for Saturday.", "United's", "surgical anesthetic propofol", "\"The woman involved -- Mandi Hamlin -- told reporters earlier Friday she was humiliated by last month's incident, in which she was forced to visibly remove the piercings", "CNN", "school, their books burned,", "Hurricane Gustav", "The cervical cancer vaccine, approved in 2006, is recommended for girls around 11 or 12.", "two courses on the Black Sea coast in Bulgaria.", "outfit from designer", "the two bodies out of the plant,", "second-degree aggravated battery.", "the man facing up, with his arms out to the side. He is wearing socks but no shoes.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines will be part of the initial wave of President Obama's surge plan to head to Afghanistan's restive provinces to support Marines and soldiers fighting a dug-in Taliban force.", "Thailand", "Arsene Wenger", "The local Republican Party", "the Gulf", "former Procol Harum bandmate Gary Brooker", "27,", "The Tupolev Tu-160 strategic bombers landed at Venezuela's Libertador military airfield and \"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "housing, business and infrastructure repairs,", "travel with privately armed guards.", "toys or doorbell installations", "British citizens", "Justin Timberlake", "kefalonia", "Brighton", "eagle", "Umberto II", "\"The Longest Yard\"", "Lucille D\u00e9sir\u00e9e Ball", "Louis XIV", "the Bronx", "Flamboyant", "South Africa"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6590472318735187}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, false, true, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true], "QA-F1": [0.22222222222222224, 1.0, 0.8571428571428571, 0.15384615384615385, 0.0, 1.0, 1.0, 0.7142857142857143, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.23529411764705882, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.2222222222222222, 1.0, 0.4, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.72, 1.0, 0.125, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-1370", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3082", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-492", "mrqa_newsqa-validation-531", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_triviaqa-validation-517", "mrqa_hotpotqa-validation-2827"], "SR": 0.546875, "CSR": 0.5461189516129032, "EFR": 0.9655172413793104, "Overall": 0.7031866135984427}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0", "portrait of William Shakespeare", "Al Gore", "200", "T.I.", "the media", "Friday,", "carving in the middle of our Mountain View, California, campus.", "Arizona", "is the U.N. nuclear watchdog agency's strongest warning yet that Iran could be aiming to build a nuclear bomb.", "\"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "56,", "April 28,", "coach", "Fernando Caceres", "BADBUL", "Nirvana", "its nude beaches.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "East Java", "\" Body Works\"", "the Nuclear Non-Proliferation Treaty in 2003.", "supermodel", "10 below", "1,073", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "fled Zimbabwe", "girls around 11 or 12.", "passengers on the Miva Marmara", "food, music, culture and language of Latin America", "cancerous tumor.", "Tennessee", "Bright Automotive,", "nuclear-armed Iran", "changed the business of music,", "exploration traded in for the comforts of home and domestic Bliss.", "165-room", "\"Oprah is an angel, she is God-sent,\"", "al Qaeda,", "people", "Susan Atkins,", "Charlotte Gainsbourg and Willem Dafoe", "daughter, Zeina,", "Omar", "China", "United States", "Russia Tower in Moscow and the Okhta Center Tower in St Petersburg", "speaking out about a cause someone feels passionate about.", "25 years", "Anil Kapoor", "President Obama and Britain's Prince Charles", "Wembley Stadium", "regulatory site", "9.0 -- 9.1 ( M )", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Robert Arthur Mould", "331", "2006", "Ruth Bader Ginsburg", "Chandler", "Seth", "peacock"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5461420067038673}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true], "QA-F1": [0.6666666666666666, 0.4, 0.0, 1.0, 0.25, 0.0, 1.0, 0.1818181818181818, 0.0, 0.25, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.08695652173913043, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.11764705882352942, 0.0, 0.6666666666666666, 1.0, 0.26666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-1956", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-4598", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746"], "SR": 0.46875, "CSR": 0.544890873015873, "EFR": 1.0, "Overall": 0.7098375496031746}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the New York Philharmonic Orchestra in North Korea", "The families of the six slain young people asked that he returned to the cabin.", "a class to help women \" learn how to dance and feel sexy,\"", "the German Foreign Ministry,", "$89", "African National Congress Deputy President Kgalema Motlanthe,", "militants from Pakistan", "Japanese officials", "The United Nations is calling on NATO to do more to stop the Afghan opium trade", "poor.", "striker", "Sixteen", "poems", "Iowa,", "Mexico where drug cartel members blocked roads with hijacked vehicles", "executive vice president.", "Golden Gate Yacht Club of San Francisco", "nearly 100", "a national telephone survey of more than 78,000 parents", "ballots", "And if Planet Solar completes its mission, the crew says that will be proof that the sun, and renewable energy at home everyday,\"", "the Obama and McCain camps", "The prince, second in line to the throne, landed a Chinook helicopter -- normally used for transporting troops -- in a field next to the home of Kate Middleton,", "part of the proceeds", "The minister later apologized, telling CNN his comments had been taken out of context.", "Fernando Torres", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars\"", "civilians,", "March 3, 2008,", "Ava Zinna ate an allergen-free meal at the Worry Free Dinners event on Sunday.", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Buddhism, a practice that originated in China, and meet weekly to focus their minds.", "The Casalesi Camorra clan", "May 4", "tranquil beaches,", "$1.5 million", "Booches Billiard Hall,", "'overcharged.'\"", "since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama Action", "Kimberlin Brown", "a turlough, or turlach", "1933-1934", "Kirk Douglas", "Rockefeller Center", "Vikram, Jyothika and Reemma Sen", "the Dutch Empire", "Captain", "Department of Education", "de Gaulle", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6608568428099678}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, false, true, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.0, 0.7777777777777778, 1.0, 0.0, 0.42857142857142855, 0.5, 1.0, 0.07692307692307691, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5454545454545454, 1.0, 0.4444444444444445, 1.0, 0.08, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 0.25, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-1286", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-4210", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3692", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-2986", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-8244", "mrqa_naturalquestions-validation-10396"], "SR": 0.546875, "CSR": 0.544921875, "EFR": 1.0, "Overall": 0.70984375}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser,", "sportswear,", "teenage", "July 23.", "Landry", "Korean-American missionary", "Chester Stiles,", "United States", "Pakistan's High Commission in India", "Wednesday.", "Wigan Athletic", "Adriano", "poems", "David Russ,", "A 22-year-old college student in Boston, Massachusetts,", "to sniff out cell phones.", "Longo-Ciprelli", "Switzerland", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944,", "\"I never thought any of this was going to be easy,\"", "\"The precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "more than 30", "his entire five-year term.", "refused to refer the case of Mohammed al-Qahtani to prosecutors", "a free laundry service.", "rural California,", "Robert Park", "11th year in a row.", "83 eggs.", "future relations between the Middle East and Washington.", "school.", "a plaque at the home of his great-grandfather", "death squad killings", "a nuclear weapon", "Tina Constable,", "\"The missile defense system is not aimed at Russia,\"", "Oregon State Senior troopers David Petersen after he was able to catch up with six exotic sports cars on a stretch of Highway 18 near Grand Ronde, Oregon.", "Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "The obscure state legislator with, as he put it, \"a funny name\" propelled himself onto the national stage at the Democratic National Convention four years ago", "$3 billion,", "Crap E-mail From A douce", "Larry King", "he acted in self defense in punching businessman Marcus McGhee.", "potential revenues from oil and gas", "Sen. Barack Obama", "jobs up and down the auto supply chain", "cannonball", "Eastern Hemisphere and Western Hemisphere", "the title character's housebound mother", "Colette", "crow", "Rhys Williams", "2015", "KULR-TV", "January 15, 2016", "piano", "Palestine", "Barnard College", "Chiltern Hills"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5808694745227254}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.8181818181818181, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.4, 0.19999999999999998, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.10526315789473685, 0.2857142857142857, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-827", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3859", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4014", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516", "mrqa_searchqa-validation-4278"], "SR": 0.484375, "CSR": 0.5439903846153846, "EFR": 0.8484848484848485, "Overall": 0.6793544216200467}, {"timecode": 65, "before_eval_results": {"predictions": ["taking a medicine that contained the banned substance cortisone.", "Larry Zeiger", "The Ski Train", "housing, business and infrastructure repairs,", "Joe Harn", "Haiti", "Uzbekistan.", "Israel", "Nigeria, Africa's largest producer.", "Mexico", "two Metro transit trains that crashed the day before, killing nine,", "identity documents", "Denver, Colorado.", "Jeffrey Jamaleldine took a bullet to his chin that blew out much of his jaw and nearly killed him while deployed in Iraq last year.", "the single-engine Cessna 206", "strong work ethic", "meter reader who led authorities last week to remains believed to be those of Caylee Anthony", "could be secretly working on a nuclear weapon", "delivered three machine guns and two silencers to the hip-hop star,", "Carol Fowler", "GOP Sens. Daniel Verdin, Shane Martin, Ronnie Cromer and Wes Hayes", "people are going to look at the content", "April 22.", "Manuel Mejia Munera", "outfit from designer", "five", "Ozzy Osbourne", "Sarah,", "Carol Browner", "pro-democracy activists clashed Friday with Egyptian security forces in central Cairo,", "eight.", "Fullerton, California,", "Hawaii", "American Bill Haas", "A Lion Among Men.", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Kr\u00f8yer", "Gyanendra,", "Arlington National Cemetery's Section 60.", "Adam Yahiye Gadahn,", "Turkey", "Polo because \"it was the sport of kings.", "Virginia, West Virginia, the Carolinas, Tennessee, Kentucky and Arkansas.", "\u00a320 million ($41.1 million) fortune", "unwanted horses", "a million", "New York high school.", "19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "it -- you know -- black is beautiful,\"", "Arnold Schoenberg", "N\u0289m\u0289n\u0289", "The virion must assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "Einstein", "Nova Scotia", "pyrotechnic", "Battelle Energy Alliance", "Lake County, Illinois", "Eran Kolirin", "cryptids", "Tigers", "Herod", "leopard"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5550277194211017}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false], "QA-F1": [0.25, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.2222222222222222, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.72, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4053", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.46875, "CSR": 0.5428503787878788, "EFR": 0.9705882352941176, "Overall": 0.7035470978163993}, {"timecode": 66, "before_eval_results": {"predictions": ["Spaniard", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "Iran's nuclear program.", "\"green-card warriors\"", "space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Booches Billiard Hall,", "Both men were hospitalized and expected to survive,", "Harris won two awards.", "Pfc. Bowe Bergdahl", "many different", "President Bush", "$17,000", "Employee Free Choice act", "assassination of President Mohamed Anwar al-Sadat at the hands of four military officers during an annual parade celebrating the anniversary of Egypt's 1973 war with Israel.", "Thomas was trying to mentor the inmates and did not assault them.", "snowstorm to hit Britain", "Arnold Drummond", "Madonna", "the content of the speech, not just the delivery.", "the commissions as a legitimate forum for prosecution, while bringing them in line with the rule of law.", "a traditional form of lounge music that flourished in 1940's Japan.", "Larry King", "250,000", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "managing his time.", "1980.", "Omar bin Laden has a message for his father, Osama: \" Find another way.\"", "Scotland", "Thabo Mbeki,", "Tutsis the privileged ethnicity, thus giving them better opportunities.", "his business dealings for possible securities violations", "January", "\"bleaching\" in which algae living in the coral die and leave behind whitened skeletons.", "Millvina Dean,", "dental work done, including removal of his diamond-studded braces.", "future relations between the Middle East and Washington.", "fake his own death by crashing his private plane into a Florida swamp.", "a female soldier, missing", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "\"Dancing With the Stars.\"", "38,", "that the deadly attack on India's financial capital last month was planned inside Pakistan,", "Henrik Stenson", "1995", "a red minivan ran a red light and struck two vehicles at an intersection,", "\"within a few months,\"", "Anjuna beach in Goa", "\"You can go from rags to riches there. People still believe in that.", "not doing more since taking office.", "Television demonstrations", "American Indian allies", "Naturalization Act of 1790", "chivalric champion of Christian Spain, El Cid", "blancmange", "apples", "Los Alamos National Laboratory", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "Joplin", "Italy", "I.M. Pei", "the Angel of the Lord"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5367464233500419}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 0.16, 0.16666666666666669, 0.4, 0.0, 1.0, 0.8571428571428571, 0.10526315789473685, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6, 1.0, 0.0, 0.0, 0.7142857142857143, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.7000000000000001, 0.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3390", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-571", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-2700", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_naturalquestions-validation-230"], "SR": 0.40625, "CSR": 0.5408115671641791, "EFR": 0.9736842105263158, "Overall": 0.703758530538099}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "road-building", "menorah", "Jaipur", "tea", "geopark", "Martin Pipe", "Wordsworth", "Ginger Rogers", "theatre", "borax", "siam", "peregrines", "diminished", "muscle tissue", "sprint from the gun to the finish line", "Derby Stakes", "Easter Parade", "Greek Home Management", "HMS Amethyst", "lion", "sergeant", "whistling tune, the Colonel Bogey March,", "Cyprus", "King George VI", "ankle joint", "Greyfriars Bobby", "honeycomb", "flea", "a white robe", "Big Bopper", "NBA", "L. P. Hartley", "Leander", "Arsenal", "entropy", "Wadsworth", "green", "elia Earhart", "James Hogg", "tears", "Loki Laufeyi Larson", "Virgin Spring", "Manfred von Richthofen", "Cain", "1879", "Los Angeles", "Loch Lomond", "isosceles", "black", "ballet", "Boston Red Sox", "1967 onwards", "absolute zero", "Bolshoi", "My Boss, My Hero", "mermaid", "death squad killings", "Atlantic Ocean.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "the bumblebee", "36 months"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6481026785714286}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_hotpotqa-validation-941", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782"], "SR": 0.578125, "CSR": 0.5413602941176471, "EFR": 1.0, "Overall": 0.7091314338235295}, {"timecode": 68, "before_eval_results": {"predictions": ["Bed and breakfast", "smen", "Cairo, Illinois", "the Americans", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "2018", "The Redwood National and State Parks ( RNSP ) are a complex of several state and national parks located in the United States, along the coast of northern California", "Zuzu & Zaza Zebra", "257,083", "the island of Puerto Rico", "Norman", "Gustav Bauer", "Shawn", "if the concentration of a compound exceeds its solubility", "the United States", "1623", "the `` round '', the rear leg of the cow", "1957", "360", "electron shells", "into the gastrointestinal tract", "Lori McKenna", "Wisconsin", "Tbilisi", "Latin centum", "1799", "The Epistle of Paul to the Philippians", "his last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "Elvis Presley", "2014", "Best Art Direction, Best Makeup, and Best Visual Effects", "long - standing policy of neutrality was tested on many occasions during the 1930s", "291 episodes", "Cairo, Illinois", "Lana Del Rey", "spacewar", "12", "in the run up to the 2010 general election", "the Pacific Plate", "Boston Celtics center Bill Russell", "Seattle, Washington", "the internal auditory canal of the temporal bone", "2010", "Buddhist missionaries first reached Han China via the maritime or overland routes of the Silk Road", "first composed in the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units within the National Health Service in England", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "1956", "april", "fearful man, all in coarse gray with a great iron on his leg", "huff & puff", "Brad Silberling", "1941", "Nick on Sunset theater", "July in the Philippines", "iCloud service", "Thursday", "bonobos", "Toward", "Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.5, "QA-F1": 0.6419376209609844}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.5, 0.5882352941176471, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.25, 0.5714285714285715, 0.3076923076923077, 0.25, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-10389", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_searchqa-validation-3351", "mrqa_searchqa-validation-12035"], "SR": 0.5, "CSR": 0.5407608695652174, "EFR": 0.9375, "Overall": 0.6965115489130435}, {"timecode": 69, "before_eval_results": {"predictions": ["whitechapel", "Uganda", "definitely maybe", "Brazil", "Artemis", "eight pawns", "Bristol", "Sunshine", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "Cambridge", "a color vision deficiency", "chambodia", "prussian Landsturm", "Russia", "1925 novel", "cooperative", "180", "blue", "Marvin Hart", "convictess oscar", "Andre Agassi", "a hawk", "The Times", "le Carr\u00e9", "Papua New Guinea", "Albania", "animals", "mata hari", "the different levels of importance of human psychological and physical needs", "polo", "gulliver", "ratings", "Saturday Night Live", "Bayern", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "silage Antonius", "a lathe", "one Canada Square in Canary Wharf,", "Snoopy", "corvidae", "convict", "general strike to support mine workers", "my Town Tokyo", "convict", "Walter Mondale", "the reactor core", "the plane crash", "Scotty Grainger Jr.", "The Kingkiller Chronicle series", "3.9 mi", "$1.5 million", "Buddhism", "grabbed the gun and  took her own life.", "a Space Shuttle orbiter", "Smithfield", "Ivan Denisovich", "10 Years"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5223958333333334}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6, 0.8, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1156", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-3373", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-9025", "mrqa_searchqa-validation-16464"], "SR": 0.46875, "CSR": 0.5397321428571429, "EFR": 0.9411764705882353, "Overall": 0.6970410976890757}, {"timecode": 70, "before_eval_results": {"predictions": ["leigh Ann Fetter", "three", "high jump", "ejaz Khan", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "grapevines", "teaching evolution", "Philip Larkin", "shropshire", "Kent", "fox", "jack brabham", "posh", "hanover", "a square root", "gab", "sampras", "prussian 2nd Army", "the Red sea", "cats", "The French Connection", "Eric Blair", "moaning Myrtle", "lago di Como", "Dubai", "ceeLo Green", "photographer", "Justin Bieber", "eptanissa", "m\u00e1qu\u00e8", "scar", "\"Stars on 45 Medley\"", "trimdon", "bowie knife", "Istanbul", "meryl Streep", "Achille Lauro", "Botham", "stop motion effects", "Claremorris", "can make it anywhere", "fijian", "tripezoid", "Dick Advocaat", "John Huston", "van Gogh", "jodie Foster", "can come and go without much of a hullabaloo", "Moscow", "2005", "the governor of West Virginia", "Payaya Indians", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman is in critical condition", "2010", "Asian", "Jerry Rice", "leotard", "Ford", "hip"], "metric_results": {"EM": 0.515625, "QA-F1": 0.56875}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-841", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-4502", "mrqa_triviaqa-validation-3914", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-3881", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-5662", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_naturalquestions-validation-368", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-2817"], "SR": 0.515625, "CSR": 0.5393926056338028, "EFR": 1.0, "Overall": 0.7087378961267606}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "Moon Shot", "Kim Sung-su", "Burma", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "The Man from Jupiter", "Aerol\u00edneas Argentinas", "October 15, 2013", "Neha Sharma", "Japan", "Quentin Coldwater", "1853", "Kew", "Apprendi v. New Jersey", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "Julianne Moore", "11", "tempo", "approximately 20 mi west of central London,", "1942", "Pollywood", "Carver Dana Andrews", "July 25 to August 4", "2015", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "special economic zone", "Darkroom", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "detention camp", "France", "Wordsworth", "Spain", "give detainees greater latitude in selecting legal representation", "\"wipe out\" the United States if provoked.", "two years,", "Yahtzee", "Hinduism", "60 Minutes", "freeview"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7695684523809524}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.734375, "CSR": 0.5421006944444444, "EFR": 1.0, "Overall": 0.709279513888889}, {"timecode": 72, "before_eval_results": {"predictions": ["the conclusion of a syllogism", "showed such a disregard for the life and safety of others as to amount to a crime and deserve punishment", "100,000", "2004", "the NFL", "9th century", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Tony Orlando and Dawn", "2014 Winter Olympics in Sochi, Russia", "the Pir Panjal Range", "nearby objects show a larger parallax than farther objects when observed from different positions", "Kansas", "1885", "the final episode of the series", "Wisconsin", "the motion of the continents", "the vascular cambium", "the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "the Rock", "2007", "Massachusetts", "Mark Jackson", "the Detterick twins", "the Earth", "need to repent in time", "The reduced chemical compounds are oxidized by a series of respiratory integral membrane proteins with sequentially increasing reduction potentials with the final electron acceptor being oxygen", "Kida", "Selena Gomez", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "Elvis Presley", "The federal government", "2013", "England", "the Little Fuzhou neighborhood within Manhattan's Chinatown", "when the cell is undergoing the metaphase of cell division", "79", "the League of Communists of Yugoslavia party", "Interphase", "1902", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "seven", "Ben Savage", "Virginia", "Tom Hanks", "Jethalal Gada", "system of state ownership of the means of production", "Gunpei Yokoi", "the Alamodome and city of San Antonio", "Amy Johnson", "architecture", "Bermuda", "win world titles in four weight classes", "their unusual behavior, such as the number of men killed and the manner of the attacks.", "Neymar", "22", "opium", "Roger Federer", "Parody", "a prostitute", "Ashlee Simpson", "b Bosnia and Herzegovina"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6298663871871593}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, true, true, false, true, false], "QA-F1": [0.35294117647058826, 0.8095238095238095, 0.07999999999999999, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.2857142857142857, 0.6, 0.14285714285714288, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.47619047619047616, 0.2222222222222222, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-10026", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-1909", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-3407", "mrqa_triviaqa-validation-4962"], "SR": 0.53125, "CSR": 0.5419520547945205, "EFR": 0.9666666666666667, "Overall": 0.7025831192922374}, {"timecode": 73, "before_eval_results": {"predictions": ["along the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Kirstjen Nielsen", "May 2017", "Barbara Windsor", "ninth w\u0101", "British Ultra code - breaking intelligence", "Bart Millard", "Jesse Wesley Williams", "Spencer Treat Clark", "1910", "FIGG Bridge Engineers, a Tallahassee - based firm", "John Smith", "Joanne Wheatley", "Everywhere", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "India", "Taylor Michel Momsen", "Magnavox Odyssey", "Lightning thief", "2015", "1971", "Sara Gilbert", "1962", "the fifth studio album by English rock band the Beatles", "John Smith", "Katharine Hepburn", "Arnold Schoenberg", "the national and state legislatures", "203", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a Vampire", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Charlton Heston", "1878", "to `` help bring creative projects to life ''", "President Lyndon Johnson", "Senator Joseph McCarthy", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Saturn", "clog", "Reggie", "Tampa", "1980", "January 28, 2016", "Jaipur", "fifth successive", "in July", "taro", "Match Game", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6907894736842105}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 0.21052631578947367, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2866", "mrqa_triviaqa-validation-249", "mrqa_hotpotqa-validation-2215", "mrqa_newsqa-validation-2749", "mrqa_searchqa-validation-2100"], "SR": 0.65625, "CSR": 0.5434966216216216, "EFR": 0.9545454545454546, "Overall": 0.7004677902334152}, {"timecode": 74, "before_eval_results": {"predictions": ["the Oakland Raiders", "Russell Stover", "center", "submarine", "Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "the classes", "greece", "a blitz", "New Wave", "a commune", "a ring", "Thames", "Marilyn Monroe", "power play", "Hans Christian", "Louis Philippe", "The Color Purple", "whales", "Jane Addams", "Queen Elizabeth", "Tanzania", "Biosphere 2", "an inch", "death", "Longfellow", "Jeb Bush", "Geneva", "humility", "bdellium", "The Mamas", "Diatomaceous earth", "the debt ceiling", "Harry Plopper", "Lake Titicaca", "Existentialism", "ashes", "kevin", "George Freeth", "Einstein", "Charles I", "Kevin Costner", "Antichrist", "treble clef", "uranium", "Louisiana", "The Hot Chick", "composting", "August 21", "January 15, 2010", "four", "Spey", "pappy", "Denmark", "Trappist beer", "4,530", "Steve Prohm", "seven", "Airbus A330-200", "Symbionese Liberation Army", "Manitowoc County"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6411458333333333}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-14913", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-10631", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-12518", "mrqa_searchqa-validation-15658", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-7832", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-8909", "mrqa_triviaqa-validation-7472", "mrqa_hotpotqa-validation-1307", "mrqa_hotpotqa-validation-3458"], "SR": 0.59375, "CSR": 0.5441666666666667, "EFR": 1.0, "Overall": 0.7096927083333333}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "James Bolam", "the main highway entrance at California State Route 1", "a vehicle that is both four - wheel - drive and primarily a road car", "Turing", "John B. Watson", "hydrogen", "Britain", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "First Epistle of John at 5 : 7 -- 8", "Asuka", "Jason Momoa", "Amanda Bynes", "the President", "Spanish missionaries", "Gustav Bauer", "art of the book and architecture", "a vertebrate's immune system", "around 2.45 billion years ago ( 2,45 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "Tevye", "March 31, 2017", "incudomalleolar joint", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "Gupta Empire", "stable, non-radioactive rubidium - 85", "55 -- 69 %", "summer of 1979", "Charles Evans Hughes", "Spanish / Basque", "U.S. service members who have died without their remains being identified", "December 1349", "Glenn Close", "Robert Remak", "the Yankees", "Arthur Miller, a play about a man whose choice to send out faulty airplane parts for the good of his business and family caused the death of twenty one pilots during World War II", "International System of Units", "Rigg", "electrons from electron donors to electron acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions", "Bill Patriots", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "ourselves alone", "lakeland", "1967", "Yubin", "100 metres", "sedative", "boat's hull", "'peregruzka,' which means 'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's", "Patrick Henry", "Samuel Joel \" Zero\" Mostel"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7324786324786325}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.888888888888889, 1.0, 0.2222222222222222, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-8004", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-7514", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-5135", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_searchqa-validation-3069", "mrqa_hotpotqa-validation-3909"], "SR": 0.578125, "CSR": 0.5446134868421053, "EFR": 0.9629629629629629, "Overall": 0.7023746649610136}, {"timecode": 76, "before_eval_results": {"predictions": ["tintoretto", "drambuie", "repechage", "inverness-shire", "Victoria Rowell", "Costa Brava", "Northumberland", "chicken", "Toby", "Michelandie", "Bleak House", "four", "the Indus valley", "Instagram", "Jaws", "Charlie Cairoli", "The Hague", "Adidas", "Coldplay", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "conclave", "Patrick Kielty", "8 minutes", "Tribbiani", "a Red Crescent ambulance", "ernick Nezet-Seguin", "Margaret Thatcher", "Hooky Street", "sam Nixon", "Andrew Lloyd Webber", "Bonn", "lieutenant general", "snakes", "Coral Sea", "The Red King", "Madonna", "bogey", "Millerlite beer", "knee", "Ice Age", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Emilia", "Hawley Harvey", "fifty-six", "1822", "1979", "1976", "Gupta Empire", "Rogue One", "2004", "Rwandan genocide", "Steve Williams", "winter storm with heavy snow and ice was heading from Texas and Oklahoma to points east, with 8 to 10 inches of snow possible in some locales,", "fight outside of an Atlanta strip club", "seasonal affective disorder", "a timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.625, "QA-F1": 0.6870223885310092}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.13793103448275862, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-1430", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-1839", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.625, "CSR": 0.5456574675324675, "EFR": 0.9583333333333334, "Overall": 0.7016575351731602}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1801", "Captain Cook's Landing Place", "M2M", "Helen Mirren", "FX", "president of Guggenheim Partners", "Diamond Rio", "johnnie ray", "master builder", "UFC 50", "James Stenbeck", "Rounders", "24 hours a day and 7 days a week", "o", "Nobel Prize in Physics", "glee", "Chris Pratt", "Ontogenetic depth", "2 November 1902", "January", "orisha", "2006", "highest commissioned SS rank", "Dziga Vertov", "The Bonnie Banks o' Loch Lomond", "National Football League", "brothers", "James Franco", "London", "Kelly Bundy", "British-American", "Ny-\u00c5lesund in Norway", "discoverer of the elliptical galaxy NGC 3610", "around 8000 BC", "2011", "Peter Seamus O'Toole", "Australian women's national soccer team", "Leonarda Cianciulli", "beer", "biola University", "playwright", "medical therapeutic method", "the Surtees Racing Organisation team that competed as a constructor in Formula One, Formula 2 and Formula 5000 from 1970 to 1978", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County", "bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Edd Kimber", "Mel Gibson", "1987", "San Francisco", "john john john peter purves", "Vancouver", "college campus.", "nearly $106.5 million", "15-year-old", "Cleopatra", "Arm & Hammer", "JANE KOKAN", "drumroll"], "metric_results": {"EM": 0.53125, "QA-F1": 0.626748511904762}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, true, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2100", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-2730", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-6460", "mrqa_newsqa-validation-2168", "mrqa_newsqa-validation-900", "mrqa_newsqa-validation-2982", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.53125, "CSR": 0.5454727564102564, "EFR": 1.0, "Overall": 0.7099539262820513}, {"timecode": 78, "before_eval_results": {"predictions": ["the sidewalk between Division Street and East Broadway", "August 1991", "Nigel Lythgoe", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "1956", "Atlanta", "The management team", "The legislation made two amendments to the Social Security Act of 1935", "before 1986", "Ali", "May 1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "fascia surrounding skeletal muscle", "when energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "September 1947", "April 10, 2018", "the external genitalia", "May 2017", "mid-1980s", "DNA polymerase", "1956", "Between 8.7 % and 9.1 %", "minor key symphonies", "Divyanka Tripathi", "Newfoundland", "Ole Einar Bj\u00f8rndalen", "31 December 1960", "following graduation with a Bachelor of Medicine, Bachelor of surgery degree", "the winter solstice", "1992", "George Strait", "All Hallows'Day", "November 1961", "midpiece", "2004", "$19.8 trillion", "7000301604928199000", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Sachin Tendulkar", "member states", "Andrew Lloyd Webber", "domestic cat", "Q", "Adam Werritty", "sheepskin", "5,922", "1866", "two", "2006", "eight or nine", "Lake Superior", "the Thames", "Mefistofele", "red"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6536919453754131}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, true, false, true, true, false, false, false, true, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.06060606060606061, 0.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.967741935483871, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.5714285714285715, 0.2222222222222222, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-1302"], "SR": 0.578125, "CSR": 0.5458860759493671, "EFR": 1.0, "Overall": 0.7100365901898734}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "Louisiana State University (LSU)", "1858", "heavy metal", "Edison Koon-hei Chen", "1875", "The The satirical", "his most brilliant student", "Juilliard School", "The 1st World Outgames", "1812", "Peach", "1935", "the Oregon State Beavers", "Victorian England,", "The War of '04", "American", "superhuman abilities after being bitten by radioactive/genetically-altered spiders.", "Alpine climate and landscapes, in particular for skiing and mountaineering", "Baudot code.", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "Sydney", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "Shameless", "from 1241 until his death in 1250", "Father Dougal McGuire", "erotic romantic comedy", "Armin Meiwes", "Curtis James Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1894", "London", "Bulgarian-Canadian", "James Mitchum", "Nick on Sunset", "Javed Miandad", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "the Roman Empire", "Max", "gollum", "Melbourne", "eenezer Scrooge", "54-year-old", "Muslim Eid-ul-Adha", "random events", "Richmond, Virginia", "Venezuela", "Stone Age", "South Carolina Republican Party Chairwoman Karen Floyd seemed to suggest Wednesday that the time had come for GOP Gov. Mark Sanford's resignation and start an investigation into his activities."], "metric_results": {"EM": 0.625, "QA-F1": 0.724784416971917}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4430", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-2794", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-5027", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_searchqa-validation-11106", "mrqa_newsqa-validation-4059"], "SR": 0.625, "CSR": 0.546875, "EFR": 1.0, "Overall": 0.710234375}, {"timecode": 80, "before_eval_results": {"predictions": ["Chicago Tribune", "a red wine producing town in the southern Rhone Valley in France", "Calvin Coolidge really said on January 17, 1925 at the National Press Club", "beach volleyball", "American singer-songwriter John Mellencamp", "hot springs", "the Philosopher's Stone", "PlayStation", "pro bono", "American politician and businessman", "a marker of corporality", "hobbit", "a dragon", "rattus rattus", "Department of Chemistry", "The Merry Wives of Windsor", "kowtow", "Mars", "Purple Finch", "Brazil", "red", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "alchemy", "Lon Chaney", "pasta", "potables", "Cuisinart", "travertine", "Bob Dole", "Ross Ice Shelf", "director", "China", "a grizzly bear", "Pinocchio", "Czech Republic", "the Palais Garnier", "a bison", "Athens", "Jodie Foster", "Cleopatra VII", "the Mummy", "White Fang", "the beetle", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "1938", "53", "The Lightning thief", "Brazil", "Edinburgh", "Ukrainian", "Christina Claire Ciminella", "University of California", "Saturday Night Live", "a Yemeni cleric and his personal assistant,", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy", "Joanne Wheatley"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5613839285714286}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true], "QA-F1": [0.6666666666666666, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4389", "mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-11275", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9625", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813"], "SR": 0.515625, "CSR": 0.5464891975308642, "EFR": 1.0, "Overall": 0.7101572145061729}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "Tasmanian", "Indonesia", "The Generation Game", "The Firm", "red hair", "fourteen", "Spanish", "georgia", "Inigo Jones", "sow", "Eucharist", "Turkey", "Anastasia Dobromyslova", "every ten years", "Matterhorn", "Lake Placid", "$10", "Liverpool", "Count Basie", "Manhattan", "arch", "Esmeralda's Barn night", "Ajman", "Hyderabad", "Mallard", "Laurent Planchon", "Apollo", "1963", "Bologna", "bear", "Coleraine", "La Toya Jackson", "Timothy", "Addis Ababa", "speedway", "kidney", "endurance", "salsa", "Mark Twain", "Doctor Who", "Yosemite National Park", "IBM", "40", "First World War", "passion fruit", "HMS Thetis", "7", "south of England", "one", "Pope Benedict XVI", "Jesse Triplett", "Orlando", "LED illuminated display", "41st", "Mel Blanc", "Mauthausen-Gusen", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "antihistamine and an epinephrine auto-injector", "The Wizard of Oz", "Danny Elfman", "Bolivia", "an intercalary year", "Val Kilmer"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5628798558897243}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.2857142857142857, 1.0, 1.0, 0.0, 0.10526315789473684, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7685", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-5153", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-992", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-1972", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-2103", "mrqa_searchqa-validation-14665"], "SR": 0.53125, "CSR": 0.5463033536585367, "EFR": 0.9666666666666667, "Overall": 0.7034533790650407}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "GZA", "McLean, unincorporated Fairfax County, Virginia", "1,696", "Melville, NY", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "Regional Rural Bank", "Tufts University,", "Hammer", "Wiltshire", "Isla de Xativa", "her gaoler's family", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Aosua Busia", "5.3 million", "six", "a polypeptide chain", "Brady Haran", "Minette Walters", "Syracuse University", "first", "Florida Panthers", "2010", "Happy Valley", "Juan Manuel Mata Garc\u00eda", "Malayalam", "Pittsburgh Steelers", "pronghorn antelope", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "American", "Kentucky Music Hall of Fame", "Taoiseach of Ireland", "50th anniversary of the founding of the National Basketball Association (NBA)", "American", "Corps of Discovery", "pubs, bars and restaurants", "Andrew Johnson", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "elected representatives from among themselves to form a governing body, such as a parliament", "illnesses", "Thomas Joseph", "drawn on the bank's own funds and signed by a cashier", "31 March 1909", "President Lyndon Johnson", "Celsius", "whooping cough", "Johannesburg", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Samuel Herr, 26, and Juri Kibuishi, 23, of Irvine,", "the sins of the members of the church,", "Superman", "Richard Nixon", "right", "Edward VIII"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6675287609062763}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473685, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-4045", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4368", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-4519", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.59375, "CSR": 0.546875, "EFR": 0.9615384615384616, "Overall": 0.7025420673076923}, {"timecode": 83, "before_eval_results": {"predictions": ["a graphite", "Riding in Cars with Boys:", "Mickey Mantle", "the Titanic", "economics", "Bill Clinton", "Graceland", "Cambodia", "a lifting rope", "David Copperfield", "Arnold Schwarzenegger", "a nonsense", "W", "a goat", "a pinball machine", "The Ghost of Tom Joad", "Dracula", "Niger", "a wind instrument", "Mrs. Miniver", "The Office", "Italy", "the lowest tone", "sheep", "Casey Jones", "the Gambler", "Hope", "the navy", "Dresden", "a flippant", "Arkansas", "Duchamp", "a sloop", "toilet paper", "Sesame seeds", "Iceland", "a nocturnal mammal", "Let's Make a Deal", "a bee", "Janet Reno", "a Connecticut Yankee", "Michelangelo", "Essen", "Appomattox", "Thailand", "Lazarus", "a cereal industry", "Pamela Anderson", "Theodor Seuss Geisel", "Siberia", "Scott McClellan", "Edd Kimber", "six", "Steffy Forrester", "Twin sisters", "John Denver", "Gargantua", "2017", "four", "Lester", "India", "1959", "two remaining crew members", "her abusive husband"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6520833333333333}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, false, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6754", "mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-7089", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-1643", "mrqa_searchqa-validation-5144", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-14643", "mrqa_searchqa-validation-12607", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_newsqa-validation-1331"], "SR": 0.59375, "CSR": 0.5474330357142857, "EFR": 0.9615384615384616, "Overall": 0.7026536744505495}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony", "a roof", "Cuisinart", "the lungs", "the Boston Massacre", "Truthful or creditable", "Simon Bolivar", "Little Red Riding Hood", "Abigail Adams", "Bank of America", "Cleopatra", "Colorado Springs", "a diamond", "Pablo Picasso", "The Robert E. Lee Memorial", "Pope John Paul II", "a car which covers the engine", "Herakles", "South Dakota", "natural selection", "Secretary of the Interior", "Cyrus the Younger", "Humpty Dumpty", "Bo Schembechler", "Gucci", "Vermont", "a chimp", "a desktop extender", "The Man in the Iron Mask", "New Zealand", "international fashion model", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Doctor Moreau", "organs", "wheat", "tundra", "Peter Falk", "AARP", "Tiffany", "the Pledge of Allegiance", "the earth", "the stiletto", "cheese", "Kentucky", "Bora Bora", "Titanic", "a physician", "the \"Fisherman's ring\"", "RBIs", "the forex market", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways plc", "Venice", "the ocean", "Disney California Adventure", "Acharacle", "New York", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "he joined the estimated 4,000 Zimbabweans who head south to South Africa, most of them illegally, every day.", "Baku"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6817794184981685}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.75, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.9743589743589743, 0.8, 0.0, 0.0, 1.0, 1.0, 0.8, 0.2857142857142857, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-728", "mrqa_searchqa-validation-13797", "mrqa_searchqa-validation-1686", "mrqa_searchqa-validation-12427", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6001", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-15036", "mrqa_searchqa-validation-1137", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-1219", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-2374", "mrqa_hotpotqa-validation-24", "mrqa_newsqa-validation-1793", "mrqa_newsqa-validation-2653", "mrqa_triviaqa-validation-5654"], "SR": 0.53125, "CSR": 0.5472426470588235, "EFR": 1.0, "Overall": 0.7103079044117647}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "The Little Old Lady", "Cochise", "James Clemens", "Margaret Mitchell", "The Big Red One", "a liqueurs", "endodontist", "a desktop microcomputer", "South Dakota", "Talbot", "Frasier", "McClellan", "Soundgarden", "Emperor Maximillian", "Superman", "Flavor Flav", "I.M. Pei", "The Name of the Rose", "the Federal Convention", "Norway", "Meriwether Lewis", "'thoughts and Prayers' are Not Enough - and What Is  Faith", "Steve McQueen", "Firebird", "Sweet Home Alabama", "the Vietnam War", "Petroleum", "Mike Huckabee", "a charter", "Peter Sellers", "St Mark", "Jon Stewart", "Howard Dean", "Pogo", "Help Myself", "Ontario", "Madonna", "a turban", "Perseid", "Holstein", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Winston Churchill", "Torvill and Dean", "The Black Eyed Peas", "cogito", "the Kingdom of Serbia", "prophets", "1987", "Toy Story", "Harriet Tubman", "The Great British Bake Off", "HC Davos", "Native American", "The Soloist", "Mildred,", "Vicente Carrillo Leyva", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7162760416666667}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-3006", "mrqa_searchqa-validation-1193", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-4130", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-2188", "mrqa_searchqa-validation-16360", "mrqa_naturalquestions-validation-2819", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.640625, "CSR": 0.548328488372093, "EFR": 1.0, "Overall": 0.7105250726744187}, {"timecode": 86, "before_eval_results": {"predictions": ["cob", "Barbara Walters", "the Bosphorus and the Ural Mountains", "hoover", "\"Stopping by Woods on a Snowy Evening,\"", "a rock star", "coffee", "a leopard frog", "Knott's Berry Farm", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "Piscis Australe", "de Gaulle", "anode", "Bernini", "Ovid", "P Pablo Escobar", "Lincoln", "Anne Boleyn", "modify", "Eyelids", "Bank of America", "copper", "a blackjack tie", "Kiss Me, Kate", "Jim Corbett", "plutonium", "bi", "milk", "Amistad", "a 2000 American sports drama film directed by Robert Redford,", "The Simpsons", "the Ladies Pro Tour", "Universal Studios Hollywood", "the Russian fleet", "Camembert", "an Achilles' heel", "red", "Sweden", "a member of the musical Partridge family.", "Jammu & Kashmir", "the Great Seal", "The Empire Strikes Back", "Nelson's Column", "Billy Bob Thornton", "Clark", "lima beans", "Will & Grace", "Robber Barons", "De Wayne Warren", "2017", "Venezuela", "The Coalminer's Daughter", "golf", "Dialogues des Carmelites", "England", "35,124", "between the ages of 14 to 17.", "software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7081473214285714}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1629", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-813", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-9585", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_searchqa-validation-5382", "mrqa_naturalquestions-validation-9523", "mrqa_triviaqa-validation-7114", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-1867"], "SR": 0.640625, "CSR": 0.5493893678160919, "EFR": 0.8695652173913043, "Overall": 0.6846502920414792}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University,", "Ian Fleming", "the zona glomerulosa of the adrenal cortex in the Adrenal gland", "late 19th and early 20th centuries", "Tom Jones", "Park Sung-woong", "Bonnie Franklin", "Violet", "Route 37 East", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "\" Easy (TV series)", "\"\u00c9cole des Beaux-Arts\" in Paris", "Gareth Barry", "Lucy Muringo Gichuhi (n\u00e9e Munyiri) ( ) (born 23 September 1962)", "\"Bambi, a Life in the Woods\" (1923)", "1896", "Apple iPod+HP", "2017", "The Timekeeper", "May 5 to July 8, 2014", "Sir Charles Benedict Ainslie,", "torpedo boats", "Xherdan Shaqiri", "Miami", "Boston Red Sox", "Netherlands", "Dallas", "Tia Carrere", "four", "Jim Davis", "Kurt Vonnegut Jr.", "Labrador Retriever,", "IndiGo", "1837", "Blackpool F.C.", "Diondre Cole", "DS Virgin Racing Formula E Team", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "1943", "Paradise, Nevada", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "(29 September 1888 \u2013 20 May 1937)", "2008", "Northrop F-15 Reporter", "Gareth Barry", "Gambaga", "March 2012", "Cheshire", "Kairi", "1978", "ase", "Turducken", "3000 BC", "Robert Devereux", "kathy Burke", "Alanis Morissette", "the Employee Free Choice act in Lafayette Square in Washington,", "\"peregruzka\"", "Port-au-Prince", "Wimbledon", "Brazil", "Rocky & Bullwinkle", "baseball"], "metric_results": {"EM": 0.5, "QA-F1": 0.5970421071983572}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.5, 0.0, 1.0, 0.0, 0.1818181818181818, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-2580", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-1902", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-4700", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-5679", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-5805", "mrqa_newsqa-validation-2345", "mrqa_searchqa-validation-14393"], "SR": 0.5, "CSR": 0.548828125, "EFR": 1.0, "Overall": 0.7106250000000001}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "the first to utilize Audio-Animatronics", "Continental Army", "1874", "Park Yong-gyu", "January 16, 2013", "Theodore Haynes", "Apple Lisa", "\"Veyyil\" (2006)", "Victoria", "Umina Beach, New South Wales", "from 1989 until 1994", "Adelaide Miethke", "Escambia County,", "Consigliere", "Orson Welles", "7", "The Bologna Process", "Peoria, Illinois", "Iran", "Lorne Michaels", "Philip K. Dick", "University of Texas Longhorns football", "\"O\"", "\"An All-Colored Vaudeville Show\"", "the local midnight", "German Shepherd", "The Vaudevillains", "Iftikhar Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "the Twist", "1,462", "Premier League", "Andrew G. Kaufman", "Eddie Albert", "Chicago", "Ford Island", "The Times Higher Education Guide", "Derry City F.C.", "Beverly Hills", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "The Bad Hemingway Contest", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State", "Akshay Kumar", "2015", "diastema", "Thames Street", "Stoppard", "brazil", "Dube attempted to escape", "an average of 25 percent", "Wally", "a pig's head", "Livin' On A Prayer", "the electoral college", "josef kipling"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7013888888888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1048", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-2226", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1697", "mrqa_searchqa-validation-6483", "mrqa_triviaqa-validation-7531"], "SR": 0.59375, "CSR": 0.5493328651685394, "EFR": 1.0, "Overall": 0.7107259480337078}, {"timecode": 89, "before_eval_results": {"predictions": ["Richard Masur", "UFOs to poltergeists, orbs, balls of fire and other spectral phenomena, various bigfoot-like sightings, giant snakes and \"thunderbirds.\"", "World War II", "Mike Pence", "Mickey Gilley", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "The Itchy & Scratchy Show", "First Street", "5249", "the Dutch Empire", "Tchaikovsky", "Ready to Die", "October 20, 2017", "artiodactyl mammal", "Lord's Resistance Army", "1965", "1943", "the Big 12 Conference", "1959", "1867", "Neighbourhood", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Billund", "Karl-Anthony Towns", "The Sun", "Song Kang-ho, Lee Byung-hun", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies.", "a B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Berthold Heinrich K\u00e4mpfert", "New South Wales", "EQT Plaza in Pittsburgh, Pennsylvania", "Panthera pardus", "Prudential Center", "ten", "Conservatorio Verdi", "clockwise", "State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "benson", "World War II", "George Santayana", "label products that contain any of the most common allergens", "a group of 20 similar cars making an annual road trip,", "101", "vinegar", "hurt Tammy Wynette", "salivary glands", "Venus Williams"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7138494318181818}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.0, 0.45454545454545453, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-1222", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-1173", "mrqa_hotpotqa-validation-4040", "mrqa_triviaqa-validation-6118", "mrqa_newsqa-validation-3736", "mrqa_newsqa-validation-3476", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464"], "SR": 0.640625, "CSR": 0.5503472222222222, "EFR": 1.0, "Overall": 0.7109288194444445}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeletons", "Joaquin Phoenix", "Pot", "the integument", "a motorcycle", "New Coke", "Abigail Adams", "the Labor Force", "University of Hawai'i at Manoa", "the leg", "Cristina Yang", "Omega Man", "van Gogh", "Sumbawa", "Atlanta", "Alanis Morissette", "Paddington Bear", "Google", "skyscraper", "1953", "Edward R. Murrow", "Cheetah Rivera", "a renowned fugitive Czech Resistance leader", "seven", "Nike", "a buck", "Sweden", "Lamborghini", "the United States Code when not operating", "John Philip Sousa", "oregano", "New South Wales", "Carrie Nation", "Ho Chi Minh", "Martha's Vineyard", "No. wore by Ted Williams", "apples", "Transformers: Earth Wars", "An American in Paris", "Taiwan", "Walt Disneys Pocahontas", "Aloha Air Group", "Gustave Eiffel", "\"Gentleman Jim\" Corbett", "Michael Jackson", "Firebird", "Sicily", "Bill Frist", "a cupronickel coin", "apocrypha", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "in 2011", "Russia", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records", "for him to be included in the family allowance.", "Aung San Suu Kyi", "75.", "quality of teaching and learning in American schools"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6184752747252746}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-10892", "mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-12132", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-8040", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.578125, "CSR": 0.5506524725274725, "EFR": 1.0, "Overall": 0.7109898695054946}, {"timecode": 91, "before_eval_results": {"predictions": ["The Channel Tunnel", "Hawaii", "Crayola", "giant", "grease", "Banana & Chocolate Top Banana Bar", "the Chesapeake Bay", "the Devil\\'s Dictionary", "AILD", "Macbeth", "Suez Canal", "Stephen Hawking", "Ecuador", "New York City", "the United States Federal Communications Commission", "acetylene", "a scrapple", "Fred Thompson", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "Dr. Quinn", "oblique", "Cracker Jack", "Ford", "the Flop", "phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "Monaco", "orange", "Venison", "South Africa", "a packer", "the Gifted", "the Andes", "Ovid", "1937", "Grendel", "CAVIAR", "Mogul", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "eyes", "the sound barrier", "Cyprus", "a jazz funeral without a body", "Nala", "Etienne de Mestre", "USA Army Pigeon", "species", "kenjutsu", "Rawlings", "Adam Levine", "Syracuse University", "Stuttgart", "television will listen for a signal and hear nothing.", "would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "Bed and breakfast"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6373381193693693}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.972972972972973, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-9882", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-10784", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-6932", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.578125, "CSR": 0.5509510869565217, "EFR": 1.0, "Overall": 0.7110495923913043}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "a clerk", "the Hausa and Fulani groups", "yente", "Occlusion", "a referendum", "alfalfa", "Phaedra", "Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "Daniel", "AANS", "Mozart", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "CROSSWord CLUES \"N\"", "The Secret", "a square rod", "a finale", "Frederick Douglass", "William Conrad", "Jericho", "the Burning Bush", "a gastropod shell", "Indian tribes", "Australia", "Freaks and Geeks", "Manet", "Finding Nemo", "Frdric Chopin", "a zipper", "a soap opera", "Amman", "Van Halen", "a Permanent Select Committee", "amyotrophic lateral sclerosis", "grapes", "Nancy Lopez", "The Magic Mountain", "Hudson's Bay", "Beguile", "hoo'zher", "a den", "a loaf of bread", "mead", "Mossad", "mnagerie", "an aide-de-camp", "Judith Aline Keppel", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "a plutocracy", "( Diego) Velazquez", "Shut the *freak* up", "Panther", "paracyclist", "The 2007 Summer Universiade", "Asashoryu's", "tallest building,", "in an attempt to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6482886904761904}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, true, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-5282", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-6365", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-10396", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-766", "mrqa_triviaqa-validation-6160", "mrqa_hotpotqa-validation-1786", "mrqa_newsqa-validation-1122"], "SR": 0.578125, "CSR": 0.5512432795698925, "EFR": 0.9259259259259259, "Overall": 0.6962932160991637}, {"timecode": 93, "before_eval_results": {"predictions": ["Department of Labor", "Standard Oil", "the Kings", "National Assembly for Wales", "archbishop", "Clark", "India", "They Long To Be", "American politician and businessman", "Mary Queen of Scots", "the Crimean War", "the elbow", "a thermostat", "a bad speed", "a sapphire", "florida", "a Wipers", "grace", "Kias", "the Davis Cup", "Blackbeard", "William III", "Emily Dickinson", "a stikhos", "Simon Wiesenthal", "Mercury and Venus", "LODGE-PODGE", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Charles Dickens", "All Saints' Day", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "flautas", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a bat", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "Sir Walter Scott", "War of the Worlds", "January 17, 1899", "when a population temporarily exceeds the long term carrying capacity of its environment", "about 13,000 astronomical units ( 0.21 ly )", "Jessica", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO", "cancerous tumor.", "Sunday.", "Charles Quinton Murphy"], "metric_results": {"EM": 0.71875, "QA-F1": 0.759375}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-4055", "mrqa_searchqa-validation-8162", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-9606", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-12927", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-12174", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_naturalquestions-validation-8832", "mrqa_hotpotqa-validation-751"], "SR": 0.71875, "CSR": 0.5530252659574468, "EFR": 1.0, "Overall": 0.7114644281914895}, {"timecode": 94, "before_eval_results": {"predictions": ["commit", "fever", "fossilis", "Janet Reno", "Harvard University", "Don Quixote", "The Turn of the Screw", "Lynch", "F Thomas G Nazareth", "spruce", "Wild Bill Hickok", "7", "stars", "vodka", "lava", "Anthrax", "Jamaica", "the Sacher Torte", "George Allen", "a coyote", "CVS/pharmacy", "Sulfur", "Virginia", "Jacques Marquette", "overbite", "Hannibal", "the nucleus", "Thomas Jefferson", "a millimeter", "Megan Fox", "Eurydice", "Unicef", "the Battle of the Little Bighorn", "Marie Curie", "the Archangel Cat", "Dustin Hoffman", "Nebraska", "E-T", "vodka", "John", "LOUIS XIV", "the rotunda", "the Yellow page", "Mazda", "Scout Finch", "Liechtenstein", "the joker", "Pulp Fiction", "Mao Zedong", "Nereid", "Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson and Peter Vale", "Sir Giles Gilbert Scott", "Andrew Jackson", "middle and long distance athletics", "HackThis Site", "Traumnovelle", "1985", "Manuel Mejia Munera", "7", "at least 300", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5703125}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.33333333333333337, 0.0, 0.5, 1.0, 0.42857142857142855, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-13563", "mrqa_searchqa-validation-1129", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-4855", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-9704", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-11462", "mrqa_naturalquestions-validation-4399", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-5124", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3822", "mrqa_newsqa-validation-3607"], "SR": 0.46875, "CSR": 0.5521381578947369, "EFR": 0.9705882352941176, "Overall": 0.7054046536377709}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "Haroun", "the Rhea Bird", "Atonement", "a palette", "ice cream", "Cherry baby", "Tajikistan", "Theology", "Forrest Gump", "a piles", "a hot dog", "Guy Ritchie", "Dixie's Land", "Alfred Nobel", "Karen Blixen", "The Edge", "Sindbad", "the Ziggurat", "the toe", "Pennsylvania", "\"War of the Worlds\"", "Hercules", "Steve Jobs", "J. P. \"The Big\" Bopper", "a Manwich", "1.80 655", "Pompey", "Lady Jane Grey", "Eugene V. Debs", "Texas", "Troy", "Antoinette Perry", "The Crucible", "the rabbit", "the Cylon Colony", "Rugby School", "Titan", "Francis", "2 Samuel", "Arthur Miller", "Billie Holiday", "Seal", "improv", "Scrabble", "2016", "the black bear", "the northern border", "the Barbary Coast", "a skunk", "Bill Belichick", "a permanent, fast - drying painting medium", "Reverend J. Long", "bridge", "mauritania", "cheese, \u201cspecial sauce\u201d (a variant of Thousand Island dressing), iceberg lettuce, pickles, and onions,", "Scholastic UK", "FIFA Women's World Cup", "Great Lakes and Midwestern", "St. Louis", "three out of four", "2002", "opening of its new restaurant next to the home of Mona Lisa as something completely normal."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6018795289855072}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.1, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913045]}}, "before_error_ids": ["mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-14256", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-14076", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-6639", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-2598", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-2950"], "SR": 0.5625, "CSR": 0.55224609375, "EFR": 0.9642857142857143, "Overall": 0.7041657366071429}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "Melanie Martinez", "international chain of full service, upscale hotels catering to business travelers and to the meetings and conventions market", "Kaley Christine Cuoco", "1877", "Everywhere", "T.S. Eliot", "international relations based on sovereign states", "30 October 1918", "Florida", "Meri", "\"Jones'then - wife, Peggy Lipton, who knew Vincent Price, suggested Price for the vocal part, which Price agreed to do", "Nicole Gale Anderson", "Tiffany Adams Coyne", "a region in Greek mythology", "Eddie Murphy", "20 November 1989", "Ben Savage", "Genoese merchant sailor Manuel Pessanha ( Pesagno )", "`` Reveille ''", "Samuel Chase", "`` save, rescue, savior ''", "Canadian Rockies continental divide east to central Saskatchewan", "June 11, 2002", "Khrushchev", "Addie Horton", "International Border ( IB )", "Ancy Lostoma duodenale", "between Glen Miller Road in Trenton and the Don Valley Parkway / Highway 404 Junction in Toronto", "King T'Chaka of the African nation Wakanda", "a warrior, Mage, or rogue coming from an elven, human, or dwarfven background", "1995", "the south western escarpment of the Jos Plateau", "The Union's forces", "Thomas Middleditch", "September 19, 2017", "a convergent plate boundary", "Iran", "American comedy web television series", "13", "Matt Monro", "Bill Russell", "Krypton", "December 14, 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "MFSK", "around 1940", "Sid Vicious", "Apocalypse Now", "Gower", "11,163", "Jaguar Land Rover Limited", "His son", "propofol,", "Courtney Love,", "park bench facing Lake Washington", "a cantata", "East of Eden", "Africa", "1919"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6803503787878789}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 0.07142857142857144, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.4, 0.3333333333333333, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.9090909090909091, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5468", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-937", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-3066", "mrqa_hotpotqa-validation-3348", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.59375, "CSR": 0.5526739690721649, "EFR": 0.9230769230769231, "Overall": 0.6960095534298176}, {"timecode": 97, "before_eval_results": {"predictions": ["Blue laws", "Dr. Sachchidananda Sinha", "2001 -- 2002 season", "New England", "2007", "New Croton Reservoir", "the mid-1970s", "Etienne de Mestre", "Billie", "Arnold Schoenberg", "1000 BC", "arousal recognition", "Panzerkampfwagen VIII Maus", "An optional message body", "Ian Hart", "contestants", "1898", "Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices", "Frankel", "Human fertilization", "senators", "a man called Lysander", "Shakespearean actresses and car salespeople", "Procol Harum", "2018", "William Shakespeare's As You Like It", "James Rodr\u00edguez", "Nucleotides", "Hathi Jr", "interstitial fluid in the `` interstitial compartment '' ( surrounding tissue cells and bathing them in a solution of nutrients and other chemicals )", "1983", "Instagram's own account", "Revelation was the last book accepted into the Christian biblical canon", "matching regions on matching chromosomes break and then reconnect to the other chromosome", "Qutab Ud - Din - Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Ernest Hemingway", "American swimmer Michael Phelps", "Kevin Zegers", "U.S. declared neutrality", "Isabela Moner", "April 29, 2009", "Smyrna", "Gibraltar", "red, white, and blue", "U.S. Fund for UNICEF's global programing", "Salt Lake City", "Schengen Area", "Greg Norman", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "a controversial theory about Mary Magdalene and Jesus.", "Barbara Streisand", "Brave New World", "a phobia", "Cryogenics", "anxiety disorder"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6341188583206245}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0, 0.0, 0.5, 1.0, 0.4, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 0.4347826086956522, 1.0, 0.5714285714285715, 0.3636363636363636, 0.07407407407407407, 1.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-786"], "SR": 0.515625, "CSR": 0.5522959183673469, "EFR": 0.9032258064516129, "Overall": 0.6919637199637919}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs", "Michael Sheen", "Rockbridge County", "Mumbai, Maharashtra", "Savannah", "\"Perfect Strangers,\"", "public", "Nelson County", "video game writer", "boundary river", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks for consumption on the premises", "\"The Simpsons 138th Episode Spectacular\"", "Twin Pines/Lone Pine Mall", "neo-Nazi", "forensic psychiatrist destined to become Graham's most cunning enemy", "Bisexuality", "Adam Dawes", "in the early 17th-century Colony of Virginia after serving his term of indenture", "Steven Selling", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "British", "1968", "Northampton Town", "Dirk Nowitzki", "highland regions of Scotland", "Kansas State 52\u201321", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "\"Because I Got High\"", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "1976", "Anthony Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "Amii Anne J. Grove", "their unusual behavior", "1952", "to start fires, hunt, and bury their dead", "In February 2011, while overseas, she discovered that she was pregnant", "Dmitri Mendeleev", "honda", "Utah", "Moby Dick", "The train in front had stopped behind another train undergoing service and awaited directions to move ahead.", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "to host the Olympic Games in Rio de Janeiro.", "\"Free Bird\"", "The Suite Life of Zack & Cody", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6943114177489178}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.14285714285714288, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.4, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.47619047619047616, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-1204", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-15800"], "SR": 0.609375, "CSR": 0.5528724747474747, "EFR": 0.96, "Overall": 0.703433869949495}, {"timecode": 99, "UKR": 0.703125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.724609375, "KG": 0.4625, "before_eval_results": {"predictions": ["The 2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "PBS", "The Bears", "1973", "Salisbury", "KKR & Co", "526", "Jean-Marie Pfaff", "West Point Foundry", "\"Hacksaw Ridge\"", "satirical erotic romantic comedy", "\"The Process\"", "Vikram", "1949", "BAFTA TV Award Best Actor winner", "Durham, North Carolina", "goalkeeper", "Levi Weeks", "219", "Esteban Ocon", "The S7 series", "Lamar Hunt", "Black Mountain College", "\"You Can Be a Star\"", "People v. Turner", "1853", "1977", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "\"City of Ghosts\" (2002)", "Ludwig van Beethoven", "Rabat", "A Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan Hypersport", "Richard Arthur", "in a number of national and international media", "May 4, 2004", "3 mi", "Field Marshal Lord Gort", "Neighbourhood", "The Rookie", "1979", "John Alexander", "eleven", "2011", "last Ice Age", "Tennessee", "BBC Radio Blackburn", "John Galliano", "GM and Chrysler", "section 60.", "Seoul", "Circumnavigate", "a comma", "a fifteenth anniversary", "the Mollusca"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7362655573593073}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false], "QA-F1": [0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-3889", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6790", "mrqa_newsqa-validation-2457", "mrqa_newsqa-validation-2265", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-10055", "mrqa_searchqa-validation-5045"], "SR": 0.65625, "CSR": 0.55390625, "EFR": 1.0, "Overall": 0.6888281249999999}]}