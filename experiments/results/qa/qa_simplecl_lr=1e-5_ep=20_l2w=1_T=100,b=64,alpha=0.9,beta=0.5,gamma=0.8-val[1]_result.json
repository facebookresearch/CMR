{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 7960, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "isomorphic", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "coordinating lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Stanford University Professor of Comparative Literature Richard Rorty, and American writer and satirist Kurt Vonnegut", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds", "The Prisoners ( Temporary Discharge for Ill Health ) Act, commonly referred to as the Cat and Mouse Act, was an Act of Parliament passed in Britain under Herbert Henry Asquith's Liberal government in 1913", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8216187280399118}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.06451612903225806, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.9333333333333333, "Overall": 0.8494791666666667}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "P", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "13 May 1899", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Lituya Bay in Alaska", "120 m ( 390 ft )", "the eighth season will have only six episodes", "100", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "the Ironclads", "Spain"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7738026486978469}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 0.888888888888889, 0.4444444444444445, 0.6666666666666666, 0.4, 1.0, 0.5853658536585366, 0.38095238095238093, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1759", "mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1454", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.734375, "EFR": 0.8571428571428571, "Overall": 0.7957589285714286}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "Abercrombie was recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "John Elway", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Bud '' Bergstein", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "In October 1973, the price was raised to $42.22", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.6875, "QA-F1": 0.772172619047619}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.2, 0.13333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.6875, "CSR": 0.72265625, "EFR": 1.0, "Overall": 0.861328125}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle", "wireless", "Beyonc\u00e9 and Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "1960s", "that narcotic drugs were controlled in all member states, and so this differed from other cases where prostitution or other quasi-legal activity was subject to restriction", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot (3.7 million cubic meter)", "the 50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "NDS, a Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "a thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "evading it", "the kettle and the Cricket, at one and the same", "Gandhi", "Vlad the Impaler", "\"Take us the foxes, the little... Alexandra - first cousins - as a means of getting Horace's money", "the 1982 Sony SL-2000 portable", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "8/4 x 365 = 730 days", "Tiger Woods' 1996 U.S. Amateur Win", "1867 to 1877", "Marshall Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali", "The new nightspot Teddy's made this presidential Hollywood hotel a happening", "LASER abbreviation", "Jean Dapra", "Juno", "Hundreds of species of peat mosses are found in bogs throughout Canada", "why", "Daya", "the fear of riding in a car", "American", "Mexican military"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6228263923576424}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.2666666666666667, 0.0, 0.3076923076923077, 0.0, 0.5, 0.0, 0.0, 0.0, 0.4, 0.1818181818181818, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-2804", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.53125, "CSR": 0.684375, "EFR": 1.0, "Overall": 0.8421875}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau", "Levi's Stadium", "ten million people", "the Lippe", "Video On Demand content", "time and storage", "semester", "the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "the League of the Three Emperors", "science", "143,007", "Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "drawn the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Br'er Rabbit", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.71875, "QA-F1": 0.812611943815988}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.7058823529411764, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-4919", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-6676", "mrqa_squad-validation-9753", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_squad-validation-3943", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.71875, "CSR": 0.6901041666666667, "EFR": 1.0, "Overall": 0.8450520833333334}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the courts of member states", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "the means to invest in new sources of creating wealth", "Spanish", "Structural geologists", "president and CEO of ABC", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Benjamin Burwell Johnston, Jr.", "a large green dinosaur", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "Jasenovac", "Rabat", "between 11 or 13 and 18", "Heather Langenkamp (born July 17, 1964)", "Henry Gwyn Jeffreys Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "English former international footballer", "Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Ashanti", "79", "Algeria", "a novel", "the Eastern part", "Polar Bear", "The Atlantic City Boardwalk"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7736344537815126}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 0.3333333333333333, 0.5, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.8, 0.7499999999999999, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-13072"], "SR": 0.609375, "CSR": 0.6785714285714286, "EFR": 1.0, "Overall": 0.8392857142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic", "the working fluid", "a suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "input", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "canalized section", "protest against the occupation of Prussia by Napoleon", "improved markedly", "nearly", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "single-tape", "Bart Starr", "oxygen that is damaging to lung tissue", "Karluk Kara-Khanid", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "A. E. Housman", "capital of the Socialist Republic of Vietnam", "Sevens", "fennec fox", "Bart Conner", "fantasy", "Martin \"Marty\" McCann", "Black Mountain College", "a secularist and nationalist", "Bothtec", "Cody Miller", "140 to 219 passengers", "the \"Father of Liberalism\"", "Christophe Lourdelet", "Pablo Escobar", "African", "Mexico City", "Sleeping Beauty", "2005", "1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Ali Bongo", "Wheat Chex", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7130208333333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-1771", "mrqa_squad-validation-3091", "mrqa_squad-validation-9287", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.671875, "CSR": 0.677734375, "EFR": 1.0, "Overall": 0.8388671875}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "relatively little work is required to drive the pump", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "the 5th Avenue laboratory fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "the constituting General Conference in Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "tailless", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston", "Fulham", "A55", "Ranulf de Gernon, 4th Earl of Chester", "\u00c6thelstan", "Madras Export Processing Zone", "44", "Division I", "Araminta Ross", "Manchester United", "Dragon TV", "Greek-American", "diastema", "Shirley Horn", "Iran", "Bigfoot", "Papua New Guinea", "Edgar Degas", "Manchester"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7795454545454545}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, false, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.2, 0.0, 1.0, 0.0, 0.8, 1.0, 0.3636363636363636, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-1501", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-305", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-1423"], "SR": 0.71875, "CSR": 0.6822916666666667, "EFR": 1.0, "Overall": 0.8411458333333334}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "its unpaired electrons", "French", "Museum of the Moving Image in London", "he sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "a pivotal event", "an American YouTube personality, spokesmodel, television personality, and LGBT rights activist", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marco Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "2500 ft", "Central Park", "Robert John Day", "the Afroasiatic family", "James Tinling", "Italy", "the 79th Masters Tournament", "Ulver and the Troms\u00f8 Chamber Orchestra", "Sullivan University College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "a North African dish of small steamed balls of semolina, usually served with a stew spooned on top", "22 million", "morphine sulfate oral solution 20 mg/ml", "The Firm (1993 film)", "a species of freshwater airbreathing catfish"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6712650677516665}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.5, 0.33333333333333337]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-4960", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.609375, "CSR": 0.675, "EFR": 1.0, "Overall": 0.8375}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Panthers", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "arrows, swords, and leather shields", "the Autons with the Nestene Consciousness and Daleks", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "a Standard Model", "Tolui", "the Rhine-Ruhr region", "lesson plan", "Prevenient grace", "Kansas Jayhawks", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "Russell Humphreys", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Bath, Maine", "Ector County", "Jim Davis", "Buck Owens", "the World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the Halle Orchestra", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "the Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "The Londoner"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7485255478533095}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-7729", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.671875, "CSR": 0.6747159090909092, "EFR": 0.9523809523809523, "Overall": 0.8135484307359307}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "Spanish", "100\u2013150", "Philo of Byzantium", "cooler", "in marine waters worldwide", "$60,000", "his mother's genetics and influence", "oil shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "a new element to the standard Christian suspicion of Judaism", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "It's helping consumers move beyond these hard times and has reignited a whole industry", "a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "does not involve MDC head Morgan Tsvangirai", "a homicide", "200", "a few teenage girls are found semi-conscious in a car park after overdosing on ketamine. A 13-year-old boy joins a gang and is given free ketamine", "opposition party members", "Missouri", "a personal opinion", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "in her home", "Employee Free Choice act", "Bush administration", "more than 200", "This is not a project for commercial gain", "best-of-three series", "Kaka", "Japanese ex-wife", "Dan Parris, 25, and Rob Lehr", "apartment near Fort Bragg", "two", "nearly $2 billion", "Jacob", "Molotov cocktails, rocks and glass", "250,000", "Winehouse", "the Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 )", "Thomas Hardy", "Richmond", "1994", "The Conjuring", "The Gallipoli Campaign", "Georgian Bay", "Nowhere Boy"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6399156248341031}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.25, 0.7499999999999999, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8666666666666666, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4524", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-3637", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.53125, "CSR": 0.6627604166666667, "EFR": 1.0, "Overall": 0.8313802083333334}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "Christ who is the victor over sin, death, and the world.", "Napoleon", "mass production", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states.", "1227", "lower lake", "three", "Elders", "587,000", "Private Bill Committees", "Bruno Mars", "the Catechism", "beneath the university's Stagg Field.", "Ian Botham", "Pyotr Tchaikovsky", "Vincent Motorcycle Company", "Srenchie", "Salvador Allende", "Marie Antoinette (Fraser)", "Hawaii", "Erik Thorvaldson", "Apollo", "the 1940 Rodgers and Hart musical Pal Joey.", "Mary Seacole", "green", "Indonesia", "supreme religious leader of the Israelites", "Antonio", "European Economic Community (EEC)", "Christine Keeler", "Jesus", "Jack Nicholson Easy Rider", "four", "Netherlands", "Sugar Baby Love", "Rosa Parks Bus", "Sean", "John Denver", "fertilized ovum", "Travis", "The Show", "Robert Kennedy", "Q", "umbrella", "a French author and philosopher", "barber", "Djonne Goolagong Cawley", "Murrah Federal Office Building", "Evita", "cigar", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley", "get four successful women together on a movie set and you'd think it's all claws, all the time.", "a delegation of American Muslim and Christian leaders", "Royal Wives", "University of South Carolina", "Kim Clijsters."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6451326884920634}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 0.8571428571428571, 1.0, 0.125, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-7974", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_newsqa-validation-1150"], "SR": 0.5625, "CSR": 0.6550480769230769, "EFR": 0.9642857142857143, "Overall": 0.8096668956043955}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Bo'orchu", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees.", "Dublin, Cork, Youghal and Waterford", "Tangled", "aaron", "moles", "Democritus", "fred", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "jazz piano", "one", "komando Pasukan Khusus", "Carlisle", "liquid", "Chillicothe and Zanesville", "Lucas", "Antarctica", "mercury gilding", "aniridia", "stearns Eliot", "River Forth", "woe", "NOW Magazine", "albert", "Italy", "Canada", "typhoid fever", "jul c", "action figure", "Walt Kowalski-Gran Torino", "2010", "volume of a given mass of a gas", "Venezuela", "stooge", "temperature inversion", "40", "phrenology", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Chris Weidman", "Athletics Stadium", "one", "Virgin America", "jul phelan", "aaron", "Iran's parliament speaker", "In Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike."], "metric_results": {"EM": 0.484375, "QA-F1": 0.55}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6078", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-2463", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.484375, "CSR": 0.6428571428571428, "EFR": 0.9090909090909091, "Overall": 0.775974025974026}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow, and to the University of Aberdeen", "public official", "the most cost efficient bidder", "sassafras", "Continent of Russia", "thigh", "Olympia", "Ukraine", "tribbles", "german Cain", "germanicus", "amber", "high school football", "The executioner's Song", "180 degree", "aaron", "anamosa", "grouchy", "The Comedy of Errors", "Camelot", "film", "knife", "glare", "Cologne", "ganley", "crucible", "Kosovo", "James Jeffords", "Prague", "tennis", "silk", "buffalo", "Sir Winston Churchill", "the Key deer", "Japan", "burt Reynolds", "thant", "boys", "windjammer", "thomas germanicus", "George Washington", "Augusta", "counter clockwise", "2013", "Nick Hornby", "parachutes", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama", "memories of his mother", "Israel"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5546875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, false, false, false, true, true, false, false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7000000000000001, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-405", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.453125, "CSR": 0.6302083333333333, "EFR": 0.9714285714285714, "Overall": 0.8008184523809523}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes)", "river Deabolis", "April 20", "Latin Rhenus", "1996", "wine", "German-Swiss", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "the word crossword", "Cuba Gooding Jr.", "Strongsville, Ohio", "Flemish", "Mastercard", "Grant Wood", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "lentigo senilis", "a gang of ex-cons rob a casino during Elvis convention week", "Toronto Maple Leaf Sports & Entertainment", "Zsa Zsa Gabor", "method acting", "Utah", "rum", "(Rabbit) Angstrom", "Johann Strauss II", "joey", "pro bono", "the Banca Monte dei Paschi di Siena", "The Fun Factory", "a beer relative", "Manfred von Richthofen", "Nacho Libre", "copper", "black magic or of dealings with the devil", "the hemlock", "Lowell Bergman", "National Poetry Month", "The Runza Way", "meager", "(1942)", "blimps", "( Gustav Kirchhoff)", "a geisha", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a tin star", "\"black\"", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6565972222222223}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-6463", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_newsqa-validation-2036"], "SR": 0.5625, "CSR": 0.6259765625, "EFR": 1.0, "Overall": 0.81298828125}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a34.2bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Weser River", "Eva Peron", "(Ho) Minh", "circumference", "the Inuit", "Detroit Rock City", "the Toronto Blue Jays", "President Lincoln", "Ray Bradbury", "crimes prompted by prejudice", "Madagascar", "Nicolas Sarkozy", "Rubicon", "(Conello)", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Clinton", "King Philip", "(Bellerophon)", "Balaam", "business", "The Caine Mutiny", "(Robbie) Robertson", "(founded 1932)", "(John) Coltrane", "peace sign", "oxygen", "the Sphinx", "Jan Hus", "The USA Network's original grassroots talent search", "the Mavericks", "Onegin", "Macy's", "a cotton-spinning machine", "(Santa) Claus", "(Denzel) Washington", "negligence", "the courts", "attached to another chromosome", "Broughton", "Australia", "The Jefferson Memorial", "aged between 11 or 13 and 18", "Michoacan Family", "prisoners", "his salary", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6855139652014652}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.5, 0.8, 0.5, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.23076923076923078]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_hotpotqa-validation-3410", "mrqa_newsqa-validation-1759"], "SR": 0.578125, "CSR": 0.6231617647058824, "EFR": 0.9629629629629629, "Overall": 0.7930623638344226}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Robert Lane and Benjamin Vail", "the telephone ring", "Party of National Unity", "22", "the dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "preston", "the Philippines", "The Mausoleum", "Million Dollar Baby", "Switzerland", "German World Airlines", "The Old Man and the Sea", "French", "Joe Louis", "the Nemean lion", "d'Artagnan", "the Bayeux Tapestry", "Front Porch", "China", "Sunni", "notes placed at the bottom of a page", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "Blanche DuBois", "a binding technique", "FRAM", "the House of Representatives", "a Belgian-owned Canadian beer company", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "Don Juan", "Ian Fleming", "the Headless Horseman", "London", "Yellowstone National Park", "Ronald Reagan", "Fiddler", "Ethiopian", "six 50 minute ( one - hour with advertisements ) episodes", "1992", "a base", "Bromley-By- Bow station", "the Ruul", "Cartoon Network", "Caylee Anthony", "what their cars say", "Rabbani, a former Afghan president who had been leading the Afghan peace council, was killed in an attack at his home.", "nuclear", "The drama of the action in-and-around the golf course"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6728125}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.16, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-7710", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-14873", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-9270", "mrqa_searchqa-validation-12814", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-4110"], "SR": 0.640625, "CSR": 0.6241319444444444, "EFR": 1.0, "Overall": 0.8120659722222222}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXI", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity", "same-gender marriages", "2006", "the mid-18th century", "tartaise", "A Raisin in the Sun", "Sistine Chapel", "Belarus", "a halfback", "a trowel", "Big Bang", "The Sex Pistols", "endodontist", "water", "the Cliffs of Dover", "Genoa", "Fanchette", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Ozone", "a rose", "The Hampton Inn", "10", "the Civil War", "alevin", "Paul McCartney", "omega-3", "paoletas", "P.S.", "Halloween", "caddy Shack", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "bears", "a quake", "betraying", "elephants", "mazurka", "Denmark", "a covert operations", "Nevada", "May 2010", "Statista", "a bay", "Thailand", "gender queer", "Minister for Social Protection", "the German government.", "the estate", "Bill Irwin", "ase", "North America"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5021655701754386}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473684]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-12757", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-2870"], "SR": 0.421875, "CSR": 0.6134868421052632, "EFR": 1.0, "Overall": 0.8067434210526316}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified", "Earth", "53,000", "one", "poet", "two points", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "Saturday", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "cognitive and physiological activation", "Charlene Holt", "Buffalo Bill", "1991", "electron shells", "Cornett family", "acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Rick Rude", "Ohio", "a form of business network", "a cylinder of glass or plastic that runs along the fiber's length", "Abraham Gottlob Werner", "Wakanda", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Necator americanus and Ancylostoma duodenale", "February 29", "The Lykan Hypersport", "disagreements involving slavery and states'rights", "oxygen", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units within the National Health Service in England", "Lou Rawls", "Hermia", "Jupiter", "Latin", "15", "John Robert Cocker", "Israel", "a simple puzzle video game", "a palace", "nervus olfactorius", "Eucalyptus", "a dolphin", "oxygen"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6439732142857143}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, true, false, true, true, false, false, false, true, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428572, 0.0, 0.2857142857142857, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-3747", "mrqa_searchqa-validation-12372", "mrqa_triviaqa-validation-2227"], "SR": 0.5625, "CSR": 0.6109375, "EFR": 0.9642857142857143, "Overall": 0.7876116071428572}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "\"bystander effect\"", "\"Listen, don't rush on boats to leave the country. Because I'll be honest with you: If you think you will reach the U.S.", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "well over 1,000 pounds", "political dead-end", "Mutassim", "Oklahoma", "Polo", "Joe Jackson", "Amstetten", "computer problems", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus", "prisoners", "September,", "consumer confidence", "5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "GospelToday", "Akio Toyoda", "\"There's no chance of it being open on time.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "Michael Schumacher", "Gustav", "gun", "Henrik Stenson", "the children that a French charity attempted to take to France from Chad for adoption", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "two years", "1966", "the winter solstice", "Pentecost", "the Dee", "\"Dumb and Dumber\"", "Nokia Sugar Bowl", "Minton", "converging", "autu", "season five", "Revenge of the Sith"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6472676765851109}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.5, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 0.052631578947368425, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.3333333333333333, 0.25]}}, "before_error_ids": ["mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-2301", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_triviaqa-validation-3226", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.5625, "CSR": 0.6086309523809523, "EFR": 1.0, "Overall": 0.8043154761904762}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress", "Southern Border Region", "chief electrician", "Newton", "static friction", "the assassination of US President John F. Kennedy", "responsibility for the abductions", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "in a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad", "Amanda Knox's aunt", "jazz", "$17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "a nurse who tried to treat Jackson's insomnia with natural remedies", "Sarah Brown", "getting out of the game,", "1981", "17 Again", "Nigeria", "$81,88010", "Republicans", "EU naval force", "Chris Robinson", "Bongo", "steam-driven, paddlewheeled overnight passenger boat.", "Hyundai Steel", "bone-growth disorder that causes dwarfism", "London Heathrow's Terminal 5.", "\"It was never our intention to offend anyone,\"", "February 12", "Monday", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military action", "White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\"", "Northumbrian", "Ophelia", "placed in Targoviste on Christmas Day.", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto Eduard Leopold,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6492975468159292}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.5714285714285715, 1.0, 1.0, 0.11764705882352941, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107"], "SR": 0.5625, "CSR": 0.6065340909090908, "EFR": 0.9642857142857143, "Overall": 0.7854099025974026}, {"timecode": 22, "before_eval_results": {"predictions": ["X-ray imaging", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia,", "two", "glowed even when turned off", "a number of celebrities and ministers, ranging from Yolanda Adams to Bishop T.D. Jakes to Kirk Franklin.", "resources that could sustain future exploration of the moon and beyond.", "sovereignty over them.", "April 6, 1994", "it's historical, inspiring, creative, romantic and beautiful.", "backbreaking labor", "a federal judge in Mississippi on March 22,", "the department has been severely affected by the earthquake,", "$22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "Monday", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Kase Ng,", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain,", "women.", "ancient rituals in Olympia,", "Zimbabwe's main opposition party", "No. 1", "nine", "Four bodies", "Friday", "Kingdom City", "Rima Fakih", "Tuesday night", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Damon Bankston", "researchers have developed technology that makes it possible to use thoughts to operate a computer, maneuver a wheelchair or even use Twitter", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning", "84-year-old", "Robert Park", "Rima Fakih", "Isthmus of Corinth", "Nalini Negi", "2017 - 12 - 10", "Runcorn", "collarbone", "paris", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Viva Zapata", "A Fairy Tale of Home"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5972372550767292}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.11764705882352941, 0.8235294117647058, 1.0, 0.5, 0.125, 0.23529411764705882, 0.7272727272727273, 1.0, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.23529411764705882, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-379", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1418", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.453125, "CSR": 0.5998641304347826, "EFR": 1.0, "Overall": 0.7999320652173914}, {"timecode": 23, "before_eval_results": {"predictions": ["help red algae catch more sunlight in deep water", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition", "Behind the Sofa", "Tulsa, Oklahoma", "56,", "Yemen", "2005", "Karen Floyd", "Four Americans", "those missing", "Haiti", "Susan Boyle", "Saturday", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy", "Hyundai", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over.", "threatening messages", "if she would try to travel to Japan for summer vacation.", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "Abrahamson", "martial arts,", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Islamabad \"has so far not received any information or evidence relating to the Mumbai incident from the government of India.", "Zuma", "made out of either heavy flannel or wool", "five", "Iraqi Prime Minister Nouri al-Maliki", "September 11, 2001", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed's security team", "Desmond Tutu", "$17,000", "Jobs", "$81,88010", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "a transformiation, change of mind, repentance, and atonement", "Jason Lee", "the stage where dreams occur.", "a word that functions as the name of some specific thing or set of things,", "Kent", "beer and soft drinks", "five aerial victories", "Cherokee River", "Manor Farm", "a former NASA astronaut and a retired captain in the United States Navy,", "Florida"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6437352404539904}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.56, 0.08333333333333333, 0.5, 0.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.1111111111111111, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.578125, "CSR": 0.5989583333333333, "EFR": 1.0, "Overall": 0.7994791666666666}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "American Lindsey Vonn", "WTA Tour titles at Strasbourg and Bali prior to Madrid", "him to step down as majority leader.", "United Nations World Food Program vessels carrying food and relief supplies to war-torn Somalia,", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "club", "cars are older than the industry average, with 88 percent born before 1946, according to Auto Pacific data.", "1979", "Heshmat Tehran Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector", "Bangladesh", "Michael Arrington,", "one out of every 17 children under 3 years old in America", "President Sheikh Sharif Sheikh Ahmed", "a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent", "military personnel", "placed behind the counter.", "11", "one Iraqi soldier,", "Michael Partain,", "her fianc\u00e9,", "racial intolerance.", "animal products.", "Vicente Carrillo Leyva, a leader of the Carrillo Fuentes drug cartel,", "Symbionese Liberation Army", "$8.8 million", "work together to stabilize Somalia and cooperate in security and military operations.", "compromise the public broadcaster's appearance of unbiasedity.", "black is beautiful", "$104,327,006", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "two Metro transit trains that crashed the day before,", "27 Awa", "Mark Obama Ndesandjo", "\"Dance Your Ass Off.\"", "\"Russian Madonna\" singer Valeriya, and London-based Russian art collector Nonna Materkova", "Raiders of the Lost Ark", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "Italy", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Walt Disney World", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.5, "QA-F1": 0.6136216035802433}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.4615384615384615, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.5, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.15384615384615385, 0.0, 1.0, 1.0, 1.0, 0.12500000000000003, 0.1142857142857143, 1.0, 0.0, 0.0, 0.4, 0.5, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.5, "CSR": 0.595, "EFR": 0.96875, "Overall": 0.781875}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "beetle", "arthropods", "Wayne Allwine", "St Pauls", "holography", "Pelias", "Sarah Collins", "Northumbria", "Harvard", "cricketer", "Seymour Hersh,", "a long pole", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "seborrheic dermatitis", "three", "a Rh\u00f4ne Grape Varietal", "Joseph Smith,", "Huntington Beach, California", "palladium", "the moon", "13", "a peplos", "The Virgin Spring", "Canada", "Clement Attlee", "Stockholm", "Peter Parker", "Goldie Myerson,", "Lesa Ukman", "bullfight", "Sparks", "Ginger Rogers", "the Rock of Gibraltar", "Comedy Playhouse", "citric", "Charles Darwin", "John Denver", "Mrs. Boddy", "Marie Van Brittan Brown", "Southern California Timing Association ( SCTA )", "In 1995, California was the first state to enact a statewide smoking ban ; throughout the early to mid-2000s,", "Bourbon", "Taylor Swift", "Adam Rex", "Tyler Peterson, a sheriff's deputy, shot and killed six people,", "The Detroit, Michigan, radio station promotion held three years ago was like a class to help women \" learn how to dance and feel sexy,\"", "Amy Bishop", "cactus", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.453125, "QA-F1": 0.541639085591133}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.5714285714285715, 0.125, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4827586206896552, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-147", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-7521", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-8908", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.453125, "CSR": 0.5895432692307692, "EFR": 0.8857142857142857, "Overall": 0.7376287774725274}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Space Museum\"", "number eight", "affordable housing", "Mao Zedong", "Verona", "New York", "elephants", "a large party of guests.", "Frank McCourt", "Harry Burton", "Judy Cassab", "Margo Leadbetter", "Schengen Area", "\u201cA\u201d", "city of Sheffield, England", "Famous Players-Lasky Corporation", "the Monkees", "Gerald Durrell", "Jezebel", "County Cork", "jason", "can eat and drink anything, has good,  strong feet and is happy being in a new place every day.", "Halifax", "Noises Off", "jimmy carter", "Frank Wilson", "Carlos the Jackal", "Edwina Currie", "st Moritz Winter Olympics in 1928,", "Robert Maxwell", "1768", "\u201cFor Gallantry;\u201d", "Tuesday's", "Caucasus", "Cahaba", "Ever decreaseasing Circles", "Tahrir Square", "plutonium", "Count de La F\u00e8re", "27", "Jack Ruby", "tintoretto", "Eric Coates", "Dubai", "Lester", "Thailand", "Sydney", "a dove", "t Tunisia", "Prince Philip", "Apsley House", "Tokyo", "Edgar Lungu", "49 cents", "heart rate that exceeds the normal resting rate", "672", "\"Linda McCartney's Life in Photography\"", "Robert Frost's former home", "an @ to your name", "Juan Martin Del Potro.", "27", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5177083333333333}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8026", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-2797", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-1451", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.453125, "CSR": 0.5844907407407407, "EFR": 0.9714285714285714, "Overall": 0.777959656084656}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "70", "forced Tesla out leaving him penniless.", "Zulfikar Ali Bhutto,", "Iran's nuclear program.", "at least 27 Awa", "(l-r)", "Daniel Cain,", "acid", "Wally", "2008", "after Wood went missing off Catalina Island,", "Rima Fakih", "Pakistan", "The Everglades,", "made 109 as Sri Lanka, seeking a win to level the series at 1-1,", "1950s", "64", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos,", "$163 million (180 million Swiss francs)", "unwanted baggage from the 80s and has grown beyond a resort town into something more substantial.", "around 3.5 percent of global greenhouse emissions.", "Ensenada,", "Orbiting Carbon Observatory", "Switzerland", "harold ramford", "Janet and La Toya,", "more than 22 million people in sub-Saharan Africa", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "he's burned badly on the backs of his knees and every time he moves his knee, it pulls, and it cracks,", "al-Shabaab", "posting a $1,725 bail,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "opryland", "Number Ones", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "Barack Obama", "\"gotten the balance right\"", "The oceans", "beat and binding", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "1932", "between 1923 and 1925", "Gilda", "jeremy carol \"while shepherds Watched Their Flocks By Night\"", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Benjamin Disraeli", "a rising sun"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6077658146591971}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 0.8, 0.28571428571428575, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.11764705882352941, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.6, 0.0, 1.0, 0.8, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.46875, "CSR": 0.5803571428571428, "EFR": 1.0, "Overall": 0.7901785714285714}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai", "Monday night", "Bailey, Colorado,", "children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans,", "40", "the Illuminati was this secret society which was brutalized by the Catholic Church in the 1600s.", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "in Japan", "Arizona", "between South America and Africa.", "Tetris", "outside influences in next month's run-off election,", "aid to Gaza,", "flipped and landed on its right side,", "suppress the memories and to live as normal a life as possible;", "Tuesday in Los Angeles.", "immediately appeal the ruling and seek a stay of the order with the U.S. Court of Appeals for the District of Columbia.", "the area was sealed off,", "knocking the World Cup off the front pages for the first time in days.", "Cash for Clunkers program", "\"project work\"", "Oprah: A Biography", "80 percent", "London's 20,000-capacity O2 Arena.", "try to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$50", "Australian officials", "the iconic Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "At least 38", "Argentine", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "17 Again", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off,", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "Tonight", "The Fifth Amendment", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Jawaharlal Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5821304563492063}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-7116", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.453125, "CSR": 0.5759698275862069, "EFR": 0.9428571428571428, "Overall": 0.7594134852216748}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "sex organs", "Russian army", "interstellar medium", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "ancient Mesopotamia", "maintenance utility", "July 4, 1776", "pick yourself up and dust yourself off and keep going", "John Ridgely", "by captains of sailing ships to cross the world's oceans for centuries", "October 12, 1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "salami cutting", "Ethel `` Edy '' Proctor", "who the better fighters are relative to their weight", "Husrev Pasha", "Jodie Sweetin", "ulnar nerve", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii", "al - Khulaf\u0101\u02beu ar - R\u0101shid\u016bn", "Lake Powell", "ornament", "September 6, 2019", "population", "substitute good", "Marries", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Mamata Banerjee", "the United States economy first went into an economic recession", "in sequence with each heartbeat", "Hermann Ebbinghaus", "Marvin Gaye", "used obscure languages as a means of secret communication during wartime", "Donny Osmond", "Rome and Carthage", "George W. Bush,", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Lake Baikal", "adventure park"], "metric_results": {"EM": 0.375, "QA-F1": 0.5161050455770284}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3076923076923077, 0.5, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 0.0, 0.19999999999999998, 1.0, 0.7142857142857143, 1.0, 0.14285714285714285, 0.4, 0.0, 0.0, 0.0, 1.0, 0.5517241379310345, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.375, "CSR": 0.5692708333333334, "EFR": 0.95, "Overall": 0.7596354166666667}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "Indiana", "Hutter", "shoes", "nine", "Rashid Akmaev,", "acetylene", "an illegal substance", "fiber", "an owl", "a rose", "Winston Rodney,", "sand", "Nanjing", "Montana", "a rabbit", "Louis XIV", "GILBERT & SullIVAN", "Fox Network", "Gaius Julius Caesar", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "\"Tordis and Toralv Maurstad\"", "Frida Kahlo", "Abigail Adams,", "\"Y\" 2 \"K\": An Eskimo", "Fat man", "Hair", "William Randolph Hearst", "basalt", "ale", "Homo sapiens", "telephone operator", "a song performed by English pop punk band Busted.", "Luther", "\"The New Colossus\"", "yelp", "Richard Wagner", "Princess Beatrice of York", "Braddock", "middleweight champion,", "bronchodilators", "Forty", "fluorescent lights", "Red Lake", "Le Mans", "Earl Long", "Neil Patrick Harris", "Dylan Walters", "1999", "vitamin D", "five", "Alberto juantorena", "R&B", "Awake", "Doctor of Philosophy", "Pakistan", "Seoul.", "Sonia Sotomayor"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5302083333333334}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, false, false, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-15632", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.484375, "CSR": 0.5665322580645161, "EFR": 0.9696969696969697, "Overall": 0.7681146138807429}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park,", "the macula", "the volume", "a crossword clue", "Breakfast at Tiffany's", "Diners' Club Card", "Christian Dior", "the Pittsburgh Cycle", "Juliet", "Notre Dame", "the Tablecloth", "Tate", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "a sandwich", "a deck", "kozo", "Tenzing Norgay", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Kate Middleton", "Ugly Betty", "an R", "Zechariah", "New Jersey", "Lake Ontario", "Matthew Perry", "Marissa Jaret Winokur", "John Ford", "kismet", "the Chocolate Factory", "artillery", "aluminum", "General McClellan", "Ned Kelly", "an assemblage", "gravitational force", "Isis", "a quiver", "Heroes", "on the two tablets", "the source of the donor organ", "seven", "Geheimrat Dr. Max", "Rocky Marciano", "Stevie Wonder,", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Peretti", "two years,", "Arsene Wenger", "as time goes on, it kind of becomes more and more of a phenomenon.\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.5994791666666667}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_triviaqa-validation-2878", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-2123"], "SR": 0.515625, "CSR": 0.56494140625, "EFR": 0.967741935483871, "Overall": 0.7663416708669355}, {"timecode": 32, "before_eval_results": {"predictions": ["the same as the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "the Black Death", "Kenneth", "John Stuart Mill", "Emperor Norton", "CIA", "piano", "Rickey Henderson", "Indira Gandhi", "Daucus", "John Grunsfeld", "Llados", "1976", "Galileo Descartes", "the clark", "Dust", "Rudy Giuliani,", "the Free Speech Clause", "Virginia", "Sif", "New Jersey", "The Omega Man", "a walk-in pantry", "a barrel", "the 1984 Summer Olympics", "Hugo Chvez", "Jewel", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Linda Davenport", "Los Angeles", "the east wind", "Richard III", "Labour", "the pen", "Mexico", "Douglas Adams", "Strindberg", "Hawaii", "Stephen Crane", "Prussia", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "Alice", "Part 2", "Coconut Cove", "a piano-like keyboard", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "\"My Backyard\"", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7052331349206349}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160"], "SR": 0.640625, "CSR": 0.5672348484848485, "EFR": 1.0, "Overall": 0.7836174242424243}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "pathogens, an allograft", "a large concrete block is next to his shoulder, with shattered pieces of it around him.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"I think she's wacko.\"", "the annual White House Correspondents' Association dinner", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "Hundreds of women protest child trafficking and shout anti-French slogans Wednesday in Abeche, Chad.", "forgery and flying without a valid license,", "a Little Rock military recruiting center", "Cash for Clunkers", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers,", "different women coping with breast cancer in five vignettes.", "a missile strike or confrontation between the two countries at sea.", "Police", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space,", "CNN", "no chance", "a children's hospital in St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "The portrait of William Shakespeare", "Symbionese Liberation Army", "he acted in self defense in punching businessman Marcus McGhee.", "two tickets to Italy on Expedia.", "Colombia", "a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, calm near-black on red-eyes when it's time to sleep", "resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1,", "Appathurai", "$40 and a bread.", "Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "Bremen, Germany", "Terry the Tomboy", "Harriet Tubman", "Mrs. Potts", "Spokescandy", "\"The Land of the Free and the Home of theBrave\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6662057152406418}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7058823529411765, 0.16666666666666666, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5333333333333333, 0.888888888888889, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.7499999999999999, 0.4444444444444445, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-1622", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.5625, "CSR": 0.5670955882352942, "EFR": 1.0, "Overall": 0.7835477941176471}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "taking it well.", "Washington State's decommissioned Hanford nuclear site,", "Yemen", "bankruptcy", "nearly $2 billion in stimulus funds", "a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Bahrain", "children of street cleaners and firefighters.", "Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers,", "Honduran", "Brazil", "eco", "strife in Somalia,", "Roy", "the WBO welterweight title", "relatives of the five suspects,", "Meredith Kercher.", "lawyers trying to save their client from the death penalty", "Aniston, Demi Moore and Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "cancerous tumor.", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "a model of sustainability.", "glamour and hedonism", "J. Crew.", "Department of Homeland Security Secretary Janet Napolitano", "543", "The patient, who prefers to be anonymous,", "Robert Gates", "Israel", "on 112 acres about 30 miles southwest of Nashville,", "in critical condition", "Seoul,", "Nicole", "a school test score of 98 with a \"What about those other two points?\"", "next week", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1972", "Black Elk", "The Hogan Family", "the hippopotamus", "Peter"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6050183757215007}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.07142857142857144, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_searchqa-validation-7879"], "SR": 0.53125, "CSR": 0.5660714285714286, "EFR": 1.0, "Overall": 0.7830357142857143}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position.", "Canada", "Malibu", "Sisyphus", "measure of sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "horseshoe", "Prospero", "the crayon", "the Aegean Sea", "the Battle of the Little Bighorn", "The Shakers", "a bellwether", "immdiates de la conscience", "chips", "Boxer", "the Field Guide to the Fantastical World Around You", "Mabel", "Las Vegas", "the Bible", "the Rose Bowl", "Norman Rockwell", "a bouffant and the beehive", "light tunais", "Napa", "Italy", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Begin", "a sundae", "Grace Evans", "50 million cells per litre (quart)", "Volitan Lionfish", "HIV", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Master of thunder,", "Lou Gehrig", "meaning and origin", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.4375, "QA-F1": 0.5255208333333333}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1389", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-13067", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12977", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.4375, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "a scallop", "take risks", "bullion", "Supernanny", "the Atlantic", "Cincinnati", "a mosque", "Henry Hudson", "a gun blast tubes", "dry ice", "Theodore Roosevelt", "Entourage", "eels", "Philadelphia", "The Museum of Modern Art", "the Unicorn", "John C. Frmont", "Russia", "(Barcelona) STREISAND", "Hermann Hesse", "the Taj Mittal", "English Monarchs These 2", "Carmen", "Margaret Mitchell", "La Esmerelda", "Sultans of Swing", "Pandarus", "cheerful", "Burt Reynolds", "the Sphinx", "Louis Armstrong", "Saudi Arabia", "American New Wave band", "Arby's", "coffee", "an order of chivalry", "Robert Burns", "The Incredible Hulk", "Atlanta", "the Memphis Belle", "Burkina Faso", "the Central Pacific", "Attorney General", "Icelandic", "a bison bull", "(Is) SportsCenter", "Edith Piaf", "Ivan III", "a prologue", "birch", "an investor couple", "Jack Gleeson", "(Phil) Hurtt", "animals", "Massachusetts", "the City of Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "\"State of Play\""], "metric_results": {"EM": 0.625, "QA-F1": 0.6808035714285714}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, false, true, false, true, false, true, true, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-15899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-1525"], "SR": 0.625, "CSR": 0.5641891891891893, "EFR": 1.0, "Overall": 0.7820945945945946}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "Kentucky Fried Chicken", "oats", "Romney", "Ivan", "Mary", "Earhart", "Egypt", "pi", "tin", "the Mississippi River", "Clark Griswold", "w", "Marriott", "France", "Canada", "The Secret", "gold", "collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Gulf of Mexico", "Austin", "the rational number system", "Eva Peron", "Cain", "Edward \"Ed\" Asner", "X-Men", "the Louvre", "the sockeye", "Prison Break", "Mars", "Maine", "a sheep's milk cheese", "Meg", "Modersohn-Becker", "the umpire", "Hans", "Peter Bogdanovich", "Billy Joel", "Pilate", "boat propulsion", "the Quaternary Period", "no contest", "Jr. Walker", "Czech Republic", "a fish", "the NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"The Disaster Artist\"", "Australian", "the sins of the members of the church,", "$22 million", "\"17 Again,\"", "Nelson County"], "metric_results": {"EM": 0.5625, "QA-F1": 0.628125}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-16789", "mrqa_searchqa-validation-5244", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-2766", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-8387", "mrqa_searchqa-validation-12168", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900"], "SR": 0.5625, "CSR": 0.5641447368421053, "EFR": 1.0, "Overall": 0.7820723684210527}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospirosis", "a recession", "Glashtyn", "Jay Silverheels", "Singapore", "M1 Abrams", "a small bell", "a canoe", "forgetting Sarah Marshall", "Witness", "Jack the Ripper", "3800", "Alan Shore", "taxonomy", "Spain", "the brain", "William McMaster Murdoch", "William Shakespeare", "comedy", "Mary Poppins", "Casowasco", "Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "a second marriage", "Livin' On A Prayer", "Sherlock Holmes", "a lollipop", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "diagonals", "Inuit", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "Harry Potter and the Philosopher Stone", "manganese", "forests", "Olympia", "Waylon Jennings", "David Lean", "Brazil", "British Columbia", "Marlee Matlin", "a scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "the different levels of importance of human psychological and physical needs", "one", "Norfolk Island", "the Wright brothers", "sexual activity", "Sam tick,", "the L'Aquila earthquake,", "voluntary depletion", "\"deep sorrow\"", "Pygmalion"], "metric_results": {"EM": 0.5, "QA-F1": 0.5562499999999999}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-14698", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.5, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "The Bridge on the River Kwai", "the Fall of Constantinople", "Thisbe", "Jefferson", "Ford", "The Orinoco", "a ready-to-use cotton swab", "California", "Dixie", "a nonprofit institution that helps improve policy and decisionmaking", "Warren Harding", "engrave", "Costar", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "Westies", "Ratatouille", "circadian fluctuations", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "a tailor", "a", "life", "a perennial herb", "the first phase", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Tara", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer", "Bob Dole", "Bollywood superstar", "managing his time"], "metric_results": {"EM": 0.5, "QA-F1": 0.5758928571428571}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-15434", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4073"], "SR": 0.5, "CSR": 0.5609375, "EFR": 1.0, "Overall": 0.78046875}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "horror", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000 people", "yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133", "Hark!", "Tsavo East National Park", "the New York Islanders", "1345 to 1377", "nearly 80 years", "Jean Acker", "the Championship", "The Gettysburg Address", "Whitney Houston", "Mbapp\u00e9", "The Rite of Spring", "1", "26,000", "Kristin Scott Thomas", "Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "bronze", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "a prototype of the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard ( born 7 March 1963 ), known by her pen name E.L. James", "Mase Dinehart", "Tevye", "Sir Tom Finney", "Cameroon", "obtaining and proper handling of human blood", "by military personnel to hazardous materials", "two", "Iggy Pop invented punk rock.", "a riddle", "a man", "Leonardo DiCaprio", "a narcissistic ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.625, "QA-F1": 0.7120039682539683}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_naturalquestions-validation-6326"], "SR": 0.625, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 41, "before_eval_results": {"predictions": ["a interception", "10", "did not identify any of the dead.", "Les Bleus", "2005", "more than 4,000", "Sen. Arlen Specter", "an angry mob.", "normal maritime", "Sri Lanka", "death", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as", "piano", "$250,000", "a \"prostitute\"", "the mammoth's skull", "tax", "Los Ticos", "acute stress disorder", "Russia and China", "Facebook and Google,", "through a facility in Salt Lake City, Utah,", "Manmohan Singh's Congress party,", "Haiti", "Tuesday afternoon", "militants from Pakistan", "23 years.", "a head injury.", "Tim Cahill", "an open window that fits neatly around him", "Leo Frank", "Paul McCartney", "Haiti's capital, Port-au-Prince, and other severely stricken parts of the country.", "President Robert Mugabe", "don't have to visit laundromats", "three", "United Kingdom Dance Championships.", "on-loan David Beckham claimed his first goal in Italian football.", "his son is fighting an unjust war for an America that went too far when it invaded Iraq", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died,", "Fayetteville, North Carolina,", "the Hercules transport plane crashed about 6:30 a.m.", "the Taliban", "Secretary of State Hillary Clinton", "Rihanna", "angular rotation", "the right side of the heart to the lungs", "54 Mbit / s", "in the County of Gloucestershire", "the B-24 Liberator", "most famous breakfast cereal", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "King of Sweden", "the Department of Transportation"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6593981105699855}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.7272727272727273, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.5714285714285715, 0.0, 1.0, 0.625, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3857", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-1519"], "SR": 0.515625, "CSR": 0.5613839285714286, "EFR": 1.0, "Overall": 0.7806919642857143}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Chinese", "Zimbabwe", "Italian Serie A title", "Darrel Mohler", "her dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "Morgan Tsvangirai.", "42", "is taking on the swords of the Taliban.", "some great travel spots to be altered or ruined by global climate change.", "80 percent of a woman's face", "1979", "\"Follow the Sun,\"", "Elena Kagan", "CNN's Campbell Brown", "an auxiliary lock", "1-1", "AbdulMutallab", "Myanmar", "Collier County Sheriff Kevin Rambosk", "Marcus Schrenker,", "Filipino-American woman", "poems", "the program was made with the parents' full consent.", "(the Democratic VP candidate", "The Red Cross, UNHCR and UNICEF", "Moscow", "debris", "not guilty of affray", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award.", "state senators who will decide whether to remove him from office", "31 meters (102 feet)", "its nude beaches.", "how preachy and awkward cancer movies can get.", "a Florida girl who disappeared in February,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill,", "\"theoretically\"", "1940's", "March 22,", "think are the best.", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"Antichrist.\"", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Orion", "brown", "Selfie", "2002", "England", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.59375, "QA-F1": 0.693739983974359}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 0.1111111111111111, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.3076923076923077, 0.5333333333333333, 0.4, 0.4, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-564", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.59375, "CSR": 0.5621366279069768, "EFR": 1.0, "Overall": 0.7810683139534884}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "legitimacy of that race.", "At least 88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "that these \"fusion teams,\" as they're being called, have come into effect.", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "$2 billion", "The National Infrastructure Program, as he called it,", "After the war,", "The station", "Krishna Rajaram,", "man's lifeless, naked body", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Camp Lejeune, North Carolina", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "that Iran could be secretly working on a nuclear weapon", "that the teens were charged as adults.", "death squad killings carried out during his rule in the 1990s.", "Elena Kagan", "Hyundai's", "100 percent", "Saturday", "Pakistan's", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Tribe", "a Muslim with Lebanese heritage,", "in a Johannesburg church that has become a de facto transit camp,", "Barack Obama", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "most of those who managed to survive the incident", "$50 less", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960 Summer Olympics in Rome", "Aston Lower Grounds", "peasants, small and medium-size farmers, landless people, women farmers, indigenous people, migrants and agricultural workers", "cue ball", "1822", "The Dressmaker", "Trilochanapala", "crote", "a buffalo", "ruby slippers", "the frontal lobe"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6038632789907461}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.08, 0.923076923076923, 0.9523809523809523, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5263157894736842, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 0.33333333333333337, 0.0, 0.125, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.46875, "CSR": 0.5600142045454546, "EFR": 1.0, "Overall": 0.7800071022727273}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf.", "Los Angeles", "Christopher Livingstone \" Chris\" Eubank Jr.", "Duval County, Florida", "Benj Pasek and Justin Paul,", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Johns Creek", "Franconia, New Hampshire,", "Operation Watchtower", "Dan Crow", "War & Peace", "Amberley Village", "What Are Little Boys Made Of?", "Berea College", "the United Football League", "Luca Guadagnino", "Liesl", "Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "nationality law", "Radcliffe College", "James A. Garfield", "Ford", "If the citizen's heart was heavier than a feather", "India", "German", "Charmed", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "Henry Luce", "I'm Shipping Up to Boston", "American", "British singer and \"Britain's Got Talent\" winner Jai McDowall", "central", "sixth - largest country by total area", "the first to develop lethal injection as a method of execution", "Nicola Adams", "\"bay of geese,\"", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "Fayetteville, North Carolina,", "Chaucer", "rattlesnakes", "suspicion", "healthy"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6153363403774588}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.8, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.10526315789473684, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.546875, "CSR": 0.5597222222222222, "EFR": 0.9655172413793104, "Overall": 0.7626197318007664}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "United States, NATO member states, Russia and India", "30", "crocodile eggs", "Colorado prosecutor", "Jason Chaffetz", "on Saturday.", "in Haiti", "in July for A Country Christmas,", "sniff out cell phones.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "\"17 Again,\"", "does not believe North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie", "Heshmatollah Attarzadeh", "the ireport form", "government", "Nine out of 10 children", "police", "Sen. Joe Lieberman,", "a crocodile", "a bronze medal in the women's figure skating final,", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families, when the service members are in uniform and traveling on orders.", "Phillip A. Myers.", "Obama's", "King Gyanendra,", "homicide by undetermined means,", "Casey Anthony,", "officers at a Texas  airport", "10 municipal police officers", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers, ages 18 and 5,", "since 2004.", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Wenger", "slavery", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan )", "Latin liberalia studia", "a British children's writer", "Johnny Mathis", "Beverly Hills Cop,", "Champion Jockey", "Luca Guadagnino", "Ms. Jackson", "the caged bird", "how timing shapes and supports brain function", "1 1/2 fl.", "unarmed"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6813586995813111}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.47619047619047616, 1.0, 1.0, 0.8695652173913044, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.6666666666666666, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.546875, "CSR": 0.5594429347826086, "EFR": 0.9310344827586207, "Overall": 0.7452387087706147}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "\" viewers can vote online, via phone calls or by text messaging, and those votes comprise 50 percent of each couple's score.", "without bail and will be arraigned June 25,", "12.3 million", "Mexico", "Argentine", "Vivek Wadhwa,", "Brett", "eight Indian army troopers, including one officer, and 17 militants,", "Saturday", "Nicole", "legitimacy of that race.", "Adidas", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "promise to improve health and beauty.", "Chinese", "Newcastle", "\"Nothing But Love\"", "allegedly involved in forged credit cards and identity theft", "June 6, 1944,", "the Middle East and North Africa", "twice", "October 19,", "\"It was a wrong thing to say, something that we both acknowledge,\"", "Seoul,", "promotes fuel economy and safety while boosted the economy.", "ALS6", "eight", "Siri.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback Forestry in Medford, Oregon,", "the children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "The rights group", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "test scores and graduation rates", "one", "the most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "Discworld", "Japan", "fox hunting", "New York", "travel diary", "16,116", "a sophomore jinx", "sukkar", "bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7149619044150295}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.8, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.625, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615388, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3956", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-380", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.65625, "CSR": 0.5615026595744681, "EFR": 1.0, "Overall": 0.780751329787234}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "A Rush of Blood to the Head", "5", "Chicago", "The Ones Who Walk Away from Omelas", "child actor", "Dennis H. Kux", "drawing the name out of a hat", "Brett Ryan Eldredge", "I-League", "two or three", "Badfinger", "Lady Frederick Windsor", "point-coloration pattern", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1946 and 1947", "5,112", "1992", "many artists' lofts and art galleries, but is now better known for its variety of shops ranging from fashionable upscale boutiques to national and international chain store outlets.", "14,673", "6'5\"", "Mickey Gilley's", "Switzerland\u2013European Union relations", "German shepherd", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London", "the Salzburg Festival", "Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "Messiah Part II", "Bunker Hill", "lion", "the Royal Navy", "World War II", "Knoxville", "\"Three's Company\"", "P.O.S,", "Labour", "Linda McCartney's Sixties: Portrait of an Era", "Erich Maria Remarque", "September 14, 2008", "79", "Frank Theodore `` Ted '' Levine", "Romania", "Zephyr, Billy Cobham, Alphonse Mouzon, the James Gang, Deep Purple, and Moxy", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces at the site.", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "cloakroom", "Lehman Bros International"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7282226454101455}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.13333333333333333, 0.0, 1.0, 0.5, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.5, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-4043", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_triviaqa-validation-2701"], "SR": 0.609375, "CSR": 0.5625, "EFR": 0.96, "Overall": 0.76125}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "tuna", "offensive", "Vulcan", "the Pilgrims", "Fawn Hall", "waive", "ding-dong", "Barnum", "Peter John", "cathode", "a torque screw", "gold", "Marlon Brando", "dnghu", "\"Inventing Impressionism\"", "University of Kentucky", "ruddy", "Bruss", "Macbeth", "General Lee", "lost $18.2 billion", "Fyodor Dostoevsky", "Martin Luther", "Clue", "Edgar Allan Poe", "Germany", "Stephen A. Douglas", "15", "Mike Connors", "Jungle Jim", "Jim Inhofe", "sancire", "Corpus Christi", "Mali", "an ostrich", "a new government", "slow-starting night owls", "mug", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "a frigate", "the Grail", "West Virginia", "Thomas Jefferson", "movie house", "Seaworld", "critic", "Khrushchev", "1904", "a young girl", "Jimmy Robertson", "ambidevous", "chariot", "Humberside Airport", "265 million", "100 million", "help rebuild the nation's highways, bridges and other public-use facilities.", "head injury.", "\"clear moral prohibition\"", "Charles II"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5339767156862745}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-3406", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-3109", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4175", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.484375, "CSR": 0.5609056122448979, "EFR": 1.0, "Overall": 0.7804528061224489}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Colorado", "Pamela Anderson", "colombo", "Treasure Island", "Pocahontas", "Drew", "(Whizzer) White", "a ukulele", "an aerosol for cleaning ovens.", "a magnum opus", "(Ferris) B Mueller", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "the Percheron", "(Ernest) Lawrence", "rodeo", "a fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "the small intestine", "the mouthpiece", "the Bahamas", "the Fellowship of the Ring", "Have You Neverbeen Mellow", "repellents", "Manhattan", "February 2", "Leontyne Price", "a compost", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "( Carrie) Bradshaw", "a spring", "Sweden", "a burnoose", "Philadelphia", "peanut butter", "Invisible Man", "cork", "Lex Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "Cowdenbeath", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "The incident Sunday evening", "three out of four", "poems telling of the pain and suffering of children just like her", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.5887152777777778}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-3349", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073"], "SR": 0.515625, "CSR": 0.56, "EFR": 0.967741935483871, "Overall": 0.7638709677419355}, {"timecode": 50, "UKR": 0.77734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.833984375, "KG": 0.503125, "before_eval_results": {"predictions": ["Fatih Ozmen", "Volvo 850", "Skyscraper", "Cadillac Stingray", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hilo", "Robert Downey", "Continental AG", "band director", "Germanic", "Anaheim", "Reinhard Heydrich", "the Big Ben clockface", "Standard Oil", "The Longest Yard", "Chiwetel Ejiofor", "president", "19th-century", "Hillary Scott", "HackThis Site", "Vice President", "Tottenham Hotspur", "October 2016", "Vixen", "a scholar during the Joseon Dynasty", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Santa Fe", "propaganda channel", "The Adelaide Lightning", "Operation Neptune", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "50 km north-northeast of Bologna", "created the American Land-Grant universities and colleges", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "Indian", "hamburgers", "Liverpool", "little hairs", "Luigi Segre", "the United States Congress", "February 16, 2018", "1980", "Nacio Herb Brown", "Geoff Hurst", "Precambrian", "Mull", "his death cast a shadow over festivities", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "progressive neurological disease", "Paul Newman", "Puccini", "John Candy", "milk and honey"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5979166666666667}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.4, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.13333333333333333, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2137", "mrqa_hotpotqa-validation-4406", "mrqa_naturalquestions-validation-2080", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-2317", "mrqa_searchqa-validation-13015"], "SR": 0.515625, "CSR": 0.5591299019607843, "EFR": 0.967741935483871, "Overall": 0.7282649924889311}, {"timecode": 51, "before_eval_results": {"predictions": ["1979", "an Indian", "The Chiltern Shakespeare Company", "1961", "Stacey Kent", "1930 December 1908 \u2013 20 September 2005", "Arthur Freed", "Elizabeth Kekaikuihala Keka\u02bbaniauokalani Kalaninuiohilaukapu La\u02bbanui Pratt", "Gothic Revival mansion", "Buffalo", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "its air-cushioned sole (dubbed \"Bouncing Soles\")", "The White Knights of the Ku Klux Klan", "WikiLeaks", "Nine-card Brag", "Montana State University", "Tool", "Wikimedia Foundation", "Flashback: The Quest for Identity", "ARY Films", "1987", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale, North West England", "the Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "the United States", "Dame Eunice Mary Kennedy Shriver,", "No. 17 and 35", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Richard Price", "Archie Andrews", "George Lawrence Mikan, Jr.", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "devonian coast", "devotional", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "October 29 and November 5.", "Joseph Holt Ingraham", "hunter sauce", "The Hobbit", "carbon"], "metric_results": {"EM": 0.625, "QA-F1": 0.6984732190324295}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.5, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2199", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747"], "SR": 0.625, "CSR": 0.5603966346153846, "EFR": 1.0, "Overall": 0.734969951923077}, {"timecode": 52, "before_eval_results": {"predictions": ["My ntonia", "King Henry VIII", "lead", "the Rose Bowl", "VC-25", "amber", "Denmark", "terriers", "Katrina & the Waves", "heaven", "freestyle", "celtic", "Ustilaginales", "Stargate", "Lou Reed", "Stonewall Jackson", "Fennoscandia", "Emma Peel", "canvas", "celtic", "The X-Files", "Frankie Muniz", "undersea world", "Huron", "Coupvray", "kinetic", "Santera", "Starsky and Hutch", "a statue", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "the San Antonio River", "a cornucopia", "All That Jazz", "Ankara", "condensation", "eight", "Uberti Winchester", "Chinese", "It's Garry Shandling's Show", "The Virgin Spring", "Como agua para chocolate", "southern Eritrea", "TGI Friday's", "John Tyler", "Daniel Craig", "humility", "programming", "the Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "if the concentration of a compound exceeds its solubility", "Doctor Zhivago", "Bishopston", "(Bill) Cobbett", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1961", "between South America and Africa.", "way American men and women dress but also on the way they imagine, seek and indulge in the Good Life,", "fake his own death by crashing his private plane into a Florida swamp.", "Stockton & Darlington"], "metric_results": {"EM": 0.5, "QA-F1": 0.5926782852564103}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, false, false, true, true, true, true, false, false, true, false, true, false, false, true, false, true, false, false, true, false], "QA-F1": [0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.28571428571428575, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.625, 1.0, 0.923076923076923, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.7142857142857143, 0.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-10899", "mrqa_searchqa-validation-16650", "mrqa_searchqa-validation-15562", "mrqa_searchqa-validation-15002", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.5, "CSR": 0.5592570754716981, "EFR": 1.0, "Overall": 0.7347420400943395}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Saint Etienne", "After Shawn's kidnapping", "manage the characteristics of the beer's head", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "birch", "slide clips, slide clamps or a cross-table", "Gary Player", "Nicolas Anelka", "season two", "DNA is held in the sequence of pieces of DNA called genes", "global crowdfunding platform focused on creativity and merchandising", "Most of the rainfall occurs in the December to March period", "David Motl", "The Portuguese", "Wisconsin", "September 1972", "2017", "Gustav Bauer", "detritus", "the magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "Lulu", "1961", "111", "Brazil, Turkey and Uzbekistan", "the dromedary", "13", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "compound sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophie Monk and Eddie Perfect", "the Coriolis force", "the five - year time jump", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Daya Jethalal Gada", "74", "a yellow background instead of a white one", "the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "noble gas", "the Department of Health and Human Services", "four distinct levels", "Janie Crawford", "Justin Timberlake", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Paul Gauguin", "brutal attacks on Muslims since the Brussels attack had not been reported.", "creeks,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "The Palm Jumeirah increased Dubai's shoreline by 100 percent after work started on it in 2001.", "the Northwest Territories", "Chekhov", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6569784757284758}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.5, 0.4615384615384615, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.7567567567567568, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3076923076923077, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4748", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.515625, "CSR": 0.5584490740740741, "EFR": 0.9032258064516129, "Overall": 0.7152256011051374}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "a proverbial phrase referring to one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "Tex - Mex cuisine is characterized by its heavy use of shredded cheese, meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "George Harrison", "Kanawha Rivers", "1803", "President pro tempore of the Senate", "c. 3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "Ellen is restored to life and is married to Bobby", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "A justice of the peace ( JP ) is a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "The resort is the first to be built in the complex in over seven years", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Coldplay", "Arkansas", "the birth centenary of Pandit Jawaharlal Nehru", "Edward Seton", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "Secretary of Homeland Security", "cylinder of glass or plastic that runs along the fiber's length", "Transvaginal ultrasonography", "741 weeks", "Zimbabwe", "Lugano, Switzerland", "Sarah Palin's", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison,", "the ship of violating Chinese and international laws during its patrols,", "a city of romance, of incredible architecture and history.", "Tater Tots", "Yemen", "a proof", "the Dalton Gang"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5936530430049065}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.4827586206896552, 0.0, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.8, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.07407407407407407, 0.060606060606060615, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.8571428571428572, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-902", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-940", "mrqa_triviaqa-validation-3099", "mrqa_hotpotqa-validation-2751", "mrqa_newsqa-validation-3310", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-8575"], "SR": 0.46875, "CSR": 0.5568181818181819, "EFR": 0.9117647058823529, "Overall": 0.7166072025401069}, {"timecode": 55, "before_eval_results": {"predictions": ["\"One day, while listening to what seems to be a crossed telephone connection, she hears two men planning a woman's murder", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "In 1967, Celtic became the first British team to win the competition", "the Columbia River Gorge", "the Northeast Monsoon", "2013", "American country music group The Nitty Gritty Dirt Band", "land, fresh water, air, rare earth metals and heavy metals including ores such as gold, iron, copper, silver", "annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "creating a so called minimum viable product that addresses and solves a problem or need that exists", "London", "Incumbent Democratic mayor Marty J. Walsh", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Ernest Rutherford", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "SI joint", "HTTP / 1.1", "the Brewster family, descended from the Mayflower", "1 mile ( 1.6 km )", "pop ballad", "8 December 1985", "during meiosis", "2007", "Arnold Schoenberg", "an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "in the books of Exodus and Deuteronomy", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outside ( skin ) and the inside cavities and lumina of bodies", "2019", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "10,605", "Tom Thornton", "Sebastian Vettel", "Alamodome in San Antonio, Texas", "Sun Harvester", "Eukarya", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Kevin Lima", "Celebrity Big Brother", "Joseph V. Micallef", "James Garner", "Boston, Massachusetts", "Robert Jenrick", "Bob Hurley", "improve the military's suicide-prevention programs.", "five", "\"The Closer.\"", "Charles the Bald", "Madonna", "Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6299207127865809}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.09523809523809522, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.7096774193548387, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 1.0, 0.1290322580645161, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-4760", "mrqa_newsqa-validation-1887", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.515625, "CSR": 0.5560825892857143, "EFR": 0.9032258064516129, "Overall": 0.7147523041474655}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "10 May 1940", "Raghu II", "16", "1840", "1999", "Old Trafford", "Tami Lynn", "A symbol consists of three dots placed in an upright triangle and is read therefore", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "Jurriaen Aernoutsz", "4 September 1936", "hydrogen and oxygen", "1940", "Authority", "April 1st", "Brobee", "the claims process starts at noon Eastern Time and ends 24 hours later", "Francisco Pizarro", "habitat", "Ben Faulks", "Lady Gaga", "can negatively affect a person's personal, work, or school life, as well as sleeping, eating habits, and general health", "1989", "Liam Cunningham", "Lorenzo Lamas", "Walter Pauk", "1979", "the septum", "Daoism", "the forex market", "`` Singing the Blues '' by Guy Mitchell in 1957", "Sir Ernest Rutherford", "Nigel Lythgoe", "December 2, 2013", "gastrocnemius", "Al Pacino", "introduced and elaborated as early as in 1651", "March 26, 1973", "1986", "on location", "President Lyndon Johnson", "prenatal", "a Nativity scene", "1840", "2007", "Branson, Missouri", "first baseman", "Tumi Holdings", "River Shiel", "brewer", "Polo", "The iconic Abbey Road music studios made famous by the Beatles are not for sale,", "ego", "Nova Scotia", "Sir Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6887629731379732}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.22222222222222224, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-7486", "mrqa_triviaqa-validation-7674", "mrqa_hotpotqa-validation-3278", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-10569"], "SR": 0.59375, "CSR": 0.5567434210526316, "EFR": 0.9615384615384616, "Overall": 0.7265470015182187}, {"timecode": 57, "before_eval_results": {"predictions": ["England", "Massachusetts", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "Casino promotions such as complimentary matchplay vouchers or 2 : 1 blackjack payouts", "the Infamy Speech of US President Franklin D. Roosevelt", "the coffee shop Monk's", "Fats Waller", "the original game release", "Ozzie Smith", "Mark Jackson", "2017", "two - year terms", "January 2018", "in all land - living organisms, both alive and dead", "September 30", "the ancestral virus, of avian origin, crossed the species boundaries and infected humans as human H1N1", "Gerald Ford", "September 8, 2017", "1998", "political ideology", "Spektor", "an object", "Cell nuclei", "1955", "October 12, 2017", "Ren\u00e9 Verdon", "preserves the intervallic relationships of the original scale", "a number of friends ( who provide their phone numbers in advance )", "to refer to a god of the Ammonites, as well as Tyrian Melqart and others", "P.V. Sindhu", "Carpenter", "Asuka", "Wilt Chamberlain", "Herman Rarebell", "Brazil", "UNESCO / ILO Recommendation concerning the Status of Teachers", "a document of the United States Department of Defense", "a spherical boundary of zero thickness in which photons that move on tangents to that sphere would be trapped in a circular orbit about the black hole", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "prenatal development", "skeletal muscle and the brain", "Ronnie Dunn", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "Long Island in the summer of 1922", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "Brian Friel", "Gust Avrakotos", "Mark Sanford,", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5913380456349207}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, false, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false], "QA-F1": [0.0, 0.4, 0.7499999999999999, 0.14285714285714288, 0.125, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.24, 0.0, 0.9600000000000001, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 1.0, 0.3, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-5291", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.46875, "CSR": 0.5552262931034483, "EFR": 0.7941176470588235, "Overall": 0.6927594130324544}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "Idaho", "October 14, 2017", "Deuteronomy", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979 -- 80 season", "the 14th most common surname in Wales and 21st most common in England", "iron", "the Reverse - Flash", "Los Angeles, California", "the thirteen American colonies regarded themselves as a new nation, the United States of America, and were no longer part of the British Empire", "Jaffa cakes", "the name of a work gang", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "1923", "the brain and spinal cord", "Seattle, Washington", "27 January -- 16 April 1898", "Yosemite National Park", "Ewan McGregor", "LED illuminated display", "turkey", "1917", "January 2004", "Anna Faris", "smen", "Mount Sinai", "Macon Blair", "genome", "by each state's DMV, which is required to drive", "France's Legislative Assembly", "four", "divergent tectonic", "Steve Russell", "to refer to either peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "on 13 February", "276", "the early 1960s", "President Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "2003", "Zuzu & Zaza Zebra", "endometriosis", "1960", "Justin Trudeau", "2006", "Walldorf", "superhero roles", "crude oil", "peppermint oil", "the FBI", "a ferry", "Leland Stanford", "Oaxaca", "Nepal"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6674861207559378}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.92, 1.0, 0.4444444444444444, 0.0, 0.0, 1.0, 0.18181818181818182, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.33333333333333337, 0.0, 0.0, 0.2857142857142857, 0.5, 0.5, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.5365853658536585, 1.0, 0.0, 1.0, 0.8, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-10561", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-10231"], "SR": 0.515625, "CSR": 0.5545550847457628, "EFR": 0.9032258064516129, "Overall": 0.7144468032394752}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic", "IIII", "an expression of at least a moderate amount of manual dexterity", "quarterback", "July 2012", "Audrey II", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "by January 2018", "George Strait", "\u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F )", "Herman Hollerith", "94 by 50 feet", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds, and also in the differential", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "January 12, 2017", "The Miracles", "provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Roxette", "Long Island", "1988", "Germany", "Rococo - era France", "Michael Crawford", "Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "September 2, 1945", "1950s", "Napoleon Bonaparte", "XXXX", "by the early - to - mid fourth century", "Made a decision to turn our will and our lives over to the care of God as we understood Him", "Leon Battista Alberti", "starting on January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Joker Wild", "Chicago", "Dijon", "Lucas Stephen Grabeel", "15,024", "model", "the test results by the medical examiner's office, Garavaglia said.", "teenage", "Sunday", "Vietnam", "the cello", "Richard", "(Son of Sam)"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7523854673552254}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9090909090909091, 0.2580645161290323, 0.5454545454545454, 0.7499999999999999, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-3750", "mrqa_triviaqa-validation-34", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_newsqa-validation-3928", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465"], "SR": 0.65625, "CSR": 0.55625, "EFR": 0.8636363636363636, "Overall": 0.7068678977272727}, {"timecode": 60, "before_eval_results": {"predictions": ["a recognized group of people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "1998", "used their knowledge of Native American languages as a basis to transmit coded messages", "the Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "a ( n )", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "honey", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Dennis C. Stewart", "Mahatma Gandhi", "people of France to the people of the United States", "eighth", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "April 2010", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Pink Floyd", "ummat al - Islamiyah", "Brazil", "Parashara", "Domhnall Gleeson", "local teas and medicines, and as a `` sweet treat ''", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1966", "the alluvial plain", "\"The closest approach to the original sound\"", "Peter Sellers", "Colonel Tom Parker", "Atlantic", "mistress of the Robes", "Australian Electoral Division", "Conway", "Kurt Cobain's", "\"Empire of the Sun,\"", "Hector Berlioz", "The Killing Fields", "Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6562131358225107}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false], "QA-F1": [0.625, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-2900", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-1282"], "SR": 0.546875, "CSR": 0.5560963114754098, "EFR": 0.8620689655172413, "Overall": 0.7065236803985302}, {"timecode": 61, "before_eval_results": {"predictions": ["March 21, 2016", "to form a higher alkane", "shared until 2010 -- 11, when Dimitar Berbatov and Carlos Tevez both scored 20 goals that season to tie for the award", "Jason Marsden", "New Mexico", "In 1889, following the Local Government Act 1888, using those same boundaries, Sussex was divided into two administrative counties, East Sussex and West Sussex together with three self - governing county boroughs, Brighton, Eastbourne and Hastings", "Poems : Series 1", "William the Conqueror", "March 2, 2016", "July 20, 2017", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Dan Stevens", "legislative act passed by the Congress of the United States and its predecessor, the Continental Congress", "2018", "from 6 -- 14 July", "the 2009 model year", "4.25 inches ( 108 mm )", "Judi Dench", "Madhouse", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "the 18th century", "Thomas Jefferson's", "Elijah Wood", "cat in the hat", "Brad Dourif", "counter clockwise direction", "Joanne Wheatley", "vice president", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "the 1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the efferent nerves that directly innervate muscles", "1773", "The First Battle of Bull Run ( the name used by Union forces )", "American country music duo Brooks & Dunn", "kippis", "northernmost continent", "The Pilgrim's Progress", "Bourbon County", "Argentina,", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.578125, "QA-F1": 0.691467803030303}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, false, false, true, false, true, false, false, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.09523809523809523, 1.0, 1.0, 0.05714285714285715, 0.24000000000000002, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5714285714285715, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.578125, "CSR": 0.5564516129032258, "EFR": 0.9259259259259259, "Overall": 0.7193661327658303}, {"timecode": 62, "before_eval_results": {"predictions": ["1952 in the television series, The Lone Ranger for one season from 1952 until 1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Javier Fern\u00e1ndez", "Tim Russert", "Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples", "toys or doorbell installations", "a microfilament", "in positions Arg15 - Ile16", "the northernmost point on the Earth", "the twin sister of Spencer", "Eduardo", "1868 war veterans, such as Polish internationalist General Carlos Roloff and Seraf\u00edn S\u00e1nchez in Las Villas", "1971", "Leo Arnaud", "Emmanuelle Chriqui", "Carlos Alan Autry Jr.", "16 March 2018", "Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 )", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "judges", "1912", "George Harrison", "Djokovic", "James Hutton", "late 1922", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Toronto, Ontario, Canada", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the final scene of the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "from New Orleans going north through Chicago and to New York", "from the port of Nueva Espa\u00f1a to the Spanish coast", "10.5 %", "ecological regions", "White House Executive Chef", "the International Border ( IB )", "Bart Millard", "a woman named Sarah Whitehead,", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "heavy metal", "Selden", "American Seung-Hui Cho who killed 32 students and himself at Virginia Tech and American John Wayne Gacy, Jr.", "the day before.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Chastity", "the Entente Council", "Chief Oshkosh", "The River Welland"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6070402908638203}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [0.47058823529411764, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.16666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 0.5, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_triviaqa-validation-7273", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.53125, "CSR": 0.5560515873015873, "EFR": 0.9666666666666667, "Overall": 0.7274342757936507}, {"timecode": 63, "before_eval_results": {"predictions": ["Robyn", "the end of the 2015 season", "the closing of the atrioventricular valves and semilunar valves, respectively", "the Coppolas", "sacroiliac joint", "the problems", "Mexico", "electronic computers", "the Internal Revenue Service", "Balaam ( Numbers 22 : 28 )", "Bhupendranath Dutt", "Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "the table", "Kristy Swanson", "Jakkur, Bangalore, India", "in a thousand years", "first year at Potter School of Witchcraft and Wizardry", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "supported modern programming practices and enabled business applications to be developed with Flash", "Forbes Burnham", "on Saturday evenings", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "the court from its members for a three - year term", "Alicia Vikander", "over 300,000", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "eight", "Lori Rom", "a Czech word, robota, meaning `` forced labor ''", "Arlen `` The Chief '' Bitterbuck", "Cameron Fraser ( who disappeared with \u00a3 60,000 of her savings )", "Austin and Pflugerville", "three times", "Exodus 20 : 7", "four", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "Lana Del Rey", "The Matterhorn", "Trinidadian Calypso", "JP Richardson", "The Pentagon", "Croatan, Nantahala, and Uwharrie", "Johnnie Ray", "Robert Mugabe", "Capitol Hill,", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionism", "the Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5590847086940837}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5714285714285715, 0.2222222222222222, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.14285714285714288, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.9523809523809523, 0.5, 1.0, 1.0, 0.125, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-4240", "mrqa_searchqa-validation-8333"], "SR": 0.421875, "CSR": 0.553955078125, "EFR": 0.8918918918918919, "Overall": 0.7120600190033783}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan,", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Foxborough", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Temple Sanchez", "Vanessa Hudgens", "top division", "Amber Laura Heard", "Peter Seamus O'Toole", "March 8, 1942", "a recurring dream of Stipe's", "January 30, 1930", "Doctor", "The Government of Ireland", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes o' Bowhether\"", "Westminster system", "I. helicon", "For Love Alone", "October 4, 1970", "King of the Polish-Lithuanian Commonwealth", "J. Robert Oppenheimer", "Transporter 3", "2000", "Gauteng province", "the Vietnam War", "Bill Walton", "the Darling River", "Brian Keith Bosworth (born March 9, 1965), nicknamed \"The Boz,\"", "over 140 million", "American", "Teri Garr", "the employer", "the 1965 -- 66 season", "Wyoming", "The Krankies", "Apeirophobia", "announced it would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "The clothing must be black, red or white,", "trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "American alternative rock band", "Ellicott City", "a sprint", "Southport, North Carolina"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6200520833333334}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-5596", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9071"], "SR": 0.53125, "CSR": 0.5536057692307692, "EFR": 0.9666666666666667, "Overall": 0.7269451121794871}, {"timecode": 65, "before_eval_results": {"predictions": ["Stephen Lee", "\"Arrested Development\"", "Albert", "September 30, 2017", "339,520", "the New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the 1946 Winecoff Hotel fire", "Silkeborg IF", "Stephen of Blois", "Scott Eastwood", "Gweilo", "Tufts College", "Prince Aimone of Savoy-Aosta", "1936", "The Wu-Tang Clan", "\"Hey Dad\"", "midtempo hip hop ballad with a pop refrain, sung by Rihanna", "melodic hard rock", "G\u00e9rard Depardieu", "rural", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse", "Kings Point, New York", "Robert Paul \"Robbie\" Gould III", "Paddy's Pub", "Baldwin", "Port Clinton", "November 20, 1942", "Wayne Conley", "the Australian coast", "Faith", "Marge agrees to stay with her old prom date, Artie Ziff, for one weekend (on the grounds that he try not to grope her like he did in \"The Way We Was\")", "the Cleveland Celtics", "Everybody Hates Chris", "CHO", "eight", "1867", "Some Syrup", "Jim Harrison", "James II", "General John Churchill, 1st Duke of Marlborough", "Lester Ben \"Benny\" Binion", "two Grammy awards", "The S7 series", "2017", "a lightning strike", "September 2000", "Thomas Jefferson", "Luxembourg", "Margaret Thatcher", "The Muffin Man", "President George Bush", "as", "former", "Yonkers", "blown", "folkloric", "Jamie Lee Curtis"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5801265035640035}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false], "QA-F1": [0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16216216216216217, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.923076923076923, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1941", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5584", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_triviaqa-validation-2994", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-30", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.484375, "CSR": 0.5525568181818181, "EFR": 0.9696969696969697, "Overall": 0.7273413825757575}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Sheffield Wednesday", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambidextrous", "Louis Daguerre", "Stephen Hawking", "Bunter [or Buntsandstein], Muschelkalk, and Keuper", "a living architect or architects whose built work demonstrates a combination of those qualities of talent, vision, and commitment,", "Guy", "a man holding up a lighted match", "Port Moresby", "LEDs", "Oscar II", "pyrotechnic", "South Korea", "Eurythmics", "a goose", "for the Olympics.", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "George Washington James Monroe", "Ellice Islands", "Meta", "the Oil Capital of Europe", "Scotland", "a double basses", "The Spice Girls", "Mr Loophole", "Istanbul", "drinking song", "Texas", "Pablo Picasso", "Yalta Conference", "Rajasthan", "African violet", "bali", "Glee", "Cardigan", "Haytham Kenway", "Djokovic", "1912", "fennec", "1927", "Prince Nikolai Sergeyevich Trubetzkoy", "Vernon Forrest,", "Linda Hogan,", "development of two courses on the Black Sea coast in Bulgaria.", "HENRIETTE Wyeth", "viruses", "Steve Wynn", "substitute good"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6484375}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-104", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391", "mrqa_searchqa-validation-16515"], "SR": 0.59375, "CSR": 0.5531716417910448, "EFR": 0.9230769230769231, "Overall": 0.7181403379735937}, {"timecode": 67, "before_eval_results": {"predictions": ["$50 less,", "Cambodia", "France", "tranquil beaches,", "took on water", "Werder Bremen", "Secretary of State", "Iran's President-elect Barack Obama", "nearly three out of four", "Fernando Caceres", "an Italian and six Africans dead.", "no evidence", "America's Cup", "Preah Vihear temple", "Uzbekistan.", "voluntary manslaughter", "Jenny Sanford", "Olivia, Sophia, Ava, Emily, Madison, Abigail, Chloe and Mia.", "Miami Beach, Florida,", "\"Percy Jackson & The Olympians,\"", "cell phones.", "two contestants.", "Scarlett Keeling", "the Southern Baptist Convention", "South Africa", "former U.S. secretary of state.", "\"an accomplished pilot\"", "54-year-old", "from Thursday and Friday to the end of her tour on June 17 and 18,", "helicopters and boats, as well as vessels from other agencies,", "terrorize is a crime,", "two tickets to Italy", "Oxbow,", "the FAA received no reports from pilots in the air of any sightings but the agency recieved \"n numerous\" calls from people on the ground from Dallas, Texas, south to Austin, Texas.", "21-year-old", "Jacob Zuma,", "Toffelmakaren", "former Procol Harum bandmate Gary Brooker", "a civil disturbance call,", "Pew Research Center", "can also taste a hamburger and pizza, and drink coffee from a cup, the \"things we take for granted every day,\"", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "Hold On", "Koine Greek : apokalypsis", "Phil Mickelson", "Dumbo", "skiffle quartet", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "julie taymor", "Perkins", "director", "to help batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6690995540787781}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.75, 0.22222222222222224, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.24390243902439027, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1935483870967742, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.59375, "CSR": 0.5537683823529411, "EFR": 0.9615384615384616, "Overall": 0.7259519937782806}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura this year.", "their homes in Bhola for the Muslim festival of Eid al-Adha.", "off Somalia's coast.", "in time as another American icon's wheels come off.", "AS Roma beat Lecce 3-2", "President Barack Obama,", "the Southern Baptist Convention", "in body bags on the roadway near the bus,", "Tuesday", "an American who entered the country illegally from China on Christmas Eve.", "2000", "at least 300", "Thursday,", "always hot and humid and it rains almost every day of the year.", "Hanin Zoabi,", "the same drama that pulls in the crowds", "2008", "root out terrorists within its borders.", "25", "\"a whole new treasure loot of fossils\"", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford", "a remote part of northwestern Montana", "genocide", "identity theft", "Bailey, Colorado,", "U.S. Justice Department", "Venus Williams", "two weeks", "Doogie Howser, M.D.", "British", "six", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "stand down.", "his past and his future", "Mombasa, Kenya,", "a loanword of the Visigothic word guma `` man", "Taron Egerton", "Vienna", "\"Book 1: Sowing\"", "purpurea", "Nellie Melba", "The King of Hollywood", "1979", "the backside", "Sweden", "a garcinia cambogia", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5624661796536796}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.8, 0.18181818181818182, 1.0, 0.3636363636363636, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.8333333333333334, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3635", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-4367", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.484375, "CSR": 0.5527626811594203, "EFR": 0.9393939393939394, "Overall": 0.721321949110672}, {"timecode": 69, "before_eval_results": {"predictions": ["lines the cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Australia's Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Kevin Sumlin", "Paradise, Nevada", "Detective Eddie Thawne", "Hathi Jr", "an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "Spektor", "The Star Spangled Banner", "Bill Russell", "a judge who lacks compassion is repeatedly approached by a poor widow, seeking justice", "by October 1986", "an address bar", "solids", "1997", "Carol Worthington", "September 6, 2019", "1972", "1853", "uprooted", "terminal velocities much lower than their muzzle velocity when they leave the barrel of a firearm", "Battle of Antietam", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Andrew Garfield", "under normal conditions", "the 1980s", "Pasek & Paul", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "White House Executive Chef", "place of trade", "25 years after the release of their first record", "the bank", "One Night in the Tropics", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation", "eucalyptus", "inflation", "Christies Foxhunters", "John M. Dowd", "December 17, 1974", "Northrop F-15 Reporter", "26", "The woman", "as soon as 2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6947791729135433}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true], "QA-F1": [0.9523809523809523, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.8, 0.3333333333333333, 1.0, 0.7586206896551725, 1.0, 0.0, 0.5714285714285715, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.17391304347826084, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.09523809523809525, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_hotpotqa-validation-993"], "SR": 0.578125, "CSR": 0.553125, "EFR": 0.8518518518518519, "Overall": 0.7038859953703703}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a specific task", "January 2, 1971", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie )", "St. Louis Cardinals", "Bonhomme Carnaval", "1792", "Longliners", "Sebastian Vettel", "Niles", "China", "2017", "Upstate New York", "Carol Ann Susi", "a bar", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "Friedman Billings Ramsey", "the NFL", "17.44667", "1 January 1904", "a password recovery tool for Microsoft Windows", "a minimum number of hours defined as such by his / her employer", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer", "The UN General Assembly", "benzodiazepines", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "May 31, 2012", "Thomas Dekker and John De Vito", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "Beorn", "South Dakota", "Donald Trump", "around 100,000", "1967", "Rajasthan", "Sodor", "the eye", "44,300", "2008", "Anglo-Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "LEWIS CARROLL", "Thailand", "500-room"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6238372806387512}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523, 0.35294117647058826, 0.058823529411764705, 0.11764705882352942, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333333, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.578125, "CSR": 0.5534771126760563, "EFR": 0.8148148148148148, "Overall": 0.6965490104981742}, {"timecode": 71, "before_eval_results": {"predictions": ["English Poet Alexander Pope", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Striding Edge", "photographer", "clown", "the Titanic", "Capua", "Hadrian", "Madagascar", "Barbizon school", "Renzo Piano", "Manet", "Gary Sparrow", "shuttle Columbia", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "'Hansel and Gretel' cottage", "japonesa", "Greenock", "ABBA", "Sonja Henie", "six", "Lord Snooty", "Greyfriars Bobby, Skye terrier", "Rudolf Hess", "koninklijke Vlaamse Academie van Belgi\u00eb voor Wetenschappen en Kunsten", "Stieg Larsson", "music Stories", "1957", "a giant menhir", "buildings", "Rotherham United", "Joseph Priestley", "a German greyhound, gazelle hound or tazi", "Davis Cup by BNP Paribas is the World Cup of Tennis.", "matrix", "camar\u00f5es", "region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Cuba", "assoluta sententia expositore non indiget", "Patience", "Chubby Checker", "Tim Roth", "establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three", "San Francisco", "after 5 years, it was earning $300,000,000 a year", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "monthly", "one of Europe's most experienced providers of carbon offsets, where each project is rigorously audited and monitored for quality.", "hiring veterans as well as job training for all service members leaving the military.", "40 lash after he was convicted of drinking alcohol in Sudan where he plays for first division side Al-Merreikh of Omdurman.", "the American Civil War", "by price/earnings ratios and the rate of inflation", "a peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5805782812136713}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3529411764705882, 0.08695652173913042, 0.8, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-127", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-5241", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5039", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-6399", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-990", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-8965", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196"], "SR": 0.515625, "CSR": 0.5529513888888888, "EFR": 0.9354838709677419, "Overall": 0.7205776769713262}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby Darin", "the Thames", "Altamont Speedway", "The Jetsons", "26.22", "ankle joint", "ocellaris", "Samson", "Connecticut", "Daedalus", "a critically burned English accented Hungarian man,", "Pandemonium", "a goad", "Peter Parker", "14", "radars", "Queen Elizabeth II", "Tonto", "hippocampus", "gunga Din", "tennis", "Orwell", "Atlantic Ocean", "New Zealand History", "Chatsworth House", "dirk bikembergs", "Budapest", "on the meibomian gland", "snowman Speights", "augusta", "aug. 24", "humped cattle", "Augustus", "Venezuela", "low-cost carrier", "SUNSET BOULEVARD", "Johnny Colla", "Derwent", "tahini", "Laos", "Allardyce", "General Henri-Philippe Petain", "Ryan O\u2019 Neal", "Miami", "Bill Haley & His comets", "augusta", "1768", "Joan Rivers", "Ethiopia", "William Refrigerator Perry", "Ghana", "as an extension to this procedure", "observing the magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "the U.S. Holocaust Memorial Museum", "Robert Barnett,", "Diego Milito", "dont wanna leave", "Dumbo the Flying elephant", "Casey at the Bat", "pythons"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5063501602564102}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-1380", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5164", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-8205", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.40625, "CSR": 0.5509417808219178, "EFR": 0.9210526315789473, "Overall": 0.717289507480173}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "Mercer Bears", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Washington", "Helen Mirren", "horse breeder", "Schutzstaffel", "Edward Albert Heimberger", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis", "sitters", "Premier League", "Sleepy Hollow", "American investigative journalist Jane Mayer", "Obafemi Martins", "Austin E. Knowlton School of Architecture", "143,007", "Philadelphia", "33-member", "American television personality and film actress", "1957", "mathematician, physicist, and spectroscopist", "King Duncan", "St Andrews Agreement", "Royal College of Music", "4145 ft above mean sea level", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "main east-west road", "schoolteacher", "People v. Turner", "William Harold \"Bill\" Ponsford", "Aamina Sheikh", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng", "Herman Hollerith", "6 -- 14 July", "parashiyot", "paramitas", "1881", "journalism", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Pixar's \"Toy Story\"", "Christianity and Judaism", "blintz", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6820340537137413}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.5, 0.0625, 0.6, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8918918918918919, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-3845", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5795", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-1002", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621"], "SR": 0.5625, "CSR": 0.551097972972973, "EFR": 0.9285714285714286, "Overall": 0.7188245053088803}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ribonucleic acid (RNA)", "ketchup", "a igloo", "a house fly", "timbaland", "The New York Times", "republic", "Latvia", "the spleen", "auf wiedersehen", "rely", "Ramesses II", "wine", "the esophagus", "Dallas Cowboys", "the King Jesus Gospel", "the twist", "Marie Tussaud", "Biscay", "Ziz", "March", "Ferdinand Magellan", "Kevin Spacey", "children of prostitutes", "a sphere", "The Aviator", "Gioachino Rossini", "Veracruz", "a tail", "nashborough", "Hanging Gardens of Babylon", "the Starfighter", "Billy Crystal", "wrinkles", "LaSalie", "kbec", "pontificio", "city", "Onagraceae", "tribunedigital", "Corpus Christi", "Odysseus", "Ruth Bader Ginsburg", "Edward R. Murrow", "Bengal", "In vitro fertilisation", "Diogenes of Sinope", "pastries", "Whatchamacallit", "the Electric Company", "the following day", "Roger Dean Stadium", "March 31, 2013", "Helen Reddy", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "giving birth to baby daughter Jada,", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6107772435897435}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, false, true, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.5, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-7401", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-14769", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9143", "mrqa_searchqa-validation-9557", "mrqa_newsqa-validation-801"], "SR": 0.515625, "CSR": 0.5506249999999999, "EFR": 1.0, "Overall": 0.733015625}, {"timecode": 75, "before_eval_results": {"predictions": ["eleven", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "2009", "1963", "The Satavahanas", "the Central Board of Artisans", "it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK", "28 July 1914", "St. Pauli Girl Special Dark", "908 mbar", "North Atlantic Ocean", "February 7, 2018", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "on the fictional Iron River Ranch, Colorado", "Valens and Richardson", "American singer - songwriter - actress Debbie Gibson", "Atticus Finch's", "31 January 1934", "Austin", "the southeastern United States", "gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "synthesizing vitamin B and vitamin K as well as metabolizing bile acids", "Kyla Coleman", "Bill Patriots", "September 1972", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish / Basque", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Mae Jones", "Motorola", "Neil Young", "a marked ( `` - s '' ) or unmarked plural", "Chuck Noland", "forested parts", "arithmetic", "Finger Tab", "red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie meals", "0-0 draw", "the Romanov Dynasty", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6701927152439924}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6842105263157894, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9428571428571428, 1.0, 1.0, 0.6, 0.5714285714285715, 0.28571428571428575, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 0.11764705882352942, 0.0, 0.5, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.888888888888889, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_searchqa-validation-12989", "mrqa_newsqa-validation-1646"], "SR": 0.5, "CSR": 0.5499588815789473, "EFR": 0.9375, "Overall": 0.7203824013157896}, {"timecode": 76, "before_eval_results": {"predictions": ["$689.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "Total Drama Action", "Christopher Lloyd", "senators", "rape", "the fictional town of West Egg on prosperous Long Island", "sovereignty", "Authority", "Archie Andrews", "American rock band Los Lonely Boys", "ecosystems", "cakes", "Kiss", "England", "Julie Adams", "during World War II", "Anthony Quinn as Craig Belden", "January 2004", "The Vamps", "Hank J. Deutschendorf II", "Derrick Henry", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins", "southern Turkey, dividing the Mediterranean coastal region of southern Turkey from the central Anatolian Plateau", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Chasty Ballesteros", "an anembryonic gestation", "It acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "a Nativity scene", "IV", "Virginia", "Saphira hatches from the stone, which was really an egg", "September 2017", "a feminine form of the Hebrew Yohannan, `` God forgave / God gratified ''", "Ace", "Spike", "regulatory site", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "InterContinental Hotels Group", "peninsula", "Jason Flemyng", "peninsula", "Norman Mailer", "vickers Vimy", "pye", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million.", "San Diego,", "CNN.com", "a jazz funeral", "echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7332705294218451}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.21052631578947367, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.7999999999999999, 0.962962962962963, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.72, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.4444444444444445, 0.6153846153846153, 1.0, 1.0, 1.0, 0.07407407407407408, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170"], "SR": 0.640625, "CSR": 0.5511363636363636, "EFR": 0.6956521739130435, "Overall": 0.6722483325098814}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Giuliano Bugiardini", "aluminum", "pulsar", "Seth", "Honda", "\"Erroneous\" Number One", "Adolf Hitler", "sonnets", "2010 FIFA World Cup", "Elizabeth I", "June", "Italy", "1960s", "Mel Brooks", "Belgium", "chlorophyll", "Paul Dukas", "San Marino", "Uranus", "rum", "apple", "Aberlemno", "Roddy Doyle", "discus thrower", "Separate Tables", "telephone call over telegraph wires between two towns in Ontario, Canada", "Beatrix Potter", "Magpie", "comets", "bobsleigh", "Kansas City", "Fidel Castro", "David Bowie 7\"", "Scotland", "red Admiral", "Illinois", "red", "Splash", "South Africa", "menorah", "A Beautiful Mind", "gollum", "otters", "mandar", "John Mortimer", "Kellogg\u2019s Special K", "line code", "native to Asia", "Liam Cunningham", "Brobee", "Madrid", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "E22", "security breach", "at checkposts and military camps in the Mohmand agency, part of the lawless Federally Administered Tribal Areas", "Mashhad, Iran.", "St Bernard", "France", "Barnard College", "the equator,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6078125}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-4389", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-6105", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-7621", "mrqa_triviaqa-validation-7254", "mrqa_triviaqa-validation-5040", "mrqa_triviaqa-validation-3681", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-6843", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.53125, "CSR": 0.5508814102564102, "EFR": 0.9, "Overall": 0.713066907051282}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Daniel Fran\u00e7ois Esprit Auber", "month", "Al Pacino", "vVD Savarkar", "by increasing the number of arcs", "Mr. Golding", "a nerve cell cluster", "vitamin B3", "director of the Security Service", "a 965-foot ocean liner", "Funchal", "bachelor", "spaghetti harvest", "Northern Ireland", "passport", "Marcel Duchamp", "quatermass experiment", "Mumbai", "phrasmide or Iphinoe", "1875", "raven", "hound", "sue", "Estimate", "$x^2", "Narendra Modi", "Richard Wagner", "quentin tarantino", "Argentina", "hard", "Kitzb\u00fchel", "Tunisia", "Crystal Gayle", "steppes steppe", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "casino square", "endora", "springtime for Hitler", "the Holy Land", "Eva Herzigov\u00e1", "David Hockney", "Ireland", "gambit", "Carrie", "Colombia", "the Emerald Isle", "the anterolateral system", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "Tudor music and English folk-song", "Martin Joseph O'Malley", "1992", "sculptures", "Sunday's strike", "Kenyan forces", "the Old Man and the Sea", "Edward I", "VH1", "there were no radar outages and said it had not lost contact with any planes during the computer glitches."], "metric_results": {"EM": 0.515625, "QA-F1": 0.608110119047619}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, false, false, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5620", "mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_hotpotqa-validation-4500", "mrqa_newsqa-validation-2485", "mrqa_newsqa-validation-2233", "mrqa_searchqa-validation-7161", "mrqa_searchqa-validation-6534", "mrqa_newsqa-validation-904"], "SR": 0.515625, "CSR": 0.5504351265822784, "EFR": 0.8387096774193549, "Overall": 0.7007195858003266}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "French", "HMS amethyst", "Libya", "tomato", "Kyoto", "costume", "Bull Moose Party", "headpan", "Jake La Motta", "resistance", "hanie McDaniel", "South Africa", "indigestion", "discretion", "xi", "baroness brady", "George Washington", "Corinth Canal", "human rights lawyer", "Iceland", "ascot", "peaches", "kris Jenner", "gangsters", "bitches", "Duncan", "UKIP", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "boston", "Julian WikiLeaks", "The IT Crowd", "ilie nastase", "local police officer Rip Nix", "german", "Richard Curtis", "terms of endearment", "China", "lagertha", "1790", "argyle", "chamomile", "driving Miss Daisy", "orchid", "Hilary Swank", "abdeen", "latitude 90 \u00b0 North", "18th century", "nine hours from Coordinated Universal Time ( UTC \u2212 09 : 00 )", "just 18 minutes", "England", "Sri Lanka Freedom Party", "\"Steamboat Bill, Jr.\"", "hostile war zones,", "Rodong Sinmun", "theology", "Cyd Charisse", "sanctions", "February"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6567410714285714}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16, 0.5714285714285715, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-2433", "mrqa_triviaqa-validation-374", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-889", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-3226", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_newsqa-validation-3862", "mrqa_searchqa-validation-2116"], "SR": 0.578125, "CSR": 0.55078125, "EFR": 0.8148148148148148, "Overall": 0.6960098379629629}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Charles Habib Malik", "senators", "2 total", "in the dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Alisabeth R\u00f6hm as Anne Phillips", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "the Hudson Bay", "H CO ( equivalently OC (OH ) )", "Miami Heat", "March 29, 2018", "four of the 50 states of the United States in their full official state names : Kentucky ( the law creating Kentucky names it the `` State of Kentucky '' but it was originally part of the land grant of the Colony of Virginia )", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas", "set to 0.05 ( 5 % )", "Tom Burlinson, Red Symons and Dannii Minogue", "A thin film is a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "Tulsa, Oklahoma", "Kristy Swanson", "Joanna Moskawa", "Santa Clara Pueblo", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation from the Great Plains whose historic territory, known as Comancheria", "United Nations", "as of October 1, 2015, when the green class A was retired", "2026", "318", "the Director of National Intelligence", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "The fourteenth season of the American television medical drama Grey's Anatomy was ordered on February 10, 2017, by American Broadcasting Company ( ABC ), and premiered on September 28, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "Lagaan", "1996", "American rock band Los Lonely Boys", "appearances", "the foreign exchange market ( FX )", "The Hustons", "Sunday Post", "Karl Pilkington", "pei Tang", "1860", "\"Back to December\"", "Buck Owens", "\"Up\"", "\"Empire of the Sun,\"", "off the coast of Somalia", "modify", "olly ringwald", "faerie", "skull and crossbones"], "metric_results": {"EM": 0.625, "QA-F1": 0.7472191737512579}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.05714285714285715, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 0.9032258064516129, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.20689655172413793, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-10102", "mrqa_naturalquestions-validation-1373", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-7286", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.625, "CSR": 0.5516975308641976, "EFR": 0.9166666666666666, "Overall": 0.7165634645061729}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "a container", "Berenice II", "nuclear warheads", "capitals", "pep", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "fauvism", "Auguste Deter", "Calabasas", "Jenny", "gestation", "ravens", "J.R. Tolkien", "Dale", "Blue Ridge Mountain Range", "Georgia", "a microstructure of iron-based alloys", "buddha", "Apple", "Thomas R. Gray", "a catfish", "A Chorus Line", "piazza del Campo", "Robbie Turner", "regret not speaking", "de Havilland", "Virginia", "College of William", "a dog recently recognized by AKC.", "Louisiana", "Vassar", "Japan", "tableware", "The Police", "Air France", "Scarlatti", "Heracles", "trudge", "Violent Femmes", "Albert Camus", "Volvo", "Rhode Island", "yodeling", "Indian Ocean", "a hypodermic needle", "Marat", "a nanosecond", "bats", "Mason Alan Dinehart", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "a forest", "2010", "cymbal", "Madagascar", "Thomas William Hiddleston", "Estadio Victoria", "Allerdale", "Mugabe's opponents", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5969122023809523}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-6250", "mrqa_naturalquestions-validation-2110", "mrqa_naturalquestions-validation-5526", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-868"], "SR": 0.515625, "CSR": 0.5512576219512195, "EFR": 0.9032258064516129, "Overall": 0.7137873106805666}, {"timecode": 82, "before_eval_results": {"predictions": ["the submarine", "Cherokee", "Vatican City", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Parthenon", "(Jack) Canfield", "Marilyn Monroe", "souvlaki", "Richard III", "the bald eagle", "the Louvre", "155", "the Galapagos", "Frans Hals", "the Black Sox Scandal", "small", "Grenadine", "Constantine", "the Aleutian Islands", "alchemy", "art nouveau", "Autobahn", "Anglo-Saxon", "the California quail", "curtsy", "lacrosse", "Toronto", "hard", "King David", "Riboflavin", "tassels", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "The hobbit", "the Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "point plat de Bruxelles", "(Lee) Marvin", "Prince Edward Island", "Westminster Abbey", "Superbad", "the Granite State", "1885", "$2.187 billion", "Isle Vierge ( 48 \u00b0 38 \u2032 23 '' N 4 \u00b0 34 \u2032 13 '' W \ufeff /\ufeff 48.63972 \u00b0 N 4.57028 \u00b0 W", "london", "acai", "abbot of Monte Cassino", "Pansexuality", "linguistic analysis", "getaway driver", "Drew Kesse,", "the pregnancy.", "eight-week", "1999"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7060416666666667}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.5866666666666668, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3634", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.609375, "CSR": 0.5519578313253012, "EFR": 0.92, "Overall": 0.7172821912650603}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "a vulture", "Nantucket", "Ebony", "Trinity College", "Algeria", "Joseph Haydn", "Dick Cheney", "the black market", "a number", "Saturday Night Fever", "(AFGHANISTAN)", "pizza al taglio", "a turtle", "the Empire State Building", "white", "a picayune", "dogwood", "Quebec", "Larry McMurtry", "Kellogg's", "Helen of Troy", "sweats sweats sweatshirt", "W=Fd", "Napoleon", "ivory", "the Arctic area of Spmi", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "Ba", "Pancho Gonzales", "the Aleutians", "the Mormon Trail", "Jane Grey", "Tommy Tutone", "the crescent", "the Hijaz", "an apple", "Nicolaus Copernicus", "poblano chiles", "William Safire", "Leonardo da Vinci", "London", "Charlton Heston", "Andrea Brooks", "the uterus", "Some Like It Hot", "Barbara Eden", "Casablanca", "T. R. M. Howard", "Parlophone", "9:20 p.m. ET Wednesday.", "Daryeel Bulasho Guud (DBG)", "1995", "four"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7109375}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-5531", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1070", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-7457", "mrqa_triviaqa-validation-2579", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-537"], "SR": 0.59375, "CSR": 0.5524553571428572, "EFR": 1.0, "Overall": 0.7333816964285715}, {"timecode": 84, "before_eval_results": {"predictions": ["Russia", "Catherine of Aragon", "a Redbud Tree", "Windsor, Ontario", "Stephen Douglas", "comrade", "the Great Gatsby", "a fox", "Sexuality", "Salaries", "Solomon", "Federer", "a bicycle", "Johnson County", "Jericho", "push", "Alexander Solzhenitsyn", "tomfoolery", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "Daughters of the American Revolution", "the Philippines", "St Mark", "Eragon", "The Beatles", "Louisiana", "Mexico", "\"Jolly Roger\"", "engrave", "Daisy Miller", "the French Legion of Honour", "X", "a ship", "Kamehameha", "a wolf", "Virginia", "Jerry Maguire", "the north magnetic pole.", "oyster", "an Italian-American", "Candlestick Park", "Zimbabwe", "a bowstring", "Patty Duke", "Pronouns", "Hoffmann", "a calico cat", "Frankie Muniz", "in season two", "A complex sentence", "40", "Neptune", "Nowhere Boy", "August", "boar", "Richa Sharma", "Haiti", "financial gain,", "in a Nazi concentration camp,", "Golfer Tiger Woods"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7360119047619047}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-5876", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-14335", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-10841", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_searchqa-validation-9898", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-9404", "mrqa_hotpotqa-validation-5599", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.65625, "CSR": 0.5536764705882353, "EFR": 0.9545454545454546, "Overall": 0.724535010026738}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "Ayn Rand", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Ezra Cornell", "strawberry Fields", "The Hague", "Geena Davis", "pharmacy", "(Bobby)", "the NHL", "Doolittle", "air", "William Shakespeare", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "the money changers", "The X-Files", "Animals", "the \"M-E\"s", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "a Booster seat", "the Church of Jesus Christ of Latter-day Saints", "Italy", "a watermelon", "the North Atlantic Treaty Organization", "Sparta", "the Sunday New York Times", "anode", "saved the original Star Trek", "the National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "hair", "the Texas Rangers", "fluoxetine", "the chemical formula H CO ( equivalently OC (OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine.", "has to move out of her rental house because it is facing foreclosure", "Why he's more American than a German,", "Santiago Ram\u00f3n y Cajal"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5921875}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8333333333333333, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-6063", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-15693", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-610", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_naturalquestions-validation-9220", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692", "mrqa_naturalquestions-validation-4103"], "SR": 0.546875, "CSR": 0.5535973837209303, "EFR": 0.8275862068965517, "Overall": 0.6991273431234963}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy Feet", "a short distance", "the Himalayas", "Joseph", "Chicago", "Aeneas", "Cannery Row", "Palatine", "California", "the Mississippi", "Alpha", "Quebec City", "nacreous", "Texas Chainsaw Massacre", "the rotunda", "a Medal of Honor", "Manet", "Plutarch", "Mediolanum", "Corin", "Shropshire", "a human", "Afghanistan", "satin", "Lady Godiva", "the Sadler", "Vasco da Gama", "Millard", "coarse", "Finnegans Wake", "aleikum", "the black market", "professor of higher education", "S-waves", "Maastricht", "Delilah", "synapses", "croissant", "Rocky Down Mexico Way", "lungs", "fuchsia", "metacarpal", "a pool", "Warsaw", "a trowel", "Mercury", "Taiwan", "Gettysburg", "the Kings", "trout", "\"I'd Like to Get You on a) Slow Boat to China\"", "1959", "season two", "$75,000", "zambia", "15", "stonemason's Yard", "Agent Carter", "Orson Welles", "Manhattan", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5924242424242424}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-4065", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8200", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.53125, "CSR": 0.5533405172413793, "EFR": 0.9, "Overall": 0.7135587284482758}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770 guaranies", "Geoffrey Zakarian", "4.5 pounds or 2.04 kg", "Mary Elizabeth ( Margaret Hoard )", "Scott Schwartz", "Paris", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Francis Ford Coppola", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "secession", "The Osmonds", "political pamphlet", "Australia", "Anakin Skywalker", "Alexander Salkind", "one", "Mary Elizabeth Ellis", "Jesse Triplett", "Kevin Garnett", "a star", "Brazil", "Selena Gomez", "Washington", "the 2nd century", "Triple threat", "in his first year at the Hogwarts School of Witchcraft and Wizardry", "shared", "foreign investors", "Napoleon", "marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "User State Migration Tool ( USMT )", "Robber baron", "December 20, 1951", "Crick", "Aconcagua", "bake Off", "1924", "Noah Levenstein", "zona glomerulosa of the adrenal cortex", "Nicole Kidman", "last summer.", "social issues like homelessness and AIDS.", "longest female cyclist of her generation", "banker", "eyelid", "the Cubs", "thief"], "metric_results": {"EM": 0.5, "QA-F1": 0.6099306314683424}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, true, false, true, false, false, true, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.782608695652174, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7741935483870968, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.05714285714285715, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-1656", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-5638", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-397", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.5, "CSR": 0.552734375, "EFR": 0.9375, "Overall": 0.7209375}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "A 22-year-old college student in Boston, Massachusetts,", "a bag", "Federer", "from Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "\"Mammograms are known to be uncomfortable,\"", "\"The group, Lashkar-e-Jhangvi, was planning to conduct attacks in Karachi,", "Salt Lake City, Utah,", "normal maritime", "Saluhallen, the covered market on Lilla Torg", "to protect ocean ecology, address climate change and promote sustainable ocean economies.", "Rocky Ford brand cantaloupes", "\"The oceans are kind of the last frontier for use and development,\"", "arrested three men with suicide vests who were plotting to carry out the attacks,", "\"We want to reset our relationship and so we will do it together.'\"", "club managers,", "Long Island", "90", "the FBI.", "Reggae legend Lucky Dube,", "Kurdish militant group in Turkey", "At least 14", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin Fritzl,", "the Defense of Marriage Act", "Europe,", "\"I believe it's discriminatory. I think it interferes with state's rights, and we will work with Congress to overturn it,\"", "immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guant Bay, Cuba.", "Greeley, Colorado,", "Festival Foods", "\"It all started when the military arrested one man, and then an hour later he emerged from building barely able to walk from the beating,\"", "drugs", "Daniel Radcliffe", "1.2 million", "\"I wanted to push it up that black a--.\"", "12.3 million", "Krishna Rajaram,", "North Korea", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Hamas ministry spokesman Taher Nunu", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "this administration recognizes the importance of Turkey and wants to engage with it from the start.", "the Yemeni port city of Aden", "federal officers", "\"Up\"", "the Chao Phraya River and its many canals.", "journalists and the flight crew", "a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "The Hague Conventions", "Robert Downey, Jr.", "Viscount Cranborne", "England and Ireland", "beef", "Sleyman", "the rainforest", "Ramadan"], "metric_results": {"EM": 0.5, "QA-F1": 0.6386920957922796}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.30769230769230765, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.9411764705882353, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.13333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.8, 1.0, 0.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763"], "SR": 0.5, "CSR": 0.5521418539325842, "EFR": 0.84375, "Overall": 0.7020689957865167}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron", "Kim So-hyun", "president of Guggenheim Partners", "Comedy Film Nerds", "9\u201310 March 1945,", "2011", "John D Rockefeller's", "the early 1970s", "Asiana Town building", "American R&B singer, guitarist, songwriter and music producer", "Rockland County", "Manitowoc County, Wisconsin", "34.9 kilometres", "1967", "alcoholic drinks for consumption on the premises.", "Fiat Group", "Chrysler", "South Australia", "gorillas", "\"Traumnovelle\" (\"Dream Story\")", "The Royal Navy", "National Archives and Records Administration (NARA)", "Yitzhak Edward Asner (born November 15, 1929)", "the Beatles", "Baden-W\u00fcrttemberg", "2001 NBA All-Star Game", "rated R", "95 AD", "1614", "French", "\"The Manhunter from Mars\" in \" Detective Comics\" #225 (Nov. 1955)", "Mondays", "Daniel Richard \" Danny\" Green, Jr.", "Snowball II is killed off,", "HSBC Main Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "The Home Rule League", "Anne Fletcher", "1822", "Mulberry (film)", "Suspiria", "BBC Focus", "Kansas\u2013Nebraska Act", "Scandinavian design", "Buck Owens", "Big Machine Records", "postal delivery", "Flaw", "June 5, 2017", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "forearm", "Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "Piers Morgan Tonight", "misdemeanor assault charges after a fight at his Texas high school", "Florida", "The Partridge Family", "Mickey Spillane", "for housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6513854201354201}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.1818181818181818, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5567", "mrqa_hotpotqa-validation-569", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-3198", "mrqa_hotpotqa-validation-3832", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3253", "mrqa_newsqa-validation-3369"], "SR": 0.578125, "CSR": 0.5524305555555555, "EFR": 0.9259259259259259, "Overall": 0.7185619212962964}, {"timecode": 90, "before_eval_results": {"predictions": ["Kim Carnes", "Ardeth Bay", "2009", "actress and singer", "Pakistan", "1754", "\"Confessions of a Teenage Drama Queen\"", "Bundesliga club VfL Wolfsburg", "valkyries", "David Villa", "Adrian Peter McLaren", "from 2007 to 2010", "an early colonist of South Australia, remembered as a schoolmaster at J. L. Young's Adelaide Educational Institution and at Saint Peter's College", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Diamond White", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "London Heathrow", "Riot Act", "The Gold Coast", "January 30, 1930", "22 September 2015", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Goitsebeng Maphiri Khama, GCB, KBE", "Scandinavian design", "Mike Pence", "Barack Obama's Cabinet", "Flexible-fuel vehicle", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian", "138,535", "Ry\u016bky\u016b", "1935", "Stern-Plaza", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravitation", "improve communication", "South Africa", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "trimaran", "Robert", "Mattel doll", "the Agony", "CO2", "Shout"], "metric_results": {"EM": 0.578125, "QA-F1": 0.652688544094794}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.787878787878788, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2564102564102564, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4945", "mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-6075", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-1446", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743"], "SR": 0.578125, "CSR": 0.5527129120879121, "EFR": 0.7777777777777778, "Overall": 0.6889887629731379}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "Apple", "the Big Cat", "Tony's", "Friday", "Sabino Canyon", "Orlando Bloom", "Babe Ruth", "housewives", "Arkansas", "Alberto Gonzales", "Virgo", "Contemporary", "Steppenwolf", "bcolicus", "Tito Puente", "Hydrogen", "Ben Jonson", "Hodgkin's lymphoma", "Margaret", "Las Vegas", "San Francisco", "Norman Mailer", "Mary Baker Eddy", "Bank One", "the College of William & Mary", "The Wright Brothers", "Badminton", "John Deere", "43", "Chrysler", "Reptiles", "Georgia", "Key lime pie", "Lettuce", "Haroun", "bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "Assyria", "Jean-Paul Marat", "Cetshwayo", "Bay of Montevideo", "the bank, rather than the purchaser, is responsible for paying the amount", "a jingle", "Bobby Brown", "Bath", "1.5 million households", "Macomb County", "Kristoffer Rygg", "Texas A&M Offshore Sailing Team", "Monday night.", "eight", "minister and biographer"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6651041666666666}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_hotpotqa-validation-4539"], "SR": 0.578125, "CSR": 0.5529891304347826, "EFR": 0.9259259259259259, "Overall": 0.7186736362721418}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico Virginia", "the East", "William Shakespeare", "William Shakespeare", "abscesses", "Colorado", "Sputnik I", "Richmond", "the period of program music", "Java", "the baritone", "Blanche DuBois", "the flag", "Room-temperature vulcanization", "Linton", "Muhammad", "September 20, 1934", "the Curse of the Black Pearl", "Charles de Gaulle", "Chesterfield", "a chipmunk", "Rose", "salt", "a Spousal privilege", "Rossini", "Oman", "Lapland", "Tom Canty", "Roman Polanski", "Joan Didion", "the frigate", "Baltimore", "the Bay of Bengal", "Button Gwinnett", "Clinton", "Terrific", "time", "six sides", "Olympia", "the Ship of Fools", "Haunted Nights", "tendang", "fluid", "Margaret Mitchell", "Frances", "Vin Diesel", "cremation", "the French & Indian War", "manic", "the Hudson Bay", "lighter fluid", "a scuffle with the Beast Folk", "Judi Dench", "Germany", "Tan-y-Bwlch Station", "Dar es Salaam", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5538194444444444}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-10078", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-12499", "mrqa_searchqa-validation-4155", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-14332", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-2418", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6867", "mrqa_hotpotqa-validation-3557"], "SR": 0.484375, "CSR": 0.5522513440860215, "EFR": 0.8484848484848485, "Overall": 0.7030378635141741}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Lulu", "Telma Hopkins", "Mel Gibson", "2017", "drivers who were 2016 Pole Award winners, former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "1971", "Highway 68 ( Holman Highway / Sunset Drive ) and 17 - Mile Drive marks the entrance to Pebble Beach", "while in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form, he made the hair more `` wild '' and covered Goku's body in red fur", "Audrey II", "January 2017 patch", "NIRA", "1922", "Jacqueline Bouvier", "Justin Timberlake", "American production duo The Chainsmokers", "13 May 1787", "Prince James, Duke of York and of Albany ( later King James II & VII )", "Paul Monti, whose son, Medal of Honor recipient Jared, was killed in Afghanistan while trying to save a fellow soldier", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3 of the United States Constitution", "McFerrin", "Napoleon", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018 at Orleans Arena, on the Las Vegas Strip in Paradise, Nevada, United States", "Tbilisi, Capital of Georgia", "Tiffany Adams Coyne", "ice giants", "hyperinflation", "1939", "Richard Masur", "Al Foster", "Tagalog or English", "Sauron", "Lana Del Rey", "position", "159", "Third Five - year Plan", "The chant was first adopted by the university's science club in 1886", "Maria has just arrived from Puerto Rico for her arranged marriage to Chino, a friend of Bernardo's", "activates a relay which will handle the higher current load", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood's A Holy Grail", "nide", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "Da Vinci Code", "humiliate herself by standing next to a story,\"", "Khrushchev", "Julie Andrews", "Ichabod Crane", "Leo Frank,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.61805947172795}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.9259259259259259, 0.0, 0.08333333333333334, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428572, 0.0, 0.7499999999999999, 1.0, 1.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.08695652173913043, 0.0, 0.4615384615384615, 1.0, 0.2, 0.0909090909090909, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-857", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-9499", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-8026", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374", "mrqa_searchqa-validation-105"], "SR": 0.515625, "CSR": 0.5518617021276595, "EFR": 0.7419354838709677, "Overall": 0.6816500621997255}, {"timecode": 94, "before_eval_results": {"predictions": ["the theory of direct scattering and inverse scattering", "Thon MarialMaker", "Battle of Chester", "youngest TV director ever", "19 February 1927", "on the shore, associated with \"the Waters of Death\" that Gilgamesh had to cross to reach Utnapishtim, the far-away.", "playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado.", "Revengers Tragedy", "Japan", "rural", "8", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "CMYKOG process", "Las Vegas Boulevard", "The Design Inference", "Anthony Herrera", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevy Corvette Stingrays", "Field of Dreams", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music.", "The Wachowskis", "the \"Pour le M\u00e9rite\"", "mastered recordings for many well known musicians, including David Bowie, The Subways, Foo Fighters, Lou Reed, Paul McCartney, Sin\u00e9ad O'Connor, Natalie Merchant, Marianne Faithfull, and Madonna.", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "the Food and Agriculture Organization", "dance partner", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "Holinshed's Chronicles", "2018 Maryland gubernatorial election will take place on November 6, 2018, to elect the Governor of Maryland.", "Commonwealth Universities", "1 April 1985", "Australia", "Bonkyll Castle", "February 5, 2015", "Zeffirelli", "giant planet", "alveolar", "Duisburg", "Hugh Quarshie", "king George V", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "Fareed Zakaria", "Easter Island", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.625, "QA-F1": 0.7584629977722083}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.0, 0.3157894736842105, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.47619047619047616, 1.0, 1.0, 0.14814814814814814, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3157894736842105, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-3258", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-1297", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-3989", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056"], "SR": 0.625, "CSR": 0.5526315789473684, "EFR": 0.7916666666666666, "Overall": 0.691750274122807}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies worldwide", "Ben Ainslie", "1978", "The Golden Egg", "Scott Mosier", "1950", "Roy Warren Spencer", "1964", "U.S. Route 71", "VH1", "March", "Russian", "Jack Ryan", "July 25 to August 4", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer, songwriter, actress, and radio and television presenter", "Northern Lights", "non-alcoholic recipe", "Mach number", "Sami Brady", "Maine", "Encore Las Vegas", "Baa, Black sheep", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "President John F. Kennedy", "paracyclist", "Mandarin", "Kevin Spacey", "a pro-vice-chancellor at some institutions in the United Kingdom and Ireland, or a Deputy Vice-Chancellor (Academic) at most Australian universities", "Song Il-gon", "Teen Titans Go!", "Mickey Mouse cup", "five-time winner", "right-hand", "Sheen Michaels Entertainment", "Sela", "whale lice", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers women's basketball", "Metro-Goldwyn-Mayer", "P.O.S,", "My Backyard", "Sun Woong", "American professional boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "March 1st.", "The Da Vinci Code", "Dog patch Labs", "iceberg", "a fuel cell", "Queen Victoria", "Venus Williams"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6837053571428572}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.5, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.8571428571428571, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-5568", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-1151", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-191", "mrqa_searchqa-validation-14503"], "SR": 0.59375, "CSR": 0.5530598958333333, "EFR": 0.8846153846153846, "Overall": 0.7104256810897436}, {"timecode": 96, "before_eval_results": {"predictions": ["an obsessed and tormented king", "1927", "16,116", "the 2012 Summer Olympics", "at the end of the 18th century", "1942", "Johnny Cash and Waylon Jennings", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "The Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "The Summer Olympic Games", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3 million", "chocolate-colored", "Norman Graham Hill", "1908", "Neneh Mariann Karlsson", "American rapper Eminem", "Love Streams", "In a Better World", "Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "\"Pimp My Ride\"", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "wooden Indian", "John Francis Kelly", "early Romantic period", "$700 million", "the Sun", "Bhushan Patel", "18 January 1669", "navigation by river", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat X", "Kew Gardens", "third season", "May 2016", "Kristy Swanson", "colonel", "Conan Doyle", "scalene", "put a lid on the marking of Ashura", "Pakistan's", "homicide", "bread pudding", "leather", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.703125, "QA-F1": 0.8379847582972583}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-447", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-5395", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_hotpotqa-validation-4514", "mrqa_triviaqa-validation-2789"], "SR": 0.703125, "CSR": 0.5546069587628866, "EFR": 0.8947368421052632, "Overall": 0.71275938517363}, {"timecode": 97, "before_eval_results": {"predictions": ["Eddie Redmayne", "the Caucasus range", "David Bowie", "John Spencer", "Granada", "Treaty of Brest-Litovsk", "Georg Wilhelm Friedrich", "Procol Harum", "duke and duchess", "cyanoguttatus", "1957", "1912", "transsexual", "Fred Astaire", "paris", "Scotland Yard detective", "Lewis and Harris (Scottish Gaelic: Le\u00f2dhas agus na Hearadh) in the Outer Hebrides", "fair", "winnie Mae", "Rudyard Kipling", "1921", "Trainspotting", "Emilia", "avocado", "Frans Hals", "Syriza", "Ford", "soybeans", "Cole Porter", "1830", "William WymarkJacobs", "the Parthenon", "Paddy Doherty", "Thomas Aquinas", "Dubonnet", "elephant", "Tigran Petrosyan", "arabia", "Westminster Abbey", "Canada", "Seal", "Edward VII", "Tombstone", "Sardinia", "Mr. Tickle", "Worcester Cathedral", "Jupiter", "December 7, 1941", "the eardrum", "Nadia Comaneci", "Buzz Aldrin", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "VAQ-135", "95 AD", "170", "\"Californication\"", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "from 1922 to 1991"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6383184523809524}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, false, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-3064", "mrqa_triviaqa-validation-3538", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-1718", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-174", "mrqa_hotpotqa-validation-2058", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.578125, "CSR": 0.5548469387755102, "EFR": 0.6296296296296297, "Overall": 0.659785938681028}, {"timecode": 98, "before_eval_results": {"predictions": ["sent an e-mail to reporters Wednesday with the subject line \"Vice presidential...\"", "Afghanistan's", "deutschneudorf", "Several suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags", "his health and about a comeback.", "poems", "then-Sen. Obama", "woman", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Former Mobile County Circuit Judge Herman Thomas", "celebrities", "Iraqi economy.", "Phillip A. Myers.", "I showed up at WAHR with the record that would play my theme song, \"Swingin' Down the Lane.\"", "to share personal information.", "British", "a Yemeni cleric and his personal assistant,", "al-Maliki", "Egypt", "\"Now that we know Muhammad is an Ennis man, we will be back,\"", "stars of TLC's \"The Little Couple,\"", "WBO welterweight title", "Austin, Texas,", "17-month", "to pay him a monthly allowance,", "Manmohan Singh's", "the war of words in the Republican Party", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "Bill Haas", "Consumer Reports", "28", "step up.\"", "42 years old", "since 1983.", "improve health and beauty.", "almost 100", "Al Alberto Espinoza Barron's", "Derek Mears", "\"we take this issue seriously.\"", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "18th", "Haeftling", "on the table", "Asuka", "Bart Millard", "Nissan", "stone arch bridges", "Jane Austen", "the Marx Brothers film", "Indian", "early 20th-century Europe.", "a hostage", "the 70th Academy Awards", "W. Somerset Maugham", "Leicestershire"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6755813539530644}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.9210526315789475, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.38095238095238093, 0.8333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.1818181818181818, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.5714285714285715, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2541", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-14191"], "SR": 0.5625, "CSR": 0.5549242424242424, "EFR": 0.5357142857142857, "Overall": 0.6410183306277057}, {"timecode": 99, "UKR": 0.759765625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.81640625, "KG": 0.52421875, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "Mach number", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "most performed song of all time", "Oregon Ducks", "Arkansas", "the 2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "GZA", "Broadcasting House in London", "London Tipton", "\"Barney Miller\"", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "The Heirs", "Saturday Night Live", "strongly associated with Gaia and Cybele,", "Tumi Holdings, Inc.", "Black Ravens", "Lifestyle cities", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Nelson County", "Kang and Kodos", "25 million records", "Cleopatra VII Philopator", "James G. Kiernan", "the MC5", "James City County", "Tunisian", "Linda Ronstadt", "the United Kingdom", "August 19, 2013", "the Americas and the entire South American temperate zone", "The Omega Man", "five", "Alex Turner, Bill Bailey, Pete Shelley, Paul Farley,", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "The term was first used in tennis", "Frank Zappa", "1991", "apples", "Fred Trueman", "Scotland", "Chesley", "Mario Balotelli", "Friday,", "Lifeboat", "a byte", "stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.546875, "QA-F1": 0.679707532051282}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.3333333333333333, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.05128205128205128, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2083", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572"], "SR": 0.546875, "CSR": 0.5548437500000001, "EFR": 0.8275862068965517, "Overall": 0.6965641163793104}]}