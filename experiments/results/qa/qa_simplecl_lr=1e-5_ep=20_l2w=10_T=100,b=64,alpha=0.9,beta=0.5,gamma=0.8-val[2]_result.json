{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 7920, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange County", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail", "Uncle Tom\u2019s Cabin", "The liver", "No man", "No.1", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8604166666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-71", "mrqa_naturalquestions-validation-646"], "SR": 0.84375, "CSR": 0.859375, "EFR": 0.9, "Overall": 0.8796875}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "demographics and economic ties", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "warmest regions", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "low ratio of organic matter to salt and water", "the city's beaches are artificial", "It seemed to me I... She was Lo, plain Lo, in the morning, standing four feet ten in one sock", "'Twas the Night Before Christmas", "guardian", "Constitution Day  Founding Father Roger Sherman from the State of Connecticut is a signer to the U.S. Constitution in September 17, 1787", "guardian", "guardian", "time goes", "guardian", "the following academic divisions: chemistry, engineering", "abolitionists", "5562"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6875270562770562}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3857"], "SR": 0.640625, "CSR": 0.7864583333333334, "EFR": 0.9130434782608695, "Overall": 0.8497509057971014}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "a group that included priests, religious leaders, and case workers as well as teachers", "Vistula River", "1290", "21 October 1512", "427,652", "double", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "ctenophores", "calcitriol", "Krak\u00f3w", "time", "since at least the mid-14th century", "mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail and a carnivorous octopus", "Orestes", "Some grow to an immense size", "the \"Today\" show host did a terrible job", "the process by which water changes from a liquid to a gas", "the travel Detective: How to Get the Best Service and the Best deals from Airlin", "a pack of any type of rice that you like; ensure that it is whole grain... of water per 1/4 cup cereal powder has worked well to create a really liquid cereal", "Inks, in which colour is imparted by... the replacement of many inorganic pigments such as chrome yellow,... alloy powder (gold bronze) are used in novel silver and gold inks", "the Mycenaean kingdoms", "a biological process that displays an endogenous, entrainable", "before the ghost of noted impresario David Belasco is said to no longer haunt it", "a fourth brother, Private James Ryan", "Evelyn \"Billie\" Frechette", "fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge"], "metric_results": {"EM": 0.671875, "QA-F1": 0.6820211038961039}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-2192", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.671875, "CSR": 0.7578125, "EFR": 1.0, "Overall": 0.87890625}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Latin Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25", "May 2013", "K-9 and Company", "capturing prey", "C4", "pasture for cattle", "Victorian", "1,300,000", "it has trouble distinguishing between carbon dioxide and oxygen, so at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "two tumen", "eight", "A computational problem", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "Malkin Athletic Center", "24\u201310", "6.7+", "empire", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "World War II", "Intel (or any company) based on 10% of global annual revenues", "Matt Kuchar and Bubba Watson", "fastest time in circling the globe in a powerboat", "a large concrete block", "the foyer of the BBC building in Glasgow, Scotland", "Christianity", "Manchester United", "his son, Isaac, and daughter, Rebecca", "three", "change course", "Tsvangirai", "cowardly lion", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a miracle food", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6997976747517188}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7058823529411764, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2666666666666667, 1.0, 0.0, 0.5454545454545454, 0.0, 0.8333333333333333, 0.25, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-8874", "mrqa_squad-validation-2984", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3696", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-862", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.640625, "CSR": 0.734375, "EFR": 1.0, "Overall": 0.8671875}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "seal", "Philip Howard", "Duke Richard II of Normandy", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "British", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC", "two", "George Westinghouse", "disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Goa", "doingogie Howser, M.D.", "France's famous Louvre museum", "Leo Frank", "Athens", "Graziano Transmissioni", "opposition parties", "204,000", "Newcastle retained fourth place with a 3-1 victory over Blackburn, who remained in the relegation zone.", "the release of the four men", "putting a personal and human face on the issue... there's nothing more crucial,\" said Washington Post columnist Sally Quinn.", "Johnny Carson", "This will be the first time any version of the Magna Carta has ever gone up for auction, according to David Redden, vice chairman of Sotheby's.", "Democratic VP candidate", "at the University of Alabama in Huntsville", "Ali Larijani", "policing the world and Africa", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "resting heart rate over 100 beats per minute", "a jolly, solid, nutritious character, which describes the Suffolk perfectly.", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.625, "QA-F1": 0.7029347265221878}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9166666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-2531", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.625, "CSR": 0.7161458333333333, "EFR": 1.0, "Overall": 0.8580729166666666}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "straight line", "In the autumn of 1991, talks were held for the broadcast rights for Premier League for a five-year period, from the 1992 season.", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1", "nerves", "1700", "New Germany", "polyhydroxy aldehydes and ketones.", "Howard Dean III (born November 17, 1948) is an American politician who served as the 79th Governor of Vermont from 1991 to 2003 and Chair of the Democratic National Committee (DNC) from 2005 to 2009.", "heart, blood, and blood vessels.", "\"Wild Thing\", he played the ocarina as well", "God took millions of years to make everything.", "Gustav Malr.", "Diana the Princess", "slave-slave", "vena cava", "a scallop", "bullseye", "Tartarus", "\"cyc\" is short for this type of backdrop that suggests infinite space behind the performer.", "Nancy Reagan", "Bardiya", "LAP", "Count Ferdinand von Zeppelin", "huge", "Duke of Clarence", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas", "Dr. Jack Shephard, Kate Austen, Sayid Jarrah, Hugo \" Hurley\"", "comic book", "Love Is All Around", "Los Angeles Dance Theater", "United States", "the FDA warned nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5716730879414703}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-2921", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.515625, "CSR": 0.6875, "EFR": 0.9354838709677419, "Overall": 0.811491935483871}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "encourage growth in richer countries", "K-9 and Company", "9.1 million", "little support", "individual countries", "cattle and citrus", "Western Xia", "semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway/Eisenhower Freeway", "Thanksgiving", "86.66%", "Two thirds", "the Privy Council", "well into the nineteenth century", "Capability deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rod Steiger", "hog", "Barack Obama", "Keith G", "a small, half size cup used for serving espresso", "a tutu", "Annapolis", "Spring", "klammeraffe", "Artificial female", "Allah", "bones", "Boa Constrictor Python", "The Bible: In the Beginning", "Ada Monroe", "Faith Hill", "Ben Affleck", "a hurricane is a large-scale, low-pressure weather system.", "Germany", "time", "a American jazz saxophonist and composer.", "Sweden", "Vietnam", "nihonium, moscovium, tennessine, and oganesson", "Alexandria", "Perfume", "New Jersey Economic Development Authority's 20% tax credit", "Georgetown", "Essex Eagles", "Alzheimer's"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5754870129870129}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7468", "mrqa_squad-validation-1938", "mrqa_squad-validation-2705", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-7473", "mrqa_squad-validation-8189", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_naturalquestions-validation-10073", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.515625, "CSR": 0.666015625, "EFR": 0.967741935483871, "Overall": 0.8168787802419355}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu", "silent", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "Red Army", "middle of the 20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Happy Endings", "seven-eighths", "Franois Girardon", "the Atlas Mountains", "Madrid", "the Danube", "Yahweh", "leather", "George Pullman", "plums", "Jesus", "Sappho", "an expression meaning that ownership is easier to maintain if one has possession of something, or difficult to enforce if one does not.", "Frangipanis", "a fraction", "Hypnos", "Texas", "the Rooty Tooty Fresh 'N Fruity", "priesian", "Bill of Rights", "an optional writing test", "Rio de Janeiro", "Walden", "Southern California", "Harry Whittington", "the Earth's", "William Donald Scherzer", "Jack B Yeats", "the Central Intelligence Agency", "d'Artagnan", "Vnus impudique", "1985", "apples, blueberries, bananas", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.46875, "QA-F1": 0.55012481668392}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.08695652173913045, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-6194", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-14640", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.46875, "CSR": 0.6440972222222222, "EFR": 0.9117647058823529, "Overall": 0.7779309640522876}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61", "During the Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "Exploration", "prep schools", "Cultural imperialism", "strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "honeyeater", "4:51", "Khrushchev", "Hera", "the vine", "Reginald Dwight", "Cuba", "the Battle of Thermopylae", "the Khazars", "(Mac) McDonald", "cricket", "white", "Wash.", "Carmen", "Genoa", "12", "tarn", "972", "buffalo", "Ann Widdecombe", "scalene", "the Old Kent Road", "Tuesday", "sodium pyroborate", "Ab Fab", "Massachusetts", "Barrow, Carlisle, Whitehaven and Workington", "California", "the Susquehanna River", "Kajagoogoo", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "actor", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "What Price", "Grover"], "metric_results": {"EM": 0.59375, "QA-F1": 0.661235119047619}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.59375, "CSR": 0.6390625, "EFR": 0.9230769230769231, "Overall": 0.7810697115384615}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the Inner Mongolia region", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "mouth", "a tree with fragrant spring flowers", "Ken Russell", "Dan Dare", "mucia", "Smiths", "Mike Tyson", "Morocco", "Pesach", "Teddy Sheringham", "kaleidoscope", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "Underground", "puca", "\"beyond violet\"", "passion fruit", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "Titanic", "William Tell", "Christian Dior", "a jack-in-the-box-like creature", "Mendip Hills", "Wichita", "Communion", "New Croton Reservoir", "Andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "\"Ni!\"", "Romek Polanski"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6944602272727273}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-5319", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-4371", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-8589"], "SR": 0.65625, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network", "public service", "Guy de Lusignan", "tiger team", "sub-group", "The European Commission", "completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic tribes", "hizbullah", "five", "Whist", "Nile River", "Toscana", "albinism", "the choroid", "Pluto", "iron", "copper", "The Hague", "Victoria", "Ironside", "gollancz", "nizhny Novgorod", "brown trout", "Beyonce", "Wordsworth", "man V Food", "Queen Elizabeth II", "Samuel Johnson", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "lettuce Seeds", "hudd", "Crimea", "Shrek", "Oslo", "lions", "rhododendron", "Chicago", "Franklin D. Roosevelt", "Shanghai", "eile de Becque", "boat lifts", "Billy Colman", "17 October 2006", "beer", "Kingman Regional Medical Center", "Saturday's Hungarian Grand Prix", "Capuchin Church of the Immaculate Conception", "Edgar Allan Poe", "bobby"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6625744047619048}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-8252", "mrqa_squad-validation-6530", "mrqa_squad-validation-10338", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.59375, "CSR": 0.63671875, "EFR": 1.0, "Overall": 0.818359375}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units", "AD 14", "orogenic wedges", "Daniel Boone", "The Handmaid's Tale", "bonobo", "The Fault in Our Stars", "CR-X", "puzzle", "1961", "400 MW", "Total Nonstop Action Wrestling", "Galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen", "Continental Army", "Jack St. Clair Kilby", "Ryan Babel", "Akhmadovich Kadyrov", "July 16, 1971", "1933", "The Heirs", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel", "Rihanna", "Nick Cassavetes", "Lamar Hunt", "Sarah", "Jean Baptiste Point du Sable", "England", "Paul W. S. Anderson", "a Christian church", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "drug trafficking is a transnational threat, and therefore national initiatives have their limitations", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "Dr. Dre", "master", "pre-Columbian times"], "metric_results": {"EM": 0.625, "QA-F1": 0.6700148809523809}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-5658", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-3896", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.625, "CSR": 0.6358173076923077, "EFR": 1.0, "Overall": 0.8179086538461539}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Catch Me Who Can", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "impossible", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold", "\u00c9mile Girardeau", "Brownlee", "partial funding", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "a nephew of the playwright Anton Chekhov", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Love at First Sting", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Firestorm\", \"The Spectre\", and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "Liquidambar styraciflua", "Gilbert du Motier", "Indian", "three", "Winter Haven", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "few", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Johnny Cash", "Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "2015", "1982", "rod", "Chris Robinson", "gossip Girl", "fluid dynamics", "out", "a sky goddess", "Richie Unterberger"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6836458333333334}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.4, 0.4, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7200000000000001, 1.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3287", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_hotpotqa-validation-96", "mrqa_naturalquestions-validation-7020", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.578125, "CSR": 0.6316964285714286, "EFR": 0.9629629629629629, "Overall": 0.7973296957671958}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "1970", "religious freedom", "Spreading throughout the Mediterranean and Europe", "kilogram-force", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "time and storage", "Vistula River", "100 to 150", "iPod Nano and iPod Touch", "at the school.", "March 8", "Democrats and Republicans", "the Catholic League", "half Moon Bay", "\"He is obviously very relieved and grateful that the pardon was granted,\" Dean said.", "Friday", "Majid Movahedi", "different women coping with breast cancer in five vignettes", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills -- began falling onto the stern of his ship", "stressed out", "milk", "Lance Cpl. Maria Lauterbach", "Hyundai Steel", "London", "400", "Val d'Isere, France earlier this year.", "the test results", "two soldiers and two civilians", "tweener love", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J. Crew", "Japanese", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "British author J.G. Ballard, whose boyhood experience in a World War II internment camp became the novel and film \"Empire of the Sun,\"", "suppress the memories and to live as normal a life as possible", "4 meters (13 feet) high", "the Irish capital", "Democrat", "Spanishfork", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "The BFG", "mercury"], "metric_results": {"EM": 0.375, "QA-F1": 0.44903370746101723}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.27272727272727276, 1.0, 1.0, 0.8750000000000001, 0.23999999999999996, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.2608695652173913, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-1672", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.375, "CSR": 0.6145833333333333, "EFR": 0.975, "Overall": 0.7947916666666666}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "a prime number", "50 fund", "Camisards", "over $40 million", "GTE.", "1,100", "spinat", "Oligocene", "Barzee", "Charles Darwin", "at a Little Rock military recruiting center.", "March 24", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"They pretty much asked me if she was depressed,... how she acted around the baby, if she seemed stressed out,\"", "56", "Fred Bright, the district attorney in Milledgeville,", "\"The Lost Symbol\"", "Heshmatullah Attarzadeh", "new intravenous vitamin \"drips\" are part of the latest quick-fix, health fad catching on in Japan", "12 off-duty federal agents", "Seoul.", "resources", "highest ranking former member of Saddam Hussein's regime still at large", "two Emmys", "\"scared I won't be able to go home,\"", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75", "eradication of the Zetas cartel", "closing these racial gaps.", "a bond hearing", "Mugabe and Tsvangirai", "a hospital in Amstetten,", "African National Congress Deputy President Kgalema Motlanthe", "spiral into economic disaster.", "resigned", "Ralph Cifaretto", "a strict interpretation of the law", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000 or so", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "\"homebrew\" settings or worlds.", "Beno\u00eet Jacquot", "topaz", "Library of Congress", "The Left Book Club", "holography"], "metric_results": {"EM": 0.5, "QA-F1": 0.6024838572124757}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.5, 0.0, 0.5, 0.16666666666666669, 0.28571428571428575, 0.0, 1.0, 0.42857142857142855, 0.0, 0.10526315789473685, 0.5, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 0.4444444444444445, 1.0, 0.0, 0.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.3, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.5, "CSR": 0.607421875, "EFR": 0.96875, "Overall": 0.7880859375}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary manslaughter", "foreplay, sexual conquests and how he picks up women, all taboo subjects in deeply conservative Saudi Arabia.", "his injuries,", "30 years ago.", "murder", "next year", "the Obama administration has not yet articulated a Sudan policy.", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "Kerstin,", "\"theoretically\" Iran could develop a nuclear weapon and it is close to achieving that desire, does that mean it would use it against Israel?", "\"whole ethos is one of violence\" and that it had \"made a brutal choice to step up attacks against innocent civilians", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "your environmental efforts", "two women", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "Monday", "male veterans struggling with homelessness and addiction.", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs", "Poland and the Czech Republic have agreed to host parts of the system, others in Europe share Russian concerns that the defensive shield could be used for offensive aims.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "World War I", "1950s,", "U.S. troops", "Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "more than 120 groups across six continents are holding vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow, a town of about 238 people,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "\"Three Colours\" Trilogy, themed on the French Revolutionary ideals of liberty, equality, and fraternity;", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "Joe Louis", "George Blake", "Bogota"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6463417918886669}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6923076923076924, 0.22222222222222224, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.16, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.5, 0.125, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.06666666666666667, 0.2857142857142857, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-3455", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_triviaqa-validation-6739"], "SR": 0.546875, "CSR": 0.6038602941176471, "EFR": 0.9310344827586207, "Overall": 0.7674473884381339}, {"timecode": 17, "before_eval_results": {"predictions": ["lower", "in hospitals", "questions and answers", "(anima non sic dormit)", "Captain Francis Fowke, Royal Engineers,", "12 January", "60,000 European settlers,", "Zagreus", "CBS", "17", "temperate", "a review of state government practices", "\"Mad Men\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's restive provinces", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends to secure a visitor's visa and bus ticket to Johannesburg.", "collaborating with the Colombian government,", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Matthew Fisher,", "unclear,", "in the north and west of the country,", "forcibly injecting them with psychotropic drugs", "introduce legislation Thursday, improve the military's suicide-prevention programs.\"", "$250,000", "this week", "Derek Mears", "a motor scooter", "Gary Player", "Nieb\u00fcll", "promotes fuel economy and safety while boosts the economy.", "a fair and independent manner and ratify successful efforts.", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22-year-old", "UNHCR", "how health care can affect families.", "Antonio Maria Costa,", "U.S. Food and Drug Administration", "Dominican Republic", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "at checkposts and military camps in the Mohmand agency,", "Lashkar-e-Tayyiba (LeT)", "Friday", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "slapped and beaten with a baseball bat and the butt of a rifle.", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism.", "C. S. Lewis", "a number", "sake", "Halifax"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5969872524330245}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.125, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3529411764705882, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.09523809523809525, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.4, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-6359", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695"], "SR": 0.515625, "CSR": 0.5989583333333333, "EFR": 1.0, "Overall": 0.7994791666666666}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam movement", "Defensive ends", "the dot", "chastity", "The European Court of Justice", "bronze medal in the women's figure skating final,", "U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "UK", "\" Teen Patti\" (\"Card Game\")", "Argentina", "Congress", "28", "New Haven, Connecticut, firefighter Frank Ricci,", "Kurdish Gas City.", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "required to submit label safety changes and the medication guide within 30 days of receiving the notification from the FDA or provide a reason why they don't believe such labeling changes are necessary,", "political and religious", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Bahrain", "federal officials were reviewing an unspecified threat to disrupt the inauguration, according to the Department of Homeland Security.", "skull", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "because the federal government is asleep at the switch", "Molotov cocktails, rocks and glass.", "problems with the way Britain implements European Union employment directives.", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "India and mainland China, and sold on the streets illegally,", "Lindsey Vonn", "\"They were nothing,\"", "prisoners' rights and better conditions for inmates, like Amnesty International.", "President Obama's race in 2008.", "Brazil", "Saluhallen,", "burned genitals", "two people", "40-year-old", "Iranian consulate in Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger.", "\"Taxman,\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "Kirk Lazarus", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6019401133022056}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.125, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.13043478260869565, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 0.33333333333333337, 0.10810810810810811, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254", "mrqa_searchqa-validation-9338"], "SR": 0.515625, "CSR": 0.5945723684210527, "EFR": 0.9032258064516129, "Overall": 0.7488990874363328}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah.", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "37 survivors, Zikuski", "the Bainbridge would be getting backup shortly.\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book.", "reports he was diagnosed with skin cancer.", "to stand down.", "Ashley \"A.J.\" Jewell,", "17", "Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "rural California,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "steam-driven, paddlewheeled overnight passenger boat.", "the Haeftling range.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "CBS, CNN, Fox and The Associated Press.", "Flint, Michigan.", "protective shoes", "public-sector labor unions launching a general strike,", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "glass shards", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International", "GZA", "suffrageist", "Cobblestone", "Tunisia", "Silver", "Bonnie and Clyde."], "metric_results": {"EM": 0.5, "QA-F1": 0.6693810757955496}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, false, true, true, false, false, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.923076923076923, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 0.8, 1.0, 0.5, 0.28571428571428575, 0.888888888888889, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2805", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-7700"], "SR": 0.5, "CSR": 0.58984375, "EFR": 0.9375, "Overall": 0.763671875}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "John D. Rockefeller", "four", "mistreatment", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000 write / erase cycles", "the United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50 feet", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956", "The first message was sent over the ARPANET in 1969 from computer science Professor Leonard Kleinrock's laboratory at University of California, Los Angeles ( UCLA ) to the second network node at Stanford Research Institute ( SRI )", "New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Archduke Franz Ferdinand of Austria, heir presumptive to the Austro - Hungarian throne, and his wife", "Koine Greek", "October 1941", "to either peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "a charbagh", "Cee - Lo", "after Shawn's kidnapping", "in consistency and content", "Labour", "three times", "November 25, 2002", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two degrees of freedom", "Alberto Salazar", "a collection of live animals", "American", "Hoosick, Rensselaer County,", "CEO of an engineering and construction company with a vast personal fortune.", "1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "approximately 600 square miles of south-central Washington,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6572015098844868}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0625, 1.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8421052631578948, 0.5263157894736842, 0.0, 1.0, 0.5641025641025641, 1.0, 0.0, 0.0, 0.1, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.8, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-7881", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.53125, "CSR": 0.5870535714285714, "EFR": 0.9, "Overall": 0.7435267857142858}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Westminster", "the ancestors of chloroplasts", "24 of the 32 songs", "the bearers", "the Washington metropolitan area", "the molar concentration", "the breast or lower chest of beef or veal", "Sargon II", "Tagalog or English", "around 1600 BC", "By mid-1988", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford,", "by the early 3rd century", "in positions Arg15 - Ile16", "Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "1957", "1776", "1995", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "Scarlett Johansson", "embryo", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Canadian ice dancers Tessa Virtue and Scott Moir", "Sophocles", "Tim Allen", "thick skin", "a cake", "Pakistan", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "a Rear-Admiral of the Navy", "Marktown", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduras", "Pardon of Richard Nixon", "Ellen DeGeneres", "1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5274688801802772}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 0.28571428571428575, 0.16666666666666666, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.7777777777777778, 1.0, 0.0, 1.0, 0.6666666666666666, 0.08333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8780", "mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3883", "mrqa_hotpotqa-validation-3984"], "SR": 0.390625, "CSR": 0.578125, "EFR": 0.9487179487179487, "Overall": 0.7634214743589743}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River", "Stanford University", "linebacker", "Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Long Island", "Coldplay", "annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the United States Congress", "Zachary John Quinto", "Tanvi Shah", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "two", "Thomas Jefferson", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "on a sound stage in front of a live audience in Burbank, California", "Grace Zabriskie", "2014", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas as Matt Morgan", "Jodie Foster", "February 27, 2007", "Malina Weissman", "8ft", "Owen Vaccaro", "detritus", "on the lateral side of the tibia", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W", "London", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "2005", "the authentic intercalary date, February 29", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "Paul Revere", "\u00ef\u00bf\u00bdbeetle", "Brendan O'Brien", "2005", "Dan Tyminski", "the oldest daughter of an incestuous relationship", "southern port city of Karachi,", "at least nine", "Bashar al-Assad", "New Revised Standard Version", "biathlon"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6893311838624339}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 0.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.8, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.578125, "CSR": 0.578125, "EFR": 0.8888888888888888, "Overall": 0.7335069444444444}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "its many castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas currently has the longest streak of consecutive NCAA tournament appearances of all - time ( 29 )", "Thaddeus Rowe Luckinbill", "by the early - to - mid fourth century", "2002", "the Emperor", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2, Clause 3", "the Constitution of India", "Richard Bremmer", "Dick Rutan and Jeana Yeager, who in December 1986 had piloted the first aircraft to fly around the world without stopping or refueling", "closing of the atrioventricular valves and semilunar valves", "Ren\u00e9 Descartes", "Jimmy Flynn", "detritus", "September 27, 2017", "Ireland", "1978", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "September 28, 2017", "Alex Skuby", "Jamestown settlement in the Colony of Virginia", "March 2016", "1922 to 1991", "Edward Hyde", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "a single peptide bond or one amino acid with two peptide bonds", "the `` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting", "The Massachusetts Compromise", "Justin Timberlake", "the forces of Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield as Al Schmid", "1871", "eye", "The History Boys", "aprimitive type of fish", "the White Knights of the Ku Klux Klan", "five", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "Phillip A. Myers.", "Osama bin Laden", "Antarctica", "gaius", "enoki"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6408087270519336}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.13333333333333333, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.17391304347826084, 0.9333333333333333, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.3076923076923077, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.4, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_squad-validation-8990", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-6109", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.484375, "CSR": 0.57421875, "EFR": 0.9393939393939394, "Overall": 0.7568063446969697}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "1996", "the onset and progression of Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "the Indian School of Business", "New York", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin button\" (2008)", "A55", "Corendon Dutch Airlines", "86", "Capella University", "Eilean Donan", "Fatih Ozmen", "U.S.", "Pacific Place", "served as the Attorney General of Michigan from 1999 to 2003", "the Donny & Marie Showroom, at the Flamingo Las Vegas", "City of Westminster, London", "2016", "Wildhorn", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "50 km north-northeast of Bologna, on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Operation Watchtower", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "musical research", "Portland, OR", "Yoruba", "Lucky", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "1966", "The Stig", "Allan Border", "Medellin", "his father", "electric cars", "2004", "genes", "olive", "Stockholm"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6690934065934067}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.5, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.546875, "CSR": 0.573125, "EFR": 0.9655172413793104, "Overall": 0.7693211206896552}, {"timecode": 25, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "the Anhaltisches Theater in Dessau", "Anna Clyne", "Terence Winter,", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Jonghyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "American", "Acid house", "at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage", "10 Years", "Haleiwa, Hawaii", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles", "PBS", "second largest", "CCTric acid", "in 1989", "Johnnie Ray", "The Five", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "torpedoes", "1972", "Geographical Indication tag", "Ringo Starr", "Cleveland Celtics", "World Championship Wrestling", "2003", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "The Tax Reform Act of 1986", "Henry Louis", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram,", "morgicus", "to become more sustainable", "green"], "metric_results": {"EM": 0.625, "QA-F1": 0.6884796626984128}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.625, "CSR": 0.5751201923076923, "EFR": 0.9166666666666666, "Overall": 0.7458934294871795}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "Sleeping Beauty", "Orchard Central", "Tom Hiddleston", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool", "port city of Aden, on the southern coast", "British", "Prince Louis of Battenberg", "1985", "Archie Andrews", "after", "17 December 177026", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "racehorse breeder and owner", "Summerlin, Nevada", "1919", "Kevin Spacey", "Love Streams", "stunt jumping", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music and English folk-song", "Hexachrome", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Ewan McGregor", "1963", "a peplos", "Herald of Free Enterprise", "A Nutshell", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "Japan", "potp0urri Flashcards"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6540436126373625}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268", "mrqa_searchqa-validation-13669"], "SR": 0.609375, "CSR": 0.5763888888888888, "EFR": 0.96, "Overall": 0.7681944444444444}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Sir Matthew Alistair Grant", "most awarded female act of all-time", "Dunlop Tyres", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "\"40 Days and 40 Nights\"", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Westerister", "Kalokuokamaile", "Raden Panji", "Don Bluth", "December 8, 1970", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "James Aaron Diamond", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "The Ci\u0119\u017cki karabin maszynowy wz.", "Steve Kiley, M.D.", "Prussian army general, adjutant to Frederick William IV of Prussia", "January 2004", "Michael Stipe", "ten", "seven", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "c3H8O3", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "bromide", "nasal septum", "9 Real NASA Technologies"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6778226342371079}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 0.18181818181818182, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.59375, "CSR": 0.5770089285714286, "EFR": 1.0, "Overall": 0.7885044642857143}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "Herrenhausen Palace, Hanover", "Henry Mancini", "A native or inhabitant of Japan", "Gordon Ramsay", "Mikhail S. Gorbachev", "Adrian Cronauer", "sub rosa", "Charlton Heston", "Anna (Julia Roberts)", "a scythe", "orchid", "Paddy Doherty", "smallpox", "The Colossus of Rhodes", "Libya", "Yeehaw", "WoO", "Iran", "Who's Who", "wry, compassionate, and brimm[ing] with... open-minded intelligence", "Count de La F\u00e8re", "Tax Day", "Eric Morley", "atenlol and lisinopril", "The Garrick Club", "Belle", "Fabio Capello", "Manhattan", "Marc Norman", "The Greatest", "a singer and performer", "the British charts", "a Scotch bonnet", "piano", "Seattle", "The Union Inn", "Cardiff", "Baton Rouge", "a 'Weber', or a 'Zenith", "Tahrir Square", "Romanian", "bathtub curve", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "Meerkat", "Greek", "Passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "June 4, 1931", "North America", "Florida's Everglades", "Garth Brooks", "elegant, sexy and international", "drive", "Glengarry Glen Ross", "Sebastian Stark"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5886284722222221}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, true, false, true, true, false], "QA-F1": [0.0, 0.5, 0.39999999999999997, 0.5, 1.0, 0.33333333333333337, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-6758", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-3804", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-1670", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-6096", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-15919"], "SR": 0.484375, "CSR": 0.5738146551724138, "EFR": 1.0, "Overall": 0.7869073275862069}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Tim Duncan", "James W. Marshall", "in florida it is illegal to sell alcohol before 1 pm on any sunday", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Thompson", "between 8.7 % and 9.1 %", "the first day of the Lunar New Year was on Friday, 16 February", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "the status line", "the retina", "jimmy McDaniels", "Triple Alliance of Germany", "Andrew Lloyd Webber", "1955", "Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar", "New York Times", "1960", "Meg Autobots", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Donald Sutherland", "Sadie Calvano", "early to mid-2000s", "i want to be with you everywhere", "due to a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Cairo, Illinois", "in the 1970s and'80s", "Hebrew Bible", "Earl ( John Doe )", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "The Miracles", "Eukarya", "elbow", "hershey Hurricane", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "27", "Long Island", "Romney", "rock", "ulnar side", "bronchitis"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5743039772727273}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.5454545454545454, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.4, 1.0, 0.0, 0.0, 0.0, 0.56, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-4017", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.515625, "CSR": 0.571875, "EFR": 1.0, "Overall": 0.7859375}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "tourism", "a circle", "( Sequoia sempervirens)", "The Fairly Oddparents", "the Spanish Republic", "a taximeter", "coyote", "pVM", "Harry Reid", "Ray", "Axis", "forge", "boxing", "Cormac McCarthy", "flowers", "Blackbird", "Footprints", "Caliban", "Tampa Bay Lightning", "federal Bureau of Investigation (FBI) data", "Tommy Lee Jones", "a chief tax collector", "\"The Secrets of a Fire King\"", "(1874-1876)", "hubris", "Yahtzee", "Tony Danza", "markup language", "hives", "life expectancy", "William S. Hart", "(Every son that is born ye shall cast into the river)", "Pride and Prejudice", "The Secret Family of Jesus", "kosher", "Munich", "Michael Jordan", "candle", "Prospero", "Hikaru Sulu", "parrots", "dough", "kyushu", "honey", "Boston", "Mattel", "Arctic Ocean", "the Italian flag", "butternut squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "1911", "Harlow Cuadra and Joseph Kerekes", "Newtonian mechanics", "Israel", "top designers", "anti-trust laws."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6276041666666666}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-5093", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3054"], "SR": 0.578125, "CSR": 0.5720766129032258, "EFR": 0.9629629629629629, "Overall": 0.7675197879330944}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Kramer's caddy Stan", "Christian Kern", "January 21, 2016", "Bloomingdale Firehouse", "elise Marie Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge Aharon Barak", "Bangkok", "Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland", "Slaughterhouse-Five", "Adventures of Huckleberry Finn", "wine", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Lawton Chiles", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Isabella Palmieri", "Hathi Jr", "1935", "phycera", "slow", "\"Cruisin'\"", "the Rockies", "the anti-trust unit", "Friday", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7370392628205128}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.65625, "CSR": 0.57470703125, "EFR": 1.0, "Overall": 0.787353515625}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\"", "jellyfish", "March", "a blank", "fauntleroy", "the World Health Organization", "Eat porridge", "Kofi Annan", "glucose", "the right to print was strictly controlled in England", "Taggart", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "Manfred Mann", "Sven Goran Eriksson", "the BBC", "Jackson Street", "Brussels", "Flora MacDonald", "John Poulson", "A\u00e9roport de Paris-Beauvais-Till\u00e9", "the euro", "Superintendent Norman Mullet", "Saskatchewan (Province)", "Laurent Planchon", "the bottom of the Solent", "vomiting", "Basketball Page 30", "Bristol Aeroplane Company", "Spinach", "Tony Meo", "\u201cArgo\u201d", "Gemini", "Surrey", "1971", "the Fosse Way", "Budapest", "Chile", "William Shakespeare", "borax (sodium tetraborate decahydrate, Na2B4O7\u221910H2O)", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "Rigor mortis is very important in meat technology", "United States customary units are a system of measurements commonly used in the United States", "Miller Brewing", "northwestern Italian coast", "Sydney, New South Wales, Australia", "without loved ones, without homes, without life's belongings.", "her decades-long portrayal of Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\" Kristal Kraft, a real estate agent in Denver", "Peter Bogdanovich", "a bird", "the Federal Republic of Cyprus"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5405891494126789}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.47058823529411764, 1.0, 0.0, 0.7499999999999999, 0.0, 0.923076923076923, 0.1, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7197", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.4375, "CSR": 0.5705492424242424, "EFR": 0.9722222222222222, "Overall": 0.7713857323232323}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "No Secrets", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown, Ph. D.", "Arctic Ocean", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "The palace has 775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Longline", "Jesus'birth", "a habitat", "irsten Simone Vangsness", "Central Germany ( German : Mitteldeutschland ) is an economic and cultural region in Germany", "Andrew Johnson", "Etienne de Mestre", "Aegisthus", "electors", "Julia Ormond", "Sauron", "1961", "Mike Mushok", "2013", "March 1", "novelization", "a usually red oxide formed by the redox reaction", "Spain disputes the legality of the constitution", "Taylor Hayes", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "abdicated in November 1918", "one of the most recognisable structures in the world", "erosion", "March 2, 2016", "stuffing", "1996", "Ray Charles", ", marriageable age was set at 16 for females and 18 for males", "the Ramones", "The original building was completed in 1800", "from the Anglo - Norman French waleis", "Ted '' Levine", "Kate lives in Los Angeles", "May 2010", "France", "Heath Ledger", "Wilson Pickett", "a centaur", "singer", "cricket fighting", "Luis Edgardo Resto", "drama that pulls in the crowds", "German authorities", "Islamabad", "Tunisia", "RAND", "bios & Profiles"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5417164409968686}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 0.5, 0.125, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.0, 0.0, 0.7368421052631579, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.3076923076923077, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-8625", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.453125, "CSR": 0.5670955882352942, "EFR": 0.9714285714285714, "Overall": 0.7692620798319327}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Zeebo", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission", "Universal Pictures", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "prophets and beloved religious leaders", "state legislators of Assam", "a key role in digestion of proteins", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "constant pressure", "`` mind your manners ''", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender )", "20 November 1989", "Tom\u00e1s de Torquemada", "the Four Seasons", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "first published in the United States by Melvil Dewey in 1876", "2003", "Sebastian Lund ( Rob Kerkovich )", "5 September 1666", "California State Route 1", "The management team", "antigen from the lumen and deliver it to the lymphoid tissue", "business applications to be developed with Flash", "Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "braking to a full stop", "early Christians of Mesopotamia", "Tennessee Titan", "ice cap climate ( K\u00f6ppen EF )", "a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "future AC/DC founders", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "at the Olympics", "Henry Ford", "Toyota", "vice president", "a mass of cells that grows slowly in"], "metric_results": {"EM": 0.5, "QA-F1": 0.6520483856421357}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.7499999999999999, 0.3333333333333333, 0.3636363636363636, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.375, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.6666666666666666, 1.0, 0.125, 0.7000000000000001, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.5, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.5, "CSR": 0.5651785714285714, "EFR": 0.90625, "Overall": 0.7357142857142858}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "a supposed mild euphoric", "hankey", "Venezuela", "Croatia", "The Ring", "Peter Pan", "Andrea del Sarto", "Arctic Ocean", "egg in front of the opening, so the egg is sucked in by the differential in this between the inside & outside of the bottle", "dams", "Lafayette", "Elijah Muhammad", "doldrums", "Village People", "Alexander Pushkin", "Australia", "Munich", "puebla", "work at night", "papacy", "Arkansas", "hanellaco", "Pierre-August Renoir", "mister", "Les Huguenots", "Innsbruck", "Charles Keating Jr.", "Microsoft", "petticoat", "the Trump Organization", "vikings", "Atlantic City's First Boardwalk", "Blackwater USA", "elephants", "American Airlines", "ibex", "Odysseus", "Quizlet", "Kensington Palace", "the Overland Flyer", "Netherlands", "Pocahontas", "author of The Lion, the Witch, and the Wardrobe", "John Galt", "a chalkboard", "Chicago Mercantile Exchange", "Las Vegas", "danskin", "wheat", "Pablo Casals", "ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "psychological horror", "John Morgan", "Hungarian Rhapsody No. 2", "Eleanor of Aquitaine", "Sen. Debbie Stabenow", "63", "we are resetting,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6261160714285714}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false], "QA-F1": [0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.5625, "CSR": 0.5651041666666667, "EFR": 0.9642857142857143, "Overall": 0.7646949404761905}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act ( NIRA )", "User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "between 2 World Trade Center and 3 World Trade center", "Southend Pier", "Santa Monica", "sovereign states", "Will", "31 January 1934", "Filipino", "1773", "random - access memory ( RAM )", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Kusha", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean", "never made", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "the Four Seas", "retinal", "the 1980s", "in soils", "card verification value", "`` rebuke with all authority '' ( Titus 2 : 15 )", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum", "Mike Czerwien", "As of July 2017", "Vienna", "English", "Africa", "Stalin", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "$22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities.", "cotton", "Denzel Washington", "Quinn", "Towcester"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7348608856421357}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.888888888888889, 0.0, 1.0, 1.0, 0.9523809523809523, 1.0, 0.5714285714285715, 0.08333333333333334, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.1, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-1028", "mrqa_triviaqa-validation-5295", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953"], "SR": 0.640625, "CSR": 0.5671452702702703, "EFR": 0.8695652173913043, "Overall": 0.7183552438307873}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "Canada", "South Africa", "first among equals", "\u201cShine,\u201d", "a cappella", "albinism", "a radical orator", "aglets", "Saturday Night Live", "FC Bayern M\u00fcnchen", "equinoxes", "Bonnie and Clyde", "French", "copper", "Dawn French", "brian gagger", "b Benedict", "Doris Lessing", "Scooby-Doo", "Swaziland", "the boston house at London Zoo", "Kent", "the Humber", "points based scoring", "automobile", "Kent", "the Von Trapp family", "Boy George", "Galileo Galilei", "Gertrud Margarete", "Scotland Yard detective", "Marilyn Manson", "Medellin", "William Shakespeare", "spark-ignition", "brazilia", "Boulder Dam", "the long-term effects of using drugs", "Iran", "Belle de Jour", "Morecambe", "abba", "rain", "white", "Asaph Hall", "France", "geena Davis", "kunsky", "the end of life", "Lady Penelope", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "heavy turbulence", "women and breast cancer", "Blaine", "a sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5519903273809523}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, false, true, false, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.375, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-69", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-3349", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-541", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.53125, "CSR": 0.5662006578947368, "EFR": 0.9666666666666667, "Overall": 0.7664336622807018}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "Tyne", "the liver", "40", "water", "Bears", "Bolivia", "cuba", "Phil Redmond", "Stevie Wonder", "head", "hound", "hanover", "stars", "Earl of Strafford", "work", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "hodgealcoatl", "a 1934 Austin seven box saloon", "Paul Anka", "Carthage", "cuba", "the king Duncan", "Blade Runner", "Jay-Z", "leopons", "drum", "\u201cSanta Buddies\u201d", "San Diego Opera", "norman tbbit", "Ticket Sarasota", "South Africa", "Christian Dior", "the A5 and A49 trunk roads", "killer whale", "Georgia", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "baron", "dragon", "ballistic missile", "frauds", "a sea horse", "even numbers", "\u201cmorally justified\u201d to assassinate Tony Blair,", "quartz or feldspar", "54 Mbit / s", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Lynn", "piano", "paid tribute to pop legend Michael Jackson,", "the United States", "French Guiana", "AOL", "cuba", "tournament leader Jean Van de Velde"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5323660714285714}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, false, false, true, true, true, false, true, true, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2224", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_triviaqa-validation-3358", "mrqa_naturalquestions-validation-655", "mrqa_hotpotqa-validation-2852", "mrqa_newsqa-validation-1352", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.484375, "CSR": 0.5641025641025641, "EFR": 0.9090909090909091, "Overall": 0.7365967365967365}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Olivo", "Midnight Cowboy", "alfa", "seborrheic dermatitis", "carol Hawkins", "steam engines", "Niger", "central Stockholm", "Tangled", "dogs", "James Douglas", "Bulls Eye", "Napoleon", "bajec-Lapajne", "Martin Clunes", "Charles Darwin", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "tommie Connors", "isambard Kingdom Brunel", "greece", "1957", "Devon", "villefranche", "white wine, onions and sometimes tomatoes", "calcium phosphate", "Ralph Vaughan Williams", "musical scale", "animal sanctuaries", "flannel", "e. T. A. Hoffmann", "hanzhou", "Spain", "grow", "Tuesday", "Guru Nanak", "bleak house", "Harry Potter", "phosphorus", "Thomas Horner", "Indianapolis", "humbert", "cuckoo", "Stringer", "Ford", "Alice Cooper", "Majorca (Mallorca)", "transfusions", "Royal Bengal Tiger", "inward spiral", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "\"The Cycle of Life,\"", "forgery and flying without a valid license", "137", "a cabin", "St. Patrick's Day", "defensive backs", "Sondheim"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4724702380952381}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6497", "mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-16910", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.40625, "CSR": 0.56015625, "EFR": 0.9210526315789473, "Overall": 0.7406044407894736}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players", "Washington", "de quincey", "yersinia pestis", "horse", "buffalo", "Cleopatra", "dove", "Sarajevo", "the Bill of Rights", "dust", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "paperfolding", "resistance", "scuba", "secretary", "jane de valence", "matricide", "smith smith", "\u201cTonight is Another Day\u201d", "linesider", "Tomorrow Never Dies", "Sudan", "Great Dane", "Washington", "Angola", "New Hampshire", "James I", "Terry Bates", "the Philippines", "purple", "one-thousandth", "charlie bunting", "a 965-foot ocean liner", "Rome", "10", "Southwest Airlines", "phone", "Jeffery Deaver", "Comedy of Errors", "charlotte", "glyn Jones", "german h.W. Bush and former first lady Barbara Bush", "cheviles", "dogger bank", "al-Qaeda\u2013inspired terrorist cell carried out a series of bombings against Madrid's Cercanias (commuter train) system", "rodinsons", "Kitty Softpaws", "August 18, 1998", "Tanvi Shah", "the EN World web site", "the 100th anniversary of the first \" Tour de France\" bicycle race", "Mach number", "Janet and La Toya", "more than 2.5 million", "researchers", "the Matrix", "seinfeld", "lothario", "performed well with respect to primary and secondary education, and matched that available in many other developed economies, they were weaker when it came to training and tertiary education"], "metric_results": {"EM": 0.453125, "QA-F1": 0.4953125}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-2275", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5826", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.453125, "CSR": 0.5575457317073171, "EFR": 0.9714285714285714, "Overall": 0.7644871515679443}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "Spain", "hula hoops", "n Nissan", "chobus", "roddy Doyle", "a counting table", "Robin Hood Men in Tights", "sisyphus", "Velazquez", "South African", "maracaibo", "london", "tchaikovsky", "oliver Twist", "Scotland", "osmond", "David Bowie", "Buzz Aldrin", "jane paul sartre", "chalin", "Dick Turpin", "rust", "jane aniston", "wales", "tbilisi", "jane jane pratt", "othello", "if you wait until late, it will take much longer to deal", "Glenn Close", "Lacock Abbey", "alex stard", "domestic cat", "anita Brookner", "jimoboam", "golda meyerson", "Black Sea", "bagram Theater Internment Facility", "Susie Dent", "a power outage", "Vienna", "The Archers", "shylock", "james james sousa", "henry gee", "jimmy boyd", "shakespears", "Marx", "aire", "habsburg monarchy", "Dry Ice", "Pat McCormick", "19 June 2018", "18 - season", "from 1993 to 1996", "James Gandolfini", "March 23, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones.", "tuba", "the o.K. Corral", "butternut squash", "Troy"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6100524749373434}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473685, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-824", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-9161"], "SR": 0.546875, "CSR": 0.5572916666666667, "EFR": 0.9655172413793104, "Overall": 0.7614044540229885}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "some work rule issues.", "hSH Nordbank Arena", "Comoros Islands", "aston villa", "Jeddah, Saudi Arabia", "40", "if you see Harrison Ford getting his chest waxed, do you immediately think about saving the rainforests", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "tweed years ago", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "dancy-Power Automotive Group", "Michoacan Family", "64", "in prison", "fastest circumnavigation of the globe in a powerboat", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career at his original club of Argentinos Juniors in 2007 and has been coaching at Independiente.", "E! News", "Haiti's capital, Port-au-Prince, and other severely stricken parts of the country.", "Madeleine K. Albright", "ice jam", "toxic smoke from burn pits", "benazir butto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South African", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "Cal Ripken Jr.", "a relative's house", "cancer", "acid attack", "former", "if drugs are funding the insurgency, NATO has a self-interest in supporting Afghan forces in destroying drug labs, markets and convoys", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m.", "Former Mobile County Circuit Judge Herman Thomas", "we say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well", "a man's lifeless, naked body", "\"release\" civilians, who it said numbered about 70,000 in Sri Lanka's war zone.", "Dodi Fayed", "in every port, the catamaran and its message has been warmly received.", "there is a decline in population density", "Real Madrid", "emperor Cuauhtemoc", "korea", "Misery", "dennis purdy", "Italo Balbo", "Thorgan", "River Clyde", "chile", "jungle Jim", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.34375, "QA-F1": 0.45037857604856446}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.5714285714285715, 0.8000000000000002, 1.0, 0.923076923076923, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.4444444444444445, 1.0, 0.08333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.14285714285714285, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.4210526315789474, 0.28571428571428575, 0.0, 0.6, 0.14545454545454548, 1.0, 0.2666666666666667, 0.3636363636363636, 0.11764705882352942, 0.11764705882352942, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-588", "mrqa_newsqa-validation-30", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_naturalquestions-validation-7333", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-5687", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.34375, "CSR": 0.5523255813953488, "EFR": 0.9523809523809523, "Overall": 0.7523532668881505}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.", "1943", "Volvo V70", "the Mountain West Conference", "the National Basketball Association", "Western Europe", "movie scripts", "Schaeffler AG", "the Championship", "1989 until 1994", "Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown", "Lollywood and Pollywood", "Emmanuel Ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs", "1988", "coaxial", "Northern Lights", "three different covers", "Malayalam cinema", "Regno di Dalmazia", "August 11, 1946", "Vincent Landay", "1967", "Estadio de L\u00f3pez Cort\u00e1zar", "Brian A. Miller", "Nicolas Vanier", "1985", "Gal Gadot", "Amy Jessup", "Texas Raiders", "Bremen, Germany", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "the UK\u2019s Trade Mark Registration Act 1875", "blue", "forearm", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.625, "QA-F1": 0.6906643263640546}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 1.0, 0.5, 1.0, 0.0, 0.29629629629629634, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-2070"], "SR": 0.625, "CSR": 0.5539772727272727, "EFR": 0.9583333333333334, "Overall": 0.756155303030303}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "over 12 million", "sexy Star", "Conservatorio Verdi in Milan", "40th United States president", "the backside", "\"the Gentle Don\"", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "2015 Orange Bowl", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool Football Club", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Australian Electoral Division", "Sun Tzu", "American singer Toni Braxton", "Hindi", "Michael Manasseri", "Irish Chekhov", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "Super Bowl VII", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Variations", "last summer", "almost 100", "into the Southeast,", "the jeffersons tv show", "Murray M. Silver, Jr.", "by... what differed for women was the status of their authority in the wider community.", "One Direction"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6907300420168068}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.75, 1.0, 0.5714285714285715, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-3263", "mrqa_searchqa-validation-12050"], "SR": 0.53125, "CSR": 0.5534722222222221, "EFR": 1.0, "Overall": 0.7767361111111111}, {"timecode": 45, "before_eval_results": {"predictions": ["the American Revolution", "a proof reader", "Royal Standard of the United Kingdom", "the Belgae", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "putt-putt", "CNN Daybreak", "Punxsutawney, Pennsylvania", "Pressburg", "yellow fever", "sea otter", "MMs", "a franchise", "rod", "the Watergate Seven", "dressage", "astronomer", "Mickey Mouse", "stigma", "Associate Professor", "a fruit snack", "Medusa", "a spiral staircase", "tabby", "staff", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "Helen of Sparta", "Vegetarianism", "the peace sign", "An Old Man, a Young Man", "English Monarchs These 2", "India", "sexy Beast", "The New York Times", "NFL", "a samt ar-rs road", "White bread and butter", "Robert's Rules of Order, Strategies for Individual Motions", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London", "Isle of Wight", "Peppercorn class", "Queen In-hyun's Man", "Oneida Limited", "Michael Jordan", "Libreville, Gabon.", "two tickets to Italy", "The station", "Cahawba"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6822916666666666}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_triviaqa-validation-888"], "SR": 0.609375, "CSR": 0.5546875, "EFR": 1.0, "Overall": 0.77734375}, {"timecode": 46, "before_eval_results": {"predictions": ["social power and wealth", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "room the book store", "faggot", "a skein, a team, or a wedge", "California Chrome", "Pluto", "Route 66", "the Taklamakan Desert", "Sindh", "Astronaut", "Great Victoria Desert", "German state of North Rhine-Westphalia", "Carole King", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Neptune", "Birmingham", "snakes", "Sedgefield", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "battle tanks", "South Korea", "pig", "definitely, maybe", "carmen", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "a hundred", "the Susquehanna River", "Argentina", "Darth Vader", "Frankfurt", "chipmunk", "Goldie Hawn", "pulsar", "Belgium", "horses", "sugar", "Benfica", "Sun Lust Pictures", "Games played", "makes Maria a dress to wear to the neighborhood dance", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11 healthy eggs", "Twilight", "the Carrousel du Louvre", "Speed Racer", "H. G. Wells", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6671875}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-445", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-4025", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.59375, "CSR": 0.5555186170212766, "EFR": 0.9615384615384616, "Overall": 0.7585285392798691}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "at Sunset", "Sinclair Lewis", "Patrick Newell", "The World is Not Enough", "pigments", "Jonathan Demme", "Vaclav Havel", "Dick Van Dyke", "millais", "Tina Turner", "2010", "Portrush", "glasses", "perfumer", "Duke Orsino", "magnetite", "Copenhagen", "Lord Sugar", "cargo", "Cubism", "sahara", "the Advisory Council of Science and Industrial Research", "eukharistos", "Charlotte's Web", "Octopussy", "silks", "William Randolph Hearst", "Lorne Greene", "rowing", "Corin Redgrave", "call my Bluff", "A", "Argentina", "Frank McCourt", "salt or sugar", "Debbie McGee", "germany", "starch", "Pears soap", "Donna Summer", "a balustrade", "Nottingham", "gdansk", "the Welcome Stranger", "taggart", "January", "Chechnya", "a police janitor", "a-teamautos", "football", "1,281,900 servicemembers", "Sir Ronald Ross", "Sun Tzu", "bioelectromagnetics", "Foxborough", "South Australian Championships", "beautiful", "Eleven", "Michelle Obama", "kbenhavn", "Communist Manifesto", "saara", "floxin"], "metric_results": {"EM": 0.46875, "QA-F1": 0.49939903846153844}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, true, true, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-366", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-3758", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-1730", "mrqa_triviaqa-validation-4754", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-15651"], "SR": 0.46875, "CSR": 0.5537109375, "EFR": 0.9705882352941176, "Overall": 0.7621495863970589}, {"timecode": 48, "before_eval_results": {"predictions": ["east", "Caesars Entertainment Corporation", "Supergirl", "Thored, Earl of southern Northumbria", "creature comforts", "Stephen Mangan", "William McKinley", "1905", "All Nippon Airways", "Mineola", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "physical", "1986", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Babylon", "Ford Falcon", "Southern State Parkway", "The Company", "1827", "Kim Bauer", "approximately $700 million", "Edward James Olmos", "Suffolk", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard H or HD blister gas", "45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "Westminster, London", "Boyd Gaming", "1848", "Texas Tech University", "John McClane", "Larry Wayne Gatlin", "Cayenne", "371.6 days", "Piedmont", "Selinsgrove", "Countess of Lovelace", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "Space Shuttle Challenger", "basil", "clio Awards", "The Rosie Show", "Current TV", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Octavius", "desert", "Library of Congress", "thylakoid membranes"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6791251509661836}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, false, false, false, true, true], "QA-F1": [0.25, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.8695652173913043, 0.19999999999999998, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-1399", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-4119", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.59375, "CSR": 0.5545280612244898, "EFR": 0.9230769230769231, "Overall": 0.7388024921507065}, {"timecode": 49, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John W. Henry", "Mos Def", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Digimon", "eastern", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five aerial victories", "Alain Robbe-Grillet", "the Seasiders", "Musicology", "Dragon TV", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1988", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "Kj\u00f8benhavns Boldklub", "Robert Jenrick", "Golden Globe Award", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "Everywhere", "the birth centenary of Pandit Jawaharlal Nehru", "honda", "Adam Smith", "Republic of Upper Volta", "56", "Nkepile M abuse", "Eintracht Frankfurt", "Lt Presley O'Bannon", "Hephaestus", "Amherst College", "six"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6780391483516484}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-1498", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.578125, "CSR": 0.5549999999999999, "EFR": 0.9629629629629629, "Overall": 0.7589814814814815}, {"timecode": 50, "UKR": 0.76953125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.791015625, "KG": 0.48515625, "before_eval_results": {"predictions": ["Sushant Singh Rajput", "\u00c6thelwald Moll", "Fife", "26,000", "Spain, Mexico and France", "1981", "geons & Dragons", "February 26, 1948", "National Aviation Hall of Fame class of 2001", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "A1 Recordings, Freebandz and Epic Records", "IFFHS World's Best Goalkeeper", "shortest player ever", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "May 5 to July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "northern mockingbird", "Picric acid", "Las Vegas", "ESPN's \" SportsCenter\"", "pioneering New Zealand food writer", "fantasy", "feats of exploration", "Dolly Records", "Bergen County", "Marlon Vaxivi\u00e8re", "Feyenoord's Sekou Ciss\u00e9", "quarter finals", "the superhero Birdman", "Biloxi", "New York Yankees", "1903", "King Kal\u0101kaua", "Mark \"Chopper\" Read", "e essence darkwave", "VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Bears", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "between 27 July and 7 August 2021", "1800", "season seven", "glycerol", "umbrella", "sheep", "is the most high-profile amalgamation of Indian and western talent yet,", "1.2 million", "84-year-old", "Jacob", "evidence", "the fourth son, Private First Class James Francis Ryan", "Mitch Murray"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6298849587912088}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.42857142857142855, 0.0, 0.25, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.30769230769230765, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4070", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-532", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4696", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770", "mrqa_searchqa-validation-1372"], "SR": 0.46875, "CSR": 0.5533088235294117, "EFR": 0.9411764705882353, "Overall": 0.7080376838235294}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County", "Prince Antoni Radziwi\u0142\u0142 (1775\u20131833)", "Hordaland", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia", "Daniel Espinosa", "1942", "water", "Bury St Edmunds, Suffolk, England", "20 July 1981", "What You Will", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "General Edward Lawrence Logan International Airport", "Blackpool Football Club", "Marvel Comics", "100 million", "James Gregory", "Volvo 850", "1978", "July 25 to August 4", "Sela Ann", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II", "Oracle Corporation", "Paris", "John Andr\u00e9", "Nine-card Brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Alexandrovich Morozov", "music of pre-Hispanic and contemporary music", "The Dragon", "two", "Outside", "Traumnovelle", "the Chechen Republic", "actress and model", "from 1986 to 2013", "Granada", "Guangzhou, China", "British", "Jaguar Land Rover Limited", "Citgo", "artist and graffiti writer", "B.R. Ambedkar, the chairman of the Drafting Committee, is widely considered to be its chief architect", "Presley Smith", "hydrological cycle or the hydrologic cycle", "Mungo Park", "Jet Harris", "Daffy Duck", "in a tenement in the Mumbai suburb of Chembur, with eight people living together in a single room.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "China could continue to claim Tibet as part of its territory.", "Popular Science", "ton", "Latter-day Saints", "people who are growing more and more suspicious of the way their business books were being handled."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6949614448051948}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.8571428571428571, 0.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.15999999999999998, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 0.5, 0.8, 0.25, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.4, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2033", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-185", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-823", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-3348", "mrqa_hotpotqa-validation-4565", "mrqa_naturalquestions-validation-3538", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.515625, "CSR": 0.5525841346153846, "EFR": 1.0, "Overall": 0.719657451923077}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "\"Physical\"", "a 19-year-old student named Romas Kalanta", "128", "novel", "the National Society of Daughters of the American Revolution", "Timmy Sanders", "Japan", "St Augustine's Abbey", "The Indianapolis Times", "Ridley Scott", "Dizzy Dean", "UHF channel 44", "North Kesteven", "Afro-Caribbean", "The Beatles", "\"Menace II Society\"", "September", "March 30, 2025", "Black Panther Party", "Pinellas County", "Ben Johnston", "Imagine", "Easy", "CBS", "\"Brickyard\"", "2012", "Candice Susan Swanepoel", "Benny Andersson", "Peter Yarrow", "Kathleen O'Brien", "Blackstone", "the north bank of the North Esk", "Paris", "Hard rock", "Yubin, Yeeun", "Ecko Unlimited", "Joe Frazier", "University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "\"General Hospital\"", "David Dunn", "William Bradford", "FieldTurf", "his fifth", "Benj Pasek and Justin Paul", "a hand injury", "the \u01c3ke e : \u01c0xarra \u01c1ke", "Johnny Cash", "the pulmonary arteries", "\"The Pope? How many divisions does he have?", "France", "Taekwondo", "the Saruman to my Frodo, the Dr. Octopus to my Spiderman.", "since 1983.", "the legitimacy of that race.", "the Duke of Norfolk", "Italy", "chili pepper", "a star"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6315848214285714}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-3459", "mrqa_hotpotqa-validation-2358", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-1813", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5343", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_newsqa-validation-2925", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.515625, "CSR": 0.5518867924528301, "EFR": 1.0, "Overall": 0.7195179834905661}, {"timecode": 53, "before_eval_results": {"predictions": ["a calendar", "Friedrich Nietzsche", "go on deck, and tell the men to fire faster, and not to give up the ship", "Carnarvon", "Ireland", "Glaciers", "bdellium", "Marie-Antoinette", "AUNT BEE'S", "Great Smoky Mountains National Park", "grasshopper", "Ohiopyle State Park", "Nostradamus", "Thomas Hodgkin", "The Flying Dutchman", "brown sugar", "Charles Howland Hammatt Billings", "The Crow", "the plain of Marathon", "John Keats", "(Scott) Peterson", "a backpacking route", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "Makar Dievushkin Alexievitch", "Discovery Channel", "Resident Evil", "daughter", "the French national holiday", "the UAE", "Dramamine", "My Little Chickadee", "beer", "Dred Scott", "Rose Tascher", "Benjamin Harrison", "Staten Island", "Transformers: Earth Wars", "Crystal Light", "the American Civil War", "the declaration of saturated fat", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "Inventors", "Indira Gandhi", "a NATO aircraft", "the Director of National Intelligence", "This procedure can be performed at any level in the spine ( cervical, thoracic, or lumbar ) and prevents any movement between the fused vertebrae", "2018", "Rubenshuis Museum", "mink mink", "David Bowie", "1 December 1948", "Lester Ben", "three centuries", "forgery and flying without a valid license", "Michoacan state,", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "Carpenter"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5655894886363636}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.125, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-7535", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-16126", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3257", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-15504", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-15589", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-11962", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-15822", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-622", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821", "mrqa_newsqa-validation-3486"], "SR": 0.46875, "CSR": 0.5503472222222222, "EFR": 0.9705882352941176, "Overall": 0.7133277165032681}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "IRL", "Gary Havelock", "Anthony Joshua", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "armoured", "Adrian Cronauer", "Copenhagen", "Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googolplex", "the Canadian Horseshoe Falls", "$SPX", "Mrs Merton", "blues", "Alamo", "Brazil", "bologna", "Aries", "Michael Faraday", "George Herbert Walker", "Montmorency", "haddock", "Happy Ever After", "Tim Peake", "Phil Redmond", "tamale", "Argentina", "St Moritz", "Good Neighbors", "Woody's horse", "Penelope Keith", "Sinclair Lewis", "deer", "zaire", "Barry White", "Batman & Robin", "Parchman Farm", "Canada", "The Hague Conventions", "Portugal", "silver", "Moby Dick", "`` Fix You ''", "`` Killer Within ''", "prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "The Worm", "\"The Sid Caesar Show.\"", "\"the most dangerous precedent in this country, violating all of our due process rights.\"", "sex scandal", "Easy Rawlins", "William McKinley", "the Scripps National Spelling Bee", "Prussia"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6508378623188406}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.08695652173913043, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-1769", "mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-3131", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187", "mrqa_searchqa-validation-14797"], "SR": 0.578125, "CSR": 0.5508522727272727, "EFR": 0.8888888888888888, "Overall": 0.6970888573232323}, {"timecode": 55, "before_eval_results": {"predictions": ["detainees are not drugged unless there is a medical reason to do so.", "the man was dead,", "CNN's Larry King", "Mexico", "customers", "the United States", "in Iraq", "the Iranian consulate,", "parachuted to the ground.", "links to paramilitary groups,", "CNN's Moscow-based Senior International Correspondent Matthew Chance", "heroin labs in neighboring countries and along trafficking routes.", "Bright Automotive", "NASCAR", "Clifford Harris", "Muslim", "a Muslim and a Coptic family", "adult reality show", "chandni Chowk Goes to China.", "Tens of thousands of new voters became the key to his Iowa win", "urged NATO to take a more active role in countering the spread of the", "1831", "the Ku Klux Klan", "President Obama", "pine beetles", "lower house of parliament", "Hillary Clinton", "Iran", "Daniel Radcliffe", "publicly criticized his father's parenting skills.", "Ronald Reagan UCLA Medical Center", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "Sixteen", "remains unknown,", "60 euros -- $89 --", "\"It didn't matter if you were 60, 40 or 20 like I am.", "Naturalist Charles Darwin", "acid attack", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy in Bangkok,", "Channel 4 said the program was made with the parents' full consent.", "top winds", "rwanda", "twice", "Bob Johnson", "the \"bystander effect\"", "\"Dancing With the Stars.\"", "his club", "Microsoft", "two years", "Confederate forces", "Sylvester Stallone", "1,228 km / h ( 763 mph )", "Thom Yorke", "Charlie Sheen", "silversmith", "Joseph Ruttenberg", "First Family of Competitive eating", "Valley Falls", "the Linen Hall", "Australia", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6355134688198363}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [0.6666666666666666, 0.4, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.04878048780487805, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.33333333333333337, 0.2608695652173913, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 0.9, 0.8235294117647058, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-1877", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-419", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_hotpotqa-validation-5224", "mrqa_searchqa-validation-1388"], "SR": 0.515625, "CSR": 0.5502232142857143, "EFR": 0.9354838709677419, "Overall": 0.7062820420506913}, {"timecode": 56, "before_eval_results": {"predictions": ["Fortress", "peso", "Nucleus", "steroids", "the future", "Stalin", "water", "ovulation", "Python", "William Proxmire", "George Orwell", "Takana", "wood", "Coach Carter", "herbivore", "one small step", "Psycho", "lawsuits", "Athens", "", "zoo", "Have You Neverbeen Mellow", "Mickey Gilley", "Oral Roberts", "employees", "Constantine XI", "tin", "Ganges", "Captain Nemo", "Dave Brubeck", "She Wore a Yellow Ribbon", "Soul", "Danville, Virginia", "Jupiter", "spiders", "Apple", "depression", "the Mausoleum at Halicarnassus", "Act One", "diamonds", "Rhapsody in Blue", "the", "Vodka", "Ronald Reagan", "Mount Kilimanjaro", "militias", "Delaware", "Graceland", "Russian", "Don", "the id", "President John F. Kennedy", "Ishaan Anirudh Sinha", "in the pouring rain at a rest stop", "Munich", "the Circle line", "1123", "Julie Kavner", "Benedict of Nursia", "A Boltzmann machine", "Abbey Road", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.421875, "QA-F1": 0.48020833333333335}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-1616", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-279", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-14560", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-15974", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-5209", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-8353", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-4868", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658"], "SR": 0.421875, "CSR": 0.5479714912280702, "EFR": 1.0, "Overall": 0.718734923245614}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "bamboo", "Merlin", "(the) round", "Alien", "Think Big", "Mariachi", "a bottle", "painful", "Kilimanjaro", "an opinion", "Francis Ford Coppola", "a", "the pope", "Vancouver", "x", "New York", "tortuga", "Thomas Paine", "Isaac Newton", "American Wedding", "Anthony Michael Hall", "Tears for Fears", "Jamestown", "the Rhine", "blacksmith", "Mohs", "Katharine McPhee", "October 7, 1913", "Purple Rain", "Cnut the Great", "spiral", "Dana Perino", "egg", "(Vijay) Singh", "geometric", "Baton Rouge", "Daniel Boone", "Chariots of Fire", "a salamander", "Sweden", "pink", "eyes", "Hong Kong", "The Addams Family", "a", "Joe Lieberman", "Bait-and-switch", "Winston Churchill", "New Year's", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "Timothy Dalton", "University of Oxford", "1,467", "Vision of Love", "alleged abuse.", "Paul Schlesselman", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5984375}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-2637", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-7113", "mrqa_searchqa-validation-11647", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-2121", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-9976", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-12380", "mrqa_searchqa-validation-7507", "mrqa_searchqa-validation-5688", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803"], "SR": 0.53125, "CSR": 0.5476831896551724, "EFR": 0.9666666666666667, "Overall": 0.7120105962643678}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "a full tropical garden", "engaging with the Taliban in Pakistan and Afghanistan.", "tells stories of different women coping with breast cancer in five vignettes.", "the funds for housing, business and infrastructure repairs, federal authorities said.", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty.", "school", "Asashoryu", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "China", "\"I never thought any of this was going to be easy,\"", "the chief executive officer, the one on the very top,", "ancient rituals", "the corpse, whose head was lying behind the meteorologist's shoulder,", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "the military trial system", "183", "Nirvana", "Patrick McGoohan,", "55-year-old", "Zimbabwe President Robert Mugabe", "new Touch", "The woman who received the first-ever near-total face transplant in the United States", "International Polo Club Palm Beach in Florida.", "President Bush", "All three pleaded not guilty in an appearance last week in Broward County Circuit Court.", "1000 square meters in forward deck space", "the United States can learn much from Turkey's expertise on Afghanistan and Pakistan", "look as easy as Fred Astaire dancing down a staircase.", "a three-story residential building in downtown Nairobi.", "cancer", "Hussein's Revolutionary Command Council.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "people", "Rev. Alberto Cutie", "Nairobi, Kenya,", "magazine", "FBI Special Agent Daniel Cain,", "farmer Alan Graham", "February 12", "Ensenada, Mexico", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "skirts during daily prayers, or they will be temporarily shut down,", "trading goods and services without exchanging money", "three people", "two", "Some of them told CNN they couldn't afford to pay for cable or satellite TV service.", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing.", "Ben Roethlisberger", "Taylor Michel Momsen", "Nick Grimshaw", "In late - 2011", "m69", "Zaire", "pasta", "DreamWorks Animation", "Debbie Harry", "2004", "a face cord", "Brian Slade", "Existentialism", "Efrem Zimbalist Jr."], "metric_results": {"EM": 0.5, "QA-F1": 0.5757963956333522}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.17391304347826086, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.18181818181818182, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.2222222222222222, 0.33333333333333326, 1.0, 0.6666666666666666, 0.0, 0.0, 0.41666666666666663, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-3948", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-6426", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.5, "CSR": 0.546875, "EFR": 0.90625, "Overall": 0.6997656250000001}, {"timecode": 59, "before_eval_results": {"predictions": ["white", "Pakistan", "DTM", "Vernon Kay", "Everglades", "ten episodes", "Tyler Posey", "Betty Cohen", "Scandinavian design", "the Bentley Twins", "Pasek and Paul", "publicly available", "Oregon", "Mrs. Eastwood & Company", "Blackpool Football Club", "Denver, Colorado", "Edward M. Kennedy", "Boeing EA-18G Growler", "21st Century Fox", "Harrisburg", "Danielle Fernandes Dominique Schuelein- Steel", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "North Atlantic Treaty Organisation", "the Nawab of Pataudi Jr.", "authoritarian", "AOL Inc.", "World War II", "coca wine", "Barack Obama", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "Best Supporting Actress", "New Jersey", "Ian Rush", "Erich Maria Remarque", "Australian", "youngest TV director ever", "Arthur William Bell III", "Henry J. Kaiser", "Delaware River", "Jean Acker", "Anheuser-Busch InBev", "MG Car Company Limited", "Boston Celtics", "May 2008", "the second in a set of 19 Hungarian Rhapsodies", "24 hours later", "Brian Steele", "from 35 to 40 hours per week", "Ceefax", "Dieppe Raid", "Herrenhausen", "Capitol Records,", "228", "The son of Gabon's former president", "stocks", "Thomas Alva Edison", "Han Solo", "Longo-Ciprelli"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6727327360139859}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, true, true, true, false, true, true, false, false, false, true, false, true, false, false, false, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666665, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.18181818181818182, 0.8, 1.0, 0.923076923076923, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-4375", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-5066", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-2131", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5286", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-4248", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3372", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-8673", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6758", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-10636"], "SR": 0.546875, "CSR": 0.546875, "EFR": 0.9655172413793104, "Overall": 0.7116190732758622}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "the plane was in fine condition at takeoff,", "Joan Rivers", "'We want to reset our relationship and so we will do it together.'\"", "Alison Sweeney", "the Carrousel du Louvre", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "Pete Docter", "at least 25", "269,000", "flooding was so fast that the thing flipped over,\"", "which type of guy you should avoid", "Patrick McGoohan,", "ambassadors", "NATO", "man's lifeless, naked body", "hanged in 1979", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "people", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell", "\"wider relationship\"", "Best Picture winner", "Noida, located in the outskirts of the capital New Delhi.", "body bags", "Afghanistan,", "10 to 15 percent", "He prepared his formal asylum request Tuesday at the airport with the help of a translator, filing it around 1 p.m.", "Donald Trump", "an engineering and construction company", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "At least 15", "four people believed to be illegal immigrants", "a one-of-a-kind navy dress with red lining", "a monthly allowance", "Too many glass shards left by beer drinkers in the city center,", "legitimacy of that race.", "Nigeria", "Andrew Morris,", "one day we will have no more oil and we'll have to find another way to live.", "Drottningtorget", "a senior at Stetson University studying computer science.", "the family's blog", "his cousin D\u00e1in", "the Mayor's son", "the American Civil War", "T.S. Eliot", "green", "Australia and Ireland", "18 December 1975", "1970", "Copenhagen", "The Pacemakers", "Khartoum", "Stand by Me", "French"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5716142944028384}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.14285714285714288, 0.19047619047619047, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.04761904761904762, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.4444444444444445, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913045, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2923", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-9604", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-2599", "mrqa_hotpotqa-validation-4172", "mrqa_searchqa-validation-6409", "mrqa_hotpotqa-validation-2403"], "SR": 0.484375, "CSR": 0.5458504098360656, "EFR": 0.9090909090909091, "Overall": 0.7001288887853949}, {"timecode": 61, "before_eval_results": {"predictions": ["allergic reaction to peanuts,", "F-14", "Santaquin City, Utah, home", "It has not intercepted any", "Ed McMahon", "Bob Bogle", "183", "Russia: Moving Forward", "in a 4-1 Serie A win at Bologna on Sunday", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "Tuesday afternoon", "General Motors'", "Four", "Mark Fields", "Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "16 Indiana National Guard soldiers", "the body of the aircraft", "Venus Williams", "college campus.", "The cervical cancer vaccine,", "Bright Automotive,", "Kingdom City", "Europe", "$7.8 million", "Polo because \"it was the sport of kings.", "The elections are slated for Saturday.", "City", "surgical anesthetic propofol", "she was humiliated by last month's incident, in which she was forced to reluctantly remove the piercings", "CNN", "school,", "Hurricane Gustav", "The cervical cancer vaccine, approved in 2006, is recommended for girls around 11 or 12.", "two", "outfit from designer", "the two bodies out of the plant,", "misdemeanor assault charges", "the man facing up, with his arms out to the side.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines", "Cambodia", "Arsene Wenger", "The local Republican Party", "the Gulf", "former Procol Harum bandmate Gary Brooker", "27", "In this month, Venezuelan President Hugo Chavez, whose comments have frequently antagonized Washington, said it would welcome the Russian air force, according to Russian news agency Novosti.", "housing, business and infrastructure repairs,", "travel in cars with tinted windows -- which protected me from identification by terrorists -- or travel with privately armed guards.", "toys or doorbell installations", "British citizens", "Justin Timberlake", "Greece", "Brighton", "eagle", "Umberto II", "The Longest Yard", "Lucille D\u00e9sir\u00e9e Ball", "Louis XIV", "the Bronx", "Flamboyant", "South Africa"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7358652505779953}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.22222222222222224, 0.5, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7906976744186047, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-2168", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-3250", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_hotpotqa-validation-2827"], "SR": 0.640625, "CSR": 0.5473790322580645, "EFR": 0.8695652173913043, "Overall": 0.6925294749298738}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0 draw away to Saudi Arabia", "portrait of William Shakespeare", "Al Gore.", "200", "rapper T.I.", "media", "Friday,", "carving in the middle of our Mountain View, California, campus.", "Arizona", "is the U.N. nuclear watchdog agency's strongest warning yet that Iran could be aiming to build a nuclear bomb.", "assassinated", "56,", "China, Taiwan, Hong Kong and Mongolia,", "former Boca Juniors teammate and national coach", "Fernando Caceres", "the license plate \"BADBUL,\"", "Nirvana frontman,", "nude beaches.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "a residential area in East Java", "\" Body Works\"", "the Nuclear Non-Proliferation Treaty in 2003.", "supermodel", "10 below", "1,073", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends to secure a visitor's visa and bus ticket to Johannesburg.", "girls around 11 or 12.", "passengers on the Miva Marmara", "food, music, culture and language of Latin America", "cancerous tumor.", "Tennessee", "Bright Automotive,", "nuclear", "changed the way the world consumed media", "exploration traded in for the comforts of home and domestic Bliss.", "165-room", "\"Oprah is an angel, she is God-sent,\"", "al Qaeda,", "the case of a man accused of sexually assaulting a toddler and capturing it on videotape years ago,", "Sharon Tate", "Charlotte Gainsbourg and Willem Dafoe", "daughter, Zeina,", "Omar", "Chinese President Hu Jintao", "United States", "Nakheel Tower", "speaking out about a cause someone feels passionate about.", "25 years.", "Anil Kapoor", "President Obama and Britain's Prince Charles", "Wembley Stadium", "a ligand - binding site on a receptor or enzyme", "40.5 metres ( 133 ft )", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Robert Arthur Mould", "331 episodes", "2006", "Ruth Bader Ginsburg", "The Big Sleep", "Seth", "cock"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5269722314219596}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, false, true, false], "QA-F1": [0.5, 0.4, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.1818181818181818, 0.0, 0.25, 0.0, 1.0, 0.14285714285714288, 0.6, 1.0, 0.5, 0.0, 0.5, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.08695652173913043, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.26666666666666666, 1.0, 0.22222222222222224, 0.6153846153846153, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-1956", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-3715", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746", "mrqa_triviaqa-validation-3869"], "SR": 0.421875, "CSR": 0.5453869047619048, "EFR": 0.8918918918918919, "Overall": 0.6965963843307594}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the Dalai Lama", "about the shootings, handed over the AR-15 and two other rifles and left the cabin.", "The Detroit, Michigan, radio station promotion held three years ago", "the German Foreign Ministry,", "$89", "South African ministers and the deputy president", "Pakistan", "Japan's", "urged NATO to take a more active role in countering the spread of the", "poor.", "striker", "Sixteen", "poems", "Iowa,", "Monterrey,", "a youth ballpark in his hometown of Aberdeen, Maryland,", "Golden Gate Yacht Club of San Francisco", "at least 300", "a national telephone survey of more than 78,000 parents", "ballots", "And if Planet Solar completes its mission, the crew says that will be proof that the sun, and solar power, is the answer.", "the Obama and McCain camps", "The Ministry of Defense", "part of the proceeds", "The minister later apologized, telling CNN his comments had been taken out of context.", "Fernando Torres", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars.\"", "civilians,", "March 3, 2008", "people thought this was a small problem,\"", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Christianity and Judaism,", "The Casalesi Camorra clan", "May 4", "tranquil beaches,", "$1.5 million", "Booches Billiard Hall,", "\"peregruzka\"", "since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama Action", "Kimberlin Brown", "A turlough, or turlach", "1933-1934", "James Donald", "Radio City Music Hall", "Vikram, Jyothika and Reemma Sen", "the Dutch Empire", "Royal Navy rank of Captain", "Department of Homeland Security", "a French colony", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7000262758075257}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false], "QA-F1": [1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.15384615384615383, 1.0, 1.0, 0.5454545454545454, 1.0, 0.07692307692307691, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-4210", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-2353", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-7047", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-8244", "mrqa_naturalquestions-validation-10396"], "SR": 0.59375, "CSR": 0.546142578125, "EFR": 0.9615384615384616, "Overall": 0.7106768329326923}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser,", "sportswear", "15-year-old", "July 23.", "Alwin Landry", "an American who entered the country illegally from China on Christmas Eve.", "Chester Stiles,", "United States", "Pakistan's High Commission in India", "Wednesday.", "Wigan Athletic", "Adriano", "poems", "Orlando police", "A 22-year-old college student in Boston, Massachusetts,", "sniff out cell phones.", "Longo-Ciprelli", "\"The Screening Room\"", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944,", "\"I'm just getting started.\"", "light snow or flurries", "more than 30", "his entire personal fortune of more than 30 billion won ($30.2 million) to the poor.", "refused to refer the case of Mohammed al-Qahtani to prosecutors", "laundromats", "rural California,", "Robert Park", "11th year in a row.", "83 eggs.", "future relations between the Middle East and Washington.", "school.", "a plaque at the home of his great-grandfather", "death squad killings", "a nuclear weapon", "Kitty Kelley", "\"The missile defense system is not aimed at Russia,\"", "Multnomah Falls, about 90 miles east.", "Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "a clear strategy that was stuck to with remarkably little internal drama. He won it with unparalleled fundraising and an overwhelming ground game. And he won it after facing various challenges and turning them to his advantage.", "$3 billion,", "Crap E-mail From A dou", "Bobby Jindal", "he acted in self defense in punching businessman Marcus McGhee.", "potential revenues from oil and gas", "Sen. Barack Obama", "jobs", "angular rotation", "in a geographical coordinate system at which longitude is defined to be 0 \u00b0", "Darlene Cates", "Colette", "crow", "Rhys Williams", "2015", "11", "January 15, 2016", "piano", "Jordan", "Barnard College", "Chiltern Hills"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6441295632136504}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, true, false, true, true, true, false, false, false, true, true, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 0.888888888888889, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.125, 0.8181818181818181, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.90625, 1.0, 0.0, 1.0, 0.10526315789473685, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-2205", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-827", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-690", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-4278"], "SR": 0.515625, "CSR": 0.5456730769230769, "EFR": 0.8387096774193549, "Overall": 0.6860171758684863}, {"timecode": 65, "before_eval_results": {"predictions": ["banned substance cortisone.", "Larry Zeiger", "The Ski Train", "housing, business and infrastructure repairs,", "Officer Joe Harn", "Port-au-Prince, Haiti", "Saudi Arabia", "Israel", "Nigeria, Africa's largest producer.", "Mexico", "two Metro transit trains that crashed the day before, killing nine,", "short- and long-range weapons", "Denver, Colorado.", "Jeffrey Jamaleldine took a bullet to his chin that blew out much of his jaw and nearly killed him while deployed in Iraq last year.", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "a strong work ethic", "The meter reader who led authorities last week to remains believed to be those of Caylee Anthony", "could be secretly working on a nuclear weapon", "delivered three machine guns and two silencers to the hip-hop star,", "Karen Floyd", "GOP state senators", "people are going to look at the content.", "April 22.", "Colombian police", "outfit from designer", "two", "Ozzy Osbourne", "Sarah,", "Carol Browner", "people were throwing Molotov cocktails, rocks and glass.", "eight.", "Fullerton, California,", "Hawaii on July 4.", "Bill Haas", "A Lion Among Men.", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Kr\u00f8yer", "Gyanendra,", "to show that a visitor had been to the grave.", "Adam Yahiye Gadahn, also known as Azzam the American,", "Turkey", "Polo because \"it was the sport of kings. It was glamorous, sexy and international.\"", "Texas and Oklahoma to points east,", "fast cars, drink and celebrity parties.", "resources", "a million", "New York", "The 19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "-- you know -- black is beautiful,\"", "Arnold Schoenberg", "N\u0289m\u0289n\u0289", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "Einstein", "Nova Scotia", "pyrotechnic", "Battelle Energy Alliance", "Lake County, Illinois", "Eran Kolirin", "cryptids", "Tigers", "Herod", "leopard"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5357360227263015}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, true, false, true, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false], "QA-F1": [0.5, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5263157894736842, 0.0, 0.2222222222222222, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.06666666666666667, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5454545454545454, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 0.0, 0.782608695652174, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3233", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-208", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.4375, "CSR": 0.5440340909090908, "EFR": 0.9444444444444444, "Overall": 0.7068363320707072}, {"timecode": 66, "before_eval_results": {"predictions": ["Spanish Davis Cup hero Fernando Verdasco, who swept past young Croatian star Marin Cilic 6-2 7-5.", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "Iran's nuclear program.", "green-card warriors", "a space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Booches Billiard Hall,", "Both men were hospitalized and expected to survive,", "Harris won two awards.", "Pfc. Bowe Bergdahl", "Lebanese heritage,", "President Bush", "$17,000", "Employee Free Choice Act", "assassination of President Mohamed Anwar al-Sadat at the hands of four military officers during an annual parade celebrating the anniversary of Egypt's 1973 war with Israel.", "Herman Thomas", "The worst snowstorm to hit Britain", "Arnold Drummond", "Madonna", "the content of the speech, not just the delivery.", "the Bush administration's controversial system of military trials", "a traditional form of lounge music that flourished in 1940's Japan.", "Larry King", "250,000 unprotected civilians", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "managing his time.", "1980,", "Omar", "Scotland", "Mugabe's opponents", "a Tutsi ethnic minority and the Hutu majority had been at odds even before 1994.", "his business dealings for possible securities violations", "January", "The Great Barrier Reef -- which is composed of about 2,900 individual reefs and is off the northeast coast of Australia -- is seeing limited bleaching now,", "9-week-old", "dental work", "Sovereign Wealth Funds", "fake his own death by crashing his private plane into a Florida swamp.", "was seven months pregnant at the time of her death,", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the difference,\"", "Apple Inc.", "38", "terrorists operating within its borders.", "Henrik Stenson", "1995", "The minivan's driver fled the scene and was later arrested,", "fear of losing their licenses to fly.", "Anjuna beach in Goa", "\"You can go from rags to riches there. People still believe in that. It is not something that has gotten lost,\"", "not doing more since taking office.", "Television demonstrations", "American Indian allies", "naturalization law for the United States, the Naturalization Act of 1790", "Sigurd the Dragonslayer", "blancmengier", "apples", "Manhattan Project", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "Joplin", "Italy", "I.M. Pei", "( Numbers 22 : 22 )"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5911545049887977}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16, 0.6666666666666666, 0.33333333333333337, 0.0, 1.0, 0.8571428571428571, 0.7272727272727273, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.0625, 1.0, 0.0, 1.0, 1.0, 0.39999999999999997, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.10526315789473685, 0.18181818181818182, 0.4, 0.5, 0.0, 0.6666666666666666, 0.0, 0.2105263157894737, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-3383", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_naturalquestions-validation-230"], "SR": 0.4375, "CSR": 0.5424440298507462, "EFR": 0.9444444444444444, "Overall": 0.7065183198590381}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "Autobahn", "a menorah", "Jaipur", "tea", "the Ordovices", "Martin Pipe", "Wordsworth", "Ginger Rogers", "a bus window", "borax", "United States Dollar", "peregrines", "5th", "muscle tissue", "hurdling", "Derby Stakes", "Singin'", "Basketball", "HMS Amethyst", "lion", "sergeant", "British POWs build a vital railway bridge in enemy-occupied Burma,", "Cyprus", "King George VI", "ankle joint", "Greyfriars", "honeycomb", "fleas", "a white robe", "The Big Bopper", "NBA", "Hartley", "Leander", "Arsenal", "entropy", "Mrs. Peacock", "green", "elia Earhart", "James Hogg", "lacrimal fluid", "Laufey", "The Apartment", "Manfred von Richthofen", "Cain", "1879", "Los Angeles", "Loch Lomond", "isosceles", "black", "ballet", "Boston Red Sox", "1967 onwards", "absolute zero", "Bolshoi Theatre", "My Boss, My Hero", "mermaid", "death squad killings", "between South America and Africa.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "a hiccup", "the bumblebee", "36 months old"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6313988095238096}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, true, false, true, false, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.7142857142857143, 1.0, 1.0, 0.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-4575", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-4883", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_searchqa-validation-7851", "mrqa_naturalquestions-validation-8352"], "SR": 0.546875, "CSR": 0.5425091911764706, "EFR": 0.9655172413793104, "Overall": 0.7107459115111563}, {"timecode": 68, "before_eval_results": {"predictions": ["Bed and breakfast", "smen", "near the city of Cairo, Illinois", "the Americans", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "2018", "California's Del Norte Coast", "Zuzu & Zaza Zebra", "257,083", "Puerto Rico ( Rich Port )", "Harold Godwinson", "Gustav Bauer", "Shawn", "if the concentration of a compound exceeds its solubility", "the Western Bloc ( the United States, its NATO allies and others )", "1603", "the `` round '', the rear leg of the cow", "1957", "360", "118", "into the gastrointestinal tract", "Lori McKenna", "Wisconsin", "Tbilisi", "the Latin centum", "1799", "Paul", "His last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "Elvis Presley", "2009", "thirteen Academy Award nominations", "Sweden's long - standing policy of neutrality was tested on many occasions during the 1930s", "291 episodes", "Cairo, Illinois", "Lana Del Rey", "Steve Russell", "the most times", "4 January 2011", "New Zealand to New Guinea", "Bill Russell", "Seattle, Washington", "the temporal lobes", "2010", "Buddhism", "first composed in the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units within the National Health Service in England", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "1956", "april", "fearful man, all in coarse gray with a great iron on his leg", "huff & puff: Can You blow down the third pig\u2019s brick home?", "Brad Silberling", "1941", "Nick on Sunset theater", "July in the Philippines", "iCloud service will now be integrated into the iOS 5 operating system. It will work with apps and allow content to be stored", "Thursday", "bonobos", "side", "the Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6477991290743307}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.923076923076923, 0.3636363636363636, 1.0, 0.888888888888889, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5555555555555556, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.3076923076923077, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.5, 0.16666666666666669, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_newsqa-validation-2251", "mrqa_searchqa-validation-3351", "mrqa_searchqa-validation-12035"], "SR": 0.53125, "CSR": 0.5423460144927537, "EFR": 0.9666666666666667, "Overall": 0.7109431612318841}, {"timecode": 69, "before_eval_results": {"predictions": ["Whitechapel", "Uganda", "The Proposal", "Brazil", "Atlas", "pieces capture opponent's pieces by moving to the square that the opponent's piece occupies.", "Bristol", "Florida", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "Cambridge", "daltonism", "Cambodia", "Prussian Landsturm", "Russia", "novel", "a co-  operative", "180", "blue", "Tommy Burns", "james Bond", "Andre Agassi", "hawks", "The Times of India", "le le Carr\u00e9", "Papua New Guinea", "Albania", "animals", "mata hari", "different levels of importance of human psychological and physical needs", "polo", "gulliver", "a Nationally Recognized Statistical Rating Organization", "Saturday Night Live", "Bayern Munchen", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "Cleopatra  In 41 B.C. Antony began an affair with the Egyptian queen Cleopara, who had been Caesar\u2019s lover in the last years of his life.", "wagons", "One Canada Square", "Snoopy", "auk", "The Hunting of the Snark", "general strike to support mine workers", "kunagawa", "Richmondshire", "Walter Mondale", "fresh nuclear fuel", "the plane crash in 1959", "Scotty Grainger Jr.", "The Kingkiller Chronicle", "3.9 mi", "$1.5 million.", "buddhism", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "Space Shuttle", "Smithfield", "Ivan Denisovich", "10 Years"], "metric_results": {"EM": 0.5, "QA-F1": 0.5661922995482778}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.08695652173913045, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.8, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-608", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-3541", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-16464"], "SR": 0.5, "CSR": 0.5417410714285714, "EFR": 0.9375, "Overall": 0.7049888392857143}, {"timecode": 70, "before_eval_results": {"predictions": ["leigh Ann Fetter", "three", "high jump", "s Stephen Hawking", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "grape plagues", "teaching evolution in violation of a Tennessee state law.", "Philip Larkin", "numbria", "Kent", "hedgehog", "jack Brabham", "peterborough indy", "hanover", "algebra precalculus", "clifden", "peter sampras", "ch\u00e2lons", "the Red sea", "cats", "The French Connection", "leon blair", "moaning Myrtle", "lago di Como", "Dubai", "CeeLo Green", "photographer", "Justin Bieber", "Ionian", "m\u00e1qu\u00e8", "scar", "stars on 45 Medley", "chiletenham & Gloucester", "bowie knife", "Istanbul", "meryl Streep", "Achille Lauro", "Botham", "stop motion effects", "lemullet", "Ellis Island", "Melanesian", "trapezoid", "Dick Advocaat", "John Huston", "starry starry night", "Anthony Hopkins", "Martin Vanuren", "Moscow", "2005", "the governor of West Virginia, who is elected to a four - year term at the same time as presidential elections", "Payaya Indians", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman is in critical condition in a Provo, Utah, hospital,", "2010", "Uzbekistan.", "Jerry Rice", "leotard", "Ford", "place"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5371550324675325}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, true, false, false, true, true, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.36363636363636365, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.38095238095238093, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-6644", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-4502", "mrqa_triviaqa-validation-3914", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-3881", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-7032", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_naturalquestions-validation-4207", "mrqa_naturalquestions-validation-368", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-2817"], "SR": 0.46875, "CSR": 0.540713028169014, "EFR": 0.8529411764705882, "Overall": 0.6878714659279205}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California (USC) Trojans", "1935", "James Worthy", "David Weissman", "test pilot, and businessman.", "Kim Sung-su", "British", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "L\u00edneas A\u00e9reas", "October 15, 2013", "Neha Sharma", "the Netherlands", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York.", "1853", "Kew", "Apprendi v. New Jersey", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "Kristin McGee", "11", "tempo", "approximately 20 mi west of central London, and 7 miles", "1942", "Pollywood", "Carver Dana Andrews", "July 25 to August 4", "2015", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "special economic zone", "Darkroom", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "Guant\u00e1namo Bay in Cuba", "France", "Wordsworth", "Spain", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "\"wipe out\" the United States if provoked.", "two years,", "Yahtzee", "Hinduism", "60 Minutes", "\"The closest approach to the original sound\""], "metric_results": {"EM": 0.75, "QA-F1": 0.8282142857142857}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 0.25, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2059", "mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-214", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.75, "CSR": 0.5436197916666667, "EFR": 0.875, "Overall": 0.6928645833333335}, {"timecode": 72, "before_eval_results": {"predictions": ["read therefore", "showed such a disregard for the life and safety of others as to amount to a crime and deserve punishment", "100,000", "2004", "the NFL", "9th century", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Tony Orlando and Dawn", "2014 Winter Olympics in Sochi, Russia", "the Pir Panjal Range", "nearby objects show a larger parallax than farther objects when observed from different positions", "Iraq", "1885", "the final episode of the series", "Wisconsin", "the past record of geomagnetic reversals was noticed by observing the magnetic stripe `` anomalies '' on the ocean floor", "the stems and roots of certain vascular plants", "the Mahalangur Himal sub-range of the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "an Islamic shrine", "the American League ( AL ) champion Kansas City Royals", "Massachusetts", "Mark Jackson", "John Coffey", "the 180th meridian in a 360 \u00b0 - system", "need to repent in time", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane, resulting in an electrical potential or ion concentration difference across the membrane", "Kida", "Instagram's own account, with over 234 million followers", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "Elvis Presley", "the federal government", "2013", "England", "the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "when the cell is undergoing the metaphase of cell division", "79", "Yugoslavia", "the cell copies its DNA in preparation for mitosis", "In England, births were initially registered with churches, who maintained registers of births", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "seven", "Ben Savage", "Virginia", "Dante Pastula", "Daya Jethalal Gada", "centralized administrative planning", "Gunpei Yokoi", "the Alamodome", "de Havilland Moth", "architecture", "Bermuda", "win world titles in four weight classes", "the number of men killed and the manner of the attacks.", "Neymar", "22", "opium", "Roger Federer", "Parody", "a prostitute", "Ashlee Simpson", "germany"], "metric_results": {"EM": 0.5, "QA-F1": 0.5779755747724498}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false, true, false, false, true, true, false, true, false, true, false, true, true, true, true, true, false, true, false], "QA-F1": [0.125, 0.8095238095238095, 0.07999999999999999, 1.0, 1.0, 1.0, 0.3076923076923077, 1.0, 0.2857142857142857, 0.6, 0.14285714285714288, 0.0, 0.4, 1.0, 1.0, 0.5714285714285715, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7692307692307692, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-1848", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-7409", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-10347", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_triviaqa-validation-1421", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-3407", "mrqa_triviaqa-validation-4962"], "SR": 0.5, "CSR": 0.5430222602739726, "EFR": 0.90625, "Overall": 0.6989950770547946}, {"timecode": 73, "before_eval_results": {"predictions": ["The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Kirstjen Nielsen", "December 14, 2017", "Barbara Windsor", "ninth w\u0101", "British Ultra code - breaking intelligence", "Bart Millard", "Jesse Wesley Williams", "Spencer Treat Clark", "1910", "FIGG Bridge Engineers, a Tallahassee - based firm", "John Smith", "Joanne Wheatley", "Everywhere", "Watson and Crick", "September 29", "Lead and lead dioxide", "India", "Taylor Michel Momsen", "Magnavox Odyssey", "The Lightning thief", "2015", "1971", "Sara Gilbert", "1962", "Help!", "John Smith", "Katharine Hepburn", "Arnold Schoenberg", "the national and state legislatures", "203", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a Vampire", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Charlton Heston", "1878", "to `` help bring creative projects to life ''", "Joan Baez", "Senator Joseph McCarthy", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Saturn", "clogs", "Reggie", "Tampa", "1874", "January 28, 2016", "Jaipur", "fifth successive", "in July", "taro", "Match Game", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.625, "QA-F1": 0.6918311403508772}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, false, true, true], "QA-F1": [0.8666666666666666, 0.21052631578947367, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-9521", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-9160", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2866", "mrqa_triviaqa-validation-249", "mrqa_newsqa-validation-2749", "mrqa_searchqa-validation-2100"], "SR": 0.625, "CSR": 0.5441300675675675, "EFR": 0.9583333333333334, "Overall": 0.7096333051801802}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland Raiders", "Russell Stover Candies", "circle", "submarine", "Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "Manic Street Preachers", "togo", "a blitz", "new wave", "a commune", "a ring", "Thames", "the breath", "ice hockey", "fairy tales", "David", "The Color Purple", "whales", "Jane Addams", "Queen Elizabeth", "Tanzania", "Biosphere 2", "inch", "death", "Henry Wadsworth", "Fred Thompson", "Geneva", "humility", "bdellium", "Twelve Thirty", "diatom", "the debt ceiling", "pig", "Lake Titicaca", "Existentialism", "ashes", "emperor", "Jack London", "Isaac Newton", "Charles I", "Kevin Costner", "Apocalypse Now", "treble clef", "uranium", "Louisiana", "The Hot Chick", "Red Worm", "August 21", "1990", "four", "Spey", "Popeye", "Denmark", "Trappist beer", "5,656", "Steve Prohm", "seven", "Airbus A330-200", "Symbionese Liberation Army", "Manitowoc County"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6291666666666667}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false], "QA-F1": [0.6666666666666666, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-10874", "mrqa_searchqa-validation-14913", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-10631", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-12518", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-7832", "mrqa_searchqa-validation-13598", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-8909", "mrqa_hotpotqa-validation-4527", "mrqa_hotpotqa-validation-1307", "mrqa_hotpotqa-validation-3458"], "SR": 0.546875, "CSR": 0.5441666666666667, "EFR": 0.9310344827586207, "Overall": 0.7041808548850575}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "James Bolam", "the main highway entrance at California State Route 1", "a marketing term for a vehicle that is both four - wheel - drive and primarily a road car", "Turing", "John B. Watson", "hydrogen", "Great Britain", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "9th century", "Asuka", "Jason Momoa", "Ashley Breckenridge", "the President", "Spanish missionaries, ranchers and troops", "Gustav Bauer", "art of the Persian Safavid dynasty from 1501 to 1722", "the main type of cell found in lymph", "around 2.45 billion years ago ( 2.15 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "Tevye", "March 31, 2017", "Incudomalleolar joint", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "Gupta Empire", "stable, non-radioactive rubidium - 85", "55 -- 69 %", "summer of 1979", "Charles Evans Hughes", "Spanish / Basque", "U.S. service members who have died without their remains being identified", "December 1349", "Glenn Close", "Robert Remak", "the Yankees", "studying All My Sons by Arthur Miller, a play about a man whose choice to send out faulty airplane parts for the good of his business and family caused the death of twenty one pilots during World War II", "International System of Units", "Rigg", "electron donors", "Bill Patriots", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "Green", "ourselves alone", "Orrest", "1967", "Yubin", "100 metres", "a drug reportedly found after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "boat's hull,", "'peregruzka,' which means 'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's", "Patrick Henry", "Samuel Joel \" Zero\" Mostel"], "metric_results": {"EM": 0.609375, "QA-F1": 0.74765625}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.25, 0.9333333333333333, 0.0, 1.0, 0.33333333333333337, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-8004", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-5135", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_searchqa-validation-3069", "mrqa_hotpotqa-validation-3909"], "SR": 0.609375, "CSR": 0.5450246710526316, "EFR": 0.88, "Overall": 0.6941455592105263}, {"timecode": 76, "before_eval_results": {"predictions": ["tintoretto", "drambuie", "repechage", "hanland", "Victoria Rowell", "Costa Brava", "Northumberland", "Chickens", "steerpike", "Normandie", "Bleak House", "four", "the Indus Valley", "Selfie", "jaws", "Charlie Cairoli", "Utrecht", "Adidas", "Coldplay", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "conclave", "Patrick Kielty", "8 minutes", "Ross", "Red Crescent", "Schumann", "Margaret Thatcher", "Hooky Street", "sam & Mark", "Andrew Lloyd Webber", "Bonn", "vice-admiral", "snakes", "Coral Sea", "Constantine", "Madonna", "bogey", "Millerlite beer", "elbow", "Ice Age", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Emilia", "Hawley Harvey Crippen", "fifty-six", "1822", "1979", "1976", "Gupta Empire", "Rogue One", "2004", "Rwandan genocide", "Steve Williams", "winter storm with heavy snow and ice was heading from Texas and Oklahoma to points east,", "fight outside of an Atlanta strip club on October 3,", "seasonal affective disorder", "timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.640625, "QA-F1": 0.7009796626984127}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.25, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-157", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-1241", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-1278", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.640625, "CSR": 0.5462662337662338, "EFR": 0.6956521739130435, "Overall": 0.6575243065358555}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1801", "Captain Cook's Landing Place", "M2M", "Helen Mirren", "FX", "president of Guggenheim Partners", "Diamond Rio", "lola Dee", "master builder", "UFC 50: The War of '04", "Anthony John Herrera", "Rounders", "24 hours a day and 7 days a week", "\"O\" theatre", "half of the Nobel Prize in Physics", "glee", "Paul Corbould", "Ontogenetic depth", "2 November 1902", "December 1993", "orisha", "2006", "highest commissioned SS rank", "Dziga Vertov", "The Bonnie Banks o' Loch Lomond", "National Football League", "brothers", "James Franco", "London", "Kelly Bundy", "British-American", "Spitsbergen in Svalbard, Norway", "the Military Band of Hanover", "around 8000 BC", "2011", "Peter Seamus O'Toole", "Australia women's national soccer team", "Leonarda Cianciulli", "beer", "Biola University in La Mirada, California", "Eugene O'Neill", "Morita therapy", "the Surtees Racing Organisation team that competed as a constructor in Formula One, Formula 2 and Formula 5000 from 1970 to 1978.", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County, New York", "a bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Edd Kimber", "Mel Gibson", "1987", "San Francisco", "john johnson johnson", "Vancouver", "onto the college campus.", "nearly $106.5 million", "15-year-old's", "Cleopatra", "Arm & Hammer", "the Persian Gulf", "tambourine"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6790550595238095}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.28571428571428575, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.8, 0.8000000000000002, 1.0, 0.0, 0.5, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2100", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-2730", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-3101", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-3829", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-6460", "mrqa_newsqa-validation-900", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.546875, "CSR": 0.5462740384615384, "EFR": 0.9655172413793104, "Overall": 0.7114988809681698}, {"timecode": 78, "before_eval_results": {"predictions": ["Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "August 1991", "Nigel Lythgoe", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "1956", "Atlanta, Georgia", "The management team", "The legislation made two amendments to the Social Security Act of 1935", "1986", "Ali", "May 1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "fascia surrounding skeletal muscle", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "September 1947", "April 10, 2018", "the internal reproductive anatomy ( such as the uterus in females )", "May 2017", "mid-1980s", "DNA polymerase", "1956", "between 8.7 % and 9.1 %", "minor key symphonies", "Divyanka Tripathi", "Newfoundland", "Norway", "31 December 1960", "following graduation", "the winter solstice", "1992", "George Strait", "All Hallows'Day", "November 1961", "midpiece", "2004", "$19.8 trillion", "7000301604928199000", "James Martin Lafferty", "Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Sachin Tendulkar", "member states", "Andrew Lloyd Webber", "domestic cat", "Q", "Adam Werritty", "sheepskin", "5,922", "1866", "two", "2006", "eight or nine", "Lake Superior", "Thames", "Liceo", "red"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6337303919739264}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true], "QA-F1": [0.896551724137931, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.06060606060606061, 0.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.5714285714285715, 0.2222222222222222, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-1538", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-1302"], "SR": 0.546875, "CSR": 0.5462816455696202, "EFR": 0.9310344827586207, "Overall": 0.7046038506656482}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "2004 Nokia Sugar Bowl", "1858", "heavy metal", "Koon-hei Chen", "1875", "The The The Onion", "his most brilliant student", "Juilliard School", "The 1st World Outgames", "1812", "Peach", "1935", "the Philadelphia Eagles", "Victorian England", "The War of '04", "American", "superhuman abilities", "Alpine climate and landscapes", "Baudot code.", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "Sydney", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "Shameless", "from 1241 until his death in 1250", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis James Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1894", "London", "Bulgarian-Canadian", "James Mitchum", "Nick on Sunset", "Javed Miandad", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples", "Max", "smeagol", "Melbourne", "paddington bear", "54-year-old", "millions of Americans", "\"This is not something that anybody can reasonably anticipate,\"", "Richmond", "Venezuela", "Stone Age", "rally"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7586443070818071}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [0.4444444444444445, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4430", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-4416", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-4059"], "SR": 0.671875, "CSR": 0.5478515625, "EFR": 0.9047619047619048, "Overall": 0.699663318452381}, {"timecode": 80, "before_eval_results": {"predictions": ["a roman numeral", "chardonnay", "'is business", "beach volleyball", "\"Jack & Diane\"", "hot springs", "the Philosopher's Stone", "Dell", "pro bono", "American politician and businessman", "epitaphic", "Glenda", "a dragon", "rattus rattus", "Department of Chemistry", "The Merry Wives of Windsor", "kowtow", "Mars", "the Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "chemy", "Lon Chaney", "bread", "a katzenjammer", "Cuisinart", "travertine", "Bob Dole", "the Ross Ice Shelf", "director", "Bali", "coast", "Pinocchio", "the Czech Republic", "the opera house", "a bison", "go home", "Jodie Foster", "Cleopatra VII", "the Mummy", "White Fang", "the bollworm", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "1937", "53", "The Lightning thief", "Brazil", "Edinburgh", "Georgia", "Christina Claire Ciminella", "University of California", "Saturday Night Live", "a Yemeni cleric and his personal assistant", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy", "Joanne Wheatley"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6084821428571429}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4389", "mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9590", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813"], "SR": 0.546875, "CSR": 0.5478395061728395, "EFR": 0.9655172413793104, "Overall": 0.71181197451043}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "the Tasmanian government", "Indonesia", "The Generation Game", "The Firm", "red hair", "fourteen", "Spain", "Georgia", "Olivia Smith", "sow", "eucharist", "Turkey", "Anastasia Dobromyslova", "every ten years", "Matterhorn", "Lake Placid", "$10", "Liverpool", "Count Basie Orchestra", "Manhattan", "arch", "bar", "jubah", "bing.com", "peterborough", "Ambroz Bajec-Lapajne", "Apollo", "1963", "Bologna", "bear", "Coleraine", "Rebbie Jackson (born May 29, 1950)", "Timothy", "Addis Ababa", "motorcycle", "kidney", "Triumph", "salsa", "Mark Twain", "Doctor Who", "Yosemite National Park", "Microsoft", "40", "the First World War", "passion fruit", "HMS Thunderbolt", "7", "hannington", "100 years", "Benedict XVI", "Jesse Triplett", "Camping World Stadium in Orlando", "LED illuminated display", "41st", "Mel Blanc", "Mauthausen\u2013Gusen", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "antihistamine and an epinephrine auto-injector", "\"A Lion Among Men,\"", "Danny Elfman", "Bolivia", "an intercalary year", "Val Kilmer"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6076715225563909}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.5, 0.10526315789473684, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7685", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-1118", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_triviaqa-validation-6728", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-2103", "mrqa_searchqa-validation-14665"], "SR": 0.578125, "CSR": 0.5482088414634146, "EFR": 0.8518518518518519, "Overall": 0.6891527636630533}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "Grandmasters", "Virginia", "1,693", "Melville, NY", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "local level", "Tufts University", "Hammer", "Wiltshire", "Isla de Xativa", "gaoler's family", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Anosua Busia", "5.3 million", "six", "a polypeptide chain", "Brady John Haran", "Minette Walters", "Syracuse University", "first", "Florida Panthers", "2010", "Hallett Cove", "Juan Manuel Mata Garc\u00eda", "Malayalam", "Pittsburgh Steelers", "pronghorn", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "Durban International Convention Centre (ICC Arena)", "Kentucky Music Hall of Fame", "Taoiseach", "50th anniversary of the founding of the National Basketball Association (NBA)", "Indian", "the Corps of Discovery", "pubs, bars and restaurants", "Andrew Johnson", "Minnesota", "exercise power directly or elect representatives from among themselves to form a governing body, such as a parliament.", "illnesses", "Thomas Joseph \"T. J.\" Lavin", "the bank, rather than the purchaser, is responsible for paying the amount", "31 March 1909", "President Lyndon Johnson", "Celsius", "whooping cough", "Johannesburg", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Juri Kibuishi, 23,", "the sins of the members of the church,", "Superman", "Richard Nixon", "right", "Edward VIII"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7095376643550396}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.08695652173913043, 1.0, 0.7499999999999999, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-605", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-4519", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.609375, "CSR": 0.5489457831325302, "EFR": 0.96, "Overall": 0.7109297816265061}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys: Confessions of a Bad Girl Who makes Good", "Mickey Mantle & Maris", "the Titanic disaster", "a science", "Bill Clinton", "Graceland", "Cambodia", "elevator", "David Copperfield", "Arnold Schwarzenegger", "a nonsense", "a vowel", "a goat", "a pinball machine", "a leftwing theater group", "Dracula", "Niger", "a bagpipe", "Mrs. Miniver", "the Office", "Germany", "a keynote", "sheep", "Casey Jones", "Coward", "Hope", "the navy", "Dresden", "flippant", "Arkansas", "Marcel Duchamp", "a sloop", "toilet paper", "Sesame seeds", "Iceland", "a nocturnal mammal", "the Monty Hall Problem", "a bees", "Janet Reno", "Mark Twain", "Michelangelo", "Essen", "Appomattox", "Thailand", "the life", "a DELICIous DISH", "Pamela Anderson", "Theodor Seuss", "Whitehorse", "Scott McClellan", "Edd Kimber", "six", "Steffy Forrester", "Twin sisters", "John Denver", "Gargantua", "2017", "four", "Lester Ben \"Benny\" Binion", "India", "1959", "two remaining crew members", "her abusive husband"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6435661764705882}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.5882352941176471, 0.8, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7445", "mrqa_searchqa-validation-6754", "mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-7089", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-7382", "mrqa_searchqa-validation-15322", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-12607", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-3314", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-1331"], "SR": 0.5625, "CSR": 0.5491071428571428, "EFR": 0.9642857142857143, "Overall": 0.7118191964285715}, {"timecode": 84, "before_eval_results": {"predictions": ["Saint Anthony of Assisi", "roof", "Cuisinart", "the alveoli", "the Boston Massacre", "Truthful or creditable", "Simon Bolivar", "Little Red Riding Hood", "Abigail Adams", "Bank of America", "Cleopatra", "Colorado Springs", "Diamond", "Picasso", "the Custis-Lee Mansion", "Pope John Paul II", "hood", "Herakles", "South Dakota", "natural selection", "Secretary of the Interior", "Cyrus the Younger", "Humpty Dumpty", "Bo Schembechler", "Gucci", "Vermont", "chimp", "a desktop extender", "The Man in the Iron Mask", "New Zealand", "fashion model", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Doctor Moreau", "organs", "wheat", "tundra", "Peter Falk", "AARP", "Lord Nelson", "the Flag", "herb", "the stiletto", "cheese", "Kentucky", "Bora Bora", "Titanic", "the French Revolution", "the \"Fisherman's ring\"", "RBIs", "the foreign exchange market (FX )", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways", "Rome", "a sphere", "Disney California Adventure", "Lochaber, Highland, Scotland", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe", "Baku"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7192794184981686}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, false, true, false, true, true, false], "QA-F1": [0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.75, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.9743589743589743, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-13797", "mrqa_searchqa-validation-1686", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6001", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-15036", "mrqa_searchqa-validation-1137", "mrqa_searchqa-validation-11856", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-2374", "mrqa_hotpotqa-validation-2558", "mrqa_newsqa-validation-1793", "mrqa_triviaqa-validation-5654"], "SR": 0.59375, "CSR": 0.5496323529411764, "EFR": 1.0, "Overall": 0.7190670955882353}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "Old Lady", "Cochise", "Langhorne Clemens", "Joyce", "The Big Red One", "a orgeat", "endodontist", "a desktop microcomputer", "South Dakota", "Pinkerton", "Frasier", "George B. McClellan", "Soundgarden", "Emperor Maximillian", "Superman", "John Gotti", "I.M. Pei", "The Name of the Rose", "a weak executive", "Norway", "Lewis", "'thoughts and Prayers' are Not Enough - and What Is  Faith", "Steve McQueen", "Firebird", "Sweet Home Alabama", "Vietnam War", "Montana", "Mike Huckabee", "a Bill of Rights", "Peter Sellers", "St. Mark", "Jon Stewart", "Howard Dean", "Pogo", "Help Myself", "Manitoba", "Madonna", "a turban", "Perseid", "Holstein", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Churchill", "Jayne Torvill and Christopher Dean", "The Black Eyed Peas", "\"I think, therefore I am\"", "the Bulgarian 2nd Army", "prophets", "1987", "Toy Story", "Harriet Tubman", "Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Mildred", "last week, officials announced the arrest of Sigifredo Najera Talamantes, a drug-trafficking suspect accused of attacking a U.S. consulate and killing Mexican soldiers.", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.625, "QA-F1": 0.7308221726190476}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.07142857142857144, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-10582", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-3006", "mrqa_searchqa-validation-9907", "mrqa_searchqa-validation-1193", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-2188", "mrqa_naturalquestions-validation-2819", "mrqa_triviaqa-validation-1386", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.625, "CSR": 0.5505087209302326, "EFR": 0.9166666666666666, "Overall": 0.7025757025193798}, {"timecode": 86, "before_eval_results": {"predictions": ["cob", "Barbara Walters", "Europe and Asia", "hoover", "Robert Frost", "bach", "coffee milk", "a bullfrog", "Knott's Berry Farm", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "Lupus", "de Gaulle", "a cathode", "Gianlorenzo Bernini", "P Percy Bysshe Shelley", "Pablo Escobar", "Abraham Lincoln", "Anne Boleyn", "modify", "an eye", "Bank of America", "copper", "push", "Kiss Me, Kate", "John L. Sullivan", "plutonium", "Bismuth", "paste", "Amistad", "a 2000 American sports drama film directed by Robert Redford, and stars Will Smith, Matt Damon and Charlize Theron", "The Simpsons", "Ladies Pro Tour", "Universal Studios Hollywood", "the Russian fleet", "Camembert", "heel", "red lip", "Sweden", "a member of the musical Partridge family", "Jammu & Kashmir", "the Great Seal", "The Empire Strikes Back", "Nelson's Column", "Billy Bob Thornton", "Meriwether Lewis", "lima beans", "Will & Grace", "the Octopus", "De Wayne Warren", "2017", "Venezuela", "Conway Twitty", "golf", "Dialogues des Carm\u00e9lites", "England", "35,124", "between the ages of 14 to 17.", "software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6768973214285714}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.8, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-15956", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-11379", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-14712", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-9585", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-6903", "mrqa_naturalquestions-validation-9523", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-1867"], "SR": 0.5625, "CSR": 0.5506465517241379, "EFR": 0.8928571428571429, "Overall": 0.6978413639162562}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Ian Fleming", "the zona glomerulosa of the adrenals cortex in the adrenal gland", "late 19th and early 20th centuries", "Tom Jones", "Park Sung-woong", "Bonnie Franklin", "Violet", "Route 37 East", "\"Martian Manhunter\"", "Easy", "\"\u00c9cole des Beaux-Arts\" in Paris", "Gareth Barry", "Lucy Muringo Gichuhi (n\u00e9e Munyiri) ( ) (born 23 September 1962)", "Bambi, a Life in the Woods", "1896", "Apple iPod Classic", "2017", "The Timekeeper", "July 8, 2014", "Ben Ainslie", "torpedoes", "Dante Bonfim Costa Santos (born 18 October 1983), commonly known as Dante (] ), is a Brazilian professional footballer who plays for French Ligue 1 club Nice.", "Glendale", "Miami Marlins", "Netherlands", "Dallas/Fort Worth", "Althea Rae Janairo", "four", "Jim Davis", "Kurt Vonnegut Jr.", "Labrador Retriever", "Haryana", "1837", "Blackpool F.C.", "Pippa", "DS Virgin Racing Formula E Team", "explores the lives of those that either own exotic animals or have been captured for illegally smuggling them,", "1943", "Paradise, Nevada", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "(29 September 1888 \u2013 20 May 1937)", "2015", "Northrop F-15 Reporter", "Gareth Barry", "Gambaga", "March 2012", "Cheshire", "Kairi", "1978", "ase", "Turducken", "3000 BC", "Damian Green", "Gary Oldman", "Alanis Morissette", "the Employee Free Choice act in Lafayette Square in Washington.", "\"peregruzka\"", "Port-au-Prince", "Martina Navratilova", "Brazil", "Rocky and Bullwinkle", "baseball"], "metric_results": {"EM": 0.5, "QA-F1": 0.5717656822344321}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, true, true, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.07999999999999999, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.09523809523809523, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-1902", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-3946", "mrqa_hotpotqa-validation-4700", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-5679", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_newsqa-validation-2345", "mrqa_searchqa-validation-14393", "mrqa_searchqa-validation-4094"], "SR": 0.5, "CSR": 0.5500710227272727, "EFR": 0.96875, "Overall": 0.7129048295454545}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "first to utilize Audio-Animatronics", "Continental Army", "1874", "(57 B.C. - A.D. 935)", "January 16, 2013", "Andrew Preston", "Apple Lisa", "Veyyil\" (2006)", "Victoria, Duchess of Kent, along with her attendant, Sir John Conroy, concerning the upbringing of the Duchess's daughter, the future Queen Victoria", "Umina Beach, New South Wales", "from 1989 until 1994", "Adelaide Laetitia \" Addie\" Miethke", "Pensacola", "Consigliere", "Orson Welles", "7", "the Bologna Process", "Peoria, Illinois", "Iran", "Dick Ebersol", "Philip K. Dick", "University of Texas Longhorns football team", "O", "\"An All-Colored Vaudeville Show\"", "the local midnight", "German shepherd", "The Vaudevillains", "Iftikhar Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "the Twist", "Carrefour", "Premier League", "Bob Zmuda", "Eddie Albert", "Chicago", "Ford Island", "\"The Times Higher Education Guide\"", "Derry City F.C.", "Beverly Hills and North Hollywood", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "The International Imitation Hemingway Competition", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State", "Akshay Kumar", "2015", "diastema", "Thames Street", "Tom Stoppard", "brazil", "Dube attempted to escape but died almost instantly from his wounds.", "an average of 25 percent", "Wally", "meat of various species", "Livin' On A Prayer", "the electoral college", "joseph kipling"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6648809523809525}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, true, true, false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.16666666666666669, 0.4, 0.5, 0.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2784", "mrqa_hotpotqa-validation-1048", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-3009", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-37", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1697", "mrqa_searchqa-validation-6483", "mrqa_triviaqa-validation-7531"], "SR": 0.546875, "CSR": 0.5500351123595506, "EFR": 0.9310344827586207, "Overall": 0.7053545440236343}, {"timecode": 89, "before_eval_results": {"predictions": ["Richard Masur", "various bigfoot-like sightings, giant snakes and \"thunderbirds.\"", "World War II", "Mike Pence", "Mickey Gilley", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "\"The Itchy & Scratchy Show\"", "First Street", "5249", "the Dutch Empire", "Black Swan", "Ready to Die", "October 20, 2017", "pronghorn antelope", "Lord's Resistance Movement", "1965", "1943", "the Big 12 Conference", "1959", "31 January 1933", "Neighbourhood", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Billund", "the University of Kentucky", "\"The Sun on Sunday\"", "Song Kang-ho", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies.", "American B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Bernd Bertie", "Lismore", "EQT Plaza in Pittsburgh, Pennsylvania", "Panthera pardus", "Prudential Center", "ten", "Conservatorio Verdi", "clockwise", "State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "Raymond Benson", "World War II", "George Santayana", "label products that contain any of the most common allergens", "exotic sports cars", "101", "vinegar", "hurt Tammy Wynette", "salivary glands", "Venus Williams"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7481488997113998}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-1222", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-4040", "mrqa_newsqa-validation-3736", "mrqa_newsqa-validation-3476", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464"], "SR": 0.6875, "CSR": 0.5515625, "EFR": 0.8, "Overall": 0.679453125}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeleton", "Joaquin Phoenix", "Whiskey", "the integument", "Harley-Davidson", "New Coke", "Mrs. Barbara Bush", "unions", "University of Hawaii", "leg", "Cristina Yang", "The Omega Man", "van Gogh", "an eruption", "Winnipeg", "\"Hands Clean\"", "Paddington Bear", "Google", "skyscraper", "1950", "Murrow", "Cheetah Rivera", "a notorious dissident", "seven", "Nike", "bck", "Sweden", "Lamborghini", "notary", "John Philip Sousa", "oregano", "New South Wales", "Carrie A. Nation", "Ho Chi Minh", "Martha's Vineyard", "No. worn by Wayne Gretzky", "apples", "Transformers: Earth Wars", "An American in Paris", "Taiwan", "The Parent Trap", "Aloha Air Group", "Gustave Eiffel", "Errol Flynn", "Michael Jackson", "Firebird", "Sicily", "Bill Frist", "a cupronickel coin", "apocrypha", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "Russia", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records.", "to pay him a monthly allowance,", "Aung San Suu Kyi", "75.", "quality of teaching and learning in American schools"], "metric_results": {"EM": 0.5, "QA-F1": 0.5513757076257076}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, true, false, false, true, false, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-7340", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-16072", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-16647", "mrqa_searchqa-validation-2561", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-11552", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-8040", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.5, "CSR": 0.5509958791208791, "EFR": 0.9375, "Overall": 0.7068398008241759}, {"timecode": 91, "before_eval_results": {"predictions": ["The Channel Tunnel", "Hawaii", "Harold Smith", "giant", "lubricant", "banana & Chocolate Top Banana Bar", "Chesapeake Bay", "the Devil's Dictionary", "AILD", "Macbeth", "the Suez Canal", "Stephen Hawking", "Ecuador", "New York City", "the United States Federal Communications Commission", "acetylene", "scrapple", "New Mexico", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "(Symphonie Fantastique)", "oblique", "Cracker Jack", "Ford", "the high jump", "the phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "France", "Orange", "venison", "South Africa", "a packer", "the Gifted", "the Andes Mountains", "Ovid", "2012", "Grendel", "ROE", "Ascomycota", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "eyes", "the sound barrier", "Cyprus", "the members of the actual club with the parading permit as well as the brass band", "Nala", "Etienne de Mestre", "USA43SC6390", "2.1", "kenjutsu", "Rawlings", "Adam Levine", "Syracuse University", "Stuttgart", "U.S. households, or 5.7 percent, were not ready for the crossover last month,", "legislation that would let prisons jam cell-phone signals within their walls.", "Bed and breakfast"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6268229166666666}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.1, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.19999999999999998, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-9882", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-8947", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-12144", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-6932", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.578125, "CSR": 0.5512907608695652, "EFR": 0.8518518518518519, "Overall": 0.6897691475442834}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie Meeber", "the Shar'ia penal code", "yente", "Occlusion", "initiative process", "alfalfa", "Phaedra", "Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "Daniel", "Women's Auxiliary Australian Air Force", "Mozart", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "\"to compare\"", "The Secret", "an acre", "ancora", "Frederick Douglass", "William Conrad", "La Fea", "the Burning Bush", "a gastropod", "Indian tribes", "Australia", "Freaks and Geeks", "Edouard Manet", "Finding Nemo", "Frdric Franois", "a zipper", "a soap opera", "Amman", "Van Halen", "Permanent Select Committee on Intelligence", "amyotrophic lateral sclerosis", "a plant", "Nancy Lopez", "the Magic Mountain", "Hudson's Bay", "Beguile", "Hoo'zher", "the house of prayer", "a loaf of bread", "a mead", "the Mossad", "a menagerie", "an aide-de-camp", "Judiththia Aline Keppel", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "plutocracy", "de goya", "Shut the *freak* up", "Jagdpanther", "paracyclist", "XXIV Summer Universiade", "many.Some have complained that his wins are too routine, and purists grouse that he does not poses the quality of \"hinkaku,\" the dignity and calm expected in a yokozuna,", "the world's tallest building,", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6244791666666666}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, false, true, false, false, true, false, false, true, false, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, true, true, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-5282", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-9804", "mrqa_searchqa-validation-6365", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-6160", "mrqa_hotpotqa-validation-1107", "mrqa_newsqa-validation-1122", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.515625, "CSR": 0.5509072580645161, "EFR": 0.9032258064516129, "Overall": 0.6999672379032258}, {"timecode": 93, "before_eval_results": {"predictions": ["Department of Labor", "Standard Oil", "Kings", "the National Assembly for Wales", "archbishop", "Clark", "India", "The Carpenters", "Cheney", "Mary Stuart", "the Crimean War", "the elbow", "a thermostat", "a bad speed", "a sapphire", "florida", "a wipers", "grace", "awagon", "the Davis Cup", "Blackbeard", "William of Orange", "Emily Dickinson", "the stikhos", "Simon Wiesenthal", "Mercury and Venus", "LODGE-PODGE", "Sea World", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "Halloween", "apples & oranges", "the Kuiper belt", "Apple", "Scream", "The Goonies", "American Bandstand", "flauta", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a bat", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "Sir Walter Scott", "The War of the Worlds", "January 17, 1899", "when a population temporarily exceeds the long term carrying capacity of its environment", "about 13,000 astronomical units ( 0.21 ly )", "Jessica", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO's Membership Action Plan, or MAP,", "a lump in Henry's nether regions was a cancerous tumor.", "Sunday.", "Charles Quinton Murphy"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7359375}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-4055", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-9606", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-12174", "mrqa_searchqa-validation-15608", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_naturalquestions-validation-8832", "mrqa_newsqa-validation-852", "mrqa_newsqa-validation-4022", "mrqa_hotpotqa-validation-751"], "SR": 0.6875, "CSR": 0.5523603723404256, "EFR": 0.95, "Overall": 0.7096126994680851}, {"timecode": 94, "before_eval_results": {"predictions": ["the assassination", "fever", "fossilis", "Janet Reno", "Harvard University", "Don Quixote", "The Turn of the Screw", "Lynch", "F Thomas G Nazareth", "spruce", "Wild Bill Hickok", "2D", "hydrogen", "vodka", "lava", "anthrax", "Jamaica", "the Sacher Torte", "Hillary Clinton", "a coyote", "CVS/pharmacy", "Sulfur", "the Confessions of Nat Turner", "Marquette", "overbite", "Hannibal Lecter", "cytokinesis", "Jefferson", "a millimeter", "Megan Fox", "Eurydice", "Unicef", "the Battle of the Little Bighorn", "Marie Curie", "the Archangel Cat", "Dustin Hoffman", "Nebraska", "E-T", "vodka", "John", "LOUIS XIV", "the vnus", "Yellow pages", "Mazda", "Scout Finch", "Liechtenstein", "the joker", "Pulp Fiction", "Mao Zedong", "Nereid", "Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson and Peter Vale", "Sir Giles Gilbert Scott", "Andrew Jackson", "middle-distance runner", "Stratfor", "Traumnovelle", "1985", "Manuel Mejia Munera", "seven", "Six", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.5, "QA-F1": 0.6}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.42857142857142855, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-13563", "mrqa_searchqa-validation-1129", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-4784", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-818", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-9704", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-11462", "mrqa_naturalquestions-validation-4399", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-5124", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3607"], "SR": 0.5, "CSR": 0.5518092105263157, "EFR": 0.78125, "Overall": 0.6757524671052633}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "the magic lantern", "the rhea", "Robbie Turner", "a palette", "ice cream", "Cherry baby", "Tajikistan", "Theology of God", "Forrest Gump", "a piles", "a hot dog", "(C)", "Dixie", "Alfred Nobel", "Karen von Blixen-finecke", "Oklahoma", "Sindbad", "the ziggurats", "the toe", "Pennsylvania", "The War of the Worlds", "Achilles", "Steve Jobs", "J. P. \"The Big\"", "Manwich", "1.80 655", "Pompey", "Jane", "Eugene V. Debs", "California", "Troy", "Antoinette Perry", "The Crucible", "rabbit", "Cylon", "Rugby School", "Pluto", "Francis", "Judges", "Arthur Miller", "Billie Holiday", "Seal", "Dead Serious", "Scrabble", "1997", "a palmetto", "Xinjiang-Uygur Autonomous Region", "the Barbary Coast", "a skunk", "Neal Dahlen", "a permanent, fast - drying painting medium consisting of colored pigments mixed with a water - soluble binder medium ( usually glutinous material such as egg yolk or some other size )", "Reverend J. Long", "bridge", "mauritania", "cheese, \u201cspecial sauce\u201d (a variant of Thousand Island dressing), iceberg lettuce, pickles, and onions,", "Scholastic UK", "FIFA Women's World Cup", "Great Lakes and Midwestern", "St. Louis", "three out of four", "2002", "\"There are already many other restaurants in the mall, so we will only be one of the many restaurants that offer visitors their products.\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.5760162601626015}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, true, true, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.7317073170731707, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.06666666666666667]}}, "before_error_ids": ["mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-14256", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-4660", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-6639", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-8999", "mrqa_searchqa-validation-3642", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-2598", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-2950"], "SR": 0.515625, "CSR": 0.5514322916666667, "EFR": 0.8387096774193549, "Overall": 0.6871690188172044}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "The Paris Sisters", "InterContinental Hotels Group", "Kaley Christine Cuoco", "1877", "`` Everywhere ''", "T.S. Eliot", "no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "30 October 1918", "St. Augustine", "Robyn", "Peggy Lipton, who knew Vincent Price, suggested Price for the vocal part, which Price agreed to do", "Nicole Gale Anderson", "Tiffany Adams Coyne", "Scheria", "Eddie Murphy", "2 September 1990", "Ben Savage", "Genoese merchant sailor Manuel Pessanha ( Pesagno )", "`` The Star Spangled Banner ''", "Thomas Stone", "meaning `` save, rescue, savior ''", "Canadian Rockies continental divide", "March 11, 2018", "Khrushchev", "Ciara Brady", "the International Border ( IB )", "Ancylostoma duodenale", "the road is travelled by funeral convoys for fallen Canadian Forces personnel from CFB Trenton to the coroner's office in Toronto", "King T'Chaka of the African nation Wakanda", "the Grey Wardens", "1992", "the Intertropical Convergence Zone ( ITCZ )", "Each side had about 18,000 poorly trained and poorly led troops in their first battle", "Matt Jones", "September 19, 2017", "a convergent plate boundary", "domestication of the wild mouflon in ancient Mesopotamia", "The show takes place on the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "Matt Monro", "Bill Russell", "Krypton", "May 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "MFSK and Olivia", "introduced around 1940", "Sid Vicious", "Apocalypse Now", "Gower Peninsula", "11,163", "Jaguar Land Rover", "His son", "propofol,", "Courtney Love,", "near his Seattle home.", "cantata", "East of Eden", "Africa", "1919"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6376868395595418}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8205128205128205, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0625, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-3206", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-2222", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.59375, "CSR": 0.5518685567010309, "EFR": 0.8461538461538461, "Overall": 0.6887451055709755}, {"timecode": 97, "before_eval_results": {"predictions": ["Blue laws", "Dr. Rajendra Prasad", "2001 -- 2002 season", "New England", "2007", "two reservoirs in the eastern Catskill Mountains", "from the 1960s to the mid-1970s", "Bart Cummings", "Billie `` The Blue Bear '', a German ex-prostitute who has a reputation as a dirty fighter", "Arnold Schoenberg", "15,000 BC", "meditation", "tanks", "A status line", "Richard Bremmer", "contestants'friends using web search engines and other Internet resources to assist them", "1898", "Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices", "Frankel", "Human fertilization", "senators", "Hermia", "Hans Christian Andersen", "Procol Harum", "2018", "the world", "James Rodr\u00edguez", "Nucleotides", "Hathi Jr", "interstitial fluid in the `` interstitial compartment '' ( surrounding tissue cells and bathing them in a solution of nutrients and other chemicals )", "1980", "Instagram's own account", "Revelation was the last book accepted into the Christian biblical canon", "when matching regions on matching chromosomes break and then reconnect to the other chromosome", "Qutab Ud - Din - Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Robert Jordan", "American swimmer Michael Phelps", "Kevin Zegers", "U.S. was not officially tied to the Allies by treaty", "Isabela Moner", "April 29, 2009", "Laodicea, near Denizli", "Gibraltar", "red, white, and blue", "small orange collection boxes distributed to millions of trick - or - treaters", "Salt Lake City", "Schengen Area (which includes 22 EU and 4 non-EU states)", "Greg Norman", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "a controversial theory about Mary Magdalene and Jesus.", "Barbara Streisand", "Brave New World", "a phobia", "cryogenics", "anxiety"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5724864173683307}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, false, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.42857142857142855, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4347826086956522, 0.0, 0.5714285714285715, 0.3636363636363636, 0.07142857142857144, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-10529", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-786", "mrqa_searchqa-validation-15118"], "SR": 0.484375, "CSR": 0.5511798469387755, "EFR": 0.696969696969697, "Overall": 0.6587705337816946}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "an American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs.", "Michael Sheen", "Rockbridge County", "Mumbai, Maharashtra", "Hong Kong", "Perfect Strangers", "public", "Nelson County", "video game", "\"boundary river\"", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks", "\"The Simpsons 138th Episode Spectacular\"", "Twin Pines/Lone Pine Mall", "neo-Nazi", "model", "Bisexuality", "Adam Dawes", "in the early 17th-century Colony of Virginia after serving his term of indenture", "Steven Selling", "Oberkommando der Wehrmacht", "1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "British", "1968", "Longford Town", "Dirk Nowitzki", "highland regions of Scotland", "University of Kansas", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "The Hungry Hustlerz: Starvation Is Motivation", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "1976", "Anthony Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "Amii Anne J. Grove", "their unusual behavior", "1952", "to start fires, hunt, and bury their dead", "`` Lauren ''", "Dmitri Mendeleev", "honda", "Utah", "Moby Dick", "The train in front had stopped behind another train undergoing service and awaited directions to move ahead.", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "to host the Olympic Games in Rio de Janeiro. Rio deserves this because Rio is a city that has suffered.\"", "Free Bird", "The Suite Life of Zach & Cody", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.640625, "QA-F1": 0.70935834998335}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.4, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47619047619047616, 0.0, 0.6153846153846153, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-1204", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-2545", "mrqa_searchqa-validation-15800"], "SR": 0.640625, "CSR": 0.5520833333333333, "EFR": 0.6521739130434783, "Overall": 0.6499920742753623}, {"timecode": 99, "UKR": 0.74609375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.779296875, "KG": 0.50859375, "before_eval_results": {"predictions": ["The 2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "PBS", "Bears", "1979", "Salisbury", "KKR & Co", "526", "Jean-Marie Pfaff", "West Point Foundry", "The Grandmaster", "satirical erotic romantic comedy", "\"The Process\"", "Vikram", "1949", "BAFTA TV Award Best Actor", "Duke University", "defender", "Levi Weeks", "219", "Esteban Ocon", "S7", "Lamar Hunt", "Black Mountain College", "You Can Be a Star", "People v. Turner", "1853", "1977", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "\"City of Ghosts\" (2002)", "Ludwig van Beethoven", "Rabat", "A Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan Hypersport", "Richard Arthur", "mentalfloss.com", "May 4, 2004", "3", "Field Marshal Lord Gort", "Neighbourhood", "Miracle", "1979", "John Alexander-Arnold", "eleven", "2011", "current day", "North Carolina", "wish FM", "John Galliano", "Ford", "Arlington National Cemetery's Section 60,", "Seoul", "Circumnavigate", "a comma", "15", "mollusca"], "metric_results": {"EM": 0.671875, "QA-F1": 0.72890625}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, true, true, false, true, true, true, false, true, false], "QA-F1": [0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-3889", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6862", "mrqa_newsqa-validation-2457", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-5045"], "SR": 0.671875, "CSR": 0.55328125, "EFR": 0.9047619047619048, "Overall": 0.6984055059523809}]}