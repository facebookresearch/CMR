{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8020, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange Counties", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "the Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange County", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "the Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "10%", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis on 2nd December 1936", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.875, "QA-F1": 0.8916666666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "the evolution of the German language and literature", "the Qur'an", "the Brotherhood", "high wages", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "his friends", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "warmest", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the decision problem in Presburger arithmetic", "1965", "a coherent theory", "German Te Deum", "Stanford Stadium", "the Jin dynasty", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "brown", "guardian", "guardian", "black", "brown"], "metric_results": {"EM": 0.625, "QA-F1": 0.6742458062770562}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-2547", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3857"], "SR": 0.625, "CSR": 0.7916666666666666, "EFR": 1.0, "Overall": 0.8958333333333333}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "the 19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "England", "Vistula River", "1290", "21 October 1512", "427,652", "double membrane", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "comb rows", "calcitriol", "Warsaw", "time", "since at least the mid-14th century", "the mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "allocution", "gauge bosons", "the A1 (Gateshead Newcastle Western Bypass", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "Mollusca", "Orestes", "the Galapagos Islands", "a vegetarian and practices Transcendental Meditation", "a liquid", "the Travel Detective", "a very liquid cereal", "a major raw", "the Mycenaean civilization", "a biological clock", "the Belasco Theatre", "the Normandy Landings", "John Dillinger", "the fibula", "Il Trovatore", "the South Pole", "the East Coast Main Line"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7132711038961039}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.6875, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Rhenus", "gambling", "secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25 percent", "May 2013", "K-9 and Company", "capturing prey", "a four-carbon compound", "livestock pasture", "Ford", "1,300,000", "passing between carbon dioxide and oxygen, so at high oxygen concentrations, rubisco starts accidentally adding oxygen to sugar precursors", "two tumen (20,000 soldiers)", "eight", "computational complexity theory", "WWSB and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empire", "domestic legislation of the Scottish Parliament", "a placebo", "Michael Bloomberg", "the oceans are growing crowded", "innovative, exciting skyscrapers", "a cancerous tumor", "the war years", "Microsoft", "Matt Kuchar and Bubba Watson", "fastest circumnavigation of the globe in a powerboat", "footage", "the foyer of the BBC building", "Buddhism", "Manchester City", "Noriko Savoie", "three", "change course", "Morgan Tsvangirai", "a Lion Among Men", "January 2, 1971", "a 100% pure and natural sweetener", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7652014819857562}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.7741935483870968, 0.4, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.2, 0.0, 0.8333333333333333, 0.2857142857142857, 0.0, 0.7272727272727273, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-4258", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-1643", "mrqa_squad-validation-6092", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-10045", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-3946", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.640625, "CSR": 0.740625, "EFR": 1.0, "Overall": 0.8703125}, {"timecode": 5, "before_eval_results": {"predictions": ["money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven classes", "the Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "chloroplasts are surrounded by a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "a seal illegally", "Philip Howard", "King Ethelred II of England", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "the constitutional traditions common to the member states", "pharmacological effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical and highly refractive bodies", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two plastid-dividing rings", "George Westinghouse", "by disrupting their plasma membrane", "internal combustion engines", "elementary particles", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops", "Anjuna beach in Goa", "How I Met Your Mother", "the Louvre", "Leo Frank", "Thessaloniki and Athens", "Graziano Transmissioni", "opposition parties", "1.2 million", "United's", "the release of the four men", "first lady Michelle Obama is weighing in on the issue by focusing on how health care can affect families", "Ed McMahon", "The Magna Carta is expected to fetch at least $20 million to $30 million,", "the Democratic VP candidate", "the end of a biology department faculty meeting at the University of Alabama in Huntsville", "Ali Larijani", "paper ballots", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium", "promotes fuel economy and safety while boosted the economy", "resting heart rate over 100 beats per minute", "a 'Suffolk Punch'", "Hamlet", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6579187182249295}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8181818181818182, 0.4, 1.0, 0.4, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2666666666666667, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-7260", "mrqa_squad-validation-8715", "mrqa_squad-validation-3408", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-8826", "mrqa_squad-validation-8867", "mrqa_squad-validation-6644", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-2613", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.515625, "CSR": 0.703125, "EFR": 0.967741935483871, "Overall": 0.8354334677419355}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "it would undermine the law by encouraging general disobedience which is neither conscientious nor of social benefit.", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "The Warsaw Stock Exchange", "They may exist to increase the chloroplast's surface area for cross-membrane transport, because they are often branched and entangled with the endoplasmic reticulum", "computational", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "a straight line", "1991", "William Smith", "William Pitt", "geochemical component called KREEP", "Theory of the Earth to the Royal Society of Edinburgh", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "John Elway", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "this to be more convenient and private method rather than traveling to a community drugstore where another customer might overhear about the drugs that they take", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1", "nerves", "1700", "Christo", "Poly & di", "Howard Dean III", "The cardiovascular system", "Reg Presley", "six", "Bratislava,", "Charles & Camilla", "slave trade.", "vena cava, the", "Chesapecten jeffersonius", "bull's-eye", "Tartarus", "\"cyc\"", "Nancy Reagan", "Achaemenid", "LAP", "Zeppelin", "38th", "Duke of Clarence", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Detective Eagan", "Judas", "Dr. Jack Shephard, Kate Austen, Sayid Jarrah, Hugo \" Hurley\"", "The Walking Dead", "Love Is All Around", "Los Angeles Dance Theater", "United States", "nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6021418386450714}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.5517241379310345, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.11111111111111112, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.5, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.08333333333333333, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6773", "mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.53125, "CSR": 0.6785714285714286, "EFR": 1.0, "Overall": 0.8392857142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction", "oxygen", "reduce growth", "K-9 and Company", "9.1 million", "a lower level of economic mobility than all the continental European countries", "individual countries", "cattle", "Western Xia", "a maze of semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway/Eisenhower Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "the human development approach", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "The Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rodeo", "hog", "John Sexton", "Kenny G", "a small, half size cup used for serving espresso", "a peacock unitard", "Annapolis", "Spring", "krukhit", "female", "Allah", "bones", "Python", "the Bible", "Ada", "Faith Hill", "Ben Affleck", "U.S.", "V", "time", "Yardbird", "Sweden", "Vietnam", "hydrogen", "destroyed", "Perfume", "the New Jersey Economic Development Authority's 20% tax credit", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5944602272727273}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, true, false, true, false, false], "QA-F1": [0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4198", "mrqa_squad-validation-7399", "mrqa_squad-validation-1938", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_squad-validation-7565", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_triviaqa-validation-3911", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.546875, "CSR": 0.662109375, "EFR": 0.9655172413793104, "Overall": 0.8138133081896552}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes or an antibody-based humoral response", "producers of the show", "BSkyB", "Kawann Short", "Daidu in the north", "silent film", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "the Red Army", "20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "the midseason forensic investigation drama Body of Proof", "seven-eighths", "the cardinal de Richelieu", "the Atlas Mountains", "Madrid", "the Danube", "Yahweh", "leather", "George Pullman", "a dark red-purple plum with red flesh", "the Messiah", "Sappho", "Possession", "the tonka bean", "the divisor", "Hypnos", "Texas", "IHOP", "a black breed", "the Bill of Rights", "the ACT", "Rio de Janeiro", "Henry David Thoreau", "Southern California", "Harry Whittington", "the Earth", "Gustave Eiffel", "Edward Hopper", "the CIA", "d'Artagnan", "the Venus figurines", "1985", "apple", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6287512400793651}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6559", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16296", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.546875, "CSR": 0.6493055555555556, "EFR": 1.0, "Overall": 0.8246527777777778}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "the United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "61", "During the Second World War", "the integer factorization problem", "Scottish independence", "Exploration is still continuing to determine if there are more reserves", "prep schools", "Cultural imperialism", "a strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "the helmeted honeyeater", "4:51", "Yuri Andropov", "Hera", "the nymphs", "Dwight", "Cuba", "the Battle of Thermopylae", "the Khazars", "Ray Kroc", "cricket", "white", "Wash.", "Carmen", "Genoa", "15", "tarn", "100", "a bison", "Ann Widdecombe", "Isosceles", "the Old Kent Road", "Tuesday", "anhydrous copper sulfate", "Ab Fab", "Massachusetts", "Barrow", "California", "the Susquehanna River", "80\u2019s", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "playing Hoffa", "Home Rule Party", "Secretary Janet Napolitano", "J. Crew", "Deval Patrick", "Bea Benaderet"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6421875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8273", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.609375, "CSR": 0.6453125, "EFR": 1.0, "Overall": 0.82265625}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "a radio network", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the Inner Mongolia region", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "the Parliament of the United Kingdom", "296", "terneuzen", "mulberry", "stomach", "stone", "Ken Russell", "Dan Dare", "mucia", "Smiths", "Mike Tyson", "alexandria", "Pesach", "Brian Deane", "kaleidoscope", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "the Underground Railroad", "puck", "\"beyond violet\"", "Passion", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "the Titanic", "William Tell", "Christian Dior", "a snail", "Mendip", "Wichita", "the eukharisti\u0101", "New Croton Reservoir", "The Way You Move", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "Monty Python", "Roman Polanski"], "metric_results": {"EM": 0.703125, "QA-F1": 0.747659632034632}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 0.4, 0.5714285714285715, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.703125, "CSR": 0.6505681818181819, "EFR": 1.0, "Overall": 0.8252840909090909}, {"timecode": 11, "before_eval_results": {"predictions": ["the method by which the medications are requested and received", "salvation", "jugs and candlesticks", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "a large public network that supported dial-up users and a private network business that allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "public service", "Guy de Lusignan", "tiger", "a sub-group of T cells", "The European Commission", "completed (or local) fields", "a fundamental error", "Mongol and Turkic tribes", "hizbullah", "julard Nimoy", "Whist", "julibouti", "Toscana (Tuscany)", "achromatopsia", "black", "Pluto", "iron and carbon", "white gold", "The Hague", "Vancouver, B.C.", "Ironside", "julian le Carr\u00e9", "Gorky", "black spots", "Beyonce", "Wordsworth", "julie", "Queen Elizabeth II", "Prince of Abissinia", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "black leaf", "julius dos Santos", "julius", "Shrek", "Oslo", "lions", "rhododendron", "Bob Fosse", "Franklin D. Roosevelt", "Shanghai", "julie Forbush", "lift", "Billy Colman", "17 October 2006", "beer", "Kingman Regional Medical Center", "Saturday's Hungarian Grand Prix", "Capuchin Church of the Immaculate Conception, Rome, Italy", "Edgar Allan Poe", "bowery Boys"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5964378720238095}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-8252", "mrqa_squad-validation-4870", "mrqa_squad-validation-6530", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-6278", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-481", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.515625, "CSR": 0.6393229166666667, "EFR": 1.0, "Overall": 0.8196614583333334}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith.", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "the International Association of Methodist-related Schools, Colleges, and Universities", "one", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadine", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas.", "The Handmaid's Tale", "bonobo", "The Fault in Our Stars", "CR-X", "video", "1898", "400 MW", "Total Nonstop Action Wrestling", "galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "New Jersey", "Continental Army", "Jack St. Clair Kilby", "Ryan Babel", "Akhmadovich Kadyrov", "July 16, 1971", "1933", "What's Up", "baudot code", "1959", "1887", "Mark Dayton", "Marvel Comics", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "constant non-native settler", "England", "Paul W. S. Anderson", "a Christian church", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "to stop the Afghan opium trade", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "andrew johnson", "constant Nursery Rhymes", "pre-Columbian times"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6771763392857142}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.12500000000000003, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-4079", "mrqa_squad-validation-9658", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-3896", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.609375, "CSR": 0.6370192307692308, "EFR": 0.96, "Overall": 0.7985096153846154}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Salamanca", "Jochi", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "south", "5,000", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "partial funding", "boarding schools", "NCAA Division II", "Adrian Lyne", "Mikhail Aleksandrovich", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dallas", "Rudolf Schenker", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics) and \"Martian Manhunter\"", "16\u201321", "Vince Guaraldi", "Tony Burke", "Michael Redgrave", "8th", "Highlands Course", "Hawaii", "moth", "Gilbert du Motier", "Gujarat", "three", "Winter Haven", "four", "The Process", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "a few", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Larnelle Harris", "Secretary of State", "2011", "1982", "10,890 square feet", "Chris Robinson", "gossip Girl", "fluid dynamics", "Bob Beamon", "Creation", "Richie Unterberger"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6056490384615385}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3176", "mrqa_squad-validation-6126", "mrqa_squad-validation-4686", "mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_squad-validation-7036", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-5454", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.515625, "CSR": 0.6283482142857143, "EFR": 1.0, "Overall": 0.8141741071428572}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "1970", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "Spreading throughout the Mediterranean and Europe, the Black Death is estimated to have killed 30\u201360% of Europe's total population", "mass", "ten times their own weight", "the Quaternary period", "1887", "other ctenophores", "symbiotic", "mathematical models of computation", "Vistula River", "100 to 150", "Apple's new iOS5 operating system", "the school in South Africa", "March 8", "Mike Meehan", "the Catholic League", "over 1,000 pounds", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "Friday", "Movahedi", "different women coping with breast cancer in five vignettes", "\"mud\" -- a mixture used to pressurize and lubricate the drills -- began falling onto the stern of his ship.", "a smile on her face, like she always does when she comes in here", "bread", "Lance Cpl. Maria Lauterbach", "South Korea's newest plant", "London", "400", "Val d'Isere, France", "the test results by the medical examiner's office, Garavaglia said.", "two soldiers and two civilians", "$14.1 million", "1616", "Sky", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J. Crew", "U.S. Secretary of State Hillary Clinton", "\"I always kind of admired him, oddly.\"", "boyhood experience in a World War II internment camp", "suppress the memories and to live as normal a life as possible", "about 4 meters (13 feet) high", "the Irish capital", "Democrat", "in the county jail in Spanishfork", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "the toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "peter", "mercury"], "metric_results": {"EM": 0.375, "QA-F1": 0.45680702634736065}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.4, 1.0, 0.0, 1.0, 1.0, 0.3, 1.0, 0.6666666666666666, 0.8750000000000001, 0.18604651162790697, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.375, "CSR": 0.6114583333333333, "EFR": 0.975, "Overall": 0.7932291666666667}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "prime", "50 fund", "Camisards", "$40 million", "GTE.", "1,100", "\" spinat\"", "Oligocene", "Melodie Rydalch,", "Charles Darwin", "a Little Rock military recruiting center", "March 24,", "the Beatles", "Robert Park", "Adriano", "Eleven", "2007", "an unprecedented wave of buying amid the elections.", "\"She had a smile on her face, like she always does when she comes in here,\"", "56", "The 28-year-old quarterback", "\"The Da Vinci Code\"", "Heshmat Tehran Attarzadeh", "IV cafe.", "two soldiers", "Atlanta", "resources", "highest ranking former member of Saddam Hussein's regime still at large", "two", "\"I have a very, very good family that I love back home in America, and I miss them every day that you have our back.\"", "Dean Martin, Katharine Hepburn and Spencer Tracy", "Rwanda", "75.", "eradication of the Zetas cartel from the state of Veracruz, Mexico", "closing these racial gaps.", "a bond hearing Friday, a federal magistrate said Monday.", "South African President Thabo Mbeki, as a representative of the Southern African Development Community, and Jean Ping,", "a hospital in Amstetten,", "African National Congress Deputy President Kgalema Motlanthe", "spiral into economic disaster.", "resigned", "Ralph Cifaretto", "a strict interpretation of the law,", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000 or so", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.", "Schleiden and Schawnn", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "blue", "the Capitol", "The Left Book Club", "holography"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5617871133496133}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.33333333333333337, 1.0, 1.0, 0.42857142857142855, 0.0, 0.05714285714285715, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 0.1111111111111111, 0.5, 0.4444444444444445, 1.0, 0.0, 0.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.3, 0.2962962962962963, 0.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-3678", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-11133", "mrqa_triviaqa-validation-6296"], "SR": 0.484375, "CSR": 0.603515625, "EFR": 1.0, "Overall": 0.8017578125}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand people", "address information", "the high risk of a conflict of interest and/or the avoidance of absolute powers.", "look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "Lt Col Paul von Lettow-Vorbeck", "several hundred thousand, some 30% of the city", "the Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary manslaughter", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "30 years ago.", "murder", "next year", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear weapon", "it had \"made a brutal choice to step up attacks against innocent civilians,\"", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "celebrity pontificating about the plight of the environment", "two women", "New Year's Day and once in June,", "Monday,", "male veterans", "Yusuf Saad Kamel", "collectibles and interesting gifts", "11 healthy eggs", "Russia and some European countries have expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "World War I", "1950s,", "U.S. troops", "a government-run health facility that provides her with free drug treatment.", "vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "Trevor Rees-Jones,", "Oxbow,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "first of three films that comprise the \"Three Colours\" Trilogy,", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "Ingemar Johansson", "George Blake", "Bogota,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6104031385281385}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.27272727272727276, 0.22222222222222224, 0.0, 1.0, 1.0, 0.2727272727272727, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 0.5454545454545454, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8339", "mrqa_squad-validation-914", "mrqa_newsqa-validation-2041", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.5, "CSR": 0.5974264705882353, "EFR": 1.0, "Overall": 0.7987132352941176}, {"timecode": 17, "before_eval_results": {"predictions": ["relatively equal distributions of wealth.", "in hospitals", "questions and answers in the catechism", "wakes (sed vigilat) and experiences visions", "Captain Francis Fowke, Royal Engineers,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich,", "\"Sesame Street's\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's restive provinces", "fled Zimbabwe and found his qualifications mean little as a refugee.", "collaborating with the Colombian government,", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Gary Brooker", "Peppermint oil, soluble fiber, and antispasmodic drugs can indeed help people with irritable bowel syndrome,", "in the north and west of the country,", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "introduce legislation Thursday to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April.", "Derek Mears", "a motor scooter that goes about 55 miles per hour -- on 12-inch wheels.", "Gary Player", "Nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "a fair and independent manner and ratify successful efforts.", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22-year-old", "the UNHCR", "how health care can affect families.", "United Nations", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "at checkposts and military camps in the Mohmand agency,", "that the deadly attack on India's financial capital last month was planned inside Pakistan,", "Friday,", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "hid his money,", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger orbiter", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "7", "rice wine", "Halifax,"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5524265142581559}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.7499999999999999, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.33333333333333337, 0.125, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3529411764705882, 0.5217391304347826, 1.0, 1.0, 0.25, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6359", "mrqa_squad-validation-2338", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_triviaqa-validation-1659", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.4375, "CSR": 0.5885416666666667, "EFR": 1.0, "Overall": 0.7942708333333334}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam", "Defensive ends", "\"the dot\"", "chastity", "The European Court of Justice", "bronze medal in the women's figure skating final,", "U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "UK", "\" Teen Patti\"", "Argentina", "Congress", "28", "New Haven, Connecticut, firefighter Frank Ricci,", "\"Kurdistan Gas City.\"", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "asked the FDA in August 2006 to put the \"black box\" warning on Cipro and other fluoroquinolones,", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "North Korea", "Al Shabaab may have been plotting an attack timed to coincide with the event,", "\"Zed,\"", "recognizes the importance of Turkey and wants to engage with it from the start.", "because the federal government is asleep at the switch,", "Molotov cocktails, rocks and glass.", "\"wildcat\" strikes,", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China,", "Lindsey Vonn", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Amnesty International.", "President Obama's race", "Brazil", "Saluhallen,", "trying to detonate an explosive device in his underwear", "two people", "40-year-old", "Peshawar,", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger", "\"Sunny Afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6247555678639996}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.125, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.0625, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611"], "SR": 0.546875, "CSR": 0.5863486842105263, "EFR": 0.9310344827586207, "Overall": 0.7586915834845736}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "unless he were removed from the school, Tesla would be killed through overwork", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012", "Pittsburgh Steelers", "apartment building in Cologne, Germany,", "Aung San Suu Kyi", "Hank Moody", "3rd District of Utah", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "an acid attack by a spurned suitor.", "most of those who managed to survive the incident hid in a boiler room and storage closets", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book", "he was in good health, contrary to media reports he was diagnosed with skin cancer.", "to stand down.", "Ashley \"A.J.\" Jewell,", "at least 17", "Satsuma,", "to the southern city of Naples", "Hugo Chavez", "London's", "rural California,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "steam-driven, paddlewheeled overnight passenger boat.", "Haeftling range.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Jeanne Tripplehorn", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "Rod Blagojevich", "Flint, Michigan", "protective shoes", "Honduran President Jose Manuel Zelaya", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "glass shards", "Sedimentary rock", "around 2.45 billion years ago", "London", "Colorado", "Bangor International", "GZA", "Suffragist", "Canterbury", "Tatooine", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.5, "QA-F1": 0.674108146969989}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.10526315789473685, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4210526315789474, 0.8, 1.0, 1.0, 0.33333333333333337, 0.888888888888889, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.0, 0.7142857142857143, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.8, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-1326", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2805", "mrqa_searchqa-validation-12322"], "SR": 0.5, "CSR": 0.58203125, "EFR": 0.96875, "Overall": 0.775390625}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "middle eastern scientists", "Marshall Field", "four", "mistreatment from government officials.", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhism", "1978", "1927, 1934, 1938, 1956", "1969", "Miami Dolphins", "Joseph Heller", "the north pole", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "the team", "November 2014", "Archduke Franz Ferdinand of Austria, heir presumptive to the Austro - Hungarian throne, and his wife Stephanie, Duchess of Hohenberg", "first word of the text, written in Koine Greek : apokalypsis", "October 1941", "peace between two entities ( especially between man and God or between two countries )", "mughal garden", "Cee - Lo", "After Shawn's kidnapping,", "tomato pur\u00e9e generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Conservative Party", "three times", "November 25, 2002", "October 29, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two", "Galen Rupp", "live animals", "American", "Hoosick,", "CEO of an engineering and construction company", "more than 1.2 million people.", "The third pig", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "approximately 600 square miles of south-central Washington,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6464117592854006}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.4347826086956522, 0.16666666666666666, 1.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.9696969696969697, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_triviaqa-validation-6891", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3167", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.53125, "CSR": 0.5796130952380952, "EFR": 0.9666666666666667, "Overall": 0.773139880952381}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "Sauron", "the Washington metropolitan area", "the molar concentration,", "the breast or lower chest of beef or veal", "the ruling city of the Northern Kingdom of Israel,", "Tagalog or English", "around 1600 BC", "Guam", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford,", "the 2nd century", "in positions Arg15 - Ile16", "Elk and Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "currency option", "1957", "1776", "1963", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "Scarlett Johansson", "embryo", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "In the 1979 -- 80 season", "Guy Berryman", "Tessa Virtue and Scott Moir", "Sophocles", "Tim Allen as Luther Krank", "thick skin", "biscuit - sized cake", "India", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "the Major General of the Navy", "Marktown", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduran", "pardoning Richard Nixon", "Ellen DeGeneres", "1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.4375, "QA-F1": 0.617910729997127}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, true, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 0.9333333333333333, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 0.8, 0.16666666666666666, 0.4, 1.0, 0.0, 0.8571428571428571, 1.0, 0.2857142857142857, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.6666666666666666, 0.0, 0.7692307692307693, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.7777777777777778, 1.0, 0.0, 1.0, 0.6666666666666666, 0.08333333333333333, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_searchqa-validation-843", "mrqa_hotpotqa-validation-3984"], "SR": 0.4375, "CSR": 0.5731534090909092, "EFR": 1.0, "Overall": 0.7865767045454546}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania", "Stanford University", "linebacker", "Mongol and Turkic", "between 1859 and 1865", "Danny Lane", "in the New Testament", "The Fixx", "the United States House of Representatives", "Hellenism", "Mark Jackson", "Long Island", "American electronic music duo The Chainsmoker", "annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "a single particle", "John Adams", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "Burbank, California", "Grace Zabriskie", "2009", "Yuzuru Hanyu", "Glenn Close", "Kanawha", "flawed democracy", "China", "Kirk Douglas", "Jodie Foster", "February 27, 2007", "Avi Lake as Isadora Quagmire", "8ft", "Owen Vaccaro", "bacteria", "on the lateral side", "Lyle Waggoner", "erosion", "90 \u00b0 N 0 \u00b0 W", "London", "into the bloodstream or surrounding tissue", "2005", "February 29", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "Queen Elizabeth II", "\u00ef\u00bf\u00bd", "Pearl Jam", "2005", "American bluegrass singer Dan Tyminski", "Elisabeth", "the southern port city of Karachi,", "at least nine", "Bashar al-Assad", "the New Revised Standard Version of the Bible", "biathlon"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5713919045744704}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, true], "QA-F1": [0.9473684210526316, 1.0, 1.0, 0.8571428571428571, 0.25, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 0.0, 0.8, 0.4444444444444445, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.5, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-8226", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-4410", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_hotpotqa-validation-5453", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-4138"], "SR": 0.4375, "CSR": 0.5672554347826086, "EFR": 0.9722222222222222, "Overall": 0.7697388285024154}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "its many castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Division I history ( 61 )", "Thaddeus Rowe Luckinbill", "December 25", "2002", "the Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd", "during prenatal development", "Ali", "Tanvi Shah", "Article 1, Section 2", "the Constitution of India came into effect on 26 January 1950", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "James P. Flynn", "detritus", "September 27, 2017", "Johnny Logan", "1981", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "on September 28, 2017", "Alex Skuby", "Jamestown settlement in the Colony of Virginia", "March 2016", "1922 to 1991", "Max Ryan", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "The Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "female - only species that reproduces by producing an egg through parthenogenesis", "John Garfield as Al Schmid", "1871", "eye", "The History Boys", "salted, non-fertilized eggs (roe) of sturgeon", "the White Knights of the Ku Klux Klan", "five", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "Phillip A. Myers.", "Osama bin Laden", "Antarctic", "the spinal cord", "mushroom"], "metric_results": {"EM": 0.4375, "QA-F1": 0.6094257305194806}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.8571428571428571, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.18181818181818182, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_squad-validation-8990", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-13614", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.4375, "CSR": 0.5618489583333333, "EFR": 0.9722222222222222, "Overall": 0.7670355902777777}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "the first hole of a sudden-death playoff", "the onset and progression of Alzheimer's disease", "Disco", "Kingdom of Dalmatia", "the Indian School of Business", "Radio City Music Hall", "Charles Whitman", "C. H. Greenblatt", "The Social Network", "A55", "Corendon Dutch Airlines", "86 ft", "Minneapolis", "Loch Duich", "Fatih Ozmen", "U.S.", "Pacific Place", "served as the Attorney General of Michigan from 1999 to 2003", "Flamingo Las Vegas", "Westminster, London", "2016", "Wildhorn", "New York University School of Law", "the Crips", "Queen's Bazaar", "dementia", "the Province of Ferrara", "Guadalcanal Campaign", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "the Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "musical research", "Portland, OR", "Yoruba", "\"Lucky\"", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "1966", "Cameron Diaz", "Jehan Mubarak", "Medellin", "Joe Jackson", "Lawmakers", "2004", "genes", "olive", "Tjejmilen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6241319444444444}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.0, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 0.6666666666666666, 0.4, 0.4, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-979", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-2659", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-5511"], "SR": 0.515625, "CSR": 0.56, "EFR": 0.967741935483871, "Overall": 0.7638709677419355}, {"timecode": 25, "before_eval_results": {"predictions": ["A progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "Anhaltisches Theater", "Anna Clyne", "Terence Winter, based on the memoir of the same name by Jordan Belfort.", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom,", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "Sharyn McCrumb", "Acid house", "at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Leigh Lambert", "Shenandoah National Park", "BBC Formula One coverage", "10 Years", "Haleiwa Ali'i Beach Park", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles of Timmy Sanders and Jack", "PBS stations nationwide,", "second largest", "Citric acid", "in 1911", "Johnnie Ray", "\"The Five\"", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "torpedo boats", "1972", "Geographical Indication tag", "Buck Owens and the Buckaroos", "the Celtics", "World Championship Wrestling", "1994", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "Tenochtitlan", "1986", "Lou Gehrig", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram,", "gorgicus", "to earn the nickname Super Eli", "green"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6780505952380952}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.8, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2056", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.59375, "CSR": 0.5612980769230769, "EFR": 0.9615384615384616, "Overall": 0.7614182692307692}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Victor Garber", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "Sleeping Beauty", "Orchard Central", "Tom Hiddleston", "late eighteenth century", "Raymond Briggs' 1978 children's book \"The Snowman\"", "1979", "Premier League club Liverpool and the England national team", "port city of Aden, on the southern coast", "British", "Prince Louis of Battenberg", "1985", "Archie", "before", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Joseph Travolta", "Hall & Oates", "Mazatl\u00e1n", "Michael James Owen", "Las Vegas, Nevada", "1919", "Kevin Spacey", "\"Love Streams\"", "stunt jumping", "Stravinsky's \"The Rite of Spring\"", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "CMYKOG", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "Frank Oz", "1960", "a peplos", "Car", "Nutshell", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan of the Apes", "Japan", "postcards"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6202638507326008}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.4, 0.2857142857142857, 1.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-3249", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5550", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-16268"], "SR": 0.515625, "CSR": 0.5596064814814814, "EFR": 1.0, "Overall": 0.7798032407407407}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity of his/her students", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "WWE 2K18", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "British Overseas Territories, and Crown dependencies", "most awarded female act of all-time", "Dunlop Tyres", "Bonkyll Castle", "Newcastle United's Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Lannister", "Kalokuokamaile", "Indonesian National Revolution", "Don Bluth", "December 8, 1970", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "I Should Have Known Better", "September 8, 2017", "FBI", "Christine MacIntyre", "American", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914 machine gun", "Robert Young", "Prussia", "January 2004", "Michael Stipe", "ten", "seven", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "glycerol", "Victor Mejia Munera", "Chris Robinson and girlfriend Allison Bridges", "U.S.-flagged Maersk Alabama", "bromide", "septum", "light"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6685829156223893}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false, true, false, true, false, false, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.4000000000000001, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-873", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-6398"], "SR": 0.59375, "CSR": 0.5608258928571428, "EFR": 1.0, "Overall": 0.7804129464285714}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools and day schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "hanover", "Henry Mancini", "jap\u00b7a\u00b7nese", "Gordon Ramsay", "Gorbachev", "Adrian Cronauer", "sabe\u00eds a qu\u00e9 puede", "Charlton Heston", "Anna (Julia Roberts)", "scythe", "orchid", "Paddy Doherty", "smallpox", "the Great Pyramid of Cheops or the Pyramid of Khufu", "Libya", "Yeehaw", "F\u00fcr Elise", "Iran", "Who\u2019s Who", "wry, compassionate, and brimm[ing] with... open-minded intelligence", "Milady de Winter", "April", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "Barb McKinley", "David Beckham", "New York", "Tom Stoppard", "The Greatest", "a singer and performer", "Newcastle-on-Tyne, England, and the surrounding area", "jellies", "jazz pianist", "Everett", "The Union Inn", "Cardiff", "Baton Rouge", "stromberg", "Tahrir Square", "Romanian", "bathtub curve", "Michael Caine", "Lord Snooty", "Alexander Borodin", "Jesse James", "muzzles", "Greek", "passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "December 6, 1941 \u2013 December 5, 1991", "North America", "Florida's Everglades", "Michael Jackson", "glamorous, sexy and international.", "driving through a fast-food chain", "Glengarry Glen Ross", "shark"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5206969246031746}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, false, true, false, false, false, false, true, true], "QA-F1": [0.0, 0.28571428571428575, 0.39999999999999997, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-4432", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-2313", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-3909", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934"], "SR": 0.4375, "CSR": 0.556573275862069, "EFR": 1.0, "Overall": 0.7782866379310345}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Kyrie Irving", "James W. Marshall", "on - and off - premises sales in one form or another on Sundays at some restricted time", "Randy VanWarmer", "Commander in Chief of the United States Armed Forces", "Emma Watson and Dan Stevens", "between 8.7 % and 9.1 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "the status line", "in the eye", "jimmy carennel", "Triple Alliance of Germany, Austria - Hungary, and Italy", "Andrew Lloyd Webber", "1955", "The president - elect and the love interest to Candace", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "1 US dollar", "The Vulcan salute was devised by Leonard Nimoy", "in 1936, when she was 10 years old", "Sam", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "Anna Faris", "early to mid-2000s", "where it reached number 14 on the Billboard Hot 100 chart and number - one on the Adult Contemporary chart", "improved economics of distribution", "Cairo, Illinois", "in the 1970s and'80s", "in the books of Exodus and Deuteronomy", "Chandler", "an epic poem written in the fifth century", "January 2, 1971", "The Miracles", "Eukarya", "forearm", "jimmy aram", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "27", "Long Island convenience store", "Mitt Romney", "Peter", "heart disease", "bronchitis"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5913609827672328}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.5454545454545454, 0.4166666666666667, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1979", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.515625, "CSR": 0.5552083333333333, "EFR": 1.0, "Overall": 0.7776041666666667}, {"timecode": 30, "before_eval_results": {"predictions": ["San Jose", "quality rental units", "major events also play a big part in tourism in Victoria, particularly cultural tourism and sports tourism", "a circle", "( Sequoia sempervirens)", "The Fairly Odd Parents", "(Elegy to the Spanish Republic", "taximeter", "coyote", "(PVM) yra fiziniai ir juridiniai asmenys (Lietuvos ir usienio)", "Harry Reid", "Ray", "Axis", "forge", "The Kinetoscope", "corey lebret", "flowers", "Blackbird", "Footprints", "(1.2.334-335)", "The Royal Report", "The U.S. Census Bureau", "Tommy Lee Jones", "(Luke 19:1-10)", "The Memory Keeper's daughter", "(1876)", "hubris", "Yahtzee", "Who's the Boss?", "markup language", "hives", "48.3", "William Surrey Hart", "jimmy", "Pride and Prejudice", "The Secret Family of Jesus", "kosher wine", "Munich", "Michael Jordan", "Candlemas", "Prospero", "Hikaru Sulu", "(Pulsatrix perspicillata)", "dough", "honshu", "honey", "Boston", "Fisher- Price", "Arctic Ocean", "pizzas", "Pumpkin soup", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Fortune cookie", "Monty Python's Spamalot", "1911", "Harlow Cuadra and Joseph Kerekes", "her translation of and commentary on Isaac Newton's book \"Principia\" containing basic laws of physics.", "Israel", "Adidas", "Intel has systematically given PC makers and stores rebates to keep computers with AMD chips off the shelves."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5446209733893557}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, true, false, true, false, true, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-315", "mrqa_squad-validation-2965", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-3260", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-5093", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-2523", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3915"], "SR": 0.46875, "CSR": 0.5524193548387097, "EFR": 1.0, "Overall": 0.7762096774193549}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "stand-up", "satirical erotic romantic comedy", "Ferengi bartender Quark", "Christian Kern", "June 26, 1970", "The Worcester Cold Storage and Warehouse Co.", "Elise Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge", "Bangkok, Thailand", "Oklahoma Sooners", "Merrimack", "Charlie Wilson", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Angie Watts", "a family member", "October 4, 1970", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland", "\"Slaughterhouse-Five\"", "Shohola Falls", "wineries", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "The Highwaymen", "Fuenlabrada", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Kenneth Hood", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Lenny Jacobson", "Hathi Jr", "1935", "phyphon", "\"Slow\"", "\"Cruisin'\"", "the Rockies", "anti-trust laws.", "Friday,", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7392227564102564}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2614", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-1315", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.65625, "CSR": 0.5556640625, "EFR": 1.0, "Overall": 0.77783203125}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\"", "jellyfish", "March", "a leather shoe", "Fauntleroy", "Dartmouth College", "Eat porridge", "Secretary-General Ban Ki-moon", "oxygen", "the right to print was strictly controlled in England", "Taggart", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "Manfred Mann", "Sven Goran Eriksson", "the College of Arms", "Route 66", "Brussels", "Flora MacDonald", "John Poulson", "Orly", "the Treaty on European Union", "Jack Frost", "Saskatchewan (Province)", "Laurent Planchon", "the Solent", "vomiting", "the Red Lion", "Bristol Aeroplane Company", "Spinach", "Steve Davis", "\"Argo\u201d", "Gemini", "Surrey", "1969", "chippenham", "Paris", "The Coquimbo Region", "William Shakespeare", "borax", "an abbreviation of either Schnellbahn, Stadtbahn or Stadtschnellb Kahn", "Jamaica", "Peter Nichols", "Diana Dors", "Kent", "Vickers-Armstrong's", "Ray Charles", "The onset of rigor mortis and its resolution partially determine the tenderness of meat", "USCS or USC", "Miller Brewing", "northwestern Italian coast", "Sydney, New South Wales, Australia", "the earthquake", "her decades-long portrayal of Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\"", "Peter Bogdanovich", "a Mourning Dove", "the Federal Republic of Germany"], "metric_results": {"EM": 0.4375, "QA-F1": 0.497827432983683}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.923076923076923, 0.12121212121212123, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-6017", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.4375, "CSR": 0.5520833333333333, "EFR": 1.0, "Overall": 0.7760416666666666}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "Lana Del Rey", "1,228 km / h ( 763 mph )", "New England Patriots, 41 -- 33,", "Doc '' Brown, Ph. D.", "Antarctica", "Mitch Murray,", "blue", "`` Ultra Hand ''", "John Bull", "775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Longline fishing", "Jesus'birth", "a habitat", "Kirsten Simone Vangsness", "Central Germany", "Andrew Johnson", "Etienne de Mestre", "Menelaus", "electors", "Julia Ormond", "Sauron", "1961", "STAYND", "2013", "`` leapling '', a `` leaper '', or a `` leap - year baby ''", "published on November 12, 1976 by Ballantine Books", "Rust is an iron oxide, a usually red oxide formed by the redox reaction", "Spain", "Steffy Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "`` Jocelyn Flores ''", "abdicated in November 1918, and fled to exile in the Netherlands", "one of the most recognisable structures in the world", "erosion", "March 2, 2016", "a large roasted turkey", "1996", "Ray Charles", "16", "the Ramones", "1800", "Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "Los Angeles", "May 2010", "France", "Heath Ledger,", "John Lee Hooker", "a centaur", "music lover who must work for a kingpin", "cricket fighting", "Luis Edgardo Resto", "drama that pulls in the crowds", "a Nazi German death camp in Poland.", "Islamabad", "Tunisia", "RAND", "bios & Profiles"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5209541089687524}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 1.0, 0.7499999999999999, 0.5, 0.06451612903225806, 1.0, 1.0, 0.0, 0.18181818181818182, 0.6666666666666666, 0.0, 0.0, 0.7368421052631579, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 1.0, 0.8205128205128205, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.25, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-8963", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-7802", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_triviaqa-validation-5607", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2118", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.4375, "CSR": 0.5487132352941176, "EFR": 1.0, "Overall": 0.7743566176470589}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Cal", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar medium", "transmission and final drive", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions", "Tanvi Shah", "March 14, 1942", "Nick Sager", "local authorities", "prophets", "state legislators of Assam", "digestion of proteins", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "101.325 kPa", "Mind your Ps and Qs", "Germany", "20 November 1989", "Tom\u00e1s de Torquemada", "Bob Gaudio", "16 August 1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc", "a four - page pamphlet", "2003", "Sebastian Lund", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Flex SDK, a set of components that included charting, advanced UI, and data services ( Flex Data Services )", "Steveston Outdoor pool", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Atticus Finch", "1850", "If the car is slowed initially by manual use of the automatic gear box", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Tennesseeitans", "\u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F )", "a cliffhanger showing the first few moments of Sam's next leap", "engraved on a bronze plaque and mounted inside the pedestal's lower level", "Cheerios", "dennis taylor", "Brian Close", "future AC/DC founders Angus Young and Malcolm Young", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "reached an agreement late Thursday to form a government of national reconciliation.", "this week", "Henry Ford", "Toyota", "Abraham Lincoln", "brain tumour"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5605654299619818}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.16666666666666669, 1.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 0.19999999999999998, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.7567567567567568, 0.06896551724137931, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2758620689655173, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.46875, "CSR": 0.5464285714285715, "EFR": 0.9411764705882353, "Overall": 0.7438025210084034}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it", "a supposed mild euphoric", "James McConkey", "Venezuela", "Mexico", "Ring Magazine", "Finding Neverland", "Pietro Perugino", "Arctic Ocean", "air pressure", "dams", "Lafayette", "Malcolm X", "a period of depression or unhappy listlessness.", "the Village People", "Alexander Pushkin", "Australia", "Munich", "ciudad de Tehuacn", "a night shift", "the papacy", "Arkansas", "Subclue 2", "Pierre-August Renoir", "alexandria", "libretti", "Innsbruck", "Lance Ito", "Microsoft", "a fern", "Sony", "medieval Vikings", "Atlantic City's", "Blackwater USA", "elephants", "American Airlines", "a bachary sheep", "Odysseus", "Brian Sanders", "Kensington Palace", "$30,000", "Netherlands", "hawhatan", "the CS Lewis Foundation", "John Galt", "a chalkboard", "the Chicago Mercantile Exchange", "Las Vegas", "\"Tights: not just for dancing\"", "wheat", "Pablo Casals", "a ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "an ancient optical illusion toy", "John Morgan", "Hungarian Rhapsody No. 2", "Henry II", "Senate Democrats", "63", "\"We are resetting, and because we are resetted, the minister and I have an overload of work.\""], "metric_results": {"EM": 0.453125, "QA-F1": 0.556845238095238}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false], "QA-F1": [0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-15317", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-8694", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-10308", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3745", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.453125, "CSR": 0.5438368055555556, "EFR": 1.0, "Overall": 0.7719184027777778}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Arizona State", "at a speed of about 15 metres ( 49 feet ) per year", "Lucknow", "2013 -- 14", "National Industrial Recovery Act ( NIRA )", "The User State Migration Tool", "the Second Battle of Manassas", "William DeVaughn", "New Jersey's formal name for the new PATH station", "Southend Pier", "Santa Monica", "layered systems of sovereignty", "Raza Jaffrey", "1934", "Filipino", "1773", "modern random - access memory ( RAM )", "May 31, 2012", "1917", "Bart Cummings", "October 27, 1904", "Raghu", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "BC Jean", "The Divergent Series : Ascendant", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "retinal ganglion cell axons and glial cells", "the 1980s", "in soils", "card verification value code", "exercise general oversight", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum -- the enkuklios paideia or `` education in a circle ''", "Mike Czerwien", "103", "Vienna", "English", "Mexico", "\u201cHow many divisions does the Pope of Rome have?", "$10.5 million", "Alfred Joel Horford Reynoso", "Andrew Johnson", "$22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities.", "cotton", "Dennis Haysbert", "Quinn", "Towcester"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6611652236652237}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.11111111111111112, 1.0, 0.0, 0.888888888888889, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.888888888888889, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.09523809523809523, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7958", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-5744", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161"], "SR": 0.546875, "CSR": 0.5439189189189189, "EFR": 0.9310344827586207, "Overall": 0.7374767008387697}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "the United States", "South Africa", "first among equals", "Shine", "a cappella", "albinism", "peterloo", "aglet", "Saturday Night Live", "FC Bayern M\u00fcnchen", "winter", "Bonnie and Clyde", "English", "copper", "Dawn French", "Blackstar", "brazil", "Doris Lessing", "Scooby-Doo", "Swaziland", "the elephant House", "Kent", "the Humber", "points based scoring system", "automobile", "Kent", "Rodgers & Hammerstein", "Boy George", "Galileo Galilei", "Zelle", "Scotland Yard", "Marilyn Manson", "Medellin", "The Tempest", "carburetor", "brazilia", "Boulder Dam", "painkillers", "Iran", "Belle de Jour", "bognor Regis", "abba", "rain", "blue", "Asaph Hall", "France", "Snowbell", "Kunsky", "death", "David Graham", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "thunderstorms", "different women coping with breast cancer in five vignettes.", "Blaine", "a sunflower", "Madonna", "March 24"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6345238095238095}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-4021", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-6503", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.59375, "CSR": 0.5452302631578947, "EFR": 1.0, "Overall": 0.7726151315789473}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "tyne", "liver", "40", "table salt", "pet", "Bolivia", "le", "Phil Redmond", "Stevie Wonder", "skull", "a dog", "hanover", "a moon", "king Charles I", "workless households", "scales", "Dirty Dancing", "Vengeance", "Diana Ross", "a man of gold", "a 1934 Austin seven box saloon", "Paul Anka", "Rome", "cuba", "the king Duncan", "Blade Runner", "Jay-Z", "leopons", "cymbal", "\u201cAir Bud\u201d", "La traviata", "Tory MP Andrew Mitchell", "Ticket Sarasota", "South Africa", "Christian dior", "a5 and A49 trunk roads", "a toothed whale", "Georgia", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "a Baron", "lizard", "cuba", "frauds", "a dolphin", "31", "Tony Blair", "quartz or feldspar", "54 Mbit / s", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Lynn", "piano", "paid tribute to pop legend Michael Jackson,", "the United States", "French Guiana", "an AOL internet", "a coat", "Tiger Woods"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5974702380952381}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-1112", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_hotpotqa-validation-2852", "mrqa_newsqa-validation-1352", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.546875, "CSR": 0.5452724358974359, "EFR": 1.0, "Overall": 0.772636217948718}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "aldi", "Midnight Cowboy", "alfa", "seborrheic dermatitis", "norman norman", "a burthen", "niger", "central Stockholm", "Tangled", "dogs", "James 'Buster' Douglas", "Bulls Eye", "o'Meara", "bach", "Martin Clunes", "Charles Darwin", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "cenozoic", "john Mellencamp", "isambard Kingdom Brunel", "gaula", "1957", "watling", "watlingon", "boulangere", "moctes", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "e. T. A. Hoffmann", "Shanghai", "Spain", "grows", "Dydd Iau", "Guru Nanak", "bleak house", "Inigo Montoya", "phosphorus", "boy jack Horner", "bristol and jernstedt", "norman humbert", "cuckoo", "mystery", "Dodge", "Alice Cooper", "Majorca", "transfusions", "Royal Bengal Tiger", "a spherical boundary of zero thickness", "Max", "syndicated columnist", "1999", "Sela Ann Ward", "Body Works", "forgery and flying without a valid license,", "137", "a log cabin", "St. Patrick's Day", "linebacker", "Sondheim"], "metric_results": {"EM": 0.453125, "QA-F1": 0.514360119047619}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-2142", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-1036", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2738", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.453125, "CSR": 0.54296875, "EFR": 1.0, "Overall": 0.771484375}, {"timecode": 40, "before_eval_results": {"predictions": ["the 19th Century", "Famous Players-Lasky", "Washington", "Thomas De Quincey", "black death", "horse", "buffalo", "jane anonius", "a raven", "Sarajevo", "the Bill of Rights", "fine", "Neighbours", "Bligh", "trumpet", "Westminster Abbey", "origami", "resistance", "the Arabian Gulf", "secretary", "fezzik", "matricide", "tuesday hanks", "\u201cThe final typescript of the last four chapters", "a linesider", "Tomorrow Never Dies", "Sudan", "a Great Dane", "Washington", "indianapolis", "New Hampshire", "James I", "shirley taylor", "the Philippines", "purple rain", "fezzik", "warblers", "fezzik", "Venice", "10", "Southwest Airlines", "a cockney", "Jeffery Deaver", "The Comedy of Errors", "chicago", "glyn Jones", "President Ford and first lady Betty Ford", "crossword clue", "an epeiric (or \"shelf\") sea", "radicalization", "Robinsons", "Humpty Dumpty", "1998", "Tanvi Shah", "the EN World web site", "the 100th anniversary of the first \"Tour de France\"", "a dimensionless quantity", "Janet and La Toya", "more than 2.5 million", "researchers", "the Matrix", "Curb Your Enthusiasm", "Nibelung", "Inequality of opportunity was higher"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5286458333333334}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.25, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999]}}, "before_error_ids": ["mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.46875, "CSR": 0.5411585365853658, "EFR": 1.0, "Overall": 0.7705792682926829}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "nile", "hula hoops", "nippon Sangyo", "Golden fleece", "roddy douglas", "an abacus", "Robin Hood Men in Tights", "aeolus", "Diego Velazquez", "european", "caracas", "angola", "tchaikovsky", "vii wilfer", "angola", "european satirical", "david Bowie", "Buzz Aldrin", "Jean-Paul Sartre", "joseph", "dennis turpin", "ferric oxide", "jane aniston", "Wiltshire", "tbilisi", "Mel Gibson", "othello", "sewing up of a small hole or tear in a piece of material", "glenn close", "Lacock Abbey", "alex b'Stard", "domestic cat", "anita Brookner", "james vii", "golda meir", "the Black Sea", "doD", "Susie Dent", "a power outage", "Vienna", "The Archers", "shylock", "james philip Sousa", "henry gee", "jimmy boyd", "shakespears Sister", "the Marx Brothers", "pershore", "Austria/Habsburg Monarchy-Challenge Cup", "Dry Ice", "Pat McCormick", "19 June 2018", "2001", "from 1993 to 1996", "James Gandolfini", "September 29, 2017", "he and the other attackers were from Pakistan and asked for a meeting with Pakistan's High Commission.", "June 6, 1944", "sniff out cell phones.", "a double bass", "the o.K. Corral", "butternut squash", "a Trojan War"], "metric_results": {"EM": 0.5, "QA-F1": 0.5803984788359788}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5714285714285715, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.07407407407407407, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-7425", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-2886", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-10746", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.5, "CSR": 0.5401785714285714, "EFR": 0.96875, "Overall": 0.7544642857142857}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "a shortfall in their pension fund and disagreements on some work rule issues.", "Eintracht Frankfurt", "Comoros Islands", "revolution of values", "near Garacad, Somalia", "40", "his chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "fifteen years ago", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "Salt Lake City, Utah", "Harlem", "Michoacan Family", "64", "life in prison.", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career", "\"E! News\"", "off Haiti's coast", "Madeleine K. Albright", "an ice jam", "toxic smoke from burn pits in Iraq", "Benazir Bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "Zimbabwe", "Larry Ellison", "the local political representative", "her fianc\u00e9,", "Cal Ripken Jr.", "Johannesburg", "cancer", "acid attack", "world boxing Federation", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m.", "former Mobile County Circuit Judge Herman Thomas", "\"A salute to the martyrs of the massacre, and our condolences to their families.\"", "a man's lifeless, naked body", "\"release\" civilians, who it said numbered about 70,000 in Sri Lanka's war zone.", "Dodi Fayed", "one day we will have no more oil and we'll have to find another way to live", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc", "spain", "Misery", "lord philip purdy", "Italo Balbo", "Thorgan", "River Clyde", "Peru", "Tarzan", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5469801976881495}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.15384615384615385, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.8000000000000002, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.14285714285714285, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4210526315789474, 0.28571428571428575, 0.0, 0.6, 0.05714285714285715, 1.0, 0.2666666666666667, 0.3636363636363636, 0.08695652173913045, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-30", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-5687", "mrqa_hotpotqa-validation-727", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.453125, "CSR": 0.5381540697674418, "EFR": 1.0, "Overall": 0.7690770348837209}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth", "House of Borromeo", "Washington, D.C.,", "1943", "a facelifted 850 saloon", "the Mountain West Conference", "the Atlanta Hawks", "Western Europe", "political thriller", "Continental AG", "English football", "1989 until 1994", "the Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown,", "Lollywood and Pollywood films", "Emmanuel ofosu Yeboah", "John Boyega, Nick Frost, Jodie Whittaker and Luke Treadaway", "Bhushan Patel and Tinu Suresh Desai", "1986", "1964", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs", "15 October 1988", "coaxial", "\"Northern Lights\"", "three different covers", "Malayalam cinema", "held in Kingdom of Dalmatia", "August 11, 1946", "Vincent Landay", "May 26, 2010", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Hanna-Barbera", "Nicolas Vanier", "1985", "Wonder Woman", "Meghan Markle", "Flying Fortress", "he was born in Bremen, Germany in a family of Portuguese descent", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Sony Computer Entertainment", "Brig Gen Augustine Warner Robins,", "United Nations", "Alice's Adventures in Wonderland", "two", "the UK\u2019s Trade Mark Registration Act 1875,", "blue", "the elbow", "Citizens are picking members of the lower house of parliament,", "the Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "Teak"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6767284798534798}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070"], "SR": 0.578125, "CSR": 0.5390625, "EFR": 1.0, "Overall": 0.76953125}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "5.3 million", "sexy Star", "Conservatorio Verdi", "George Herbert Walker Bush", "the backside", "\"the Gentle Don\"", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "December 31, 2015", "Margarine Unie", "death", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool Football Club", "21 years and 154 days", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Chrysler", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Australian Electoral Division", "Socrates", "Caesars Entertainment Corporation", "Hindi", "Richard Masur", "Irish Chekhov", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "Super Bowl VIII", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "Elgar\u2019s", "last summer", "almost 100", "into the Southeast,", "the jeffersons", "Great Balls of Fire", "heresy", "One Direction"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7537508753501401}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766"], "SR": 0.65625, "CSR": 0.5416666666666667, "EFR": 1.0, "Overall": 0.7708333333333334}, {"timecode": 45, "before_eval_results": {"predictions": ["to take charge of Methodist activities there", "a proof reader", "Queen Elizabeth II", "the Belgae", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "miniature golf", "CNN Daybreak", "Punxsutawney, Pennsylvania", "Bratislava", "yellow fever", "a sea otter", "a \"piece of the alphabet\"", "a \"submarine sandwich\"", "a rod", "Nixon", "dressage", "observing the moon", "Mickey Mouse", "a stigma", "Associate Professor", "Fruit Roll-Ups", "Medusa", "a staircase", "a silk fabric", "a staff of workers or assistants", "Voyager 1", "an awkward, and sometimes painful, crab hand or hook style of writing", "glucose", "objects", "China", "Helen of Sparta,", "meat", "a \"peace sign\"", "An Old Man, a Young Man", "English Monarchs These 2", "Rajasthan", "\"retired\" safecracker Gal for one last job, but it", "a \"piece to explore the universe\"", "Oklahoma Sooners", "a \"road above one's head\"", "how shall he cut it", "Rules of Order, Nominations and Elections", "Wordsworth", "brushes", "a subtype of planet", "Fairy Tales", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London", "Isle of Wight", "The Peppercorn Pioneer", "Queen In-hyun's Man", "Oneida Limited", "Michael Jordan", "Libreville, Gabon", "tickets", "the station", "Cahawba"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5044034090909091}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, true, false], "QA-F1": [0.18181818181818182, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9923", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-3132", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14560", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1744", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-12750", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_triviaqa-validation-888"], "SR": 0.40625, "CSR": 0.5387228260869565, "EFR": 1.0, "Overall": 0.7693614130434783}, {"timecode": 46, "before_eval_results": {"predictions": ["the position of people within the four-class system was not an indication of their actual social power and wealth,", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "room the book store", "Faggot", "a skein, or a wedge", "California Chrome", "Pluto", "Route 66", "Zagros Mountains", "Sindh", "Movie", "the Great Victoria Desert", "German", "Jack Smith", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Neptune", "Birmingham", "snakes", "Sedgefield in North East England", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "a trenches exhibition", "South Korea", "a pig", "definitely, maybe", "Holzi194", "Kenya", "Stephen Potter", "Casa di Giulietta", "Anwar Sadat", "a hundred", "potomac", "Argentina", "Luke Skywalker", "Frankfurt", "chipmunk", "Goldie Hawn", "a pulsar", "Belgium", "horses", "honey", "Benfica", "Sun Lust Pictures", "number of games where the player played, in whole or in part", "confesses to Anita that she is not in love with Chino", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "the Carrousel du Louvre", "Speed Racer", "Henry Holt", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6199940958164643}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, true], "QA-F1": [0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.33333333333333326, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-445", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-6115", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-3654", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-716", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-5788"], "SR": 0.546875, "CSR": 0.5388962765957447, "EFR": 1.0, "Overall": 0.7694481382978724}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "andean", "Sinclair Lewis", "toms, The bear andy griffith", "james Bond", "pigments", "jodie Foster", "v\u00e1clav Havel", "Dick Van Dyke", "millais", "Tina Turner", "2010", "derry", "glasses", "perfume", "duke orsino", "iron", "Copenhagen", "lord sugar", "cargo", "Cubism", "sahara desert", "sahara", "eucharist", "Charlotte's Web", "james Bond", "silks", "William Randolph Hearst", "lorne Greene", "rowing", "carmen", "call My Bluff", "a", "germany", "Angela McCourt", "oats", "caroline Aherne", "germany", "oxygen", "soap", "Donna Summer", "a balustrade", "nottingham", "gdansk", "the Welcome Stranger", "taggart", "April", "chechnya", "a police janitor", "the A- Team", "football", "801,200", "CV Raman", "Sun Tzu", "bioelectromagnetics", "Foxborough, Massachusetts", "Speedway World Championship", "because I didn't understand the whole concept of communism.", "Eleven people died and 36 were wounded", "Michelle Obama", "Copenhagen", "the Communist Manifesto", "sara", "fluoroquinolones"], "metric_results": {"EM": 0.515625, "QA-F1": 0.552059659090909}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-736", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-3758", "mrqa_triviaqa-validation-1730", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-1804"], "SR": 0.515625, "CSR": 0.5384114583333333, "EFR": 1.0, "Overall": 0.7692057291666666}, {"timecode": 48, "before_eval_results": {"predictions": ["East Lothian", "Caesars Entertainment Corporation", "Supergirl", "King \u00c6thelred the Unready", "shaun the sheep", "British Airways", "William McKinley", "1905", "Vanilla Air", "Mineola, New York", "dziga Vertov", "Strange Interlude", "Julia Compton Moore", "Olivia Newton-John", "1986", "early Romantic period", "Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Babylon", "Ford Falcon", "Southern State Parkway", "The Company", "1827", "Kim Bauer", "United States Food and Drug Administration (FDA)", "Lieutenant Martin", "Suffolk, England", "Otto von Bismarck", "o", "Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard H or HD blister gas", "the 45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "August 14, 1848", "Texas Tech University", "John McClane", "Larry Gatlin & the Gatlin Brothers", "924", "381.6 days", "North Carolina", "Selinsgrove,", "created the first algorithm intended to be carried out by such a machine", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "space shuttle", "basil", "Clio Awards", "The Rosie Show", "North Korea", "well over 1,000 pounds", "Julius Caesar", "desert", "the Library of Congress", "the thylakoid membranes"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6335206686429513}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8695652173913043, 0.19999999999999998, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-4008", "mrqa_hotpotqa-validation-3680", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-2595", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028"], "SR": 0.578125, "CSR": 0.5392219387755102, "EFR": 0.9629629629629629, "Overall": 0.7510924508692365}, {"timecode": 49, "before_eval_results": {"predictions": ["baseball, oin\u0103, ( Italy) and pes\u00e4pallo", "Jena Malone", "Washington, D.C.", "Wandervogel", "John W. Henry", "Mos Def", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Love Hina", "eastern India", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five aerial victories", "Alain Robbe-Grillet", "the Seasiders", "Musicology", "Dragon TV", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Eminem, Bad Meets Evil, Akon, Christina Aguilera and Taio Cruz", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "three Golden Globe Awards", "Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "a Fennec fox of the same name who solves little mysteries in the peaceful town of Chewington", "Dutch", "Terry Malloy", "Golden Calf for Best Actor in 2013", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "Everywhere", "the Department of Science and Technology of the Government of India", "Honda", "J. M. W. Turner", "the Republic of Upper Volta", "56", "Nkepile Mabuse", "Eintracht Frankfurt", "the US marines", "Hephaestus", "Amherst College", "two courses"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7027195537305833}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.25, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 0.25, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.578125, "CSR": 0.54, "EFR": 1.0, "Overall": 0.77}, {"timecode": 50, "UKR": 0.720703125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.869140625, "KG": 0.49296875, "before_eval_results": {"predictions": ["Sushant Singh Rajput", "\u00c6thelwald Moll", "Fife", "about 26,000", "Spain, Mexico and France", "1981", "Dragons", "February 26, 1948", "National Aviation Hall of Fame class of 2001", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "Epic Records", "IFFHS World's Best Goalkeeper", "shortest player ever", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "Scrappy Moc", "Picric acid", "Las Vegas", "ESPN's", "a pioneering New Zealand food writer", "fantasy role-playing game", "feats of exploration", "Dolly Records", "Bergen", "Matthieu Vaxivi\u00e8re", "Feyenoord's Sekou Ciss\u00e9, WS Woluwe's Bassilia Sakanoko, UTA Arad's Leoh Digbeu", "1994", "the superhero Birdman", "Harrison County", "New York Yankees", "1903", "King Kal\u0101kaua", "Mark \"Chopper\" Read", "ethereal darkwave", "VNO, ICAO: EYVI", "The virus is zoonotic,", "122,067", "the High Court of Admiralty", "Mercer Bears", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "21 December 2017", "1800", "season seven", "glycerol", "an umbrella", "intestines", "Ben Kingsley", "1.2 million people", "84-year-old", "Jacob", "an accomplice", "Steven Spielberg", "Mitch Murray"], "metric_results": {"EM": 0.46875, "QA-F1": 0.598663576007326}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false, false, true], "QA-F1": [0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.25, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4070", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-3065", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-4696", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-4462", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_triviaqa-validation-1015", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770", "mrqa_searchqa-validation-1372"], "SR": 0.46875, "CSR": 0.5386029411764706, "EFR": 1.0, "Overall": 0.7242830882352942}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County", "Prince Antoni Radziwi\u0142\u0142", "Hordaland", "Charles Perrault's", "Via Port Rotterdam", "the First Balkan War", "Australia", "Daniel Espinosa", "1942", "water sprite", "Bury St Edmunds, Suffolk, England", "20 July 1981", "What You Will", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "General Edward Lawrence Logan International Airport", "Blackpool Football Club", "American comic books", "100 million", "Joseph McCarthy", "Volvo 850", "1978", "July 25 to August 4", "Ann", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II", "Oracle Corporation", "Pittsburgh, Pennsylvania", "John Andr\u00e9", "Nine-card Brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Morozov", "its inspiring interpretations of traditional music of pre-Hispanic and contemporary music of the Andes", "The Dragon", "two", "Outside", "Traumnovelle", "the Chechen Republic", "actress and model", "from 1986 to 2013", "Granada", "Guangzhou, China", "British", "Jaguar Land Rover Automotive PLC", "Citgo Petroleum Corporation", "artist and graffiti writer", "B.R. Ambedkar, the chairman of the Drafting Committee", "Presley Smith", "the hydrological cycle or the hydrologic cycle", "mungo Park", "Joe Meek", "Daffy Duck", "in a tenement in the Mumbai suburb of Chembur", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "their culture, religion and national identity", "Popular Science", "a ton", "Latter-day Saints", "more and more suspicious of the way their business books were being handled."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6536181526806526}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, false, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.15999999999999998, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.5, 1.0, 0.2666666666666667, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.5, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-185", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-2663", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-3348", "mrqa_hotpotqa-validation-5766", "mrqa_hotpotqa-validation-4565", "mrqa_naturalquestions-validation-3538", "mrqa_triviaqa-validation-5002", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.515625, "CSR": 0.5381610576923077, "EFR": 1.0, "Overall": 0.7241947115384615}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "Physical", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "novel", "the National Society of Daughters of the American Revolution", "Timmy Sanders", "November 23, 1996 in Japan and May 1997 in the rest of the world", "St Augustine's Abbey", "The Washington Post", "Dan O'Bannon", "Jay Hanna \"Dizzy\" Dean", "UHF channel 44", "North Kesteven,", "Afro-Caribbean", "The Beatles", "\"Menace II Society\"", "September", "March 30, 2025", "the Black Panther Party", "Pinellas County", "Ben Johnston", "Imagine", "Evan Jonigkeit", "CBS", "\"Brickyard\"", "2012", "Candice Susan Swanepoel", "Benny Andersson", "Peter, Paul and Mary", "Kathleen O'Brien", "Blackstone", "the north bank of the North Esk", "Paris", "Hard rock", "Yubin, Yeeun, Sunmi and Hyerim", "\"Complex\" magazine", "Muhammad Ali vs. Jimmy Ellis", "the University of Keele", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "\"The Omega Man\"", "David Dunn", "William Bradford", "FieldTurf", "his fifth studio", "Benj Pasek", "a hand injury", "Freedom Day 27 April 2000", "U2", "the pulmonary arteries", "Pope Benedict XVI", "France", "Taekwondo", "The Tinkler", "since 1983", "the legitimacy of that race.", "the Dukes of Norfolk", "Italy", "chili peppers", "a star"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6454117063492064}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-2358", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-2209", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-1813", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-3644", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-7953", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.515625, "CSR": 0.5377358490566038, "EFR": 1.0, "Overall": 0.7241096698113207}, {"timecode": 53, "before_eval_results": {"predictions": ["a calendar", "Friedrich Nietzsche", "give up the ship", "Lord Carnarvon", "Ireland", "the Glaciers", "white", "Marie Antoinette", "the Aunt Bee", "Great Smoky Mountains National Park", "grasshopper", "a National Park", "Nostradamus", "the malignant disease", "The Cannonball Run", "white sugar", "Amos Muzzey", "The Crow", "the plain of Marathon", "John Keats", "Scott", "a backpacking route", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "Dostoyevsky", "Mike Rowe", "Resident Evil", "Daughter", "Bastille Day", "the United Arab Emirates", "Dramamine", "a tiny little blue Korbat", "the Oktoberfest", "the Negro", "the Empress Josephine", "President McKinley", "Staten Island", "Transformers", "a \"blueberry Cassis Gelato", "the American Civil War", "the declaration of saturated fat", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "an ear", "Indira Gandhi", "the AWACS E-3", "the Director of National Intelligence", "The procedure can be performed at any level in the spine ( cervical, thoracic, or lumbar ) and prevents any movement", "2018", "Peter Paul Rubens", "mink mink", "David Bowie", "1 December 1948", "Lester Ben", "three centuries", "forgery and flying without a valid license,", "Michoacan state,", "\"gotten the balance right\"", "Carpenter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7063244047619047}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.07142857142857142, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-16117", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-12841", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-11962", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-3729", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821"], "SR": 0.609375, "CSR": 0.5390625, "EFR": 1.0, "Overall": 0.724375}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "152", "Phil Sedgmen", "Roberto Cammarelle", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "armoured", "Adrian Cronauer", "Copenhagen", "Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googol", "Canadian Horseshoe Falls", "$SPX", "Mrs Merton", "blues", "Alamo", "Brazil", "baloney cubed", "George Williams", "michael faraday", "George Bush Sr.", "Montmorency", "haddock", "Terry & June", "Tim Peake", "Phil Redmond", "tamale", "Argentina", "St Moritz", "My wife Next Door", "Woody's horse", "Penelope Keith", "Sinclair Lewis", "deer", "brazil", "Barry White", "Robin", "Parchman Farm", "Canada", "The Hague Conventions", "Portugal", "silver", "Moby Dick", "X&Y ( 2005 )", "`` Killer Within ''", "prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "The Worm", "\"The Golden Girls,\"", "the legislation will foster racial profiling,", "his new boss, Adam Scott,", "Easy Rawlins", "William McKinley", "the Scripps National Spelling Bee", "Berlin"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6416666666666666}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-6992", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-3131", "mrqa_naturalquestions-validation-6206", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187"], "SR": 0.578125, "CSR": 0.5397727272727273, "EFR": 0.9629629629629629, "Overall": 0.7171096380471381}, {"timecode": 55, "before_eval_results": {"predictions": ["detainees are not drugged unless there is a medical reason to do so.", "the man was dead,", "CNN's Larry King", "Five masked men dressed in black", "customers", "the United States", "Iraq", "the Iranian consulate,", "parachuted to the ground", "ties to paramilitary groups,", "Matthew Chance", "heroin labs in neighboring countries and along trafficking routes.", "Bright Automotive", "NASCAR", "Clifford Harris", "Muslim", "Copts", "adult reality show", "In \"Kambakkht Ishq,\"", "Tens of thousands of new voters", "safer controls in chemical-producing countries and stronger intelligence-sharing between Afghanistan and its neighbors.", "1831", "the Ku Klux Klan", "President Obama", "pine beetles", "lower house of parliament", "Robert Barnett", "Iran", "Daniel Radcliffe", "has publicly criticized his father's parenting skills.", "California", "two years after he was ousted as prime minister in a military coup.", "six", "remains unknown,", "$89", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Charles Darwin", "acid attack", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy", "Channel 4 has been criticized for creating a new television show which looks at how children as young as eight would cope without their parents for two weeks.", "gustav's top winds", "Rwanda", "2", "Bob Johnson", "the \"bystander effect\"", "\"Dancing With the Stars.\"", "his club", "Microsoft", "two years", "Confederate forces", "Adam Sandler", "1,228 km / h ( 763 mph )", "Edward Yorke", "Charlie Sheen", "silversmith", "Joseph Ruttenberg", "the International Federation of Competitive eating", "Valley Falls", "the Provisional Irish Republican Army", "Australia", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.5, "QA-F1": 0.6125262605042017}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, false, true, true, true], "QA-F1": [0.6666666666666666, 0.4, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.08333333333333334, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 0.058823529411764705, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.14285714285714285, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.6, 1.0, 0.4, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-1877", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-1541", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_naturalquestions-validation-5983", "mrqa_triviaqa-validation-1475", "mrqa_hotpotqa-validation-5224", "mrqa_hotpotqa-validation-698", "mrqa_searchqa-validation-1388"], "SR": 0.5, "CSR": 0.5390625, "EFR": 0.96875, "Overall": 0.718125}, {"timecode": 56, "before_eval_results": {"predictions": ["the Stratofortress", "the peso", "the nucleus", "prednisone and prednisolone", "the Starship Troopers", "Stalin", "the Ogallala aquifer", "the egg", "the reticulated Python", "William Proxmire", "George Orwell", "the Takana", "lazy Susan", "The Man", "herbivore", "a giant leap", "Psycho", "a believer", "Athens", "makes perfect sense", "a zoos", "Olivia Newton-John", "Mickey Gilley", "Oral Roberts", "staff", "Constantine XI", "tin", "the Ganges", "Captain Nemo", "Dave Brubeck Quartet", "the Yellow Ribbon", "Stevie Wonder", "Richmond, Virginia", "Jupiter", "a tarantula", "Apple", "depression", "the Mausolus", "Act One", "the Star of Bombay", "the Rhapsody", "the Ziegfeld Follies", "a Bloody Mary & a screwdrivers Vodka", "Ronald", "Mount Kilimanjaro", "a militia", "Delaware", "Graceland", "the MiG-29", "Don Michael Corleone", "the libido", "John F. Kennedy", "Siddharth Arora / Vibhav Roy", "in the pouring rain at a rest stop", "Munich", "the Circle line", "1123", "Julie Kavner", "saint Benedict", "A Boltzmann machine", "\"Abbey Road.\"", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5369791666666667}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, true, false, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2168", "mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-1616", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-4802", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-10267", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-9015", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-2176", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658", "mrqa_hotpotqa-validation-1078"], "SR": 0.4375, "CSR": 0.5372807017543859, "EFR": 1.0, "Overall": 0.7240186403508773}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "the Cup", "Merlin", "sculpture", "Alien", "live Large", "mariachi", "the first player to return after a kidney", "excruciating", "Kilimanjaro", "an opinion", "Apocalypse", "pardon", "(St) Peter", "Calais", "Twenty", "New York", "a tortuga", "Thomas Paine", "Isaac Newton", "American Wedding", "Johnny Smith", "Tears for Fears", "Jamestown", "the Rhine", "blacksmith", "Mohs", "Katharine McPhee", "October 7, 1913", "Prince", "(Cnut) the Great", "spiral", "Karl Rove", "trout", "(Vijay) Singh", "geometric", "Louisiana", "the Cumberland", "Chariots of Fire", "a reptile", "Sweden", "pink", "an eyelid", "Hong Kong", "The Addams Family", "a bacterium", "Sanders", "a more expensive in-house payment plan", "Winston Churchill", "New Year's", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "December 8, 2013", "Jupiter", "90%", "Timothy Dalton", "the University of Oxford", "1,467", "Vision of Love", "grabbed a pupil by the throat and threw her against a wall", "Paul Schlesselman", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5794642857142857}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, false, false, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-6635", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-2121", "mrqa_searchqa-validation-7362", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-9919", "mrqa_searchqa-validation-7951", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-10072", "mrqa_searchqa-validation-12380", "mrqa_searchqa-validation-7507", "mrqa_searchqa-validation-5688", "mrqa_naturalquestions-validation-3953", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803"], "SR": 0.515625, "CSR": 0.5369073275862069, "EFR": 1.0, "Overall": 0.7239439655172414}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "super-yacht", "pulling Turkey into any kind of engagement with the Taliban", "tells stories of different women coping with breast cancer in five vignettes.", "housing, business and infrastructure repairs", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty", "school", "Asashoryu", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "China", "\"I never thought any of this was going to be easy,\"", "\"It is I, the chief executive officer, the one on the very top,", "longest domestic relay in Olympic history", "a man's lifeless, naked body", "Both Won Sei Hoon, who heads South Korea's National Intelligence Service, and Defense Minister Kim Kwan Jim", "military trials", "183", "Nirvana", "Patrick McGoohan,", "55-year-old", "Zimbabwe", "new Touch,", "woman who received the first-ever near-total face transplant in the United States", "International Polo Club Palm Beach in Wellington, Florida", "President Bush", "All three pleaded not guilty in an appearance last week in Broward County Circuit Court.", "all the comforts of home", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "Polo because \"it was the sport of kings.", "a three-story residential building in downtown Nairobi", "cancer", "Hussein's Revolutionary Command Council", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "people", "Rev. Alberto Cutie", "Daryeel Bulasho Guud", "magazine", "FBI Special Agent Daniel Cain,", "Graham's wife", "February 12", "Oaxaca, Mexico", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "strict interpretation of sharia forbids girls from attending school, requires veils for women and beards for men,", "trading goods and services without exchanging money", "two people", "11 countries", "Some of them", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing", "Ben Roethlisberger", "Jenny Humphrey", "Brian Kesinger", "In November 2016, she began starring in the reality television series Total Divas on E! as part of the main cast", "m69", "kinshasa, Zaire", "toasts", "DreamWorks Animation", "Debbie Harry", "2004", "a cord", "Bob Dylan", "Existentialism", "Nancy Walker & Efrem Zimbalist Jr."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6214213956333521}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.72, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.9333333333333333, 1.0, 0.4444444444444445, 0.0, 0.17391304347826086, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.2222222222222222, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.41666666666666663, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-4124", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-535", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-14208"], "SR": 0.53125, "CSR": 0.536811440677966, "EFR": 1.0, "Overall": 0.7239247881355932}, {"timecode": 59, "before_eval_results": {"predictions": ["Greenwood, Archer, and Pine", "Pakistan", "DTM", "Vernon Kay", "Everglades", "ten episodes", "Tyler Posey", "Maxwell Atoms", "Scandinavian design", "Hugh Hefner", "Pasek and Paul", "Toxics Release Inventory", "Oregon", "\"Mrs. Eastwood & Company\"", "Blackpool Football Club", "Denver, Colorado", "Edward M. Kennedy", "Boeing EA-18G Growler", "21st Century Fox", "Pennsylvania's", "Danielle Fernandes Dominique Schuelein- Steel", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "Operation Gladio", "from 1952 until 1971", "authoritarian tendencies", "AOL Inc.", "World War II", "coca wine", "Thomas Perez", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "Best Supporting Actress", "New Jersey", "Ian Rush", "Erich Maria Remarque", "Australian", "youngest TV director ever", "Arthur William Bell III", "Kaiser Steel", "Delaware River", "Jean Acker", "Anheuser-Busch", "MG Car Company Limited", "Boston Celtics", "May 2008", "Hungarian Rhapsody No. 2", "24 hours later", "Brian Steele", "35 to 40 hours per week", "Ceefax", "Dieppe Raid", "October 30, 1683", "the iconic Hollywood headquarters of Capitol Records,", "228", "son of Gabon's former president", "pig stealers", "a vote-recording machine", "Han Solo", "Longo-Ciprelli"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6278645833333334}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true, false, true, true, false, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, true, true], "QA-F1": [0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.6666666666666665, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-4375", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-1512", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5535", "mrqa_hotpotqa-validation-5066", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-2131", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-2977", "mrqa_naturalquestions-validation-215", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6758", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-2346", "mrqa_searchqa-validation-10636"], "SR": 0.546875, "CSR": 0.5369791666666667, "EFR": 1.0, "Overall": 0.7239583333333334}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "the plane was in fine condition at takeoff,", "Joan Rivers", "'We want to reset our relationship and so we will do it together.'\"", "Alison Sweeney,", "the Louvre", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "Russell", "43,000", "269,000", "flooding", "\"I don't watch TV,\"", "Patrick McGoohan,", "ambassadors", "NATO", "man's lifeless, naked body", "hanged in 1979", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "people", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell", "greater spending and investment on the country's infrastructure", "\"Watchmen\"", "Noida,", "body bags", "Afghanistan", "10 to 15 percent", "His flight Monday originated in Cairo, Egypt,", "Annie Duke", "an engineering and construction company", "the shoreline of the city of Quebradillas", "At least 15", "the Harris Fire.", "a one-of-a-kind navy dress with red lining", "monthly allowance", "The reason? Too many glass shards left by beer drinkers in the city center,", "the legitimacy of that race", "Nigeria", "Andrew Morris,", "everyone can use solar and renewable energy at home everyday,\"", "Drottningtorget", "the driver", "The house was rocking back and forth in a way that I cannot even begin to", "his cousin D\u00e1in", "Jesse McCartney", "the American Civil War", "T.S. Eliot", "White", "Australia and Ireland", "18 December 1975", "1970", "Copenhagen", "the Pacemakers", "Khartoum", "Stand by Me", "Italian"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6287045403982618}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, false, false, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.14285714285714288, 0.19047619047619047, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.04761904761904762, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.9565217391304348, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-417", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-2599", "mrqa_hotpotqa-validation-4172", "mrqa_searchqa-validation-6409"], "SR": 0.546875, "CSR": 0.537141393442623, "EFR": 1.0, "Overall": 0.7239907786885247}, {"timecode": 61, "before_eval_results": {"predictions": ["allergic reaction to peanuts,", "Flying a space shuttle", "Santaquin City, Utah, home", "it has not", "Ed McMahon,", "Bob Bogle", "183", "English and Russian", "4-1 Serie A win at Bologna on Sunday", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "Tuesday afternoon.", "General Motors'", "Four Americans", "Ford", "Lula da Silva", "adopted new and more restrictive policies, and improved oversight procedures for interrogation and detention operations.", "16 Indiana National Guard soldiers", "the body of the aircraft", "Venus Williams", "onto the college campus.", "The cervical cancer vaccine,", "Bright Automotive,", "The tower will be built in the Saudi town of Jeddah", "Europe", "$7.8 million", "Polo because \"it was the sport of kings.", "The elections are slated for Saturday.", "United's", "propofol", "said she was humiliated by last month's incident,", "CNN", "school,", "Hurricane Gustav", "The cervical cancer vaccine,", "two", "outfit from designer", "the two bodies", "misdemeanor assault charges", "the man facing up, with his arms out to the side.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines", "Cambodian government", "Arsene Wenger", "The local Republican Party", "the Gulf", "former Procol Harum bandmate Gary Brooker", "27", "The Tupolev Tu-160 strategic bombers landed at Venezuela's Libertador military airfield and \"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "for housing, business and infrastructure repairs,", "travel with privately armed guards.", "toys or doorbell installations", "British citizens", "Justin Timberlake", "Greece", "Brighton", "eagle", "Umberto II", "The Longest Yard", "Lucille D\u00e9sir\u00e9e Ball", "Louis XIV", "the Bronx", "Flamboyant", "South Africa"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6964995941558443}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, true, false, false, true, false, false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.22222222222222224, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.5, 0.5454545454545454, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2457", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3816", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2970", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-3250", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_hotpotqa-validation-2827"], "SR": 0.578125, "CSR": 0.5378024193548387, "EFR": 1.0, "Overall": 0.7241229838709679}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0 draw away to Saudi Arabia", "a portrait of William Shakespeare", "Al Gore.", "200", "T.I.", "the media", "Friday,", "carving in the middle of our Mountain View, California, campus.", "Arizona", "could be at work on building a nuclear weapon.", "two suicide bombers,", "56", "April 28", "former Boca Juniors teammate", "Fernando Caceres", "\"BADBUL,\"", "Kurt Cobain", "nude beaches.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "East Java", "\"The Cycle of Life,\"", "diplomatic relations", "supermodel", "10 below", "1,073", "Zoe's Ark", "fled Zimbabwe", "girls around 11 or 12.", "passengers on the Miva Marmara", "food, music, culture and language of Latin America", "a lump in Henry's nether regions was a cancerous tumor.", "Tennessee.", "Bright Automotive,", "nuclear", "first completely full-length computer-generated animated film with Pixar's \"Toy Story\"", "\"Up,\"", "165-room", "\"Oprah is an angel, she is God-sent,\"", "al Qaeda,", "potential jurors", "Susan Atkins,", "Charlotte Gainsbourg and Willem Dafoe", "daughter, Zeina,", "Omar", "Hu and other top Chinese officials", "United States", "Nakheel Tower", "speaking out about a cause someone feels passionate about.", "25", "Anil Kapoor.", "President Obama and Britain's Prince Charles", "Wembley Stadium", "a ligand - binding site on a receptor or enzyme is distinct from the active site", "40.5 metres ( 133 ft )", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Bob Mould", "331", "2008", "Ginsburg", "Chandler's", "Seth", "peacock"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5866750437062936}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, false, true, false, false, false, true, false, false, false, false, true, false, true, true], "QA-F1": [0.5, 0.4, 0.0, 1.0, 0.25, 0.0, 1.0, 0.1818181818181818, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.26666666666666666, 1.0, 0.14285714285714285, 0.6153846153846153, 0.0, 1.0, 0.5, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-3409", "mrqa_hotpotqa-validation-4598", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-12746"], "SR": 0.46875, "CSR": 0.5367063492063492, "EFR": 0.9705882352941176, "Overall": 0.7180214169000934}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "achievement gaps between racial groups", "journalists and aid workers are prohibited from entering the Ogaden,", "the New York Philharmonic Orchestra in North Korea to Dharamsala,", "handed over the AR-15 and two other rifles and left the cabin.", "like a class to help women \"learn how to dance and feel sexy,\"", "German Foreign Ministry,", "shoes that are also worn by dogs who walk on ice in Alaska.", "Ten South African ministers and the deputy president", "militants in Afghanistan", "Japanese officials", "urged NATO to take a more active role in countering the spread of the", "poor.", "head for Italy.", "Sixteen", "poems telling of the pain and suffering of children just like her", "(3 degrees Fahrenheit),", "Technological Institute of Higher Learning of Monterrey,", "Orioles", "Golden Gate Yacht Club of San Francisco", "at least 300", "a national telephone survey of more than 78,000 parents of children ages 3 to 17.", "ballots", "and renewable energy at home everyday,\"", "the Obama and McCain camps", "The Ministry of Defense", "part of the proceeds from sales", "The minister later apologized, telling CNN his comments had been taken out of context.", "Fernando Torres", "eight-day", "Alexey Pajitnov,", "three", "Ozzy Osbourne", "\"Dancing With the Stars.", "civilians,", "March 3, 2008,", "for a long time, people thought this was a small problem,\"", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Christianity and Judaism", "Casalesi Camorra clan", "after the party made a poor showing last year against another Communist movement.", "tranquil beaches,", "$1.5 million.", "Booches Billiard Hall,", "\"peregruzka\"", "for an independent homeland since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama World Tour", "Kimberlin Brown", "A turlough, or turlach", "1910", "Kirk Douglas", "theater hall", "Vikram, Jyothika and Reemma Sen", "Dutch Empire", "Royal Navy rank of Captain", "Department of Homeland Security", "France", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6763160582215342}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.42857142857142855, 0.4444444444444445, 0.19999999999999998, 0.0, 0.0, 0.7368421052631579, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.4, 0.33333333333333337, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-1995", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1261", "mrqa_newsqa-validation-3075", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-4210", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-967", "mrqa_newsqa-validation-2353", "mrqa_newsqa-validation-372", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-2986", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_naturalquestions-validation-10396"], "SR": 0.546875, "CSR": 0.536865234375, "EFR": 1.0, "Overall": 0.7239355468750001}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser,", "sportswear", "teenage", "July 23.", "Landry", "an American who entered the country illegally from China on Christmas Eve.", "Chester Arthur Stiles,", "United States", "Pakistan's High Commission in India", "Wednesday.", "Wigan Athletic", "Amir Zaki", "poems", "Drew Kesse", "A 22-year-old college student in Boston, Massachusetts,", "sniff out cell phones.", "Longo-Ciprelli", "terence Leonard", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944", "\"I'm just getting started.\"", "\"The precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "more than 30", "his salary", "refused to refer the case of Mohammed al-Qahtani to prosecutors", "free laundry service.", "rural California,", "Robert Park", "11th year in a row.", "83 eggs.", "future relations between the Middle East and Washington.", "school", "a plaque", "death squad killings", "a nuclear weapon", "Kitty Kelley", "\"The missile defense system is not aimed at Russia,\"", "Oregon", "Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "unparalleled fundraising and an overwhelming ground game.", "$3 billion,", "G Chat away message.", "Bobby Jindal", "acted in self defense in punching businessman Marcus McGhee.", "potential revenues from oil and gas", "Sen. Barack Obama", "jobs", "cannonball", "in a geographical coordinate system at which longitude is defined to be 0 \u00b0", "Darlene Cates", "Colette", "the crow", "douglas", "26 August 2013", "11", "January 15, 2016", "piano", "Palestine", "Barnard", "Chiltern Hills"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6392435689310689}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, true, false, false, true, true, true, true, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.30769230769230765, 0.888888888888889, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8181818181818181, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.5, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.34285714285714286, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-690", "mrqa_newsqa-validation-3859", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516"], "SR": 0.546875, "CSR": 0.5370192307692307, "EFR": 1.0, "Overall": 0.7239663461538461}, {"timecode": 65, "before_eval_results": {"predictions": ["banned substance cortisone.", "Larry", "The Ski Train", "housing, business and infrastructure repairs,", "Joe Harn", "Haiti", "Uzbekistan", "Israel", "Nigeria, Africa's largest producer.", "Mexico", "two Metro transit trains that crashed the day before,", "short- and long-range weapons with ammunition,", "Denver, Colorado.", "\"He hears what I'm saying, but there's just no coming through,\"", "the single-engine Cessna 206", "no need for such humility.", "Angelo Nieves, an Orange County Sheriff's Department commander,", "could be secretly working on a nuclear weapon", "was arrested Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Carol Fowler", "Republican senators", "\"I'm certainly not nearly as good of a speaker as he is.\"", "April 22.", "Manuel Mejia Munera", "outfit from designer", "five", "Ozzy Osbourne", "Sarah,", "Carol Browner", "pro-democracy activists", "eight", "Fullerton, California,", "Hawaii", "Bill Haas", "\"A Lion Among Men,\"", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Donald Duck", "Narayanthi Royal Palace", "all faiths", "Adam Yahiye Gadahn, also known as Azzam", "Turkey", "his company Polo because \"it was the sport of kings.", "Texas and Oklahoma to points east,", "\u00a320 million ($41.1 million) fortune", "unwanted horses", "a million", "New York", "19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "it -- you know -- black is beautiful,\"", "Arnold Schoenberg", "N\u0289m\u0289n\u0289", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "Einstein", "Nova Scotia", "pyrotechnic", "Battelle Energy Alliance", "Lake County, Illinois", "Eran Kolirin", "cryptids", "Tigers", "Herod", "leopard"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5861440001725329}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false], "QA-F1": [0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.08695652173913043, 0.0, 0.22222222222222224, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6, 1.0, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.782608695652174, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4053", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.46875, "CSR": 0.5359848484848485, "EFR": 1.0, "Overall": 0.7237594696969698}, {"timecode": 66, "before_eval_results": {"predictions": ["Spaniard", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "Iran's development of a nuclear weapon", "\"green-card warriors\"", "a space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Columbia, Missouri.", "Both men were hospitalized and expected to survive,", "Harris provided the bodyguard $12,000 to buy the weapons,", "Bowe Bergdahl", "many different", "President Bush", "$17,000", "the Employee Free Choice Act", "Sadat at the hands of four military officers during an annual parade celebrating the anniversary of Egypt's 1973 war with Israel.", "Judge Herman Thomas", "The worst snowstorm to hit Britain in 18 years", "Gary Coleman", "Madonna", "the content of the speech,", "the Bush administration's controversial system of military trials for some Guant Bay detainees.", "a traditional form of lounge music that flourished in 1940's Japan.", "Larry King", "250,000", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "managing his time.", "1980,", "Omar", "Scotland", "Mugabe's opponents", "Tutsi ethnic minority and the Hutu majority had been at odds even before 1994.", "his business dealings for possible securities violations", "January", "\"bleaching\" in which algae living in the coral die and leave behind whitened skeletons.", "Millvina Dean,", "diamond-studded braces.", "Sovereign Wealth Funds", "fake his own death by crashing his private plane into a Florida swamp.", "was found in a hotel near Fort Bragg.", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "Apple Inc.", "38,", "terrorists operating within its borders.", "Henrik Stenson", "1995", "a red minivan ran a red light and struck two vehicles at an intersection,", "fear of losing their licenses to fly.", "Anjuna beach in Goa", "Jeffrey Jamaleldine took a bullet to his chin that blew out much of his jaw", "not doing more since taking office.", "demonstrations", "military units from their parent countries of Great Britain and France, as well as by American Indian allies", "naturalization law", "sigurd the Dragonslayer", "blancmange", "apple", "Los Alamos National Laboratory", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "Joplin", "Italy", "I.M. Pei", "Balaam then sets out in the morning with the princes of Moab"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5720226821789323}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, false, false, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.2, 0.0, 1.0, 1.0, 1.0, 1.0, 0.09999999999999999, 0.5, 0.2222222222222222, 1.0, 1.0, 0.5454545454545454, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.09523809523809523, 0.0, 0.4, 0.0909090909090909, 0.16666666666666669, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-3301", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_naturalquestions-validation-230"], "SR": 0.46875, "CSR": 0.5349813432835822, "EFR": 1.0, "Overall": 0.7235587686567164}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "road-building", "candlestick", "Jaipur", "to heat and boil water for tea", "palaeozoic Era", "Martin Pipe", "Wordsworth", "Ginger Rogers", "palace of culture of the Podshipnikov Zavod", "borax", "United States Dollars", "peregrines", "7th", "muscle tissue", "hurdle", "Derby Stakes", "Easter Parade", "Basketball", "HMS Amethyst", "lion", "sargento", "whistling tune, the Colonel Bogey March,", "Cyprus", "King George VI", "ankle joint", "Greyfriars Bobby", "honeycomb structures", "flea", "a burial cloak", "jockey", "the NBA", "l. p. Hartley", "leander", "siegfried", "entropy", "Wadsworth", "green", "Amelia Earhart", "James Hogg", "lacrimal fluid", "Loki Laufeyiarson,", "The Apartment", "manfred von Richthofen", "God", "1879", "Los Angeles", "lomond", "isosceles", "black", "ballet", "Boston Red Sox", "1967 onwards", "thermodynamic temperature", "Bolshoi Theatre", "My Boss, My Hero", "Mermaids", "death squad killings", "along the equator between South America and Africa.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "the bumblebee", "12 to 36 months old"], "metric_results": {"EM": 0.53125, "QA-F1": 0.612109375}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, false, false, true, true, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.42857142857142855, 0.8750000000000001, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-4293", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-4575", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-1541", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6429", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-9761", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_hotpotqa-validation-4446", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_naturalquestions-validation-8352"], "SR": 0.53125, "CSR": 0.5349264705882353, "EFR": 1.0, "Overall": 0.7235477941176471}, {"timecode": 68, "before_eval_results": {"predictions": ["Bed and breakfast", "smen", "the northern borders of West Virginia and Kentucky ; and the southern borders of Ohio, Indiana and Illinois", "the Americans", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "2018", "California's Del Norte Coast, Jedediah Smith, and Prairie Creek Redwoods State Parks", "Zuzu", "257,083", "Caparra", "the Norman conquest of England", "Gustav Bauer, the head of the new government, sent a telegram stating his intention to sign the treaty if certain articles were withdrawn", "Shawn", "if the concentration of a compound exceeds its solubility", "the United States", "first published in the First Folio in 1623", "the round ( of ) round, bottom round, and top round", "1957", "360", "118", "the gastrointestinal tract", "Lori McKenna", "Wisconsin", "Tbilisi", "the Latin centum", "in the fourth Anglo - Mysore war during which Tipu Sultan was killed", "The Epistle of Paul to the Philippians", "His last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "Elvis Presley", "2014", "Best Picture, Best Director for Fincher, Best Actor for Pitt and Best Supporting Actress for Taraji P. Henson", "Sweden's long - standing policy of neutrality was tested on many occasions during the 1930s", "291 episodes", "Cairo, Illinois", "No Secrets", "spacewar", "12", "4 January 2011", "New Zealand to New Guinea", "Bill Russell", "Seattle, Washington", "the pituitary gland", "In 2010, along with Jackie Chan, Smith starred in The Karate Kid, a remake of the 1984 film", "Buddhist missionaries", "the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "1956", "January", "gamin of the streets of London", "huff & puff: Can You Blow Down the Houses of the Three Little Pigs?", "Brad Silberling", "1941", "Nick on Sunset theater", "July in the Philippines", "iCloud service", "Thursday", "Bonobo", "Toward", "the Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.4375, "QA-F1": 0.565324919256371}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.125, 0.5, 1.0, 0.0, 0.25, 0.1904761904761905, 0.0, 0.923076923076923, 1.0, 0.0, 0.16666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.09999999999999999, 0.5555555555555556, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.3076923076923077, 1.0, 0.125, 0.0, 0.6, 0.5, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 0.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.8571428571428571, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-6749", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-10704", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_searchqa-validation-12035"], "SR": 0.4375, "CSR": 0.5335144927536232, "EFR": 0.9722222222222222, "Overall": 0.7177098429951692}, {"timecode": 69, "before_eval_results": {"predictions": ["Whitechapel", "Uganda", "manhattan horror", "Brazil", "soraya", "white and black sets", "bristol", "Florida", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "Cambridge", "daltonism", "Cambodia", "Prussian Landsturm", "Russia", "1925 novel", "cooperative", "180 degrees", "blue", "john L. Sullivan, James J. Corbett, In the Ring With john Fitzsimmons", "lady macbeth", "Andre Agassi", "hawk", "The Times of London", "john le carr\u00e9", "german New Guinea", "Albania", "zoological", "mata hari", "the different levels of importance of human psychological and physical needs", "polo", "gulliver", "rating agency", "Saturday Night Live", "Bayern Munich", "Alexander Dubcek", "Hydrogen", "Guinea", "ghee", "octavian", "lathe", "one Canada Square in Canary Wharf,", "Snoopy", "auk", "snark", "general strike to support mine workers", "Tokyo Metropolitan Assembly,", "siegfried castle", "Walter Mondale", "fresh nuclear fuel", "the plane crash in 1959", "Scotty Grainger Jr.", "The Kingkiller Chronicle series", "3.9 mi", "$1.5 million", "Buddhism", "grabbed the gun and  took her own life.", "Space Shuttle", "Smithfield", "Aleksandr Solzhenitsyn", "10 Years"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5879734848484849}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-3373", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_newsqa-validation-2197"], "SR": 0.546875, "CSR": 0.5337053571428572, "EFR": 0.9655172413793104, "Overall": 0.7164070197044335}, {"timecode": 70, "before_eval_results": {"predictions": ["Leigh Ann Fetter", "three", "high jump", "ejaz khan", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "vitis vinifera L.,", "evolution", "Philip Larkin", "numbria", "Kent", "rabbit", "Jack Brabham", "peterborough United", "hanover", "square root", "b\u00e9al Feirste", "Pete Sampras", "prussia", "red sea", "cats", "The French Connection", "eagles", "Moaning Myrtle", "chile", "Dubai", "ceeLo Green", "photographer", "Justin Bieber", "Greece", "m\u00e1qu\u00e8", "scar", "stars on 45 Medley", "chetenham & Gloucester", "Jim Bowie knife", "turkish", "Margaret Thatcher", "Achille Lauro", "botham", "stop motion effects", "Claremorris", "Ellis Island", "fijian", "tripezoid", "wood vii poyet", "john Huston", "vii gogh", "thomas Harris", "Martin Vanuren", "Moscow", "2005", "the governor of West Virginia, who is elected to a four - year term at the same time as presidential elections", "Spanish", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman is in critical condition in a Provo, Utah, hospital,", "2010", "Uzbekistan", "Jerry Rice", "leotard", "Ford", "Shakira"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6069940476190476}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, false, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.4, 1.0, 1.0, 0.38095238095238093, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-6644", "mrqa_triviaqa-validation-841", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-4502", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-1672", "mrqa_triviaqa-validation-7032", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_naturalquestions-validation-4207", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232"], "SR": 0.546875, "CSR": 0.5338908450704225, "EFR": 1.0, "Overall": 0.7233406690140846}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "Moon Shot", "Kim Sung-su,", "Burma", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "Aerol\u00edneas Argentinas", "October 15, 2013", "Neha Sharma", "Netherlands", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York.", "1853", "Kew", "Apprendi v. New Jersey", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "John Anderson, Elizabeth Banks, Jon Hamm, Kristin McGee, Julianne Moore, Michael Sheen, Jason Sudeikis, and Dean Winters", "11", "mid-tempo pop and R&B love song", "7 miles", "1942", "Pollywood", "Carver Dana Andrews", "July 25 to August 4", "2015", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "special economic zone", "Darkroom", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "Guant\u00e1namo Bay", "France", "Wordsworth", "spain", "greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "\"wipe out\" the United States if provoked.", "two years", "Yahtzee", "Hinduism", "60 Minutes", "\"The closest approach to the original sound\""], "metric_results": {"EM": 0.75, "QA-F1": 0.8017641760651629}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-4299", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.75, "CSR": 0.5368923611111112, "EFR": 1.0, "Overall": 0.7239409722222223}, {"timecode": 72, "before_eval_results": {"predictions": ["the conclusion of a syllogism", "showed such a disregard for the life and safety of others as to amount to a crime and deserve punishment", "100,000", "2004", "the host community", "8", "Bob Dylan", "Tony Orlando and Dawn", "2014 Winter Olympics in Sochi, Russia", "the Pir Panjal Range in Jammu and Kashmir", "nearby objects show a larger parallax than farther objects when observed from different positions", "Kansas", "1885", "the final episode of the series", "Wisconsin", "the theory of plate tectonics", "stems and roots of certain vascular plants", "the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "an Islamic shrine located on the Temple Mount in the Old City of Jerusalem", "2007 World Series", "Massachusetts", "Mark Jackson", "John Coffey", "antimeridian", "dust", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Kida", "Selena Gomez", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "Elvis Presley", "the federal government", "2013", "England", "Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "the metaphase of cell division", "73", "the League of Communists of Yugoslavia party", "Interphase", "1902", "the midpiece", "seven", "Ben Savage", "Virginia", "Tom Hanks", "Daya Jethalal Gada", "system of state ownership of the means of production", "Gunpei Yokoi", "the Alamodome", "de Havilland Moth", "architecture", "Bermuda", "win world titles in four weight classes", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Neymar", "22", "opium", "Roger Federer", "satirical", "Gomer", "Ashlee Simpson", "Denmark"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6077629697712418}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, false, true, true, true, true, false, true, true, false], "QA-F1": [0.35294117647058826, 0.8095238095238095, 0.07999999999999999, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.14285714285714288, 1.0, 0.4, 1.0, 1.0, 0.0, 0.22222222222222224, 0.33333333333333337, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666667, 0.4, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-3243", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-10026", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-1909", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_triviaqa-validation-1421", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-15285", "mrqa_triviaqa-validation-4962"], "SR": 0.53125, "CSR": 0.5368150684931507, "EFR": 0.9666666666666667, "Overall": 0.7172588470319635}, {"timecode": 73, "before_eval_results": {"predictions": ["along the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Kirstjen Nielsen", "May 2017", "Barbara Windsor", "the ninth w\u0101", "North Africa", "Bart Millard", "Jesse Wesley Williams", "Lucius Verus", "1910", "FIGG Bridge Engineers, a Tallahassee - based firm", "John Smith", "Joanne Wheatley", "`` Everywhere ''", "Watson and Crick", "September 29", "Lead and lead dioxide", "1928", "Taylor Michel Momsen", "Magnavox Odyssey", "The Lightning thief", "2015", "1971", "Sara Gilbert", "1962", "the fifth studio album by English rock band the Beatles", "John Smith", "Jane Fonda -- Chelsea Thayer Wayne", "Arnold Schoenberg", "the Election Commission of India", "203", "using a baby as bait, allowing a child to go through a torturous treatment to gain information, and allowing Dean to become a Vampire", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Charlton Heston", "1877", "to `` help bring creative projects to life ''", "Joan Baez", "Joseph Nye Welch", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "the Jurchen Aisin Gioro clan in Manchuria", "Sanchez Navarro", "Spencer Milligan", "Neil Diamond", "Saturn", "clog", "Kevin the Gerbil", "Tampa", "1980", "January 28, 2016", "Jaipur", "five", "July", "a taro", "Match Game", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.625, "QA-F1": 0.7010573308270676}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true, false, true, false, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 0.21052631578947367, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-9521", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-9644", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7311", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2866", "mrqa_triviaqa-validation-249", "mrqa_hotpotqa-validation-2215", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-270", "mrqa_searchqa-validation-2100"], "SR": 0.625, "CSR": 0.5380067567567568, "EFR": 0.9583333333333334, "Overall": 0.715830518018018}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland Raiders", "Russell Stover", "a hub", "a franchise", "the Maccabees", "Macbeth", "Clay Aiken", "Scrabble", "Passover", "the masses", "China", "a blitz", "New Wave", "a commune", "a ring", "Thames", "Tracy Monroe", "hockey", "Hans Christian Andersen", "Louis Philippe", "The Color Purple", "whales", "Jane Addams", "Martin Clunes", "Tanzania", "Oracle", "an inch", "death", "Henry Wadsworth", "Jeb Bush", "Geneva", "humility", "bdellium", "Twelve Thirty", "Diatomaceous earth", "$8.2 trillion", "a pig", "Sesli Szlk", "Existentialism", "ashes", "Julius Caesar", "Jack London", "Isaac Newton", "Charles I", "Kevin Costner", "Antichrist", "the treble clef", "uranium", "Louisiana", "Deuce Bigalow", "composting", "SummerSlam", "August 2, 1990", "four", "tweed", "papeye", "Denmark", "Trappist beer", "4,530", "Steve Prohm", "seven", "Airbus A330-200", "Symbionese Liberation Army", "Manitowoc County"], "metric_results": {"EM": 0.609375, "QA-F1": 0.659375}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-1313", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-13356", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-9751", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-7832", "mrqa_naturalquestions-validation-6049", "mrqa_triviaqa-validation-6580", "mrqa_triviaqa-validation-7472", "mrqa_hotpotqa-validation-1307", "mrqa_hotpotqa-validation-3458"], "SR": 0.609375, "CSR": 0.5389583333333333, "EFR": 1.0, "Overall": 0.7243541666666667}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "James Bolam", "the main highway entrance at California State Route 1,", "a vehicle that is both four - wheel - drive and primarily a road car", "Turing", "B.F. Skinner", "hydrogen", "France", "William the Conqueror", "111", "1983", "Baker, California", "a routing table", "Paul Hogan", "the 9th century", "Asuka", "Jason Momoa", "James Snyder", "the President", "Spanish missionaries, ranchers and troops", "Gustav Bauer", "art of the book and architecture", "white blood cell in a vertebrate's immune system", "around 2.45 billion years ago ( 2,45 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "Golde", "March 31, 2017", "Incudomalleolar joint", "( born November 28, 1973 )", "Gupta Empire", "stable, non-radioactive rubidium - 85", "3 ( 55 -- 69 % ) & 4 ( 40 -- 54 % )", "the summer of 1979", "John Roberts", "Spanish / Basque origin", "U.S. service members who have died without their remains being identified", "December 1349", "Glenn Close", "Robert Remak", "the Yankees", "studying All My Sons by Arthur Miller, a play about a man whose choice to send out faulty airplane parts for the good of his business and family caused the death of twenty one pilots during World War II", "International System of Units ( SI )", "Rigg", "electron donors", "Bill Patriots", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "the underground organization of the Irish Republican Brotherhood (see 2.272n) in the early twentieth century", "Haystacks", "1967", "Yubin, Yeeun", "Men's 100 metres", "sedative", "a sailboat matching the description of the missing 38-foot boat was found overturned about 5:15 p.m. Saturday,", "'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's", "Patrick Henry", "Samuel Joel \" Zero\" Mostel"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7630208333333334}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4, 0.13333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-438", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-2810", "mrqa_hotpotqa-validation-2232", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_searchqa-validation-3069", "mrqa_hotpotqa-validation-3909"], "SR": 0.671875, "CSR": 0.5407072368421053, "EFR": 0.9523809523809523, "Overall": 0.7151801378446117}, {"timecode": 76, "before_eval_results": {"predictions": ["tintoretto", "scotch", "repechage", "hanland", "robin", "Costa Brava", "Northumberland", "chicken", "george lovett", "jimmy weiss", "Bleak House", "52", "the Indus valley", "photo", "jaws", "Charlie cairoli", "The Hague", "Adidas", "Coldplay", "jules verne", "Switzerland", "basketball", "Elizabeth II", "conclave", "Patrick kielty", "about 8 minutes", "james", "soFloFreeper", "robin ticciati", "Margaret Thatcher", "hooky Street", "sam & mark", "douglas", "Bonn", "vice-admiral", "snakes", "Coral Sea", "Constantine", "madonna", "a hole-in-one", "tastes great, less filling", "leg", "Ice Age: The meltdown", "Darwin", "Oliver Stone", "Bahrain", "jocky johnson", "emilia", "Hawley Harvey", "two", "1799", "1979", "1976", "Gupta Empire", "Rogue One", "2004", "Rwandan genocide", "Steve Williams", "winter storm", "fight outside of an Atlanta strip club", "seasonal affective disorder", "a timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6166380494505495}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-6962", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-1430", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-1241", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2870", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-1278", "mrqa_triviaqa-validation-6645", "mrqa_triviaqa-validation-460", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3403", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.578125, "CSR": 0.5411931818181819, "EFR": 1.0, "Overall": 0.7248011363636364}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1801", "Captain Cook's Landing Place", "M2M", "Helen Mirren", "FX", "president of Guggenheim Partners", "Diamond Rio", "johnnie ray", "Robert Moses", "UFC 50", "Anthony John Herrera", "Rounders", "24 hours a day and 7 days a week", "Le R\u00eave", "half of the Nobel Prize in Physics", "glee", "Chris Pratt, Zoe Saldana, Dave Bautista", "intelligent design", "2 November 1902", "December 1993", "orisha", "2006", "highest commissioned SS rank", "Dziga Vertov", "The Bonnie Banks o' Loch Lomond", "National Football League", "brothers", "James Franco", "London", "Kelly Bundy", "British", "Ny-\u00c5lesund in Norway", "of German and Czech-Jewish origin", "around 8000 BC", "2002\u201303", "Peter Seamus O'Toole", "Australia women's national soccer team", "Leonarda Cianciulli", "beer", "Biola University", "director", "Morita therapy", "the Lola team", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County, New York", "a bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Candice Brown", "Mel Gibson", "1987", "San Francisco", "sir john johnson", "Vancouver", "college campus.", "$106,482,500", "15-year-old", "Cleopatra", "A&W", "JANE KOKAN", "tambourine"], "metric_results": {"EM": 0.5, "QA-F1": 0.6058667027417027}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.22222222222222224, 1.0, 0.0, 0.8, 0.8000000000000002, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2100", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-2730", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-3829", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-6460", "mrqa_newsqa-validation-2168", "mrqa_newsqa-validation-2982", "mrqa_searchqa-validation-4417", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.5, "CSR": 0.5406650641025641, "EFR": 0.96875, "Overall": 0.7184455128205128}, {"timecode": 78, "before_eval_results": {"predictions": ["Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "August 1991", "Nigel Lythgoe", "the presence of correctly oriented P waves on the electrocardiogram ( ECG )", "1956", "Atlanta, Georgia", "The management team", "The legislation made two amendments to the Social Security Act of 1935", "The Tax Reform Act of 1986", "Ali", "after Margaret Thatcher became Prime Minister in May 1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "fascia surrounding skeletal muscle", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "September 1947", "April 10, 2018", "internal reproductive anatomy", "December 14, 2017", "mid-1980s", "the S - stage of interphase", "1956", "between 8.7 % and 9.1 %", "minor key", "Divyanka Tripathi", "Newfoundland", "Ole Einar Bj\u00f8rndalen", "31 December 1960", "following graduation", "pre-Christian festivals that were celebrated around the winter solstice", "from 1992 to 2013", "George Strait", "All Hallows'Day", "November 1961", "The neck", "2004", "$19.8 trillion", "7000301604928199000", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Alastair Cook", "military experts", "Andrew Lloyd Webber", "domestic cat in America,", "Q", "liam fox", "twin-faced sheepskin with fleece on the inside, a tanned outer surface and a synthetic sole", "5,922", "1866", "two", "2006", "eight or nine", "Lake Superior", "the Thames", "Charles Gounod", "red"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6260647936833281}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, false, true, false, true], "QA-F1": [0.896551724137931, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.06060606060606061, 0.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.5, 0.4, 0.0, 0.22222222222222224, 1.0, 0.0, 0.5, 0.5714285714285715, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-3164", "mrqa_triviaqa-validation-5102", "mrqa_hotpotqa-validation-1250", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-1302"], "SR": 0.515625, "CSR": 0.5403481012658228, "EFR": 0.967741935483871, "Overall": 0.7181805073499388}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "The Tigers won the BCS National Championship Game", "1858", "heavy metal", "Edison Koon-hei Chen", "1875", "The The Onion", "his most brilliant student", "Juilliard School", "World Outgames", "1812", "Peach", "1885", "Oregon State Beavers", "Victorian England", "The War of '04", "American", "superhuman abilities", "Alpine climate and landscapes, in particular for skiing and mountaineering", "the Baudot code.", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "Sydney", "NCAA Division I Football Bowl Subdivision", "motor ships", "\"an unusually impressive imposter\"", "Shameless", "between 1252 and 1259", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis James Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1894", "London", "Bulgarian-Canadian", "James Mitchum", "Nick on Sunset theater", "Javed Miandad", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "the Roman Empire", "Max", "gollum", "Melbourne", "paddington bear", "54-year-old", "American Muslims", "\"These random events are very challenging to prevent and difficult to deal with when they occur.", "Richmond", "Venezuela", "Stone Age", "rally at the State House next week"], "metric_results": {"EM": 0.6875, "QA-F1": 0.79786134004884}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.33333333333333337, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4430", "mrqa_hotpotqa-validation-3440", "mrqa_hotpotqa-validation-4171", "mrqa_naturalquestions-validation-2794", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-4059"], "SR": 0.6875, "CSR": 0.5421875, "EFR": 1.0, "Overall": 0.725}, {"timecode": 80, "before_eval_results": {"predictions": ["Tribune", "Chablis", "\"The chief business of the American people is business\"", "beach volleyball", "song written and performed by American singer-songwriter John Mellencamp, then performing as \"John Cougar.\"", "hot springs", "the Philosopher's Stone", "G-Force", "pro bono", "Vice President", "epitaphic", "Boq", "Yggdrasill", "a rattus norvegicus", "Department of Chemistry", "The Merry Wives of Windsor", "kowtow", "Mars", "a Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "chemy", "Lon Chaney", "bread", "a katzenjammer", "Cuisinart", "travertine", "Robert Dole", "Ross Ice Shelf", "director", "China", "California", "Pinocchio", "the Czech Republic", "an underground lake", "a bison", "come home", "Jodie Foster", "Cleopatra VII", "The Mummy:", "White Fang", "the beetle", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "1937", "53", "The Lightning thief", "Brazil", "Edinburgh", "gagra Range of the Western Caucasus,", "Christina Claire Ciminella", "University of California", "Saturday Night Live", "Mohammed Mohsen Zayed,", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy", "Joanne Wheatley"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5996685606060606}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-8319", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9590", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-14558", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813"], "SR": 0.546875, "CSR": 0.5422453703703703, "EFR": 1.0, "Overall": 0.7250115740740741}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "the Tasmanian government", "Indonesia", "The Generation Game", "The Firm", "red hair", "fourteen", "the Netherlands", "georgia", "wren", "sow", "Eucharist", "Turkey", "Anastasia Dobromyslova", "every ten years", "The Matterhorn", "Lake Placid", "$50", "Liverpool", "the Count Basie Orchestra", "Manhattan", "arch", "georgia andrew kray", "sharjah", "Bombay", "Mallard", "Laurent planchon", "Apollo", "1963", "Bologna", "bear", "coleraine", "Jackie", "Timothy", "Addis Ababa", "motorcycle", "kidney", "Harris", "salsa", "Mark Twain", "Doctor Who", "Yosemite", "Microsoft", "40", "the First World War", "passion fruit", "USS Thresher", "7", "southampton", "100 years", "Benedict XVI", "Jesse Triplett", "Orlando", "LED illuminated", "43rd", "Mel Blanc", "Mauthausen-Gusen", "entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "antihistamine and an epinephrine", "the Cowardly Lion", "Danny Elfman", "Bolivia", "a leap year", "Val Kilmer"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5808560924369748}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.19999999999999998, 0.0, 1.0, 0.0, 0.11764705882352941, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7685", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-5153", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-14665"], "SR": 0.546875, "CSR": 0.5423018292682926, "EFR": 0.9655172413793104, "Overall": 0.7181263141295207}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "Grandmasters", "Illinois", "1,693", "Melville", "Western Europe", "girls", "March 14, 2000", "local level", "Tufts University", "Hammer", "the birthplace of Sir Christopher Wren", "Isla de Xativa", "Mary, Queen of Scots", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Akosua Busia", "over 12 million", "six", "a polypeptide chain", "Brady John Haran", "Minette Walters", "Syracuse University", "three", "Florida Panthers", "2010", "Hallett Cove", "Juan Manuel Mata Garc\u00eda", "Malayalam", "Pittsburgh Steelers", "antelope", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "Durban International Convention Centre (ICC Arena)", "the Kentucky Music Hall of Fame", "Taoiseach", "National Basketball Association", "American", "the Corps of Discovery,", "pubs, bars and restaurants", "Andrew Johnson", "the US state of Minnesota to the west, the US State of Minnesota", "power directly or elect representatives from among themselves to form a governing body, such as a parliament", "illnesses", "Thomas Joseph", "a bank, drawn on the bank's own funds and signed by a cashier", "16 December 1908", "President Lyndon Johnson", "Celsius", "whooping cough", "Johannesburg", "National Intelligence Service, and Defense Minister Kim Kwan Jim", "Samuel Herr, 26, and Juri Kibuishi, 23, of Irvine,", "the sins of the members of the church,", "Superman", "Richard Nixon", "90", "edward VIII"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6283143939393939}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.4, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.09090909090909091, 1.0, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3636363636363636, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4045", "mrqa_hotpotqa-validation-1187", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-605", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-1186", "mrqa_triviaqa-validation-4519", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.53125, "CSR": 0.5421686746987953, "EFR": 1.0, "Overall": 0.7249962349397591}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys:", "Mickey Mantle & Maris", "the Titanic", "Physics", "Bill Clinton", "Graceland", "Cambodia", "an Elevator", "David Copperfield", "California", "the chortle", "W", "a goats", "a pinball machine", "the Almanac Singers", "a Vampire", "the Horn of Africa", "a bagpipe", "Mrs. Miniver", "the chief monk of Tibetan Buddhism", "Germany", "a keynote", "sheep", "Casey Jones", "the Gambler", "Hope", "the navy", "Dresden", "a flippant", "Arkansas", "Duchamp", "a pillage", "a toilet paper", "Sesame", "Iceland", "a nocturnal mammal", "the Monty Hall Problem", "a bees", "Janet Reno", "a connecticut yankee in king arthur's court", "Gianlorenzo Bernini", "Cologne", "Appomattox", "Thailand", "Lazarus", "a breakfast competition", "Pamela Anderson", "Dr. Seuss", "Whitehorse", "Scott McClellan", "Edd Kimber", "six - hoop", "Jacqueline MacInnes Wood", "no", "john denver", "Gargantua", "2017", "four", "Lester", "India", "1959", "two", "her abusive husband"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6541666666666667}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6754", "mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-7089", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-3848", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-7801", "mrqa_searchqa-validation-7382", "mrqa_searchqa-validation-5144", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-16440", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-1831", "mrqa_naturalquestions-validation-8695", "mrqa_triviaqa-validation-7594", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-3590"], "SR": 0.578125, "CSR": 0.5425967261904762, "EFR": 1.0, "Overall": 0.7250818452380953}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony", "roof", "Cuisinart", "the alveoli", "the Boston Massacre,", "Truthful or creditable", "Bolivar", "Little Red Riding Hood", "Abigail Adams", "Bank of America", "Cleopatra", "Colorado Springs", "diamond", "Picasso", "Arlington House", "John Paul II", "the hood", "Herakles", "South Dakota", "natural selection", "Department of the Interior", "Cyrus the Younger", "LEWIS CARROLL", "Schembechler", "Gucci", "Vermont", "a chimp", "Mixtikl 7", "The Man in the Iron Mask", "Fiji", "Germany", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Doctor Moreau", "organs", "wheat", "tundra", "Peter Falk", "AARP", "Tiffany", "the flag", "seeds", "the stiletto", "cheese", "Kentucky", "Bora Bora", "Titanic", "the Revolution", "the \"Fisherman\\'s ring\"", "RBIs", "the foreign exchange market ( FX )", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways", "Rome", "the ocean", "Disney California Adventure", "Acharacle", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe", "Baku"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7423448946886446}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.75, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.9743589743589743, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-4199", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-15036", "mrqa_searchqa-validation-1137", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-2374", "mrqa_newsqa-validation-1793", "mrqa_triviaqa-validation-5654"], "SR": 0.65625, "CSR": 0.5439338235294118, "EFR": 1.0, "Overall": 0.7253492647058823}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "The Little Old Lady", "Cochise", "Samuel Langhorne Clemens", "Margaret Mitchell", "Ford Coppola", "a hangover", "endodontist", "a desktop microcomputer", "South Dakota", "Hercule Poirot", "Frasier Crane", "George B. McClellan", "Soundgarden", "Emperor Maximillian", "Superman Returns", "flavor Flav", "I.M. Pei", "The Name of the Rose", "the Federal Convention", "Norway", "Lewis", "\"Where there is hatred, let me sow love... where there is despair, hope\"", "Steve McQueen", "Firebird", "\"Sweet Home\"", "Vietnam", "Petroleum", "Mike Huckabee", "a Bill of Rights", "Peter Sellers", "St. Mark", "Jon Stewart", "Howard Dean", "Pogo", "I Can't Help Myself", "Ontario", "Madonna", "a turban", "the Perseid Meteor Shower", "Holstein", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Winston Churchill", "Torvill and Dean", "The Black Eyed Peas", "\"I think, therefore I am\"", "the Kingdom of Serbia", "prophets and beloved religious leaders", "1987", "Toy Story", "Harriet Tubman", "the Great British Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Mildred,", "Sigifredo Najera Talamantes,", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.59375, "QA-F1": 0.705078125}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.7499999999999999, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-4518", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-2098", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-1193", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-6557", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-4130", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-2188", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-5105", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.59375, "CSR": 0.5445130813953488, "EFR": 0.9615384615384616, "Overall": 0.7177728085867621}, {"timecode": 86, "before_eval_results": {"predictions": ["a cob", "Barbara Walters", "the Bosphorus and the Ural Mountains", "hoover", "\"Stopping by Woods on a Snowy Evening,\"", "\"The Once and Future King\"", "coffee", "a leopard", "(Cordelia) Knott's Berry Farm", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "Pluto", "Michel de Gaulle", "an electrolyte", "Bernini", "Ovid", "Pablo Escobar", "Abraham Lincoln", "Anne Boleyn", "modify", "a pinnipeds", "Bank of America", "copper", "a blackjack", "Kiss Me, Kate", "Corbett", "plutonium", "Bi", "a \"Cheesy Stuffed Garlic Butter Crescent Rolls", "Amistad", "a book", "The Simpsons", "Babe Didrikson", "Universal Studios Hollywood", "the Russian fleet", "Camembert", "an Achilles' heel", "red", "Sweden", "a member of the musical Partridge family", "Kashmir", "the seal", "The Empire Strikes Back", "Nelson's Column", "Billy Bob Thornton", "Clark", "a \"Chilean salad\"", "Will & Grace", "Robber Barons", "De Wayne Warren", "2017", "Venezuela", "The Coalminer\\'s Daughter,", "golf", "Dialogues des Carm\u00e9lites", "England,", "35,124", "between June 20 and July 20.", "the syndicate, founded by software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6603422619047619}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1629", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-6192", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-3046", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-11379", "mrqa_searchqa-validation-813", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_searchqa-validation-5382", "mrqa_searchqa-validation-1268", "mrqa_naturalquestions-validation-9523", "mrqa_triviaqa-validation-7114", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-2461"], "SR": 0.578125, "CSR": 0.5448994252873562, "EFR": 0.9629629629629629, "Overall": 0.7181349776500638}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Ian Fleming", "zona glomerulosa (from and into the tubular fluids, respectively) of the kidney", "late 19th and early 20th centuries", "\"Tom Jones\"", "Park Sung-woong", "Bonnie Franklin", "Violet", "Route 37 East", "Martian Manhunter", "\" Easy\"", "Dayton Memorial Hall", "Gareth Barry", "Robert John Day", "Bambi: Eine Lebensgeschichte aus dem Walde", "1896", "The iPod Classic", "2017", "The Timekeeper", "May 5 to July 8, 2014", "Ben Ainslie", "torpedoes", "Dante", "Miami Gardens, Florida", "the Miami Marlins", "Netherlands", "Dallas/Fort Worth", "Tia Carrere", "four", "Jim Davis", "Kurt Vonnegut Jr.", "Labrador Retriever", "Gurgaon", "1837", "Blackpool F.C.", "Nasim Pedrad", "DS Virgin Racing Formula E Team", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "1943", "Las Vegas", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "(29 September 1888 \u2013 20 May 1937)", "2015", "Northrop P-61 Black Widow (later RF-61)", "Gareth Barry", "Gambaga", "March 2012", "Cheshire", "Kairi", "1978", "peroxidase", "Gooducken", "c. 3000 BC", "Robert Devereux", "Gary Oldman", "Alanis Morissette", "the Employee Free Choice act in Lafayette Square in Washington.", "\"peregruzka\"", "Port-au-Prince", "Martina Navratilova", "Brazil", "Rocky & Bullwinkle", "baseball"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6286258012820513}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-4700", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_naturalquestions-validation-5711", "mrqa_naturalquestions-validation-5058", "mrqa_naturalquestions-validation-902", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_newsqa-validation-2345", "mrqa_searchqa-validation-14393"], "SR": 0.53125, "CSR": 0.5447443181818181, "EFR": 1.0, "Overall": 0.7255113636363637}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "the first to utilize Audio-Animatronics", "Continental Army", "1874", "Park Yong-gyu", "January 16, 2013", "James Taylor", "Apple Lisa", "\"Veyyil\" (2006)", "Victoria, Duchess of Kent", "Umina Beach, New South Wales", "from 1989 until 1994", "Adelaide Miethke", "Escambia County", "Consigliere", "Joseph Cotten", "7", "the Bologna Process", "Peoria, Illinois", "Iran", "Lorne Michaels", "Philip K. Dick", "University of Texas Longhorns football team", "\"O\" theatre", "\"An All-Colored Vaudeville Show\"", "the local midnight", "German Shepherd", "The Vaudevillains", "Iftikhar Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "The chicken dance", "1,462", "Premier League", "Bob Zmuda", "Eddie Albert", "Chicago", "Ford Island", "The Times Higher Education Guide", "Derry City F.C.", "Beverly Hills", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "The International Imitation Hemingway Contest", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State,", "Akshay Kumar", "2015", "A diastema ( plural diastemata )", "Thames Street", "tom stoppard", "chile", "Dube attempted to escape", "an average of 25 percent", "super-yacht designers", "wild rabbit", "\"Livin' On A Prayer\"", "the electoral college", "joseph kipling"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6870535714285715}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.8, 0.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-3335", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-2566", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1697", "mrqa_searchqa-validation-6483", "mrqa_triviaqa-validation-7531"], "SR": 0.5625, "CSR": 0.5449438202247191, "EFR": 0.9642857142857143, "Overall": 0.7184084069020867}, {"timecode": 89, "before_eval_results": {"predictions": ["Michael Manasseri", "various bigfoot-like sightings, giant snakes and \"thunderbirds.\"", "World War II", "Mike Pence", "Mickey Gilley", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "The Itchy & Scratchy Show", "First Street", "5249", "the Dutch Empire", "Black Swan", "The Notorious B.I.G.", "October 20, 2017", "Antilocapra americana", "Lord's Resistance Movement", "1965", "1943", "National Collegiate Athletic Association (NCAA)", "1959", "31 January 1933", "Neighbourhoods are often social communities with considerable face-to-face interaction among members", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Billund", "the University of Kentucky", "The Sun", "Song Kang-ho, Lee Byung-hun", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "American Boeing B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Berthold Heinrich K\u00e4mpfert", "New South Wales", "EQT Plaza in Pittsburgh, Pennsylvania", "Panthera pardus", "Newark, New Jersey", "ten", "Conservatorio Verdi", "clockwise", "the State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "joseph truncale", "World War II", "george santayana", "label products that contain any of the most common allergens", "an annual road trip,", "102", "a cruet", "give up my intelligence", "saliva", "Venus Williams"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6748850108225108}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-1222", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-1173", "mrqa_hotpotqa-validation-4896", "mrqa_hotpotqa-validation-4040", "mrqa_triviaqa-validation-6118", "mrqa_newsqa-validation-3736", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-12464", "mrqa_searchqa-validation-3153"], "SR": 0.640625, "CSR": 0.5460069444444444, "EFR": 1.0, "Overall": 0.725763888888889}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeletons", "Joaquin Phoenix", "Collard Greens", "the integument", "a motorcycle", "New Coke", "Abigail Adams", "unions", "University of Hawaii", "the leg", "Cristina Yang", "The Omega Man", "van Gogh", "an eruption", "Atlanta", "Alanis Morissette", "Paddington Bear", "Google", "a skyscraper", "1950", "Edward R. Murrow", "Cheetah Rivera", "Czech Resistance leader", "seven", "Nike", "a buck", "Sweden", "Lamborghini", "the Uniform Code of Military Justice", "John Philip Sousa", "oregano", "New South Wales", "died", "Nguyen the Patriot", "Martha\\'s Vineyard", "Smells Like Teen Spirit", "apples", "Transformers: Earth Wars", "A American in Paris", "Taiwan", "Mary Poppins", "Mesa Air Group", "William Donald Scherzer", "\"Gentleman Jim\" Corbett", "Michael Jackson", "Firebird", "Sicily", "Bill Frist", "a cupronickel coin", "apocrypha", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "Russia", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records", "a monthly allowance,", "Aung San Suu Kyi", "75.", "quality of teaching and learning in American schools"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5912431318681319}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-10892", "mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-16647", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-8040", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.546875, "CSR": 0.5460164835164836, "EFR": 1.0, "Overall": 0.7257657967032968}, {"timecode": 91, "before_eval_results": {"predictions": ["The Channel Tunnel", "Hawaii", "Crayola", "slalom", "lubricant", "Banana & Chocolate Top Banana Bar", "the Chesapeake Bay", "(Richard) Kostelanetz", "American", "Shakespeare", "the Suez Canal", "Stephen Hawking", "Ecuador", "New York City", "the Communications Commission", "acetylene", "the scrapple", "Tennessee", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "Dr. Quinn", "oblique", "Cracker Jack", "Ford", "the high jump", "the phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "Monaco", "orange", "Venison", "South Africa", "a packer", "the Gifted", "the Andes", "Ovid", "1937", "Grendel", "(thesaurus)", "ascomycota", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "tentacles", "the sound barrier", "Cyprus", "the members of the actual club", "Sarafina", "Etienne de Mestre", "People\u2019s Dispensary for Sick Animals", "main", "kenjutsu", "Rawlings", "Adam Levine", "Syracuse", "Stuttgart", "The switch had been scheduled for February 17,", "legislation that would crack down on convicts caught with phones", "Bed and breakfast"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6169899425287357}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, false, false, false, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6206896551724138, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-9882", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-6932", "mrqa_hotpotqa-validation-1014", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.5625, "CSR": 0.5461956521739131, "EFR": 1.0, "Overall": 0.7258016304347826}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie Meeber", "sharia", "Yente", "elbow", "a referendum", "alfalfa", "Phaedra", "Franklin D. Roosevelt", "Joseph Heller", "Alice Walker", "As I Lay Dying", "Daniel", "Australian", "Beethoven\\'s", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "the velocity", "The Secret", "an acre", "ancora", "Benjamin Harrison", "William Conrad", "Jericho", "(Exodus)", "a seashell", "Indian tribes", "Australia", "Freaks and Geeks", "(Edouard) Manet", "(The Help, Juno)", "Frdric Franois Chopin", "a calculator", "'Knots Landing'", "Amman", "Van Halen", "The Permanent Select Committee on Intelligence", "Amyotrophic lateral sclerosis", "grapes", "Nancy Lopez", "The Magic Mountain", "Hudson\\'s Bay", "Beguile", "Aboite", "a den", "a loaf of bread", "a mead", "the Mossad", "a mnagerie", "a aide-de-camp", "Judiththia Aline Keppel", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "plutocracy", "de goya", "Laughing my freaking *a* off", "The Panther", "paracyclist", "the XXIV Summer Universiade", "Asashoryu's", "Kingdom City", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5651041666666666}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, false, true, true, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, false, true], "QA-F1": [1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-16477", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-3483", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-9061", "mrqa_searchqa-validation-16904", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-12520", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-4268", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-6365", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-10396", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-6160", "mrqa_newsqa-validation-1122", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.484375, "CSR": 0.5455309139784946, "EFR": 1.0, "Overall": 0.725668682795699}, {"timecode": 93, "before_eval_results": {"predictions": ["Labor", "Standard Oil", "Kings", "English", "archbishop", "Clark", "Bangladesh", "The Carpenters", "Wyoming", "Mary", "the Crimean War", "the elbow", "a thermostat", "a bad speed", "a sapphire", "a florida", "a Wipers", "grace", "gasoline", "the Davis Cup", "Blackbeard", "William of Orange", "Emily Dickinson", "a stikhos", "Simon Wiesenthal", "Mercury and Venus", "Conrad Hilton", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "All Hallows", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "a Tacos", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a fruit", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "Sir Walter Scott", "The War of the Worlds", "January 17, 1899", "when a population temporarily exceeds the long term carrying capacity of its environment", "about 13,000 astronomical units ( 0.21 ly )", "Jessica", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO's Membership Action Plan, or MAP,", "cancerous tumor.", "Sunday.", "Charles Quinton Murphy"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7802083333333334}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false], "QA-F1": [0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-5561", "mrqa_searchqa-validation-2685", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-9606", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_naturalquestions-validation-8832", "mrqa_newsqa-validation-852", "mrqa_hotpotqa-validation-751"], "SR": 0.71875, "CSR": 0.547373670212766, "EFR": 1.0, "Overall": 0.7260372340425533}, {"timecode": 94, "before_eval_results": {"predictions": ["the assassination", "fever", "fossilis", "Janet Reno", "Harvard", "Don Quixote", "The Turn of the Screw", "Lynch", "F Thomas G Nazareth", "spruce", "Wild Bill Hickok", "4D", "hydrogen", "vodka", "lava", "anthrax", "Jamaica", "the Sacher Torte", "George Allen", "a coyote", "CVS/pharmacy", "Sulfur", "the Confessions of Nat Turner", "Jacques Marquette", "malocclusion", "The Silence of the Lambs", "the nucleus", "Thomas Jefferson", "a millimeter", "Megan Fox", "Eurydice", "Unicef", "the Battle of the Little Bighorn", "Marie Curie", "the Archangel Cat", "The Graduate", "Nebraska", "\"E-T\"", "vodka", "John", "LOUIS XIV", "a painted caves", "a yellow page", "Jaguar", "Scout (Scout)", "Liechtenstein", "the Joker", "Pulp Fiction", "Mao Zedong", "Nereid", "Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson", "Sir Giles Gilbert Scott", "Andrew Jackson", "middle and long distance athletics", "WikiLeaks", "\"Traumnovelle\" (\"Dream Story\")", "1985", "Manuel Mejia Munera", "seven", "Six", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.515625, "QA-F1": 0.5858630952380952}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, false, false, true, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-1129", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-4855", "mrqa_searchqa-validation-9813", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-9704", "mrqa_searchqa-validation-7314", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-11462", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3607"], "SR": 0.515625, "CSR": 0.5470394736842106, "EFR": 1.0, "Overall": 0.7259703947368422}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "Haroun", "a cassowary", "Robbie Turner", "a palette", "ice cream", "Cherry baby", "Tajikistan", "theology", "Forrest Gump", "a piles", "a hot dog", "Anthony", "Dixie\\'s Land", "Alfred Nobel", "Karen Blixen", "New York", "Sindbad", "a ziggurat", "the toe", "Pennsylvania", "The War of the Worlds", "Homer", "Steve Jobs", "Dion", "Manwich", "salinity", "Caesar", "Lady Jane Grey", "Eugene V. Debs", "Texas", "Troy", "Antoinette Perry", "The Crucible", "the rabbit", "The Twelve Colonies of Man", "Rugby School", "Titan", "Francis", "Samuel", "Arthur Miller", "Billie Holiday", "Seal", "improv", "Scrabble", "2016", "a moose", "the SinoIndian border dispute", "The Barbary Coast", "Hippos & baboons", "Neal Dahlen", "a permanent, fast - drying painting medium", "Reverend J. Long", "bridge", "mauritania", "cheese, \u201cspecial sauce\u201d (a variant of Thousand Island dressing), iceberg lettuce, pickles, and onions,", "Scholastic UK", "FIFA Women's World Cup", "Great Lakes and Midwestern", "St. Louis, Missouri,", "three out of four", "2002", "the opening of its new restaurant next to the home of Mona Lisa"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6146655701754385}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.1, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.10526315789473685]}}, "before_error_ids": ["mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-14076", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-6639", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_searchqa-validation-5472", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-2598", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-621", "mrqa_newsqa-validation-2950"], "SR": 0.5625, "CSR": 0.5472005208333333, "EFR": 1.0, "Overall": 0.7260026041666666}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "Lill - Babs", "Holiday Inn Hotels & Resorts", "Kaley Christine Cuoco", "1877", "`` Everywhere ''", "T.S. Eliot", "norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "30 October 1918", "Florida", "Robyn", "Peggy Lipton", "Nicole Gale Anderson", "Tiffany Adams Coyne", "a region in Greek mythology", "Randy Watson", "20 November 1989", "Ben Savage", "Genoese merchant sailor Manuel Pessanha ( Pesagno )", "`` The Star Spangled Banner ''", "Charles Carroll", "meaning `` save, rescue, savior ''", "the Canadian Rockies continental divide east to central Saskatchewan", "March 11, 2018", "Khrushchev", "Ciara Brady", "International Border ( IB )", "Ancylostoma duodenale", "the Scenic Highway between Gananoque and Brockville", "found only in Wakanda and the Savage Land", "the player", "1996", "atlantic ocean", "The Union's forces", "Majandra Delfino", "September 19, 2017", "a convergent plate boundary", "in ancient Mesopotamia", "fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "Matt Monro", "Bill Russell", "Krypton", "May 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "digital transmission modes", "introduced around 1940", "Sid Vicious", "Apocalypse Now", "gower", "11,163", "Jaguar Land Rover", "His son", "propofol,", "Courtney Love,", "his Seattle home.", "a cantata", "East of Eden", "Africa", "1919"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5744536108271573}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 0.9302325581395349, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 0.15384615384615383, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.07142857142857142, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5468", "mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-4196", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-3206", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-2222", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.515625, "CSR": 0.546875, "EFR": 0.9354838709677419, "Overall": 0.7130342741935485}, {"timecode": 97, "before_eval_results": {"predictions": ["Blue laws", "Dr. Sachchidananda Sinha", "2001 -- 2002", "New England", "2007", "two reservoirs in the eastern Catskill Mountains", "from the 1960s to the mid-1970s", "Bart Cummings", "Billie `` The Blue Bear ''", "Arnold Schoenberg", "1500 BC", "mindfulness", "Panzerkampfwagen VIII Maus", "An empty line", "Ian Hart", "contestant's", "1898", "Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4", "a major fall in stock prices", "Frankel", "Human fertilization", "senators", "Helena", "Hans Christian Andersen", "Procol Harum", "2018", "William Shakespeare's As You Like It", "James Rodr\u00edguez", "Nucleotides", "Hathi Jr", "interstitial and intravascular compartments", "1983", "Instagram's own account", "the last book accepted into the Christian biblical canon", "in the pachytene stage of prophase I of meiosis", "Qutab Ud - Din - Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Robert Jordan", "American swimmer Michael Phelps", "Don McMillan", "U.S. was not officially tied to the Allies by treaty", "Santiago Cabrera", "April 29, 2009", "Smyrna", "Gibraltar", "red, white, and blue", "U.S. Fund for UNICEF", "Salt Lake City", "Schengen Area", "Arnold Palmer", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "\"The Da Vinci Code\"", "Diana Krall", "Ford\\'s", "a phobia", "cryogenics", "social anxiety"], "metric_results": {"EM": 0.5, "QA-F1": 0.6283363036011547}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.3333333333333333, 0.8, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 0.5714285714285715, 0.4444444444444445, 0.7368421052631579, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-9953", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-564", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-786", "mrqa_searchqa-validation-7556", "mrqa_searchqa-validation-15118"], "SR": 0.5, "CSR": 0.5463966836734694, "EFR": 0.90625, "Overall": 0.7070918367346939}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs.", "Michael Sheen, and Laurence Fishburne", "Rockbridge County", "Mumbai, Maharashtra", "Savannah", "\"Perfect Strangers,\"", "public", "Nelson County", "video game", "\"boundary river\"", "Imagine", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks", "\"The Simpsons 138th Episode Spectacular\"", "Puente Hills Mall", "neo-Nazi", "model", "Bisexuality", "Adam Dawes", "1621", "Steven Selling", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "1975", "Target Corporation", "Sofia the First", "playback singer", "Australian", "1968", "Longford", "Dirk Werner Nowitzki", "Scotland", "Kansas Jayhawks football team", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "The Hungry Hustlerz: Starvation Is Motivation", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "1976", "Anthony Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "Amii Anne J. Grove,", "their unusual behavior", "1952", "to start fires, hunt, and bury their dead", "`` 200 ''", "Dmitri Mendeleev", "honda", "Utah", "moby Dick", "The train in front had stopped", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "to host the Olympic Games in Rio de Janeiro.", "\"Free Bird\"", "Gone Home", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.625, "QA-F1": 0.6741477272727273}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, true, true, false, false, true, false, false, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714288, 1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-1204", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-745", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-4863", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-15800"], "SR": 0.625, "CSR": 0.5471906565656566, "EFR": 1.0, "Overall": 0.7260006313131313}, {"timecode": 99, "UKR": 0.6953125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.765625, "KG": 0.48125, "before_eval_results": {"predictions": ["The 2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "PBS", "The Bears", "1979", "Salisbury", "KKR & Co", "526", "Jean-Marie Pfaff", "West Point", "The Grandmaster", "satirical erotic romantic comedy", "\"The Process\"", "Vikram", "1949", "BAFTA TV Award Best Actor winner", "Cameron Indoor Stadium", "defender", "Levi Weeks", "219 passengers", "Esteban Ocon", "The S7 series", "Lamar Hunt", "Black Mountain College", "You Can Be a Star", "People v. Turner", "1853", "1977", "wine", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "\"City of Ghosts\" (2002)", "Ludwig van Beethoven", "Rabat", "A Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan Hypersport", "Richard Arthur", "The magazine \"mental_floss\"", "May 4, 2004", "3 mi", "Field Marshal John Standish Surtees Prendergast Vereker", "Neighbourhood", "Miracle", "1979", "John Alexander", "eleven", "2011", "the last Ice Age", "n Carolina", "wish FM", "John Galliano", "Mark Fields", "Arlington National Cemetery's Section 60,", "Seoul", "Circumnavigate", "a comma", "a 15th anniversary", "the mollusca"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7247328192640693}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false], "QA-F1": [0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6862", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-10055", "mrqa_searchqa-validation-5045"], "SR": 0.65625, "CSR": 0.54828125, "EFR": 1.0, "Overall": 0.6980937500000001}]}