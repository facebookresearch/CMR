{"method_class": "er", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/QA_er_lr=3e-5_ep=10_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.1,gamma=0.8', gradient_accumulation_steps=1, inference_query_size=1, init_memory_cache_path='na', kg_eval_freq=10, kg_eval_mode='metric', kr_eval_freq=10, kr_eval_mode='metric', learning_rate=3e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='experiments/ckpt_dirs/qa/er/QA_er_lr=3e-5_ep=10_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.1,gamma=0.8/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, replay_candidate_size=8, replay_frequency=1, replay_size=64, save_ckpt_freq=10, skip_instant_eval=False, total_steps=10000, upstream_sample_ratio=0.5, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/QA_er_lr=3e-5_ep=10_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.1,gamma=0.8_result.json', submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.1,gamma=0.8.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 11770, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["high cost injectable, oral, infused, or inhaled medications", "a plastid that lacks chlorophyll", "Observations on the Geology of the United States", "1887", "2000", "gain support from China", "the south", "push", "New England Patriots", "A cylindrical Service Module", "gold", "Fermat primality test", "highly diversified", "WWSB and WOTV", "the end itself", "Chen's theorem", "La Rochelle", "Fort Caroline", "around half", "the move from the manufacturing sector to the service sector", "1.7 billion years ago", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "July 18, 2006", "electromagnetic force", "Robert Bork", "East Smithfield burial site in England", "non-violent", "John Houghton", "Enthusiastic teachers", "high voltage", "Johann Walter", "Shoushi Li", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "priest", "business districts", "BankAmericard", "Bruno Mars", "Jamukha", "German New Guinea", "Onon", "good, clear laws", "the International Stanis\u0142aw Moniuszko Vocal Competition", "forces", "Factory Project", "2010", "fundraising drives", "1000 CE", "Van Nuys Airport", "overinflated", "basic design typical of Eastern bloc countries", "the tax rate", "sequential proteolytic activation of complement molecules", "customs of his tribe", "Robert Guiscard", "wide sidewalks", "CBS Sports.com", "the March Battle of Fort Bull", "a rendezvous", "6 feet 2 inches", "formalism", "the sale of indulgences", "the English Court of Appeal, the German Bundesgerichtshof, the Belgian Cour du travail", "British failures in North America", "Besan\u00e7on Hugues"], "metric_results": {"EM": 0.75, "QA-F1": 0.7846657363104732}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true], "QA-F1": [0.2, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1111111111111111, 1.0, 0.3636363636363636, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6393", "mrqa_squad-validation-8452", "mrqa_squad-validation-5", "mrqa_squad-validation-6091", "mrqa_squad-validation-7382", "mrqa_squad-validation-9489", "mrqa_squad-validation-10483", "mrqa_squad-validation-4902", "mrqa_squad-validation-2145", "mrqa_squad-validation-7430", "mrqa_squad-validation-680", "mrqa_squad-validation-9896", "mrqa_squad-validation-6645", "mrqa_squad-validation-6072", "mrqa_squad-validation-525", "mrqa_squad-validation-4361"], "SR": 0.75, "CSR": 0.75, "EFR": 0.875, "Overall": 0.8125}, {"timecode": 1, "before_eval_results": {"predictions": ["fast forwarding of accessed content", "supporting applications such as on-line betting, financial applications", "San Jose State", "DeMarcus Ware", "two poles", "Presiding Officer", "1206", "high fuel prices and new competition from low-cost air services", "lens-shaped", "Regis Philbin", "defensins", "Sweden", "linebacker", "the Calvin cycle", "ships", "Archbishop of Westminster", "a coherent theory", "\"Roentgen rays\" or \"X-Rays\"", "Fridays", "M\u00e9ni\u00e8re's disease, vertigo, fainting, tinnitus, and a cataract in one eye", "Oahu", "1784", "William of Volpiano and John of Ravenna", "yellow fever outbreaks", "Philippines", "$125 per month", "in any other group of chloroplasts", "Abercynon", "Michael Heckenberger and colleagues of the University of Florida", "only \"essentials\"", "a pointless pursuit", "United Nations", "a plug-n-play system", "Roone Arledge", "driving them in front of the army", "business", "1726", "lower rates of social goods", "main hymn", "France", "extinction of the dinosaurs", "ABC Entertainment Group", "the 17th century", "U.S. flags left on the Moon during the Apollo missions were found to still be standing", "T cells", "1080i HD", "the state (including the judges)", "30 July 1891", "Inherited wealth", "the journal Science", "administration", "elected by citizens", "Trypanosoma brucei", "Falls", "1975", "over half", "1835", "France", "The relationship between some gut flora and humans is not merely commensal ( a non-harmful coexistence )", "its initial home range spanning from Iran, Pakistan, India, Nepal, Bhutan, Bangladesh and Sri Lanka", "Principal photography began on November 2, 2016", "The song was written by Mitch Murray", "Rigveda, Atharvaveda and Taittiriya Samhita", "1947"], "metric_results": {"EM": 0.734375, "QA-F1": 0.7842046957671958}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.14814814814814817, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857144, 0.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-809", "mrqa_squad-validation-5758", "mrqa_squad-validation-10427", "mrqa_squad-validation-1504", "mrqa_squad-validation-2506", "mrqa_squad-validation-8662", "mrqa_squad-validation-7571", "mrqa_squad-validation-4206", "mrqa_squad-validation-3998", "mrqa_squad-validation-7457", "mrqa_squad-validation-8576", "mrqa_squad-validation-3922", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-6050"], "SR": 0.734375, "CSR": 0.7421875, "retrieved_ids": ["mrqa_squad-train-8643", "mrqa_squad-train-24262", "mrqa_squad-train-62861", "mrqa_squad-train-26256", "mrqa_squad-train-6640", "mrqa_squad-train-5496", "mrqa_squad-train-21712", "mrqa_squad-train-17654", "mrqa_squad-train-83132", "mrqa_squad-train-36942", "mrqa_squad-train-68026", "mrqa_squad-train-26918", "mrqa_squad-train-63293", "mrqa_squad-train-66424", "mrqa_squad-train-28692", "mrqa_squad-train-76989", "mrqa_squad-train-58724", "mrqa_squad-train-10491", "mrqa_squad-train-18886", "mrqa_squad-train-77152", "mrqa_squad-train-5326", "mrqa_squad-train-39740", "mrqa_squad-train-19597", "mrqa_squad-train-22520", "mrqa_squad-train-157", "mrqa_squad-train-64559", "mrqa_squad-train-7114", "mrqa_squad-train-85935", "mrqa_squad-train-27782", "mrqa_squad-train-71342", "mrqa_squad-train-7926", "mrqa_squad-train-358", "mrqa_squad-validation-6091", "mrqa_squad-validation-2145", "mrqa_squad-validation-10483", "mrqa_squad-validation-6645", "mrqa_squad-validation-4902", "mrqa_squad-validation-6393", "mrqa_squad-validation-5", "mrqa_squad-validation-7382", "mrqa_squad-validation-525", "mrqa_squad-validation-680", "mrqa_squad-validation-8452", "mrqa_squad-validation-9489", "mrqa_squad-validation-6072", "mrqa_squad-validation-9896", "mrqa_squad-validation-4361", "mrqa_squad-validation-7430"], "EFR": 1.0, "Overall": 0.87109375}, {"timecode": 2, "before_eval_results": {"predictions": ["magnetic", "photosynthetic function", "Egyptians", "gold", "fund travelers who would come back with tales of their discoveries", "reactive allotrope of oxygen", "aligning his personal goals with his academic goals", "ABC Circle Films", "Jews", "Kaifeng", "passion", "Combined Statistical Area", "European Union law", "monophyletic", "\"Provisional Registration\"", "biochemical oxygen demand", "electrical repair jobs", "hospitals and other institutions", "gold", "1998", "160 kPa", "The General Board of Church and Society, and the United Methodist Women", "successfully preventing it from being cut down", "lab monitoring, adherence counseling, and assist patients with cost-containment strategies", "St. Johns River", "The increasing use of technology", "10 years", "Genghis Khan", "HIV", "1857", "Rijn", "Caris & Co.", "Stage 2", "\u00d6gedei", "governmental entities", "Anglo-Saxon language of their subjects", "two populations of rodents", "The Deadly Assassin and Mawdryn undead", "Dave Logan", "the top row of windows", "fast forwarding of accessed content", "The Dornbirner Ach", "combustion chamber", "a gift", "104 \u00b0F (40 \u00b0C)", "strict", "the property owner", "southern Europe", "1913", "patient compliance", "20th century", "ambiguity", "The Xmas song standard titled these Bells was introduced by Bob Hope in the 1951 movie The Lemon Drop Kid", "the culture of maiko, who replace the... white one upon becoming one of these | a geisha.", "Abraham Lincoln", "The Sky This Week for September 2 to September 11", "Carefully paddling down this Congolese river that lends its name to a deadly virus", "The 10 dog breeds with the best sense of smell - Dogtime  Basset Hound.", "The Dardanelles formerly known as Hellespont is a narrow, natural strait and internationally", "The Zionist Criminal Network - Christopher Bollyn", "half the northbound cars wait 90 minutes", "the prehistoric and medieval period.", "James Edward Kelly", "2 March 1972"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7094572368421053}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.10526315789473684, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3497", "mrqa_squad-validation-2717", "mrqa_squad-validation-1308", "mrqa_squad-validation-3692", "mrqa_squad-validation-6244", "mrqa_squad-validation-6753", "mrqa_squad-validation-1108", "mrqa_squad-validation-7162", "mrqa_squad-validation-1808", "mrqa_squad-validation-9895", "mrqa_squad-validation-6361", "mrqa_searchqa-validation-5591", "mrqa_searchqa-validation-5713", "mrqa_searchqa-validation-7896", "mrqa_searchqa-validation-13651", "mrqa_searchqa-validation-5075", "mrqa_searchqa-validation-12371", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-15243", "mrqa_searchqa-validation-16877", "mrqa_searchqa-validation-3385", "mrqa_hotpotqa-validation-1393"], "SR": 0.65625, "CSR": 0.7135416666666667, "retrieved_ids": ["mrqa_squad-train-2551", "mrqa_squad-train-37433", "mrqa_squad-train-69557", "mrqa_squad-train-72424", "mrqa_squad-train-12773", "mrqa_squad-train-34175", "mrqa_squad-train-51102", "mrqa_squad-train-58071", "mrqa_squad-train-42991", "mrqa_squad-train-49618", "mrqa_squad-train-15469", "mrqa_squad-train-54632", "mrqa_squad-train-7919", "mrqa_squad-train-40930", "mrqa_squad-train-6185", "mrqa_squad-train-5129", "mrqa_squad-train-21772", "mrqa_squad-train-75668", "mrqa_squad-train-71187", "mrqa_squad-train-57050", "mrqa_squad-train-25793", "mrqa_squad-train-25343", "mrqa_squad-train-55673", "mrqa_squad-train-40996", "mrqa_squad-train-54480", "mrqa_squad-train-25969", "mrqa_squad-train-76288", "mrqa_squad-train-63657", "mrqa_squad-train-11772", "mrqa_squad-train-62543", "mrqa_squad-train-19185", "mrqa_squad-train-20840", "mrqa_squad-validation-4902", "mrqa_squad-validation-680", "mrqa_naturalquestions-validation-7393", "mrqa_squad-validation-7457", "mrqa_squad-validation-4361", "mrqa_squad-validation-5", "mrqa_squad-validation-9489", "mrqa_squad-validation-5758", "mrqa_naturalquestions-validation-3942", "mrqa_squad-validation-8576", "mrqa_squad-validation-2145", "mrqa_squad-validation-8662", "mrqa_squad-validation-6645", "mrqa_squad-validation-7430", "mrqa_naturalquestions-validation-5672", "mrqa_squad-validation-1504", "mrqa_squad-validation-10427", "mrqa_squad-validation-7571", "mrqa_squad-validation-8452", "mrqa_squad-validation-2506", "mrqa_squad-validation-525", "mrqa_squad-validation-10483", "mrqa_squad-validation-6091", "mrqa_squad-validation-6072", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-6050", "mrqa_squad-validation-809", "mrqa_squad-validation-9896", "mrqa_squad-validation-7382", "mrqa_squad-validation-6393", "mrqa_squad-validation-4206", "mrqa_squad-validation-3922"], "EFR": 1.0, "Overall": 0.8567708333333334}, {"timecode": 3, "before_eval_results": {"predictions": ["a strange odor in their spacesuits", "Muqali", "inversely to member state size", "if they are distinct or equal classes", "1884", "Isaac Komnenos", "the printing press", "1997", "June 6, 1951", "Marshall Cohen", "1.7 billion years ago", "a not-for-profit United States computer networking consortium led by members from the research and education communities, industry, and government", "contemporary accounts were exaggerations", "residency registration", "Tower District", "individual state laws", "October 2007", "Moscone Center", "medical cannabis dispensaries and Voice in the Wilderness", "September 1944", "\u015ar\u00f3dmie\u015bcie", "oxyacetylene welding", "9.6%", "Commander", "macrophages and lymphocytes", "kill Luther", "his son Duncan", "\"an idealized and systematized version of conservative tribal village customs\" under the label of Sharia", "the Dongshan Dafo Dian", "Jean Cauvin", "220 miles (350 km)", "\"Blue Harvest\" and \"420\"", "Thomas Commerford Martin", "rubisco", "The Book of Roger", "force of gravity", "Africa", "Pierre Bayle", "The results of the Haensch study have since been confirmed and amended", "32.9%", "30\u201360% of Europe's total population", "1368\u20131644", "reduction gears", "Spanish force from the nearby Spanish settlement of St. Augustine", "a liquid oxygen tank exploded", "$105 billion", "1688\u20131692", "AFC", "Parlophone", "Super Bowl XXIX", "The Number Twelve looks Like You", "end of the 18th century", "Tulsa", "26,788", "Richa Sharma", "Stage Stores", "25 laps", "youngest publicly documented people to be identified as transgender", "672 km2", "the Boston and Maine Railroad's Southern Division", "Dusty Dvoracek", "sincerity", "Himalayan", "murder"], "metric_results": {"EM": 0.78125, "QA-F1": 0.8645387164918416}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.8181818181818181, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_squad-validation-4210", "mrqa_squad-validation-7011", "mrqa_squad-validation-4019", "mrqa_squad-validation-1116", "mrqa_squad-validation-9740", "mrqa_squad-validation-4901", "mrqa_squad-validation-3370", "mrqa_squad-validation-7207", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-5251", "mrqa_newsqa-validation-246", "mrqa_newsqa-validation-1577", "mrqa_newsqa-validation-3564"], "SR": 0.78125, "CSR": 0.73046875, "retrieved_ids": ["mrqa_squad-train-35989", "mrqa_squad-train-74894", "mrqa_squad-train-4328", "mrqa_squad-train-73100", "mrqa_squad-train-27770", "mrqa_squad-train-83533", "mrqa_squad-train-32475", "mrqa_squad-train-10579", "mrqa_squad-train-57229", "mrqa_squad-train-200", "mrqa_squad-train-25303", "mrqa_squad-train-1634", "mrqa_squad-train-7860", "mrqa_squad-train-60098", "mrqa_squad-train-81172", "mrqa_squad-train-10711", "mrqa_squad-train-43249", "mrqa_squad-train-70981", "mrqa_squad-train-55185", "mrqa_squad-train-51854", "mrqa_squad-train-80625", "mrqa_squad-train-14125", "mrqa_squad-train-44655", "mrqa_squad-train-33278", "mrqa_squad-train-71961", "mrqa_squad-train-85989", "mrqa_squad-train-1134", "mrqa_squad-train-15079", "mrqa_squad-train-40743", "mrqa_squad-train-65228", "mrqa_squad-train-63760", "mrqa_squad-train-61828", "mrqa_squad-validation-1308", "mrqa_searchqa-validation-5936", "mrqa_squad-validation-4361", "mrqa_squad-validation-9489", "mrqa_squad-validation-8662", "mrqa_squad-validation-680", "mrqa_squad-validation-9896", "mrqa_squad-validation-1808", "mrqa_squad-validation-3692", "mrqa_searchqa-validation-5591", "mrqa_squad-validation-10483", "mrqa_squad-validation-7162", "mrqa_squad-validation-8452", "mrqa_naturalquestions-validation-1435", "mrqa_squad-validation-6072", "mrqa_squad-validation-2145", "mrqa_searchqa-validation-12371", "mrqa_naturalquestions-validation-6050", "mrqa_searchqa-validation-16877", "mrqa_squad-validation-8576", "mrqa_squad-validation-6393", "mrqa_squad-validation-3497", "mrqa_squad-validation-5758", "mrqa_squad-validation-6645", "mrqa_searchqa-validation-7896", "mrqa_squad-validation-6244", "mrqa_squad-validation-4902", "mrqa_squad-validation-9895", "mrqa_squad-validation-6361", "mrqa_searchqa-validation-5713", "mrqa_squad-validation-1504", "mrqa_searchqa-validation-3385"], "EFR": 0.9285714285714286, "Overall": 0.8295200892857143}, {"timecode": 4, "before_eval_results": {"predictions": ["consultant", "reformers", "Modern English", "Commission v Italy", "the West", "1893", "demand for a Scottish Parliament", "1881", "1421", "W. E. B. Du Bois", "between 25-minute episodes", "captive import policy", "15th century", "two", "two", "a pivotal event", "Mexico", "Black Sea", "a single output", "The Central Region", "an attack against the forts Shirley had erected at the Oneida carry", "Murray Gold and Ben Foster", "ambiguity", "Super Bowl XLIV", "Urarina", "a global to a domestic scale", "a force model that is independent of any macroscale position vector", "lost in the 5th Avenue laboratory fire of March 1895", "Westwood One", "free", "Resurgence", "issues related to the substance of the statement", "1763\u20131775", "classical position variables", "512-bit", "Deabolis", "necessity", "the ATP is synthesized there, in position to be used in the dark reactions", "cartels", "Hughes Hotel", "88", "8 November 2010", "Jean Baptiste Say", "The Perfect Storm", "Terry Scott and June Whitfield", "architecture", "Bolts or arrows", "Common moles", "a complex number raised to the zero power", "Mikhail Gorbachev", "Good Will Hunting", "Quentin Blake", "The History Boys", "a valid passport", "\"caliper\"", "protons", "James Hoban", "elia Earhart", "1963", "cricket bat making process", "Sasha Banks", "The United States of America", "iPods", "Charles M. Schulz"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7270833333333333}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-2437", "mrqa_squad-validation-9334", "mrqa_squad-validation-7708", "mrqa_squad-validation-6197", "mrqa_squad-validation-10251", "mrqa_squad-validation-7537", "mrqa_squad-validation-10466", "mrqa_squad-validation-8905", "mrqa_triviaqa-validation-6413", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-1603", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-2758", "mrqa_triviaqa-validation-6052", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-6761", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-873", "mrqa_naturalquestions-validation-9871", "mrqa_searchqa-validation-4355"], "SR": 0.671875, "CSR": 0.71875, "retrieved_ids": ["mrqa_squad-train-73266", "mrqa_squad-train-9417", "mrqa_squad-train-76310", "mrqa_squad-train-19715", "mrqa_squad-train-80280", "mrqa_squad-train-423", "mrqa_squad-train-37275", "mrqa_squad-train-37161", "mrqa_squad-train-26227", "mrqa_squad-train-59540", "mrqa_squad-train-44814", "mrqa_squad-train-42254", "mrqa_squad-train-3400", "mrqa_squad-train-38206", "mrqa_squad-train-74590", "mrqa_squad-train-37327", "mrqa_squad-train-42970", "mrqa_squad-train-84102", "mrqa_squad-train-73797", "mrqa_squad-train-48103", "mrqa_squad-train-21822", "mrqa_squad-train-49483", "mrqa_squad-train-18765", "mrqa_squad-train-21358", "mrqa_squad-train-6581", "mrqa_squad-train-62782", "mrqa_squad-train-1314", "mrqa_squad-train-49342", "mrqa_squad-train-14131", "mrqa_squad-train-64687", "mrqa_squad-train-40143", "mrqa_squad-train-36257", "mrqa_naturalquestions-validation-3942", "mrqa_squad-validation-2145", "mrqa_squad-validation-7162", "mrqa_squad-validation-7571", "mrqa_squad-validation-9489", "mrqa_naturalquestions-validation-6050", "mrqa_squad-validation-1108", "mrqa_squad-validation-6753", "mrqa_hotpotqa-validation-3182", "mrqa_squad-validation-5", "mrqa_searchqa-validation-15243", "mrqa_squad-validation-6244", "mrqa_squad-validation-1504", "mrqa_squad-validation-1808", "mrqa_searchqa-validation-3385", "mrqa_squad-validation-3370", "mrqa_searchqa-validation-16877", "mrqa_newsqa-validation-3564", "mrqa_squad-validation-7457", "mrqa_hotpotqa-validation-1393", "mrqa_squad-validation-3497", "mrqa_squad-validation-1116", "mrqa_newsqa-validation-246", "mrqa_squad-validation-525", "mrqa_squad-validation-4210", "mrqa_squad-validation-7382", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-5672", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-7393", "mrqa_squad-validation-4902", "mrqa_squad-validation-8576"], "EFR": 1.0, "Overall": 0.859375}, {"timecode": 5, "before_eval_results": {"predictions": ["7:00 to 9:00 a.m.", "ammed", "vaccination", "62", "Maciot de Bethencourt", "Spain", "C. J. Anderson", "Cam Newton", "eastwards", "accessory pigments that override the chlorophylls' green colors", "his last statement", "the Pleistocene epoch", "Because he published his findings first", "Nurses", "time and space complexity", "1951", "the Marches", "black earth", "Nederrijn", "opposite end from the mouth", "Refined Hindu and Buddhist sculptures", "the mid-sixties", "the Kuznets curve hypothesis", "the lost chloroplast's existence", "Schr\u00f6dinger equation", "90\u00b0", "anticlines and synclines", "Tanaghrisson", "Siegfried", "Sydney", "220 miles", "Northern San Diego", "Video On Demand", "Genghis Khan", "Arizona Cardinals", "Pleurobrachia, Beroe and Mnemiopsis", "chloroplast's stroma", "operations requiring constant speed, such as cotton spinning", "10 November 2017", "psilocybin", "\"SpongeBob SquarePants\"", "Tudor music", "England", "2009", "Ella Fitzgerald", "sarod", "1981", "Rikki Farr", "Nia Sanchez", "German", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "Fran", "Ed O'Neill", "Kristine Leahy", "1999 Odisha", "Fat Albert", "\" Frontline\"", "d\u00edsir", "Shinola  Shinola LLC", "variation in plants", "a person trained to pilot, navigate, or otherwise participate as a crew member of a spacecraft", "U.N. aid agency said.", "altostratus", "independence for the country's ethnic Tamil minority"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6706473214285713}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.5, 0.0, 0.25, 0.5714285714285715, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.45454545454545453, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5454545454545454]}}, "before_error_ids": ["mrqa_squad-validation-9029", "mrqa_squad-validation-1064", "mrqa_squad-validation-9176", "mrqa_squad-validation-10386", "mrqa_squad-validation-4631", "mrqa_squad-validation-6044", "mrqa_squad-validation-8900", "mrqa_squad-validation-3374", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-1473", "mrqa_hotpotqa-validation-3821", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4399", "mrqa_hotpotqa-validation-961", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-3871", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-1161", "mrqa_hotpotqa-validation-171", "mrqa_hotpotqa-validation-3937", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-5534", "mrqa_naturalquestions-validation-3663", "mrqa_triviaqa-validation-2357", "mrqa_newsqa-validation-539", "mrqa_searchqa-validation-1523", "mrqa_newsqa-validation-1718"], "SR": 0.5625, "CSR": 0.6927083333333333, "retrieved_ids": ["mrqa_squad-train-33260", "mrqa_squad-train-56939", "mrqa_squad-train-69451", "mrqa_squad-train-18553", "mrqa_squad-train-3726", "mrqa_squad-train-28208", "mrqa_squad-train-68402", "mrqa_squad-train-1902", "mrqa_squad-train-17767", "mrqa_squad-train-17816", "mrqa_squad-train-24474", "mrqa_squad-train-22063", "mrqa_squad-train-72894", "mrqa_squad-train-65617", "mrqa_squad-train-78318", "mrqa_squad-train-72109", "mrqa_squad-train-81129", "mrqa_squad-train-80372", "mrqa_squad-train-48841", "mrqa_squad-train-74000", "mrqa_squad-train-86063", "mrqa_squad-train-30549", "mrqa_squad-train-81012", "mrqa_squad-train-12240", "mrqa_squad-train-6328", "mrqa_squad-train-42760", "mrqa_squad-train-47722", "mrqa_squad-train-5596", "mrqa_squad-train-62019", "mrqa_squad-train-35417", "mrqa_squad-train-11281", "mrqa_squad-train-7080", "mrqa_squad-validation-2717", "mrqa_squad-validation-3692", "mrqa_squad-validation-6197", "mrqa_triviaqa-validation-4710", "mrqa_squad-validation-1116", "mrqa_naturalquestions-validation-9871", "mrqa_squad-validation-3370", "mrqa_squad-validation-6393", "mrqa_squad-validation-10483", "mrqa_triviaqa-validation-2758", "mrqa_squad-validation-5758", "mrqa_searchqa-validation-3385", "mrqa_squad-validation-7708", "mrqa_squad-validation-9740", "mrqa_searchqa-validation-5936", "mrqa_squad-validation-1108", "mrqa_squad-validation-7537", "mrqa_squad-validation-2437", "mrqa_squad-validation-4210", "mrqa_hotpotqa-validation-3182", "mrqa_searchqa-validation-15243", "mrqa_squad-validation-6753", "mrqa_squad-validation-4019", "mrqa_newsqa-validation-1577", "mrqa_squad-validation-10251", "mrqa_squad-validation-9896", "mrqa_triviaqa-validation-6318", "mrqa_searchqa-validation-16877", "mrqa_squad-validation-6645", "mrqa_squad-validation-3998", "mrqa_squad-validation-7011", "mrqa_squad-validation-7571"], "EFR": 0.9642857142857143, "Overall": 0.8284970238095237}, {"timecode": 6, "before_eval_results": {"predictions": ["2010", "retained after the pathogen has been eliminated", "the Calvin cycle", "Zhenjin", "specialised education and training", "June 11, 1962", "The Commission's President", "68,511", "queuing", "1880", "8 mm cine film", "Pittsburgh", "the seal of the Federal Communications Commission", "\u00a3250,000", "Michael Jayston", "radiography", "Norway", "the courts of member states", "Texas", "shortening the cutoff", "12.5 acres", "within a few hundred feet of each other", "an innate force of impetus", "the Conservative Party", "an international data communications network", "the environment in which they lived", "safety Darian Stewart", "the Great Fire of London", "acular", "San Francisco", "The View and The Chew", "Parliament of the United Kingdom at Westminster", "successfully preventing it from being cut down", "baptism", "England", "one hundred pennies", "specialist insurance", "Parkinson's", "Tintin", "british", "b", "West Germany", "McKinney", "Sarek", "Solomon", "Blackstar", "Geology", "Earth", "british", "Richmond in North Yorkshire", "The Passenger Pigeon", "Richard Wagner", "false teeth", "Debbie Rowe", "Ethiopia", "1973", "The Return of the Pink Panther", "London", "Stephen Graham", "Southaven", "East Java", "\"Gold Digger\"", "President Paul Biya", "trading goods and services without exchanging money"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6307291666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6680", "mrqa_squad-validation-8295", "mrqa_squad-validation-806", "mrqa_squad-validation-89", "mrqa_squad-validation-512", "mrqa_triviaqa-validation-7060", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1561", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-7742", "mrqa_triviaqa-validation-5336", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-7430", "mrqa_triviaqa-validation-134", "mrqa_triviaqa-validation-1064", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-4197", "mrqa_hotpotqa-validation-426", "mrqa_searchqa-validation-13016", "mrqa_newsqa-validation-1664", "mrqa_newsqa-validation-714"], "SR": 0.59375, "CSR": 0.6785714285714286, "retrieved_ids": ["mrqa_squad-train-53308", "mrqa_squad-train-43746", "mrqa_squad-train-7544", "mrqa_squad-train-5885", "mrqa_squad-train-54212", "mrqa_squad-train-44622", "mrqa_squad-train-22426", "mrqa_squad-train-34886", "mrqa_squad-train-51485", "mrqa_squad-train-32831", "mrqa_squad-train-51777", "mrqa_squad-train-12896", "mrqa_squad-train-26569", "mrqa_squad-train-82760", "mrqa_squad-train-41315", "mrqa_squad-train-58645", "mrqa_squad-train-64102", "mrqa_squad-train-73948", "mrqa_squad-train-65380", "mrqa_squad-train-55766", "mrqa_squad-train-61897", "mrqa_squad-train-64592", "mrqa_squad-train-56160", "mrqa_squad-train-66807", "mrqa_squad-train-6448", "mrqa_squad-train-51694", "mrqa_squad-train-79418", "mrqa_squad-train-75629", "mrqa_squad-train-18056", "mrqa_squad-train-72760", "mrqa_squad-train-71867", "mrqa_squad-train-31767", "mrqa_squad-validation-1064", "mrqa_squad-validation-10386", "mrqa_triviaqa-validation-2758", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-3247", "mrqa_searchqa-validation-12371", "mrqa_squad-validation-10483", "mrqa_squad-validation-4902", "mrqa_squad-validation-7457", "mrqa_squad-validation-2506", "mrqa_hotpotqa-validation-3937", "mrqa_searchqa-validation-4355", "mrqa_hotpotqa-validation-171", "mrqa_squad-validation-6072", "mrqa_squad-validation-8905", "mrqa_squad-validation-4019", "mrqa_squad-validation-9334", "mrqa_squad-validation-10466", "mrqa_triviaqa-validation-1603", "mrqa_triviaqa-validation-6413", "mrqa_triviaqa-validation-2357", "mrqa_squad-validation-680", "mrqa_squad-validation-9896", "mrqa_squad-validation-1308", "mrqa_squad-validation-7382", "mrqa_squad-validation-8452", "mrqa_squad-validation-8576", "mrqa_squad-validation-6753", "mrqa_squad-validation-4901", "mrqa_squad-validation-525", "mrqa_naturalquestions-validation-1435", "mrqa_hotpotqa-validation-5101"], "EFR": 0.9615384615384616, "Overall": 0.820054945054945}, {"timecode": 7, "before_eval_results": {"predictions": ["ten times their own weight", "Cape of Good Hope", "Time magazine", "Rhine-kilometers", "14", "150", "North American Aviation", "register as a professional on the General Pharmaceutical Council (GPhC) register", "the Sovereign", "weakness in school discipline", "Fort Caroline", "the concept Distributed Adaptive Message Block Switching", "at elevated partial pressures", "His lab was torn down in 1904", "interacting", "Omnicare, Kindred Healthcare and PharMerica", "Tiffany & Co.", "conservative", "March Battle of Fort Bull", "swimming-plates", "eleven", "it would undermine the law", "1332", "separately from physicians", "the south", "Geordie", "ignition sources are minimized", "US$10 a week", "the harvests of their Chinese tenants eaten up by costs of equipping and dispatching men for their tours of duty", "142 pounds (64 kg)", "1806-07", "spock the Crocodile", "he built a shed", "british", "a police car", "Dead Man's Curve", "Wordsworth", "the Chetniks", "Chrysler", "paris", "Rookwood", "the Devil Wears Prada", "Edward R. Murrow", "a steep rugged rock", "rowe", "british", "british", "british", "Kenya", "Christopher Marlowe", "iPhone", "all right angles are equal", "Genoa, Italy", "two nations", "jonathan kiedis", "the port of Inchon", "The Federal Reserve", "eight", "Jane Eyre", "World War II", "Hussein's Revolutionary Command Council", "police", "the Cowardly Lion", "March 22"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6169442536630036}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.0, 0.4166666666666667, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6324", "mrqa_squad-validation-1404", "mrqa_squad-validation-2097", "mrqa_squad-validation-6773", "mrqa_squad-validation-3483", "mrqa_squad-validation-1272", "mrqa_squad-validation-8238", "mrqa_searchqa-validation-2499", "mrqa_searchqa-validation-8411", "mrqa_searchqa-validation-3075", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-9133", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-5916", "mrqa_searchqa-validation-14572", "mrqa_searchqa-validation-6726", "mrqa_searchqa-validation-679", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-8040", "mrqa_searchqa-validation-12316", "mrqa_searchqa-validation-455", "mrqa_searchqa-validation-6095", "mrqa_searchqa-validation-478", "mrqa_searchqa-validation-14852", "mrqa_searchqa-validation-621", "mrqa_searchqa-validation-4533", "mrqa_searchqa-validation-14514", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-858"], "SR": 0.546875, "CSR": 0.662109375, "retrieved_ids": ["mrqa_squad-train-21081", "mrqa_squad-train-77445", "mrqa_squad-train-9168", "mrqa_squad-train-6086", "mrqa_squad-train-25531", "mrqa_squad-train-52572", "mrqa_squad-train-58166", "mrqa_squad-train-51866", "mrqa_squad-train-56510", "mrqa_squad-train-4947", "mrqa_squad-train-45213", "mrqa_squad-train-75673", "mrqa_squad-train-69072", "mrqa_squad-train-7894", "mrqa_squad-train-60111", "mrqa_squad-train-6385", "mrqa_squad-train-18203", "mrqa_squad-train-64778", "mrqa_squad-train-29589", "mrqa_squad-train-3950", "mrqa_squad-train-57710", "mrqa_squad-train-19390", "mrqa_squad-train-71980", "mrqa_squad-train-43356", "mrqa_squad-train-33611", "mrqa_squad-train-61100", "mrqa_squad-train-34060", "mrqa_squad-train-62326", "mrqa_squad-train-27536", "mrqa_squad-train-76121", "mrqa_squad-train-27521", "mrqa_squad-train-82597", "mrqa_triviaqa-validation-478", "mrqa_hotpotqa-validation-171", "mrqa_squad-validation-2145", "mrqa_triviaqa-validation-5194", "mrqa_hotpotqa-validation-426", "mrqa_squad-validation-6091", "mrqa_squad-validation-6197", "mrqa_searchqa-validation-3385", "mrqa_squad-validation-3692", "mrqa_hotpotqa-validation-3871", "mrqa_hotpotqa-validation-5526", "mrqa_squad-validation-10466", "mrqa_squad-validation-4210", "mrqa_naturalquestions-validation-6050", "mrqa_squad-validation-3497", "mrqa_squad-validation-7011", "mrqa_hotpotqa-validation-5251", "mrqa_triviaqa-validation-2357", "mrqa_searchqa-validation-5075", "mrqa_squad-validation-6645", "mrqa_squad-validation-809", "mrqa_triviaqa-validation-6554", "mrqa_squad-validation-2506", "mrqa_squad-validation-1064", "mrqa_squad-validation-9334", "mrqa_squad-validation-7537", "mrqa_squad-validation-9029", "mrqa_hotpotqa-validation-5534", "mrqa_newsqa-validation-3564", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6052", "mrqa_squad-validation-7430"], "EFR": 1.0, "Overall": 0.8310546875}, {"timecode": 8, "before_eval_results": {"predictions": ["a flour mill Boulton & Watt were building", "directly every four years", "Alan Turing", "2\u20133", "coordinating lead authors", "effectiveness of treatment regimens", "43 million tons", "720p high definition", "Denver", "Singing Revolution", "The Newlywed Game", "17th", "counterflow", "pattern recognition receptors", "climate change in addition to deforestation", "Glucocorticoids", "a special episode of The Late Show with Stephen Colbert", "international footballers", "Newcastle Student Radio", "immunoglobulins and T cell receptors", "City council", "Torchwood: Miracle Day", "November 1979", "in homologous recombination and replication structures similar to bacteriophage T4", "opposition to the decisions of non-governmental agencies such as trade unions, banks, and private universities", "Cobham's", "Sir Edward Poynter", "Museum of the Moving Image in London", "the Simien Mountains", "Florida State University", "Ear's malleus", "Mao", "arroz con leche", "Hawaii", "Kiwanis International", "the log cabin", "saxophones", "a tornado", "the Chateau de Vendeuvre", "Fingerspelling", "Sofia Scicolone", "dizygotic", "the DASH Diet", "Hawaii", "lox", "neurotransmitters", "Jon of the Clue Crew", "Meg Cabot", "Bresaola", "Massachusetts", "larynx", "John Galt", "Arbor Day", "cloves", "the obtuse angle", "Kentucky", "Henry Clay", "Congress passed the Chinese Exclusion Act in 1882", "shrew", "1953", "Harry Nicolaides", "Mineola", "Blender's \"500 Greatest Songs Since You Were Born\"", "2018\u201319 UEFA Europa League group stage"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6732142857142858}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, true, false, false], "QA-F1": [0.5, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.8333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-3373", "mrqa_squad-validation-964", "mrqa_squad-validation-10067", "mrqa_squad-validation-434", "mrqa_squad-validation-8747", "mrqa_squad-validation-7674", "mrqa_searchqa-validation-16960", "mrqa_searchqa-validation-177", "mrqa_searchqa-validation-2115", "mrqa_searchqa-validation-6666", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-8348", "mrqa_searchqa-validation-9679", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-11392", "mrqa_searchqa-validation-14471", "mrqa_searchqa-validation-12963", "mrqa_searchqa-validation-10669", "mrqa_searchqa-validation-14307", "mrqa_searchqa-validation-12243", "mrqa_searchqa-validation-5760", "mrqa_searchqa-validation-5070", "mrqa_naturalquestions-validation-10012", "mrqa_triviaqa-validation-4730", "mrqa_hotpotqa-validation-5174", "mrqa_hotpotqa-validation-1263"], "SR": 0.59375, "CSR": 0.6545138888888888, "retrieved_ids": ["mrqa_squad-train-32494", "mrqa_squad-train-61991", "mrqa_squad-train-58504", "mrqa_squad-train-84555", "mrqa_squad-train-82496", "mrqa_squad-train-64005", "mrqa_squad-train-74955", "mrqa_squad-train-67147", "mrqa_squad-train-31469", "mrqa_squad-train-72346", "mrqa_squad-train-3518", "mrqa_squad-train-46394", "mrqa_squad-train-79916", "mrqa_squad-train-14000", "mrqa_squad-train-38690", "mrqa_squad-train-10753", "mrqa_squad-train-71237", "mrqa_squad-train-43533", "mrqa_squad-train-24801", "mrqa_squad-train-44673", "mrqa_squad-train-34629", "mrqa_squad-train-32393", "mrqa_squad-train-32508", "mrqa_squad-train-20030", "mrqa_squad-train-62642", "mrqa_squad-train-27651", "mrqa_squad-train-82054", "mrqa_squad-train-57668", "mrqa_squad-train-7", "mrqa_squad-train-31416", "mrqa_squad-train-59808", "mrqa_squad-train-52043", "mrqa_searchqa-validation-5916", "mrqa_squad-validation-10386", "mrqa_squad-validation-6753", "mrqa_squad-validation-1808", "mrqa_squad-validation-6197", "mrqa_squad-validation-1308", "mrqa_squad-validation-3374", "mrqa_newsqa-validation-467", "mrqa_searchqa-validation-5936", "mrqa_newsqa-validation-1718", "mrqa_searchqa-validation-6726", "mrqa_searchqa-validation-15243", "mrqa_searchqa-validation-7896", "mrqa_naturalquestions-validation-6050", "mrqa_squad-validation-7571", "mrqa_squad-validation-3483", "mrqa_squad-validation-1504", "mrqa_newsqa-validation-246", "mrqa_squad-validation-7207", "mrqa_squad-validation-6091", "mrqa_searchqa-validation-12316", "mrqa_squad-validation-9489", "mrqa_squad-validation-9176", "mrqa_searchqa-validation-621", "mrqa_squad-validation-512", "mrqa_searchqa-validation-7782", "mrqa_hotpotqa-validation-2905", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-5672", "mrqa_triviaqa-validation-6761", "mrqa_triviaqa-validation-4573", "mrqa_squad-validation-6324"], "EFR": 1.0, "Overall": 0.8272569444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["Holyrood area of Edinburgh", "only people established in the Netherlands could give legal advice", "terra nullius", "assisting in fabricating evidence or committing perjury", "kicker", "theory of relativity", "Red Turban rebels", "Jurassic Period", "Fort Presque Isle", "William S. Paley", "anaerobic bacteria", "more sunlight in deep water", "eicosanoids and cytokines", "the Christian ought to live", "50-yard line", "heard her songs", "1/6", "DC traction motor", "the \"richest 1 percent in the United States now own more wealth than the bottom 90 percent", "the divinity of Jesus", "EastEnders", "J. S. Bach", "highest", "a few drops", "1882", "the Beldam / Other Mother", "North America", "Sachin Tendulkar", "Coton in the Elms", "\u03bb", "Audrey II", "the last Ice Age", "Christy", "2026", "Georgia", "the defendant's negligence was gross, that is, it showed such a disregard for the life and safety of others as to amount to a crime and deserve punishment", "1984 Summer Olympics in Los Angeles", "4 September 1936", "Andrew Moray and William Wallace", "Julie Thatcher", "Pangaea", "Have I Told You Lately", "sinoatrial node", "the fourth quarter of the preceding year", "2013 non-fiction book of the same name by David Finkel", "to prevent further offense by convincing the offender that their conduct was wrong", "Bob Dylan", "September of that year", "Judicial discretion", "Lynda Carter", "a well - worn USB drive may be write - protected to help ensure the life of individual cells", "substitute good", "September 27, 2017", "President Gerald Ford", "Monk's Caf\u00e9", "Dolph Lundgren", "Tintin", "Alaska", "140 million", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II", "People Against Switching Sides", "around 3.5 percent of global greenhouse emissions", "Billy Budd", "En banc"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7058608329695515}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, true, true, false], "QA-F1": [0.4, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.9387755102040817, 0.4444444444444444, 1.0, 0.8333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.4, 0.0, 1.0, 1.0, 1.0, 0.15999999999999998, 0.888888888888889, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9304", "mrqa_squad-validation-4460", "mrqa_squad-validation-9764", "mrqa_squad-validation-8596", "mrqa_squad-validation-2443", "mrqa_squad-validation-805", "mrqa_squad-validation-7459", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-75", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-7935", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-801", "mrqa_hotpotqa-validation-3481", "mrqa_newsqa-validation-1319", "mrqa_searchqa-validation-12968"], "SR": 0.5625, "CSR": 0.6453125, "retrieved_ids": ["mrqa_squad-train-26073", "mrqa_squad-train-2480", "mrqa_squad-train-13674", "mrqa_squad-train-76910", "mrqa_squad-train-40992", "mrqa_squad-train-51288", "mrqa_squad-train-27675", "mrqa_squad-train-77339", "mrqa_squad-train-39758", "mrqa_squad-train-10532", "mrqa_squad-train-58167", "mrqa_squad-train-77769", "mrqa_squad-train-72086", "mrqa_squad-train-84398", "mrqa_squad-train-43023", "mrqa_squad-train-12995", "mrqa_squad-train-43834", "mrqa_squad-train-83705", "mrqa_squad-train-44996", "mrqa_squad-train-37403", "mrqa_squad-train-39351", "mrqa_squad-train-64303", "mrqa_squad-train-73018", "mrqa_squad-train-9122", "mrqa_squad-train-46349", "mrqa_squad-train-9909", "mrqa_squad-train-2226", "mrqa_squad-train-32868", "mrqa_squad-train-9620", "mrqa_squad-train-66756", "mrqa_squad-train-31428", "mrqa_squad-train-65820", "mrqa_searchqa-validation-14471", "mrqa_triviaqa-validation-478", "mrqa_searchqa-validation-13651", "mrqa_squad-validation-4361", "mrqa_naturalquestions-validation-7393", "mrqa_hotpotqa-validation-2327", "mrqa_searchqa-validation-12371", "mrqa_squad-validation-7430", "mrqa_squad-validation-8662", "mrqa_hotpotqa-validation-1263", "mrqa_triviaqa-validation-6052", "mrqa_squad-validation-6773", "mrqa_squad-validation-89", "mrqa_searchqa-validation-478", "mrqa_searchqa-validation-12316", "mrqa_squad-validation-1108", "mrqa_searchqa-validation-5591", "mrqa_squad-validation-7708", "mrqa_squad-validation-6244", "mrqa_naturalquestions-validation-6050", "mrqa_triviaqa-validation-6643", "mrqa_searchqa-validation-2115", "mrqa_triviaqa-validation-5507", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-6318", "mrqa_searchqa-validation-4533", "mrqa_searchqa-validation-3075", "mrqa_squad-validation-9895", "mrqa_squad-validation-512", "mrqa_squad-validation-3374", "mrqa_hotpotqa-validation-3075", "mrqa_searchqa-validation-13016"], "EFR": 0.9642857142857143, "Overall": 0.8047991071428571}, {"timecode": 10, "UKR": 0.775390625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1124", "mrqa_hotpotqa-validation-1159", "mrqa_hotpotqa-validation-1161", "mrqa_hotpotqa-validation-1205", "mrqa_hotpotqa-validation-1258", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-1473", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-171", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-204", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-2590", "mrqa_hotpotqa-validation-2829", "mrqa_hotpotqa-validation-2885", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-3323", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-3821", "mrqa_hotpotqa-validation-3871", "mrqa_hotpotqa-validation-3937", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-4399", "mrqa_hotpotqa-validation-4836", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5174", "mrqa_hotpotqa-validation-524", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5268", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-5465", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-5534", "mrqa_hotpotqa-validation-5642", "mrqa_hotpotqa-validation-961", "mrqa_naturalquestions-validation-1067", "mrqa_naturalquestions-validation-10723", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-1372", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-2658", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3965", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6190", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-75", "mrqa_naturalquestions-validation-7935", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-8889", "mrqa_naturalquestions-validation-956", "mrqa_naturalquestions-validation-9871", "mrqa_newsqa-validation-1319", "mrqa_newsqa-validation-1577", "mrqa_newsqa-validation-1664", "mrqa_newsqa-validation-1718", "mrqa_newsqa-validation-2248", "mrqa_newsqa-validation-246", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-378", "mrqa_newsqa-validation-698", "mrqa_newsqa-validation-714", "mrqa_searchqa-validation-10289", "mrqa_searchqa-validation-10305", "mrqa_searchqa-validation-10669", "mrqa_searchqa-validation-11248", "mrqa_searchqa-validation-11392", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-1196", "mrqa_searchqa-validation-12243", "mrqa_searchqa-validation-12316", "mrqa_searchqa-validation-12371", "mrqa_searchqa-validation-12649", "mrqa_searchqa-validation-12740", "mrqa_searchqa-validation-12963", "mrqa_searchqa-validation-12968", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-13651", "mrqa_searchqa-validation-14307", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-14471", "mrqa_searchqa-validation-145", "mrqa_searchqa-validation-14514", "mrqa_searchqa-validation-14572", "mrqa_searchqa-validation-14723", "mrqa_searchqa-validation-14852", "mrqa_searchqa-validation-14879", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-15243", "mrqa_searchqa-validation-16910", "mrqa_searchqa-validation-177", "mrqa_searchqa-validation-2115", "mrqa_searchqa-validation-2481", "mrqa_searchqa-validation-2499", "mrqa_searchqa-validation-2561", "mrqa_searchqa-validation-3075", "mrqa_searchqa-validation-3385", "mrqa_searchqa-validation-4355", "mrqa_searchqa-validation-455", "mrqa_searchqa-validation-478", "mrqa_searchqa-validation-5070", "mrqa_searchqa-validation-5075", "mrqa_searchqa-validation-5591", "mrqa_searchqa-validation-5713", "mrqa_searchqa-validation-5814", "mrqa_searchqa-validation-5916", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-6095", "mrqa_searchqa-validation-621", "mrqa_searchqa-validation-6666", "mrqa_searchqa-validation-679", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-7896", "mrqa_searchqa-validation-8348", "mrqa_searchqa-validation-8411", "mrqa_searchqa-validation-8578", "mrqa_searchqa-validation-9133", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-10008", "mrqa_squad-validation-10067", "mrqa_squad-validation-1009", "mrqa_squad-validation-10111", "mrqa_squad-validation-10127", "mrqa_squad-validation-10204", "mrqa_squad-validation-10207", "mrqa_squad-validation-1021", "mrqa_squad-validation-1023", "mrqa_squad-validation-10251", "mrqa_squad-validation-10251", "mrqa_squad-validation-10260", "mrqa_squad-validation-10287", "mrqa_squad-validation-10351", "mrqa_squad-validation-10386", "mrqa_squad-validation-10387", "mrqa_squad-validation-10413", "mrqa_squad-validation-10427", "mrqa_squad-validation-10466", "mrqa_squad-validation-10483", "mrqa_squad-validation-10504", "mrqa_squad-validation-1051", "mrqa_squad-validation-1064", "mrqa_squad-validation-1071", "mrqa_squad-validation-1078", "mrqa_squad-validation-1104", "mrqa_squad-validation-1108", "mrqa_squad-validation-1108", "mrqa_squad-validation-1116", "mrqa_squad-validation-1138", "mrqa_squad-validation-1142", "mrqa_squad-validation-1181", "mrqa_squad-validation-1236", "mrqa_squad-validation-1241", "mrqa_squad-validation-1255", "mrqa_squad-validation-1282", "mrqa_squad-validation-1301", "mrqa_squad-validation-1308", "mrqa_squad-validation-1312", "mrqa_squad-validation-1316", "mrqa_squad-validation-1338", "mrqa_squad-validation-1378", "mrqa_squad-validation-1401", "mrqa_squad-validation-1461", "mrqa_squad-validation-1504", "mrqa_squad-validation-1506", "mrqa_squad-validation-1552", "mrqa_squad-validation-1553", "mrqa_squad-validation-1554", "mrqa_squad-validation-159", "mrqa_squad-validation-1601", "mrqa_squad-validation-1636", "mrqa_squad-validation-1706", "mrqa_squad-validation-1780", "mrqa_squad-validation-1808", "mrqa_squad-validation-1813", "mrqa_squad-validation-1831", "mrqa_squad-validation-1856", "mrqa_squad-validation-1875", "mrqa_squad-validation-1880", "mrqa_squad-validation-1951", "mrqa_squad-validation-1973", "mrqa_squad-validation-2040", "mrqa_squad-validation-2069", "mrqa_squad-validation-2097", "mrqa_squad-validation-2135", "mrqa_squad-validation-2145", "mrqa_squad-validation-2210", "mrqa_squad-validation-2434", "mrqa_squad-validation-2437", "mrqa_squad-validation-2443", "mrqa_squad-validation-2449", "mrqa_squad-validation-2451", "mrqa_squad-validation-2453", "mrqa_squad-validation-2476", "mrqa_squad-validation-2506", "mrqa_squad-validation-2571", "mrqa_squad-validation-2603", "mrqa_squad-validation-2643", "mrqa_squad-validation-2643", "mrqa_squad-validation-2717", "mrqa_squad-validation-2753", "mrqa_squad-validation-2780", "mrqa_squad-validation-2807", "mrqa_squad-validation-2832", "mrqa_squad-validation-2865", "mrqa_squad-validation-2888", "mrqa_squad-validation-2955", "mrqa_squad-validation-3086", "mrqa_squad-validation-3092", "mrqa_squad-validation-31", "mrqa_squad-validation-3109", "mrqa_squad-validation-312", "mrqa_squad-validation-3153", "mrqa_squad-validation-3196", "mrqa_squad-validation-3223", "mrqa_squad-validation-3257", "mrqa_squad-validation-3310", "mrqa_squad-validation-3320", "mrqa_squad-validation-3346", "mrqa_squad-validation-3363", "mrqa_squad-validation-3370", "mrqa_squad-validation-3374", "mrqa_squad-validation-3381", "mrqa_squad-validation-3415", "mrqa_squad-validation-3456", "mrqa_squad-validation-3475", "mrqa_squad-validation-3497", "mrqa_squad-validation-350", "mrqa_squad-validation-351", "mrqa_squad-validation-3551", "mrqa_squad-validation-3551", "mrqa_squad-validation-356", "mrqa_squad-validation-3575", "mrqa_squad-validation-3607", "mrqa_squad-validation-3641", "mrqa_squad-validation-3683", "mrqa_squad-validation-3692", "mrqa_squad-validation-3724", "mrqa_squad-validation-3752", "mrqa_squad-validation-3773", "mrqa_squad-validation-3823", "mrqa_squad-validation-3865", "mrqa_squad-validation-3890", "mrqa_squad-validation-3904", "mrqa_squad-validation-3922", "mrqa_squad-validation-3939", "mrqa_squad-validation-3998", "mrqa_squad-validation-401", "mrqa_squad-validation-4018", "mrqa_squad-validation-4019", "mrqa_squad-validation-4100", "mrqa_squad-validation-4110", "mrqa_squad-validation-4162", "mrqa_squad-validation-4206", "mrqa_squad-validation-4210", "mrqa_squad-validation-4232", "mrqa_squad-validation-4240", "mrqa_squad-validation-4297", "mrqa_squad-validation-4316", "mrqa_squad-validation-4343", "mrqa_squad-validation-441", "mrqa_squad-validation-4430", "mrqa_squad-validation-4458", "mrqa_squad-validation-4460", "mrqa_squad-validation-4473", "mrqa_squad-validation-4491", "mrqa_squad-validation-4595", "mrqa_squad-validation-4615", "mrqa_squad-validation-4631", "mrqa_squad-validation-4631", "mrqa_squad-validation-4665", "mrqa_squad-validation-4729", "mrqa_squad-validation-4783", "mrqa_squad-validation-4791", "mrqa_squad-validation-4795", "mrqa_squad-validation-4824", "mrqa_squad-validation-4841", "mrqa_squad-validation-4857", "mrqa_squad-validation-4860", "mrqa_squad-validation-4870", "mrqa_squad-validation-4901", "mrqa_squad-validation-4902", "mrqa_squad-validation-4921", "mrqa_squad-validation-4978", "mrqa_squad-validation-5", "mrqa_squad-validation-50", "mrqa_squad-validation-510", "mrqa_squad-validation-5115", "mrqa_squad-validation-512", "mrqa_squad-validation-5167", "mrqa_squad-validation-5187", "mrqa_squad-validation-525", "mrqa_squad-validation-5275", "mrqa_squad-validation-5310", "mrqa_squad-validation-5320", "mrqa_squad-validation-5350", "mrqa_squad-validation-5363", "mrqa_squad-validation-5374", "mrqa_squad-validation-5422", "mrqa_squad-validation-5450", "mrqa_squad-validation-5471", "mrqa_squad-validation-5492", "mrqa_squad-validation-5591", "mrqa_squad-validation-5602", "mrqa_squad-validation-5624", "mrqa_squad-validation-5638", "mrqa_squad-validation-5714", "mrqa_squad-validation-5758", "mrqa_squad-validation-5844", "mrqa_squad-validation-5844", "mrqa_squad-validation-5883", "mrqa_squad-validation-5889", "mrqa_squad-validation-5943", "mrqa_squad-validation-5971", "mrqa_squad-validation-5978", "mrqa_squad-validation-60", "mrqa_squad-validation-6015", "mrqa_squad-validation-603", "mrqa_squad-validation-6044", "mrqa_squad-validation-6070", "mrqa_squad-validation-6072", "mrqa_squad-validation-6091", "mrqa_squad-validation-6120", "mrqa_squad-validation-6143", "mrqa_squad-validation-6181", "mrqa_squad-validation-6197", "mrqa_squad-validation-62", "mrqa_squad-validation-6255", "mrqa_squad-validation-6284", "mrqa_squad-validation-6286", "mrqa_squad-validation-6361", "mrqa_squad-validation-6361", "mrqa_squad-validation-6373", "mrqa_squad-validation-6393", "mrqa_squad-validation-6394", "mrqa_squad-validation-6408", "mrqa_squad-validation-6428", "mrqa_squad-validation-6454", "mrqa_squad-validation-6511", "mrqa_squad-validation-6512", "mrqa_squad-validation-6518", "mrqa_squad-validation-6524", "mrqa_squad-validation-6539", "mrqa_squad-validation-6625", "mrqa_squad-validation-6626", "mrqa_squad-validation-6645", "mrqa_squad-validation-6657", "mrqa_squad-validation-6658", "mrqa_squad-validation-6658", "mrqa_squad-validation-6680", "mrqa_squad-validation-6725", "mrqa_squad-validation-6753", "mrqa_squad-validation-6753", "mrqa_squad-validation-6773", "mrqa_squad-validation-6791", "mrqa_squad-validation-680", "mrqa_squad-validation-6831", "mrqa_squad-validation-687", "mrqa_squad-validation-6873", "mrqa_squad-validation-6958", "mrqa_squad-validation-6997", "mrqa_squad-validation-70", "mrqa_squad-validation-7011", "mrqa_squad-validation-7013", "mrqa_squad-validation-7013", "mrqa_squad-validation-7021", "mrqa_squad-validation-7040", "mrqa_squad-validation-7082", "mrqa_squad-validation-7101", "mrqa_squad-validation-7162", "mrqa_squad-validation-7206", "mrqa_squad-validation-7207", "mrqa_squad-validation-7209", "mrqa_squad-validation-7230", "mrqa_squad-validation-7317", "mrqa_squad-validation-7382", "mrqa_squad-validation-7395", "mrqa_squad-validation-7430", "mrqa_squad-validation-7457", "mrqa_squad-validation-7459", "mrqa_squad-validation-7463", "mrqa_squad-validation-7537", "mrqa_squad-validation-7566", "mrqa_squad-validation-7646", "mrqa_squad-validation-7670", "mrqa_squad-validation-7674", "mrqa_squad-validation-7694", "mrqa_squad-validation-7708", "mrqa_squad-validation-7765", "mrqa_squad-validation-7831", "mrqa_squad-validation-7837", "mrqa_squad-validation-7867", "mrqa_squad-validation-787", "mrqa_squad-validation-7918", "mrqa_squad-validation-7937", "mrqa_squad-validation-7959", "mrqa_squad-validation-7961", "mrqa_squad-validation-7961", "mrqa_squad-validation-805", "mrqa_squad-validation-806", "mrqa_squad-validation-8135", "mrqa_squad-validation-8227", "mrqa_squad-validation-8233", "mrqa_squad-validation-8238", "mrqa_squad-validation-8242", "mrqa_squad-validation-8243", "mrqa_squad-validation-8295", "mrqa_squad-validation-8312", "mrqa_squad-validation-8436", "mrqa_squad-validation-8452", "mrqa_squad-validation-8480", "mrqa_squad-validation-8553", "mrqa_squad-validation-8557", "mrqa_squad-validation-8576", "mrqa_squad-validation-8596", "mrqa_squad-validation-8602", "mrqa_squad-validation-8627", "mrqa_squad-validation-8647", "mrqa_squad-validation-8662", "mrqa_squad-validation-8755", "mrqa_squad-validation-8781", "mrqa_squad-validation-8807", "mrqa_squad-validation-8872", "mrqa_squad-validation-8881", "mrqa_squad-validation-89", "mrqa_squad-validation-8900", "mrqa_squad-validation-8971", "mrqa_squad-validation-9022", "mrqa_squad-validation-9029", "mrqa_squad-validation-9109", "mrqa_squad-validation-9154", "mrqa_squad-validation-9176", "mrqa_squad-validation-9226", "mrqa_squad-validation-9240", "mrqa_squad-validation-9304", "mrqa_squad-validation-9334", "mrqa_squad-validation-9335", "mrqa_squad-validation-9351", "mrqa_squad-validation-9360", "mrqa_squad-validation-9371", "mrqa_squad-validation-9405", "mrqa_squad-validation-9411", "mrqa_squad-validation-9484", "mrqa_squad-validation-9489", "mrqa_squad-validation-9512", "mrqa_squad-validation-9546", "mrqa_squad-validation-9562", "mrqa_squad-validation-9611", "mrqa_squad-validation-9619", "mrqa_squad-validation-968", "mrqa_squad-validation-9750", "mrqa_squad-validation-9764", "mrqa_squad-validation-9856", "mrqa_squad-validation-9890", "mrqa_squad-validation-9895", "mrqa_squad-validation-9896", "mrqa_squad-validation-9999", "mrqa_triviaqa-validation-1064", "mrqa_triviaqa-validation-134", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1603", "mrqa_triviaqa-validation-1827", "mrqa_triviaqa-validation-2045", "mrqa_triviaqa-validation-2357", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-3681", "mrqa_triviaqa-validation-393", "mrqa_triviaqa-validation-4146", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5336", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-5671", "mrqa_triviaqa-validation-5754", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-5948", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-632", "mrqa_triviaqa-validation-6413", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-6761", "mrqa_triviaqa-validation-7060", "mrqa_triviaqa-validation-7430", "mrqa_triviaqa-validation-7470", "mrqa_triviaqa-validation-790", "mrqa_triviaqa-validation-873"], "OKR": 0.91015625, "KG": 0.4828125, "before_eval_results": {"predictions": ["Warszawa", "the SI unit of magnetic flux density the tesla", "2007", "Duval County", "2003", "the father of the house when in his home", "Electrical Experimenter Tesla", "Richard Wilkinson and Kate Pickett", "some teachers and parents", "Governor Vaudreuil", "pastors and teachers", "Justin Tucker", "1543", "None", "Yosemite Freeway", "Switzerland", "unit-dose, or a single doses of medicine", "War of Currents", "\"vanguard of change and Islamic reform\" centered around the Muslim Brotherhood", "continental European countries", "RogerNFL", "events and festivals", "9", "Adelaide", "once", "200,000", "itty Hawk", "Nidal Hasan", "University of Maryland", "Charles Coughlin", "Harry Hook", "Consigliere", "Pierce County", "Harry F. Sinclair", "Homebrewing", "December 1974", "2012", "1999", "2004", "Best Sound", "Nelson Rockefeller", "Fort Snelling, Minnesota", "Amy", "at the State House in Augusta", "1970", "1978", "2005", "My Cat from Hell", "Mark Sinclair", "Colonel", "1999", "17", "La Liga", "Buffalo Soldier", "Kal Ho Naa Ho", "Key West, Florida", "gastrocnemius", "John Roberts", "repechage", "Carl Johan", "two", "Madonna", "Freddie Mercury", "the Sousa Band"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7111244658119659}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, false, true, false, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.6, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-1251", "mrqa_squad-validation-2318", "mrqa_squad-validation-1491", "mrqa_squad-validation-10259", "mrqa_squad-validation-2337", "mrqa_squad-validation-4562", "mrqa_squad-validation-6526", "mrqa_squad-validation-9578", "mrqa_squad-validation-85", "mrqa_squad-validation-680", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-2751", "mrqa_hotpotqa-validation-5703", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-497", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-3669", "mrqa_hotpotqa-validation-1691", "mrqa_hotpotqa-validation-4166", "mrqa_hotpotqa-validation-5810", "mrqa_hotpotqa-validation-3807", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-674", "mrqa_naturalquestions-validation-7608", "mrqa_searchqa-validation-4509"], "SR": 0.578125, "CSR": 0.6392045454545454, "retrieved_ids": ["mrqa_squad-train-85250", "mrqa_squad-train-37539", "mrqa_squad-train-86020", "mrqa_squad-train-24077", "mrqa_squad-train-63964", "mrqa_squad-train-48652", "mrqa_squad-train-35674", "mrqa_squad-train-3709", "mrqa_squad-train-83331", "mrqa_squad-train-44141", "mrqa_squad-train-47530", "mrqa_squad-train-427", "mrqa_squad-train-51818", "mrqa_squad-train-54151", "mrqa_squad-train-47827", "mrqa_squad-train-40553", "mrqa_squad-train-57197", "mrqa_squad-train-69023", "mrqa_squad-train-30061", "mrqa_squad-train-35178", "mrqa_squad-train-39980", "mrqa_squad-train-37781", "mrqa_squad-train-78180", "mrqa_squad-train-45391", "mrqa_squad-train-22384", "mrqa_squad-train-35600", "mrqa_squad-train-80675", "mrqa_squad-train-85633", "mrqa_squad-train-75568", "mrqa_squad-train-64186", "mrqa_squad-train-80210", "mrqa_squad-train-8229", "mrqa_searchqa-validation-5070", "mrqa_newsqa-validation-714", "mrqa_searchqa-validation-6726", "mrqa_searchqa-validation-455", "mrqa_naturalquestions-validation-7935", "mrqa_triviaqa-validation-134", "mrqa_triviaqa-validation-7742", "mrqa_squad-validation-10386", "mrqa_searchqa-validation-478", "mrqa_squad-validation-9895", "mrqa_newsqa-validation-246", "mrqa_squad-validation-6773", "mrqa_newsqa-validation-858", "mrqa_squad-validation-1272", "mrqa_squad-validation-809", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-961", "mrqa_squad-validation-10483", "mrqa_searchqa-validation-12316", "mrqa_triviaqa-validation-7430", "mrqa_squad-validation-7537", "mrqa_squad-validation-7457", "mrqa_searchqa-validation-8348", "mrqa_squad-validation-7674", "mrqa_searchqa-validation-4355", "mrqa_squad-validation-3373", "mrqa_newsqa-validation-1319", "mrqa_squad-validation-9304", "mrqa_triviaqa-validation-6761", "mrqa_squad-validation-4631", "mrqa_searchqa-validation-12371", "mrqa_squad-validation-8295"], "EFR": 0.9629629629629629, "Overall": 0.7541053766835016}, {"timecode": 11, "before_eval_results": {"predictions": ["pr\u00e9tendus r\u00e9form\u00e9s", "587,000", "Bishopsgate", "Mnemiopsis", "from tomb and memorial, to portrait, allegorical, religious, mythical, statues for gardens including fountains, as well as architectural decorations", "Beirut", "smaller trade relations with their neighbours", "Tommy Lee Jones", "150", "four", "308", "Queen Victoria", "huge compensation pools", "the Orange Democratic Movement (ODM)", "Charlesfort", "adaptive (or acquired) immunity creates immunological memory after an initial response to a specific pathogen", "Battle of the Restigouche", "Boston", "force of gravity acting on the object balanced by a force applied by the \"spring reaction force\"", "head writer and executive producer", "The elephant Man", "a psychologist", "every year", "the character's name", "Batmitten", "Hong Kong", "ambidextrous", "Batman", "a horse", "the Irrawaddy River", "Ed White", "The Deep", "the lunar new year", "James", "New York City", "Troy", "Amnesty International", "John Gorman", "bison", "Edinburgh", "Viking feet", "Paul Gauguin", "Action Comics", "The Enigma code", "heat of fusion", "Novak Djokovic", "New Zealand", "Oasis", "The Golden Girls", "green", "Rajasthan", "The Union Gap", "floating ribs", "The G8 summit is an annual meeting between leaders from eight of the most powerful countries in the world", "golf", "Secretary of Homeland Security", "the Bee Gees", "Adelaide", "Edward John \"Eddie\" Izzard", "Sabina Guzzanti", "a $13 million global crime ring", "a quark", "krypton", "`` Glory '' is one of the most common words in scripture"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6136744281045752}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4256", "mrqa_squad-validation-5545", "mrqa_squad-validation-5303", "mrqa_squad-validation-7083", "mrqa_squad-validation-9255", "mrqa_squad-validation-6449", "mrqa_squad-validation-10351", "mrqa_triviaqa-validation-5724", "mrqa_triviaqa-validation-1114", "mrqa_triviaqa-validation-730", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-6783", "mrqa_triviaqa-validation-3751", "mrqa_triviaqa-validation-4974", "mrqa_triviaqa-validation-4944", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3215", "mrqa_triviaqa-validation-3888", "mrqa_triviaqa-validation-146", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-1686", "mrqa_triviaqa-validation-3095", "mrqa_naturalquestions-validation-5094", "mrqa_hotpotqa-validation-462", "mrqa_newsqa-validation-3199", "mrqa_searchqa-validation-7976", "mrqa_naturalquestions-validation-9323"], "SR": 0.515625, "CSR": 0.62890625, "retrieved_ids": ["mrqa_squad-train-75056", "mrqa_squad-train-76934", "mrqa_squad-train-75018", "mrqa_squad-train-29441", "mrqa_squad-train-83017", "mrqa_squad-train-44237", "mrqa_squad-train-41571", "mrqa_squad-train-8728", "mrqa_squad-train-1761", "mrqa_squad-train-64213", "mrqa_squad-train-42786", "mrqa_squad-train-20215", "mrqa_squad-train-69530", "mrqa_squad-train-85660", "mrqa_squad-train-2508", "mrqa_squad-train-54433", "mrqa_squad-train-20467", "mrqa_squad-train-4347", "mrqa_squad-train-2812", "mrqa_squad-train-53640", "mrqa_squad-train-35108", "mrqa_squad-train-56786", "mrqa_squad-train-69612", "mrqa_squad-train-27212", "mrqa_squad-train-8746", "mrqa_squad-train-34552", "mrqa_squad-train-50720", "mrqa_squad-train-71115", "mrqa_squad-train-64293", "mrqa_squad-train-41296", "mrqa_squad-train-70007", "mrqa_squad-train-29585", "mrqa_squad-validation-89", "mrqa_searchqa-validation-12963", "mrqa_naturalquestions-validation-2148", "mrqa_squad-validation-8452", "mrqa_searchqa-validation-12371", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-4967", "mrqa_squad-validation-2318", "mrqa_naturalquestions-validation-3942", "mrqa_searchqa-validation-478", "mrqa_squad-validation-2443", "mrqa_squad-validation-4206", "mrqa_hotpotqa-validation-2751", "mrqa_triviaqa-validation-4573", "mrqa_hotpotqa-validation-961", "mrqa_searchqa-validation-12968", "mrqa_squad-validation-4562", "mrqa_squad-validation-7571", "mrqa_squad-validation-6680", "mrqa_squad-validation-4902", "mrqa_hotpotqa-validation-1473", "mrqa_squad-validation-8576", "mrqa_searchqa-validation-16877", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-3481", "mrqa_squad-validation-7430", "mrqa_naturalquestions-validation-5672", "mrqa_squad-validation-2337", "mrqa_newsqa-validation-858", "mrqa_naturalquestions-validation-6050", "mrqa_newsqa-validation-539", "mrqa_hotpotqa-validation-1393"], "EFR": 0.967741935483871, "Overall": 0.7530015120967742}, {"timecode": 12, "before_eval_results": {"predictions": ["pulmonary fibrosis", "Henry Cavendish", "Virginia", "melatonin", "90-60's", "the deaths of two friends", "1985", "Ismailiyah, Egypt", "England", "the ability to pursue valued goals", "tentilla", "political support in his struggle against leftists", "$5 million", "Lake George", "Jadaran", "Dwight D. Eisenhower", "decreases", "one Commissioner", "Secretariat", "1955", "Australia", "September 1901", "The United States of America", "The Dragon", "psilocin", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Eurasia", "Boyd Gaming", "MGM Resorts International", "James G. Kiernan", "Omega SA", "September 14, 1877", "a jersey or uniform that a sports team wear in games instead of its home outfit or its away outfit", "Yasir Hussain", "Malayalam movies", "Kennedy Road", "2002", "31", "Grant Field", "Bill Boyd", "Jack Ryan", "Emilia-Romagna", "Buckingham Palace", "322,520", "Chief Strategy Officer", "Dave Lee Travis", "Bedknobs and Broomsticks", "Jane", "William Bradford", "140 million", "Beauty and the Beast", "Gary Ross", "International Boxing Hall of Fame (IBHOF)", "1996", "Revolver", "Jack Nicklaus", "repudiation, change of mind, repentance, and atonement", "Mussolini", "Ryan O' Neal", "off the coast of Dubai", "1918", "butter", "surrey", "rain"], "metric_results": {"EM": 0.625, "QA-F1": 0.696446608946609}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.09999999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.9090909090909091, 0.5, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3639", "mrqa_squad-validation-3192", "mrqa_squad-validation-2657", "mrqa_squad-validation-9565", "mrqa_squad-validation-6108", "mrqa_squad-validation-4294", "mrqa_hotpotqa-validation-149", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-577", "mrqa_hotpotqa-validation-2341", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-80", "mrqa_hotpotqa-validation-3833", "mrqa_hotpotqa-validation-278", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-2122", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-1893", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-4173", "mrqa_newsqa-validation-2790", "mrqa_searchqa-validation-16321"], "SR": 0.625, "CSR": 0.6286057692307692, "retrieved_ids": ["mrqa_squad-train-75886", "mrqa_squad-train-6382", "mrqa_squad-train-70947", "mrqa_squad-train-67641", "mrqa_squad-train-79478", "mrqa_squad-train-68010", "mrqa_squad-train-78575", "mrqa_squad-train-59095", "mrqa_squad-train-74838", "mrqa_squad-train-12551", "mrqa_squad-train-73010", "mrqa_squad-train-63605", "mrqa_squad-train-18561", "mrqa_squad-train-37798", "mrqa_squad-train-56564", "mrqa_squad-train-76034", "mrqa_squad-train-37533", "mrqa_squad-train-75213", "mrqa_squad-train-63706", "mrqa_squad-train-27066", "mrqa_squad-train-49268", "mrqa_squad-train-40844", "mrqa_squad-train-24639", "mrqa_squad-train-16450", "mrqa_squad-train-70847", "mrqa_squad-train-40174", "mrqa_squad-train-18441", "mrqa_squad-train-29592", "mrqa_squad-train-65495", "mrqa_squad-train-58716", "mrqa_squad-train-20358", "mrqa_squad-train-7917", "mrqa_triviaqa-validation-7060", "mrqa_newsqa-validation-1319", "mrqa_triviaqa-validation-3131", "mrqa_squad-validation-5303", "mrqa_squad-validation-4256", "mrqa_searchqa-validation-621", "mrqa_triviaqa-validation-6052", "mrqa_squad-validation-3374", "mrqa_naturalquestions-validation-328", "mrqa_hotpotqa-validation-1473", "mrqa_squad-validation-9304", "mrqa_squad-validation-4210", "mrqa_triviaqa-validation-253", "mrqa_searchqa-validation-3075", "mrqa_searchqa-validation-9679", "mrqa_searchqa-validation-13016", "mrqa_triviaqa-validation-1064", "mrqa_naturalquestions-validation-5094", "mrqa_triviaqa-validation-2357", "mrqa_squad-validation-10351", "mrqa_squad-validation-2337", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-4974", "mrqa_triviaqa-validation-5950", "mrqa_squad-validation-805", "mrqa_squad-validation-10466", "mrqa_squad-validation-7430", "mrqa_searchqa-validation-15243", "mrqa_naturalquestions-validation-6927", "mrqa_searchqa-validation-177", "mrqa_searchqa-validation-3385", "mrqa_searchqa-validation-1151"], "EFR": 1.0, "Overall": 0.7593930288461539}, {"timecode": 13, "before_eval_results": {"predictions": ["poverty", "Fred Silverman", "occupational burnout", "Saudi", "Some defendant accused of illegally protesting nuclear power, when asked to enter his plea, stated, \"I plead for the beauty that surrounds us\"; this is known as a \"creative plea,\"", "colloblasts, sticky cells", "$20.4 billion", "twelve", "Anglo-Saxons", "excerpts from the Doctor Who Confidential documentary", "stricter discipline based on their power of expulsion", "killed in a horse-riding accident", "1522", "eight", "Of course [the price of oil] is going to rise", "Roman law meaning 'empty land'", "Henry Hudson", "chipmunk", "Constantine", "Melbourne", "Albania", "brown trout", "Mayflower", "Tarzan", "lacrimal fluid", "George Best", "alla capella", "The Great British Bake Off", "dick grayson", "Fenn Street School", "Smiths", "Peter Crouch", "The Nobel Prize in Literature", "Pakistan", "The Observer", "United States", "Big Fat Gypsy Wedding", "beards", "Andes", "Thor", "The Comitium", "Moon River", "Tina Turner", "SW19", "Lancashire", "Pacific Ocean", "racing", "Rustle My Davies", "climatic types", "Charlie Brown", "vinaya", "avocado", "the Black Sea", "lactic acid", "1933", "Mirror Image", "Abu Dhabi", "Craig William Macneill", "terminal brain cancer", "800,000", "cinder cone", "giant slalom", "Serie B", "Saoirse Ronan"], "metric_results": {"EM": 0.609375, "QA-F1": 0.693556426635695}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 0.14634146341463414, 0.5, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3863", "mrqa_squad-validation-6913", "mrqa_squad-validation-4621", "mrqa_squad-validation-7112", "mrqa_squad-validation-3730", "mrqa_squad-validation-9761", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-2777", "mrqa_triviaqa-validation-270", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-2989", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-3865", "mrqa_triviaqa-validation-7595", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-5978", "mrqa_triviaqa-validation-1088", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-1076", "mrqa_naturalquestions-validation-6991", "mrqa_hotpotqa-validation-3607", "mrqa_searchqa-validation-1416", "mrqa_searchqa-validation-15315"], "SR": 0.609375, "CSR": 0.6272321428571428, "retrieved_ids": ["mrqa_squad-train-37559", "mrqa_squad-train-21446", "mrqa_squad-train-33006", "mrqa_squad-train-78147", "mrqa_squad-train-72453", "mrqa_squad-train-41061", "mrqa_squad-train-33257", "mrqa_squad-train-995", "mrqa_squad-train-41714", "mrqa_squad-train-31461", "mrqa_squad-train-77871", "mrqa_squad-train-60307", "mrqa_squad-train-82158", "mrqa_squad-train-38337", "mrqa_squad-train-44935", "mrqa_squad-train-17048", "mrqa_squad-train-10374", "mrqa_squad-train-81252", "mrqa_squad-train-83024", "mrqa_squad-train-54581", "mrqa_squad-train-19681", "mrqa_squad-train-83340", "mrqa_squad-train-5835", "mrqa_squad-train-44854", "mrqa_squad-train-2623", "mrqa_squad-train-35468", "mrqa_squad-train-29955", "mrqa_squad-train-79902", "mrqa_squad-train-84058", "mrqa_squad-train-29510", "mrqa_squad-train-33209", "mrqa_squad-train-1003", "mrqa_triviaqa-validation-4197", "mrqa_searchqa-validation-5713", "mrqa_squad-validation-9255", "mrqa_searchqa-validation-8040", "mrqa_squad-validation-7430", "mrqa_searchqa-validation-14307", "mrqa_triviaqa-validation-146", "mrqa_squad-validation-9334", "mrqa_triviaqa-validation-3080", "mrqa_squad-validation-8576", "mrqa_squad-validation-8747", "mrqa_searchqa-validation-1151", "mrqa_triviaqa-validation-1064", "mrqa_naturalquestions-validation-75", "mrqa_searchqa-validation-16960", "mrqa_squad-validation-1108", "mrqa_newsqa-validation-1577", "mrqa_naturalquestions-validation-1435", "mrqa_squad-validation-7459", "mrqa_squad-validation-9896", "mrqa_naturalquestions-validation-2146", "mrqa_squad-validation-4210", "mrqa_searchqa-validation-12371", "mrqa_squad-validation-7674", "mrqa_hotpotqa-validation-1893", "mrqa_squad-validation-4562", "mrqa_hotpotqa-validation-5526", "mrqa_newsqa-validation-1319", "mrqa_triviaqa-validation-1603", "mrqa_searchqa-validation-621", "mrqa_squad-validation-512", "mrqa_squad-validation-6393"], "EFR": 0.96, "Overall": 0.7511183035714286}, {"timecode": 14, "before_eval_results": {"predictions": ["at the Cathedral of Saint John the Divine", "The Ruhr", "Hulu", "time complexity", "Muslim Iberia", "10 o'clock", "NYPD Blue", "AAUW", "the Magnetophon tape recorder", "running away to Tomingaj", "Rotterdam", "in certain cases, with great economic inequality, there is nonetheless not more waste and pollution created", "Charles Dickens", "force", "best teachers", "imperfect", "albatross", "wind", "you go and save the best for last", "The National Gallery of Art", "Portland", "Montego Bay", "Solferino", "Menelaus", "a pheasant", "turkeys", "neptune", "lionhead", "William", "red parrot", "a light-year", "Clark Gable", "El burlador de Sevilla", "Muqtada al-Sadr", "Prince Charles", "cocoa butter", "Violent Femmes", "oats", "a personal guardian angel", "laser", "James Fenimore Cooper", "Veep", "gold", "Rudyard Kipling", "a boxer-turned-drug addict", "a fox", "Copenhagen", "Madonna", "Jose de San", "Madrid", "a pirate", "Jaime", "Harvard", "Blackwell", "fertilization", "As of 2011, with an estimated population of 1.2 billion, India is the world's second most populous country after the People's Republic of China", "Renault", "candelabra", "Kind Hearts and Coronets", "2012", "poems", "Cyprus", "Honda", "neptune"], "metric_results": {"EM": 0.515625, "QA-F1": 0.592549001924002}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, true, true, true, true, true, true, true, false], "QA-F1": [0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.7272727272727273, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2962962962962963, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-1234", "mrqa_squad-validation-7632", "mrqa_searchqa-validation-7109", "mrqa_searchqa-validation-456", "mrqa_searchqa-validation-10097", "mrqa_searchqa-validation-3019", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1948", "mrqa_searchqa-validation-9250", "mrqa_searchqa-validation-8283", "mrqa_searchqa-validation-14628", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-15637", "mrqa_searchqa-validation-6931", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-6298", "mrqa_searchqa-validation-4555", "mrqa_searchqa-validation-4068", "mrqa_searchqa-validation-13012", "mrqa_searchqa-validation-8607", "mrqa_searchqa-validation-10093", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-3485", "mrqa_searchqa-validation-10060", "mrqa_searchqa-validation-16156", "mrqa_searchqa-validation-5613", "mrqa_searchqa-validation-5460", "mrqa_searchqa-validation-14502", "mrqa_naturalquestions-validation-8420", "mrqa_triviaqa-validation-7170"], "SR": 0.515625, "CSR": 0.6197916666666667, "retrieved_ids": ["mrqa_squad-train-35889", "mrqa_squad-train-27007", "mrqa_squad-train-20121", "mrqa_squad-train-81501", "mrqa_squad-train-70932", "mrqa_squad-train-3874", "mrqa_squad-train-24909", "mrqa_squad-train-77773", "mrqa_squad-train-19550", "mrqa_squad-train-52301", "mrqa_squad-train-82916", "mrqa_squad-train-15848", "mrqa_squad-train-15892", "mrqa_squad-train-18488", "mrqa_squad-train-2509", "mrqa_squad-train-18627", "mrqa_squad-train-3665", "mrqa_squad-train-16058", "mrqa_squad-train-12719", "mrqa_squad-train-83057", "mrqa_squad-train-38583", "mrqa_squad-train-30890", "mrqa_squad-train-80128", "mrqa_squad-train-81401", "mrqa_squad-train-6464", "mrqa_squad-train-8087", "mrqa_squad-train-58104", "mrqa_squad-train-81127", "mrqa_squad-train-63291", "mrqa_squad-train-26014", "mrqa_squad-train-50862", "mrqa_squad-train-78051", "mrqa_squad-validation-2145", "mrqa_squad-validation-10483", "mrqa_triviaqa-validation-4710", "mrqa_squad-validation-2097", "mrqa_hotpotqa-validation-1893", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-1076", "mrqa_hotpotqa-validation-4967", "mrqa_triviaqa-validation-2321", "mrqa_squad-validation-10067", "mrqa_triviaqa-validation-5194", "mrqa_hotpotqa-validation-961", "mrqa_searchqa-validation-2499", "mrqa_squad-validation-805", "mrqa_squad-validation-7162", "mrqa_searchqa-validation-8040", "mrqa_squad-validation-1308", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-2851", "mrqa_squad-validation-5", "mrqa_triviaqa-validation-6783", "mrqa_squad-validation-7112", "mrqa_naturalquestions-validation-5798", "mrqa_squad-validation-7571", "mrqa_searchqa-validation-5713", "mrqa_squad-validation-680", "mrqa_searchqa-validation-5760", "mrqa_squad-validation-6449", "mrqa_triviaqa-validation-270", "mrqa_squad-validation-2318"], "EFR": 0.967741935483871, "Overall": 0.7511785954301076}, {"timecode": 15, "before_eval_results": {"predictions": ["trial division", "Arriva", "three to five", "heavy/highway, heavy civil or heavy engineering", "Osama bin Laden", "September 1944", "the spin magnetic moments of the unpaired electrons in the molecule, and the negative exchange energy between neighboring O2 molecules", "criminal investigations and arrests", "complexity classes", "April 1, 1963", "Jamukha", "consultant at the Westinghouse Electric & Manufacturing Company's Pittsburgh labs", "711,988", "12951 / 52 Mumbai Rajdhani Express", "Speaker of the House of Representatives", "Hugo Weaving", "the word continued to be used as the Old French word autompne ( automne in modern French ) or autumpne in Middle English, and was later normalised to the original Latin", "The Dursleys live at Number 4, Privet Drive, Little Whinging in Surrey, England", "DJ Lance Rock", "the nerves and ganglia outside the brain and spinal cord", "Aman Gandotra and 406 Bharadwaj", "Daya Jethalal Gada", "Kevin Sumlin", "birch", "The United States is the only Western country currently applying the death penalty, one of 57 countries worldwide applying it, and was the first to develop lethal injection as a method of execution", "Canada", "two - stroke engines and chain drive", "the English", "petition for a writ of certiorari", "Emma Watson", "the inmates have been detained indefinitely without trial", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "The Jamestown settlement in the Colony of Virginia", "January 2017 patch", "Set six months after Kratos killed his wife and child, he has been imprisoned by the three Furies for breaking his blood oath to Ares", "Tatsumi", "December 15, 2017", "Sunni Muslim family", "Magnavox Odyssey", "The Buckwheat Boyz", "Christianity", "India", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "between 1923 and 1925", "Moscazzano", "the stems and roots of certain vascular plants", "St. Pauli Girl Special Dark", "The National Football League", "during cellular respiration to an electrochemical gradient created by the difference in proton ( H ) concentration across the mitochondrial membrane in eukaryotes or the plasma membrane in bacteria", "San Francisco, California", "Hal Derwin", "to oversee the local church", "October 28, 2007", "~ 0.058 - 0.072 mm ( ~ 55 - 75 micrometers )", "Robert Boyle", "the solar system", "Ascona", "Ludwig van Beethoven", "former Boca Juniors teammate and national coach", "Akshay Kumar", "Harriet", "Bananas", "heat- and chemically resistant", "a centerpiece"], "metric_results": {"EM": 0.484375, "QA-F1": 0.615995433964184}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.33333333333333337, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 0.4615384615384615, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.22222222222222224, 0.5714285714285715, 0.0, 0.29629629629629634, 0.0, 1.0, 0.16666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 0.6, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8910", "mrqa_squad-validation-5318", "mrqa_squad-validation-3500", "mrqa_squad-validation-6921", "mrqa_squad-validation-6113", "mrqa_squad-validation-1312", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-1400", "mrqa_naturalquestions-validation-144", "mrqa_naturalquestions-validation-2606", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-1433", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-3429", "mrqa_naturalquestions-validation-5036", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8962", "mrqa_hotpotqa-validation-1409", "mrqa_newsqa-validation-3042", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-397"], "SR": 0.484375, "CSR": 0.611328125, "retrieved_ids": ["mrqa_squad-train-12879", "mrqa_squad-train-46888", "mrqa_squad-train-2790", "mrqa_squad-train-21504", "mrqa_squad-train-69409", "mrqa_squad-train-20356", "mrqa_squad-train-12577", "mrqa_squad-train-24302", "mrqa_squad-train-10196", "mrqa_squad-train-79855", "mrqa_squad-train-70158", "mrqa_squad-train-30179", "mrqa_squad-train-5542", "mrqa_squad-train-41997", "mrqa_squad-train-16089", "mrqa_squad-train-59718", "mrqa_squad-train-35383", "mrqa_squad-train-38964", "mrqa_squad-train-58925", "mrqa_squad-train-19765", "mrqa_squad-train-59075", "mrqa_squad-train-79239", "mrqa_squad-train-29502", "mrqa_squad-train-46371", "mrqa_squad-train-11879", "mrqa_squad-train-75815", "mrqa_squad-train-40435", "mrqa_squad-train-77265", "mrqa_squad-train-32916", "mrqa_squad-train-76140", "mrqa_squad-train-62646", "mrqa_squad-train-16540", "mrqa_squad-validation-2717", "mrqa_naturalquestions-validation-7101", "mrqa_hotpotqa-validation-47", "mrqa_squad-validation-8747", "mrqa_triviaqa-validation-2357", "mrqa_squad-validation-7674", "mrqa_hotpotqa-validation-3607", "mrqa_searchqa-validation-1416", "mrqa_searchqa-validation-16321", "mrqa_squad-validation-3373", "mrqa_squad-validation-10251", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3199", "mrqa_hotpotqa-validation-2896", "mrqa_squad-validation-1572", "mrqa_searchqa-validation-6931", "mrqa_searchqa-validation-455", "mrqa_squad-validation-7162", "mrqa_newsqa-validation-246", "mrqa_squad-validation-6091", "mrqa_hotpotqa-validation-577", "mrqa_searchqa-validation-10093", "mrqa_squad-validation-7571", "mrqa_squad-validation-3497", "mrqa_hotpotqa-validation-462", "mrqa_searchqa-validation-5713", "mrqa_squad-validation-5545", "mrqa_searchqa-validation-1948", "mrqa_searchqa-validation-7782", "mrqa_hotpotqa-validation-765", "mrqa_squad-validation-9578", "mrqa_triviaqa-validation-1441"], "EFR": 1.0, "Overall": 0.7559375}, {"timecode": 16, "before_eval_results": {"predictions": ["512-bit", "the worst-case time complexity T(n) is defined to be the maximum time taken over all inputs of size n", "National Broadcasting Company", "Marco Polo", "November 2006 and May 2008", "quite complex", "too cold in northern Europe for the survival of fleas", "they circulate and are moved around within plant cells, and occasionally pinch in two to reproduce", "xenoliths", "80", "the leader of the political party or coalition with the most seats", "April 1887", "Thin patties on a triple decker bun topped with cheese, cheese, pickles, onions \u2013 on a sesame seed bun", "Rock Follies", "Montmorency", "\"Brings out the tiger in you, in you!\"", "Elton John", "beer", "David Davis", "a double dip recession", "Corfu", "the central or middle rib of a leaf", "Kinshasa", "8 minutes", "the National Industrial Conference Board", "four", "Cyclops", "oxygen", "Silent Spring", "the value of unknown electrical resistance", "white spirit", "(Viburnum nudum)", "Harold Wilson", "Denmark", "Anna (Julia Roberts)", "James Mason", "\"Shooting Star\"", "Hudson", "ostrich", "Moby Dick", "William Golding", "the 5th fret", "The Runaways", "Kuznetsova", "Max Bygraves", "the A38", "Nicola Walker", "Virgin", "1948", "Port Talbot", "a pluvial was an extended period of abundant rainfall lasting many thousands of years", "\"The best is yet to come.\"", "Nicola Adams", "Sax Rohmer", "the EU Data Protection Directive 1995 protection", "May 2010", "Bruce R. Cook", "Sir Patrick Barnewall", "the Obama administration", "The man ran out of bullets and blew himself up", "the Equator", "Aerosmith", "Cesar Millan", "Princeton"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6171636477557529}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 0.3, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.2857142857142857, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1708", "mrqa_squad-validation-5605", "mrqa_squad-validation-8560", "mrqa_squad-validation-2852", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-376", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-2385", "mrqa_triviaqa-validation-162", "mrqa_triviaqa-validation-6428", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-2242", "mrqa_triviaqa-validation-5993", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-3133", "mrqa_triviaqa-validation-3473", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-7387", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-1320", "mrqa_triviaqa-validation-7067", "mrqa_triviaqa-validation-4622", "mrqa_triviaqa-validation-1360", "mrqa_triviaqa-validation-2147", "mrqa_naturalquestions-validation-3930", "mrqa_hotpotqa-validation-1542", "mrqa_newsqa-validation-1537", "mrqa_hotpotqa-validation-4298"], "SR": 0.5625, "CSR": 0.6084558823529411, "retrieved_ids": ["mrqa_squad-train-9072", "mrqa_squad-train-24111", "mrqa_squad-train-62513", "mrqa_squad-train-14114", "mrqa_squad-train-13642", "mrqa_squad-train-42920", "mrqa_squad-train-32437", "mrqa_squad-train-32857", "mrqa_squad-train-65803", "mrqa_squad-train-46308", "mrqa_squad-train-67631", "mrqa_squad-train-73179", "mrqa_squad-train-76293", "mrqa_squad-train-39690", "mrqa_squad-train-21593", "mrqa_squad-train-9957", "mrqa_squad-train-18124", "mrqa_squad-train-2508", "mrqa_squad-train-23726", "mrqa_squad-train-404", "mrqa_squad-train-34804", "mrqa_squad-train-67397", "mrqa_squad-train-50539", "mrqa_squad-train-39788", "mrqa_squad-train-54109", "mrqa_squad-train-20758", "mrqa_squad-train-67805", "mrqa_squad-train-84192", "mrqa_squad-train-28579", "mrqa_squad-train-25444", "mrqa_squad-train-8750", "mrqa_squad-train-78202", "mrqa_searchqa-validation-1523", "mrqa_triviaqa-validation-5724", "mrqa_searchqa-validation-1416", "mrqa_squad-validation-8910", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-2115", "mrqa_triviaqa-validation-3751", "mrqa_searchqa-validation-397", "mrqa_squad-validation-7382", "mrqa_squad-validation-6072", "mrqa_hotpotqa-validation-80", "mrqa_triviaqa-validation-270", "mrqa_hotpotqa-validation-4810", "mrqa_triviaqa-validation-1114", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-328", "mrqa_searchqa-validation-4068", "mrqa_searchqa-validation-16156", "mrqa_hotpotqa-validation-2237", "mrqa_triviaqa-validation-2758", "mrqa_searchqa-validation-10060", "mrqa_triviaqa-validation-1064", "mrqa_hotpotqa-validation-3607", "mrqa_searchqa-validation-679", "mrqa_searchqa-validation-8607", "mrqa_squad-validation-2145", "mrqa_searchqa-validation-14852", "mrqa_squad-validation-3497", "mrqa_triviaqa-validation-134", "mrqa_triviaqa-validation-6979", "mrqa_squad-validation-525", "mrqa_searchqa-validation-14572"], "EFR": 1.0, "Overall": 0.7553630514705882}, {"timecode": 17, "before_eval_results": {"predictions": ["after the end of the Mexican War", "fort Beaus\u00e9jour", "journalist", "Seventy percent", "modern hatred of the Jews", "Germany and Austria", "the principle of inclusions and components", "Sweynforkbeard", "the King", "eight", "Sierra Freeway", "Mickey Mouse", "Rugby", "Spain and Portugal", "bacteria", "Google", "dance", "children of prostitutes", "Quebec", "Planet of the Apes", "Prince Edward Island", "bilirubin", "frosted", "Virginia Woolf", "Vasco da Gama", "canter", "Musculus gluteus maximus", "1972", "Arbor Day", "Countrywide Financial", "a red light", "Conan O'Brien", "Georgia", "manav", "Nixon", "manhattan", "Hair", "mountain region", "Robert Stempel", "boo", "Sepoy", "final", "Wayne Brady", "submarines", "Joan la Pucelie", "pea soup", "Trinidad and Tobago", "Vladimir Nabokov", "Oreo", "Peter Pan", "homo", "a laser beam", "Phi Beta Phi Society", "Elizabeth Weber", "Numbers 22 : 28", "vaud, Switzerland", "Prince Philip", "Athenion", "5.3 million", "pilot", "a pregnant soldier", "Avatar", "Tears for Fears", "paper"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6011160714285715}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, true, true, false, false, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10273", "mrqa_squad-validation-4260", "mrqa_squad-validation-1092", "mrqa_searchqa-validation-6", "mrqa_searchqa-validation-11651", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-5574", "mrqa_searchqa-validation-14952", "mrqa_searchqa-validation-9389", "mrqa_searchqa-validation-4933", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-14512", "mrqa_searchqa-validation-9551", "mrqa_searchqa-validation-6712", "mrqa_searchqa-validation-15777", "mrqa_searchqa-validation-6531", "mrqa_searchqa-validation-1289", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-15560", "mrqa_searchqa-validation-9529", "mrqa_searchqa-validation-10063", "mrqa_searchqa-validation-12536", "mrqa_searchqa-validation-9096", "mrqa_searchqa-validation-2247", "mrqa_searchqa-validation-2347", "mrqa_naturalquestions-validation-3284", "mrqa_triviaqa-validation-1965", "mrqa_triviaqa-validation-6259", "mrqa_newsqa-validation-349", "mrqa_newsqa-validation-2525"], "SR": 0.515625, "CSR": 0.6032986111111112, "retrieved_ids": ["mrqa_squad-train-6543", "mrqa_squad-train-38566", "mrqa_squad-train-65494", "mrqa_squad-train-956", "mrqa_squad-train-69107", "mrqa_squad-train-83445", "mrqa_squad-train-67175", "mrqa_squad-train-30229", "mrqa_squad-train-77037", "mrqa_squad-train-57783", "mrqa_squad-train-57574", "mrqa_squad-train-47872", "mrqa_squad-train-70313", "mrqa_squad-train-71732", "mrqa_squad-train-25616", "mrqa_squad-train-66519", "mrqa_squad-train-10460", "mrqa_squad-train-82794", "mrqa_squad-train-22794", "mrqa_squad-train-3574", "mrqa_squad-train-22059", "mrqa_squad-train-69805", "mrqa_squad-train-38010", "mrqa_squad-train-59418", "mrqa_squad-train-82506", "mrqa_squad-train-7155", "mrqa_squad-train-4933", "mrqa_squad-train-39886", "mrqa_squad-train-68028", "mrqa_squad-train-16970", "mrqa_squad-train-44797", "mrqa_squad-train-23688", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-3930", "mrqa_hotpotqa-validation-497", "mrqa_squad-validation-10427", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-1504", "mrqa_triviaqa-validation-162", "mrqa_triviaqa-validation-3888", "mrqa_triviaqa-validation-3133", "mrqa_newsqa-validation-858", "mrqa_squad-validation-3373", "mrqa_squad-validation-2506", "mrqa_searchqa-validation-455", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-6052", "mrqa_triviaqa-validation-7430", "mrqa_searchqa-validation-2499", "mrqa_squad-validation-1808", "mrqa_triviaqa-validation-3095", "mrqa_naturalquestions-validation-5036", "mrqa_triviaqa-validation-2242", "mrqa_naturalquestions-validation-688", "mrqa_squad-validation-1312", "mrqa_triviaqa-validation-146", "mrqa_triviaqa-validation-3215", "mrqa_searchqa-validation-456", "mrqa_triviaqa-validation-2147", "mrqa_hotpotqa-validation-5174", "mrqa_searchqa-validation-12968", "mrqa_triviaqa-validation-3131", "mrqa_hotpotqa-validation-47", "mrqa_squad-validation-3500"], "EFR": 1.0, "Overall": 0.7543315972222222}, {"timecode": 18, "before_eval_results": {"predictions": ["quantum mechanics", "near the surface", "Alfred Stevens", "domestic social reforms", "algebraic", "eight", "1886/1887", "clerical marriage", "Apollo", "Linebacker", "2000", "Richard Street", "Jack Chick", "1926 Paris", "American burlesque", "Polk County", "Skyscraper", "schoolteacher", "Dunlop India Ltd", "Martin O'Neill", "a family member", "Nagapattinam District", "Attorney General and as Lord Chancellor of England", "North Dakota", "fennec", "Norwood, Massachusetts", "1993", "the 10-metre platform event", "Liquidambar styraciflua", "Battle of Chester", "Flashback", "Kentucky", "Marco Fu", "Francis the Talking Mule", "Kristin Scott Thomas", "\"The King of Hollywood\"", "evangelical Christian", "paternalistic policies enacted upon Native American tribes", "The Hindu Group", "Kealakekua Bay", "1919", "Julia Verdin", "1967", "Guthred", "The Arizona Health Care Cost Containment System", "South Australia", "1945", "1912", "La Scala", "How to Train Your Dragon", "pronghorn", "United States ambassador to Ghana", "Life Is a Minestrone", "Monk's", "Sir Ernest Rutherford", "bump", "may", "France", "at least $20 million to $30 million", "(Ulysses S. Grant)", "(Sidney) Tibbs", "the eventual closure of Guantanamo Bay prison and CIA \"black site\" prisons", "CNN", "Michael Arrington"], "metric_results": {"EM": 0.5625, "QA-F1": 0.653390522875817}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.5, 0.0, 0.7058823529411764, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9286", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-1227", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3929", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-4899", "mrqa_hotpotqa-validation-5094", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-0", "mrqa_naturalquestions-validation-339", "mrqa_triviaqa-validation-4705", "mrqa_triviaqa-validation-7209", "mrqa_newsqa-validation-2601", "mrqa_searchqa-validation-2674", "mrqa_searchqa-validation-12442", "mrqa_newsqa-validation-1114"], "SR": 0.5625, "CSR": 0.6011513157894737, "retrieved_ids": ["mrqa_squad-train-32156", "mrqa_squad-train-39396", "mrqa_squad-train-25752", "mrqa_squad-train-1641", "mrqa_squad-train-24666", "mrqa_squad-train-34320", "mrqa_squad-train-18988", "mrqa_squad-train-66691", "mrqa_squad-train-68711", "mrqa_squad-train-22994", "mrqa_squad-train-47243", "mrqa_squad-train-81439", "mrqa_squad-train-3571", "mrqa_squad-train-77120", "mrqa_squad-train-77284", "mrqa_squad-train-61288", "mrqa_squad-train-29079", "mrqa_squad-train-53461", "mrqa_squad-train-34514", "mrqa_squad-train-56642", "mrqa_squad-train-51428", "mrqa_squad-train-57305", "mrqa_squad-train-36057", "mrqa_squad-train-15712", "mrqa_squad-train-35324", "mrqa_squad-train-19789", "mrqa_squad-train-25963", "mrqa_squad-train-58460", "mrqa_squad-train-10155", "mrqa_squad-train-71022", "mrqa_squad-train-20164", "mrqa_squad-train-79638", "mrqa_squad-validation-10259", "mrqa_squad-validation-9255", "mrqa_searchqa-validation-15777", "mrqa_triviaqa-validation-134", "mrqa_searchqa-validation-6726", "mrqa_hotpotqa-validation-3247", "mrqa_triviaqa-validation-6643", "mrqa_squad-validation-9304", "mrqa_hotpotqa-validation-5703", "mrqa_naturalquestions-validation-328", "mrqa_squad-validation-2852", "mrqa_searchqa-validation-16156", "mrqa_triviaqa-validation-456", "mrqa_squad-validation-7430", "mrqa_naturalquestions-validation-3942", "mrqa_triviaqa-validation-7742", "mrqa_searchqa-validation-9529", "mrqa_searchqa-validation-456", "mrqa_squad-validation-7708", "mrqa_triviaqa-validation-3133", "mrqa_squad-validation-434", "mrqa_squad-validation-7112", "mrqa_squad-validation-1251", "mrqa_naturalquestions-validation-3284", "mrqa_naturalquestions-validation-5960", "mrqa_searchqa-validation-1151", "mrqa_squad-validation-5545", "mrqa_searchqa-validation-13651", "mrqa_squad-validation-4631", "mrqa_squad-validation-3373", "mrqa_triviaqa-validation-5336", "mrqa_searchqa-validation-8411"], "EFR": 0.9642857142857143, "Overall": 0.7467592810150376}, {"timecode": 19, "before_eval_results": {"predictions": ["2,200", "swimming-plates", "MHC I", "Executive Vice President of Football Operations", "10", "France", "Time", "Nafzger", "Warszawa", "The Troggs", "schizophrenia", "Cressida", "Tom Osborne", "Moses", "Pekingese", "Golda Meir", "Fiddler on the Roof", "Monopoly", "Al Czervik", "Stanislaw I", "mask", "Alien", "Tower of London", "reptiles", "Madonna", "onion", "Walter Alston", "Benazir Bhutto", "Coca-Cola", "Red Bull", "Chaillot", "Ibrahim Petrovich Hannibal", "flour", "grow a Beard", "The Soup Nazi", "Pyrrhus", "Guatemala", "bonds", "Edgar Allan Poe", "chicken & Egg", "August Strindberg", "Sacher Torte", "Palestine: Peace Not Apartheid", "parachute jump", "Lovebirds", "African-born", "dessert glasses", "Daisy Miller", "the Arithmometer", "American opposition to British policy", "Frank Sinatra", "The Dark Lady of the Sonnets", "South Africa", "United States Frigate", "Pearl Harbor", "Costa del Sol", "River Stour", "Annales de chimie et de physique", "gull-wing doors", "New Jersey Economic Development Authority", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March", "1994", "state senators", "38"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5337282509157509}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.15384615384615385, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4730", "mrqa_squad-validation-375", "mrqa_squad-validation-1239", "mrqa_searchqa-validation-3955", "mrqa_searchqa-validation-13110", "mrqa_searchqa-validation-1529", "mrqa_searchqa-validation-5329", "mrqa_searchqa-validation-4072", "mrqa_searchqa-validation-7322", "mrqa_searchqa-validation-583", "mrqa_searchqa-validation-7688", "mrqa_searchqa-validation-9769", "mrqa_searchqa-validation-10971", "mrqa_searchqa-validation-2105", "mrqa_searchqa-validation-1800", "mrqa_searchqa-validation-5060", "mrqa_searchqa-validation-2783", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-11216", "mrqa_searchqa-validation-16595", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-7776", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-14453", "mrqa_searchqa-validation-6208", "mrqa_searchqa-validation-12078", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-9809", "mrqa_hotpotqa-validation-4813", "mrqa_newsqa-validation-2607", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-406"], "SR": 0.46875, "CSR": 0.59453125, "retrieved_ids": ["mrqa_squad-train-13772", "mrqa_squad-train-13939", "mrqa_squad-train-49201", "mrqa_squad-train-59091", "mrqa_squad-train-16238", "mrqa_squad-train-56397", "mrqa_squad-train-76152", "mrqa_squad-train-46398", "mrqa_squad-train-63058", "mrqa_squad-train-67005", "mrqa_squad-train-63981", "mrqa_squad-train-66206", "mrqa_squad-train-64338", "mrqa_squad-train-3375", "mrqa_squad-train-49593", "mrqa_squad-train-47871", "mrqa_squad-train-34192", "mrqa_squad-train-50722", "mrqa_squad-train-76130", "mrqa_squad-train-8980", "mrqa_squad-train-22387", "mrqa_squad-train-85885", "mrqa_squad-train-67874", "mrqa_squad-train-44929", "mrqa_squad-train-2269", "mrqa_squad-train-31704", "mrqa_squad-train-48062", "mrqa_squad-train-11442", "mrqa_squad-train-44788", "mrqa_squad-train-7968", "mrqa_squad-train-67157", "mrqa_squad-train-62469", "mrqa_naturalquestions-validation-10367", "mrqa_squad-validation-10251", "mrqa_triviaqa-validation-2777", "mrqa_hotpotqa-validation-3937", "mrqa_searchqa-validation-10060", "mrqa_searchqa-validation-15560", "mrqa_triviaqa-validation-7349", "mrqa_hotpotqa-validation-3607", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-8254", "mrqa_hotpotqa-validation-2341", "mrqa_squad-validation-1092", "mrqa_squad-validation-809", "mrqa_hotpotqa-validation-2751", "mrqa_squad-validation-7382", "mrqa_squad-validation-4260", "mrqa_searchqa-validation-5070", "mrqa_triviaqa-validation-1561", "mrqa_searchqa-validation-6931", "mrqa_triviaqa-validation-3131", "mrqa_searchqa-validation-4509", "mrqa_squad-validation-6197", "mrqa_squad-validation-3500", "mrqa_triviaqa-validation-7060", "mrqa_newsqa-validation-467", "mrqa_naturalquestions-validation-3217", "mrqa_triviaqa-validation-3751", "mrqa_squad-validation-5605", "mrqa_naturalquestions-validation-2606", "mrqa_squad-validation-8900", "mrqa_squad-validation-9565", "mrqa_triviaqa-validation-7595"], "EFR": 1.0, "Overall": 0.7525781250000001}, {"timecode": 20, "UKR": 0.7734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1340", "mrqa_hotpotqa-validation-1361", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-1760", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-204", "mrqa_hotpotqa-validation-208", "mrqa_hotpotqa-validation-2122", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2885", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-2981", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-3323", "mrqa_hotpotqa-validation-3374", "mrqa_hotpotqa-validation-338", "mrqa_hotpotqa-validation-3480", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-3669", "mrqa_hotpotqa-validation-3734", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-3815", "mrqa_hotpotqa-validation-3821", "mrqa_hotpotqa-validation-3929", "mrqa_hotpotqa-validation-3937", "mrqa_hotpotqa-validation-3968", "mrqa_hotpotqa-validation-3969", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-4085", "mrqa_hotpotqa-validation-4166", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-472", "mrqa_hotpotqa-validation-474", "mrqa_hotpotqa-validation-4899", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5045", "mrqa_hotpotqa-validation-5054", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-5174", "mrqa_hotpotqa-validation-530", "mrqa_hotpotqa-validation-5303", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5358", "mrqa_hotpotqa-validation-5534", "mrqa_hotpotqa-validation-5624", "mrqa_hotpotqa-validation-5642", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5854", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-722", "mrqa_hotpotqa-validation-722", "mrqa_hotpotqa-validation-731", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-80", "mrqa_hotpotqa-validation-884", "mrqa_hotpotqa-validation-928", "mrqa_hotpotqa-validation-996", "mrqa_naturalquestions-validation-10012", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1400", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-2606", "mrqa_naturalquestions-validation-2609", "mrqa_naturalquestions-validation-2658", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-3429", "mrqa_naturalquestions-validation-3930", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3965", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-4657", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-6506", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-6770", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-75", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8585", "mrqa_naturalquestions-validation-8962", "mrqa_naturalquestions-validation-9921", "mrqa_naturalquestions-validation-9972", "mrqa_newsqa-validation-1319", "mrqa_newsqa-validation-1537", "mrqa_newsqa-validation-1649", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-2248", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-2790", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3075", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-4169", "mrqa_newsqa-validation-613", "mrqa_newsqa-validation-632", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-858", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10060", "mrqa_searchqa-validation-10097", "mrqa_searchqa-validation-10173", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10669", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10971", "mrqa_searchqa-validation-11248", "mrqa_searchqa-validation-11392", "mrqa_searchqa-validation-12648", "mrqa_searchqa-validation-12740", "mrqa_searchqa-validation-1289", "mrqa_searchqa-validation-12952", "mrqa_searchqa-validation-13012", "mrqa_searchqa-validation-13026", "mrqa_searchqa-validation-13110", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-13931", "mrqa_searchqa-validation-14184", "mrqa_searchqa-validation-14471", "mrqa_searchqa-validation-14502", "mrqa_searchqa-validation-14512", "mrqa_searchqa-validation-14514", "mrqa_searchqa-validation-14666", "mrqa_searchqa-validation-14723", "mrqa_searchqa-validation-14849", "mrqa_searchqa-validation-14852", "mrqa_searchqa-validation-14952", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-1529", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15637", "mrqa_searchqa-validation-15702", "mrqa_searchqa-validation-15845", "mrqa_searchqa-validation-16156", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-16595", "mrqa_searchqa-validation-177", "mrqa_searchqa-validation-2105", "mrqa_searchqa-validation-2202", "mrqa_searchqa-validation-2783", "mrqa_searchqa-validation-3385", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-3485", "mrqa_searchqa-validation-3955", "mrqa_searchqa-validation-4068", "mrqa_searchqa-validation-4072", "mrqa_searchqa-validation-4355", "mrqa_searchqa-validation-455", "mrqa_searchqa-validation-456", "mrqa_searchqa-validation-478", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-5060", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-5329", "mrqa_searchqa-validation-5477", "mrqa_searchqa-validation-5574", "mrqa_searchqa-validation-5583", "mrqa_searchqa-validation-5760", "mrqa_searchqa-validation-577", "mrqa_searchqa-validation-5920", "mrqa_searchqa-validation-6208", "mrqa_searchqa-validation-621", "mrqa_searchqa-validation-628", "mrqa_searchqa-validation-6298", "mrqa_searchqa-validation-6531", "mrqa_searchqa-validation-6712", "mrqa_searchqa-validation-6937", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-7896", "mrqa_searchqa-validation-7976", "mrqa_searchqa-validation-8385", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-8578", "mrqa_searchqa-validation-8900", "mrqa_searchqa-validation-9096", "mrqa_searchqa-validation-9133", "mrqa_searchqa-validation-9151", "mrqa_searchqa-validation-9529", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-10008", "mrqa_squad-validation-1009", "mrqa_squad-validation-10111", "mrqa_squad-validation-10207", "mrqa_squad-validation-10251", "mrqa_squad-validation-10273", "mrqa_squad-validation-10285", "mrqa_squad-validation-10335", "mrqa_squad-validation-10351", "mrqa_squad-validation-10351", "mrqa_squad-validation-10413", "mrqa_squad-validation-10427", "mrqa_squad-validation-10466", "mrqa_squad-validation-10474", "mrqa_squad-validation-1079", "mrqa_squad-validation-1079", "mrqa_squad-validation-1092", "mrqa_squad-validation-1095", "mrqa_squad-validation-1116", "mrqa_squad-validation-1138", "mrqa_squad-validation-1180", "mrqa_squad-validation-1219", "mrqa_squad-validation-1241", "mrqa_squad-validation-1255", "mrqa_squad-validation-1312", "mrqa_squad-validation-1316", "mrqa_squad-validation-1338", "mrqa_squad-validation-1461", "mrqa_squad-validation-1552", "mrqa_squad-validation-1554", "mrqa_squad-validation-161", "mrqa_squad-validation-1636", "mrqa_squad-validation-1636", "mrqa_squad-validation-1681", "mrqa_squad-validation-1706", "mrqa_squad-validation-1808", "mrqa_squad-validation-1949", "mrqa_squad-validation-1973", "mrqa_squad-validation-1982", "mrqa_squad-validation-2005", "mrqa_squad-validation-2069", "mrqa_squad-validation-2318", "mrqa_squad-validation-2369", "mrqa_squad-validation-2434", "mrqa_squad-validation-2437", "mrqa_squad-validation-2453", "mrqa_squad-validation-2458", "mrqa_squad-validation-2476", "mrqa_squad-validation-2569", "mrqa_squad-validation-2609", "mrqa_squad-validation-2670", "mrqa_squad-validation-2717", "mrqa_squad-validation-2768", "mrqa_squad-validation-2780", "mrqa_squad-validation-2832", "mrqa_squad-validation-2888", "mrqa_squad-validation-3046", "mrqa_squad-validation-3138", "mrqa_squad-validation-3153", "mrqa_squad-validation-3197", "mrqa_squad-validation-3217", "mrqa_squad-validation-3223", "mrqa_squad-validation-3243", "mrqa_squad-validation-3326", "mrqa_squad-validation-3346", "mrqa_squad-validation-3363", "mrqa_squad-validation-3381", "mrqa_squad-validation-3415", "mrqa_squad-validation-3475", "mrqa_squad-validation-3497", "mrqa_squad-validation-3500", "mrqa_squad-validation-3551", "mrqa_squad-validation-3575", "mrqa_squad-validation-3633", "mrqa_squad-validation-3641", "mrqa_squad-validation-3683", "mrqa_squad-validation-3724", "mrqa_squad-validation-375", "mrqa_squad-validation-3752", "mrqa_squad-validation-3773", "mrqa_squad-validation-3922", "mrqa_squad-validation-3998", "mrqa_squad-validation-4110", "mrqa_squad-validation-4210", "mrqa_squad-validation-4226", "mrqa_squad-validation-4240", "mrqa_squad-validation-4256", "mrqa_squad-validation-4264", "mrqa_squad-validation-4294", "mrqa_squad-validation-4348", "mrqa_squad-validation-4357", "mrqa_squad-validation-4361", "mrqa_squad-validation-441", "mrqa_squad-validation-4458", "mrqa_squad-validation-4491", "mrqa_squad-validation-4595", "mrqa_squad-validation-4614", "mrqa_squad-validation-4631", "mrqa_squad-validation-4666", "mrqa_squad-validation-4729", "mrqa_squad-validation-4730", "mrqa_squad-validation-4795", "mrqa_squad-validation-4857", "mrqa_squad-validation-4870", "mrqa_squad-validation-4902", "mrqa_squad-validation-4921", "mrqa_squad-validation-4978", "mrqa_squad-validation-50", "mrqa_squad-validation-5098", "mrqa_squad-validation-510", "mrqa_squad-validation-5106", "mrqa_squad-validation-5112", "mrqa_squad-validation-5118", "mrqa_squad-validation-512", "mrqa_squad-validation-5167", "mrqa_squad-validation-5242", "mrqa_squad-validation-5303", "mrqa_squad-validation-5320", "mrqa_squad-validation-5344", "mrqa_squad-validation-5350", "mrqa_squad-validation-5363", "mrqa_squad-validation-5374", "mrqa_squad-validation-5389", "mrqa_squad-validation-5407", "mrqa_squad-validation-5590", "mrqa_squad-validation-5624", "mrqa_squad-validation-5714", "mrqa_squad-validation-5844", "mrqa_squad-validation-5859", "mrqa_squad-validation-5874", "mrqa_squad-validation-5889", "mrqa_squad-validation-5954", "mrqa_squad-validation-5958", "mrqa_squad-validation-6015", "mrqa_squad-validation-6025", "mrqa_squad-validation-6072", "mrqa_squad-validation-6074", "mrqa_squad-validation-6181", "mrqa_squad-validation-6196", "mrqa_squad-validation-6244", "mrqa_squad-validation-6284", "mrqa_squad-validation-6361", "mrqa_squad-validation-6373", "mrqa_squad-validation-6393", "mrqa_squad-validation-6394", "mrqa_squad-validation-6511", "mrqa_squad-validation-6512", "mrqa_squad-validation-6518", "mrqa_squad-validation-6645", "mrqa_squad-validation-6658", "mrqa_squad-validation-6690", "mrqa_squad-validation-6728", "mrqa_squad-validation-6753", "mrqa_squad-validation-6791", "mrqa_squad-validation-680", "mrqa_squad-validation-687", "mrqa_squad-validation-6873", "mrqa_squad-validation-6920", "mrqa_squad-validation-70", "mrqa_squad-validation-7011", "mrqa_squad-validation-7013", "mrqa_squad-validation-7068", "mrqa_squad-validation-7082", "mrqa_squad-validation-7082", "mrqa_squad-validation-7083", "mrqa_squad-validation-7112", "mrqa_squad-validation-7153", "mrqa_squad-validation-7206", "mrqa_squad-validation-7207", "mrqa_squad-validation-7209", "mrqa_squad-validation-7230", "mrqa_squad-validation-7303", "mrqa_squad-validation-7311", "mrqa_squad-validation-7398", "mrqa_squad-validation-7430", "mrqa_squad-validation-7566", "mrqa_squad-validation-7646", "mrqa_squad-validation-7674", "mrqa_squad-validation-7694", "mrqa_squad-validation-7765", "mrqa_squad-validation-7867", "mrqa_squad-validation-7887", "mrqa_squad-validation-7895", "mrqa_squad-validation-791", "mrqa_squad-validation-7918", "mrqa_squad-validation-7937", "mrqa_squad-validation-8135", "mrqa_squad-validation-8167", "mrqa_squad-validation-8190", "mrqa_squad-validation-8233", "mrqa_squad-validation-8243", "mrqa_squad-validation-8295", "mrqa_squad-validation-8312", "mrqa_squad-validation-8436", "mrqa_squad-validation-8452", "mrqa_squad-validation-8480", "mrqa_squad-validation-85", "mrqa_squad-validation-8516", "mrqa_squad-validation-8557", "mrqa_squad-validation-8596", "mrqa_squad-validation-8647", "mrqa_squad-validation-8662", "mrqa_squad-validation-8747", "mrqa_squad-validation-8900", "mrqa_squad-validation-8905", "mrqa_squad-validation-8910", "mrqa_squad-validation-9029", "mrqa_squad-validation-9085", "mrqa_squad-validation-9176", "mrqa_squad-validation-9304", "mrqa_squad-validation-9325", "mrqa_squad-validation-9334", "mrqa_squad-validation-9335", "mrqa_squad-validation-9345", "mrqa_squad-validation-9351", "mrqa_squad-validation-9371", "mrqa_squad-validation-9411", "mrqa_squad-validation-9484", "mrqa_squad-validation-9489", "mrqa_squad-validation-9512", "mrqa_squad-validation-9562", "mrqa_squad-validation-9565", "mrqa_squad-validation-9578", "mrqa_squad-validation-958", "mrqa_squad-validation-9614", "mrqa_squad-validation-9619", "mrqa_squad-validation-964", "mrqa_squad-validation-9750", "mrqa_squad-validation-9761", "mrqa_squad-validation-9892", "mrqa_squad-validation-9895", "mrqa_squad-validation-9895", "mrqa_squad-validation-99", "mrqa_squad-validation-9999", "mrqa_triviaqa-validation-1064", "mrqa_triviaqa-validation-1088", "mrqa_triviaqa-validation-1114", "mrqa_triviaqa-validation-1206", "mrqa_triviaqa-validation-1320", "mrqa_triviaqa-validation-134", "mrqa_triviaqa-validation-146", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-1747", "mrqa_triviaqa-validation-1771", "mrqa_triviaqa-validation-179", "mrqa_triviaqa-validation-1827", "mrqa_triviaqa-validation-1849", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-1965", "mrqa_triviaqa-validation-2030", "mrqa_triviaqa-validation-2054", "mrqa_triviaqa-validation-2080", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-2335", "mrqa_triviaqa-validation-2344", "mrqa_triviaqa-validation-2357", "mrqa_triviaqa-validation-2523", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-270", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-3133", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3192", "mrqa_triviaqa-validation-3473", "mrqa_triviaqa-validation-3606", "mrqa_triviaqa-validation-3751", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-4379", "mrqa_triviaqa-validation-4426", "mrqa_triviaqa-validation-4583", "mrqa_triviaqa-validation-4611", "mrqa_triviaqa-validation-4705", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-4944", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5336", "mrqa_triviaqa-validation-5495", "mrqa_triviaqa-validation-552", "mrqa_triviaqa-validation-5560", "mrqa_triviaqa-validation-5948", "mrqa_triviaqa-validation-5978", "mrqa_triviaqa-validation-6136", "mrqa_triviaqa-validation-632", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-6643", "mrqa_triviaqa-validation-6761", "mrqa_triviaqa-validation-6847", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-7060", "mrqa_triviaqa-validation-7067", "mrqa_triviaqa-validation-708", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-7470", "mrqa_triviaqa-validation-7595", "mrqa_triviaqa-validation-7742"], "OKR": 0.90625, "KG": 0.478125, "before_eval_results": {"predictions": ["dendritic cells, keratinocytes and macrophages", "Roone Arledge", "Muslims in the semu class", "The John W. Weeks Bridge", "9th", "inside hospitals and clinics", "US$3 per barrel", "Trajan's Column", "the Mascarenhas Archipelago", "Victoria Rowell", "Golda Meyerson", "xerophyte", "anions", "Uranus", "George III", "Mike Danger", "Iolani Palace", "Gandalf", "Mungo Park", "squash", "Bill Pertwee", "magnetite", "Sam Mendes", "Ciudad Ju\u00e1rez", "Emeril Lagasse", "shine", "Karl Marx", "an ornamental figure or illustration", "four and a half hours", "norway", "Jamaica", "Skylab", "Sydney", "Peter Purves", "Boreas", "Baffin Island", "Dumbo", "Dickens", "Botany Bay", "The English Football League", "FC Porto", "absolute visual magnitude", "11 years and 302 days", "California", "red", "supernova", "Brainy", "Andrew Nicholson", "Duke Francis of Teck", "Algeria", "Spain", "Daniel Boaventura", "gin", "Dennis C. Stewart", "1966", "guitar feedback", "The LA Galaxy", "an 88-year-old white supremacists", "Veracruz, Mexico", "tantalus", "Simon & Garfunkel", "Alan Graham", "2009", "Robert Kimmitt"], "metric_results": {"EM": 0.578125, "QA-F1": 0.625}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3635", "mrqa_triviaqa-validation-5857", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-554", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-7360", "mrqa_triviaqa-validation-1566", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2408", "mrqa_triviaqa-validation-3025", "mrqa_triviaqa-validation-5603", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-2883", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-6939", "mrqa_triviaqa-validation-1817", "mrqa_triviaqa-validation-1904", "mrqa_triviaqa-validation-7210", "mrqa_naturalquestions-validation-1008", "mrqa_newsqa-validation-2939", "mrqa_newsqa-validation-3091"], "SR": 0.578125, "CSR": 0.59375, "retrieved_ids": ["mrqa_squad-train-33570", "mrqa_squad-train-66972", "mrqa_squad-train-79027", "mrqa_squad-train-79402", "mrqa_squad-train-35845", "mrqa_squad-train-61601", "mrqa_squad-train-69228", "mrqa_squad-train-44510", "mrqa_squad-train-59488", "mrqa_squad-train-48190", "mrqa_squad-train-56743", "mrqa_squad-train-7777", "mrqa_squad-train-66965", "mrqa_squad-train-62667", "mrqa_squad-train-12951", "mrqa_squad-train-45593", "mrqa_squad-train-61137", "mrqa_squad-train-56801", "mrqa_squad-train-20965", "mrqa_squad-train-38630", "mrqa_squad-train-2770", "mrqa_squad-train-54312", "mrqa_squad-train-20202", "mrqa_squad-train-42026", "mrqa_squad-train-55166", "mrqa_squad-train-17406", "mrqa_squad-train-43628", "mrqa_squad-train-62743", "mrqa_squad-train-10877", "mrqa_squad-train-55810", "mrqa_squad-train-56293", "mrqa_squad-train-61338", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-146", "mrqa_searchqa-validation-4068", "mrqa_hotpotqa-validation-4436", "mrqa_searchqa-validation-456", "mrqa_searchqa-validation-14471", "mrqa_naturalquestions-validation-3930", "mrqa_searchqa-validation-10093", "mrqa_searchqa-validation-2783", "mrqa_squad-validation-6753", "mrqa_squad-validation-1116", "mrqa_triviaqa-validation-2147", "mrqa_newsqa-validation-1664", "mrqa_hotpotqa-validation-80", "mrqa_hotpotqa-validation-149", "mrqa_hotpotqa-validation-5174", "mrqa_squad-validation-1272", "mrqa_squad-validation-3497", "mrqa_squad-validation-9029", "mrqa_squad-validation-6044", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-5591", "mrqa_searchqa-validation-6666", "mrqa_searchqa-validation-4509", "mrqa_squad-validation-1234", "mrqa_searchqa-validation-15560", "mrqa_squad-validation-10386", "mrqa_squad-validation-9304", "mrqa_naturalquestions-validation-8412", "mrqa_searchqa-validation-15315", "mrqa_hotpotqa-validation-5101", "mrqa_squad-validation-2145"], "EFR": 1.0, "Overall": 0.7503124999999999}, {"timecode": 21, "before_eval_results": {"predictions": ["1349", "the center of mass", "July 23, 1963", "very rare", "James E. Webb", "eight", "foreclosure", "Adobe Flash CS3 Professional", "February 6, 2005", "development of electronic computers", "159", "a virtual reality simulator", "Andhra Pradesh and Odisha", "1975", "John Vincent Calipari", "winter solstice", "Billie Jean King", "Robert Hooke", "rocks and minerals", "October 2, 2017", "to avoid the inconvenienceiences of a pure barter system", "four", "Philadelphia", "Lykan", "in the pachytene stage of prophase I of meiosis", "Baltimore -- Washington metropolitan area", "Once Upon a Time in India", "Hank J. Deutschendorf II", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "Bill Condon", "moral tale", "May 5, 1904", "Albert Einstein", "March 21, 2016", "1992", "restored to life", "Master Christopher Jones", "solve its problem of lack of food self - sufficiency", "Bud '' Bergstein", "Portuguese version of this surname is Tavares", "in the bloodstream or surrounding tissue following surgery, disease, or trauma", "sexton Robert Newman and Captain John Pulling", "Fox Ranch in Malibu Creek State Park", "Gibraltar", "Dmitri Mendeleev", "`` Colonel '' Edward House, who was sent on many top - level missions", "31", "the disputed 1824 presidential election", "12", "local organization of businesses whose goal is to further the interests of businesses", "for providing telecommunication services to enterprises and offices", "twelve", "Paige O'Hara", "ghee", "\"The Crow\"", "Marigold Newey", "micronutrient-rich", "george iv", "top designers", "Heathrow", "gold", "h2g2", "george iv", "liver"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5969206814497441}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.11764705882352941, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.6666666666666666, 0.7058823529411764, 0.0, 1.0, 0.6666666666666666, 0.7368421052631579, 0.8571428571428571, 0.625, 1.0, 0.4615384615384615, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.08695652173913043, 0.0, 0.0, 0.0, 0.9333333333333333, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.125, 0.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1449", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-5133", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-5961", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-3429", "mrqa_naturalquestions-validation-10273", "mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-3199", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-6052", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4874", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-9650", "mrqa_naturalquestions-validation-2635", "mrqa_hotpotqa-validation-4181", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-3054", "mrqa_searchqa-validation-7212", "mrqa_triviaqa-validation-5476", "mrqa_triviaqa-validation-4182"], "SR": 0.46875, "CSR": 0.5880681818181819, "retrieved_ids": ["mrqa_squad-train-66612", "mrqa_squad-train-81141", "mrqa_squad-train-9794", "mrqa_squad-train-50685", "mrqa_squad-train-4472", "mrqa_squad-train-78697", "mrqa_squad-train-23077", "mrqa_squad-train-70524", "mrqa_squad-train-28331", "mrqa_squad-train-58182", "mrqa_squad-train-52657", "mrqa_squad-train-42861", "mrqa_squad-train-74205", "mrqa_squad-train-57967", "mrqa_squad-train-28450", "mrqa_squad-train-45629", "mrqa_squad-train-8868", "mrqa_squad-train-18603", "mrqa_squad-train-29658", "mrqa_squad-train-45813", "mrqa_squad-train-63920", "mrqa_squad-train-1599", "mrqa_squad-train-16922", "mrqa_squad-train-22114", "mrqa_squad-train-27143", "mrqa_squad-train-70962", "mrqa_squad-train-73313", "mrqa_squad-train-42077", "mrqa_squad-train-72150", "mrqa_squad-train-14979", "mrqa_squad-train-42899", "mrqa_squad-train-56099", "mrqa_hotpotqa-validation-4436", "mrqa_searchqa-validation-14512", "mrqa_squad-validation-512", "mrqa_searchqa-validation-8139", "mrqa_squad-validation-9489", "mrqa_triviaqa-validation-6783", "mrqa_searchqa-validation-14502", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-9557", "mrqa_triviaqa-validation-1360", "mrqa_searchqa-validation-583", "mrqa_squad-validation-6449", "mrqa_squad-validation-1116", "mrqa_searchqa-validation-3485", "mrqa_naturalquestions-validation-3942", "mrqa_triviaqa-validation-162", "mrqa_searchqa-validation-14514", "mrqa_searchqa-validation-10060", "mrqa_triviaqa-validation-873", "mrqa_triviaqa-validation-1441", "mrqa_naturalquestions-validation-9871", "mrqa_searchqa-validation-2337", "mrqa_naturalquestions-validation-4803", "mrqa_searchqa-validation-6712", "mrqa_searchqa-validation-4068", "mrqa_searchqa-validation-2115", "mrqa_squad-validation-6324", "mrqa_hotpotqa-validation-4273", "mrqa_searchqa-validation-5070", "mrqa_triviaqa-validation-7387", "mrqa_squad-validation-6773", "mrqa_triviaqa-validation-3131"], "EFR": 0.9705882352941176, "Overall": 0.7432937834224599}, {"timecode": 22, "before_eval_results": {"predictions": ["machine labor", "an intuitive understanding", "evenly round the body", "2,869 young people between the ages of 18 and 24", "president of NBC's entertainment division", "the Wesel-Datteln Canal", "Melanie Griffith", "fowls", "lexicographer", "Islamic Republic", "One Flew Over the Cuckoo's Nest", "red", "Anne of Cleves", "Harpers Ferry", "cha da tarde", "the Nun's Priest's Tale", "Versailles", "Target", "grasshopper", "Russia", "\"Tom Terrific\"", "magnesium", "\"The Swamp Fox\"", "the Union", "German Shepherd", "peanuts", "Sikkim", "Parker House", "Damascus", "the Jennies", "a laser light", "Thomas Gibson", "the 1906 earthquake", "war", "North Carolina", "Virginia Woolf", "apogee", "Cherry Garcia", "in his magic books", "Diamond Jim Brady", "axiom", "Princeton", "Eric Knight", "Apple", "The Sound of Music", "Pygmalion", "T. S. Eliot", "Asia", "Emerald", "asteroids", "the Nutcracker", "a large earthquake", "Conservative Party", "1996", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie )", "The Merry Wives of Windsor", "redheaded", "Republican", "Wojek (bear)", "Bangor Air National Guard Base", "2009", "cancer", "12-hour-plus", "start a dialogue of peace"], "metric_results": {"EM": 0.5625, "QA-F1": 0.62890625}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2194", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-14583", "mrqa_searchqa-validation-3243", "mrqa_searchqa-validation-8691", "mrqa_searchqa-validation-13527", "mrqa_searchqa-validation-2162", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-12151", "mrqa_searchqa-validation-9255", "mrqa_searchqa-validation-9788", "mrqa_searchqa-validation-6349", "mrqa_searchqa-validation-1565", "mrqa_searchqa-validation-9123", "mrqa_searchqa-validation-4038", "mrqa_searchqa-validation-9368", "mrqa_searchqa-validation-457", "mrqa_searchqa-validation-7828", "mrqa_searchqa-validation-9991", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-4236", "mrqa_naturalquestions-validation-10625", "mrqa_hotpotqa-validation-1856", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-403"], "SR": 0.5625, "CSR": 0.5869565217391304, "retrieved_ids": ["mrqa_squad-train-26131", "mrqa_squad-train-6612", "mrqa_squad-train-22831", "mrqa_squad-train-22104", "mrqa_squad-train-68540", "mrqa_squad-train-42121", "mrqa_squad-train-22265", "mrqa_squad-train-72790", "mrqa_squad-train-74147", "mrqa_squad-train-61670", "mrqa_squad-train-54475", "mrqa_squad-train-66994", "mrqa_squad-train-33837", "mrqa_squad-train-66709", "mrqa_squad-train-22155", "mrqa_squad-train-20139", "mrqa_squad-train-3324", "mrqa_squad-train-3049", "mrqa_squad-train-61659", "mrqa_squad-train-22150", "mrqa_squad-train-52074", "mrqa_squad-train-65376", "mrqa_squad-train-19128", "mrqa_squad-train-6888", "mrqa_squad-train-85821", "mrqa_squad-train-68550", "mrqa_squad-train-17430", "mrqa_squad-train-76105", "mrqa_squad-train-46943", "mrqa_squad-train-73926", "mrqa_squad-train-43727", "mrqa_squad-train-28230", "mrqa_squad-validation-8900", "mrqa_searchqa-validation-12316", "mrqa_newsqa-validation-1114", "mrqa_triviaqa-validation-7060", "mrqa_searchqa-validation-7322", "mrqa_squad-validation-964", "mrqa_squad-validation-6753", "mrqa_triviaqa-validation-5476", "mrqa_naturalquestions-validation-5133", "mrqa_hotpotqa-validation-2985", "mrqa_squad-validation-809", "mrqa_searchqa-validation-679", "mrqa_newsqa-validation-2525", "mrqa_squad-validation-1308", "mrqa_triviaqa-validation-1686", "mrqa_squad-validation-9764", "mrqa_squad-validation-10386", "mrqa_searchqa-validation-5613", "mrqa_squad-validation-8295", "mrqa_squad-validation-4631", "mrqa_searchqa-validation-348", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2883", "mrqa_squad-validation-4260", "mrqa_searchqa-validation-11392", "mrqa_searchqa-validation-8607", "mrqa_triviaqa-validation-3133", "mrqa_squad-validation-9176", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-7067", "mrqa_hotpotqa-validation-4166", "mrqa_searchqa-validation-5574"], "EFR": 1.0, "Overall": 0.7489538043478261}, {"timecode": 23, "before_eval_results": {"predictions": ["Department for Culture, Media and Sport", "Kevin Harlan", "Khongirad", "Solim\u00f5es Basin", "49\u201315", "the 21st century", "Mombasa, Kenya", "(the Democratic VP candidate", "27 Awa", "top designers", "very proud", "the body of the aircraft", "intricate Flemish tapestries", "the United States", "Michigan", "in Iraq", "Two", "Russia", "The Tinkler", "$106,482,500", "Tuesday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "misdemeanor", "three out of four", "tennis", "Disney", "Christmas", "90", "directly involved in an Internet broadband deal with a Chinese firm", "$279", "free laundry service", "Doral", "Jeffrey Jamaleldine", "insurgent small arms fire", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East", "1.2 million people", "the former Massachusetts governor", "Citizens", "healing and \"the blessing of your voice, your chaste touch.\"", "near Grand Ronde, Oregon", "Seasons of My Heart", "robbery and robbery", "150", "Anil Kapoor", "misdemeanor assault charges", "Pope reiterated the Vatican's policy on condom use", "people thought this was a small problem", "martin aloysius Culhane", "sustainability", "Kenyan", "more use of nuclear, wind and solar power", "motor bike accident", "the Isthmus of Corinth", "Dave Tozer", "Old Trafford", "nirvana", "Bobbi Kristina Brown", "Shayne Ward", "Christina Ricci", "Floyd Nathaniel \"Nate\" Hills", "January", "Dredge", "the midnight ride", "emerald"], "metric_results": {"EM": 0.40625, "QA-F1": 0.529378434065934}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-233", "mrqa_squad-validation-4356", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2635", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3021", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2934", "mrqa_newsqa-validation-3784", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3897", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-3085", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-1271", "mrqa_newsqa-validation-1665", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-2791", "mrqa_newsqa-validation-2418", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-2748", "mrqa_newsqa-validation-2167", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-8272", "mrqa_triviaqa-validation-4569", "mrqa_triviaqa-validation-2919", "mrqa_hotpotqa-validation-3787", "mrqa_hotpotqa-validation-5469", "mrqa_searchqa-validation-11024", "mrqa_searchqa-validation-12527"], "SR": 0.40625, "CSR": 0.5794270833333333, "retrieved_ids": ["mrqa_squad-train-54619", "mrqa_squad-train-3567", "mrqa_squad-train-1228", "mrqa_squad-train-64764", "mrqa_squad-train-79151", "mrqa_squad-train-47641", "mrqa_squad-train-83871", "mrqa_squad-train-45000", "mrqa_squad-train-24386", "mrqa_squad-train-11761", "mrqa_squad-train-73218", "mrqa_squad-train-81638", "mrqa_squad-train-9429", "mrqa_squad-train-27573", "mrqa_squad-train-507", "mrqa_squad-train-59368", "mrqa_squad-train-61722", "mrqa_squad-train-70238", "mrqa_squad-train-60860", "mrqa_squad-train-47397", "mrqa_squad-train-25506", "mrqa_squad-train-24947", "mrqa_squad-train-67123", "mrqa_squad-train-68184", "mrqa_squad-train-16925", "mrqa_squad-train-65588", "mrqa_squad-train-3207", "mrqa_squad-train-9674", "mrqa_squad-train-82599", "mrqa_squad-train-61120", "mrqa_squad-train-6011", "mrqa_squad-train-27047", "mrqa_triviaqa-validation-5336", "mrqa_squad-validation-805", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-7595", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-3473", "mrqa_squad-validation-2717", "mrqa_squad-validation-6113", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-577", "mrqa_naturalquestions-validation-9741", "mrqa_squad-validation-9334", "mrqa_triviaqa-validation-2989", "mrqa_triviaqa-validation-1088", "mrqa_naturalquestions-validation-1008", "mrqa_squad-validation-512", "mrqa_squad-validation-3998", "mrqa_squad-validation-3692", "mrqa_triviaqa-validation-1603", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-6979", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-5251", "mrqa_searchqa-validation-6900", "mrqa_triviaqa-validation-6783", "mrqa_naturalquestions-validation-5036", "mrqa_searchqa-validation-11216", "mrqa_hotpotqa-validation-1657", "mrqa_searchqa-validation-13110", "mrqa_searchqa-validation-8691", "mrqa_naturalquestions-validation-392"], "EFR": 1.0, "Overall": 0.7474479166666665}, {"timecode": 24, "before_eval_results": {"predictions": ["John Harvard", "1886", "the AKS primality test", "Command Module design, workmanship and quality control", "Gold footballs", "1967", "Dunlop", "XVideos", "Niger\u2013Congo", "Sports Illustrated", "Robert A. Iger", "Regional League North", "The 2002 United States Senate election in Minnesota", "Harsh Times", "Fade Out: The Calamitous Final Days of MGM", "Restoration Hardware", "Louis Silvie \"Louie\" Zamperini", "Taipei City", "Minneapolis, Minnesota", "Idisi", "Ambroise Thomas", "Hans Rosenfeldt", "May 4, 2004", "Everything Is wrong", "Captain", "Smoothie King Center", "Martin Scorsese", "Viacom Media Networks", "1853", "imp My Ride", "Columbia Records", "Umar S. Israilov", "Derry City F.C.", "Fort Hood, Texas", "Port Macquarie", "London", "1999", "2006", "scorer", "Zero Mostel", "October 13, 1980", "the Chechen Republic", "House of Commons", "1926", "Nikolai Morozov", "1968", "Berthold Heinrich K\u00e4mpfert", "Girl Meets World", "January 15, 1975", "Pansexuality", "Javan leopard", "2,463,431", "Acts of the Apostles", "Father Christmas", "Pyeongchang County, South Korea", "Celts", "Rudolph", "Chechnya", "Aryan Airlines Flight 1625", "Sen. Barack Obama", "her son has strong values.", "Jay Gillespie", "Glinda", "Hormuz"], "metric_results": {"EM": 0.609375, "QA-F1": 0.703383901637578}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.8235294117647058, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.7692307692307693, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3930", "mrqa_hotpotqa-validation-2553", "mrqa_hotpotqa-validation-1247", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-4084", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-1416", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-1457", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-943", "mrqa_hotpotqa-validation-4038", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-4818", "mrqa_naturalquestions-validation-2990", "mrqa_naturalquestions-validation-3016", "mrqa_triviaqa-validation-7434", "mrqa_newsqa-validation-1837", "mrqa_newsqa-validation-1892", "mrqa_searchqa-validation-4914", "mrqa_searchqa-validation-8010"], "SR": 0.609375, "CSR": 0.580625, "retrieved_ids": ["mrqa_squad-train-73987", "mrqa_squad-train-52035", "mrqa_squad-train-27956", "mrqa_squad-train-16882", "mrqa_squad-train-69389", "mrqa_squad-train-46928", "mrqa_squad-train-55480", "mrqa_squad-train-81123", "mrqa_squad-train-76824", "mrqa_squad-train-12413", "mrqa_squad-train-61840", "mrqa_squad-train-63759", "mrqa_squad-train-8666", "mrqa_squad-train-61426", "mrqa_squad-train-34829", "mrqa_squad-train-16612", "mrqa_squad-train-51375", "mrqa_squad-train-76768", "mrqa_squad-train-83987", "mrqa_squad-train-34144", "mrqa_squad-train-45234", "mrqa_squad-train-31744", "mrqa_squad-train-63782", "mrqa_squad-train-43450", "mrqa_squad-train-28896", "mrqa_squad-train-26227", "mrqa_squad-train-6716", "mrqa_squad-train-20812", "mrqa_squad-train-63443", "mrqa_squad-train-78368", "mrqa_squad-train-19570", "mrqa_squad-train-40861", "mrqa_searchqa-validation-6349", "mrqa_searchqa-validation-14583", "mrqa_squad-validation-964", "mrqa_naturalquestions-validation-75", "mrqa_searchqa-validation-14572", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8619", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-349", "mrqa_squad-validation-2657", "mrqa_hotpotqa-validation-80", "mrqa_searchqa-validation-7109", "mrqa_squad-validation-3374", "mrqa_searchqa-validation-455", "mrqa_squad-validation-1272", "mrqa_triviaqa-validation-4705", "mrqa_searchqa-validation-8449", "mrqa_squad-validation-5", "mrqa_hotpotqa-validation-2425", "mrqa_naturalquestions-validation-1165", "mrqa_searchqa-validation-11651", "mrqa_searchqa-validation-6712", "mrqa_squad-validation-4902", "mrqa_hotpotqa-validation-4436", "mrqa_triviaqa-validation-7349", "mrqa_hotpotqa-validation-3833", "mrqa_hotpotqa-validation-2985", "mrqa_triviaqa-validation-7742", "mrqa_squad-validation-6091", "mrqa_hotpotqa-validation-996", "mrqa_squad-validation-6753", "mrqa_searchqa-validation-7739"], "EFR": 1.0, "Overall": 0.7476875}, {"timecode": 25, "before_eval_results": {"predictions": ["1894", "Effective teachers", "a pointless pursuit", "warning the operators, who may then manually suppress the fire", "Northern Rail", "South Korea", "paralysis", "golf", "Romania", "Pocahontas", "Matlock", "Washington", "Argentina", "The Blue Boy", "Three Worlds", "Liriope", "the Egyptian Goddess of Creation", "Pennsylvania", "Pyrenees", "(See Important Quotations Explained )", "Dutch", "Salem witch trials", "Gryffindor", "Allardyce", "Olympics", "Nick Hancock", "Edward Yorke", "keeper of the Longstone (Fame Islands) lighthouse", "Sean \"Puff Daddy\" Combs", "Superman: The Movie", "Richard Walter Jenkins", "Burkina Faso", "Billy Cox", "Javier Bardem", "Independence Day", "baryons", "Jordan", "So Solid Crew", "Richard Ripley", "(Magi)", "neptune", "(Hons)", "Common Ash", "Ian Botham", "squash", "Leander Club", "Sir Stirling Craufurd Moss", "E. B. White's Charlotte's Web", "Poland", "Lingerie Football League", "Mexico", "Jesus", "Authority", "1 mile ( 1.6 km )", "Steve Valentine", "\"Power Rangers Zeo\" and Hal Stewart in \" Masked Rider\"", "Virgin", "UFC Fight Pass", "the Airbus A330-200", "fill a million sandbags and place 700,000 around our city", "75 percent of utilities had taken steps to mitigate the Aurora vulnerability", "percipient", "amelia earhart", "Final Cut Pro"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6640625}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, false, true, true, true, true, true, false, false, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.5, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-2098", "mrqa_squad-validation-3207", "mrqa_triviaqa-validation-2266", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-7062", "mrqa_triviaqa-validation-610", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-6445", "mrqa_triviaqa-validation-3102", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1475", "mrqa_triviaqa-validation-7460", "mrqa_triviaqa-validation-39", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-5101", "mrqa_triviaqa-validation-6537", "mrqa_triviaqa-validation-305", "mrqa_triviaqa-validation-3924", "mrqa_triviaqa-validation-5009", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-3201", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-4836", "mrqa_hotpotqa-validation-5822", "mrqa_searchqa-validation-8379", "mrqa_searchqa-validation-5324"], "SR": 0.578125, "CSR": 0.5805288461538461, "retrieved_ids": ["mrqa_squad-train-72453", "mrqa_squad-train-70663", "mrqa_squad-train-61269", "mrqa_squad-train-83543", "mrqa_squad-train-8627", "mrqa_squad-train-79476", "mrqa_squad-train-25350", "mrqa_squad-train-85626", "mrqa_squad-train-42743", "mrqa_squad-train-32095", "mrqa_squad-train-47813", "mrqa_squad-train-56192", "mrqa_squad-train-46982", "mrqa_squad-train-32865", "mrqa_squad-train-26515", "mrqa_squad-train-40372", "mrqa_squad-train-11127", "mrqa_squad-train-38304", "mrqa_squad-train-45806", "mrqa_squad-train-43850", "mrqa_squad-train-60754", "mrqa_squad-train-75518", "mrqa_squad-train-5318", "mrqa_squad-train-20551", "mrqa_squad-train-70987", "mrqa_squad-train-5961", "mrqa_squad-train-60597", "mrqa_squad-train-49317", "mrqa_squad-train-51764", "mrqa_squad-train-33654", "mrqa_squad-train-59616", "mrqa_squad-train-62283", "mrqa_triviaqa-validation-1603", "mrqa_squad-validation-6680", "mrqa_triviaqa-validation-6413", "mrqa_naturalquestions-validation-1165", "mrqa_squad-validation-525", "mrqa_newsqa-validation-2791", "mrqa_hotpotqa-validation-4181", "mrqa_squad-validation-9176", "mrqa_triviaqa-validation-1360", "mrqa_searchqa-validation-10063", "mrqa_squad-validation-7430", "mrqa_naturalquestions-validation-10273", "mrqa_searchqa-validation-8691", "mrqa_naturalquestions-validation-6052", "mrqa_newsqa-validation-2934", "mrqa_hotpotqa-validation-3937", "mrqa_squad-validation-806", "mrqa_searchqa-validation-6726", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-2357", "mrqa_newsqa-validation-2790", "mrqa_searchqa-validation-9769", "mrqa_hotpotqa-validation-3821", "mrqa_triviaqa-validation-3215", "mrqa_hotpotqa-validation-4002", "mrqa_naturalquestions-validation-4874", "mrqa_hotpotqa-validation-1893", "mrqa_squad-validation-3497", "mrqa_hotpotqa-validation-171", "mrqa_searchqa-validation-6931", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-149"], "EFR": 1.0, "Overall": 0.7476682692307692}, {"timecode": 26, "before_eval_results": {"predictions": ["at the narrow end", "Levi's Stadium", "specific catechism questions", "a 12th/13th-century nobleman", "the disk", "2016", "the Islamic prophet Muhammad", "Mel Tillis", "Pangaea or Pangea", "Stephen Lang", "2018", "Erika Mitchell Leonard", "eight years", "Edd Kimber", "The Jewel of the Nile", "Orange Juice", "photoelectric", "September 9, 2010", "Jesse Frederick James Conaway", "an even - toed ungulate", "Dan Stevens", "Jackie Van Beek", "`` Darkspawn ''", "1979", "October 27, 2016", "Authority", "spiritual gifts originating from patristic authors", "Luther Ingram", "Jodie Foster", "Barry Watson", "Sanchez Navarro", "faster than the rate of economic growth", "1997", "British Columbia, Canada", "New York University", "2007", "2001", "Washington Redskins", "the books of Exodus and Deuteronomy", "September 14, 2008", "the federal government", "Pasek & Paul", "Chicago metropolitan area", "Francisco Pizarro", "1940", "Norman", "Mary Rose Foster", "John Smith", "The eighth and final season", "1623", "neutrality", "he cheated on Miley", "banjo", "anabaptists", "The Rocky and Bullwinkle", "Taylor Alison Swift", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Michael Crawford", "$22 million", "14-day", "flooding", "Angostura", "David", "fiscal"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6459794494720965}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, false, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.375, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.8, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6637", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-3499", "mrqa_naturalquestions-validation-6378", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-6612", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1728", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-2837", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-6998", "mrqa_naturalquestions-validation-6514", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-7650", "mrqa_triviaqa-validation-3954", "mrqa_triviaqa-validation-7563", "mrqa_hotpotqa-validation-4567", "mrqa_hotpotqa-validation-511", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-1236"], "SR": 0.5625, "CSR": 0.5798611111111112, "retrieved_ids": ["mrqa_squad-train-41013", "mrqa_squad-train-53266", "mrqa_squad-train-21493", "mrqa_squad-train-63124", "mrqa_squad-train-42051", "mrqa_squad-train-18032", "mrqa_squad-train-84939", "mrqa_squad-train-31500", "mrqa_squad-train-18013", "mrqa_squad-train-66676", "mrqa_squad-train-66220", "mrqa_squad-train-71635", "mrqa_squad-train-7075", "mrqa_squad-train-74912", "mrqa_squad-train-62570", "mrqa_squad-train-29399", "mrqa_squad-train-55915", "mrqa_squad-train-68438", "mrqa_squad-train-59496", "mrqa_squad-train-80561", "mrqa_squad-train-91", "mrqa_squad-train-82195", "mrqa_squad-train-80771", "mrqa_squad-train-36296", "mrqa_squad-train-58161", "mrqa_squad-train-68124", "mrqa_squad-train-37512", "mrqa_squad-train-83344", "mrqa_squad-train-48162", "mrqa_squad-train-24055", "mrqa_squad-train-17339", "mrqa_squad-train-57026", "mrqa_triviaqa-validation-1561", "mrqa_searchqa-validation-5916", "mrqa_squad-validation-5545", "mrqa_triviaqa-validation-6002", "mrqa_squad-validation-1572", "mrqa_squad-validation-85", "mrqa_naturalquestions-validation-9323", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-3075", "mrqa_squad-validation-512", "mrqa_squad-validation-2318", "mrqa_hotpotqa-validation-3408", "mrqa_searchqa-validation-6726", "mrqa_naturalquestions-validation-9650", "mrqa_searchqa-validation-11651", "mrqa_naturalquestions-validation-2572", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-9991", "mrqa_triviaqa-validation-6445", "mrqa_searchqa-validation-14453", "mrqa_naturalquestions-validation-801", "mrqa_searchqa-validation-621", "mrqa_squad-validation-7632", "mrqa_searchqa-validation-14583", "mrqa_newsqa-validation-3054", "mrqa_hotpotqa-validation-3180", "mrqa_naturalquestions-validation-10625", "mrqa_squad-validation-1708", "mrqa_searchqa-validation-16877", "mrqa_newsqa-validation-3085", "mrqa_searchqa-validation-9255", "mrqa_hotpotqa-validation-3807"], "EFR": 0.9642857142857143, "Overall": 0.740391865079365}, {"timecode": 27, "before_eval_results": {"predictions": ["multiple revisions", "mathematical models of computation", "BAFTA", "around 300", "an anvil", "1999", "Robert G. Durant", "her work on Charles Babbage's proposed mechanical general-purpose computer, the Analytical Engine", "London", "she is generally considered to have liberal political views", "Hanford Site", "Native American", "Mindy Kaling", "Alonso L\u00f3pez", "Blackstone", "Ginger Rogers", "U.S. Marshals", "churro", "Christies Beach", "Odisha", "Arsenal Football Club", "Don Bluth and Gary Goldman", "new, small and fast vessels such as torpedo boats and later submarines", "1969 until 1974", "skiing and mountaineering", "June 11, 1973", "January 18, 1977", "Protestant Christian", "defender", "Henry J. Kaiser", "Saoirse Ronan", "122,067", "Wandsworth, London", "YouTube", "Daniel Andre Sturridge", "USS Essex", "Ron Cowen and Daniel Lipman", "Isabella Hedgeland", "Captain while retaining the substantive rank of Commodore", "Giuseppe Verdi", "Tomasz Adamek", "Russell T Davies", "Geraldine Page", "Manchester", "3,000", "Umberto II", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan", "Daphnis et Chlo\u00e9", "saloon-keeper and Justice of the Peace", "John Lennon", "The Bad Hemingway Competition", "The Emperor of Japan", "Mary Rose Foster", "11 February 2012", "the pitches used may change and introduce a different scale", "gold", "Australia", "stroke", "denied the claim", "Amanda Knox's aunt", "there could be 100,000 snakes in the Everglades, but no one knows for sure.", "red", "With a Little Help from My Friends", "North Carolina"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5918087121212121}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.33333333333333337, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.14285714285714288, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7819", "mrqa_hotpotqa-validation-3943", "mrqa_hotpotqa-validation-4113", "mrqa_hotpotqa-validation-346", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-1767", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-2183", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-5770", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-2335", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-3187", "mrqa_hotpotqa-validation-1080", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-4961", "mrqa_hotpotqa-validation-4543", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-4497", "mrqa_triviaqa-validation-1818", "mrqa_triviaqa-validation-2192", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-3907", "mrqa_searchqa-validation-15555", "mrqa_searchqa-validation-9122"], "SR": 0.515625, "CSR": 0.5775669642857143, "retrieved_ids": ["mrqa_squad-train-18757", "mrqa_squad-train-74549", "mrqa_squad-train-23667", "mrqa_squad-train-27757", "mrqa_squad-train-51963", "mrqa_squad-train-21159", "mrqa_squad-train-43552", "mrqa_squad-train-34074", "mrqa_squad-train-14555", "mrqa_squad-train-82510", "mrqa_squad-train-49427", "mrqa_squad-train-45082", "mrqa_squad-train-3268", "mrqa_squad-train-49020", "mrqa_squad-train-9373", "mrqa_squad-train-65185", "mrqa_squad-train-1415", "mrqa_squad-train-15238", "mrqa_squad-train-13481", "mrqa_squad-train-13540", "mrqa_squad-train-18351", "mrqa_squad-train-73559", "mrqa_squad-train-23964", "mrqa_squad-train-27625", "mrqa_squad-train-57043", "mrqa_squad-train-84452", "mrqa_squad-train-14046", "mrqa_squad-train-78427", "mrqa_squad-train-32607", "mrqa_squad-train-32202", "mrqa_squad-train-69497", "mrqa_squad-train-20914", "mrqa_searchqa-validation-4933", "mrqa_squad-validation-8576", "mrqa_triviaqa-validation-4573", "mrqa_searchqa-validation-14307", "mrqa_searchqa-validation-2674", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-1817", "mrqa_searchqa-validation-9679", "mrqa_hotpotqa-validation-2732", "mrqa_squad-validation-9489", "mrqa_newsqa-validation-2635", "mrqa_hotpotqa-validation-3075", "mrqa_searchqa-validation-11216", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-7896", "mrqa_searchqa-validation-621", "mrqa_naturalquestions-validation-10114", "mrqa_squad-validation-7083", "mrqa_squad-validation-7430", "mrqa_triviaqa-validation-6643", "mrqa_naturalquestions-validation-10433", "mrqa_triviaqa-validation-3473", "mrqa_hotpotqa-validation-497", "mrqa_naturalquestions-validation-1325", "mrqa_hotpotqa-validation-3607", "mrqa_searchqa-validation-5574", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-2967", "mrqa_hotpotqa-validation-471", "mrqa_newsqa-validation-403", "mrqa_naturalquestions-validation-5447", "mrqa_searchqa-validation-6298"], "EFR": 1.0, "Overall": 0.7470758928571428}, {"timecode": 28, "before_eval_results": {"predictions": ["left foot", "the USSR", "flagellated", "Mildred", "Adidas", "Secretary of State Hillary Clinton", "billions of dollars", "one", "the Beatles", "Communist Party of Nepal", "Pope Benedict XVI", "around 8 p.m. local time", "Sri Lanka's Tamil rebels", "64", "CNN", "six months.", "A witness", "Adriano", "they've switched off our irrigation system, taken out keys and stop our trucks if we want to deliver maize", "183", "American Civil Liberties Union", "deployment of unmanned drones, including possibly the Predator drones used in Iraq and Afghanistan.", "six Pakistan soldiers", "Aldgate East", "137", "54-year-old", "Government Accountability Office report", "Jacob", "South Africa.", "the Markland Locks and Dam", "4,000", "Oaxaca City", "provided Syria and Iraq 500 cubic meters of water", "Catholic League", "August 19, 2007.", "10 years", "not guilty", "Japan", "her children \"have no problems about the school, they are happy about everything.\"", "consumer confidence", "he fired several rounds at the soldiers with the intent of killing them", "six", "nearly 28 years", "July 18, 1994.", "Dan Brown", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves", "Zubaydah had been waterboarded for \"about 30 seconds, 35 seconds\" and agreed to cooperate with interrogators the following day.", "central business district", "two", "antihistamine and an epinephrine", "400", "he discussed foreplay, sexual conquests and how he picks up women, all taboo subjects in deeply conservative Saudi Arabia.", "Jean F Kernel", "10 : 30am", "Johannes Gutenberg", "tide-wise", "Christian Wulff", "Ambroz Bajec-Lapajne", "general secretary", "the George Washington Bridge", "Highlands Course", "junk", "Aristotle's lantern", "albacore"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6399255418375485}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 0.5454545454545454, 1.0, 1.0, 0.4, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 0.9473684210526316, 1.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.5, 0.5, 0.9473684210526316, 0.0, 1.0, 0.8571428571428571, 0.0, 0.125, 0.4, 0.8, 1.0, 0.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8652", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-1314", "mrqa_newsqa-validation-960", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-274", "mrqa_newsqa-validation-3530", "mrqa_newsqa-validation-1443", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-892", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-198", "mrqa_newsqa-validation-3264", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3290", "mrqa_newsqa-validation-1131", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-3640", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-9007", "mrqa_triviaqa-validation-7076", "mrqa_triviaqa-validation-6923", "mrqa_hotpotqa-validation-435", "mrqa_searchqa-validation-2733", "mrqa_searchqa-validation-12506"], "SR": 0.453125, "CSR": 0.5732758620689655, "retrieved_ids": ["mrqa_squad-train-77007", "mrqa_squad-train-58849", "mrqa_squad-train-78381", "mrqa_squad-train-29802", "mrqa_squad-train-34058", "mrqa_squad-train-13198", "mrqa_squad-train-63041", "mrqa_squad-train-46950", "mrqa_squad-train-40405", "mrqa_squad-train-2984", "mrqa_squad-train-47143", "mrqa_squad-train-69241", "mrqa_squad-train-3618", "mrqa_squad-train-14516", "mrqa_squad-train-11050", "mrqa_squad-train-14708", "mrqa_squad-train-49771", "mrqa_squad-train-45992", "mrqa_squad-train-33118", "mrqa_squad-train-67876", "mrqa_squad-train-49598", "mrqa_squad-train-58066", "mrqa_squad-train-76100", "mrqa_squad-train-79355", "mrqa_squad-train-78637", "mrqa_squad-train-34700", "mrqa_squad-train-45495", "mrqa_squad-train-85935", "mrqa_squad-train-26325", "mrqa_squad-train-37615", "mrqa_squad-train-5246", "mrqa_squad-train-41783", "mrqa_naturalquestions-validation-5017", "mrqa_naturalquestions-validation-6998", "mrqa_searchqa-validation-5063", "mrqa_triviaqa-validation-4622", "mrqa_searchqa-validation-5060", "mrqa_triviaqa-validation-2266", "mrqa_searchqa-validation-4355", "mrqa_searchqa-validation-1565", "mrqa_triviaqa-validation-134", "mrqa_squad-validation-680", "mrqa_triviaqa-validation-6413", "mrqa_searchqa-validation-9679", "mrqa_triviaqa-validation-1938", "mrqa_naturalquestions-validation-7473", "mrqa_triviaqa-validation-308", "mrqa_squad-validation-9761", "mrqa_searchqa-validation-1523", "mrqa_triviaqa-validation-6259", "mrqa_hotpotqa-validation-5251", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-5460", "mrqa_hotpotqa-validation-2341", "mrqa_squad-validation-6913", "mrqa_searchqa-validation-12243", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-8254", "mrqa_newsqa-validation-1577", "mrqa_naturalquestions-validation-1165", "mrqa_squad-validation-233", "mrqa_squad-validation-3922", "mrqa_searchqa-validation-2783", "mrqa_triviaqa-validation-7563"], "EFR": 0.9714285714285714, "Overall": 0.7405033866995073}, {"timecode": 29, "before_eval_results": {"predictions": ["Cadeby", "Lorelei", "10,004,721", "lunch", "lovebird", "Chicago", "monk seal", "Prussia", "inqurere", "Take Me Out to the Ballgame", "an expression used in drinking a person's health", "Morse code", "New Zealand", "St. Erasmus", "Tommy Tucker", "H. G. Wells", "a Holstein cow", "illegible", "Scrabble", "Mussolini", "Valkyries", "rain", "shank", "Jodie Foster", "Elysian Fields", "Bobby' Dupea", "Thomas Edison", "Manhattan Project", "Charles I", "a divorce", "Enchanted", "the Liberty Bell", "USB", "Autobahn", "Destiny", "Lord Byron", "a robin", "corticosteroid", "Margot Fonteyn", "an eel", "Bones and Castle", "(Whizzer) White", "professor", "Galileo Galilei", "existentialism", "John Donne", "Beijing", "Annie", "human", "Charles Lindbergh", "a queen", "neurons", "the Holy See", "James W. Marshall", "a set of related data", "Brazil", "\"Slow\"", "Monster M*A*S*H", "Growler", "5249", "Fleetwood Mac", "around 3.5 percent of global greenhouse emissions.", "reading a novel", "HPV"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6214962121212121}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, false, true, false, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.7272727272727272, 0.0, 0.0, 1.0, 0.5, 0.8, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9015", "mrqa_searchqa-validation-10014", "mrqa_searchqa-validation-14849", "mrqa_searchqa-validation-6961", "mrqa_searchqa-validation-8331", "mrqa_searchqa-validation-685", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16889", "mrqa_searchqa-validation-2615", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-5788", "mrqa_searchqa-validation-7864", "mrqa_searchqa-validation-3122", "mrqa_searchqa-validation-5167", "mrqa_searchqa-validation-12715", "mrqa_searchqa-validation-10507", "mrqa_searchqa-validation-13377", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-6814", "mrqa_searchqa-validation-5715", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9472", "mrqa_searchqa-validation-15174", "mrqa_naturalquestions-validation-3048", "mrqa_naturalquestions-validation-2956", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-935", "mrqa_hotpotqa-validation-739", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-1372"], "SR": 0.515625, "CSR": 0.5713541666666666, "retrieved_ids": ["mrqa_squad-train-74904", "mrqa_squad-train-74789", "mrqa_squad-train-31741", "mrqa_squad-train-32321", "mrqa_squad-train-86125", "mrqa_squad-train-26068", "mrqa_squad-train-52668", "mrqa_squad-train-79186", "mrqa_squad-train-81617", "mrqa_squad-train-43348", "mrqa_squad-train-22413", "mrqa_squad-train-68984", "mrqa_squad-train-25402", "mrqa_squad-train-67724", "mrqa_squad-train-33900", "mrqa_squad-train-65626", "mrqa_squad-train-68536", "mrqa_squad-train-77644", "mrqa_squad-train-9894", "mrqa_squad-train-5386", "mrqa_squad-train-66549", "mrqa_squad-train-10643", "mrqa_squad-train-51496", "mrqa_squad-train-12092", "mrqa_squad-train-61083", "mrqa_squad-train-10292", "mrqa_squad-train-12698", "mrqa_squad-train-68129", "mrqa_squad-train-80556", "mrqa_squad-train-40756", "mrqa_squad-train-65719", "mrqa_squad-train-43819", "mrqa_naturalquestions-validation-10433", "mrqa_newsqa-validation-3167", "mrqa_naturalquestions-validation-8254", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-4885", "mrqa_hotpotqa-validation-3075", "mrqa_naturalquestions-validation-7468", "mrqa_triviaqa-validation-6643", "mrqa_searchqa-validation-14514", "mrqa_triviaqa-validation-6537", "mrqa_hotpotqa-validation-5251", "mrqa_newsqa-validation-858", "mrqa_hotpotqa-validation-2237", "mrqa_searchqa-validation-3243", "mrqa_squad-validation-1312", "mrqa_hotpotqa-validation-462", "mrqa_squad-validation-9304", "mrqa_triviaqa-validation-2056", "mrqa_searchqa-validation-4533", "mrqa_searchqa-validation-457", "mrqa_searchqa-validation-14583", "mrqa_squad-validation-7457", "mrqa_searchqa-validation-12243", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-9250", "mrqa_naturalquestions-validation-677", "mrqa_searchqa-validation-8449", "mrqa_hotpotqa-validation-3937", "mrqa_triviaqa-validation-6847", "mrqa_squad-validation-3192", "mrqa_squad-validation-1251", "mrqa_triviaqa-validation-2883"], "EFR": 1.0, "Overall": 0.7458333333333333}, {"timecode": 30, "UKR": 0.7890625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1080", "mrqa_hotpotqa-validation-1247", "mrqa_hotpotqa-validation-1263", "mrqa_hotpotqa-validation-1323", "mrqa_hotpotqa-validation-1361", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-1687", "mrqa_hotpotqa-validation-1906", "mrqa_hotpotqa-validation-2020", "mrqa_hotpotqa-validation-2064", "mrqa_hotpotqa-validation-208", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2122", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-2183", "mrqa_hotpotqa-validation-2222", "mrqa_hotpotqa-validation-2693", "mrqa_hotpotqa-validation-2816", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-2937", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-2981", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-2994", "mrqa_hotpotqa-validation-3032", "mrqa_hotpotqa-validation-314", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3206", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-338", "mrqa_hotpotqa-validation-3454", "mrqa_hotpotqa-validation-3607", "mrqa_hotpotqa-validation-3669", "mrqa_hotpotqa-validation-3722", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-3937", "mrqa_hotpotqa-validation-3937", "mrqa_hotpotqa-validation-3969", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4146", "mrqa_hotpotqa-validation-4166", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-435", "mrqa_hotpotqa-validation-4390", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-472", "mrqa_hotpotqa-validation-474", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-4818", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5045", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5259", "mrqa_hotpotqa-validation-530", "mrqa_hotpotqa-validation-5303", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5534", "mrqa_hotpotqa-validation-5677", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-884", "mrqa_hotpotqa-validation-996", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-10273", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1707", "mrqa_naturalquestions-validation-1728", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2379", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-2515", "mrqa_naturalquestions-validation-2609", "mrqa_naturalquestions-validation-2658", "mrqa_naturalquestions-validation-2956", "mrqa_naturalquestions-validation-3016", "mrqa_naturalquestions-validation-3199", "mrqa_naturalquestions-validation-3217", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-3499", "mrqa_naturalquestions-validation-3930", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3965", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-4236", "mrqa_naturalquestions-validation-4307", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-4814", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-6052", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6770", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-6998", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-75", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7811", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8849", "mrqa_naturalquestions-validation-8889", "mrqa_naturalquestions-validation-8962", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-9278", "mrqa_naturalquestions-validation-9311", "mrqa_naturalquestions-validation-9650", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9967", "mrqa_naturalquestions-validation-9972", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-1275", "mrqa_newsqa-validation-1319", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1443", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1537", "mrqa_newsqa-validation-1665", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2248", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-2790", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-2919", "mrqa_newsqa-validation-2934", "mrqa_newsqa-validation-2939", "mrqa_newsqa-validation-3021", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3085", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-349", "mrqa_newsqa-validation-3520", "mrqa_newsqa-validation-3644", "mrqa_newsqa-validation-3784", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-406", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4169", "mrqa_newsqa-validation-527", "mrqa_newsqa-validation-539", "mrqa_newsqa-validation-564", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-613", "mrqa_newsqa-validation-668", "mrqa_newsqa-validation-820", "mrqa_searchqa-validation-10060", "mrqa_searchqa-validation-10093", "mrqa_searchqa-validation-10173", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10247", "mrqa_searchqa-validation-10507", "mrqa_searchqa-validation-10669", "mrqa_searchqa-validation-11024", "mrqa_searchqa-validation-11216", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-12078", "mrqa_searchqa-validation-1236", "mrqa_searchqa-validation-12715", "mrqa_searchqa-validation-12740", "mrqa_searchqa-validation-1289", "mrqa_searchqa-validation-13012", "mrqa_searchqa-validation-13110", "mrqa_searchqa-validation-13282", "mrqa_searchqa-validation-13330", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-13651", "mrqa_searchqa-validation-13803", "mrqa_searchqa-validation-14468", "mrqa_searchqa-validation-14512", "mrqa_searchqa-validation-14514", "mrqa_searchqa-validation-14583", "mrqa_searchqa-validation-14849", "mrqa_searchqa-validation-1529", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15560", "mrqa_searchqa-validation-15637", "mrqa_searchqa-validation-1565", "mrqa_searchqa-validation-15845", "mrqa_searchqa-validation-16016", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-177", "mrqa_searchqa-validation-1823", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-2040", "mrqa_searchqa-validation-2162", "mrqa_searchqa-validation-2202", "mrqa_searchqa-validation-2674", "mrqa_searchqa-validation-3014", "mrqa_searchqa-validation-3122", "mrqa_searchqa-validation-3485", "mrqa_searchqa-validation-3955", "mrqa_searchqa-validation-429", "mrqa_searchqa-validation-4355", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-4555", "mrqa_searchqa-validation-457", "mrqa_searchqa-validation-4602", "mrqa_searchqa-validation-4721", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-478", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-5368", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5574", "mrqa_searchqa-validation-5591", "mrqa_searchqa-validation-5760", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-6208", "mrqa_searchqa-validation-621", "mrqa_searchqa-validation-628", "mrqa_searchqa-validation-6417", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-6712", "mrqa_searchqa-validation-7233", "mrqa_searchqa-validation-7616", "mrqa_searchqa-validation-7688", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-7828", "mrqa_searchqa-validation-7864", "mrqa_searchqa-validation-7896", "mrqa_searchqa-validation-7976", "mrqa_searchqa-validation-8348", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-8578", "mrqa_searchqa-validation-8900", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-9096", "mrqa_searchqa-validation-9122", "mrqa_searchqa-validation-9133", "mrqa_searchqa-validation-915", "mrqa_searchqa-validation-9151", "mrqa_searchqa-validation-9529", "mrqa_searchqa-validation-9991", "mrqa_squad-validation-10008", "mrqa_squad-validation-10111", "mrqa_squad-validation-10207", "mrqa_squad-validation-1021", "mrqa_squad-validation-10251", "mrqa_squad-validation-10279", "mrqa_squad-validation-10351", "mrqa_squad-validation-10351", "mrqa_squad-validation-10427", "mrqa_squad-validation-10474", "mrqa_squad-validation-1079", "mrqa_squad-validation-1092", "mrqa_squad-validation-1116", "mrqa_squad-validation-1138", "mrqa_squad-validation-121", "mrqa_squad-validation-1219", "mrqa_squad-validation-1241", "mrqa_squad-validation-1449", "mrqa_squad-validation-1461", "mrqa_squad-validation-1636", "mrqa_squad-validation-1681", "mrqa_squad-validation-1856", "mrqa_squad-validation-1951", "mrqa_squad-validation-1973", "mrqa_squad-validation-1982", "mrqa_squad-validation-2005", "mrqa_squad-validation-2194", "mrqa_squad-validation-2318", "mrqa_squad-validation-2434", "mrqa_squad-validation-2506", "mrqa_squad-validation-2569", "mrqa_squad-validation-2609", "mrqa_squad-validation-2670", "mrqa_squad-validation-2768", "mrqa_squad-validation-312", "mrqa_squad-validation-3153", "mrqa_squad-validation-3223", "mrqa_squad-validation-3326", "mrqa_squad-validation-3363", "mrqa_squad-validation-3456", "mrqa_squad-validation-3497", "mrqa_squad-validation-354", "mrqa_squad-validation-3575", "mrqa_squad-validation-3633", "mrqa_squad-validation-3683", "mrqa_squad-validation-3724", "mrqa_squad-validation-375", "mrqa_squad-validation-3752", "mrqa_squad-validation-3904", "mrqa_squad-validation-3922", "mrqa_squad-validation-3930", "mrqa_squad-validation-3998", "mrqa_squad-validation-4110", "mrqa_squad-validation-4226", "mrqa_squad-validation-4264", "mrqa_squad-validation-4294", "mrqa_squad-validation-4343", "mrqa_squad-validation-4357", "mrqa_squad-validation-4361", "mrqa_squad-validation-4458", "mrqa_squad-validation-4491", "mrqa_squad-validation-4595", "mrqa_squad-validation-4614", "mrqa_squad-validation-4621", "mrqa_squad-validation-4631", "mrqa_squad-validation-4631", "mrqa_squad-validation-4729", "mrqa_squad-validation-4730", "mrqa_squad-validation-4795", "mrqa_squad-validation-4857", "mrqa_squad-validation-4902", "mrqa_squad-validation-4965", "mrqa_squad-validation-4978", "mrqa_squad-validation-50", "mrqa_squad-validation-5098", "mrqa_squad-validation-510", "mrqa_squad-validation-5118", "mrqa_squad-validation-5242", "mrqa_squad-validation-525", "mrqa_squad-validation-5303", "mrqa_squad-validation-5320", "mrqa_squad-validation-5350", "mrqa_squad-validation-5363", "mrqa_squad-validation-5389", "mrqa_squad-validation-5590", "mrqa_squad-validation-5605", "mrqa_squad-validation-5624", "mrqa_squad-validation-5844", "mrqa_squad-validation-5859", "mrqa_squad-validation-5865", "mrqa_squad-validation-5874", "mrqa_squad-validation-5889", "mrqa_squad-validation-5954", "mrqa_squad-validation-5973", "mrqa_squad-validation-6025", "mrqa_squad-validation-6181", "mrqa_squad-validation-6284", "mrqa_squad-validation-6286", "mrqa_squad-validation-629", "mrqa_squad-validation-6361", "mrqa_squad-validation-6393", "mrqa_squad-validation-6394", "mrqa_squad-validation-6467", "mrqa_squad-validation-6518", "mrqa_squad-validation-6645", "mrqa_squad-validation-6658", "mrqa_squad-validation-6753", "mrqa_squad-validation-6791", "mrqa_squad-validation-680", "mrqa_squad-validation-687", "mrqa_squad-validation-6873", "mrqa_squad-validation-6921", "mrqa_squad-validation-70", "mrqa_squad-validation-7011", "mrqa_squad-validation-7013", "mrqa_squad-validation-7040", "mrqa_squad-validation-7068", "mrqa_squad-validation-7082", "mrqa_squad-validation-7082", "mrqa_squad-validation-7153", "mrqa_squad-validation-7206", "mrqa_squad-validation-7207", "mrqa_squad-validation-7230", "mrqa_squad-validation-7303", "mrqa_squad-validation-7311", "mrqa_squad-validation-7430", "mrqa_squad-validation-7566", "mrqa_squad-validation-7646", "mrqa_squad-validation-7674", "mrqa_squad-validation-7694", "mrqa_squad-validation-7765", "mrqa_squad-validation-7887", "mrqa_squad-validation-7895", "mrqa_squad-validation-791", "mrqa_squad-validation-7937", "mrqa_squad-validation-8135", "mrqa_squad-validation-8167", "mrqa_squad-validation-8233", "mrqa_squad-validation-8295", "mrqa_squad-validation-8452", "mrqa_squad-validation-85", "mrqa_squad-validation-8516", "mrqa_squad-validation-8596", "mrqa_squad-validation-89", "mrqa_squad-validation-8910", "mrqa_squad-validation-9029", "mrqa_squad-validation-9304", "mrqa_squad-validation-9325", "mrqa_squad-validation-9351", "mrqa_squad-validation-9360", "mrqa_squad-validation-9411", "mrqa_squad-validation-9512", "mrqa_squad-validation-9562", "mrqa_squad-validation-9565", "mrqa_squad-validation-9578", "mrqa_squad-validation-9614", "mrqa_squad-validation-9895", "mrqa_squad-validation-9895", "mrqa_squad-validation-99", "mrqa_squad-validation-9920", "mrqa_triviaqa-validation-1088", "mrqa_triviaqa-validation-1206", "mrqa_triviaqa-validation-134", "mrqa_triviaqa-validation-1360", "mrqa_triviaqa-validation-1382", "mrqa_triviaqa-validation-1566", "mrqa_triviaqa-validation-1697", "mrqa_triviaqa-validation-1827", "mrqa_triviaqa-validation-1849", "mrqa_triviaqa-validation-1965", "mrqa_triviaqa-validation-2030", "mrqa_triviaqa-validation-2054", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-2075", "mrqa_triviaqa-validation-2080", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-2335", "mrqa_triviaqa-validation-2344", "mrqa_triviaqa-validation-2408", "mrqa_triviaqa-validation-2523", "mrqa_triviaqa-validation-255", "mrqa_triviaqa-validation-2624", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2676", "mrqa_triviaqa-validation-2758", "mrqa_triviaqa-validation-2919", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-3102", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3201", "mrqa_triviaqa-validation-3473", "mrqa_triviaqa-validation-3476", "mrqa_triviaqa-validation-3751", "mrqa_triviaqa-validation-3876", "mrqa_triviaqa-validation-39", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-4379", "mrqa_triviaqa-validation-4611", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-4944", "mrqa_triviaqa-validation-5009", "mrqa_triviaqa-validation-5101", "mrqa_triviaqa-validation-5172", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-552", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-5857", "mrqa_triviaqa-validation-5942", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-5978", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-6187", "mrqa_triviaqa-validation-632", "mrqa_triviaqa-validation-6387", "mrqa_triviaqa-validation-6400", "mrqa_triviaqa-validation-6403", "mrqa_triviaqa-validation-6404", "mrqa_triviaqa-validation-6428", "mrqa_triviaqa-validation-6435", "mrqa_triviaqa-validation-6445", "mrqa_triviaqa-validation-6460", "mrqa_triviaqa-validation-6537", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-6761", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-6842", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6939", "mrqa_triviaqa-validation-6972", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7360", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-7473", "mrqa_triviaqa-validation-7474", "mrqa_triviaqa-validation-7742", "mrqa_triviaqa-validation-790", "mrqa_triviaqa-validation-922"], "OKR": 0.92578125, "KG": 0.51328125, "before_eval_results": {"predictions": ["ten minutes", "1892", "motivated students", "Prince Nikolai Sergeyevich Trubetzkoy", "June 1925", "bushwhackers", "British", "Santiago", "Baudot code", "Jacksonville", "DTM", "Switzerland", "Maryland", "Tennessee", "John Ford", "Operation Watchtower", "34.9 kilometres", "1 December 1948", "omnisexuality", "Westfield Tea Tree Plaza", "southwest Denver, Colorado", "Atlanta, Georgia", "Boston Red Sox", "Scunthorpe", "2004", "Donald McNichol Sutherland", "Towards the Sun", "the heart of the southern (Dolomitic) Alps", "Angus Brayshaw", "impresario", "philosophy", "January 30, 1930", "Sulla", "Australian folk song \"Waltzing Matilda\"", "Jaguar Land Rover and General Motors", "tempo", "Milk Barn Animation", "Jenson Alexander Lyons Button", "Timothy Dowling", "London", "Jane", "Patricia Arquette", "Otto Hahn and Meitner", "AMC Theatres", "31", "Robbie Gould", "Eddie Collins", "Jude", "twenty-three", "Gararish", "A. R. Rahman", "Whoopi Goldberg", "September 8, 2017", "volcanic activity", "Burbank, California", "\"Black Beauty\"", "Werner Heisenberg", "the Kiel Canal", "contract talks", "Eintracht Frankfurt", "Democrat", "a p puppy", "Nickelback", "Will & Grace"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6467719780219781}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, true, true, true, true, false, true, true, false, false, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.8, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.20000000000000004, 0.4, 1.0, 0.0, 1.0, 1.0, 0.20000000000000004, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3076923076923077, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5590", "mrqa_hotpotqa-validation-458", "mrqa_hotpotqa-validation-1358", "mrqa_hotpotqa-validation-1311", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5864", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-5503", "mrqa_hotpotqa-validation-2465", "mrqa_hotpotqa-validation-1920", "mrqa_hotpotqa-validation-1865", "mrqa_hotpotqa-validation-4732", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-1111", "mrqa_hotpotqa-validation-5877", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-4487", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1181", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-4389", "mrqa_hotpotqa-validation-3223", "mrqa_hotpotqa-validation-5187", "mrqa_naturalquestions-validation-6012", "mrqa_triviaqa-validation-1106", "mrqa_newsqa-validation-1898", "mrqa_newsqa-validation-2032", "mrqa_searchqa-validation-6730"], "SR": 0.546875, "CSR": 0.5705645161290323, "retrieved_ids": ["mrqa_squad-train-3837", "mrqa_squad-train-24715", "mrqa_squad-train-75001", "mrqa_squad-train-55205", "mrqa_squad-train-77895", "mrqa_squad-train-4564", "mrqa_squad-train-22510", "mrqa_squad-train-32426", "mrqa_squad-train-80624", "mrqa_squad-train-21851", "mrqa_squad-train-46249", "mrqa_squad-train-33168", "mrqa_squad-train-53962", "mrqa_squad-train-66342", "mrqa_squad-train-5596", "mrqa_squad-train-25231", "mrqa_squad-train-9063", "mrqa_squad-train-65515", "mrqa_squad-train-44435", "mrqa_squad-train-62715", "mrqa_squad-train-30608", "mrqa_squad-train-3510", "mrqa_squad-train-33217", "mrqa_squad-train-55868", "mrqa_squad-train-47247", "mrqa_squad-train-41856", "mrqa_squad-train-72310", "mrqa_squad-train-53422", "mrqa_squad-train-11173", "mrqa_squad-train-9611", "mrqa_squad-train-77498", "mrqa_squad-train-27947", "mrqa_triviaqa-validation-1894", "mrqa_hotpotqa-validation-3247", "mrqa_triviaqa-validation-610", "mrqa_newsqa-validation-2790", "mrqa_triviaqa-validation-5974", "mrqa_naturalquestions-validation-1400", "mrqa_searchqa-validation-4509", "mrqa_triviaqa-validation-5009", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-2989", "mrqa_searchqa-validation-6900", "mrqa_triviaqa-validation-1566", "mrqa_naturalquestions-validation-2146", "mrqa_triviaqa-validation-7210", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-3217", "mrqa_squad-validation-7083", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-4899", "mrqa_squad-validation-8662", "mrqa_hotpotqa-validation-3210", "mrqa_searchqa-validation-9991", "mrqa_triviaqa-validation-371", "mrqa_newsqa-validation-1537", "mrqa_hotpotqa-validation-4166", "mrqa_searchqa-validation-4792", "mrqa_hotpotqa-validation-4391", "mrqa_searchqa-validation-9255", "mrqa_triviaqa-validation-5724", "mrqa_naturalquestions-validation-801", "mrqa_searchqa-validation-12243"], "EFR": 1.0, "Overall": 0.7597379032258064}, {"timecode": 31, "before_eval_results": {"predictions": ["salicylic acid, jasmonic acid, nitric oxide and reactive oxygen species", "500", "7.63\u00d725mm Mauser", "the Harpe brothers", "French", "1944", "Clara Petacci", "2007", "Marko Tapani \" Marco\" Hietala", "Shankar", "Cody Miller", "The Mars Manhunter", "video game", "Carson City", "Nick Cannon Show", "Mickey's Christmas Carol", "San Antonio", "Alpine, New Jersey", "the 1824 Constitution of Mexico", "Hellenism", "Tomorrowland", "Jaffrey", "Frederick Alexander Lindemann,", "Rawhide", "astronomer and composer of German and Czech-Jewish origin", "Don DeLillo", "The Seduction of Hillary Rodham", "balloon Street, Manchester", "9,984", "the Rose Garden", "Spain", "Deep Purple", "Abdul Razzak Yaqoob", "Port Macquarie", "Dan Castellaneta", "Roseann O'Donnell", "Saturday", "Taylor Swift", "Pearl Brewing Company", "Centers for Medicare and Medicaid Services", "Indianapolis Motor Speedway", "Creech Air Force Base, Nevada", "Jay Gruden", "Jango Fett", "High Court of Admiralty", "An All-Colored Vaudeville Show", "Lutheranism", "Robert John Day", "Valley Falls", "dice", "Nicholas \" Nick\" Offerman", "Jewish", "JackScanlon", "Leonard Bernstein", "19", "France", "chloronium", "secretary", "eight", "a nuclear weapon", "2005", "Beastie Boys", "Madison", "Carrie8"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6776041666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.16666666666666666, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-4628", "mrqa_hotpotqa-validation-4489", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-2811", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-3869", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-534", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-1185", "mrqa_hotpotqa-validation-4450", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-1505", "mrqa_hotpotqa-validation-728", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-3737", "mrqa_triviaqa-validation-1534", "mrqa_newsqa-validation-1741", "mrqa_newsqa-validation-3106", "mrqa_searchqa-validation-10363", "mrqa_searchqa-validation-3835"], "SR": 0.5625, "CSR": 0.5703125, "retrieved_ids": ["mrqa_squad-train-49676", "mrqa_squad-train-45958", "mrqa_squad-train-54501", "mrqa_squad-train-68482", "mrqa_squad-train-55952", "mrqa_squad-train-6611", "mrqa_squad-train-36215", "mrqa_squad-train-55501", "mrqa_squad-train-53639", "mrqa_squad-train-17049", "mrqa_squad-train-78461", "mrqa_squad-train-75070", "mrqa_squad-train-51634", "mrqa_squad-train-647", "mrqa_squad-train-12839", "mrqa_squad-train-7527", "mrqa_squad-train-72991", "mrqa_squad-train-22249", "mrqa_squad-train-25256", "mrqa_squad-train-8404", "mrqa_squad-train-83297", "mrqa_squad-train-14306", "mrqa_squad-train-69731", "mrqa_squad-train-66816", "mrqa_squad-train-80464", "mrqa_squad-train-40041", "mrqa_squad-train-82666", "mrqa_squad-train-80791", "mrqa_squad-train-39534", "mrqa_squad-train-78740", "mrqa_squad-train-37545", "mrqa_squad-train-55700", "mrqa_triviaqa-validation-5993", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-3021", "mrqa_newsqa-validation-403", "mrqa_searchqa-validation-9250", "mrqa_squad-validation-375", "mrqa_hotpotqa-validation-5770", "mrqa_searchqa-validation-2337", "mrqa_naturalquestions-validation-7608", "mrqa_triviaqa-validation-3101", "mrqa_searchqa-validation-5713", "mrqa_hotpotqa-validation-943", "mrqa_searchqa-validation-6900", "mrqa_newsqa-validation-1792", "mrqa_searchqa-validation-7828", "mrqa_squad-validation-4356", "mrqa_hotpotqa-validation-3871", "mrqa_hotpotqa-validation-4312", "mrqa_searchqa-validation-13377", "mrqa_hotpotqa-validation-4113", "mrqa_searchqa-validation-10669", "mrqa_hotpotqa-validation-1730", "mrqa_squad-validation-7571", "mrqa_triviaqa-validation-3080", "mrqa_triviaqa-validation-5595", "mrqa_searchqa-validation-16877", "mrqa_searchqa-validation-455", "mrqa_squad-validation-6197", "mrqa_squad-validation-9578", "mrqa_squad-validation-434", "mrqa_naturalquestions-validation-10114", "mrqa_triviaqa-validation-7349"], "EFR": 1.0, "Overall": 0.7596875}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh Downs", "education", "Till Death Us Do Part", "Laputa", "Leeds", "Bob Neal", "LysergS\u00e4ureDiethylamid", "king Stephen", "Albania", "Tombstone", "Charlie", "Jaguar Land Rover", "Diego Maradona", "Sudan", "Bubba Watson, Jr.", "football", "a multi-user real-time virtual world described entirely in text.", "fondu", "Greece", "(1932-1934)", "Steve Coogan", "Sophie Marceau", "the Boston Marathon", "Carl Smith, with whom she performed at Nashville's Grand Ole Opry, and their daughter, Rebecca Carlene", "Humble pie", "Jorge Lorenzo", "The Rescuers (A Walt Disney Classic) (The Classics)", "checkers", "Les Dawson", "King Ferdinand", "the Grail", "Ronald Reagan", "Nicholas Ball", "climate", "at the Coney Island Old Island Pier in New York, NY.", "the Sutton Hoo burial ship", "in some cases, through a liver transplant", "Guildford Dudley", "the Amoco Cadiz", "John Howard", "1 Samuel", "His Holiness", "12th", "Cornell University", "Flybe", "The Altamont Speedway Free Festival", "in a pot or crock and covered with fat", "The Lost Weekend", "Stockholm", "Switzerland", "taekwondo", "tomato", "senior-most judge of the supreme court", "early Christians of Mesopotamia", "House of Representatives", "2006", "Central Avenue", "middleweight division", "Mokotedi Mpshe,", "preventative forestry", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "Canterbury", "Harold Macmillan", "a bog"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6264946219715957}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.4210526315789474, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-719", "mrqa_triviaqa-validation-2318", "mrqa_triviaqa-validation-3263", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-2930", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-1179", "mrqa_triviaqa-validation-4327", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-435", "mrqa_triviaqa-validation-4244", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-7163", "mrqa_triviaqa-validation-7226", "mrqa_triviaqa-validation-5600", "mrqa_triviaqa-validation-1178", "mrqa_triviaqa-validation-2330", "mrqa_hotpotqa-validation-1023", "mrqa_hotpotqa-validation-3988", "mrqa_newsqa-validation-1816", "mrqa_newsqa-validation-4060", "mrqa_newsqa-validation-3089", "mrqa_searchqa-validation-6833"], "SR": 0.578125, "CSR": 0.5705492424242424, "retrieved_ids": ["mrqa_squad-train-42276", "mrqa_squad-train-51819", "mrqa_squad-train-42344", "mrqa_squad-train-31657", "mrqa_squad-train-31733", "mrqa_squad-train-57526", "mrqa_squad-train-15264", "mrqa_squad-train-48432", "mrqa_squad-train-8695", "mrqa_squad-train-56897", "mrqa_squad-train-65674", "mrqa_squad-train-14491", "mrqa_squad-train-63175", "mrqa_squad-train-54732", "mrqa_squad-train-36090", "mrqa_squad-train-39871", "mrqa_squad-train-69243", "mrqa_squad-train-60021", "mrqa_squad-train-30600", "mrqa_squad-train-34651", "mrqa_squad-train-72918", "mrqa_squad-train-36885", "mrqa_squad-train-21497", "mrqa_squad-train-26929", "mrqa_squad-train-29799", "mrqa_squad-train-79789", "mrqa_squad-train-11206", "mrqa_squad-train-4883", "mrqa_squad-train-23359", "mrqa_squad-train-3409", "mrqa_squad-train-16027", "mrqa_squad-train-47020", "mrqa_squad-validation-4260", "mrqa_squad-validation-7537", "mrqa_naturalquestions-validation-2146", "mrqa_searchqa-validation-14514", "mrqa_searchqa-validation-8411", "mrqa_hotpotqa-validation-2905", "mrqa_searchqa-validation-9529", "mrqa_naturalquestions-validation-3048", "mrqa_triviaqa-validation-1904", "mrqa_searchqa-validation-9679", "mrqa_newsqa-validation-3091", "mrqa_squad-validation-525", "mrqa_triviaqa-validation-4836", "mrqa_searchqa-validation-7212", "mrqa_triviaqa-validation-6052", "mrqa_naturalquestions-validation-3217", "mrqa_searchqa-validation-6666", "mrqa_squad-validation-3374", "mrqa_newsqa-validation-1114", "mrqa_hotpotqa-validation-1691", "mrqa_hotpotqa-validation-4135", "mrqa_squad-validation-5758", "mrqa_squad-validation-6091", "mrqa_searchqa-validation-12316", "mrqa_hotpotqa-validation-996", "mrqa_squad-validation-7708", "mrqa_hotpotqa-validation-5877", "mrqa_hotpotqa-validation-497", "mrqa_hotpotqa-validation-2341", "mrqa_newsqa-validation-103", "mrqa_searchqa-validation-12536", "mrqa_triviaqa-validation-5336"], "EFR": 0.9629629629629629, "Overall": 0.7523274410774411}, {"timecode": 33, "before_eval_results": {"predictions": ["Brown v. Board of Education of Topeka", "early 1938", "Adidas", "Ennis, County Clare", "Stratfor's website", "in the last few months,", "Jaime Andrade", "1 percent of children ages 3 to 17", "girls", "records showing that Barlow and the girl were married and any evidence of them having a child.", "the stylish Sansibar (80 H\u00f6rnumer Str., Rantum)", "gasoline", "vivian, and one of the officers for the official \"Dancing With the Stars\" \" Facebook group.", "\"AS IS/ HERE IS\"", "two", "a residential dike", "Michael brewer,", "abduction of minors.", "Brazil", "J. Crew", "state's first lady,", "Florida", "Bhola", "T.I.", "Pew Research Center", "Nirvana", "Dr. Conrad Murray", "Jared Polis", "based on race or its understanding of what the law required it to do.", "he won it after facing various challenges and turning them to his advantage.", "between June 20 and July 20.", "paul fidler", "misdemeanor", "1.2 million", "100,000", "Heshmatollah Attarzadeh", "crossfire by insurgent small arms fire,", "2002", "she would try to take the children and flee to Japan.", "a \"new chapter\" of improved governance in Afghanistan", "Luka Modric.", "Sunday's strike", "shelling of the compound", "in the mouth.", "Atlantic Ocean", "movahedi", "Nepal", "Jiverly Wong,", "\"The Dr. Phil Show\"", "Carrousel du Louvre", "September 21.", "Grayback forest-firefighters", "Supplemental oxygen", "Prince Bao ( \u5bf6 \u89aa\u738b ), then became the Qianlong Emperor", "Narendra Modi", "Stephen Hendry", "aged 75 or older", "johnny heeran", "musical research", "Randall Boggs", "Mick Jackson", "West Virginia", "Sid Vicious", "Paris"], "metric_results": {"EM": 0.5, "QA-F1": 0.5484544101731602}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, true, true, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0, 0.18181818181818182, 0.0, 1.0, 0.13333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5238095238095238, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-715", "mrqa_newsqa-validation-3196", "mrqa_newsqa-validation-775", "mrqa_newsqa-validation-3432", "mrqa_newsqa-validation-2702", "mrqa_newsqa-validation-2086", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3438", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2709", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2200", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-314", "mrqa_newsqa-validation-2485", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-1643", "mrqa_newsqa-validation-832", "mrqa_newsqa-validation-3004", "mrqa_newsqa-validation-4062", "mrqa_naturalquestions-validation-997", "mrqa_naturalquestions-validation-9569", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7079", "mrqa_hotpotqa-validation-4112", "mrqa_searchqa-validation-8669", "mrqa_searchqa-validation-44"], "SR": 0.5, "CSR": 0.5684742647058824, "retrieved_ids": ["mrqa_squad-train-54418", "mrqa_squad-train-84720", "mrqa_squad-train-67017", "mrqa_squad-train-70878", "mrqa_squad-train-9202", "mrqa_squad-train-38147", "mrqa_squad-train-37506", "mrqa_squad-train-62041", "mrqa_squad-train-77269", "mrqa_squad-train-65932", "mrqa_squad-train-26270", "mrqa_squad-train-19516", "mrqa_squad-train-8552", "mrqa_squad-train-30185", "mrqa_squad-train-34895", "mrqa_squad-train-75239", "mrqa_squad-train-21483", "mrqa_squad-train-65822", "mrqa_squad-train-16223", "mrqa_squad-train-11056", "mrqa_squad-train-44906", "mrqa_squad-train-84979", "mrqa_squad-train-68894", "mrqa_squad-train-58186", "mrqa_squad-train-30601", "mrqa_squad-train-40863", "mrqa_squad-train-61404", "mrqa_squad-train-69846", "mrqa_squad-train-21364", "mrqa_squad-train-64337", "mrqa_squad-train-50737", "mrqa_squad-train-20333", "mrqa_naturalquestions-validation-8272", "mrqa_searchqa-validation-15581", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-1443", "mrqa_searchqa-validation-14512", "mrqa_squad-validation-375", "mrqa_triviaqa-validation-2357", "mrqa_triviaqa-validation-3473", "mrqa_squad-validation-1504", "mrqa_newsqa-validation-2939", "mrqa_triviaqa-validation-2919", "mrqa_squad-validation-8662", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-1353", "mrqa_searchqa-validation-7976", "mrqa_squad-validation-4730", "mrqa_hotpotqa-validation-1111", "mrqa_newsqa-validation-3264", "mrqa_searchqa-validation-8411", "mrqa_hotpotqa-validation-1505", "mrqa_squad-validation-3863", "mrqa_triviaqa-validation-3102", "mrqa_squad-validation-2097", "mrqa_triviaqa-validation-7742", "mrqa_naturalquestions-validation-10138", "mrqa_hotpotqa-validation-3943", "mrqa_triviaqa-validation-2758", "mrqa_newsqa-validation-1131", "mrqa_hotpotqa-validation-3481", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-3954"], "EFR": 1.0, "Overall": 0.7593198529411764}, {"timecode": 34, "before_eval_results": {"predictions": ["most common", "boudins", "Robert A. Heinlein", "Mumbai", "Indiana", "zoology", "Moonwalk", "Laos", "vislor Turlough", "Westminster Abbey", "Battle of Agincourt", "white spirit", "king george v", "Kent", "Miss Prism", "Diptera", "a turkey", "transuranic", "Harold Shipman", "river Wyre", "Carson City", "All Things Must Pass", "United Kingdom", "Mercury", "Doctor Who", "North Yorkshire", "George Blake", "Nirvana", "Janis Joplin", "Kenya", "Manchester City", "Moscow", "Caracas", "oil of Olay", "hair", "decoupage", "Bathsheba", "Ennio Morricone", "DitaVon Teese", "collapsible support assembly", "Republican", "Argentina", "French", "dennis taylor", "internal kidney structures", "british giant", "Rocky Marciano", "The Benedictine Order", "Coventry to Leicester Motorway", "princess british", "Jack Lemmon", "four", "1965", "2018", "a lightning strike", "Danny Lebern Glover", "Trey Parker and Matt Stone", "219", "Hundreds", "Democrats", "31 meters (102 feet)", "Sir Lancelot", "Sacramento", "Hawaii"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7291666666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-2181", "mrqa_triviaqa-validation-3950", "mrqa_triviaqa-validation-1518", "mrqa_triviaqa-validation-5548", "mrqa_triviaqa-validation-2474", "mrqa_triviaqa-validation-331", "mrqa_triviaqa-validation-798", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-7774", "mrqa_triviaqa-validation-4133", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4317", "mrqa_naturalquestions-validation-8444", "mrqa_naturalquestions-validation-10490", "mrqa_hotpotqa-validation-1922", "mrqa_newsqa-validation-3976", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-3920"], "SR": 0.671875, "CSR": 0.5714285714285714, "retrieved_ids": ["mrqa_squad-train-53641", "mrqa_squad-train-44443", "mrqa_squad-train-76491", "mrqa_squad-train-34795", "mrqa_squad-train-20185", "mrqa_squad-train-57364", "mrqa_squad-train-3612", "mrqa_squad-train-30238", "mrqa_squad-train-66514", "mrqa_squad-train-2409", "mrqa_squad-train-20757", "mrqa_squad-train-41705", "mrqa_squad-train-5003", "mrqa_squad-train-68770", "mrqa_squad-train-69677", "mrqa_squad-train-76526", "mrqa_squad-train-7247", "mrqa_squad-train-83946", "mrqa_squad-train-23019", "mrqa_squad-train-21830", "mrqa_squad-train-13159", "mrqa_squad-train-55669", "mrqa_squad-train-66700", "mrqa_squad-train-33824", "mrqa_squad-train-47412", "mrqa_squad-train-81967", "mrqa_squad-train-37304", "mrqa_squad-train-78364", "mrqa_squad-train-34024", "mrqa_squad-train-29655", "mrqa_squad-train-34769", "mrqa_squad-train-43329", "mrqa_searchqa-validation-5460", "mrqa_searchqa-validation-6833", "mrqa_triviaqa-validation-4730", "mrqa_searchqa-validation-8348", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-8046", "mrqa_hotpotqa-validation-2377", "mrqa_searchqa-validation-9472", "mrqa_searchqa-validation-14852", "mrqa_newsqa-validation-2607", "mrqa_naturalquestions-validation-2582", "mrqa_triviaqa-validation-1114", "mrqa_triviaqa-validation-4944", "mrqa_hotpotqa-validation-346", "mrqa_triviaqa-validation-7062", "mrqa_searchqa-validation-5715", "mrqa_naturalquestions-validation-3663", "mrqa_triviaqa-validation-6783", "mrqa_searchqa-validation-44", "mrqa_hotpotqa-validation-2327", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-5502", "mrqa_searchqa-validation-14583", "mrqa_newsqa-validation-1314", "mrqa_triviaqa-validation-3473", "mrqa_searchqa-validation-15777", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-8283", "mrqa_searchqa-validation-6814", "mrqa_naturalquestions-validation-10114", "mrqa_squad-validation-3998", "mrqa_squad-validation-3635"], "EFR": 1.0, "Overall": 0.7599107142857142}, {"timecode": 35, "before_eval_results": {"predictions": ["late 1970s", "Aristotle", "Daiquiri", "Calvary", "armadillos", "the Elizabethan Theatres", "television", "Absalom", "Molly", "The Goonies", "flag", "Ecuador", "the Seine river", "alcohol", "Alyssa Milano", "bites a dog", "the national anthem", "The Rolling Stones", "Lincoln's Inn", "a rooks", "Benjamin Franklin", "Bob Dylan", "a urinal", "Apollo 11", "Spain", "Cadillac", "Matt Damon", "the Great American Novel", "Shalom", "white", "Arthur James Balfour", "a decree", "Easton", "Scrabble", "Iceland", "Goggins Mountain", "an incubation chamber", "Upton Sinclair", "Stephen", "Brooke Bollea", "a war", "Nancy Sinatra", "David", "Pinot noir", "Robert Lowell", "forgo/ forgoes", "Richmond", "\"I think they got Elliot's\"", "Amy Tan", "Florence", "Pandora", "Grenada", "the Mahalangur Himal", "Kusha", "Only Fools and Horses", "Costa Brava", "Stainless-steel", "one", "2015", "October 20, 2017", "Columbus", "Gustav's top winds", "Piedad Cordoba,", "Martin \"Al\" Culhane,"], "metric_results": {"EM": 0.625, "QA-F1": 0.6852678571428571}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6319", "mrqa_searchqa-validation-1076", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-2248", "mrqa_searchqa-validation-12623", "mrqa_searchqa-validation-7906", "mrqa_searchqa-validation-10999", "mrqa_searchqa-validation-9007", "mrqa_searchqa-validation-8365", "mrqa_searchqa-validation-3188", "mrqa_searchqa-validation-12576", "mrqa_searchqa-validation-9559", "mrqa_searchqa-validation-929", "mrqa_searchqa-validation-11471", "mrqa_searchqa-validation-15863", "mrqa_searchqa-validation-9", "mrqa_searchqa-validation-3703", "mrqa_searchqa-validation-559", "mrqa_searchqa-validation-3922", "mrqa_searchqa-validation-9192", "mrqa_naturalquestions-validation-10026", "mrqa_naturalquestions-validation-1407", "mrqa_triviaqa-validation-6212", "mrqa_newsqa-validation-2307"], "SR": 0.625, "CSR": 0.5729166666666667, "retrieved_ids": ["mrqa_squad-train-19017", "mrqa_squad-train-62812", "mrqa_squad-train-83427", "mrqa_squad-train-17514", "mrqa_squad-train-26486", "mrqa_squad-train-2257", "mrqa_squad-train-23880", "mrqa_squad-train-53843", "mrqa_squad-train-6672", "mrqa_squad-train-13361", "mrqa_squad-train-51349", "mrqa_squad-train-59883", "mrqa_squad-train-81732", "mrqa_squad-train-85593", "mrqa_squad-train-72485", "mrqa_squad-train-23541", "mrqa_squad-train-38125", "mrqa_squad-train-76615", "mrqa_squad-train-21137", "mrqa_squad-train-46772", "mrqa_squad-train-4963", "mrqa_squad-train-28524", "mrqa_squad-train-4806", "mrqa_squad-train-76433", "mrqa_squad-train-4167", "mrqa_squad-train-50432", "mrqa_squad-train-4001", "mrqa_squad-train-22280", "mrqa_squad-train-71226", "mrqa_squad-train-62033", "mrqa_squad-train-32971", "mrqa_squad-train-63034", "mrqa_hotpotqa-validation-1227", "mrqa_hotpotqa-validation-3787", "mrqa_searchqa-validation-5715", "mrqa_triviaqa-validation-1106", "mrqa_hotpotqa-validation-577", "mrqa_triviaqa-validation-1938", "mrqa_naturalquestions-validation-4072", "mrqa_hotpotqa-validation-4436", "mrqa_newsqa-validation-2418", "mrqa_newsqa-validation-2062", "mrqa_triviaqa-validation-1178", "mrqa_naturalquestions-validation-144", "mrqa_naturalquestions-validation-10307", "mrqa_newsqa-validation-1271", "mrqa_searchqa-validation-10063", "mrqa_newsqa-validation-3004", "mrqa_triviaqa-validation-6052", "mrqa_squad-validation-7112", "mrqa_hotpotqa-validation-4290", "mrqa_searchqa-validation-16595", "mrqa_triviaqa-validation-6113", "mrqa_hotpotqa-validation-108", "mrqa_triviaqa-validation-4705", "mrqa_naturalquestions-validation-392", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-2474", "mrqa_squad-validation-1064", "mrqa_triviaqa-validation-6445", "mrqa_triviaqa-validation-4173", "mrqa_hotpotqa-validation-5521", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-10014"], "EFR": 0.9583333333333334, "Overall": 0.751875}, {"timecode": 36, "before_eval_results": {"predictions": ["February 1082", "Bowe Bergdahl,", "people around the world commented, pondered, and paid tribute to pop legend Michael Jackson,", "a Columbian mammoth", "Symbionese Liberation Army", "steamboat,", "a mechanism at the federal level to ensure that drivers comply.", "Tim Clark, Matt Kuchar and Bubba Watson", "a long-range missile on its launch pad,", "75 percent", "prisoners at the South Dakota State Penitentiary", "women.", "CNN/Opinion Research Corporation", "Saudi Prince and billionaire Al-Waleed bin Talal", "an engineering and construction company with a vast personal fortune.", "Ku Klux Klan", "Felipe Calderon", "137", "3-3 draw", "Dancing With the Stars.", "love and loss.", "Michael Jackson", "\"a striking blow to due process and the rule of law\"", "Venezuela", "their business books", "the Nazi war crimes suspect", "a number of calls,", "Mandi Hamlin,", "South Dakota State Penitentiary", "Department of Homeland Security Secretary Janet Napolitano", "Russian concerns that the defensive shield could be used for offensive aims.", "Bob Dole,", "they can demonstrate they have been satisfactorily treated", "Oklahoma to eastern Tennessee", "\"Dance Your Ass Off\"", "Malawi", "246", "skull", "Six", "Izzat Ibrahim al-Douri,", "Nearly eight in 10", "a one-shot victory in the Bob Hope Classic on the final hole", "Muslim north of Sudan", "37", "Clifford Harris,", "Bea Arthur,", "Susan Boyle", "Florida", "UNICEF", "United States, NATO member states, Russia and India", "27-year-old", "45 %", "Phil Gallagher", "September 4, 2000", "One Direction", "Runcorn", "oxygen", "Ben R. Guttery", "Preston, Lancashire, UK", "1993 to 1996", "Chile", "Halloween", "Gregor Mendel", "Dick & Jane"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6741932189542483}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.1, 0.0, 1.0, 0.0, 0.47058823529411764, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4444444444444445, 1.0, 1.0, 0.0, 0.16666666666666666, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1661", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-3130", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-4211", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-466", "mrqa_newsqa-validation-2856", "mrqa_newsqa-validation-152", "mrqa_newsqa-validation-3380", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-2078", "mrqa_newsqa-validation-3069", "mrqa_naturalquestions-validation-5564", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2625", "mrqa_searchqa-validation-5817", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-10010"], "SR": 0.53125, "CSR": 0.5717905405405406, "retrieved_ids": ["mrqa_squad-train-118", "mrqa_squad-train-68810", "mrqa_squad-train-17606", "mrqa_squad-train-82634", "mrqa_squad-train-37386", "mrqa_squad-train-59450", "mrqa_squad-train-39217", "mrqa_squad-train-60782", "mrqa_squad-train-20359", "mrqa_squad-train-45363", "mrqa_squad-train-74760", "mrqa_squad-train-83027", "mrqa_squad-train-36509", "mrqa_squad-train-74150", "mrqa_squad-train-22426", "mrqa_squad-train-46587", "mrqa_squad-train-27603", "mrqa_squad-train-28588", "mrqa_squad-train-53932", "mrqa_squad-train-49226", "mrqa_squad-train-60521", "mrqa_squad-train-80116", "mrqa_squad-train-82943", "mrqa_squad-train-9860", "mrqa_squad-train-32458", "mrqa_squad-train-84963", "mrqa_squad-train-40683", "mrqa_squad-train-84187", "mrqa_squad-train-84468", "mrqa_squad-train-52926", "mrqa_squad-train-24889", "mrqa_squad-train-38012", "mrqa_squad-validation-3922", "mrqa_newsqa-validation-2790", "mrqa_triviaqa-validation-1603", "mrqa_searchqa-validation-4485", "mrqa_triviaqa-validation-6805", "mrqa_hotpotqa-validation-1409", "mrqa_squad-validation-9176", "mrqa_searchqa-validation-8042", "mrqa_naturalquestions-validation-7393", "mrqa_hotpotqa-validation-4290", "mrqa_searchqa-validation-583", "mrqa_hotpotqa-validation-4112", "mrqa_triviaqa-validation-703", "mrqa_searchqa-validation-559", "mrqa_hotpotqa-validation-4336", "mrqa_searchqa-validation-6961", "mrqa_triviaqa-validation-4398", "mrqa_naturalquestions-validation-3217", "mrqa_hotpotqa-validation-4899", "mrqa_searchqa-validation-6900", "mrqa_triviaqa-validation-371", "mrqa_squad-validation-7207", "mrqa_newsqa-validation-1271", "mrqa_hotpotqa-validation-4818", "mrqa_triviaqa-validation-6683", "mrqa_newsqa-validation-2227", "mrqa_searchqa-validation-8283", "mrqa_searchqa-validation-5936", "mrqa_triviaqa-validation-4133", "mrqa_squad-validation-9565", "mrqa_newsqa-validation-3376", "mrqa_searchqa-validation-1187"], "EFR": 0.9666666666666667, "Overall": 0.7533164414414414}, {"timecode": 37, "before_eval_results": {"predictions": ["over $20 billion", "the Veneto region of Northern Italy", "Preston", "Jean de Florette", "George Orwell", "Eric Allan Kramer", "eight", "Kathryn Bigelow", "Fredric Warburg", "Ben Ainslie", "1905", "Sex Drive", "Yoruba", "Archbishop of Canterbury", "brother-in-law", "Chrysler", "Portal", "a chronological collection of critical quotations", "Terrence Jones", "S&M", "one", "V", "O", "The Grandmaster", "Scotland", "1960s", "Eugene Wigner", "The Russian Empire", "Cold Spring", "Hilary Duff", "Ogallala, Nebraska", "October 21, 2016", "My Beautiful Dark Twisted Fantasy", "Everything Is wrong", "Massapequa", "1988", "Dan Bilzerian", "Spitsbergen", "1967", "m.A. Roxas Avenue", "Francesco Maria Piave", "band director", "1875", "$10\u201320 million", "Mandarin", "Fester Addams", "March", "Michael-Leon Wooley", "Esp\u00edrito Santo Financial Group", "Los Angeles", "The New Yorker", "Walter Egan", "`` Wah - Wah ''", "Confederate", "Shirley Horn", "Richie McCaw", "earwax", "mental health and recovery.", "the Bronx.", "billions of dollars", "Diamond", "Simon Legree", "Sideways", "Pindar"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6125}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, false, false, true, false, true, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3431", "mrqa_hotpotqa-validation-5342", "mrqa_hotpotqa-validation-4661", "mrqa_hotpotqa-validation-2047", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-388", "mrqa_hotpotqa-validation-3391", "mrqa_hotpotqa-validation-4294", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-5651", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-365", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-3220", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-3877", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-4687", "mrqa_naturalquestions-validation-4148", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-6464", "mrqa_searchqa-validation-12752", "mrqa_searchqa-validation-8753"], "SR": 0.5625, "CSR": 0.571546052631579, "retrieved_ids": ["mrqa_squad-train-40337", "mrqa_squad-train-40174", "mrqa_squad-train-18755", "mrqa_squad-train-73629", "mrqa_squad-train-43157", "mrqa_squad-train-30399", "mrqa_squad-train-3856", "mrqa_squad-train-17679", "mrqa_squad-train-32386", "mrqa_squad-train-27968", "mrqa_squad-train-44082", "mrqa_squad-train-39217", "mrqa_squad-train-55981", "mrqa_squad-train-38436", "mrqa_squad-train-86231", "mrqa_squad-train-54923", "mrqa_squad-train-80408", "mrqa_squad-train-23093", "mrqa_squad-train-27068", "mrqa_squad-train-64775", "mrqa_squad-train-8349", "mrqa_squad-train-58510", "mrqa_squad-train-56736", "mrqa_squad-train-67896", "mrqa_squad-train-13602", "mrqa_squad-train-29694", "mrqa_squad-train-85333", "mrqa_squad-train-29347", "mrqa_squad-train-43935", "mrqa_squad-train-24376", "mrqa_squad-train-5645", "mrqa_squad-train-9082", "mrqa_searchqa-validation-11392", "mrqa_hotpotqa-validation-1630", "mrqa_squad-validation-7430", "mrqa_squad-validation-7162", "mrqa_squad-validation-8900", "mrqa_triviaqa-validation-4836", "mrqa_squad-validation-4361", "mrqa_hotpotqa-validation-596", "mrqa_newsqa-validation-3784", "mrqa_squad-validation-4631", "mrqa_searchqa-validation-3703", "mrqa_searchqa-validation-6349", "mrqa_triviaqa-validation-6979", "mrqa_squad-validation-10427", "mrqa_searchqa-validation-9123", "mrqa_searchqa-validation-8042", "mrqa_naturalquestions-validation-10012", "mrqa_triviaqa-validation-7076", "mrqa_hotpotqa-validation-3988", "mrqa_newsqa-validation-3907", "mrqa_hotpotqa-validation-3187", "mrqa_newsqa-validation-1537", "mrqa_searchqa-validation-8331", "mrqa_hotpotqa-validation-5866", "mrqa_naturalquestions-validation-9809", "mrqa_squad-validation-1234", "mrqa_hotpotqa-validation-5534", "mrqa_hotpotqa-validation-1691", "mrqa_squad-validation-9565", "mrqa_newsqa-validation-3048", "mrqa_naturalquestions-validation-2572", "mrqa_searchqa-validation-478"], "EFR": 1.0, "Overall": 0.7599342105263157}, {"timecode": 38, "before_eval_results": {"predictions": ["Turing machines", "Nepal", "Wang Chung", "Panama", "a gastropod shell", "Thailand", "Abraham Lincoln", "a cat", "Georgie Porgie", "Mork & Mindy", "Catherine de Medici", "dressage", "Benito Jurez", "Southern California", "Fort Leavenworth", "INXS", "globalization", "wildebeest", "Extra-Terrestrial Intelligence", "Henry VIII", "Kenneth Noland", "Clara Barton", "Nine to Five", "a snake", "an elk", "Winnipeg", "Nicaragua", "Arthur Miller", "Princess Margaret", "1937", "a Seaweed", "feminism", "the Space Coast Convention Center", "a gallbladder", "the cakes and the visit to the house of Hwang", "Midway", "Liechtenstein", "Custer", "a physician", "salt", "Gloria Steinem", "Queen Louise's", "Tonga", "Minos", "Gulliver", "rum", "SeaWorld", "a grce", "Tyra Banks", "Richard Gephardt", "Bucharest", "Manley", "synthesizing vitamin B and vitamin K as well as metabolizing bile acids, sterols, and xenobiotics", "attack on Pearl Harbor", "negative", "inch", "british", "Canterbury", "Lowndes County", "Northern Rhodesia", "the actor who created one of British television's most surreal thrillers", "Anjuna beach in Goa", "stuck to with remarkably little internal drama. He won it with unparalleled fundraising and an overwhelming ground game. And he won it after facing various challenges and turning them to", "1,500"], "metric_results": {"EM": 0.53125, "QA-F1": 0.618465909090909}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.18181818181818182, 0.4, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-948", "mrqa_searchqa-validation-7279", "mrqa_searchqa-validation-14384", "mrqa_searchqa-validation-10873", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-5765", "mrqa_searchqa-validation-1647", "mrqa_searchqa-validation-7186", "mrqa_searchqa-validation-8804", "mrqa_searchqa-validation-14900", "mrqa_searchqa-validation-13802", "mrqa_searchqa-validation-2090", "mrqa_searchqa-validation-8233", "mrqa_searchqa-validation-16148", "mrqa_searchqa-validation-15378", "mrqa_searchqa-validation-9113", "mrqa_searchqa-validation-5436", "mrqa_searchqa-validation-16431", "mrqa_searchqa-validation-2041", "mrqa_searchqa-validation-13649", "mrqa_searchqa-validation-11425", "mrqa_triviaqa-validation-1183", "mrqa_triviaqa-validation-2115", "mrqa_hotpotqa-validation-1770", "mrqa_hotpotqa-validation-4989", "mrqa_hotpotqa-validation-4053", "mrqa_newsqa-validation-2059", "mrqa_newsqa-validation-2980", "mrqa_newsqa-validation-3579"], "SR": 0.53125, "CSR": 0.5705128205128205, "retrieved_ids": ["mrqa_squad-train-31866", "mrqa_squad-train-32484", "mrqa_squad-train-30649", "mrqa_squad-train-8245", "mrqa_squad-train-79998", "mrqa_squad-train-47659", "mrqa_squad-train-62550", "mrqa_squad-train-69495", "mrqa_squad-train-19720", "mrqa_squad-train-75217", "mrqa_squad-train-8655", "mrqa_squad-train-49580", "mrqa_squad-train-53660", "mrqa_squad-train-28380", "mrqa_squad-train-64447", "mrqa_squad-train-37827", "mrqa_squad-train-8805", "mrqa_squad-train-8119", "mrqa_squad-train-26820", "mrqa_squad-train-36636", "mrqa_squad-train-60716", "mrqa_squad-train-12864", "mrqa_squad-train-45115", "mrqa_squad-train-25286", "mrqa_squad-train-16094", "mrqa_squad-train-85478", "mrqa_squad-train-34783", "mrqa_squad-train-23134", "mrqa_squad-train-36224", "mrqa_squad-train-50176", "mrqa_squad-train-43262", "mrqa_squad-train-47844", "mrqa_naturalquestions-validation-9809", "mrqa_triviaqa-validation-6002", "mrqa_squad-validation-8452", "mrqa_searchqa-validation-6712", "mrqa_searchqa-validation-3920", "mrqa_searchqa-validation-14453", "mrqa_newsqa-validation-775", "mrqa_hotpotqa-validation-1505", "mrqa_naturalquestions-validation-6998", "mrqa_newsqa-validation-3106", "mrqa_squad-validation-7162", "mrqa_squad-validation-1312", "mrqa_squad-validation-4356", "mrqa_hotpotqa-validation-4433", "mrqa_triviaqa-validation-1904", "mrqa_triviaqa-validation-6052", "mrqa_naturalquestions-validation-677", "mrqa_searchqa-validation-5713", "mrqa_naturalquestions-validation-3663", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-1400", "mrqa_searchqa-validation-1948", "mrqa_squad-validation-6091", "mrqa_hotpotqa-validation-149", "mrqa_hotpotqa-validation-3669", "mrqa_triviaqa-validation-4836", "mrqa_newsqa-validation-1443", "mrqa_searchqa-validation-583", "mrqa_hotpotqa-validation-5187", "mrqa_triviaqa-validation-6091", "mrqa_triviaqa-validation-2883", "mrqa_hotpotqa-validation-4813"], "EFR": 1.0, "Overall": 0.759727564102564}, {"timecode": 39, "before_eval_results": {"predictions": ["over the age of 18", "Nalini Negi", "Sundays", "The 1980 Summer Olympics", "The International Baccalaureate", "the medulla oblongata", "Andreas Vesalius", "`` The Crossing ''", "Nicole DuPort", "Angus Young", "Tony Hightower", "After World War I", "studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "Pac - 12 Conference Champions Stanford Cardinal", "Wake County", "60 by West All - Stars", "RMS Titanic", "Sally Field", "Elizabeth Dean Lail", "Ravi Shastri", "beans, peppers and spices", "6 March 1983", "Amanda Leighton", "James Arthur", "James Watson and Francis Crick", "The Pacific Ocean", "during the American Civil War", "Thomas Middleditch", "slavery", "Sir Ernest Rutherford", "Buddhist missionaries", "1832", "parthenogenesis", "on the two tablets", "Buffalo Bill", "$19.8 trillion", "`` Sacrifice ''", "boy", "1820s", "Chernobyl Nuclear Power Plant", "Vienna", "Dmitri Mendeleev", "Dalveer Bhandari", "standard temperature and pressure", "John Ernest Crawford", "July 2014", "`` Can't Get You Out of My Head ''", "1924", "Americans", "`` state '' or `` states ''", "Sedimentary rock", "Carmen", "duck", "glass", "Rikki Farr's", "the Israeli Declaration of Independence", "two Nobel Peace Prizes", "18", "2002", "Gaslight Theater.", "Dragnet", "Depeche Mode", "Louis Rukeyser", "Matt Groening"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6794127096861472}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, false, true, true, false, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.18181818181818182, 0.5, 0.2666666666666667, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0625, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-8118", "mrqa_naturalquestions-validation-3257", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-3926", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-6237", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2467", "mrqa_naturalquestions-validation-2894", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1699", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-1327", "mrqa_naturalquestions-validation-5624", "mrqa_newsqa-validation-2020", "mrqa_searchqa-validation-1911"], "SR": 0.609375, "CSR": 0.571484375, "retrieved_ids": ["mrqa_squad-train-12973", "mrqa_squad-train-77338", "mrqa_squad-train-33275", "mrqa_squad-train-22214", "mrqa_squad-train-47802", "mrqa_squad-train-7927", "mrqa_squad-train-41165", "mrqa_squad-train-80564", "mrqa_squad-train-7684", "mrqa_squad-train-20038", "mrqa_squad-train-1704", "mrqa_squad-train-58566", "mrqa_squad-train-37262", "mrqa_squad-train-60631", "mrqa_squad-train-58461", "mrqa_squad-train-55449", "mrqa_squad-train-63130", "mrqa_squad-train-44015", "mrqa_squad-train-71330", "mrqa_squad-train-34193", "mrqa_squad-train-9354", "mrqa_squad-train-64870", "mrqa_squad-train-989", "mrqa_squad-train-12882", "mrqa_squad-train-8215", "mrqa_squad-train-1986", "mrqa_squad-train-44452", "mrqa_squad-train-34789", "mrqa_squad-train-19248", "mrqa_squad-train-6839", "mrqa_squad-train-72969", "mrqa_squad-train-39137", "mrqa_newsqa-validation-2032", "mrqa_searchqa-validation-11392", "mrqa_searchqa-validation-12527", "mrqa_newsqa-validation-714", "mrqa_hotpotqa-validation-2732", "mrqa_searchqa-validation-15777", "mrqa_hotpotqa-validation-4543", "mrqa_naturalquestions-validation-7262", "mrqa_searchqa-validation-12715", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-198", "mrqa_hotpotqa-validation-1920", "mrqa_searchqa-validation-7140", "mrqa_hotpotqa-validation-2183", "mrqa_triviaqa-validation-7062", "mrqa_hotpotqa-validation-765", "mrqa_naturalquestions-validation-10026", "mrqa_searchqa-validation-8010", "mrqa_naturalquestions-validation-4803", "mrqa_hotpotqa-validation-4989", "mrqa_hotpotqa-validation-4433", "mrqa_searchqa-validation-13802", "mrqa_newsqa-validation-3444", "mrqa_naturalquestions-validation-468", "mrqa_searchqa-validation-9007", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-5851", "mrqa_newsqa-validation-3290", "mrqa_triviaqa-validation-1817", "mrqa_triviaqa-validation-5143", "mrqa_hotpotqa-validation-1767", "mrqa_hotpotqa-validation-5094"], "EFR": 0.96, "Overall": 0.751921875}, {"timecode": 40, "UKR": 0.78125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1081", "mrqa_hotpotqa-validation-1159", "mrqa_hotpotqa-validation-1505", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1548", "mrqa_hotpotqa-validation-1579", "mrqa_hotpotqa-validation-1597", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-1760", "mrqa_hotpotqa-validation-1767", "mrqa_hotpotqa-validation-1781", "mrqa_hotpotqa-validation-1876", "mrqa_hotpotqa-validation-1957", "mrqa_hotpotqa-validation-2047", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-224", "mrqa_hotpotqa-validation-2240", "mrqa_hotpotqa-validation-2312", "mrqa_hotpotqa-validation-2341", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-2365", "mrqa_hotpotqa-validation-2472", "mrqa_hotpotqa-validation-2476", "mrqa_hotpotqa-validation-2521", "mrqa_hotpotqa-validation-2542", "mrqa_hotpotqa-validation-2589", "mrqa_hotpotqa-validation-2664", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2788", "mrqa_hotpotqa-validation-2890", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-2981", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-3174", "mrqa_hotpotqa-validation-3220", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-331", "mrqa_hotpotqa-validation-3358", "mrqa_hotpotqa-validation-3359", "mrqa_hotpotqa-validation-338", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-346", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3821", "mrqa_hotpotqa-validation-3867", "mrqa_hotpotqa-validation-3869", "mrqa_hotpotqa-validation-388", "mrqa_hotpotqa-validation-3963", "mrqa_hotpotqa-validation-3988", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-4246", "mrqa_hotpotqa-validation-4299", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4450", "mrqa_hotpotqa-validation-462", "mrqa_hotpotqa-validation-4749", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4836", "mrqa_hotpotqa-validation-4967", "mrqa_hotpotqa-validation-497", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-5427", "mrqa_hotpotqa-validation-5458", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5624", "mrqa_hotpotqa-validation-5642", "mrqa_hotpotqa-validation-5661", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-5703", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-5794", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-674", "mrqa_hotpotqa-validation-728", "mrqa_hotpotqa-validation-731", "mrqa_hotpotqa-validation-783", "mrqa_hotpotqa-validation-80", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-855", "mrqa_naturalquestions-validation-10159", "mrqa_naturalquestions-validation-10258", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-1067", "mrqa_naturalquestions-validation-10723", "mrqa_naturalquestions-validation-1236", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-2894", "mrqa_naturalquestions-validation-3016", "mrqa_naturalquestions-validation-3048", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-3926", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-4090", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-4796", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-4869", "mrqa_naturalquestions-validation-5133", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-6460", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-6637", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-7015", "mrqa_naturalquestions-validation-7039", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-75", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-767", "mrqa_naturalquestions-validation-7806", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8420", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9323", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9569", "mrqa_naturalquestions-validation-9650", "mrqa_naturalquestions-validation-9967", "mrqa_naturalquestions-validation-997", "mrqa_naturalquestions-validation-9972", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1643", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-1724", "mrqa_newsqa-validation-1741", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2002", "mrqa_newsqa-validation-2059", "mrqa_newsqa-validation-2097", "mrqa_newsqa-validation-2117", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-2454", "mrqa_newsqa-validation-246", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-2697", "mrqa_newsqa-validation-2748", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-2934", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3021", "mrqa_newsqa-validation-3028", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3075", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-314", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3196", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3644", "mrqa_newsqa-validation-3972", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-4018", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-4060", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-513", "mrqa_newsqa-validation-539", "mrqa_newsqa-validation-613", "mrqa_newsqa-validation-698", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-779", "mrqa_searchqa-validation-10063", "mrqa_searchqa-validation-10247", "mrqa_searchqa-validation-10289", "mrqa_searchqa-validation-10304", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-11246", "mrqa_searchqa-validation-11651", "mrqa_searchqa-validation-1173", "mrqa_searchqa-validation-1190", "mrqa_searchqa-validation-12110", "mrqa_searchqa-validation-12129", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-12442", "mrqa_searchqa-validation-12576", "mrqa_searchqa-validation-12597", "mrqa_searchqa-validation-12623", "mrqa_searchqa-validation-12715", "mrqa_searchqa-validation-12740", "mrqa_searchqa-validation-12979", "mrqa_searchqa-validation-13012", "mrqa_searchqa-validation-1311", "mrqa_searchqa-validation-13110", "mrqa_searchqa-validation-13282", "mrqa_searchqa-validation-13931", "mrqa_searchqa-validation-13955", "mrqa_searchqa-validation-14017", "mrqa_searchqa-validation-14184", "mrqa_searchqa-validation-1437", "mrqa_searchqa-validation-145", "mrqa_searchqa-validation-14583", "mrqa_searchqa-validation-14849", "mrqa_searchqa-validation-15030", "mrqa_searchqa-validation-15243", "mrqa_searchqa-validation-15282", "mrqa_searchqa-validation-15555", "mrqa_searchqa-validation-15652", "mrqa_searchqa-validation-15881", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-16545", "mrqa_searchqa-validation-16889", "mrqa_searchqa-validation-2032", "mrqa_searchqa-validation-2347", "mrqa_searchqa-validation-3122", "mrqa_searchqa-validation-3243", "mrqa_searchqa-validation-3249", "mrqa_searchqa-validation-3920", "mrqa_searchqa-validation-3983", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-4555", "mrqa_searchqa-validation-4602", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-5070", "mrqa_searchqa-validation-5167", "mrqa_searchqa-validation-532", "mrqa_searchqa-validation-5324", "mrqa_searchqa-validation-5460", "mrqa_searchqa-validation-5461", "mrqa_searchqa-validation-5817", "mrqa_searchqa-validation-583", "mrqa_searchqa-validation-6319", "mrqa_searchqa-validation-6349", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-6506", "mrqa_searchqa-validation-685", "mrqa_searchqa-validation-6977", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7109", "mrqa_searchqa-validation-7616", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-7776", "mrqa_searchqa-validation-7828", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7864", "mrqa_searchqa-validation-7906", "mrqa_searchqa-validation-7932", "mrqa_searchqa-validation-8229", "mrqa_searchqa-validation-8365", "mrqa_searchqa-validation-8600", "mrqa_searchqa-validation-8648", "mrqa_searchqa-validation-8866", "mrqa_searchqa-validation-9113", "mrqa_searchqa-validation-9122", "mrqa_searchqa-validation-9123", "mrqa_searchqa-validation-9133", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-929", "mrqa_searchqa-validation-9323", "mrqa_searchqa-validation-9559", "mrqa_squad-validation-10260", "mrqa_squad-validation-10279", "mrqa_squad-validation-10413", "mrqa_squad-validation-10474", "mrqa_squad-validation-1071", "mrqa_squad-validation-1088", "mrqa_squad-validation-1138", "mrqa_squad-validation-1219", "mrqa_squad-validation-1312", "mrqa_squad-validation-1338", "mrqa_squad-validation-161", "mrqa_squad-validation-1672", "mrqa_squad-validation-1708", "mrqa_squad-validation-1808", "mrqa_squad-validation-1814", "mrqa_squad-validation-1982", "mrqa_squad-validation-2145", "mrqa_squad-validation-233", "mrqa_squad-validation-2434", "mrqa_squad-validation-2437", "mrqa_squad-validation-2458", "mrqa_squad-validation-2506", "mrqa_squad-validation-2609", "mrqa_squad-validation-2888", "mrqa_squad-validation-3086", "mrqa_squad-validation-3196", "mrqa_squad-validation-3207", "mrqa_squad-validation-3415", "mrqa_squad-validation-350", "mrqa_squad-validation-3551", "mrqa_squad-validation-356", "mrqa_squad-validation-3575", "mrqa_squad-validation-3752", "mrqa_squad-validation-3865", "mrqa_squad-validation-3883", "mrqa_squad-validation-3953", "mrqa_squad-validation-4117", "mrqa_squad-validation-4162", "mrqa_squad-validation-4232", "mrqa_squad-validation-4294", "mrqa_squad-validation-4316", "mrqa_squad-validation-434", "mrqa_squad-validation-4341", "mrqa_squad-validation-4348", "mrqa_squad-validation-4356", "mrqa_squad-validation-447", "mrqa_squad-validation-4473", "mrqa_squad-validation-4562", "mrqa_squad-validation-4666", "mrqa_squad-validation-4783", "mrqa_squad-validation-4795", "mrqa_squad-validation-4857", "mrqa_squad-validation-4921", "mrqa_squad-validation-4965", "mrqa_squad-validation-5001", "mrqa_squad-validation-5098", "mrqa_squad-validation-5167", "mrqa_squad-validation-5303", "mrqa_squad-validation-5310", "mrqa_squad-validation-5318", "mrqa_squad-validation-5374", "mrqa_squad-validation-5389", "mrqa_squad-validation-5407", "mrqa_squad-validation-5590", "mrqa_squad-validation-5630", "mrqa_squad-validation-5638", "mrqa_squad-validation-566", "mrqa_squad-validation-5758", "mrqa_squad-validation-5844", "mrqa_squad-validation-5846", "mrqa_squad-validation-5889", "mrqa_squad-validation-5978", "mrqa_squad-validation-6025", "mrqa_squad-validation-603", "mrqa_squad-validation-6072", "mrqa_squad-validation-6113", "mrqa_squad-validation-6196", "mrqa_squad-validation-6286", "mrqa_squad-validation-6316", "mrqa_squad-validation-6361", "mrqa_squad-validation-6393", "mrqa_squad-validation-6408", "mrqa_squad-validation-6511", "mrqa_squad-validation-6645", "mrqa_squad-validation-6658", "mrqa_squad-validation-6690", "mrqa_squad-validation-7144", "mrqa_squad-validation-7303", "mrqa_squad-validation-7428", "mrqa_squad-validation-7457", "mrqa_squad-validation-7459", "mrqa_squad-validation-7474", "mrqa_squad-validation-7571", "mrqa_squad-validation-7632", "mrqa_squad-validation-7852", "mrqa_squad-validation-7867", "mrqa_squad-validation-7961", "mrqa_squad-validation-806", "mrqa_squad-validation-8227", "mrqa_squad-validation-8421", "mrqa_squad-validation-8436", "mrqa_squad-validation-8576", "mrqa_squad-validation-8602", "mrqa_squad-validation-8647", "mrqa_squad-validation-8747", "mrqa_squad-validation-8761", "mrqa_squad-validation-8910", "mrqa_squad-validation-8910", "mrqa_squad-validation-8971", "mrqa_squad-validation-901", "mrqa_squad-validation-9022", "mrqa_squad-validation-9029", "mrqa_squad-validation-9085", "mrqa_squad-validation-9226", "mrqa_squad-validation-9286", "mrqa_squad-validation-9333", "mrqa_squad-validation-9360", "mrqa_squad-validation-9411", "mrqa_squad-validation-9740", "mrqa_squad-validation-9750", "mrqa_squad-validation-9818", "mrqa_squad-validation-9895", "mrqa_triviaqa-validation-1311", "mrqa_triviaqa-validation-1318", "mrqa_triviaqa-validation-1336", "mrqa_triviaqa-validation-1360", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1475", "mrqa_triviaqa-validation-1566", "mrqa_triviaqa-validation-1603", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1817", "mrqa_triviaqa-validation-1841", "mrqa_triviaqa-validation-1868", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-2045", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-2242", "mrqa_triviaqa-validation-2335", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-2523", "mrqa_triviaqa-validation-2624", "mrqa_triviaqa-validation-2883", "mrqa_triviaqa-validation-2974", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-3095", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-3313", "mrqa_triviaqa-validation-3488", "mrqa_triviaqa-validation-3650", "mrqa_triviaqa-validation-380", "mrqa_triviaqa-validation-3939", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-3999", "mrqa_triviaqa-validation-4182", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-4317", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-4397", "mrqa_triviaqa-validation-4426", "mrqa_triviaqa-validation-4534", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-4611", "mrqa_triviaqa-validation-4647", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-5172", "mrqa_triviaqa-validation-5208", "mrqa_triviaqa-validation-5336", "mrqa_triviaqa-validation-5394", "mrqa_triviaqa-validation-5402", "mrqa_triviaqa-validation-552", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-5603", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5750", "mrqa_triviaqa-validation-5754", "mrqa_triviaqa-validation-5898", "mrqa_triviaqa-validation-5942", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-5993", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-6269", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-6387", "mrqa_triviaqa-validation-6400", "mrqa_triviaqa-validation-6404", "mrqa_triviaqa-validation-6445", "mrqa_triviaqa-validation-6460", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-6561", "mrqa_triviaqa-validation-6564", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-6761", "mrqa_triviaqa-validation-6898", "mrqa_triviaqa-validation-6907", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-719", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-7415", "mrqa_triviaqa-validation-7519", "mrqa_triviaqa-validation-7567", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7719", "mrqa_triviaqa-validation-790", "mrqa_triviaqa-validation-822"], "OKR": 0.9140625, "KG": 0.48359375, "before_eval_results": {"predictions": ["architect or engineer", "Naples", "dengue fever", "Jefferson Davis", "Rubiks cube", "a kettledrum", "salt", "a Toxic Employee", "a hammer head", "Department of Justice", "Jimmy Doolittle", "John Brown", "anamosa", "One Hundred Years of Solitude", "Frida Kahlo", "Aziraphale", "Wodehouse", "Corsica", "(litho)", "William Pitt the Younger", "Popcorn", "Madonna", "Welterweight", "the yo-yo", "Charlotte", "\"There Is Nothin' Like A Dame\"", "Edinburgh, Scotland", "penicillin", "center-backs", "Colorado columbine", "Italy", "kwanza", "Bob Dylan", "Nigeria", "William Jennings Bryan", "Lucinda's Secret", "a petition signed by a certain", "Chicago", "the Great Pyramid", "Herod", "Alaska", "marry", "Asia", "anaphylaxis", "Peter Pan", "Kuwait", "the th", "(Tod) Hackett", "diamond", "Charlie Sheen", "The Call of the Wild", "Spain", "Cleveland Indians", "1923", "Bahrain", "El Hiero", "Hans Lippershey", "Some Sizzurp", "Larry Eustachy", "Isabella II", "Stanford", "Vicente Carrillo Leyva,", "a shortfall in their pension fund", "2018"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5239583333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.20000000000000004, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6829", "mrqa_searchqa-validation-1729", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-8907", "mrqa_searchqa-validation-4950", "mrqa_searchqa-validation-8166", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-7034", "mrqa_searchqa-validation-2943", "mrqa_searchqa-validation-58", "mrqa_searchqa-validation-11346", "mrqa_searchqa-validation-846", "mrqa_searchqa-validation-16742", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-13271", "mrqa_searchqa-validation-11968", "mrqa_searchqa-validation-57", "mrqa_searchqa-validation-13046", "mrqa_searchqa-validation-327", "mrqa_searchqa-validation-8632", "mrqa_searchqa-validation-15643", "mrqa_searchqa-validation-13067", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-12335", "mrqa_searchqa-validation-14691", "mrqa_searchqa-validation-4305", "mrqa_searchqa-validation-3504", "mrqa_searchqa-validation-11661", "mrqa_searchqa-validation-13771", "mrqa_searchqa-validation-5758", "mrqa_searchqa-validation-15319", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-6197", "mrqa_triviaqa-validation-6424", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-4568", "mrqa_newsqa-validation-3554"], "SR": 0.421875, "CSR": 0.5678353658536586, "retrieved_ids": ["mrqa_squad-train-9985", "mrqa_squad-train-18984", "mrqa_squad-train-78084", "mrqa_squad-train-84657", "mrqa_squad-train-49113", "mrqa_squad-train-44753", "mrqa_squad-train-34612", "mrqa_squad-train-74941", "mrqa_squad-train-59278", "mrqa_squad-train-73882", "mrqa_squad-train-5830", "mrqa_squad-train-67179", "mrqa_squad-train-76673", "mrqa_squad-train-71712", "mrqa_squad-train-39419", "mrqa_squad-train-47973", "mrqa_squad-train-52140", "mrqa_squad-train-80945", "mrqa_squad-train-3748", "mrqa_squad-train-60802", "mrqa_squad-train-73118", "mrqa_squad-train-61526", "mrqa_squad-train-16137", "mrqa_squad-train-54115", "mrqa_squad-train-9043", "mrqa_squad-train-12169", "mrqa_squad-train-17508", "mrqa_squad-train-18238", "mrqa_squad-train-8123", "mrqa_squad-train-71819", "mrqa_squad-train-65677", "mrqa_squad-train-42624", "mrqa_squad-validation-3374", "mrqa_triviaqa-validation-1183", "mrqa_naturalquestions-validation-4995", "mrqa_hotpotqa-validation-2751", "mrqa_hotpotqa-validation-1227", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-3391", "mrqa_triviaqa-validation-4569", "mrqa_hotpotqa-validation-1922", "mrqa_naturalquestions-validation-3217", "mrqa_newsqa-validation-1899", "mrqa_triviaqa-validation-2758", "mrqa_naturalquestions-validation-4803", "mrqa_searchqa-validation-12151", "mrqa_squad-validation-2145", "mrqa_hotpotqa-validation-1025", "mrqa_searchqa-validation-9557", "mrqa_triviaqa-validation-4705", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2113", "mrqa_searchqa-validation-16233", "mrqa_triviaqa-validation-1353", "mrqa_naturalquestions-validation-8046", "mrqa_triviaqa-validation-6259", "mrqa_hotpotqa-validation-2377", "mrqa_newsqa-validation-403", "mrqa_squad-validation-9764", "mrqa_naturalquestions-validation-5036", "mrqa_naturalquestions-validation-8412", "mrqa_triviaqa-validation-1178", "mrqa_hotpotqa-validation-3975", "mrqa_triviaqa-validation-7387"], "EFR": 0.972972972972973, "Overall": 0.7439429177653263}, {"timecode": 41, "before_eval_results": {"predictions": ["$40,000", "Stockton & Darlington Railway", "aurochs/urus", "Israel", "Prince Rainier", "Charlie Harper", "Fred Astaire", "Humphrey Bogart", "honda CBR1000RR", "Alan Bartlett Shepard Jr.", "Priestley", "Smiley's", "jackstones", "Rosslyn Chapel", "Hispaniola", "zulu warriors", "blood", "Ironside", "Aristotle", "Basil Fawlty", "South Sudan", "Monday", "norway", "Secretary of State William H. Seward", "east coast", "Antoine Lavoisier", "NOW Magazine", "Tuscany", "Battle of the Alamo", "Beaujolais Nouveau", "Edmund Cartwright", "Stern", "(died May 30, 1640, Antwerp, Spanish Netherlands [now in Belgium)", "popes", "kippis", "Jennifer Ellison", "Wisconsin", "Sir John Barbirolli", "Eton College", "Harrods", "Charles Dickens", "(Ted) Hankey", "General Joseph W. Stilwell", "leaf", "manubrium", "Portuguese", "Guerrero", "Greece", "Ed Miliband", "commitment", "polio", "Mandate of Heaven", "in the fascia surrounding skeletal muscle", "a man with a face described as looking like the devil - two protrusions emanating from his forehead ( like horns ), eyes burning like'fire in a cave '", "Distinguished Service Cross", "Indian classical music", "1998", "11", "\"an eye for an eye,\"", "Arabic, French and English", "Schwalbe", "the owl and the Pussycat", "Seinfeld", "Cress"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6264136904761904}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-2666", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-6289", "mrqa_triviaqa-validation-2826", "mrqa_triviaqa-validation-4046", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-725", "mrqa_triviaqa-validation-2983", "mrqa_triviaqa-validation-2802", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-5810", "mrqa_triviaqa-validation-3390", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-7332", "mrqa_triviaqa-validation-837", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-4189", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-1676", "mrqa_triviaqa-validation-2154", "mrqa_triviaqa-validation-4630", "mrqa_triviaqa-validation-3086", "mrqa_naturalquestions-validation-7945", "mrqa_newsqa-validation-2336", "mrqa_searchqa-validation-11859"], "SR": 0.546875, "CSR": 0.5673363095238095, "retrieved_ids": ["mrqa_squad-train-1203", "mrqa_squad-train-6845", "mrqa_squad-train-72852", "mrqa_squad-train-61678", "mrqa_squad-train-64145", "mrqa_squad-train-78582", "mrqa_squad-train-25212", "mrqa_squad-train-21193", "mrqa_squad-train-63927", "mrqa_squad-train-76821", "mrqa_squad-train-59827", "mrqa_squad-train-29652", "mrqa_squad-train-73833", "mrqa_squad-train-8476", "mrqa_squad-train-68045", "mrqa_squad-train-63462", "mrqa_squad-train-2910", "mrqa_squad-train-70822", "mrqa_squad-train-8957", "mrqa_squad-train-1491", "mrqa_squad-train-13246", "mrqa_squad-train-43696", "mrqa_squad-train-46748", "mrqa_squad-train-38578", "mrqa_squad-train-27024", "mrqa_squad-train-34664", "mrqa_squad-train-42245", "mrqa_squad-train-33635", "mrqa_squad-train-22291", "mrqa_squad-train-12618", "mrqa_squad-train-27827", "mrqa_squad-train-23684", "mrqa_newsqa-validation-3048", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4084", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-2147", "mrqa_searchqa-validation-2615", "mrqa_hotpotqa-validation-4489", "mrqa_naturalquestions-validation-7407", "mrqa_searchqa-validation-14849", "mrqa_hotpotqa-validation-1416", "mrqa_triviaqa-validation-6923", "mrqa_hotpotqa-validation-534", "mrqa_newsqa-validation-1016", "mrqa_squad-validation-3692", "mrqa_searchqa-validation-11425", "mrqa_triviaqa-validation-3095", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-8118", "mrqa_squad-validation-3192", "mrqa_searchqa-validation-14512", "mrqa_squad-validation-7457", "mrqa_hotpotqa-validation-4662", "mrqa_squad-validation-1116", "mrqa_newsqa-validation-3222", "mrqa_triviaqa-validation-5600", "mrqa_squad-validation-10273", "mrqa_searchqa-validation-13377", "mrqa_squad-validation-10386", "mrqa_hotpotqa-validation-4113", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-1730", "mrqa_triviaqa-validation-2318"], "EFR": 1.0, "Overall": 0.7492485119047618}, {"timecode": 42, "before_eval_results": {"predictions": ["Sybilla of Normandy", "beta decay", "Caleb", "George Strait", "Andrew Gold", "1983", "virtual reality simulator", "Lord Banquo / \u02c8b\u00e6\u014bkwo\u028a /, the Thane of Lochaber", "Pakistan", "October 1, 2015", "MFSK and Olivia", "Isaiah Amir Mustafa", "negotiates treaties with foreign nations, but treaties enter into force if ratified by two - thirds of the Senate", "Paracelsus", "Dan Bern and Mike Viola", "Marshall Sahlins", "Gloria", "Utah, Arizona, Wyoming, and Oroville, California", "epidermis", "1898", "1770 BC", "360", "a single, implicitly structured data item in a table", "1959", "Gunpei Yokoi", "216", "Justin Bieber", "the Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "ideology", "Gatiman", "Chinese", "Andrew Garfield", "after 5 years, it was earning $300,000,000 a year", "Gibraltar", "electron pairs", "cut off close by the hip, and under the left shoulder", "Lulu", "which the better fighters are relative to their weight ( i.e., adjusted to compensate for weight class )", "Tokyo for the 2020 Summer Olympics", "1972", "Virgil Tibbs", "Ethel Merman", "1961", "all transmissions are in clear text, and usernames, passwords, commands and data can be read by anyone able to perform packet capture ( sniffing ) on the network", "National Industrial Recovery Act ( NIRA )", "adenosine diphosphate", "General George Washington", "Barbara Eve Harris as Colonel O'Donnell", "Lake Wales", "1560s", "Johannes Gutenberg", "Wichita", "Tina Turner", "dior", "Henry John Kaiser", "Marilyn Martin", "SARS", "tax incentives", "woman who received the first-ever near-total face transplant in the United States", "over a kilometer (3,281 feet) high.", "neon", "Harry Potter & the Prisoner of Azkaban", "the ark of acacia", "Basilan"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5982966924143395}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.35294117647058826, 0.2857142857142857, 1.0, 0.0, 0.5, 1.0, 0.45454545454545453, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809525, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.16666666666666666, 1.0, 0.3888888888888889, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.14814814814814814, 0.888888888888889, 0.8, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.18181818181818182, 1.0, 1.0, 0.9090909090909091, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-6519", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-9474", "mrqa_naturalquestions-validation-8669", "mrqa_naturalquestions-validation-2334", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-10118", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-7701", "mrqa_naturalquestions-validation-4123", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-8433", "mrqa_naturalquestions-validation-3533", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-5104", "mrqa_naturalquestions-validation-3802", "mrqa_naturalquestions-validation-10386", "mrqa_triviaqa-validation-7013", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-4021", "mrqa_hotpotqa-validation-153", "mrqa_newsqa-validation-1549", "mrqa_newsqa-validation-1091", "mrqa_searchqa-validation-909", "mrqa_searchqa-validation-7408", "mrqa_newsqa-validation-3408"], "SR": 0.4375, "CSR": 0.5643168604651163, "retrieved_ids": ["mrqa_squad-train-65525", "mrqa_squad-train-85490", "mrqa_squad-train-68189", "mrqa_squad-train-33918", "mrqa_squad-train-48984", "mrqa_squad-train-68704", "mrqa_squad-train-33482", "mrqa_squad-train-7185", "mrqa_squad-train-23100", "mrqa_squad-train-45084", "mrqa_squad-train-63028", "mrqa_squad-train-3033", "mrqa_squad-train-53766", "mrqa_squad-train-50904", "mrqa_squad-train-63778", "mrqa_squad-train-18368", "mrqa_squad-train-1892", "mrqa_squad-train-83249", "mrqa_squad-train-35401", "mrqa_squad-train-80516", "mrqa_squad-train-68125", "mrqa_squad-train-28912", "mrqa_squad-train-29641", "mrqa_squad-train-69020", "mrqa_squad-train-50594", "mrqa_squad-train-62410", "mrqa_squad-train-81462", "mrqa_squad-train-28618", "mrqa_squad-train-14336", "mrqa_squad-train-42624", "mrqa_squad-train-81387", "mrqa_squad-train-83149", "mrqa_hotpotqa-validation-672", "mrqa_searchqa-validation-455", "mrqa_hotpotqa-validation-5534", "mrqa_squad-validation-8652", "mrqa_squad-validation-809", "mrqa_newsqa-validation-2709", "mrqa_searchqa-validation-4533", "mrqa_triviaqa-validation-1518", "mrqa_naturalquestions-validation-4885", "mrqa_searchqa-validation-2499", "mrqa_triviaqa-validation-4317", "mrqa_squad-validation-7207", "mrqa_triviaqa-validation-5093", "mrqa_hotpotqa-validation-2425", "mrqa_squad-validation-6108", "mrqa_hotpotqa-validation-2327", "mrqa_newsqa-validation-2939", "mrqa_searchqa-validation-16742", "mrqa_searchqa-validation-5613", "mrqa_searchqa-validation-6298", "mrqa_searchqa-validation-15643", "mrqa_searchqa-validation-16595", "mrqa_hotpotqa-validation-346", "mrqa_newsqa-validation-1836", "mrqa_hotpotqa-validation-4294", "mrqa_triviaqa-validation-3215", "mrqa_naturalquestions-validation-1003", "mrqa_squad-validation-8452", "mrqa_searchqa-validation-8691", "mrqa_searchqa-validation-3385", "mrqa_searchqa-validation-15378", "mrqa_searchqa-validation-16447"], "EFR": 0.9722222222222222, "Overall": 0.7430890665374676}, {"timecode": 43, "before_eval_results": {"predictions": ["article 30", "coffee", "Sheffield United", "Google", "Wat Tyler", "dale evans", "Scotland", "Earth", "James Hogg", "Texas", "lincoln", "Pears soap", "the Czech Republic", "Louis XVI", "martin buren", "fifty-three", "neptune", "Xenophon", "chord", "Chubby Checker", "Separate Tables", "Wilson", "luster", "stephen", "delaware", "eukharisti\u0101", "baseball", "Bear Grylls", "jaws", "Tanzania", "Val Doonican", "tittle", "e. T. A. Hoffmann", "Republic of Upper Volta", "Robert Wright", "elephant", "the United States", "New Zealand", "Mendip Hills", "graffiti", "Jane Austen", "God bless America, My home sweet home", "trademark", "boxing", "british", "The Jungle Book", "(The Great Leap)", "Jan van Eyck", "Prime Minister Yitzhak Rabin", "Shania Twain", "john Nash", "electron donors", "`` It Ain't Over'til It's Over ''", "used as a pH indicator, a color marker", "Nicolas Winding Refn", "private liberal arts college", "Elvis' Christmas Album", "the coalition seeks to reduce tension between its military forces and Afghan civilians in an effort to maintain Afghan public support.", "Robert Park", "21", "Cairo", "Jackson Pollock", "moose", "tax"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6483469202898551}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.2608695652173913, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3732", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-4232", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2611", "mrqa_triviaqa-validation-5296", "mrqa_triviaqa-validation-5923", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-5307", "mrqa_triviaqa-validation-532", "mrqa_triviaqa-validation-4458", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-4759", "mrqa_triviaqa-validation-3105", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-7849", "mrqa_hotpotqa-validation-501", "mrqa_newsqa-validation-2862", "mrqa_newsqa-validation-1305", "mrqa_searchqa-validation-15709", "mrqa_newsqa-validation-1551"], "SR": 0.59375, "CSR": 0.5649857954545454, "retrieved_ids": ["mrqa_squad-train-63195", "mrqa_squad-train-17789", "mrqa_squad-train-677", "mrqa_squad-train-100", "mrqa_squad-train-60731", "mrqa_squad-train-70414", "mrqa_squad-train-55026", "mrqa_squad-train-7111", "mrqa_squad-train-83605", "mrqa_squad-train-6670", "mrqa_squad-train-4214", "mrqa_squad-train-86490", "mrqa_squad-train-41843", "mrqa_squad-train-43628", "mrqa_squad-train-44266", "mrqa_squad-train-43400", "mrqa_squad-train-20971", "mrqa_squad-train-14859", "mrqa_squad-train-38849", "mrqa_squad-train-18203", "mrqa_squad-train-74918", "mrqa_squad-train-55965", "mrqa_squad-train-60648", "mrqa_squad-train-40172", "mrqa_squad-train-72304", "mrqa_squad-train-52094", "mrqa_squad-train-40496", "mrqa_squad-train-30737", "mrqa_squad-train-62690", "mrqa_squad-train-52800", "mrqa_squad-train-25526", "mrqa_squad-train-22847", "mrqa_newsqa-validation-466", "mrqa_naturalquestions-validation-997", "mrqa_newsqa-validation-4060", "mrqa_triviaqa-validation-1676", "mrqa_naturalquestions-validation-3930", "mrqa_newsqa-validation-2709", "mrqa_newsqa-validation-1741", "mrqa_squad-validation-2318", "mrqa_squad-validation-3635", "mrqa_newsqa-validation-3106", "mrqa_searchqa-validation-10873", "mrqa_squad-validation-9761", "mrqa_searchqa-validation-9529", "mrqa_squad-validation-1092", "mrqa_naturalquestions-validation-3016", "mrqa_searchqa-validation-7896", "mrqa_newsqa-validation-1386", "mrqa_triviaqa-validation-3215", "mrqa_naturalquestions-validation-3300", "mrqa_squad-validation-1572", "mrqa_naturalquestions-validation-2572", "mrqa_searchqa-validation-13046", "mrqa_hotpotqa-validation-4441", "mrqa_naturalquestions-validation-6998", "mrqa_newsqa-validation-1664", "mrqa_searchqa-validation-8907", "mrqa_hotpotqa-validation-3669", "mrqa_hotpotqa-validation-4038", "mrqa_triviaqa-validation-2919", "mrqa_triviaqa-validation-3676", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-10386"], "EFR": 1.0, "Overall": 0.7487784090909091}, {"timecode": 44, "before_eval_results": {"predictions": ["1994\u20131999", "Aamir Khan", "Euripides", "Alfonso Cuar\u00f3n", "2013", "in Austria, south Germany, German Switzerland, and Slovenia at the end of the 18th century", "June 24, 1935", "Frederick Martin \"Fred\" Mac Murray", "Kauffman Stadium", "concentration camp", "2013\u201314 Premier League", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "from 1995 to 2012", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "Rothschild", "China", "smith", "model", "alternate uniform", "1874", "Citric acid", "North Dakota and Minnesota to the south", "David Edward Williams, OBE", "Zambia", "The Sun", "Christopher Tin", "Saint Louis County", "Chesley Burnett \"Sully\" Sullenberger III", "Francis", "1909 Cuban-American Major League Clubs Series", "Cleveland Browns", "a coaxial cable with RCA connectors or a fibre optic cable with TOSLINK connectors", "Dutch", "Battle of Prome", "35,000", "eastern shore of the Firth of Clyde, Scotland", "first and only U.S. born world grand prix champion", "2015", "19th District", "luchadora\" \"enmascarada\"", "Lev Ivanovich Yashin", "Carrefour", "John Monash", "Benjam\u00edn Arellano F\u00e9lix", "Bank of China Tower", "first Spanish conquistadors in the region of North America now known as Texas", "Chickamauga Wars", "9", "Merv", "Gatwick Airport", "200,000", "2,140 kilometres ( 1,330 mi )", "Highlands County, Florida", "honey bees", "squash", "Chicago", "soybean", "Nineteen", "How I Met Your Mother", "caused sections of the roof to collapse.", "Everest", "I.M. Pei", "\"The Lady with the Lamp\"", "the Citadel"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6577317290552585}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, false, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, false, false, true, true, false, false, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0909090909090909, 1.0, 1.0, 1.0, 0.6, 0.0, 1.0, 0.28571428571428575, 0.0, 0.8, 1.0, 1.0, 0.5714285714285715, 0.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1050", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-3995", "mrqa_hotpotqa-validation-1321", "mrqa_hotpotqa-validation-4064", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-1383", "mrqa_hotpotqa-validation-3360", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-3554", "mrqa_hotpotqa-validation-3729", "mrqa_hotpotqa-validation-1052", "mrqa_hotpotqa-validation-800", "mrqa_hotpotqa-validation-2581", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-1257", "mrqa_hotpotqa-validation-655", "mrqa_hotpotqa-validation-189", "mrqa_hotpotqa-validation-4754", "mrqa_hotpotqa-validation-2715", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-10098", "mrqa_naturalquestions-validation-8186", "mrqa_newsqa-validation-2766", "mrqa_searchqa-validation-9156", "mrqa_searchqa-validation-16341"], "SR": 0.546875, "CSR": 0.5645833333333333, "retrieved_ids": ["mrqa_squad-train-86502", "mrqa_squad-train-40255", "mrqa_squad-train-15469", "mrqa_squad-train-44883", "mrqa_squad-train-84750", "mrqa_squad-train-24696", "mrqa_squad-train-64633", "mrqa_squad-train-8233", "mrqa_squad-train-16825", "mrqa_squad-train-78169", "mrqa_squad-train-3686", "mrqa_squad-train-86056", "mrqa_squad-train-44278", "mrqa_squad-train-1527", "mrqa_squad-train-3425", "mrqa_squad-train-34845", "mrqa_squad-train-294", "mrqa_squad-train-54613", "mrqa_squad-train-47851", "mrqa_squad-train-86161", "mrqa_squad-train-38827", "mrqa_squad-train-11534", "mrqa_squad-train-32648", "mrqa_squad-train-42843", "mrqa_squad-train-13539", "mrqa_squad-train-61585", "mrqa_squad-train-22507", "mrqa_squad-train-39807", "mrqa_squad-train-75812", "mrqa_squad-train-28235", "mrqa_squad-train-28337", "mrqa_squad-train-83895", "mrqa_squad-validation-6113", "mrqa_newsqa-validation-2525", "mrqa_naturalquestions-validation-6237", "mrqa_triviaqa-validation-2474", "mrqa_triviaqa-validation-4320", "mrqa_newsqa-validation-1247", "mrqa_searchqa-validation-60", "mrqa_triviaqa-validation-6939", "mrqa_triviaqa-validation-3950", "mrqa_hotpotqa-validation-2341", "mrqa_naturalquestions-validation-3499", "mrqa_triviaqa-validation-5194", "mrqa_searchqa-validation-5460", "mrqa_naturalquestions-validation-1400", "mrqa_newsqa-validation-1899", "mrqa_triviaqa-validation-6746", "mrqa_squad-validation-1092", "mrqa_squad-validation-7382", "mrqa_naturalquestions-validation-2894", "mrqa_hotpotqa-validation-4181", "mrqa_triviaqa-validation-2357", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-674", "mrqa_squad-validation-10427", "mrqa_searchqa-validation-11968", "mrqa_squad-validation-2717", "mrqa_naturalquestions-validation-5624", "mrqa_searchqa-validation-9559", "mrqa_triviaqa-validation-5978", "mrqa_naturalquestions-validation-688", "mrqa_squad-validation-2098", "mrqa_hotpotqa-validation-4298"], "EFR": 0.9655172413793104, "Overall": 0.7418013649425287}, {"timecode": 45, "before_eval_results": {"predictions": ["Islam", "Spain", "jonathan", "Oklahoma City", "insulin", "frenchie", "John Mortimer", "John Walsh", "Moldova", "Mnemosyne", "London", "Profumo Affair", "duke of Westminster", "The Lion King", "perfumer", "Wyoming", "british", "Oasis", "Javier Bardem", "8", "Lee Harvey Oswald", "virtual", "Sherlock Holmes", "fc Bayern", "rotherham United", "Passover", "bobby Kennedy", "Britannica", "d\u00e3o", "Rhine", "Confucius", "Japan", "Winklevi(i)", "London", "Christian Dior", "Phoenicia", "(C) Bobby Moore", "Changing Places", "Jerez de la Frontera", "plac\u0113b\u014d", "LORD MUTUAL FRIend", "porto", "marketing", "smith", "rochdale", "Portuguese", "Madagascar", "Tallinn", "Monopoly", "myxomatosis", "Ceylon", "8.7 %", "in a wide surrounding area, in the Georgia counties of Newton ( where Covington is located ), Rockdale, Walton, Morgan, and Jasper", "mid-size four - wheel drive luxury Volvo", "Denmark", "eastern India", "World Famous Gold & Silver Pawn Shop", "1957", "Tim Masters,", "South Africa", "teeth", "ABBA", "Phoenician", "New York Giants"], "metric_results": {"EM": 0.5, "QA-F1": 0.5620631720430108}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, true, false, true, false, false, true, false, true, false, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, false, true, true, false, false, false, false, false, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8387096774193548, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-5370", "mrqa_triviaqa-validation-4940", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-3437", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-2324", "mrqa_triviaqa-validation-6095", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-4976", "mrqa_triviaqa-validation-3970", "mrqa_triviaqa-validation-5064", "mrqa_triviaqa-validation-6828", "mrqa_triviaqa-validation-2186", "mrqa_triviaqa-validation-2776", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-4034", "mrqa_triviaqa-validation-3756", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-10353", "mrqa_naturalquestions-validation-1586", "mrqa_hotpotqa-validation-4222", "mrqa_newsqa-validation-3710", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-593", "mrqa_searchqa-validation-5528", "mrqa_searchqa-validation-4760"], "SR": 0.5, "CSR": 0.5631793478260869, "retrieved_ids": ["mrqa_squad-train-23766", "mrqa_squad-train-76862", "mrqa_squad-train-21251", "mrqa_squad-train-44200", "mrqa_squad-train-65873", "mrqa_squad-train-7232", "mrqa_squad-train-61747", "mrqa_squad-train-20797", "mrqa_squad-train-80188", "mrqa_squad-train-41062", "mrqa_squad-train-65284", "mrqa_squad-train-28780", "mrqa_squad-train-14154", "mrqa_squad-train-67134", "mrqa_squad-train-14042", "mrqa_squad-train-22155", "mrqa_squad-train-5834", "mrqa_squad-train-42000", "mrqa_squad-train-68489", "mrqa_squad-train-28802", "mrqa_squad-train-5149", "mrqa_squad-train-64403", "mrqa_squad-train-18716", "mrqa_squad-train-56362", "mrqa_squad-train-84434", "mrqa_squad-train-70672", "mrqa_squad-train-73911", "mrqa_squad-train-73021", "mrqa_squad-train-50857", "mrqa_squad-train-34369", "mrqa_squad-train-36031", "mrqa_squad-train-62421", "mrqa_triviaqa-validation-6212", "mrqa_newsqa-validation-2032", "mrqa_squad-validation-1404", "mrqa_searchqa-validation-12243", "mrqa_hotpotqa-validation-3408", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-719", "mrqa_searchqa-validation-8607", "mrqa_naturalquestions-validation-5017", "mrqa_searchqa-validation-12752", "mrqa_triviaqa-validation-7349", "mrqa_hotpotqa-validation-3937", "mrqa_naturalquestions-validation-4148", "mrqa_hotpotqa-validation-5590", "mrqa_hotpotqa-validation-3729", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-4092", "mrqa_triviaqa-validation-4327", "mrqa_naturalquestions-validation-4369", "mrqa_searchqa-validation-9529", "mrqa_hotpotqa-validation-3737", "mrqa_squad-validation-3497", "mrqa_newsqa-validation-2934", "mrqa_naturalquestions-validation-1904", "mrqa_searchqa-validation-7782", "mrqa_triviaqa-validation-6091", "mrqa_squad-validation-3635", "mrqa_searchqa-validation-15174", "mrqa_hotpotqa-validation-4436", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-5070", "mrqa_naturalquestions-validation-6577"], "EFR": 0.9375, "Overall": 0.7359171195652173}, {"timecode": 46, "before_eval_results": {"predictions": ["several", "Mattel", "stromatolites", "Rugby School", "a modem", "Clinton", "George Herbert Walker Bush", "Penn State", "Thebes", "Vladimir Putin", "a serpent", "Mending Wall", "wombat", "a crystal", "thunder", "Josephine", "The Three Musketeers", "the iTunes Store", "Neptune", "Annie", "The Comedy of Humours", "KLM", "Captain America", "Hugh Jackman", "the retina", "a goat", "Planet of the Apes", "a knish", "British", "Reading Railroad", "\"the people are like water and the army is like fish\"", "pressed into rectangular blocks then rolled in a mildly-spicy coating", "the Justice Department", "Yes I Am", "Ignace Jan Paderewski", "Jon of the Clue Crew", "Charles Schulz", "the Chesapeake Bay", "Frida Kahlo", "Jane Austen", "Rikki-tikki-Tavi", "a mutual fund", "polygons", "Tennessee", "lime", "a bear", "Tiananmen Square", "The Oresteia", "Sugar Smacks", "Baltimore", "the (Miami) Dolphins", "Thomas Mundy Peterson", "USS Chesapeake", "From 1900", "george terrier", "alligators", "sneaker", "London", "John Snow", "Ghana's", "Thai soldiers had not gone anywhere they were not permitted to be.", "Pakistan intelligence institutions and its army", "Tuesday", "1955"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6079516045548654}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.9565217391304348, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5523", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-230", "mrqa_searchqa-validation-4878", "mrqa_searchqa-validation-15410", "mrqa_searchqa-validation-9307", "mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-8030", "mrqa_searchqa-validation-2851", "mrqa_searchqa-validation-13179", "mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-9246", "mrqa_searchqa-validation-8593", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-7238", "mrqa_searchqa-validation-14169", "mrqa_searchqa-validation-370", "mrqa_searchqa-validation-6124", "mrqa_searchqa-validation-14944", "mrqa_searchqa-validation-2212", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-12880", "mrqa_searchqa-validation-5255", "mrqa_naturalquestions-validation-4341", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-3147", "mrqa_hotpotqa-validation-4185", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-1216"], "SR": 0.546875, "CSR": 0.5628324468085106, "retrieved_ids": ["mrqa_squad-train-84592", "mrqa_squad-train-61465", "mrqa_squad-train-11813", "mrqa_squad-train-622", "mrqa_squad-train-47396", "mrqa_squad-train-76735", "mrqa_squad-train-22486", "mrqa_squad-train-75405", "mrqa_squad-train-21660", "mrqa_squad-train-58449", "mrqa_squad-train-49491", "mrqa_squad-train-62726", "mrqa_squad-train-75013", "mrqa_squad-train-60337", "mrqa_squad-train-9953", "mrqa_squad-train-84541", "mrqa_squad-train-23175", "mrqa_squad-train-28348", "mrqa_squad-train-59069", "mrqa_squad-train-28954", "mrqa_squad-train-16653", "mrqa_squad-train-34273", "mrqa_squad-train-24224", "mrqa_squad-train-33643", "mrqa_squad-train-57062", "mrqa_squad-train-17263", "mrqa_squad-train-37565", "mrqa_squad-train-8450", "mrqa_squad-train-17461", "mrqa_squad-train-78650", "mrqa_squad-train-7726", "mrqa_squad-train-57646", "mrqa_triviaqa-validation-5993", "mrqa_triviaqa-validation-1076", "mrqa_naturalquestions-validation-8444", "mrqa_newsqa-validation-3408", "mrqa_triviaqa-validation-376", "mrqa_newsqa-validation-1443", "mrqa_squad-validation-8238", "mrqa_squad-validation-4210", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-13651", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-1227", "mrqa_naturalquestions-validation-4803", "mrqa_searchqa-validation-929", "mrqa_hotpotqa-validation-577", "mrqa_triviaqa-validation-4320", "mrqa_hotpotqa-validation-4113", "mrqa_searchqa-validation-7140", "mrqa_squad-validation-1092", "mrqa_naturalquestions-validation-3961", "mrqa_squad-validation-2717", "mrqa_hotpotqa-validation-3182", "mrqa_triviaqa-validation-2147", "mrqa_hotpotqa-validation-1865", "mrqa_searchqa-validation-9551", "mrqa_newsqa-validation-1212", "mrqa_naturalquestions-validation-801", "mrqa_hotpotqa-validation-718", "mrqa_triviaqa-validation-7332", "mrqa_naturalquestions-validation-2606", "mrqa_squad-validation-1504", "mrqa_newsqa-validation-3444"], "EFR": 0.9655172413793104, "Overall": 0.7414511876375641}, {"timecode": 47, "before_eval_results": {"predictions": ["Koke'e", "the Lord Mayor", "Shel Silverstein", "beers", "trolley", "Liverpool", "Mount Rushmore", "Cyrus", "Greece", "Jim Bunning", "John Fogerty", "the Starfighter", "a woofer", "Cubism", "Dune", "the Panama Canal", "Eragon", "vacuum tubes", "drug and alcohol", "the Darfur region", "bicentennial", "midway", "Gershwin", "alpacas", "Earhart", "Heredity", "Bicentennial Man", "rod", "heart attack", "Jodie Foster", "Ivan the Terrible", "Flav", "Fulgencio Batista", "The Indianapolis 500", "the twist", "(Rabbie) Burns", "a cuckoos", "London", "beetles", "Joan of Arc", "palindrome", "quid", "Vanilla Ice", "Saturday Night Live", "Steinbeck", "Eric Knight", "Heroes", "the Ganges", "Thomas Mann", "The First Chronicles", "Sing Sing", "Rajendra Prasad", "August 18, 1945", "an edited version of a film ( or television episode, music video, commercial, or video game ) that is supposed to represent the director's own approved edit", "british", "Otto", "jonathan", "Lord's Resistance Army", "the plant \"Lawsonia inermis\"", "Netflix", "immediate release", "Casa de Campo International Airport", "July", "period dependent"], "metric_results": {"EM": 0.625, "QA-F1": 0.7198948620823621}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 0.22222222222222218, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 1.0, 0.4, 0.7692307692307693, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14149", "mrqa_searchqa-validation-15469", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-11991", "mrqa_searchqa-validation-13367", "mrqa_searchqa-validation-12232", "mrqa_searchqa-validation-10161", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-10425", "mrqa_searchqa-validation-5717", "mrqa_searchqa-validation-8106", "mrqa_searchqa-validation-2258", "mrqa_searchqa-validation-2691", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-3342", "mrqa_triviaqa-validation-7151", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-344", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-2504", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-3958", "mrqa_hotpotqa-validation-741"], "SR": 0.625, "CSR": 0.5641276041666667, "retrieved_ids": ["mrqa_squad-train-79173", "mrqa_squad-train-75687", "mrqa_squad-train-77644", "mrqa_squad-train-51478", "mrqa_squad-train-69707", "mrqa_squad-train-34321", "mrqa_squad-train-10160", "mrqa_squad-train-55829", "mrqa_squad-train-57060", "mrqa_squad-train-44407", "mrqa_squad-train-19269", "mrqa_squad-train-20444", "mrqa_squad-train-19078", "mrqa_squad-train-67762", "mrqa_squad-train-76353", "mrqa_squad-train-81968", "mrqa_squad-train-37458", "mrqa_squad-train-79900", "mrqa_squad-train-61885", "mrqa_squad-train-82572", "mrqa_squad-train-23180", "mrqa_squad-train-1969", "mrqa_squad-train-78626", "mrqa_squad-train-3410", "mrqa_squad-train-5338", "mrqa_squad-train-54874", "mrqa_squad-train-41953", "mrqa_squad-train-83868", "mrqa_squad-train-77290", "mrqa_squad-train-2517", "mrqa_squad-train-13956", "mrqa_squad-train-11833", "mrqa_hotpotqa-validation-3381", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-5630", "mrqa_naturalquestions-validation-8118", "mrqa_newsqa-validation-1577", "mrqa_squad-validation-4901", "mrqa_naturalquestions-validation-7407", "mrqa_searchqa-validation-13377", "mrqa_searchqa-validation-11661", "mrqa_searchqa-validation-15863", "mrqa_searchqa-validation-11859", "mrqa_newsqa-validation-820", "mrqa_triviaqa-validation-5082", "mrqa_hotpotqa-validation-4181", "mrqa_naturalquestions-validation-6637", "mrqa_searchqa-validation-5523", "mrqa_searchqa-validation-8593", "mrqa_squad-validation-3207", "mrqa_squad-validation-6113", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-4288", "mrqa_searchqa-validation-11471", "mrqa_naturalquestions-validation-7608", "mrqa_hotpotqa-validation-674", "mrqa_naturalquestions-validation-10114", "mrqa_triviaqa-validation-1076", "mrqa_searchqa-validation-6833", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16447", "mrqa_newsqa-validation-3444", "mrqa_hotpotqa-validation-2341", "mrqa_searchqa-validation-9255"], "EFR": 0.9583333333333334, "Overall": 0.7402734375}, {"timecode": 48, "before_eval_results": {"predictions": ["Jaws 2", "Eva Mendes", "Elizabeth Taylor", "James Patterson", "The Incredibles", "a Cheetah", "Charlie Brown", "Odin", "Japan", "sea-Monkeys", "a cloud", "Hard Drive Life", "Neil Simon", "Voyager", "a gull", "Nez Perce", "Eva Peron", "incense", "the Hawkeyes", "Ivica Zubac", "Swiffer", "Huckleberry Hound", "Austria", "Jason Bourne", "Brazil", "The Trojan War", "atolls", "the Colosseum", "Cambodia", "Dr. Hook & the Medicine Show", "Songs of Innocence", "Uvula", "extreme", "Benoni", "Scrubs", "Cheyenne", "the Black Sea", "George", "Frank Sinatra", "Zambezi", "tea", "Exodus To Exile", "The Police", "Jamestown", "American funk rock band", "Robert Ford", "St. Francis of Assisi", "Lemon Meringue pie", "Hugh Williams", "Tarzan & Jane", "Brett Favre", "1919", "eight years", "Taron Egerton", "crimson tide", "Stieg Larsson", "Measure for Measure and All's Well that Ends Well", "Tomasz Adamek", "The Thomas Crown Affair", "1866", "new materials -- including ultra-high-strength steel and boron", "India", "EU naval force", "ruritania"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7144886363636364}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16827", "mrqa_searchqa-validation-6724", "mrqa_searchqa-validation-9800", "mrqa_searchqa-validation-16623", "mrqa_searchqa-validation-9001", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-16716", "mrqa_searchqa-validation-14611", "mrqa_searchqa-validation-4185", "mrqa_searchqa-validation-14290", "mrqa_searchqa-validation-2130", "mrqa_searchqa-validation-2673", "mrqa_searchqa-validation-8513", "mrqa_searchqa-validation-2516", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-15716", "mrqa_searchqa-validation-15578", "mrqa_searchqa-validation-2929", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-6041", "mrqa_newsqa-validation-455"], "SR": 0.671875, "CSR": 0.5663265306122449, "retrieved_ids": ["mrqa_squad-train-30260", "mrqa_squad-train-55118", "mrqa_squad-train-40499", "mrqa_squad-train-85635", "mrqa_squad-train-46131", "mrqa_squad-train-81728", "mrqa_squad-train-44857", "mrqa_squad-train-34944", "mrqa_squad-train-50451", "mrqa_squad-train-61378", "mrqa_squad-train-83422", "mrqa_squad-train-63902", "mrqa_squad-train-68148", "mrqa_squad-train-11237", "mrqa_squad-train-53739", "mrqa_squad-train-12871", "mrqa_squad-train-14311", "mrqa_squad-train-13088", "mrqa_squad-train-60812", "mrqa_squad-train-24793", "mrqa_squad-train-55862", "mrqa_squad-train-33510", "mrqa_squad-train-82874", "mrqa_squad-train-63749", "mrqa_squad-train-46518", "mrqa_squad-train-13990", "mrqa_squad-train-65407", "mrqa_squad-train-49865", "mrqa_squad-train-12772", "mrqa_squad-train-45016", "mrqa_squad-train-44418", "mrqa_squad-train-23484", "mrqa_triviaqa-validation-3591", "mrqa_naturalquestions-validation-3802", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-4391", "mrqa_naturalquestions-validation-4466", "mrqa_triviaqa-validation-4944", "mrqa_searchqa-validation-2105", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-7688", "mrqa_triviaqa-validation-7060", "mrqa_hotpotqa-validation-4290", "mrqa_naturalquestions-validation-4123", "mrqa_searchqa-validation-4914", "mrqa_newsqa-validation-3856", "mrqa_searchqa-validation-16595", "mrqa_naturalquestions-validation-10012", "mrqa_newsqa-validation-342", "mrqa_squad-validation-2097", "mrqa_naturalquestions-validation-7262", "mrqa_hotpotqa-validation-2715", "mrqa_searchqa-validation-9559", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-10014", "mrqa_triviaqa-validation-3326", "mrqa_squad-validation-6361", "mrqa_naturalquestions-validation-2582", "mrqa_squad-validation-4361", "mrqa_newsqa-validation-2870", "mrqa_hotpotqa-validation-3481", "mrqa_triviaqa-validation-7430", "mrqa_triviaqa-validation-730", "mrqa_triviaqa-validation-270"], "EFR": 0.9523809523809523, "Overall": 0.7395227465986395}, {"timecode": 49, "before_eval_results": {"predictions": ["1972", "stonemason's Yard", "carmen", "Isles of Scilly", "Holy Land", "feminist", "fourteen", "the kidneys", "crabapples", "Athina,", "rafa nadal", "Apollo 11", "five", "Kirk Douglas", "John Ford", "tin", "longchamp", "nihon-koku", "Ford", "joey", "Maine", "USS Missouri", "Pyrenees", "basketball", "Janis Joplin", "Stringer", "basketball", "South Africa", "peek into the fragile and wistful soul of Brian Wilson", "Ed Miliband", "Scotland", "an aeoline", "Margaret Mitchell", "Republic of Upper Volta", "johnny roft", "40", "75", "Sir Winston Churchill", "John Masefield", "Rio de Janeiro", "party of God", "Bengali", "Claire", "quetzal", "carousel", "Leicester", "Bobby Tambling", "radishes", "lister", "Downton Abbey", "a knife slightly larger than today's sgian dubh", "Garfield Sobers", "Herman Hollerith", "September 2017", "Golden Gate National Recreation Area", "Forbes", "The English Electric Canberra", "Ford", "\"pattern matching.\"", "he was one of 10 gunmen who attacked several targets in Mumbai", "a norvegicus", "tapas", "Maria Callas", "Hern\u00e1n Jorge Crespo"], "metric_results": {"EM": 0.625, "QA-F1": 0.6832465277777777}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.4444444444444445, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-5762", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-5325", "mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-62", "mrqa_triviaqa-validation-5440", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1657", "mrqa_triviaqa-validation-7720", "mrqa_naturalquestions-validation-8483", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-2457", "mrqa_newsqa-validation-3302", "mrqa_searchqa-validation-4559", "mrqa_hotpotqa-validation-3207"], "SR": 0.625, "CSR": 0.5675, "retrieved_ids": ["mrqa_squad-train-29896", "mrqa_squad-train-1294", "mrqa_squad-train-6197", "mrqa_squad-train-23773", "mrqa_squad-train-11851", "mrqa_squad-train-50017", "mrqa_squad-train-42723", "mrqa_squad-train-34023", "mrqa_squad-train-46795", "mrqa_squad-train-71046", "mrqa_squad-train-16291", "mrqa_squad-train-57182", "mrqa_squad-train-9031", "mrqa_squad-train-38392", "mrqa_squad-train-86053", "mrqa_squad-train-6328", "mrqa_squad-train-46573", "mrqa_squad-train-79714", "mrqa_squad-train-30372", "mrqa_squad-train-10041", "mrqa_squad-train-34487", "mrqa_squad-train-3251", "mrqa_squad-train-53094", "mrqa_squad-train-50366", "mrqa_squad-train-481", "mrqa_squad-train-6343", "mrqa_squad-train-79820", "mrqa_squad-train-78767", "mrqa_squad-train-67714", "mrqa_squad-train-77270", "mrqa_squad-train-57399", "mrqa_squad-train-63845", "mrqa_searchqa-validation-10014", "mrqa_hotpotqa-validation-471", "mrqa_newsqa-validation-2078", "mrqa_newsqa-validation-455", "mrqa_triviaqa-validation-2324", "mrqa_triviaqa-validation-2192", "mrqa_searchqa-validation-2212", "mrqa_searchqa-validation-13367", "mrqa_squad-validation-1092", "mrqa_searchqa-validation-7279", "mrqa_triviaqa-validation-4189", "mrqa_squad-validation-2657", "mrqa_squad-validation-4210", "mrqa_hotpotqa-validation-1052", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3021", "mrqa_squad-validation-4902", "mrqa_hotpotqa-validation-1893", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-5960", "mrqa_newsqa-validation-820", "mrqa_searchqa-validation-5329", "mrqa_newsqa-validation-1643", "mrqa_searchqa-validation-1416", "mrqa_searchqa-validation-16623", "mrqa_searchqa-validation-13016", "mrqa_squad-validation-8905", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-4710", "mrqa_naturalquestions-validation-997", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-3663"], "EFR": 0.9583333333333334, "Overall": 0.7409479166666666}, {"timecode": 50, "UKR": 0.78125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1081", "mrqa_hotpotqa-validation-1159", "mrqa_hotpotqa-validation-1321", "mrqa_hotpotqa-validation-1505", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1548", "mrqa_hotpotqa-validation-1579", "mrqa_hotpotqa-validation-1596", "mrqa_hotpotqa-validation-1657", "mrqa_hotpotqa-validation-1760", "mrqa_hotpotqa-validation-1767", "mrqa_hotpotqa-validation-1876", "mrqa_hotpotqa-validation-1957", "mrqa_hotpotqa-validation-2047", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-224", "mrqa_hotpotqa-validation-2312", "mrqa_hotpotqa-validation-2341", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-2365", "mrqa_hotpotqa-validation-2400", "mrqa_hotpotqa-validation-2472", "mrqa_hotpotqa-validation-2476", "mrqa_hotpotqa-validation-2521", "mrqa_hotpotqa-validation-2589", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2788", "mrqa_hotpotqa-validation-2890", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-2981", "mrqa_hotpotqa-validation-3022", "mrqa_hotpotqa-validation-307", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-3174", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-331", "mrqa_hotpotqa-validation-3358", "mrqa_hotpotqa-validation-3359", "mrqa_hotpotqa-validation-338", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3821", "mrqa_hotpotqa-validation-3869", "mrqa_hotpotqa-validation-3963", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-4246", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4450", "mrqa_hotpotqa-validation-462", "mrqa_hotpotqa-validation-464", "mrqa_hotpotqa-validation-4749", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-4815", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4836", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-497", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5117", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-540", "mrqa_hotpotqa-validation-5427", "mrqa_hotpotqa-validation-5458", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5481", "mrqa_hotpotqa-validation-5553", "mrqa_hotpotqa-validation-5624", "mrqa_hotpotqa-validation-5642", "mrqa_hotpotqa-validation-5661", "mrqa_hotpotqa-validation-5667", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-5703", "mrqa_hotpotqa-validation-5794", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-674", "mrqa_hotpotqa-validation-728", "mrqa_hotpotqa-validation-731", "mrqa_hotpotqa-validation-783", "mrqa_hotpotqa-validation-80", "mrqa_naturalquestions-validation-10159", "mrqa_naturalquestions-validation-10258", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-10386", "mrqa_naturalquestions-validation-10417", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-1067", "mrqa_naturalquestions-validation-10723", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1404", "mrqa_naturalquestions-validation-1824", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2467", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3048", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-3099", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-3692", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-3959", "mrqa_naturalquestions-validation-4090", "mrqa_naturalquestions-validation-4148", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-5133", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-5851", "mrqa_naturalquestions-validation-6237", "mrqa_naturalquestions-validation-6460", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6768", "mrqa_naturalquestions-validation-6913", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7473", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-9569", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-9967", "mrqa_naturalquestions-validation-997", "mrqa_naturalquestions-validation-9972", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1643", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-1724", "mrqa_newsqa-validation-1741", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2002", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2097", "mrqa_newsqa-validation-2117", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-2236", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-246", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-2748", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-2934", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3021", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-314", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-3644", "mrqa_newsqa-validation-3972", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-513", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-613", "mrqa_newsqa-validation-698", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-732", "mrqa_searchqa-validation-10063", "mrqa_searchqa-validation-10247", "mrqa_searchqa-validation-10289", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-11651", "mrqa_searchqa-validation-1173", "mrqa_searchqa-validation-12110", "mrqa_searchqa-validation-12127", "mrqa_searchqa-validation-12129", "mrqa_searchqa-validation-12144", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-12442", "mrqa_searchqa-validation-12597", "mrqa_searchqa-validation-12623", "mrqa_searchqa-validation-12715", "mrqa_searchqa-validation-12979", "mrqa_searchqa-validation-13012", "mrqa_searchqa-validation-1311", "mrqa_searchqa-validation-13110", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-13282", "mrqa_searchqa-validation-13771", "mrqa_searchqa-validation-13931", "mrqa_searchqa-validation-13955", "mrqa_searchqa-validation-14017", "mrqa_searchqa-validation-14149", "mrqa_searchqa-validation-1418", "mrqa_searchqa-validation-14218", "mrqa_searchqa-validation-1437", "mrqa_searchqa-validation-145", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-14849", "mrqa_searchqa-validation-14910", "mrqa_searchqa-validation-14930", "mrqa_searchqa-validation-15003", "mrqa_searchqa-validation-15030", "mrqa_searchqa-validation-15243", "mrqa_searchqa-validation-15282", "mrqa_searchqa-validation-15555", "mrqa_searchqa-validation-15578", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-15643", "mrqa_searchqa-validation-15652", "mrqa_searchqa-validation-15881", "mrqa_searchqa-validation-15942", "mrqa_searchqa-validation-16187", "mrqa_searchqa-validation-1642", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-16899", "mrqa_searchqa-validation-191", "mrqa_searchqa-validation-2256", "mrqa_searchqa-validation-230", "mrqa_searchqa-validation-2347", "mrqa_searchqa-validation-2691", "mrqa_searchqa-validation-3122", "mrqa_searchqa-validation-3243", "mrqa_searchqa-validation-3920", "mrqa_searchqa-validation-4142", "mrqa_searchqa-validation-4305", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-4555", "mrqa_searchqa-validation-4602", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-4848", "mrqa_searchqa-validation-5070", "mrqa_searchqa-validation-5105", "mrqa_searchqa-validation-5167", "mrqa_searchqa-validation-5255", "mrqa_searchqa-validation-5324", "mrqa_searchqa-validation-5461", "mrqa_searchqa-validation-5528", "mrqa_searchqa-validation-5532", "mrqa_searchqa-validation-5717", "mrqa_searchqa-validation-5817", "mrqa_searchqa-validation-6319", "mrqa_searchqa-validation-6349", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-6506", "mrqa_searchqa-validation-6724", "mrqa_searchqa-validation-685", "mrqa_searchqa-validation-6977", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7087", "mrqa_searchqa-validation-7279", "mrqa_searchqa-validation-7408", "mrqa_searchqa-validation-7616", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-7785", "mrqa_searchqa-validation-7828", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7864", "mrqa_searchqa-validation-7906", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-8229", "mrqa_searchqa-validation-8365", "mrqa_searchqa-validation-846", "mrqa_searchqa-validation-8600", "mrqa_searchqa-validation-8632", "mrqa_searchqa-validation-8648", "mrqa_searchqa-validation-8866", "mrqa_searchqa-validation-9113", "mrqa_searchqa-validation-9123", "mrqa_searchqa-validation-9133", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-929", "mrqa_searchqa-validation-9323", "mrqa_searchqa-validation-9451", "mrqa_searchqa-validation-9800", "mrqa_squad-validation-10260", "mrqa_squad-validation-10279", "mrqa_squad-validation-10413", "mrqa_squad-validation-10474", "mrqa_squad-validation-1160", "mrqa_squad-validation-1219", "mrqa_squad-validation-1312", "mrqa_squad-validation-1338", "mrqa_squad-validation-161", "mrqa_squad-validation-1672", "mrqa_squad-validation-1808", "mrqa_squad-validation-1982", "mrqa_squad-validation-2145", "mrqa_squad-validation-233", "mrqa_squad-validation-2434", "mrqa_squad-validation-2437", "mrqa_squad-validation-2458", "mrqa_squad-validation-2506", "mrqa_squad-validation-2888", "mrqa_squad-validation-3196", "mrqa_squad-validation-3207", "mrqa_squad-validation-350", "mrqa_squad-validation-3575", "mrqa_squad-validation-3752", "mrqa_squad-validation-3865", "mrqa_squad-validation-3883", "mrqa_squad-validation-3953", "mrqa_squad-validation-4117", "mrqa_squad-validation-4232", "mrqa_squad-validation-4294", "mrqa_squad-validation-4316", "mrqa_squad-validation-4341", "mrqa_squad-validation-4348", "mrqa_squad-validation-4356", "mrqa_squad-validation-447", "mrqa_squad-validation-4473", "mrqa_squad-validation-4562", "mrqa_squad-validation-4666", "mrqa_squad-validation-4795", "mrqa_squad-validation-4857", "mrqa_squad-validation-4921", "mrqa_squad-validation-4965", "mrqa_squad-validation-5098", "mrqa_squad-validation-5303", "mrqa_squad-validation-5310", "mrqa_squad-validation-5389", "mrqa_squad-validation-5407", "mrqa_squad-validation-5590", "mrqa_squad-validation-5630", "mrqa_squad-validation-5638", "mrqa_squad-validation-566", "mrqa_squad-validation-5758", "mrqa_squad-validation-5844", "mrqa_squad-validation-5846", "mrqa_squad-validation-5978", "mrqa_squad-validation-6025", "mrqa_squad-validation-603", "mrqa_squad-validation-6072", "mrqa_squad-validation-6113", "mrqa_squad-validation-6196", "mrqa_squad-validation-6286", "mrqa_squad-validation-6316", "mrqa_squad-validation-6361", "mrqa_squad-validation-6393", "mrqa_squad-validation-6408", "mrqa_squad-validation-6645", "mrqa_squad-validation-6658", "mrqa_squad-validation-7144", "mrqa_squad-validation-7303", "mrqa_squad-validation-7428", "mrqa_squad-validation-7459", "mrqa_squad-validation-7474", "mrqa_squad-validation-7571", "mrqa_squad-validation-7632", "mrqa_squad-validation-7852", "mrqa_squad-validation-7867", "mrqa_squad-validation-8227", "mrqa_squad-validation-8421", "mrqa_squad-validation-8436", "mrqa_squad-validation-8576", "mrqa_squad-validation-8647", "mrqa_squad-validation-8971", "mrqa_squad-validation-901", "mrqa_squad-validation-9022", "mrqa_squad-validation-9029", "mrqa_squad-validation-9226", "mrqa_squad-validation-9286", "mrqa_squad-validation-9333", "mrqa_squad-validation-9360", "mrqa_squad-validation-9740", "mrqa_squad-validation-9750", "mrqa_squad-validation-9818", "mrqa_squad-validation-9895", "mrqa_triviaqa-validation-1259", "mrqa_triviaqa-validation-1318", "mrqa_triviaqa-validation-1360", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1475", "mrqa_triviaqa-validation-1518", "mrqa_triviaqa-validation-1603", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1817", "mrqa_triviaqa-validation-1868", "mrqa_triviaqa-validation-2045", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-2154", "mrqa_triviaqa-validation-2186", "mrqa_triviaqa-validation-2335", "mrqa_triviaqa-validation-2399", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-2624", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2883", "mrqa_triviaqa-validation-2974", "mrqa_triviaqa-validation-2980", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-3086", "mrqa_triviaqa-validation-3095", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3195", "mrqa_triviaqa-validation-3313", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-3631", "mrqa_triviaqa-validation-380", "mrqa_triviaqa-validation-3810", "mrqa_triviaqa-validation-3812", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-3999", "mrqa_triviaqa-validation-4145", "mrqa_triviaqa-validation-4172", "mrqa_triviaqa-validation-4189", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-4232", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-4426", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-4611", "mrqa_triviaqa-validation-4647", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4940", "mrqa_triviaqa-validation-5044", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-5128", "mrqa_triviaqa-validation-5172", "mrqa_triviaqa-validation-5182", "mrqa_triviaqa-validation-532", "mrqa_triviaqa-validation-5325", "mrqa_triviaqa-validation-5336", "mrqa_triviaqa-validation-5370", "mrqa_triviaqa-validation-5393", "mrqa_triviaqa-validation-5394", "mrqa_triviaqa-validation-5402", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-5464", "mrqa_triviaqa-validation-5496", "mrqa_triviaqa-validation-552", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-5603", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5720", "mrqa_triviaqa-validation-5750", "mrqa_triviaqa-validation-5898", "mrqa_triviaqa-validation-5993", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-62", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-6404", "mrqa_triviaqa-validation-6460", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-6561", "mrqa_triviaqa-validation-6564", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6786", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6898", "mrqa_triviaqa-validation-6907", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-719", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-725", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7519", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-790", "mrqa_triviaqa-validation-806", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-996"], "OKR": 0.91015625, "KG": 0.49296875, "before_eval_results": {"predictions": ["Ross Elliott", "Annette", "the 1980s", "Nodar Kumaritashvili", "Carpenter", "Dan Stevens", "human colon", "December 1886", "July 1, 1890", "March 31, 2013", "Manley", "1978", "Judiththia Aline Keppel", "BC Jean and Toby Gad", "2018 Winter Olympics", "The Walking Dead ( franchise )", "in Christian eschatology", "1962", "non-ferrous", "the state sector", "The sacroiliac joint or SI joint", "the Sunni Muslim family", "after World War II", "London", "The Massachusetts Compromise", "L.K. Advani", "30 months", "Jason Marsden", "Charles Lebrun", "Ashrita Furman", "St. Augustine renders it as clara notitia cum laude, `` brilliant celebrity with praise ''", "early 1980s", "602", "the beginning", "2013", "Diego Tinoco", "the Pearson correlation between the rank values of those two variables", "January 2004", "Glenn Close", "the roofs of the choir side - aisles at Durham Cathedral", "Johannes Gutenberg of Mainz", "Dan Stevens", "Charlotte", "Dr. Addison Montgomery", "Carolyn Sue Jones", "De pictura ( English : `` On Painting '' ) is a treatise written by the Italian architect and art theorist Leon Battista Alberti", "the Formless All - pervasive Reality, made of stone, metal, or clay", "in various submucosal membrane sites", "Article 1, Section 2, Clause 3", "the tree species ( that generally grows in the elevation range of 3,000 to 4,200 metres ( 9,800 to 13,800 ft ) in the Himalayas )", "push the food down the esophagus", "Dolly Parton", "westminster bridge", "durham", "Jack Murphy Stadium", "Black Abbots", "Prince Amedeo, 5th Duke of Aosta", "mental health", "Suba Kampong township", "2004.", "Laryngitis", "Pequod", "Calvin Coolidge", "Dan Parris, 25, and Rob Lehr, 26,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6531497131680956}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.14814814814814814, 0.1818181818181818, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.16, 0.6666666666666666, 1.0, 0.11764705882352941, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.6399999999999999, 0.14285714285714288, 0.3571428571428571, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-2743", "mrqa_naturalquestions-validation-10029", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-1301", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1090", "mrqa_naturalquestions-validation-4315", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-486", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-6901", "mrqa_naturalquestions-validation-9191", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2686", "mrqa_triviaqa-validation-7304", "mrqa_triviaqa-validation-6353", "mrqa_hotpotqa-validation-5522", "mrqa_hotpotqa-validation-1577", "mrqa_newsqa-validation-3406", "mrqa_newsqa-validation-2294"], "SR": 0.546875, "CSR": 0.5670955882352942, "retrieved_ids": ["mrqa_squad-train-25494", "mrqa_squad-train-68662", "mrqa_squad-train-62086", "mrqa_squad-train-22697", "mrqa_squad-train-30125", "mrqa_squad-train-64470", "mrqa_squad-train-60590", "mrqa_squad-train-73102", "mrqa_squad-train-22037", "mrqa_squad-train-81689", "mrqa_squad-train-82456", "mrqa_squad-train-582", "mrqa_squad-train-78073", "mrqa_squad-train-77576", "mrqa_squad-train-8494", "mrqa_squad-train-6568", "mrqa_squad-train-31067", "mrqa_squad-train-8553", "mrqa_squad-train-26368", "mrqa_squad-train-52175", "mrqa_squad-train-57607", "mrqa_squad-train-17921", "mrqa_squad-train-74248", "mrqa_squad-train-59590", "mrqa_squad-train-34792", "mrqa_squad-train-79205", "mrqa_squad-train-62906", "mrqa_squad-train-11471", "mrqa_squad-train-61614", "mrqa_squad-train-34550", "mrqa_squad-train-40358", "mrqa_squad-train-26839", "mrqa_naturalquestions-validation-6237", "mrqa_newsqa-validation-3782", "mrqa_hotpotqa-validation-5117", "mrqa_triviaqa-validation-6643", "mrqa_hotpotqa-validation-5822", "mrqa_newsqa-validation-2426", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-2266", "mrqa_triviaqa-validation-62", "mrqa_newsqa-validation-1551", "mrqa_naturalquestions-validation-8962", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-2813", "mrqa_naturalquestions-validation-5509", "mrqa_squad-validation-3922", "mrqa_triviaqa-validation-2983", "mrqa_newsqa-validation-3408", "mrqa_triviaqa-validation-2265", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-4792", "mrqa_naturalquestions-validation-3993", "mrqa_naturalquestions-validation-8619", "mrqa_searchqa-validation-5717", "mrqa_squad-validation-10386", "mrqa_naturalquestions-validation-10283", "mrqa_searchqa-validation-14514", "mrqa_searchqa-validation-5528", "mrqa_naturalquestions-validation-7935", "mrqa_newsqa-validation-4060", "mrqa_hotpotqa-validation-4290", "mrqa_triviaqa-validation-39", "mrqa_triviaqa-validation-146"], "EFR": 0.9655172413793104, "Overall": 0.7433975659229209}, {"timecode": 51, "before_eval_results": {"predictions": ["Domhnall Gleeson", "Lagaan ( English : Taxation ; also called Lagaa : Once Upon a Time in India )", "Alicia Vikander as Lara Croft, who embarks on a perilous journey to her father's last - known destination", "the person compelled to pay for reformist programs", "Scottish post-punk band Orange Juice", "1837", "Zoe Badwi, Jade Thirlwall's cousin", "22 November 1914", "Shareef Abdur - Rahim", "2018", "breast or lower chest of beef or veal", "mid - to late 1920s", "near Camarillo, California", "Lucia Iipumbu", "1994", "Exodus 20 : 1 -- 17", "prevent any contaminants in the sink from flowing into the potable water system by siphonage", "to connect the CNS to the limbs and organs", "15 February 1998", "brothers Henry, Jojo and Ringo Garza", "Thomas Alva Edison", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew", "`` Mirror Image ''", "two senators, regardless of its population", "E-2s and E-3s", "1603", "Eduardo", "a child with Treacher Collins syndrome trying to fit in", "Kansas currently has the longest streak of consecutive NCAA tournament appearances of all - time ( 29 )", "Efren Manalang Reyes, OLD, PLH ( born August 26, 1954 ), nicknamed the Magician and Bata,", "Jim Carrey", "Baseball Writers'Association of America ( or BBWAA ), or the Veterans Committee", "Herman Hollerith", "ulnar nerve", "December 18, 2017", "Brooklyn, New York", "2015, 2016", "Buddhism", "Rodney Crowell", "Atlanta", "peninsular", "2005", "chairman ( more usually now called the `` chair '' or `` chairperson '' ), who holds whatever title is specified in the bylaws or articles of association", "Germany", "Ego", "Darlene Cates", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson", "birch", "Bennett Cerf", "Bongos", "Joe Willie Kirk", "fats Domino", "Vito Corleone", "supply chain management", "House of Fraser", "Venice", "Hyundai Steel", "Gaylord Opryland", "100 percent", "New York City", "Roger Clemens", "Andrew Carnegie", "an independent homeland for the country's ethnic"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5879368434510149}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true], "QA-F1": [1.0, 0.9090909090909091, 0.47619047619047616, 1.0, 0.5714285714285715, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.6666666666666666, 0.888888888888889, 0.8, 0.0, 0.0, 1.0, 0.0, 0.5185185185185185, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666666, 0.0, 1.0, 0.0, 1.0, 0.13333333333333333, 0.375, 0.0, 0.7999999999999999, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8205128205128205, 0.9302325581395349, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-2379", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-4698", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-7489", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-5297", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8916", "mrqa_naturalquestions-validation-9608", "mrqa_naturalquestions-validation-4318", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-6069", "mrqa_naturalquestions-validation-4728", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-407", "mrqa_naturalquestions-validation-9563", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-4493", "mrqa_hotpotqa-validation-1001", "mrqa_hotpotqa-validation-1756", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-268", "mrqa_searchqa-validation-8208"], "SR": 0.421875, "CSR": 0.5643028846153846, "retrieved_ids": ["mrqa_squad-train-74698", "mrqa_squad-train-31977", "mrqa_squad-train-8885", "mrqa_squad-train-77360", "mrqa_squad-train-6784", "mrqa_squad-train-21703", "mrqa_squad-train-83365", "mrqa_squad-train-8902", "mrqa_squad-train-47436", "mrqa_squad-train-46725", "mrqa_squad-train-83554", "mrqa_squad-train-69758", "mrqa_squad-train-7936", "mrqa_squad-train-83026", "mrqa_squad-train-17919", "mrqa_squad-train-11998", "mrqa_squad-train-70816", "mrqa_squad-train-4679", "mrqa_squad-train-49077", "mrqa_squad-train-35961", "mrqa_squad-train-78283", "mrqa_squad-train-24985", "mrqa_squad-train-49241", "mrqa_squad-train-39353", "mrqa_squad-train-63352", "mrqa_squad-train-85082", "mrqa_squad-train-69742", "mrqa_squad-train-12749", "mrqa_squad-train-72788", "mrqa_squad-train-10532", "mrqa_squad-train-57463", "mrqa_squad-train-44132", "mrqa_hotpotqa-validation-4391", "mrqa_searchqa-validation-1565", "mrqa_squad-validation-5605", "mrqa_triviaqa-validation-5194", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-1416", "mrqa_searchqa-validation-11991", "mrqa_searchqa-validation-397", "mrqa_searchqa-validation-44", "mrqa_naturalquestions-validation-10273", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-5998", "mrqa_newsqa-validation-2791", "mrqa_newsqa-validation-2790", "mrqa_searchqa-validation-1640", "mrqa_hotpotqa-validation-365", "mrqa_triviaqa-validation-5591", "mrqa_searchqa-validation-4913", "mrqa_triviaqa-validation-2883", "mrqa_hotpotqa-validation-4661", "mrqa_newsqa-validation-1898", "mrqa_newsqa-validation-3106", "mrqa_naturalquestions-validation-6577", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-943", "mrqa_newsqa-validation-342", "mrqa_searchqa-validation-6095", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-10138", "mrqa_searchqa-validation-15777", "mrqa_hotpotqa-validation-1657", "mrqa_newsqa-validation-2934"], "EFR": 0.8108108108108109, "Overall": 0.7118977390852391}, {"timecode": 52, "before_eval_results": {"predictions": ["Vilnius Old Town", "Roc-A-Fella Records and Priority Records", "United States Army", "White Horse", "Qu'est-ce qu'on a fait au Bon Dieu", "created the American Land-Grant universities and colleges", "Pacific War", "1949", "The Dark Tower", "John Samuel Waters Jr.", "1945", "Sacramento Kings", "S7", "Magic Band", "Supergirl", "April 1, 1949", "Scottish Premiership club Hearts", "Standard Oil", "Bill Ponsford", "Anatoly Vasilyevich Lunacharsky", "Bobby Hurley", "Macbeth", "Brad Silberling", "1987", "Italy", "Vaisakhi List", "\"Twice in a Lifetime\"", "seventh generation", "Len Wiseman", "31 July 1975", "American college football coach", "Walldorf", "Elvis' Christmas Album", "sarod", "Keith Crofford", "Sarah Winnemucca Hopkins", "Robert Moses", "Godiva Chocolatier", "Manchester United", "The Simpsons", "Manhattan Project", "land area", "Lush Ltd.", "Telugu", "1952", "Georgia Southern University", "Restoration Hardware", "1942", "Kauffman Stadium", "Don Was", "C. H. Greenblatt", "Stephen Graham", "The former confers executive power upon the President alone, and the latter grants judicial power solely to the federal judiciary", "introverted Sensing ( Si ), Extroverted Thinking ( Te ), introverted feeling ( Fi ) and Extrovert Intuition ( Ne )", "Belgium", "The Big Bopper", "Jackson Pollock", "Damon Bankston", "about 3,000 kilometers (1,900 miles)", "Casalesi Camorra clan", "Wyatt Earp", "Scrabble", "Wendell", "an intercalary year"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7144925820707071}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.375, 1.0, 1.0, 1.0, 0.5, 0.888888888888889, 0.8, 0.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1844", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-66", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-1372", "mrqa_hotpotqa-validation-2915", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1835", "mrqa_hotpotqa-validation-305", "mrqa_hotpotqa-validation-2819", "mrqa_hotpotqa-validation-850", "mrqa_hotpotqa-validation-2532", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-1997", "mrqa_naturalquestions-validation-4714", "mrqa_naturalquestions-validation-6706", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-2641", "mrqa_searchqa-validation-7977", "mrqa_searchqa-validation-1784", "mrqa_searchqa-validation-2103"], "SR": 0.609375, "CSR": 0.5651533018867925, "retrieved_ids": ["mrqa_squad-train-4174", "mrqa_squad-train-83340", "mrqa_squad-train-6018", "mrqa_squad-train-48263", "mrqa_squad-train-65152", "mrqa_squad-train-69381", "mrqa_squad-train-12100", "mrqa_squad-train-16247", "mrqa_squad-train-72549", "mrqa_squad-train-69949", "mrqa_squad-train-68260", "mrqa_squad-train-70035", "mrqa_squad-train-55902", "mrqa_squad-train-72543", "mrqa_squad-train-3437", "mrqa_squad-train-79481", "mrqa_squad-train-59570", "mrqa_squad-train-72064", "mrqa_squad-train-47038", "mrqa_squad-train-46754", "mrqa_squad-train-12496", "mrqa_squad-train-40456", "mrqa_squad-train-13980", "mrqa_squad-train-45872", "mrqa_squad-train-42936", "mrqa_squad-train-45275", "mrqa_squad-train-69748", "mrqa_squad-train-21175", "mrqa_squad-train-59845", "mrqa_squad-train-57741", "mrqa_squad-train-35040", "mrqa_squad-train-40051", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-2976", "mrqa_naturalquestions-validation-1664", "mrqa_newsqa-validation-3021", "mrqa_searchqa-validation-10014", "mrqa_hotpotqa-validation-3787", "mrqa_squad-validation-8576", "mrqa_hotpotqa-validation-5311", "mrqa_searchqa-validation-8030", "mrqa_hotpotqa-validation-458", "mrqa_naturalquestions-validation-144", "mrqa_naturalquestions-validation-8412", "mrqa_hotpotqa-validation-1770", "mrqa_triviaqa-validation-2154", "mrqa_triviaqa-validation-2826", "mrqa_searchqa-validation-13527", "mrqa_hotpotqa-validation-4298", "mrqa_newsqa-validation-2422", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-668", "mrqa_newsqa-validation-1549", "mrqa_triviaqa-validation-5547", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-1443", "mrqa_naturalquestions-validation-4318", "mrqa_newsqa-validation-2294", "mrqa_triviaqa-validation-7460", "mrqa_triviaqa-validation-3243", "mrqa_hotpotqa-validation-5708", "mrqa_triviaqa-validation-6548", "mrqa_searchqa-validation-4914", "mrqa_hotpotqa-validation-3431"], "EFR": 1.0, "Overall": 0.7499056603773585}, {"timecode": 53, "before_eval_results": {"predictions": ["$250,000 for Rivers' charity: God's Love We Deliver.", "The cervical cancer vaccine,", "eight-day", "97", "Iran's President Mahmoud Ahmadinejad", "18", "Darrel Mohler", "Spc. Megan Lynn Touma,", "Operation Pipeline Express.", "Both Won Sei Hoon, who heads South Korea's National Intelligence Service, and Defense Minister Kim Kwan Jim", "a house party in Crandon, Wisconsin,", "Senate Sotomayor,", "Mother Nature has proven to be a challenge.", "Grand Ronde, Oregon.", "a bag", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "14-day", "the fact that the teens were charged as adults.", "Conway", "co-chair of the Genocide Prevention Task Force.", "rwanda", "Arsene Wenger", "scored a hat-trick as AC Milan went second in Serie A with a 5-1 win over Torino in the San Siro", "Genocide Prevention Task Force", "Sheik Mohammed Ali al-Moayad and Mohammed Mohsen Zayed", "\"black box\"", "Jacob Zuma,", "the return of a fallen U.S. service member", "Sporting Lisbon", "The opposition group, also known as the \"red shirts,\"", "Saturday", "social networking sites", "a member of the band for more than 40 years and co-wrote its signature song,\"The Devil Went Down to Georgia.\"", "Democratic VP candidate", "Charlotte Gainsbourg", "left Old Trafford at the end of the season.", "three", "between June 20 and July 20", "President Richard M. Nixon,", "Piedad Cordoba,", "buddhism", "Bollywood superstar", "Pakistani territory", "fight outside of an Atlanta strip club", "Larry King Live", "Sen. Barack Obama", "the game", "the man facing up, with his arms out to the side.", "stand down.", "in a muddy barley field owned by farmer Alan Graham outside Bangor,", "The ACLU", "carrying an amino acid to the protein synthetic machinery of a cell ( ribosome ) as directed by a three - nucleotide sequence ( codon ) in a messenger RNA ( mRNA )", "Bruno Mars", "2018", "surfer", "arthropylum: arthropoda", "white", "2018 governor's race", "1898", "My Beautiful Dark Twisted Fantasy", "Ned Kelly", "Beta Monocerotis", "fish", "a crust of mashed potato"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6260805714753084}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.28571428571428575, 0.5, 0.0, 1.0, 1.0, 0.9523809523809523, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.21052631578947367, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09999999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.30769230769230765, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-3144", "mrqa_newsqa-validation-2521", "mrqa_newsqa-validation-239", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2315", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-2723", "mrqa_newsqa-validation-319", "mrqa_newsqa-validation-2511", "mrqa_newsqa-validation-1806", "mrqa_newsqa-validation-2672", "mrqa_newsqa-validation-1183", "mrqa_newsqa-validation-3990", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3864", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-4128", "mrqa_newsqa-validation-1142", "mrqa_newsqa-validation-3097", "mrqa_naturalquestions-validation-3783", "mrqa_triviaqa-validation-2038", "mrqa_hotpotqa-validation-5406", "mrqa_searchqa-validation-12411", "mrqa_naturalquestions-validation-10616"], "SR": 0.546875, "CSR": 0.5648148148148149, "retrieved_ids": ["mrqa_squad-train-1477", "mrqa_squad-train-83967", "mrqa_squad-train-31714", "mrqa_squad-train-11027", "mrqa_squad-train-26848", "mrqa_squad-train-34619", "mrqa_squad-train-52684", "mrqa_squad-train-43598", "mrqa_squad-train-35132", "mrqa_squad-train-66338", "mrqa_squad-train-24400", "mrqa_squad-train-74181", "mrqa_squad-train-2278", "mrqa_squad-train-2474", "mrqa_squad-train-5468", "mrqa_squad-train-57969", "mrqa_squad-train-86108", "mrqa_squad-train-167", "mrqa_squad-train-57755", "mrqa_squad-train-52323", "mrqa_squad-train-32585", "mrqa_squad-train-11943", "mrqa_squad-train-9850", "mrqa_squad-train-53352", "mrqa_squad-train-74694", "mrqa_squad-train-21193", "mrqa_squad-train-84751", "mrqa_squad-train-43409", "mrqa_squad-train-67002", "mrqa_squad-train-80888", "mrqa_squad-train-993", "mrqa_squad-train-40632", "mrqa_naturalquestions-validation-6052", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-8106", "mrqa_squad-validation-6244", "mrqa_squad-validation-6753", "mrqa_hotpotqa-validation-5117", "mrqa_naturalquestions-validation-4318", "mrqa_searchqa-validation-9096", "mrqa_hotpotqa-validation-5174", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-12968", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-7434", "mrqa_naturalquestions-validation-6577", "mrqa_triviaqa-validation-4173", "mrqa_hotpotqa-validation-3220", "mrqa_newsqa-validation-1039", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-4874", "mrqa_triviaqa-validation-7076", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-2181", "mrqa_newsqa-validation-1319", "mrqa_newsqa-validation-2231", "mrqa_naturalquestions-validation-3930", "mrqa_triviaqa-validation-532", "mrqa_searchqa-validation-8804", "mrqa_newsqa-validation-3021", "mrqa_naturalquestions-validation-8484", "mrqa_searchqa-validation-9133", "mrqa_newsqa-validation-4060", "mrqa_naturalquestions-validation-1301"], "EFR": 0.9655172413793104, "Overall": 0.7429414112388251}, {"timecode": 54, "before_eval_results": {"predictions": ["Haikou on the Hainan Island", "Squamish, British Columbia, Canada", "2018", "2004", "the left of the dinner plate", "Ned Stark", "Tony Rydinger", "ThonMaker", "Hans Raffert", "31", "Jesse Frederick James Conaway", "an Aldabra giant tortoise", "declared neutrality and worked to broker a peace", "Number 4, Privet Drive, Little Whinging in Surrey, England", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "2018", "Malibu, California", "desublimation", "eight", "Anglo - Norman French waleis", "three mystic apes", "white blood cell", "into the intermembrane space", "Kansas", "New England Patriots", "Chesapeake Bay", "Thomas Edison", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "the body - centered cubic ( BCC ) lattice", "President Lyndon Johnson", "in a Norwegian town circa 1879", "16 best - selling religious novels by Tim LaHaye and Jerry B. Jenkins", "the topography and the dominant wind direction", "Development of Substitute Materials", "a pagan custom", "to encounter antigens passing through the mucosal epithelium", "2013", "John Garfield as Al Schmid", "the Islamic Community", "Lord Irwin", "the volume", "a constitutional right", "Robert Gillespie Adamson IV", "the end of the 18th century", "1998", "the left atrium of the heart", "Gladys Knight & the Pips", "Sir Ernest Rutherford", "Hendersonville, North Carolina", "the internal auditory canal of the temporal bone", "1803", "UPS", "The Wrestling Classic", "The Kennel Club", "Timothy Dalton", "Grammy awards", "John D Rockefeller's Standard Oil Company", "misdemeanor assault charges", "$106,482,500", "introduce legislation Thursday to improve the military's suicide-prevention programs.", "Stone Temple Pilots", "real estate investment trusts", "Hubert Humphrey", "Tim Clark, Matt Kuchar and Bubba Watson"], "metric_results": {"EM": 0.5, "QA-F1": 0.609416335978836}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.888888888888889, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.25, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.21428571428571425, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.08333333333333333, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.29629629629629634, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.25, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-309", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-3309", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-9087", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-5472", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7405", "mrqa_naturalquestions-validation-1103", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-4815", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-3174", "mrqa_naturalquestions-validation-4974", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-6727", "mrqa_triviaqa-validation-3624", "mrqa_newsqa-validation-3250", "mrqa_searchqa-validation-2971", "mrqa_searchqa-validation-3606"], "SR": 0.5, "CSR": 0.5636363636363637, "retrieved_ids": ["mrqa_squad-train-67089", "mrqa_squad-train-16438", "mrqa_squad-train-45823", "mrqa_squad-train-12057", "mrqa_squad-train-44743", "mrqa_squad-train-35672", "mrqa_squad-train-22034", "mrqa_squad-train-32405", "mrqa_squad-train-8990", "mrqa_squad-train-80640", "mrqa_squad-train-52972", "mrqa_squad-train-75009", "mrqa_squad-train-46960", "mrqa_squad-train-19861", "mrqa_squad-train-40247", "mrqa_squad-train-21020", "mrqa_squad-train-66860", "mrqa_squad-train-47955", "mrqa_squad-train-78666", "mrqa_squad-train-7175", "mrqa_squad-train-4025", "mrqa_squad-train-33482", "mrqa_squad-train-75712", "mrqa_squad-train-64259", "mrqa_squad-train-52748", "mrqa_squad-train-54111", "mrqa_squad-train-29728", "mrqa_squad-train-55801", "mrqa_squad-train-66965", "mrqa_squad-train-11797", "mrqa_squad-train-30308", "mrqa_squad-train-42281", "mrqa_hotpotqa-validation-3408", "mrqa_naturalquestions-validation-2245", "mrqa_triviaqa-validation-6761", "mrqa_naturalquestions-validation-5328", "mrqa_triviaqa-validation-5644", "mrqa_searchqa-validation-6829", "mrqa_naturalquestions-validation-801", "mrqa_hotpotqa-validation-534", "mrqa_hotpotqa-validation-4961", "mrqa_triviaqa-validation-4443", "mrqa_squad-validation-5605", "mrqa_squad-validation-8662", "mrqa_triviaqa-validation-6413", "mrqa_newsqa-validation-2336", "mrqa_naturalquestions-validation-8433", "mrqa_newsqa-validation-1114", "mrqa_squad-validation-1239", "mrqa_triviaqa-validation-5414", "mrqa_squad-validation-6449", "mrqa_triviaqa-validation-1836", "mrqa_searchqa-validation-8042", "mrqa_squad-validation-7819", "mrqa_triviaqa-validation-7360", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-4803", "mrqa_hotpotqa-validation-5101", "mrqa_naturalquestions-validation-10273", "mrqa_hotpotqa-validation-4487", "mrqa_searchqa-validation-1529", "mrqa_naturalquestions-validation-328", "mrqa_squad-validation-4621", "mrqa_triviaqa-validation-5440"], "EFR": 0.90625, "Overall": 0.7308522727272727}, {"timecode": 55, "before_eval_results": {"predictions": ["Dr. Ruth Westheimer", "John Updike", "Jeopardy", "clouds", "Jericho", "swab", "asteroids", "plankton", "In 1876, Rutherford B. Hayes won the election (by a margin of one electoral vote), but he lost the popular vote by more than 250,000 ballots to", "Eleanor Roosevelt", "the War of 1812", "Bangladesh", "The Secret", "Sudan", "Judd Apatow", "a laser", "Jamaica", "Walt Disney World", "Mexico", "Artemis", "pH", "Aladdin", "Nine to Five", "Jan & Dean", "made his enemies walk the plank", "ice cream", "Huckabee", "catherine the great", "California", "constellations", "AILD", "Kate Winslet", "Ross Perot", "the Black Sea", "C. S. Lewis", "Thomas Paine", "Back to the Future", "antelope", "Anne Boleyn", "Q'umarkaj", "Dizzy", "soup", "reasoning", "Fermi", "Moon", "suspension", "Tigger", "the breath", "a marathon", "QWERTY", "Renewal of the Covenant", "to collect menstrual flow", "13 May 1787", "nasal septum", "Triumph", "denmark", "recorder", "UFC 50: The War of '04", "newspapers, television, radio, cable television, and other businesses", "March 17, 2015", "4.6 million", "Tibetan exile leaders,", "its captain", "Geoffrey Zakarian"], "metric_results": {"EM": 0.5, "QA-F1": 0.6131725045787546}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, false, false, true], "QA-F1": [0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 0.8, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.7692307692307693, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14322", "mrqa_searchqa-validation-9438", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-8235", "mrqa_searchqa-validation-12019", "mrqa_searchqa-validation-942", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-1425", "mrqa_searchqa-validation-4506", "mrqa_searchqa-validation-12782", "mrqa_searchqa-validation-11807", "mrqa_searchqa-validation-8846", "mrqa_searchqa-validation-2969", "mrqa_searchqa-validation-6544", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-518", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-11295", "mrqa_searchqa-validation-30", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-14266", "mrqa_searchqa-validation-16953", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-2219", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4151", "mrqa_triviaqa-validation-1245", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-4855", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-2205"], "SR": 0.5, "CSR": 0.5625, "retrieved_ids": ["mrqa_squad-train-56493", "mrqa_squad-train-80087", "mrqa_squad-train-73170", "mrqa_squad-train-41424", "mrqa_squad-train-45412", "mrqa_squad-train-10517", "mrqa_squad-train-76359", "mrqa_squad-train-53982", "mrqa_squad-train-44252", "mrqa_squad-train-10012", "mrqa_squad-train-18128", "mrqa_squad-train-16906", "mrqa_squad-train-81553", "mrqa_squad-train-77156", "mrqa_squad-train-70237", "mrqa_squad-train-42866", "mrqa_squad-train-15344", "mrqa_squad-train-57872", "mrqa_squad-train-58952", "mrqa_squad-train-78024", "mrqa_squad-train-83596", "mrqa_squad-train-10237", "mrqa_squad-train-47957", "mrqa_squad-train-58630", "mrqa_squad-train-50547", "mrqa_squad-train-13895", "mrqa_squad-train-46643", "mrqa_squad-train-65573", "mrqa_squad-train-36757", "mrqa_squad-train-27508", "mrqa_squad-train-36077", "mrqa_squad-train-54464", "mrqa_squad-validation-2852", "mrqa_squad-validation-1050", "mrqa_triviaqa-validation-3715", "mrqa_newsqa-validation-1564", "mrqa_squad-validation-3483", "mrqa_triviaqa-validation-7067", "mrqa_hotpotqa-validation-3360", "mrqa_squad-validation-8596", "mrqa_triviaqa-validation-1441", "mrqa_naturalquestions-validation-844", "mrqa_searchqa-validation-14691", "mrqa_naturalquestions-validation-3737", "mrqa_hotpotqa-validation-1185", "mrqa_naturalquestions-validation-7950", "mrqa_newsqa-validation-2020", "mrqa_searchqa-validation-10014", "mrqa_searchqa-validation-8166", "mrqa_naturalquestions-validation-6927", "mrqa_newsqa-validation-775", "mrqa_hotpotqa-validation-4064", "mrqa_squad-validation-10067", "mrqa_searchqa-validation-815", "mrqa_naturalquestions-validation-10208", "mrqa_newsqa-validation-246", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-8272", "mrqa_newsqa-validation-3167", "mrqa_triviaqa-validation-1183", "mrqa_triviaqa-validation-610", "mrqa_squad-validation-805", "mrqa_naturalquestions-validation-3429"], "EFR": 1.0, "Overall": 0.749375}, {"timecode": 56, "before_eval_results": {"predictions": ["Pegida", "Amy ( TV : Victory of the Daleks, 39:29)", "maple", "The Potteries", "bulgaria", "iron", "Little arrows", "m\u00fcnchen", "cats", "reanne evans", "Central African Republic", "Battle of Camlann", "hilbert", "1905", "France", "lab\u00e8que", "britishman", "blackpool", "Muhammad Ali", "Carbon", "woodentop", "m65", "Boxing Day", "cheers", "Taliban", "alpestrine", "a toad", "pain", "norway", "skirts", "Australia", "Blucher", "Atlas", "Sachin Tendulkar", "a black Ferrari", "river hull", "tenerife", "Britain", "bone", "Nutbush", "Jeremy Thorpe", "shinto", "dewsbury", "the Greater Antilles", "peaty", "Pluto", "john bardon", "cryonic suspension", "185 Fleet Street", "Scafell Pike", "baseball", "President pro tempore of the Senate", "Athens", "iOS, watchOS, and tvOS", "Leslie James \"Les\" Clark", "the fourth season of \"American Idol\"", "Realty Bites", "Former Mobile County Circuit Judge Herman Thomas", "The prince, second in line to the throne, landed a Chinook helicopter", "propofol", "Emmett Kelly", "Paul Simon", "the Curtain", "she can't change me"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5748139880952381}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, false, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.20000000000000004, 0.0, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.049999999999999996, 1.0, 1.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-5873", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-5220", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-6925", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-7039", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4167", "mrqa_triviaqa-validation-2262", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-3642", "mrqa_triviaqa-validation-101", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-6922", "mrqa_triviaqa-validation-3696", "mrqa_triviaqa-validation-6228", "mrqa_triviaqa-validation-1575", "mrqa_naturalquestions-validation-8114", "mrqa_naturalquestions-validation-1284", "mrqa_naturalquestions-validation-2748", "mrqa_hotpotqa-validation-1084", "mrqa_hotpotqa-validation-2903", "mrqa_hotpotqa-validation-2374", "mrqa_newsqa-validation-1282", "mrqa_searchqa-validation-1086", "mrqa_searchqa-validation-378", "mrqa_naturalquestions-validation-7270"], "SR": 0.53125, "CSR": 0.5619517543859649, "retrieved_ids": ["mrqa_squad-train-53097", "mrqa_squad-train-2112", "mrqa_squad-train-37666", "mrqa_squad-train-58252", "mrqa_squad-train-60573", "mrqa_squad-train-85819", "mrqa_squad-train-2251", "mrqa_squad-train-33661", "mrqa_squad-train-33602", "mrqa_squad-train-67815", "mrqa_squad-train-15074", "mrqa_squad-train-65839", "mrqa_squad-train-32472", "mrqa_squad-train-18808", "mrqa_squad-train-26534", "mrqa_squad-train-60235", "mrqa_squad-train-5089", "mrqa_squad-train-11852", "mrqa_squad-train-47862", "mrqa_squad-train-78965", "mrqa_squad-train-84680", "mrqa_squad-train-53985", "mrqa_squad-train-62533", "mrqa_squad-train-49889", "mrqa_squad-train-8853", "mrqa_squad-train-60942", "mrqa_squad-train-46550", "mrqa_squad-train-24860", "mrqa_squad-train-80815", "mrqa_squad-train-28390", "mrqa_squad-train-48943", "mrqa_squad-train-3651", "mrqa_hotpotqa-validation-1505", "mrqa_searchqa-validation-1076", "mrqa_squad-validation-1050", "mrqa_triviaqa-validation-6464", "mrqa_naturalquestions-validation-4236", "mrqa_triviaqa-validation-1534", "mrqa_hotpotqa-validation-3975", "mrqa_newsqa-validation-2607", "mrqa_newsqa-validation-3724", "mrqa_searchqa-validation-8166", "mrqa_hotpotqa-validation-5521", "mrqa_searchqa-validation-9113", "mrqa_searchqa-validation-13235", "mrqa_naturalquestions-validation-8962", "mrqa_squad-validation-8662", "mrqa_searchqa-validation-12623", "mrqa_naturalquestions-validation-6720", "mrqa_searchqa-validation-3122", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-9878", "mrqa_squad-validation-3207", "mrqa_searchqa-validation-15379", "mrqa_newsqa-validation-2913", "mrqa_hotpotqa-validation-739", "mrqa_naturalquestions-validation-7812", "mrqa_searchqa-validation-9438", "mrqa_triviaqa-validation-7076", "mrqa_triviaqa-validation-2919", "mrqa_searchqa-validation-5717", "mrqa_hotpotqa-validation-2377", "mrqa_naturalquestions-validation-6800", "mrqa_triviaqa-validation-3954"], "EFR": 0.9666666666666667, "Overall": 0.7425986842105263}, {"timecode": 57, "before_eval_results": {"predictions": ["against outside influences in next month's run-off election", "Monday", "eight-week", "which type of guy you should avoid.", "coalition", "won't cast a spell on him.", "Stratfor", "\"scared I won't be able to go home.\"", "The 23-year-old Rezai -- who had only claimed WTA Tour titles at Strasbourg and Bali prior to Madrid -- continued her remarkable week with a 6-2 7-5 victory", "murder in the beating death of", "David Beckham", "from the capital, Dhaka, to their homes in Bhola for the Muslim festival of Eid al-Adha.", "Islamabad", "Dennis Davern,", "sailor", "\"a smoking gun of confirmation of Brazil's effort to engage in operations to overthrow the government of Chile and a discussion of collusion with the United States.\"", "opposition group, also known as the \"red shirts,\"", "Madhav Kumar Nepal of the Communist Party of Nepal (Unified Marxist-Leninist)", "Saturday", "\"Russian Madonna\" singer Valeriya, and London-based Russian art collector Nonna Materkova", "attempted car-jacking as he dropped his children off at a relative's house,", "11", "put a gun to Valencia's head.", "both countries should be able to take part in NATO's Membership Action Plan, or MAP,", "Citizens are picking members of the lower house of parliament,", "refusal or inability to \"turn it off\"", "Janet Napolitano", "bicycles", "The alleged surviving attacker from last month's Mumbai terror attacks is seeking help from Pakistani officials,", "Afghanistan", "the fact that the teens were charged as adults.", "Cognitive Assistant", "dogs who walk on ice in Alaska.", "10 to 15 percent", "Israel", "british", "a man walked through an exit on the public side to the secure \"sterile\" side for passengers who had cleared screening,", "Landry", "President Bush", "Thebault", "Steven Gerrard", "three", "Golden Gate Yacht Club of San Francisco", "annual Veracruz Regatta race", "Grease", "Afghanistan's restive provinces", "2002 for British broadcaster Channel 4", "The sound of pounding hooves thunders in the high desert air.", "millionaire's surtax", "Fourteen", "Osama bin Laden's sons", "outside cultivated areas", "Spain", "Wyatt and Dylan Walters", "2004", "crocodile", "Ambassador Bridge", "University of Liverpool", "Count Schlieffen", "Chillingham Castle", "400th anniversary", "the Liffey", "Scrabble", "Rickie Lee Skaggs"], "metric_results": {"EM": 0.5, "QA-F1": 0.5615756882615435}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, false, false, true, true, true, true], "QA-F1": [0.9333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.10526315789473685, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2105263157894737, 1.0, 0.4615384615384615, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.14814814814814814, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0606060606060606, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3942", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3285", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-1446", "mrqa_newsqa-validation-3865", "mrqa_newsqa-validation-964", "mrqa_newsqa-validation-4121", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-889", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-2968", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1448", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-2015", "mrqa_newsqa-validation-1799", "mrqa_newsqa-validation-4123", "mrqa_newsqa-validation-648", "mrqa_naturalquestions-validation-246", "mrqa_naturalquestions-validation-919", "mrqa_triviaqa-validation-5508", "mrqa_hotpotqa-validation-5455", "mrqa_hotpotqa-validation-3212"], "SR": 0.5, "CSR": 0.5608836206896552, "retrieved_ids": ["mrqa_squad-train-24011", "mrqa_squad-train-10267", "mrqa_squad-train-53695", "mrqa_squad-train-72049", "mrqa_squad-train-82182", "mrqa_squad-train-54631", "mrqa_squad-train-16879", "mrqa_squad-train-32499", "mrqa_squad-train-38357", "mrqa_squad-train-84981", "mrqa_squad-train-79874", "mrqa_squad-train-44049", "mrqa_squad-train-7828", "mrqa_squad-train-1763", "mrqa_squad-train-42531", "mrqa_squad-train-3109", "mrqa_squad-train-25804", "mrqa_squad-train-40121", "mrqa_squad-train-81066", "mrqa_squad-train-18144", "mrqa_squad-train-39618", "mrqa_squad-train-29940", "mrqa_squad-train-9060", "mrqa_squad-train-86075", "mrqa_squad-train-13769", "mrqa_squad-train-723", "mrqa_squad-train-49683", "mrqa_squad-train-52264", "mrqa_squad-train-70844", "mrqa_squad-train-53328", "mrqa_squad-train-67013", "mrqa_squad-train-21719", "mrqa_naturalquestions-validation-5053", "mrqa_searchqa-validation-9255", "mrqa_searchqa-validation-3922", "mrqa_hotpotqa-validation-4818", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-3948", "mrqa_searchqa-validation-10063", "mrqa_newsqa-validation-3564", "mrqa_searchqa-validation-14169", "mrqa_naturalquestions-validation-1336", "mrqa_triviaqa-validation-7083", "mrqa_searchqa-validation-909", "mrqa_hotpotqa-validation-5406", "mrqa_squad-validation-6108", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-310", "mrqa_squad-validation-9740", "mrqa_newsqa-validation-3784", "mrqa_naturalquestions-validation-7608", "mrqa_searchqa-validation-13651", "mrqa_newsqa-validation-1837", "mrqa_searchqa-validation-13367", "mrqa_hotpotqa-validation-3481", "mrqa_naturalquestions-validation-10098", "mrqa_searchqa-validation-9800", "mrqa_searchqa-validation-11392", "mrqa_hotpotqa-validation-3391", "mrqa_naturalquestions-validation-1135", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-15716", "mrqa_searchqa-validation-9559", "mrqa_searchqa-validation-6666"], "EFR": 0.96875, "Overall": 0.7428017241379311}, {"timecode": 58, "before_eval_results": {"predictions": ["Ted", "1,467", "1989", "Nicole Kidman", "14", "National Basketball Development League", "Gust Avrakotos", "involuntary euthanasia", "test pilot", "a common pochard", "Summer Olympic Games", "Miami", "St. Louis Cardinals", "1992", "1993", "University of Vienna", "Jack Ridley", "Pennsylvania State University", "Chicago, Illinois", "William Corcoran Eustis", "Christian", "Hanoi", "ITV", "Australia", "suburb", "bi-fuel vehicles", "The Savannah River Site", "swingman", "Patriots Day", "Scotland", "Todd Emmanuel Fisher", "1944", "Suicide Squad", "1883", "23", "Mach number", "James Gay-Rees", "(foaled February 1, 1999)", "otion poetry", "Madonna", "musicologist", "Lauren Alaina", "Prince Amedeo", "Ben Ainslie", "Forbidden Quest", "non-alcoholic", "Scratchcard", "White Horse", "Duncan Kenworthy", "Malayalam movies", "Peter Nowalk", "Annette", "an exultation of spirit", "Bumblebee", "riyadh", "gagapedia", "African violets", "three", "There's no chance", "the Carrousel du Louvre", "A Tale of Two Cities", "Gabriel", "William Wallace", "( Boss) Tweed"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6604166666666667}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-2681", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-4747", "mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-1256", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-1674", "mrqa_hotpotqa-validation-472", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-5470", "mrqa_hotpotqa-validation-4806", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4510", "mrqa_hotpotqa-validation-1820", "mrqa_hotpotqa-validation-2144", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-3420", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6523", "mrqa_triviaqa-validation-1018", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2955", "mrqa_searchqa-validation-3318", "mrqa_searchqa-validation-7521"], "SR": 0.578125, "CSR": 0.5611758474576272, "retrieved_ids": ["mrqa_squad-train-32872", "mrqa_squad-train-5612", "mrqa_squad-train-19703", "mrqa_squad-train-23317", "mrqa_squad-train-85846", "mrqa_squad-train-25297", "mrqa_squad-train-61832", "mrqa_squad-train-858", "mrqa_squad-train-83390", "mrqa_squad-train-43284", "mrqa_squad-train-82614", "mrqa_squad-train-25729", "mrqa_squad-train-9102", "mrqa_squad-train-54276", "mrqa_squad-train-50542", "mrqa_squad-train-42353", "mrqa_squad-train-13780", "mrqa_squad-train-26698", "mrqa_squad-train-44585", "mrqa_squad-train-77934", "mrqa_squad-train-11083", "mrqa_squad-train-66713", "mrqa_squad-train-64886", "mrqa_squad-train-55082", "mrqa_squad-train-69160", "mrqa_squad-train-52880", "mrqa_squad-train-53474", "mrqa_squad-train-61179", "mrqa_squad-train-85552", "mrqa_squad-train-21998", "mrqa_squad-train-82512", "mrqa_squad-train-54542", "mrqa_triviaqa-validation-6318", "mrqa_searchqa-validation-6319", "mrqa_hotpotqa-validation-108", "mrqa_searchqa-validation-10873", "mrqa_hotpotqa-validation-2581", "mrqa_triviaqa-validation-4317", "mrqa_searchqa-validation-16742", "mrqa_searchqa-validation-8348", "mrqa_newsqa-validation-455", "mrqa_squad-validation-8596", "mrqa_searchqa-validation-7828", "mrqa_naturalquestions-validation-7468", "mrqa_searchqa-validation-378", "mrqa_triviaqa-validation-725", "mrqa_squad-validation-512", "mrqa_hotpotqa-validation-5590", "mrqa_hotpotqa-validation-1835", "mrqa_hotpotqa-validation-1161", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-4113", "mrqa_naturalquestions-validation-10461", "mrqa_searchqa-validation-14169", "mrqa_triviaqa-validation-253", "mrqa_newsqa-validation-3106", "mrqa_naturalquestions-validation-7812", "mrqa_triviaqa-validation-5950", "mrqa_hotpotqa-validation-943", "mrqa_triviaqa-validation-7062", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-3783", "mrqa_squad-validation-4361", "mrqa_newsqa-validation-3250"], "EFR": 0.9629629629629629, "Overall": 0.741702762084118}, {"timecode": 59, "before_eval_results": {"predictions": ["New Croton Reservoir", "connotations of the passing of the year", "John Barry", "Thespis", "in the Saronic Gulf, about 1 nautical mile ( 2 km ) off - coast from Piraeus and about 16 kilometres ( 10 miles ) west of Athens", "2010", "Coroebus", "Obi - Wan Kenobi : A Jedi Master", "1952", "iron", "Jesse Frederick James Conaway", "tolled ( quota ) highways", "supported modern programming practices and enabled business applications to be developed with Flash", "Gene MacLellan", "1957", "certain actions taken by employers or unions that violate the National Labor Relations Act of 1935", "a four - page pamphlet in 1876", "Have I Told You Lately ''", "the world's second most populous country", "the second Persian invasion of Greece", "Lana Del Rey", "April 1979", "`` The Crossing ''", "Janie Crawford", "the adoption of the first ten amendments, the Bill of Rights", "2018", "Byzantine Greek culture and Eastern Christianity", "ordain presbyters / bishops and to exercise general oversight", "11 January 1923", "1961", "the Indians", "reduces the back pressure, which in turn reduces the steam consumption, and thus the fuel consumption, while at the same time increasing power and recycling boiler - water", "\u00c9mile Gagnan and Naval Lieutenant ( `` lieutenant de vaisseau '' ) Jacques Cousteau", "Felix Baumgartner", "1995", "2026", "the Golden Age of India", "Abigail Hawk", "Gary Mitchell", "in East Asia", "the 1970s", "1919", "23 September 1889", "carbon, chlorine, and fluorine", "October 27, 2017", "three levels", "Richard Crispin Armitage", "Missouri River", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophie Monk and Eddie Perfect", "Jack Barry", "headdresses", "We Can Love", "south african", "One Direction", "Delacorte Press", "Drifting", "1949", "Bollywood", "The West", "\"wipe out\" the United States if provoked.", "Celsius", "Chicago", "Jonathan Swift", "\"Linux Format\""], "metric_results": {"EM": 0.578125, "QA-F1": 0.6725971262569053}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false], "QA-F1": [0.5454545454545454, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.7499999999999999, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5283018867924527, 0.26666666666666666, 1.0, 0.7272727272727272, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.8235294117647058, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-9560", "mrqa_naturalquestions-validation-4872", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-1423", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-290", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-8420", "mrqa_naturalquestions-validation-5561", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-5143", "mrqa_naturalquestions-validation-720", "mrqa_naturalquestions-validation-2090", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-3782", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-870", "mrqa_triviaqa-validation-6837", "mrqa_triviaqa-validation-4980", "mrqa_hotpotqa-validation-5386", "mrqa_newsqa-validation-2663", "mrqa_hotpotqa-validation-4642"], "SR": 0.578125, "CSR": 0.5614583333333334, "retrieved_ids": ["mrqa_squad-train-17533", "mrqa_squad-train-23563", "mrqa_squad-train-76812", "mrqa_squad-train-76442", "mrqa_squad-train-66797", "mrqa_squad-train-65271", "mrqa_squad-train-33152", "mrqa_squad-train-48924", "mrqa_squad-train-64336", "mrqa_squad-train-24454", "mrqa_squad-train-53131", "mrqa_squad-train-65295", "mrqa_squad-train-59642", "mrqa_squad-train-71308", "mrqa_squad-train-69188", "mrqa_squad-train-56264", "mrqa_squad-train-24868", "mrqa_squad-train-37967", "mrqa_squad-train-33924", "mrqa_squad-train-6614", "mrqa_squad-train-9800", "mrqa_squad-train-49221", "mrqa_squad-train-34009", "mrqa_squad-train-58973", "mrqa_squad-train-38359", "mrqa_squad-train-38923", "mrqa_squad-train-11299", "mrqa_squad-train-62301", "mrqa_squad-train-60849", "mrqa_squad-train-19690", "mrqa_squad-train-78861", "mrqa_squad-train-7300", "mrqa_naturalquestions-validation-407", "mrqa_squad-validation-9565", "mrqa_naturalquestions-validation-997", "mrqa_searchqa-validation-10097", "mrqa_hotpotqa-validation-2978", "mrqa_searchqa-validation-2783", "mrqa_triviaqa-validation-6259", "mrqa_searchqa-validation-5528", "mrqa_newsqa-validation-593", "mrqa_squad-validation-806", "mrqa_hotpotqa-validation-2327", "mrqa_naturalquestions-validation-6216", "mrqa_hotpotqa-validation-149", "mrqa_searchqa-validation-9133", "mrqa_naturalquestions-validation-6927", "mrqa_hotpotqa-validation-4661", "mrqa_searchqa-validation-8804", "mrqa_searchqa-validation-3122", "mrqa_naturalquestions-validation-10490", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-278", "mrqa_newsqa-validation-3349", "mrqa_searchqa-validation-4072", "mrqa_triviaqa-validation-3888", "mrqa_squad-validation-3374", "mrqa_hotpotqa-validation-1393", "mrqa_searchqa-validation-9007", "mrqa_naturalquestions-validation-4497", "mrqa_triviaqa-validation-5093", "mrqa_searchqa-validation-8040", "mrqa_searchqa-validation-5324", "mrqa_newsqa-validation-3406"], "EFR": 0.9259259259259259, "Overall": 0.7343518518518519}, {"timecode": 60, "UKR": 0.77734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1081", "mrqa_hotpotqa-validation-1084", "mrqa_hotpotqa-validation-1159", "mrqa_hotpotqa-validation-1288", "mrqa_hotpotqa-validation-1321", "mrqa_hotpotqa-validation-1372", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-1505", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1548", "mrqa_hotpotqa-validation-1579", "mrqa_hotpotqa-validation-1596", "mrqa_hotpotqa-validation-1643", "mrqa_hotpotqa-validation-1691", "mrqa_hotpotqa-validation-1760", "mrqa_hotpotqa-validation-1767", "mrqa_hotpotqa-validation-1876", "mrqa_hotpotqa-validation-1935", "mrqa_hotpotqa-validation-1957", "mrqa_hotpotqa-validation-1993", "mrqa_hotpotqa-validation-2008", "mrqa_hotpotqa-validation-2047", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-224", "mrqa_hotpotqa-validation-2312", "mrqa_hotpotqa-validation-2341", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-2365", "mrqa_hotpotqa-validation-2400", "mrqa_hotpotqa-validation-2472", "mrqa_hotpotqa-validation-2521", "mrqa_hotpotqa-validation-2581", "mrqa_hotpotqa-validation-2589", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-2788", "mrqa_hotpotqa-validation-284", "mrqa_hotpotqa-validation-2890", "mrqa_hotpotqa-validation-2968", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-3022", "mrqa_hotpotqa-validation-307", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-3174", "mrqa_hotpotqa-validation-3247", "mrqa_hotpotqa-validation-3359", "mrqa_hotpotqa-validation-338", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-3577", "mrqa_hotpotqa-validation-3604", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-3821", "mrqa_hotpotqa-validation-3869", "mrqa_hotpotqa-validation-3963", "mrqa_hotpotqa-validation-3995", "mrqa_hotpotqa-validation-4096", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-4246", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4450", "mrqa_hotpotqa-validation-462", "mrqa_hotpotqa-validation-4749", "mrqa_hotpotqa-validation-4754", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-4815", "mrqa_hotpotqa-validation-4836", "mrqa_hotpotqa-validation-4875", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-540", "mrqa_hotpotqa-validation-5427", "mrqa_hotpotqa-validation-5458", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5481", "mrqa_hotpotqa-validation-5553", "mrqa_hotpotqa-validation-5553", "mrqa_hotpotqa-validation-5661", "mrqa_hotpotqa-validation-5667", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-5794", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-674", "mrqa_hotpotqa-validation-731", "mrqa_hotpotqa-validation-783", "mrqa_hotpotqa-validation-80", "mrqa_naturalquestions-validation-10029", "mrqa_naturalquestions-validation-10159", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-10386", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-10597", "mrqa_naturalquestions-validation-10723", "mrqa_naturalquestions-validation-10723", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1328", "mrqa_naturalquestions-validation-1377", "mrqa_naturalquestions-validation-1398", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-2226", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3048", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-3099", "mrqa_naturalquestions-validation-324", "mrqa_naturalquestions-validation-3477", "mrqa_naturalquestions-validation-3692", "mrqa_naturalquestions-validation-3892", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4090", "mrqa_naturalquestions-validation-4148", "mrqa_naturalquestions-validation-4222", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-4315", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-4498", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-5133", "mrqa_naturalquestions-validation-5297", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5374", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-559", "mrqa_naturalquestions-validation-5672", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-5864", "mrqa_naturalquestions-validation-6237", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-6460", "mrqa_naturalquestions-validation-6474", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6768", "mrqa_naturalquestions-validation-6913", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7047", "mrqa_naturalquestions-validation-7162", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-7892", "mrqa_naturalquestions-validation-808", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-870", "mrqa_naturalquestions-validation-8916", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-8995", "mrqa_naturalquestions-validation-9191", "mrqa_naturalquestions-validation-9569", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-9614", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-9814", "mrqa_naturalquestions-validation-9967", "mrqa_naturalquestions-validation-997", "mrqa_naturalquestions-validation-9972", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-1183", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1611", "mrqa_newsqa-validation-1643", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-1724", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1890", "mrqa_newsqa-validation-2002", "mrqa_newsqa-validation-2015", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-2097", "mrqa_newsqa-validation-2117", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-2236", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-246", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-2511", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-2748", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-2934", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3021", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-314", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3972", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-427", "mrqa_newsqa-validation-513", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-593", "mrqa_newsqa-validation-613", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-97", "mrqa_searchqa-validation-10063", "mrqa_searchqa-validation-10124", "mrqa_searchqa-validation-10247", "mrqa_searchqa-validation-10289", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-1173", "mrqa_searchqa-validation-11828", "mrqa_searchqa-validation-12110", "mrqa_searchqa-validation-12127", "mrqa_searchqa-validation-12129", "mrqa_searchqa-validation-12144", "mrqa_searchqa-validation-12230", "mrqa_searchqa-validation-12597", "mrqa_searchqa-validation-12623", "mrqa_searchqa-validation-12715", "mrqa_searchqa-validation-12782", "mrqa_searchqa-validation-12979", "mrqa_searchqa-validation-13012", "mrqa_searchqa-validation-13110", "mrqa_searchqa-validation-13282", "mrqa_searchqa-validation-13771", "mrqa_searchqa-validation-13931", "mrqa_searchqa-validation-13955", "mrqa_searchqa-validation-1418", "mrqa_searchqa-validation-14218", "mrqa_searchqa-validation-1437", "mrqa_searchqa-validation-14849", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14910", "mrqa_searchqa-validation-14930", "mrqa_searchqa-validation-15003", "mrqa_searchqa-validation-15030", "mrqa_searchqa-validation-15243", "mrqa_searchqa-validation-15282", "mrqa_searchqa-validation-15410", "mrqa_searchqa-validation-15469", "mrqa_searchqa-validation-15555", "mrqa_searchqa-validation-15578", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-15643", "mrqa_searchqa-validation-15652", "mrqa_searchqa-validation-15881", "mrqa_searchqa-validation-15942", "mrqa_searchqa-validation-16187", "mrqa_searchqa-validation-16447", "mrqa_searchqa-validation-16837", "mrqa_searchqa-validation-2130", "mrqa_searchqa-validation-2256", "mrqa_searchqa-validation-2347", "mrqa_searchqa-validation-2691", "mrqa_searchqa-validation-2929", "mrqa_searchqa-validation-2971", "mrqa_searchqa-validation-3122", "mrqa_searchqa-validation-3243", "mrqa_searchqa-validation-3455", "mrqa_searchqa-validation-3920", "mrqa_searchqa-validation-4142", "mrqa_searchqa-validation-4185", "mrqa_searchqa-validation-4305", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-4555", "mrqa_searchqa-validation-4602", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-4721", "mrqa_searchqa-validation-4848", "mrqa_searchqa-validation-5070", "mrqa_searchqa-validation-5105", "mrqa_searchqa-validation-5167", "mrqa_searchqa-validation-5324", "mrqa_searchqa-validation-5461", "mrqa_searchqa-validation-5528", "mrqa_searchqa-validation-5725", "mrqa_searchqa-validation-5817", "mrqa_searchqa-validation-6319", "mrqa_searchqa-validation-6367", "mrqa_searchqa-validation-6506", "mrqa_searchqa-validation-685", "mrqa_searchqa-validation-6977", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7279", "mrqa_searchqa-validation-7408", "mrqa_searchqa-validation-7616", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-7828", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7864", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7906", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-8229", "mrqa_searchqa-validation-8365", "mrqa_searchqa-validation-846", "mrqa_searchqa-validation-8600", "mrqa_searchqa-validation-8632", "mrqa_searchqa-validation-8648", "mrqa_searchqa-validation-8866", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-9113", "mrqa_searchqa-validation-9123", "mrqa_searchqa-validation-9133", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-929", "mrqa_searchqa-validation-9323", "mrqa_squad-validation-10260", "mrqa_squad-validation-10279", "mrqa_squad-validation-10474", "mrqa_squad-validation-1160", "mrqa_squad-validation-1219", "mrqa_squad-validation-1338", "mrqa_squad-validation-161", "mrqa_squad-validation-1808", "mrqa_squad-validation-1982", "mrqa_squad-validation-2145", "mrqa_squad-validation-2434", "mrqa_squad-validation-2458", "mrqa_squad-validation-2506", "mrqa_squad-validation-2888", "mrqa_squad-validation-3196", "mrqa_squad-validation-3207", "mrqa_squad-validation-350", "mrqa_squad-validation-3575", "mrqa_squad-validation-3752", "mrqa_squad-validation-3865", "mrqa_squad-validation-4117", "mrqa_squad-validation-4232", "mrqa_squad-validation-4294", "mrqa_squad-validation-4316", "mrqa_squad-validation-4341", "mrqa_squad-validation-4348", "mrqa_squad-validation-4356", "mrqa_squad-validation-447", "mrqa_squad-validation-4562", "mrqa_squad-validation-4666", "mrqa_squad-validation-4795", "mrqa_squad-validation-4965", "mrqa_squad-validation-5098", "mrqa_squad-validation-5303", "mrqa_squad-validation-5310", "mrqa_squad-validation-5407", "mrqa_squad-validation-5590", "mrqa_squad-validation-5630", "mrqa_squad-validation-5638", "mrqa_squad-validation-566", "mrqa_squad-validation-5758", "mrqa_squad-validation-5844", "mrqa_squad-validation-5846", "mrqa_squad-validation-5978", "mrqa_squad-validation-6025", "mrqa_squad-validation-6072", "mrqa_squad-validation-6113", "mrqa_squad-validation-6196", "mrqa_squad-validation-6286", "mrqa_squad-validation-6316", "mrqa_squad-validation-6361", "mrqa_squad-validation-6393", "mrqa_squad-validation-6408", "mrqa_squad-validation-6645", "mrqa_squad-validation-6658", "mrqa_squad-validation-7144", "mrqa_squad-validation-7303", "mrqa_squad-validation-7428", "mrqa_squad-validation-7474", "mrqa_squad-validation-7571", "mrqa_squad-validation-7632", "mrqa_squad-validation-7852", "mrqa_squad-validation-7867", "mrqa_squad-validation-8227", "mrqa_squad-validation-8421", "mrqa_squad-validation-8436", "mrqa_squad-validation-8576", "mrqa_squad-validation-8647", "mrqa_squad-validation-8971", "mrqa_squad-validation-901", "mrqa_squad-validation-9022", "mrqa_squad-validation-9029", "mrqa_squad-validation-9226", "mrqa_squad-validation-9286", "mrqa_squad-validation-9333", "mrqa_squad-validation-9360", "mrqa_squad-validation-9740", "mrqa_squad-validation-9750", "mrqa_squad-validation-9818", "mrqa_squad-validation-9895", "mrqa_triviaqa-validation-1035", "mrqa_triviaqa-validation-1259", "mrqa_triviaqa-validation-1318", "mrqa_triviaqa-validation-1331", "mrqa_triviaqa-validation-1360", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1475", "mrqa_triviaqa-validation-1603", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1868", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-2154", "mrqa_triviaqa-validation-2186", "mrqa_triviaqa-validation-2335", "mrqa_triviaqa-validation-2399", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-2624", "mrqa_triviaqa-validation-274", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2974", "mrqa_triviaqa-validation-2980", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3086", "mrqa_triviaqa-validation-3095", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3195", "mrqa_triviaqa-validation-3313", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-3631", "mrqa_triviaqa-validation-3642", "mrqa_triviaqa-validation-380", "mrqa_triviaqa-validation-3810", "mrqa_triviaqa-validation-3812", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4145", "mrqa_triviaqa-validation-4167", "mrqa_triviaqa-validation-4172", "mrqa_triviaqa-validation-4189", "mrqa_triviaqa-validation-4197", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4573", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-4611", "mrqa_triviaqa-validation-4647", "mrqa_triviaqa-validation-4933", "mrqa_triviaqa-validation-5044", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-5128", "mrqa_triviaqa-validation-5182", "mrqa_triviaqa-validation-5336", "mrqa_triviaqa-validation-5370", "mrqa_triviaqa-validation-5393", "mrqa_triviaqa-validation-5394", "mrqa_triviaqa-validation-5402", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-5464", "mrqa_triviaqa-validation-5496", "mrqa_triviaqa-validation-552", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-5603", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5720", "mrqa_triviaqa-validation-5743", "mrqa_triviaqa-validation-5750", "mrqa_triviaqa-validation-5898", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-6125", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6159", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-6404", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-6561", "mrqa_triviaqa-validation-6564", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-6907", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-719", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-725", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7506", "mrqa_triviaqa-validation-7519", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-790", "mrqa_triviaqa-validation-806", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-996"], "OKR": 0.912109375, "KG": 0.496875, "before_eval_results": {"predictions": ["Revolt of the Sergeants", "St. Vincent", "5,042", "Mandalay Entertainment", "Carrie Fisher", "1963\u201393", "Michael George Holmgren", "2,627", "the Northern Wars", "Sparky", "Fort Oranje", "American", "Virgin", "October 21, 2016", "Heart", "Ferdinand Magellan", "Sun Records founder Sam Phillips", "the Corps of Discovery", "receive the benefits of the Morrill Acts of 1862 and 1890", "High Knob", "Miss Universe 2010", "Maryland", "(2008)", "democracy and personal freedom", "Terrina Chrishell Stause", "French Canadians", "1964 to 1974", "Vanarama National League", "The Bloods and Westies", "Continental Army", "Wes Archer", "Monica Seles", "Vancouver", "difficult and intricate topics", "Thomas Mawson", "Tony Aloupis", "various", "North Dakota", "Sir Francis Nethersole", "The Panther", "British", "twelfth", "University of California", "City of Onkaparinga", "2 February", "thirteen", "Princes Park", "The Bye Bye Man", "Germanic", "\"Blue (Da Ba Dee)\"", "1698", "orbit", "the Constitution of India came into effect on 26 January 1950", "Raza Jaffrey", "Jon Stewart", "for gallantry", "Statue of Liberty", "Government Accountability Office", "Brian Smith.", "$249", "high and dry", "An American Tail", "a cat", "Peru"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6959077380952381}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4114", "mrqa_hotpotqa-validation-3918", "mrqa_hotpotqa-validation-2954", "mrqa_hotpotqa-validation-2214", "mrqa_hotpotqa-validation-5489", "mrqa_hotpotqa-validation-2559", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-2582", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-631", "mrqa_hotpotqa-validation-3525", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-2964", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-1011", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2635", "mrqa_naturalquestions-validation-10257", "mrqa_triviaqa-validation-5468", "mrqa_searchqa-validation-8784"], "SR": 0.65625, "CSR": 0.5630122950819672, "retrieved_ids": ["mrqa_squad-train-83784", "mrqa_squad-train-22017", "mrqa_squad-train-11382", "mrqa_squad-train-79770", "mrqa_squad-train-20608", "mrqa_squad-train-28894", "mrqa_squad-train-52079", "mrqa_squad-train-65196", "mrqa_squad-train-51379", "mrqa_squad-train-17502", "mrqa_squad-train-59688", "mrqa_squad-train-11358", "mrqa_squad-train-76715", "mrqa_squad-train-81589", "mrqa_squad-train-84348", "mrqa_squad-train-13804", "mrqa_squad-train-48540", "mrqa_squad-train-74858", "mrqa_squad-train-13245", "mrqa_squad-train-2667", "mrqa_squad-train-47513", "mrqa_squad-train-35348", "mrqa_squad-train-43210", "mrqa_squad-train-26648", "mrqa_squad-train-30625", "mrqa_squad-train-24079", "mrqa_squad-train-83458", "mrqa_squad-train-58643", "mrqa_squad-train-27077", "mrqa_squad-train-61452", "mrqa_squad-train-2491", "mrqa_squad-train-23917", "mrqa_triviaqa-validation-1603", "mrqa_hotpotqa-validation-3220", "mrqa_searchqa-validation-15643", "mrqa_naturalquestions-validation-5769", "mrqa_squad-validation-6645", "mrqa_newsqa-validation-744", "mrqa_searchqa-validation-6095", "mrqa_searchqa-validation-2248", "mrqa_squad-validation-8652", "mrqa_hotpotqa-validation-2978", "mrqa_newsqa-validation-467", "mrqa_searchqa-validation-7186", "mrqa_hotpotqa-validation-2759", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-5476", "mrqa_newsqa-validation-1183", "mrqa_triviaqa-validation-7151", "mrqa_triviaqa-validation-6554", "mrqa_searchqa-validation-9096", "mrqa_hotpotqa-validation-4112", "mrqa_naturalquestions-validation-3533", "mrqa_searchqa-validation-15555", "mrqa_hotpotqa-validation-5101", "mrqa_searchqa-validation-4913", "mrqa_triviaqa-validation-7434", "mrqa_naturalquestions-validation-7827", "mrqa_searchqa-validation-8030", "mrqa_newsqa-validation-2360", "mrqa_naturalquestions-validation-2067", "mrqa_searchqa-validation-13046", "mrqa_newsqa-validation-2200", "mrqa_naturalquestions-validation-3048"], "EFR": 0.9545454545454546, "Overall": 0.7407771749254843}, {"timecode": 61, "before_eval_results": {"predictions": ["The Blades", "george Blake", "Rita Hayworth", "trout", "emerald fowlds", "javanese", "French", "Manchester", "sky", "Susan Bullock", "Danny Willett", "autumnmas", "Wonga", "(George) Stevens", "Genghis Khan", "Kofi Annan", "l'homme des bois", "left", "Istanbul", "lamb", "space Oddity", "collie", "35", "copepods", "florida", "mike Hammer", "jimmy smith", "Glennie", "a heart", "Zaragoza", "David Bowie", "Billy Wilder", "\"Mr Loophole\"", "a peplos", "4.4 million", "today", "Westminster Abbey", "ralph Lauren", "Whitsunday", "Morgan Spurlock", "pease pudding and saveloys", "Debbie Reynolds", "Caroline Aherne", "anions", "George Santayana", "Rudolf Nureyev", "Paul Wellens", "cat", "apple", "dalmatix", "Rodgers & Hammerstein", "part of a pre-recorded television program, Rendezvous with Destiny", "By 1770 BC", "the U.S. Senate", "5", "Amal Clooney", "C. J. Cherryh", "autonomy.", "Heshmatollah Attarzadeh", "Mark Obama Ndesandjo", "a second colony, in what is now North Carolina, vanished in the 1580s and became immortalized in history", "the Louvre", "Kansas City, Missouri", "Yiddish Scientific Institute"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5888020833333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 1.0, 0.5, 0.0, 1.0, 0.8, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7044", "mrqa_triviaqa-validation-2081", "mrqa_triviaqa-validation-2610", "mrqa_triviaqa-validation-5522", "mrqa_triviaqa-validation-6699", "mrqa_triviaqa-validation-336", "mrqa_triviaqa-validation-1052", "mrqa_triviaqa-validation-1643", "mrqa_triviaqa-validation-1824", "mrqa_triviaqa-validation-3702", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-6779", "mrqa_triviaqa-validation-600", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-2389", "mrqa_triviaqa-validation-3457", "mrqa_triviaqa-validation-6339", "mrqa_triviaqa-validation-554", "mrqa_triviaqa-validation-6210", "mrqa_triviaqa-validation-4021", "mrqa_naturalquestions-validation-6224", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-4178", "mrqa_hotpotqa-validation-2955", "mrqa_newsqa-validation-2489", "mrqa_searchqa-validation-4730", "mrqa_searchqa-validation-5842", "mrqa_hotpotqa-validation-3793"], "SR": 0.515625, "CSR": 0.5622479838709677, "retrieved_ids": ["mrqa_squad-train-1888", "mrqa_squad-train-41314", "mrqa_squad-train-59694", "mrqa_squad-train-3897", "mrqa_squad-train-57300", "mrqa_squad-train-48320", "mrqa_squad-train-13433", "mrqa_squad-train-29143", "mrqa_squad-train-34032", "mrqa_squad-train-13761", "mrqa_squad-train-85284", "mrqa_squad-train-63943", "mrqa_squad-train-34850", "mrqa_squad-train-41552", "mrqa_squad-train-83691", "mrqa_squad-train-55773", "mrqa_squad-train-68285", "mrqa_squad-train-15281", "mrqa_squad-train-45964", "mrqa_squad-train-63315", "mrqa_squad-train-68544", "mrqa_squad-train-7372", "mrqa_squad-train-39927", "mrqa_squad-train-1394", "mrqa_squad-train-42826", "mrqa_squad-train-889", "mrqa_squad-train-71812", "mrqa_squad-train-65562", "mrqa_squad-train-71125", "mrqa_squad-train-4254", "mrqa_squad-train-67780", "mrqa_squad-train-45308", "mrqa_hotpotqa-validation-5018", "mrqa_naturalquestions-validation-3332", "mrqa_triviaqa-validation-2919", "mrqa_triviaqa-validation-4630", "mrqa_triviaqa-validation-5194", "mrqa_hotpotqa-validation-741", "mrqa_squad-validation-4206", "mrqa_newsqa-validation-1857", "mrqa_squad-validation-1116", "mrqa_hotpotqa-validation-1803", "mrqa_searchqa-validation-8040", "mrqa_hotpotqa-validation-2625", "mrqa_newsqa-validation-2315", "mrqa_triviaqa-validation-4046", "mrqa_searchqa-validation-1640", "mrqa_hotpotqa-validation-3995", "mrqa_naturalquestions-validation-10616", "mrqa_triviaqa-validation-3865", "mrqa_naturalquestions-validation-3784", "mrqa_squad-validation-6753", "mrqa_naturalquestions-validation-6035", "mrqa_triviaqa-validation-1114", "mrqa_newsqa-validation-2939", "mrqa_searchqa-validation-2615", "mrqa_triviaqa-validation-2324", "mrqa_naturalquestions-validation-8728", "mrqa_searchqa-validation-11769", "mrqa_triviaqa-validation-1178", "mrqa_naturalquestions-validation-3533", "mrqa_searchqa-validation-14900", "mrqa_squad-validation-4019", "mrqa_naturalquestions-validation-8254"], "EFR": 0.967741935483871, "Overall": 0.7432636088709679}, {"timecode": 62, "before_eval_results": {"predictions": ["Curtis James Martin Jr.", "Gabriel Iglesias", "The Snowman", "Bhushan Patel", "Helsinki, Finland", "Future", "Tommy Cannon", "Scottish national team", "203", "Patricia Neal", "Illinois's 15 congressional district", "Buffalo", "7,500 and 40,000", "5,112 feet", "Prof Media", "Jack", "four months in jail", "Michael Redgrave", "Sturt", "Taylor Swift", "\"Beauty and the Beast\"", "Europe", "Trilochanapala", "Deadpan sketch group", "small family car", "Spanish", "Algernod Lanier Washington", "14,000", "in photographs, film and television", "37", "Taoiseach", "137th", "Mr. Nice Guy", "Japan Airlines Flight 123", "professional wrestling", "Bury St Edmunds, Suffolk, England", "Loretta Lynn", "Ford Island", "pressure-sensitive film products", "film and short novels", "The United States of America", "Lerotholi Polytechnic Football Club", "Ribhu Dasgupta", "Peter Thiel", "orange", "Memphis", "the Swiss Confederation", "Lake Erie", "Sophie Monk", "Reinhard Heydrich", "lo Stivale", "the Tigris and Euphrates rivers", "During his first year in Spain", "Woodrow Wilson", "our mutual friend", "zebras", "Volkswagen", "Lifeway Christian Stores", "Pope Benedict XVI", "St. Louis, Missouri.", "pearl", "sarsaparilla", "overbite", "Iran of trying to build nuclear bombs,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6663163442460318}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, true, false, true, true, false, false, false, true, false, true, false, true, true, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666665, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.888888888888889, 1.0, 0.5, 1.0, 1.0, 0.0625, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-956", "mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-614", "mrqa_hotpotqa-validation-4494", "mrqa_hotpotqa-validation-2581", "mrqa_hotpotqa-validation-5496", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-5623", "mrqa_hotpotqa-validation-3059", "mrqa_hotpotqa-validation-2278", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-1675", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-4554", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-5585", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4604", "mrqa_hotpotqa-validation-3356", "mrqa_hotpotqa-validation-5666", "mrqa_naturalquestions-validation-5897", "mrqa_triviaqa-validation-3842", "mrqa_newsqa-validation-2278", "mrqa_searchqa-validation-6948"], "SR": 0.546875, "CSR": 0.5620039682539683, "retrieved_ids": ["mrqa_squad-train-6006", "mrqa_squad-train-24586", "mrqa_squad-train-76290", "mrqa_squad-train-55834", "mrqa_squad-train-43712", "mrqa_squad-train-81501", "mrqa_squad-train-42951", "mrqa_squad-train-39398", "mrqa_squad-train-32937", "mrqa_squad-train-15952", "mrqa_squad-train-4920", "mrqa_squad-train-70172", "mrqa_squad-train-40739", "mrqa_squad-train-46292", "mrqa_squad-train-6885", "mrqa_squad-train-46985", "mrqa_squad-train-5252", "mrqa_squad-train-6580", "mrqa_squad-train-9947", "mrqa_squad-train-58504", "mrqa_squad-train-66514", "mrqa_squad-train-51905", "mrqa_squad-train-78018", "mrqa_squad-train-49270", "mrqa_squad-train-45026", "mrqa_squad-train-80511", "mrqa_squad-train-42514", "mrqa_squad-train-43738", "mrqa_squad-train-76840", "mrqa_squad-train-27953", "mrqa_squad-train-47162", "mrqa_squad-train-32521", "mrqa_triviaqa-validation-6837", "mrqa_hotpotqa-validation-450", "mrqa_naturalquestions-validation-2748", "mrqa_searchqa-validation-16623", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5311", "mrqa_searchqa-validation-1948", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5675", "mrqa_triviaqa-validation-4244", "mrqa_newsqa-validation-3199", "mrqa_hotpotqa-validation-631", "mrqa_squad-validation-4621", "mrqa_searchqa-validation-7034", "mrqa_searchqa-validation-9096", "mrqa_searchqa-validation-4555", "mrqa_searchqa-validation-10971", "mrqa_triviaqa-validation-6548", "mrqa_searchqa-validation-13235", "mrqa_naturalquestions-validation-10310", "mrqa_squad-validation-1308", "mrqa_hotpotqa-validation-497", "mrqa_triviaqa-validation-5923", "mrqa_triviaqa-validation-3133", "mrqa_squad-validation-7537", "mrqa_searchqa-validation-10363", "mrqa_searchqa-validation-16321", "mrqa_squad-validation-3497", "mrqa_hotpotqa-validation-2625", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-435", "mrqa_searchqa-validation-8691"], "EFR": 0.896551724137931, "Overall": 0.7289767634783799}, {"timecode": 63, "before_eval_results": {"predictions": ["Tinseltown", "Claude Monet", "Brazil", "Jacob Zuma,", "apartment building", "in July for A Country Christmas,", "2005 & 2006 Acura MDX", "Ryan Adams,", "80 percent", "Olympia,", "27-year-old's", "next week", "1913,", "12-1", "Brazil jolted the global health community in 1996 when it began guaranteeing free anti-retroviral treatment to HIV/AIDS patients.", "next year", "the game was started by cross-country skiers who used the football matches in knee-deep mud to strengthen their leg muscles.", "his son, Isaac, and daughter, Rebecca.", "The Falklands, known as Las Malvinas", "the world's largest solar powered boat, recently stopped off in Hong Kong's Victoria Harbor as part of its 18-month journey around the world.", "Roger Federer", "tennis", "two", "the 1950s", "Gary Player", "about 12 million", "\"The Orchid thief\"", "a little coastal cleanup -- country style.", "President Bill Clinton", "average of 25 percent", "The plane had a crew of 14 people and was carrying an additional 98 passengers,", "800,000", "Sporting Lisbon", "President Sheikh Sharif Sheikh Ahmed", "2005", "\"He is more American than German.\"", "Johan Persson and Martin Schibbye", "Israel", "Sunday's", "Swat Valley.", "Jeffrey Jamaleldine", "The Rev. Alberto Cutie", "all day starting at 10 a.m.,", "\"a fantastic five episodes.\"", "to make life a little easier for these families by organizing the distribution of wheelchair, donated and paid for by his charity, Wheelchair for Iraqi Kids.", "her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "crafts poems telling of the pain and suffering of children just like her", "in the head", "350 U.S. soldiers", "neck", "dining scene", "Andrew Garfield", "New England Patriots", "interstitial fluid in the `` interstitial compartment '' ( surrounding tissue cells and bathing them in a solution of nutrients and other chemicals )", "79", "The Mystery of Edwin Drood", "Bligh", "Melbourne", "1998", "23 July 1989", "Tuesday", "Evian", "Ashbury", "Kind Hearts and Coronets"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6965773623604865}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.1111111111111111, 1.0, 0.0, 0.0, 0.33333333333333337, 0.5517241379310345, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 0.8, 0.4, 0.21428571428571427, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.8, 1.0, 1.0, 0.4347826086956522, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1873", "mrqa_newsqa-validation-271", "mrqa_newsqa-validation-1681", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-3848", "mrqa_newsqa-validation-4070", "mrqa_newsqa-validation-1142", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-1902", "mrqa_newsqa-validation-3973", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-1570", "mrqa_newsqa-validation-1346", "mrqa_newsqa-validation-2680", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2044", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-1147", "mrqa_newsqa-validation-2324", "mrqa_newsqa-validation-2423", "mrqa_newsqa-validation-3434", "mrqa_naturalquestions-validation-3261", "mrqa_triviaqa-validation-3872", "mrqa_triviaqa-validation-2862", "mrqa_searchqa-validation-5963"], "SR": 0.5625, "CSR": 0.56201171875, "retrieved_ids": ["mrqa_squad-train-78903", "mrqa_squad-train-19463", "mrqa_squad-train-56714", "mrqa_squad-train-39139", "mrqa_squad-train-16571", "mrqa_squad-train-81144", "mrqa_squad-train-82927", "mrqa_squad-train-21064", "mrqa_squad-train-54562", "mrqa_squad-train-20118", "mrqa_squad-train-28985", "mrqa_squad-train-29457", "mrqa_squad-train-23056", "mrqa_squad-train-37724", "mrqa_squad-train-6092", "mrqa_squad-train-22441", "mrqa_squad-train-51381", "mrqa_squad-train-78610", "mrqa_squad-train-12109", "mrqa_squad-train-83941", "mrqa_squad-train-1425", "mrqa_squad-train-11037", "mrqa_squad-train-77528", "mrqa_squad-train-18107", "mrqa_squad-train-175", "mrqa_squad-train-6282", "mrqa_squad-train-60891", "mrqa_squad-train-47214", "mrqa_squad-train-23150", "mrqa_squad-train-17146", "mrqa_squad-train-57947", "mrqa_squad-train-60418", "mrqa_naturalquestions-validation-7608", "mrqa_triviaqa-validation-32", "mrqa_searchqa-validation-16233", "mrqa_hotpotqa-validation-1730", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-8916", "mrqa_hotpotqa-validation-2228", "mrqa_newsqa-validation-3640", "mrqa_naturalquestions-validation-1090", "mrqa_naturalquestions-validation-1325", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-4946", "mrqa_naturalquestions-validation-9715", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1906", "mrqa_naturalquestions-validation-3342", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-9569", "mrqa_naturalquestions-validation-405", "mrqa_searchqa-validation-4533", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2870", "mrqa_searchqa-validation-9389", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-426", "mrqa_hotpotqa-validation-4567", "mrqa_triviaqa-validation-4173", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-850", "mrqa_triviaqa-validation-5591", "mrqa_hotpotqa-validation-593"], "EFR": 0.8928571428571429, "Overall": 0.7282393973214286}, {"timecode": 64, "before_eval_results": {"predictions": ["Den V\u00e6gelsindede", "Max Martin and Shellback", "George III", "6,396", "Reinhard Heydrich", "Standard Oil", "40 million albums", "Lieutenant Colonel Horace Meek Hickam", "Charles Russell", "May 1, 2011", "Konstant\u012bns Raudive", "South West Peninsula League", "Transporter 3", "1983", "December 13, 1920", "Gaelic", "more than 265 million", "January 2004", "The Eisenhower Executive Office Building", "Big 12 Conference", "Thocmentony", "thirteen", "Robert Bunda", "New Jersey", "Black Panther Party", "Walt Disney and Ub Iwerks", "\"Queen In-hyun's Man\"", "Woodsy owl", "Daniel Louis Castellaneta", "other individuals, teams, or entire organizations", "1,467 rooms", "Ian Rush", "John Alexander-Arnold", "The 2008\u201309 UEFA Champions League", "Kramer Guitars", "Florida and Oklahoma", "1968", "Holston River", "July 10, 2017", "London", "science fiction", "Neon City", "Stephen Mangan", "largest Mission Revival Style building in the United States", "George Balanchine", "\"The Terminator\"", "Samoa", "fifth studio album", "Timo Hildebrand", "Univision", "first flume ride in Ireland", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "the dome", "the Mishnah", "Mexico", "Julie Andrews Edwards", "Captain Mark Phillips", "Democratic VP candidate", "$75 for full-day class,", "\"Nu au Plateau de Sculpteur,\"", "a cigar", "The Bridges of Madison County", "Thomas Jefferson", "a foreign exchange option"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7470486111111111}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1692", "mrqa_hotpotqa-validation-1818", "mrqa_hotpotqa-validation-3934", "mrqa_hotpotqa-validation-2171", "mrqa_hotpotqa-validation-755", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-3096", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-2080", "mrqa_hotpotqa-validation-76", "mrqa_hotpotqa-validation-3120", "mrqa_hotpotqa-validation-2802", "mrqa_hotpotqa-validation-5557", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-5191", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-4619", "mrqa_triviaqa-validation-1508", "mrqa_newsqa-validation-901", "mrqa_searchqa-validation-12600", "mrqa_searchqa-validation-1518", "mrqa_naturalquestions-validation-8414"], "SR": 0.65625, "CSR": 0.5634615384615385, "retrieved_ids": ["mrqa_squad-train-11830", "mrqa_squad-train-54132", "mrqa_squad-train-47233", "mrqa_squad-train-18152", "mrqa_squad-train-8013", "mrqa_squad-train-42493", "mrqa_squad-train-46162", "mrqa_squad-train-79688", "mrqa_squad-train-41961", "mrqa_squad-train-51744", "mrqa_squad-train-13642", "mrqa_squad-train-46317", "mrqa_squad-train-73564", "mrqa_squad-train-3436", "mrqa_squad-train-84663", "mrqa_squad-train-54804", "mrqa_squad-train-52618", "mrqa_squad-train-2561", "mrqa_squad-train-65923", "mrqa_squad-train-85486", "mrqa_squad-train-9087", "mrqa_squad-train-70551", "mrqa_squad-train-47462", "mrqa_squad-train-14150", "mrqa_squad-train-69012", "mrqa_squad-train-43029", "mrqa_squad-train-40825", "mrqa_squad-train-72429", "mrqa_squad-train-20769", "mrqa_squad-train-63854", "mrqa_squad-train-56874", "mrqa_squad-train-7638", "mrqa_naturalquestions-validation-5769", "mrqa_hotpotqa-validation-5187", "mrqa_searchqa-validation-2247", "mrqa_naturalquestions-validation-3721", "mrqa_triviaqa-validation-6445", "mrqa_triviaqa-validation-2192", "mrqa_searchqa-validation-15243", "mrqa_naturalquestions-validation-5133", "mrqa_searchqa-validation-457", "mrqa_hotpotqa-validation-5534", "mrqa_newsqa-validation-2790", "mrqa_naturalquestions-validation-4236", "mrqa_searchqa-validation-6814", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-11651", "mrqa_hotpotqa-validation-3343", "mrqa_hotpotqa-validation-3606", "mrqa_triviaqa-validation-5009", "mrqa_triviaqa-validation-1975", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-1892", "mrqa_naturalquestions-validation-10026", "mrqa_searchqa-validation-15469", "mrqa_hotpotqa-validation-4760", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3406", "mrqa_searchqa-validation-1729", "mrqa_naturalquestions-validation-3300", "mrqa_newsqa-validation-1314", "mrqa_searchqa-validation-5936", "mrqa_triviaqa-validation-7076", "mrqa_hotpotqa-validation-5342"], "EFR": 1.0, "Overall": 0.7499579326923078}, {"timecode": 65, "before_eval_results": {"predictions": ["prophets and beloved religious leaders", "John Ernest Crawford", "Justin Timberlake", "cells", "Indo - Pacific", "the leaves of the plant species Stevia rebaudiana", "Gustav Bauer", "Universal Pictures", "May 2010", "American blues electric guitar musician T - Bone Walker", "recognisable structures in the world", "Bobby Darin", "Alex Skuby", "All four volumes were illustrated by E.H. Shepard", "James Rodr\u00edguez", "Lou Rawls", "Andrew Garfield", "Juliet", "Payaya Indians", "the Whig Party's colorful Log Cabin Campaign in the 1840 United States presidential election", "Robert Irsay", "Infiltration is the process by which water on the ground surface enters the soil", "1940", "the pulmonary arteries", "Puente Hills Mall", "1977", "HTTP / 1.1 200 OK", "June 1992", "the National Health Service ( NHS )", "28 July 1914 to 11 November 1918", "Richard Stallman", "1", "October 27, 1904", "by the early - to - mid fourth century the Western Christian Church had placed Christmas on December 25,", "monitor lizards", "Tom Burlinson, Red Symons and Dannii Minogue", "the final scene of the fourth season", "Auburn Tigers football team", "during meiosis", "a contemporary drama in a rural setting", "Yuzuru Hanyu", "The Italian Agostino Bassi", "Rachel Sarah Bilson", "plant matter that contained spores of dung fungus", "Jonathan Cheban", "2015", "computers or in an organised paper filing system", "the bicameral Congress", "Missouri River", "sport utility vehicles", "March 2, 2016", "nadal", "In Reel Life: In Real Life:", "Gretel and Gretel", "\"Get Him to the Greek\"", "Netflix", "The highway's eastern terminus is at U.S. Route 71 in Kansas City, Missouri", "three", "Rolling Stone magazine", "fifth", "Tina Turner", "Bingo SOLO", "Elgin", "salve"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5976997099619381}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, false, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, true, true, false, false, false], "QA-F1": [0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 0.08695652173913043, 1.0, 0.0, 1.0, 0.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.0, 1.0, 0.8, 1.0, 0.14814814814814814, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-1430", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9144", "mrqa_naturalquestions-validation-368", "mrqa_naturalquestions-validation-4552", "mrqa_naturalquestions-validation-746", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4018", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8612", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-1698", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-5599", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-8733", "mrqa_naturalquestions-validation-9162", "mrqa_naturalquestions-validation-5751", "mrqa_triviaqa-validation-266", "mrqa_triviaqa-validation-4814", "mrqa_triviaqa-validation-5315", "mrqa_hotpotqa-validation-5271", "mrqa_hotpotqa-validation-3806", "mrqa_newsqa-validation-2388", "mrqa_searchqa-validation-9384", "mrqa_searchqa-validation-13572", "mrqa_triviaqa-validation-2486"], "SR": 0.484375, "CSR": 0.5622632575757576, "retrieved_ids": ["mrqa_squad-train-36493", "mrqa_squad-train-44902", "mrqa_squad-train-51083", "mrqa_squad-train-60633", "mrqa_squad-train-38155", "mrqa_squad-train-64265", "mrqa_squad-train-64057", "mrqa_squad-train-70612", "mrqa_squad-train-4647", "mrqa_squad-train-22883", "mrqa_squad-train-75460", "mrqa_squad-train-79280", "mrqa_squad-train-38910", "mrqa_squad-train-43135", "mrqa_squad-train-83279", "mrqa_squad-train-29415", "mrqa_squad-train-64414", "mrqa_squad-train-72445", "mrqa_squad-train-72278", "mrqa_squad-train-84948", "mrqa_squad-train-7630", "mrqa_squad-train-63205", "mrqa_squad-train-41990", "mrqa_squad-train-16403", "mrqa_squad-train-37915", "mrqa_squad-train-58552", "mrqa_squad-train-78673", "mrqa_squad-train-54464", "mrqa_squad-train-53011", "mrqa_squad-train-13020", "mrqa_squad-train-60009", "mrqa_squad-train-12579", "mrqa_hotpotqa-validation-4986", "mrqa_triviaqa-validation-3102", "mrqa_naturalquestions-validation-7405", "mrqa_searchqa-validation-8907", "mrqa_hotpotqa-validation-2715", "mrqa_triviaqa-validation-7062", "mrqa_hotpotqa-validation-2978", "mrqa_searchqa-validation-9250", "mrqa_triviaqa-validation-2802", "mrqa_hotpotqa-validation-3431", "mrqa_searchqa-validation-12600", "mrqa_hotpotqa-validation-728", "mrqa_searchqa-validation-2219", "mrqa_hotpotqa-validation-765", "mrqa_newsqa-validation-3942", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-4182", "mrqa_naturalquestions-validation-1008", "mrqa_squad-validation-89", "mrqa_naturalquestions-validation-3802", "mrqa_newsqa-validation-1351", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-3212", "mrqa_searchqa-validation-2041", "mrqa_triviaqa-validation-4034", "mrqa_triviaqa-validation-3263", "mrqa_naturalquestions-validation-1904", "mrqa_newsqa-validation-2485", "mrqa_naturalquestions-validation-7489", "mrqa_triviaqa-validation-4946", "mrqa_searchqa-validation-12527"], "EFR": 0.9696969696969697, "Overall": 0.7436576704545456}, {"timecode": 66, "before_eval_results": {"predictions": ["braille", "james Garner", "720\u00b0", "Steely Dan", "gladiatorball", "c Clement Richard Attlee", "about a mile north of the village of Dunvegan", "head cheese", "bruce wayne", "stone age", "bieber", "norway", "1925 novel", "gunpowder Plot of 1605", "Moldova", "morocco", "edwina Currie", "sprite", "IKEA", "sotheby\u2019s", "Some Like It Hot", "Ralph Vaughan Williams", "Tony Blair", "pickwick", "four", "caracas", "Ireland", "The Donington Grand Prix Collection is, quite simply, the largest showcase of Grand Prix racing cars in the world", "Jim Peters", "horse racing", "onion", "bobby brown", "1948", "monoceros", "Sikh", "giraffe", "kabuki", "email", "zachary Taylor", "indigo", "france", "\u201cFor Gallantry;\u201d", "Swindon Town", "cricket", "jordan", "iranma  Naingngandaw", "south", "hongi", "british", "stephen", "Italy", "`` Far Away '' by Jos\u00e9 Gonz\u00e1lez with Best Song in a Game", "Buddhism", "endocytosis", "Hechingen", "1986", "Charles L. Clifford", "Eleven", "Joe Pantoliano", "Robert Barnett", "Jeopardy", "The Bridges of Madison County", "Paraguay", "WikiLeaks"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6113095238095239}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.2, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-728", "mrqa_triviaqa-validation-5759", "mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-5239", "mrqa_triviaqa-validation-7706", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3091", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-1031", "mrqa_triviaqa-validation-1283", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-7085", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-7545", "mrqa_triviaqa-validation-4887", "mrqa_triviaqa-validation-23", "mrqa_triviaqa-validation-7525", "mrqa_naturalquestions-validation-2981", "mrqa_naturalquestions-validation-10355", "mrqa_hotpotqa-validation-2378", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2030", "mrqa_searchqa-validation-3081", "mrqa_hotpotqa-validation-1714"], "SR": 0.546875, "CSR": 0.5620335820895522, "retrieved_ids": ["mrqa_squad-train-31957", "mrqa_squad-train-75491", "mrqa_squad-train-45559", "mrqa_squad-train-11239", "mrqa_squad-train-81519", "mrqa_squad-train-84329", "mrqa_squad-train-49783", "mrqa_squad-train-30546", "mrqa_squad-train-83914", "mrqa_squad-train-21267", "mrqa_squad-train-64746", "mrqa_squad-train-15837", "mrqa_squad-train-83004", "mrqa_squad-train-45963", "mrqa_squad-train-67088", "mrqa_squad-train-6735", "mrqa_squad-train-38872", "mrqa_squad-train-33493", "mrqa_squad-train-29218", "mrqa_squad-train-26017", "mrqa_squad-train-45869", "mrqa_squad-train-36552", "mrqa_squad-train-31684", "mrqa_squad-train-5636", "mrqa_squad-train-16488", "mrqa_squad-train-65316", "mrqa_squad-train-21627", "mrqa_squad-train-47781", "mrqa_squad-train-11590", "mrqa_squad-train-79454", "mrqa_squad-train-26179", "mrqa_squad-train-55442", "mrqa_squad-validation-1108", "mrqa_naturalquestions-validation-10277", "mrqa_searchqa-validation-16960", "mrqa_hotpotqa-validation-3207", "mrqa_hotpotqa-validation-1372", "mrqa_naturalquestions-validation-9007", "mrqa_hotpotqa-validation-278", "mrqa_squad-validation-7011", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-524", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-5760", "mrqa_triviaqa-validation-2862", "mrqa_naturalquestions-validation-9563", "mrqa_newsqa-validation-54", "mrqa_hotpotqa-validation-4818", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-3533", "mrqa_triviaqa-validation-719", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-6545", "mrqa_triviaqa-validation-4443", "mrqa_searchqa-validation-9246", "mrqa_searchqa-validation-16716", "mrqa_squad-validation-1272", "mrqa_newsqa-validation-1816", "mrqa_squad-validation-1808", "mrqa_naturalquestions-validation-4698", "mrqa_triviaqa-validation-2242", "mrqa_newsqa-validation-2862"], "EFR": 0.8620689655172413, "Overall": 0.7220861345213587}, {"timecode": 67, "before_eval_results": {"predictions": ["yann martel", "The Archers", "Tiffany and Co.", "Nguni", "Cambridge", "france", "1830", "Lorraine", "delusional parisitosis", "george chaucer", "sports agent", "rough collie", "Sen. Edward M. Kennedy", "james", "red squirrels", "Richard Lester", "Buick", "polish", "gooseberry", "no George, they isn't", "The Color Purple", "Elizabeth Montgomery", "Il Divo", "Barack Obama", "1984", "Bosnia", "China", "Quito", "Cromwell", "grimy young", "Leon Baptiste", "360", "joseph b Brahms", "12th", "Mitford", "Sparta", "Hyundai", "november", "Julian Fellowes,", "haddock", "yemen", "George Miller", "mainland China", "Nowhere Boy", "glenmarkt", "brain", "quant pole", "Edward ignorance", "35", "back", "jury Lane, Haverfordwest", "Robyn", "South Asia", "Uralic languages", "New York City", "early 1942", "a card (or cards) during a card game", "Larry Zeiger", "India", "[Dan] Brown, [ Ron] Howard and [Tom] Hanks", "Oakland Raiders", "the Mediterranean", "Isabella", "Turing"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6442708333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3632", "mrqa_triviaqa-validation-3849", "mrqa_triviaqa-validation-1176", "mrqa_triviaqa-validation-6966", "mrqa_triviaqa-validation-7668", "mrqa_triviaqa-validation-5265", "mrqa_triviaqa-validation-178", "mrqa_triviaqa-validation-616", "mrqa_triviaqa-validation-2911", "mrqa_triviaqa-validation-7485", "mrqa_triviaqa-validation-5412", "mrqa_triviaqa-validation-6024", "mrqa_triviaqa-validation-5658", "mrqa_triviaqa-validation-4792", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-3288", "mrqa_triviaqa-validation-3996", "mrqa_triviaqa-validation-7592", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-1788", "mrqa_triviaqa-validation-467", "mrqa_triviaqa-validation-2460", "mrqa_triviaqa-validation-1501", "mrqa_naturalquestions-validation-5787", "mrqa_hotpotqa-validation-2623", "mrqa_hotpotqa-validation-3709", "mrqa_hotpotqa-validation-1641", "mrqa_newsqa-validation-1334", "mrqa_newsqa-validation-177", "mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-1508", "mrqa_searchqa-validation-475"], "SR": 0.484375, "CSR": 0.5608915441176471, "retrieved_ids": ["mrqa_squad-train-81778", "mrqa_squad-train-49001", "mrqa_squad-train-2924", "mrqa_squad-train-15489", "mrqa_squad-train-60155", "mrqa_squad-train-43792", "mrqa_squad-train-42048", "mrqa_squad-train-20277", "mrqa_squad-train-17775", "mrqa_squad-train-70746", "mrqa_squad-train-62233", "mrqa_squad-train-59847", "mrqa_squad-train-47135", "mrqa_squad-train-33124", "mrqa_squad-train-49107", "mrqa_squad-train-29588", "mrqa_squad-train-50616", "mrqa_squad-train-65780", "mrqa_squad-train-34475", "mrqa_squad-train-85858", "mrqa_squad-train-3580", "mrqa_squad-train-84604", "mrqa_squad-train-28383", "mrqa_squad-train-71060", "mrqa_squad-train-12215", "mrqa_squad-train-8896", "mrqa_squad-train-41495", "mrqa_squad-train-75253", "mrqa_squad-train-50279", "mrqa_squad-train-22033", "mrqa_squad-train-72270", "mrqa_squad-train-36510", "mrqa_searchqa-validation-518", "mrqa_triviaqa-validation-6041", "mrqa_naturalquestions-validation-6545", "mrqa_newsqa-validation-349", "mrqa_hotpotqa-validation-5455", "mrqa_newsqa-validation-2227", "mrqa_hotpotqa-validation-3538", "mrqa_naturalquestions-validation-1284", "mrqa_searchqa-validation-4878", "mrqa_hotpotqa-validation-1542", "mrqa_triviaqa-validation-4622", "mrqa_triviaqa-validation-7039", "mrqa_hotpotqa-validation-1997", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-7262", "mrqa_hotpotqa-validation-2635", "mrqa_triviaqa-validation-3215", "mrqa_searchqa-validation-6208", "mrqa_searchqa-validation-12880", "mrqa_newsqa-validation-901", "mrqa_triviaqa-validation-1824", "mrqa_hotpotqa-validation-5489", "mrqa_searchqa-validation-8106", "mrqa_searchqa-validation-12600", "mrqa_newsqa-validation-2723", "mrqa_searchqa-validation-13023", "mrqa_hotpotqa-validation-3343", "mrqa_searchqa-validation-11769", "mrqa_hotpotqa-validation-5174", "mrqa_hotpotqa-validation-3220", "mrqa_naturalquestions-validation-4236", "mrqa_hotpotqa-validation-4450"], "EFR": 0.9090909090909091, "Overall": 0.7312621156417112}, {"timecode": 68, "before_eval_results": {"predictions": ["Siri", "Philippines", "heavy turbulence about 02:15 a.m. local time Monday (10:15 p.m.) ET Sunday),", "Brian Smith,", "Tim Clark, Matt Kuchar and Bubba Watson", "\"black rain\" of drilling fluid and a roar of escaping gas erupted from the doomed Deepwater Horizon shortly before the explosion that sank the oil rig,", "Ricardo Valles de la Rosa,", "Elin Nordegren", "We Found Love", "immediate release into the United States of 17 Chinese", "millionaire's surtax", "E! News\"", "about 50 formal applications for speed attempts during 2008.", "two-state solution", "Yusuf Saad Kamel", "foyer of the BBC building in Glasgow, Scotland", "his father,", "Iran", "South Africa's", "insurgency,", "of all faiths", "The Rosie Show", "Ricardo Valles de la Rosa,", "March 24,", "left his indelible fingerprints on the entertainment industry.", "in the mouth.", "about 100 light bulbs.", "Anne Frank,", "The EU naval force", "five", "Joel \"Taz\" Di Gregorio", "The father of Haleigh Cummings,", "off the coast of Dubai", "near the Somali coast", "municipal police officers", "job training for all service members leaving the military.", "shock, quickly followed by speculation about what was going to happen next,\"", "northwestern Montana", "Iran test-launched a rocket capable of carrying a satellite,", "without bail and will be arraigned June 25,", "February 12", "general astonishment", "a place for another non-European Union player in Frank Rijkaard's squad.", "Chile", "The two were separated in June 2004", "Democratic VP candidate", "martial arts,", "poor, older than 55, rural residents or racial minorities,", "The Tupolev Tu-160 strategic bombers landed at Venezuela's Libertador military airfield and \"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "June 6, 1944,", "The escalating conflict in Mogadishu is having a devastating impact on the city's population causing enormous suffering and massive displacement,\"", "nations that have had sovereignty over some or all of the current territory of the U.S. state of Texas", "a standalone variation on the standard speed limit sign, with a yellow background instead of a white one, the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead", "Eurasian Plate", "horses", "Samuel H. Rumph", "Brooklyn", "Tetrahydrogestrinone", "Real Madrid and the Spain national team", "Brea, California", "Titanic", "Bongoyo Island", "dualism", "(William) Wordsworth"], "metric_results": {"EM": 0.5, "QA-F1": 0.6077255964755965}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.11999999999999998, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.19999999999999998, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 0.0, 0.8, 0.8571428571428571, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3, 0.9189189189189189, 0.05405405405405406, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-670", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-1705", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2198", "mrqa_newsqa-validation-1789", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-3992", "mrqa_newsqa-validation-3768", "mrqa_newsqa-validation-973", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-169", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-3164", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-1139", "mrqa_triviaqa-validation-55", "mrqa_triviaqa-validation-884", "mrqa_searchqa-validation-6786"], "SR": 0.5, "CSR": 0.5600090579710144, "retrieved_ids": ["mrqa_squad-train-4384", "mrqa_squad-train-83950", "mrqa_squad-train-20174", "mrqa_squad-train-29408", "mrqa_squad-train-10628", "mrqa_squad-train-53795", "mrqa_squad-train-72258", "mrqa_squad-train-57795", "mrqa_squad-train-37220", "mrqa_squad-train-20905", "mrqa_squad-train-81892", "mrqa_squad-train-28250", "mrqa_squad-train-38021", "mrqa_squad-train-5227", "mrqa_squad-train-21106", "mrqa_squad-train-28557", "mrqa_squad-train-41822", "mrqa_squad-train-69371", "mrqa_squad-train-79252", "mrqa_squad-train-52898", "mrqa_squad-train-81077", "mrqa_squad-train-84288", "mrqa_squad-train-56375", "mrqa_squad-train-11708", "mrqa_squad-train-11549", "mrqa_squad-train-73471", "mrqa_squad-train-70547", "mrqa_squad-train-43367", "mrqa_squad-train-57431", "mrqa_squad-train-11357", "mrqa_squad-train-18210", "mrqa_squad-train-73749", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-9551", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-7163", "mrqa_searchqa-validation-15174", "mrqa_squad-validation-8452", "mrqa_searchqa-validation-1236", "mrqa_searchqa-validation-15378", "mrqa_triviaqa-validation-2181", "mrqa_squad-validation-4901", "mrqa_naturalquestions-validation-1400", "mrqa_searchqa-validation-58", "mrqa_hotpotqa-validation-2374", "mrqa_triviaqa-validation-5600", "mrqa_newsqa-validation-2418", "mrqa_hotpotqa-validation-534", "mrqa_hotpotqa-validation-5314", "mrqa_triviaqa-validation-2883", "mrqa_triviaqa-validation-3948", "mrqa_newsqa-validation-1216", "mrqa_triviaqa-validation-4046", "mrqa_triviaqa-validation-1178", "mrqa_searchqa-validation-6814", "mrqa_newsqa-validation-198", "mrqa_newsqa-validation-1142", "mrqa_triviaqa-validation-7062", "mrqa_searchqa-validation-2674", "mrqa_hotpotqa-validation-2465", "mrqa_searchqa-validation-16889", "mrqa_triviaqa-validation-2610", "mrqa_newsqa-validation-2748", "mrqa_searchqa-validation-4950"], "EFR": 0.75, "Overall": 0.699267436594203}, {"timecode": 69, "before_eval_results": {"predictions": ["1902", "Max Martin and Shellback", "Americana Manhasset", "Mayfair", "Minister for Social Protection", "1864", "Tunisian", "the southern North Sea", "Larry Richard Drake", "The Bad Hemingway Contest", "Culiac\u00e1n, Sinaloa", "villanelle", "Ezo", "\"Back to December\"", "Heather Elizabeth Langenkamp", "two Nobel Peace Prizes", "Londonderry", "Daniel Craig", "Hamburger SV", "Four Weddings and a Funeral", "Eisstadion Davos", "Mulberry", "Edward Longshanks and the Hammer of the Scots", "late 12th Century", "Christopher McCulloch", "Novel", "The Krypto Report", "Fort Saint Anthony", "IT products and services", "Japan", "1919", "Tak and the Power of Juju", "the western end of the National Mall", "Len Wiseman", "Stephen Crawford Young", "\"My Backyard\" in Jacksonville, Florida", "Gerard \"Gerry\" Adams", "\"Kill Your Darlings\"", "Girls' Generation", "Robert Matthew Hurley", "September 1901", "Tuesday", "anabolic\u2013androgenic steroids", "North West England", "NCAA's Division I", "\"Polovetskie plyaski\"", "Virginia", "1961", "1896", "2000", "Donald Sterling", "20 - year period", "Saint Peter", "mining", "the Earth", "best value diamond", "the Great War", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Asashoryu", "Venezuela's Libertador military airfield", "Juilliard School", "lizard hips", "the Boy Scouts of America", "Inuit"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7293154761904762}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, true, true, false, false, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.5, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2863", "mrqa_hotpotqa-validation-3095", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-1986", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-3245", "mrqa_hotpotqa-validation-512", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-1572", "mrqa_hotpotqa-validation-3446", "mrqa_hotpotqa-validation-3428", "mrqa_hotpotqa-validation-5725", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-375", "mrqa_triviaqa-validation-984", "mrqa_triviaqa-validation-5271", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-3029", "mrqa_searchqa-validation-7074", "mrqa_searchqa-validation-11439", "mrqa_searchqa-validation-4320"], "SR": 0.59375, "CSR": 0.5604910714285714, "retrieved_ids": ["mrqa_squad-train-81846", "mrqa_squad-train-16087", "mrqa_squad-train-85687", "mrqa_squad-train-31245", "mrqa_squad-train-12782", "mrqa_squad-train-19593", "mrqa_squad-train-24400", "mrqa_squad-train-53425", "mrqa_squad-train-4146", "mrqa_squad-train-75548", "mrqa_squad-train-75086", "mrqa_squad-train-67708", "mrqa_squad-train-49141", "mrqa_squad-train-35885", "mrqa_squad-train-73181", "mrqa_squad-train-82195", "mrqa_squad-train-15125", "mrqa_squad-train-17844", "mrqa_squad-train-59557", "mrqa_squad-train-70578", "mrqa_squad-train-32121", "mrqa_squad-train-26937", "mrqa_squad-train-68476", "mrqa_squad-train-45772", "mrqa_squad-train-26265", "mrqa_squad-train-627", "mrqa_squad-train-14890", "mrqa_squad-train-8895", "mrqa_squad-train-39094", "mrqa_squad-train-2443", "mrqa_squad-train-21662", "mrqa_squad-train-45928", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-3013", "mrqa_naturalquestions-validation-10029", "mrqa_newsqa-validation-1314", "mrqa_triviaqa-validation-554", "mrqa_naturalquestions-validation-1694", "mrqa_hotpotqa-validation-2257", "mrqa_triviaqa-validation-7244", "mrqa_squad-validation-7457", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-4053", "mrqa_squad-validation-3374", "mrqa_searchqa-validation-16716", "mrqa_naturalquestions-validation-8962", "mrqa_hotpotqa-validation-4568", "mrqa_triviaqa-validation-1643", "mrqa_searchqa-validation-8042", "mrqa_naturalquestions-validation-7101", "mrqa_triviaqa-validation-3091", "mrqa_newsqa-validation-1643", "mrqa_squad-validation-434", "mrqa_hotpotqa-validation-4760", "mrqa_searchqa-validation-1948", "mrqa_hotpotqa-validation-3871", "mrqa_newsqa-validation-3687", "mrqa_hotpotqa-validation-2811", "mrqa_triviaqa-validation-3170", "mrqa_naturalquestions-validation-4645", "mrqa_hotpotqa-validation-3929", "mrqa_naturalquestions-validation-10490", "mrqa_newsqa-validation-2231", "mrqa_squad-validation-7537"], "EFR": 0.8846153846153846, "Overall": 0.7262869162087913}, {"timecode": 70, "UKR": 0.80078125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1052", "mrqa_hotpotqa-validation-1088", "mrqa_hotpotqa-validation-1247", "mrqa_hotpotqa-validation-1292", "mrqa_hotpotqa-validation-13", "mrqa_hotpotqa-validation-1473", "mrqa_hotpotqa-validation-1490", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-1687", "mrqa_hotpotqa-validation-1691", "mrqa_hotpotqa-validation-176", "mrqa_hotpotqa-validation-1838", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-1856", "mrqa_hotpotqa-validation-189", "mrqa_hotpotqa-validation-1986", "mrqa_hotpotqa-validation-2045", "mrqa_hotpotqa-validation-2111", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-2378", "mrqa_hotpotqa-validation-2476", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2590", "mrqa_hotpotqa-validation-2665", "mrqa_hotpotqa-validation-2873", "mrqa_hotpotqa-validation-2892", "mrqa_hotpotqa-validation-2903", "mrqa_hotpotqa-validation-2908", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-2952", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-2984", "mrqa_hotpotqa-validation-307", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3175", "mrqa_hotpotqa-validation-3201", "mrqa_hotpotqa-validation-3245", "mrqa_hotpotqa-validation-3313", "mrqa_hotpotqa-validation-3323", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3374", "mrqa_hotpotqa-validation-3428", "mrqa_hotpotqa-validation-346", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-3793", "mrqa_hotpotqa-validation-3934", "mrqa_hotpotqa-validation-3937", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-4038", "mrqa_hotpotqa-validation-4084", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-4510", "mrqa_hotpotqa-validation-4632", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4818", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4841", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-5063", "mrqa_hotpotqa-validation-5172", "mrqa_hotpotqa-validation-5358", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-542", "mrqa_hotpotqa-validation-5427", "mrqa_hotpotqa-validation-5666", "mrqa_hotpotqa-validation-5719", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-5864", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-66", "mrqa_hotpotqa-validation-76", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-884", "mrqa_hotpotqa-validation-9", "mrqa_hotpotqa-validation-916", "mrqa_hotpotqa-validation-975", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-10159", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-10417", "mrqa_naturalquestions-validation-10493", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-1336", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1797", "mrqa_naturalquestions-validation-1824", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2090", "mrqa_naturalquestions-validation-214", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2379", "mrqa_naturalquestions-validation-2400", "mrqa_naturalquestions-validation-2515", "mrqa_naturalquestions-validation-2837", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-2981", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-3569", "mrqa_naturalquestions-validation-3692", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-3930", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-4014", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4307", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5072", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-5331", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-5425", "mrqa_naturalquestions-validation-5503", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6069", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-6800", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-6901", "mrqa_naturalquestions-validation-6913", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-7182", "mrqa_naturalquestions-validation-7410", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-757", "mrqa_naturalquestions-validation-7595", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-7806", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7856", "mrqa_naturalquestions-validation-7892", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-9560", "mrqa_naturalquestions-validation-9608", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-9871", "mrqa_naturalquestions-validation-9878", "mrqa_newsqa-validation-1013", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-1183", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-1365", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1547", "mrqa_newsqa-validation-1547", "mrqa_newsqa-validation-1661", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-175", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-183", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-2002", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-2494", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2856", "mrqa_newsqa-validation-2861", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2990", "mrqa_newsqa-validation-2992", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3085", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-3179", "mrqa_newsqa-validation-319", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-3520", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-378", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3865", "mrqa_newsqa-validation-3897", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3992", "mrqa_newsqa-validation-406", "mrqa_newsqa-validation-4060", "mrqa_newsqa-validation-466", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-606", "mrqa_newsqa-validation-632", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-946", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-10330", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-10776", "mrqa_searchqa-validation-10999", "mrqa_searchqa-validation-11024", "mrqa_searchqa-validation-11216", "mrqa_searchqa-validation-11294", "mrqa_searchqa-validation-11425", "mrqa_searchqa-validation-1173", "mrqa_searchqa-validation-11898", "mrqa_searchqa-validation-1196", "mrqa_searchqa-validation-12085", "mrqa_searchqa-validation-12127", "mrqa_searchqa-validation-12151", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-12360", "mrqa_searchqa-validation-12782", "mrqa_searchqa-validation-13014", "mrqa_searchqa-validation-13765", "mrqa_searchqa-validation-13803", "mrqa_searchqa-validation-14307", "mrqa_searchqa-validation-14471", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-1497", "mrqa_searchqa-validation-15064", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-15709", "mrqa_searchqa-validation-15716", "mrqa_searchqa-validation-15725", "mrqa_searchqa-validation-16016", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-16162", "mrqa_searchqa-validation-16346", "mrqa_searchqa-validation-16865", "mrqa_searchqa-validation-16910", "mrqa_searchqa-validation-191", "mrqa_searchqa-validation-1950", "mrqa_searchqa-validation-1966", "mrqa_searchqa-validation-2189", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-2481", "mrqa_searchqa-validation-2540", "mrqa_searchqa-validation-2591", "mrqa_searchqa-validation-2622", "mrqa_searchqa-validation-2673", "mrqa_searchqa-validation-2943", "mrqa_searchqa-validation-30", "mrqa_searchqa-validation-3081", "mrqa_searchqa-validation-324", "mrqa_searchqa-validation-327", "mrqa_searchqa-validation-3299", "mrqa_searchqa-validation-3455", "mrqa_searchqa-validation-3838", "mrqa_searchqa-validation-4305", "mrqa_searchqa-validation-4320", "mrqa_searchqa-validation-4380", "mrqa_searchqa-validation-4509", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-4878", "mrqa_searchqa-validation-5060", "mrqa_searchqa-validation-5477", "mrqa_searchqa-validation-5971", "mrqa_searchqa-validation-6150", "mrqa_searchqa-validation-6782", "mrqa_searchqa-validation-6814", "mrqa_searchqa-validation-6829", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-6961", "mrqa_searchqa-validation-6977", "mrqa_searchqa-validation-7162", "mrqa_searchqa-validation-7186", "mrqa_searchqa-validation-7322", "mrqa_searchqa-validation-7521", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7880", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-7932", "mrqa_searchqa-validation-8166", "mrqa_searchqa-validation-8331", "mrqa_searchqa-validation-8481", "mrqa_searchqa-validation-8648", "mrqa_searchqa-validation-8691", "mrqa_searchqa-validation-8907", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-8986", "mrqa_searchqa-validation-9096", "mrqa_searchqa-validation-9438", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-10067", "mrqa_squad-validation-1023", "mrqa_squad-validation-10335", "mrqa_squad-validation-10466", "mrqa_squad-validation-10483", "mrqa_squad-validation-1071", "mrqa_squad-validation-1116", "mrqa_squad-validation-1215", "mrqa_squad-validation-1251", "mrqa_squad-validation-1312", "mrqa_squad-validation-1856", "mrqa_squad-validation-1959", "mrqa_squad-validation-2098", "mrqa_squad-validation-2434", "mrqa_squad-validation-2437", "mrqa_squad-validation-2443", "mrqa_squad-validation-2458", "mrqa_squad-validation-2717", "mrqa_squad-validation-2888", "mrqa_squad-validation-3202", "mrqa_squad-validation-343", "mrqa_squad-validation-3551", "mrqa_squad-validation-356", "mrqa_squad-validation-3633", "mrqa_squad-validation-3823", "mrqa_squad-validation-3953", "mrqa_squad-validation-4110", "mrqa_squad-validation-4430", "mrqa_squad-validation-4595", "mrqa_squad-validation-4870", "mrqa_squad-validation-5112", "mrqa_squad-validation-512", "mrqa_squad-validation-5272", "mrqa_squad-validation-5492", "mrqa_squad-validation-5590", "mrqa_squad-validation-5686", "mrqa_squad-validation-5874", "mrqa_squad-validation-5889", "mrqa_squad-validation-60", "mrqa_squad-validation-6091", "mrqa_squad-validation-6255", "mrqa_squad-validation-629", "mrqa_squad-validation-6316", "mrqa_squad-validation-6324", "mrqa_squad-validation-6373", "mrqa_squad-validation-6393", "mrqa_squad-validation-6524", "mrqa_squad-validation-6539", "mrqa_squad-validation-6657", "mrqa_squad-validation-6690", "mrqa_squad-validation-6831", "mrqa_squad-validation-687", "mrqa_squad-validation-7068", "mrqa_squad-validation-7082", "mrqa_squad-validation-7144", "mrqa_squad-validation-7162", "mrqa_squad-validation-7209", "mrqa_squad-validation-7744", "mrqa_squad-validation-7937", "mrqa_squad-validation-805", "mrqa_squad-validation-8436", "mrqa_squad-validation-8662", "mrqa_squad-validation-8747", "mrqa_squad-validation-8761", "mrqa_squad-validation-8807", "mrqa_squad-validation-8872", "mrqa_squad-validation-8881", "mrqa_squad-validation-9154", "mrqa_squad-validation-9484", "mrqa_squad-validation-9578", "mrqa_squad-validation-9761", "mrqa_triviaqa-validation-1076", "mrqa_triviaqa-validation-1088", "mrqa_triviaqa-validation-1123", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1183", "mrqa_triviaqa-validation-1272", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1575", "mrqa_triviaqa-validation-1657", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-1965", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-2458", "mrqa_triviaqa-validation-2518", "mrqa_triviaqa-validation-2523", "mrqa_triviaqa-validation-2610", "mrqa_triviaqa-validation-2653", "mrqa_triviaqa-validation-2653", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-3025", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-305", "mrqa_triviaqa-validation-3064", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-3104", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3201", "mrqa_triviaqa-validation-3263", "mrqa_triviaqa-validation-3288", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-3376", "mrqa_triviaqa-validation-344", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-3625", "mrqa_triviaqa-validation-3630", "mrqa_triviaqa-validation-3631", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3739", "mrqa_triviaqa-validation-3812", "mrqa_triviaqa-validation-3865", "mrqa_triviaqa-validation-393", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-401", "mrqa_triviaqa-validation-4086", "mrqa_triviaqa-validation-4146", "mrqa_triviaqa-validation-4167", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-4436", "mrqa_triviaqa-validation-4450", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-4584", "mrqa_triviaqa-validation-4614", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4887", "mrqa_triviaqa-validation-4891", "mrqa_triviaqa-validation-4923", "mrqa_triviaqa-validation-5101", "mrqa_triviaqa-validation-521", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-5265", "mrqa_triviaqa-validation-543", "mrqa_triviaqa-validation-5440", "mrqa_triviaqa-validation-5469", "mrqa_triviaqa-validation-5496", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5735", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-599", "mrqa_triviaqa-validation-6289", "mrqa_triviaqa-validation-6346", "mrqa_triviaqa-validation-6353", "mrqa_triviaqa-validation-6428", "mrqa_triviaqa-validation-6504", "mrqa_triviaqa-validation-6599", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-6738", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-7039", "mrqa_triviaqa-validation-7062", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7319", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-7506", "mrqa_triviaqa-validation-7557", "mrqa_triviaqa-validation-7668", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-915", "mrqa_triviaqa-validation-935"], "OKR": 0.900390625, "KG": 0.4984375, "before_eval_results": {"predictions": ["Arkansas", "early 1970s", "Pittsburgh", "875 acre", "every aspect of public and private life", "Maria von Trapp", "Rat Pack", "12", "port city of Aden", "Scott Eastwood", "United States and Canada", "Patricia Veryan", "David Michael Bautista Jr.", "2 March 1972", "Tie Domi", "Mika H\u00e4kkinen", "Princess Jessica", "Queensland", "\"master builder\" of mid-20th century New York City", "Honolulu", "Eureka", "Badfinger", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "XVideos", "the performance of Hofmannsthal's \"Jedermann\"", "political correctness", "devotional", "Martin Joseph O'Malley", "1891", "Secret Intelligence Service", "Currer Bell", "University of Nevada, Las Vegas (UNLV)", "mermaid", "850 m", "DeskMate", "Athenion", "Adolfo Rodr\u00edguez Sa\u00e1", "The Beatles", "Czech (Bohemian) and German (Franconian)", "ninth", "Hanna", "Manchester Victoria station", "a power amplifier", "\"My Love from the Star\" (2014)", "Captain Cook's Landing Place", "the new king in 1714", "Seventeen", "37", "bass", "Citizens for a Sound Economy", "Barbara Feldon", "H CO", "prophets", "Bill Russell", "Andre Agassi", "vienne", "Phillies", "fill those sandbags", "Caster Semenya", "stop manufacturing 14 unapproved narcotics that are widely used to treat pain.", "Cuyahoga River", "Uranium", "Peter Sellers", "river Elbe"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7434456168831169}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.9090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.06666666666666667, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-4123", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-626", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-5365", "mrqa_hotpotqa-validation-4500", "mrqa_hotpotqa-validation-1791", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-1544", "mrqa_hotpotqa-validation-4015", "mrqa_hotpotqa-validation-2125", "mrqa_hotpotqa-validation-1991", "mrqa_naturalquestions-validation-9220", "mrqa_triviaqa-validation-4263", "mrqa_triviaqa-validation-105", "mrqa_newsqa-validation-3842", "mrqa_newsqa-validation-1065", "mrqa_searchqa-validation-10027", "mrqa_triviaqa-validation-4324"], "SR": 0.65625, "CSR": 0.5618397887323944, "retrieved_ids": ["mrqa_squad-train-65510", "mrqa_squad-train-40364", "mrqa_squad-train-80691", "mrqa_squad-train-34034", "mrqa_squad-train-86192", "mrqa_squad-train-14804", "mrqa_squad-train-44486", "mrqa_squad-train-2279", "mrqa_squad-train-22190", "mrqa_squad-train-61666", "mrqa_squad-train-19700", "mrqa_squad-train-5334", "mrqa_squad-train-25163", "mrqa_squad-train-5066", "mrqa_squad-train-76937", "mrqa_squad-train-39750", "mrqa_squad-train-7127", "mrqa_squad-train-65533", "mrqa_squad-train-83517", "mrqa_squad-train-29752", "mrqa_squad-train-11995", "mrqa_squad-train-38551", "mrqa_squad-train-4647", "mrqa_squad-train-5772", "mrqa_squad-train-37039", "mrqa_squad-train-53248", "mrqa_squad-train-28261", "mrqa_squad-train-61557", "mrqa_squad-train-61071", "mrqa_squad-train-59919", "mrqa_squad-train-47", "mrqa_squad-train-14628", "mrqa_naturalquestions-validation-4645", "mrqa_searchqa-validation-14307", "mrqa_hotpotqa-validation-718", "mrqa_squad-validation-1116", "mrqa_searchqa-validation-4533", "mrqa_triviaqa-validation-1064", "mrqa_squad-validation-3207", "mrqa_naturalquestions-validation-8659", "mrqa_squad-validation-3863", "mrqa_newsqa-validation-2680", "mrqa_squad-validation-2443", "mrqa_hotpotqa-validation-4236", "mrqa_triviaqa-validation-6289", "mrqa_squad-validation-1272", "mrqa_newsqa-validation-85", "mrqa_hotpotqa-validation-4273", "mrqa_searchqa-validation-9007", "mrqa_naturalquestions-validation-9608", "mrqa_triviaqa-validation-1622", "mrqa_squad-validation-806", "mrqa_searchqa-validation-6786", "mrqa_hotpotqa-validation-5822", "mrqa_searchqa-validation-4320", "mrqa_hotpotqa-validation-3096", "mrqa_naturalquestions-validation-1423", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-5470", "mrqa_hotpotqa-validation-1457", "mrqa_triviaqa-validation-2883", "mrqa_newsqa-validation-3579", "mrqa_triviaqa-validation-3025", "mrqa_triviaqa-validation-5414"], "EFR": 0.9545454545454546, "Overall": 0.7431989236555698}, {"timecode": 71, "before_eval_results": {"predictions": ["Nearly eight in 10", "Marie-Therese Walter.", "help at-risk youth, victims of violent crimes and homeless children.", "Russian air force.", "female soldier,", "three", "Goa", "Iran", "100 percent", "Kenyan and Somali governments", "Susan Atkins,", "Casa de Campo International Airport in the Dominican Republic", "\"Operation Crank Call,\"", "228", "hostile war zones,", "National September 11 Memorial Museum", "Harlem,", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "last year's", "Elisabeth,", "1959", "his", "269,000", "issued his first military orders as leader of North Korea", "iTunes,", "a group of teenagers.", "Six", "kase Ng,", "27-year-old's", "outside influences in next month's run-off", "nuclear warheads", "\"A Whiter Shade of Pale\"", "security breach", "$250,000", "returning combat veterans", "$1.5 million.", "resources", "$10 billion", "Christopher Savoie", "United States, NATO member states, Russia", "1,500", "trading goods and services without exchanging money -- as a way to cope with tough economic times.", "Charman Sinkfield, 30; Demario Ware, 20; and Jquante Crews, 25", "Fiona MacKeown", "Sen. Barack Obama", "Ashley \"A.J.\" Jewell,", "a motor scooter that goes about 55 miles per hour -- on 12-inch wheels.", "shelling of the compound", "Japan and Singapore,", "pine beetles", "international aid agencies", "Aspirin", "either February 28 or March 1", "Indo - Pacific", "mining", "josezuma", "Maryland", "2012", "Acela Express", "Crackle", "a porcupine", "Oxygen", "the Bird of Prey", "Truman"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6457148754023754}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, false, false], "QA-F1": [0.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.04761904761904762, 0.0, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6363636363636364, 0.4615384615384615, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1303", "mrqa_newsqa-validation-3714", "mrqa_newsqa-validation-1399", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3753", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-1750", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-717", "mrqa_newsqa-validation-25", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-2491", "mrqa_newsqa-validation-933", "mrqa_naturalquestions-validation-4809", "mrqa_triviaqa-validation-2418", "mrqa_triviaqa-validation-4549", "mrqa_searchqa-validation-9135", "mrqa_searchqa-validation-14427"], "SR": 0.578125, "CSR": 0.5620659722222222, "retrieved_ids": ["mrqa_squad-train-59381", "mrqa_squad-train-62817", "mrqa_squad-train-47155", "mrqa_squad-train-62252", "mrqa_squad-train-66956", "mrqa_squad-train-2687", "mrqa_squad-train-37993", "mrqa_squad-train-27489", "mrqa_squad-train-66965", "mrqa_squad-train-17282", "mrqa_squad-train-36400", "mrqa_squad-train-51395", "mrqa_squad-train-29412", "mrqa_squad-train-7125", "mrqa_squad-train-11234", "mrqa_squad-train-29915", "mrqa_squad-train-5035", "mrqa_squad-train-34370", "mrqa_squad-train-10296", "mrqa_squad-train-43592", "mrqa_squad-train-17124", "mrqa_squad-train-36938", "mrqa_squad-train-23314", "mrqa_squad-train-2841", "mrqa_squad-train-36608", "mrqa_squad-train-83593", "mrqa_squad-train-22982", "mrqa_squad-train-45271", "mrqa_squad-train-49556", "mrqa_squad-train-27624", "mrqa_squad-train-34986", "mrqa_squad-train-30002", "mrqa_naturalquestions-validation-2291", "mrqa_newsqa-validation-1448", "mrqa_naturalquestions-validation-5580", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-2408", "mrqa_triviaqa-validation-476", "mrqa_searchqa-validation-6730", "mrqa_searchqa-validation-5591", "mrqa_triviaqa-validation-6024", "mrqa_triviaqa-validation-5724", "mrqa_triviaqa-validation-6783", "mrqa_hotpotqa-validation-472", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-3037", "mrqa_triviaqa-validation-3970", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1741", "mrqa_triviaqa-validation-5702", "mrqa_searchqa-validation-13649", "mrqa_hotpotqa-validation-3180", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2186", "mrqa_triviaqa-validation-2989", "mrqa_naturalquestions-validation-4803", "mrqa_triviaqa-validation-6125", "mrqa_searchqa-validation-4355", "mrqa_hotpotqa-validation-4181", "mrqa_hotpotqa-validation-3120", "mrqa_squad-validation-2657", "mrqa_triviaqa-validation-5808", "mrqa_hotpotqa-validation-3381", "mrqa_searchqa-validation-16623"], "EFR": 0.7407407407407407, "Overall": 0.7004832175925926}, {"timecode": 72, "before_eval_results": {"predictions": ["Ed Roland", "1997", "Sharyans Resources", "a marketing term for a vehicle that is both four - wheel - drive and primarily a road car", "Isaac Morris", "Texas A&M University", "stromal connective tissue", "in the last section of the Tanakh, known as the Ketuvim ( or `` Writings '' ), and a book of the Old Testament", "Anatomy ( Greek anatom\u0113, `` dissection '' )", "a maritime signal, indicating that the vessel flying it is about to leave", "President Lyndon Johnson", "Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Olivia Olson", "Eukarya -- called eukaryotes", "Mara Jade", "Gary Grimes as Hermie", "very important", "Richard of Shrewsbury, Duke of York", "Ashrita Furman", "Morty", "Jean Fernel", "in 1991, 1994, 2002, 2004 and 2010 in Switzerland, Austria, France and Germany", "May 1980", "erosion", "English", "1960", "Ronald Reagan, who was 73 years, 274 days old at the time of his election to a second term", "Johnny Logan, who performed `` What's Another Year '' in 1980 and `` Hold Me Now '' in 1987", "revenge and karma", "Exodus 20 : 7", "England and Wales", "1996", "1000 BC", "Idaho", "early Christians of Mesopotamia", "eight hours ( UTC \u2212 08 : 00 )", "Dr. Rajendra Prasad", "Carlos Alan Autry Jr. ( also known for a period of time as Carlos Brown ; born July 31, 1952 ), is an American actor, politician, and former National Football League player", "Jay Baruchel", "Ann E. Todd", "merengue", "Butter Island off North Haven, Maine in the Penobscot Bay", "toward the end of the 18th century, and in most areas was at its peak in the approximate period from 1800 to 1850", "during the 1890s Klondike Gold Rush", "secure communication over a computer network", "3 lines of reflection and rotational symmetry of order 3 about its center", "1939", "the BBC", "Help!", "in soils", "Felicity Huffman", "John of Gaunt", "75", "m62", "Montana State University", "Sun Valley, Idaho", "president", "\"Itsy Bitsy Teeny Weeny Yellow Polka Dot Bikini.\"", "doctors", "The crash destroyed four homes and killed two people who lived in at least one of the homes,", "the Amazon", "Upromise", "The Crow", "Britain"], "metric_results": {"EM": 0.5625, "QA-F1": 0.684108215671141}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, true, false, false, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.4, 0.1111111111111111, 0.3333333333333333, 1.0, 1.0, 0.13333333333333333, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.2, 1.0, 0.0, 1.0, 0.23529411764705882, 0.5, 1.0, 0.11764705882352941, 1.0, 0.21052631578947367, 0.2105263157894737, 1.0, 1.0, 0.5, 1.0, 0.4, 1.0, 1.0, 0.6, 1.0, 0.25806451612903225, 1.0, 1.0, 1.0, 1.0, 0.9302325581395349, 1.0, 0.3333333333333333, 0.14285714285714288, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7948", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-6918", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-6859", "mrqa_naturalquestions-validation-2540", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-8744", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1414", "mrqa_naturalquestions-validation-6480", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-2119", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-6435", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-484", "mrqa_naturalquestions-validation-49", "mrqa_naturalquestions-validation-8474", "mrqa_newsqa-validation-3504", "mrqa_searchqa-validation-3477", "mrqa_newsqa-validation-646"], "SR": 0.5625, "CSR": 0.5620719178082192, "retrieved_ids": ["mrqa_squad-train-72879", "mrqa_squad-train-85173", "mrqa_squad-train-23602", "mrqa_squad-train-58969", "mrqa_squad-train-37249", "mrqa_squad-train-17550", "mrqa_squad-train-29250", "mrqa_squad-train-27881", "mrqa_squad-train-66688", "mrqa_squad-train-1106", "mrqa_squad-train-6622", "mrqa_squad-train-84563", "mrqa_squad-train-26866", "mrqa_squad-train-55368", "mrqa_squad-train-50194", "mrqa_squad-train-17109", "mrqa_squad-train-25166", "mrqa_squad-train-41676", "mrqa_squad-train-10283", "mrqa_squad-train-23027", "mrqa_squad-train-49646", "mrqa_squad-train-83505", "mrqa_squad-train-54425", "mrqa_squad-train-14750", "mrqa_squad-train-76642", "mrqa_squad-train-80167", "mrqa_squad-train-61545", "mrqa_squad-train-54744", "mrqa_squad-train-49809", "mrqa_squad-train-61144", "mrqa_squad-train-7526", "mrqa_squad-train-75536", "mrqa_triviaqa-validation-4622", "mrqa_newsqa-validation-3557", "mrqa_triviaqa-validation-4182", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-16953", "mrqa_squad-validation-9578", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-1350", "mrqa_searchqa-validation-8139", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-2090", "mrqa_hotpotqa-validation-3538", "mrqa_searchqa-validation-4185", "mrqa_triviaqa-validation-6210", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-1088", "mrqa_searchqa-validation-3835", "mrqa_searchqa-validation-6726", "mrqa_triviaqa-validation-2321", "mrqa_newsqa-validation-1899", "mrqa_naturalquestions-validation-4236", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-3700", "mrqa_hotpotqa-validation-4528", "mrqa_triviaqa-validation-7430", "mrqa_searchqa-validation-9472", "mrqa_naturalquestions-validation-405", "mrqa_hotpotqa-validation-4441", "mrqa_newsqa-validation-276", "mrqa_hotpotqa-validation-718", "mrqa_triviaqa-validation-4710"], "EFR": 0.8928571428571429, "Overall": 0.7309076871330724}, {"timecode": 73, "before_eval_results": {"predictions": ["Venezuela", "The Fall Guy", "crown", "Maria Montessori", "Fugitive", "Alexander Hamilton", "Rendezvous with Rama", "\"The Long Way Home\"", "Patrick Ewing", "Fletcher Christian", "an ambulance", "Condoleezza Rice", "Pakistan", "China", "liquor", "Texas", "the Baltimore Symphony Orchestra", "John James Audubon", "Pontius Pilate", "Goldwater", "neurotransmitters", "the halfpipe", "Jackie Collins", "carioca", "Freakonomics", "George Washington Carver", "Devon", "Champagne", "Red Heat", "New Orleans", "the Dominican Republic", "a carrel", "a flop", "Prince William", "Sherlock Holmes", "ancistroid", "Orion", "Bangladesh", "carbon monoxide", "John", "a plug in", "a monster", "the phallus", "manslaughter", "programming", "the Tennessee River", "Ptolemy", "Billy Idol", "the Missouri Compromise", "Rat", "Tom Hanks", "to encounter antigens passing through the mucosal epithelium", "$1.528 billion", "on the left hand ring finger", "Conrad Murray", "Gryffendor", "Czech Republic", "Sochi, Russia", "two years", "Manchester\u2013Boston Regional Airport", "President Obama", "The noose incident occurred two weeks after Black History Month was mocked in an off-campus party that was condemned by the school.", "American Civil Liberties Union", "monthly"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6909722222222222}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, true, false, false, true, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13288", "mrqa_searchqa-validation-3219", "mrqa_searchqa-validation-9645", "mrqa_searchqa-validation-377", "mrqa_searchqa-validation-13116", "mrqa_searchqa-validation-5326", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-10889", "mrqa_searchqa-validation-8097", "mrqa_searchqa-validation-7195", "mrqa_searchqa-validation-6326", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-11318", "mrqa_searchqa-validation-284", "mrqa_searchqa-validation-5858", "mrqa_searchqa-validation-702", "mrqa_searchqa-validation-2145", "mrqa_searchqa-validation-3189", "mrqa_searchqa-validation-14970", "mrqa_searchqa-validation-15757", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-10093", "mrqa_triviaqa-validation-5472", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-131", "mrqa_hotpotqa-validation-1233"], "SR": 0.59375, "CSR": 0.5625, "retrieved_ids": ["mrqa_squad-train-75351", "mrqa_squad-train-18016", "mrqa_squad-train-26499", "mrqa_squad-train-62173", "mrqa_squad-train-61576", "mrqa_squad-train-56707", "mrqa_squad-train-20362", "mrqa_squad-train-83946", "mrqa_squad-train-2406", "mrqa_squad-train-19000", "mrqa_squad-train-22267", "mrqa_squad-train-13685", "mrqa_squad-train-60100", "mrqa_squad-train-82265", "mrqa_squad-train-41523", "mrqa_squad-train-41108", "mrqa_squad-train-32370", "mrqa_squad-train-79202", "mrqa_squad-train-38139", "mrqa_squad-train-2610", "mrqa_squad-train-25559", "mrqa_squad-train-15288", "mrqa_squad-train-53436", "mrqa_squad-train-47552", "mrqa_squad-train-62580", "mrqa_squad-train-55771", "mrqa_squad-train-45571", "mrqa_squad-train-25647", "mrqa_squad-train-20151", "mrqa_squad-train-60216", "mrqa_squad-train-62297", "mrqa_squad-train-18630", "mrqa_squad-validation-6913", "mrqa_searchqa-validation-8669", "mrqa_triviaqa-validation-532", "mrqa_newsqa-validation-895", "mrqa_searchqa-validation-230", "mrqa_triviaqa-validation-6554", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-5787", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9162", "mrqa_naturalquestions-validation-5017", "mrqa_triviaqa-validation-331", "mrqa_triviaqa-validation-7387", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-1674", "mrqa_hotpotqa-validation-996", "mrqa_squad-validation-233", "mrqa_hotpotqa-validation-5725", "mrqa_triviaqa-validation-2806", "mrqa_hotpotqa-validation-4989", "mrqa_newsqa-validation-2086", "mrqa_newsqa-validation-3199", "mrqa_squad-validation-8576", "mrqa_squad-validation-6044", "mrqa_hotpotqa-validation-4628", "mrqa_searchqa-validation-9135", "mrqa_searchqa-validation-14471", "mrqa_naturalquestions-validation-6452", "mrqa_searchqa-validation-9123", "mrqa_naturalquestions-validation-1430", "mrqa_triviaqa-validation-7085", "mrqa_searchqa-validation-11807"], "EFR": 0.8461538461538461, "Overall": 0.7216526442307692}, {"timecode": 74, "before_eval_results": {"predictions": ["saccharides", "dennis tiller", "Anna", "liver", "private eye", "Gibraltar", "jack ruby", "1500 meter event", "british Airways", "business", "b4425", "Pete Best", "Bonnie and Clyde", "Pandora", "Concepcion", "St Moritz", "Edmund Cartwright", "Par-4", "Prometheus", "Japanese silvergrass", "April", "arthur conan doyle", "Wolfgang Amadeus Mozart", "honeybee", "sun hill", "Nutcracker", "51 kg", "adare", "muppets", "photography", "kirsty Young", "Samuel Johnson", "sports & Leisure", "bear", "ganges", "tabloid", "car door", "kolkata", "odeon", "Bangladesh", "Shangri-La", "The Tempest", "Diana Ross", "Mansion House", "Ishmael", "repechage", "Crusades", "Kiri Te Kanawa", "Churchill Downs", "up stairs down stairs", "One Direction", "ulnar nerve", "Gibraltar", "111", "Merck Sharp & Dohme", "shortstop", "Vietnam War", "\"I wasn't sure whether I was going to return to 'E! News' this week or after the new year.", "Amnesty International.", "after Wood went missing off Catalina Island, near the California coast,", "\"I'll have\"", "Breckenridge", "The Fray", "President Clinton."], "metric_results": {"EM": 0.625, "QA-F1": 0.6406650641025641}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, false, true, false, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.10256410256410256, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2843", "mrqa_triviaqa-validation-3972", "mrqa_triviaqa-validation-3733", "mrqa_triviaqa-validation-861", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-3876", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-2871", "mrqa_triviaqa-validation-2356", "mrqa_triviaqa-validation-5243", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-5025", "mrqa_triviaqa-validation-7118", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-2993", "mrqa_triviaqa-validation-170", "mrqa_triviaqa-validation-7365", "mrqa_hotpotqa-validation-4763", "mrqa_hotpotqa-validation-3058", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-3966", "mrqa_searchqa-validation-12893", "mrqa_searchqa-validation-14621"], "SR": 0.625, "CSR": 0.5633333333333334, "retrieved_ids": ["mrqa_squad-train-14244", "mrqa_squad-train-57574", "mrqa_squad-train-53208", "mrqa_squad-train-58860", "mrqa_squad-train-34772", "mrqa_squad-train-740", "mrqa_squad-train-15035", "mrqa_squad-train-33707", "mrqa_squad-train-84387", "mrqa_squad-train-8805", "mrqa_squad-train-50356", "mrqa_squad-train-66645", "mrqa_squad-train-68314", "mrqa_squad-train-58036", "mrqa_squad-train-30542", "mrqa_squad-train-64111", "mrqa_squad-train-44508", "mrqa_squad-train-68545", "mrqa_squad-train-61805", "mrqa_squad-train-73700", "mrqa_squad-train-60378", "mrqa_squad-train-28809", "mrqa_squad-train-53092", "mrqa_squad-train-74465", "mrqa_squad-train-4781", "mrqa_squad-train-20457", "mrqa_squad-train-13539", "mrqa_squad-train-13161", "mrqa_squad-train-21498", "mrqa_squad-train-5415", "mrqa_squad-train-58447", "mrqa_squad-train-69531", "mrqa_triviaqa-validation-1788", "mrqa_triviaqa-validation-7530", "mrqa_searchqa-validation-12442", "mrqa_hotpotqa-validation-346", "mrqa_hotpotqa-validation-1865", "mrqa_searchqa-validation-13288", "mrqa_naturalquestions-validation-1053", "mrqa_triviaqa-validation-5810", "mrqa_searchqa-validation-9123", "mrqa_hotpotqa-validation-3869", "mrqa_searchqa-validation-685", "mrqa_hotpotqa-validation-3806", "mrqa_newsqa-validation-2702", "mrqa_triviaqa-validation-3888", "mrqa_searchqa-validation-11651", "mrqa_naturalquestions-validation-5561", "mrqa_hotpotqa-validation-4112", "mrqa_triviaqa-validation-3004", "mrqa_hotpotqa-validation-4178", "mrqa_squad-validation-2717", "mrqa_triviaqa-validation-3147", "mrqa_squad-validation-3500", "mrqa_triviaqa-validation-146", "mrqa_hotpotqa-validation-3381", "mrqa_newsqa-validation-3990", "mrqa_hotpotqa-validation-5822", "mrqa_newsqa-validation-1837", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-720", "mrqa_newsqa-validation-2059", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-1066"], "EFR": 0.875, "Overall": 0.7275885416666668}, {"timecode": 75, "before_eval_results": {"predictions": ["Fitzroya cupressoides", "Martin O'Neill", "2012", "3730 km", "Kind Hearts and Coronets", "Bath, Maine", "Nippon Professional Baseball", "hiphop", "commercial success", "Eumolpus", "Brendan O'Brien", "John Churchill", "Sir William McMahon", "Hopi", "North Kesteven", "American", "Jean-Marie Pfaff", "Steve Prohm", "Brazil", "1954", "Newcastle upon Tyne, England", "four", "Sargent Shriver Jr.", "The Vaudevillains", "Chinese Coffee", "Love and Theft", "Hallett Cove", "4145 ft above mean sea level", "University of Georgia", "just over 1 million", "an advertisement figure", "The Last of the Mohicans", "Centennial Olympic Stadium", "media for the 65.8 million", "Paul Avery", "25 October 1921", "Arnold", "J. Cole", "Idisi", "The Books", "port of Mazatl\u00e1n", "Danish", "London, England", "Rochdale, North West England", "1959", "Telugu and Tamil", "Centers for Medicare and Medicaid Services", "Laura Jeanne Reese Witherspoon", "Koch Industries", "William Howard Ashton", "Mindy Kaling", "summer of 1990", "September 21, 2016", "a 12 '' x 12 '' attached giant - sized booklet with state - of - the - art photography of the band's performance and outdoor session pictures", "earache", "anniversary island", "cuckoo", "$2 billion", "San Simeon, California,", "said he was injected with drugs by ICE agents against his will.", "Patrick", "The Tomb of the Unknown Soldier", "Mount Vesuvius", "in a park in a residential area of Mexico City,"], "metric_results": {"EM": 0.65625, "QA-F1": 0.756168831168831}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.9090909090909091, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5394", "mrqa_hotpotqa-validation-758", "mrqa_hotpotqa-validation-5556", "mrqa_hotpotqa-validation-550", "mrqa_hotpotqa-validation-4455", "mrqa_hotpotqa-validation-3398", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-1307", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-2049", "mrqa_naturalquestions-validation-661", "mrqa_naturalquestions-validation-3556", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-140", "mrqa_searchqa-validation-13410"], "SR": 0.65625, "CSR": 0.5645559210526316, "retrieved_ids": ["mrqa_squad-train-55974", "mrqa_squad-train-43081", "mrqa_squad-train-36699", "mrqa_squad-train-17952", "mrqa_squad-train-36773", "mrqa_squad-train-42786", "mrqa_squad-train-61542", "mrqa_squad-train-22444", "mrqa_squad-train-85101", "mrqa_squad-train-4963", "mrqa_squad-train-81943", "mrqa_squad-train-45072", "mrqa_squad-train-59167", "mrqa_squad-train-17087", "mrqa_squad-train-57800", "mrqa_squad-train-30266", "mrqa_squad-train-70880", "mrqa_squad-train-30894", "mrqa_squad-train-78243", "mrqa_squad-train-63614", "mrqa_squad-train-50749", "mrqa_squad-train-12576", "mrqa_squad-train-5236", "mrqa_squad-train-54208", "mrqa_squad-train-65149", "mrqa_squad-train-16975", "mrqa_squad-train-18675", "mrqa_squad-train-32832", "mrqa_squad-train-71436", "mrqa_squad-train-53833", "mrqa_squad-train-64319", "mrqa_squad-train-65920", "mrqa_naturalquestions-validation-1941", "mrqa_triviaqa-validation-4630", "mrqa_searchqa-validation-6724", "mrqa_triviaqa-validation-663", "mrqa_newsqa-validation-1873", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-1818", "mrqa_squad-validation-1116", "mrqa_squad-validation-6361", "mrqa_naturalquestions-validation-10265", "mrqa_naturalquestions-validation-9741", "mrqa_newsqa-validation-2641", "mrqa_searchqa-validation-13046", "mrqa_hotpotqa-validation-3995", "mrqa_triviaqa-validation-3025", "mrqa_naturalquestions-validation-8962", "mrqa_triviaqa-validation-2411", "mrqa_newsqa-validation-1816", "mrqa_naturalquestions-validation-4803", "mrqa_hotpotqa-validation-4754", "mrqa_hotpotqa-validation-5666", "mrqa_searchqa-validation-11471", "mrqa_naturalquestions-validation-3942", "mrqa_newsqa-validation-771", "mrqa_triviaqa-validation-4046", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-2777", "mrqa_naturalquestions-validation-7407", "mrqa_searchqa-validation-8846", "mrqa_hotpotqa-validation-4899", "mrqa_searchqa-validation-4509", "mrqa_naturalquestions-validation-720"], "EFR": 0.7727272727272727, "Overall": 0.7073785137559809}, {"timecode": 76, "before_eval_results": {"predictions": ["pet sounds", "Glenfinnan in the Scottish Highlands", "\"A Metro\u2013Goldwyn\u2013Mayer Picture\u201d", "Liszt Strauss Wagner Dvorak", "James Callaghan", "cedar", "bank", "Dublin", "Pyrenees", "leprosy", "left", "harridan james", "avocado", "Anne Boleyn", "The Double", "lexis", "Supertramp", "hula hoops", "Augustus", "one night / I Got Stung", "heston Blumenthal", "united states", "fools and Horses", "Some Like It Hot", "Mr Loophole", "ken purdy", "Wolf Hall", "Ernests Gulbis", "alberta juantorena", "street art", "Friedrich Nietzsche", "Dee Caffari", "cheese", "new coaches", "Kristiania", "piano", "Moby Dick", "snakes", "sacred Wonders of Britain", "heartbeat", "pea", "Jo Moore", "Sea of Galilee", "one", "Helen of Troy", "memory-robbing disease", "crimson tide", "1982", "an even break", "31536000", "Jordan", "fishes, amphibians, reptiles, birds, and mammals", "a very long forward pass in American football, made in desperation, with only a small chance of success and time running out on the clock", "2018", "Miami Marlins", "Maxwell Smart", "Las Vegas Strip in Paradise, Nevada", "Argentine coach Diego Maradona has urged Carlos Tevez to quit Manchester United at the end of the season and head for Italy.", "Rev. Alberto Cutie", "Michelle Obama", "an alto trombone", "270", "place", "The American Red Cross"], "metric_results": {"EM": 0.5, "QA-F1": 0.5446381040131041}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.08108108108108107, 1.0, 0.0, 1.0, 0.9090909090909091, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-1696", "mrqa_triviaqa-validation-3300", "mrqa_triviaqa-validation-1355", "mrqa_triviaqa-validation-6685", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-166", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-611", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-4313", "mrqa_triviaqa-validation-6352", "mrqa_triviaqa-validation-6657", "mrqa_triviaqa-validation-3671", "mrqa_triviaqa-validation-1759", "mrqa_triviaqa-validation-4857", "mrqa_triviaqa-validation-5439", "mrqa_triviaqa-validation-5429", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-3590", "mrqa_triviaqa-validation-3468", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-1026", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-5819", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-71", "mrqa_newsqa-validation-1261", "mrqa_searchqa-validation-4422", "mrqa_searchqa-validation-3092", "mrqa_searchqa-validation-14139"], "SR": 0.5, "CSR": 0.5637175324675325, "retrieved_ids": ["mrqa_squad-train-10534", "mrqa_squad-train-60026", "mrqa_squad-train-84760", "mrqa_squad-train-759", "mrqa_squad-train-75233", "mrqa_squad-train-56418", "mrqa_squad-train-68200", "mrqa_squad-train-54483", "mrqa_squad-train-51616", "mrqa_squad-train-58129", "mrqa_squad-train-36493", "mrqa_squad-train-46407", "mrqa_squad-train-13368", "mrqa_squad-train-81735", "mrqa_squad-train-7487", "mrqa_squad-train-58213", "mrqa_squad-train-22548", "mrqa_squad-train-58657", "mrqa_squad-train-59430", "mrqa_squad-train-33955", "mrqa_squad-train-21160", "mrqa_squad-train-17566", "mrqa_squad-train-15082", "mrqa_squad-train-77983", "mrqa_squad-train-64201", "mrqa_squad-train-12882", "mrqa_squad-train-68688", "mrqa_squad-train-46989", "mrqa_squad-train-5858", "mrqa_squad-train-32620", "mrqa_squad-train-9875", "mrqa_squad-train-25393", "mrqa_naturalquestions-validation-6474", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-2425", "mrqa_newsqa-validation-2200", "mrqa_triviaqa-validation-5644", "mrqa_naturalquestions-validation-7935", "mrqa_searchqa-validation-378", "mrqa_hotpotqa-validation-4102", "mrqa_triviaqa-validation-6002", "mrqa_newsqa-validation-4151", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5889", "mrqa_newsqa-validation-670", "mrqa_hotpotqa-validation-2378", "mrqa_searchqa-validation-12371", "mrqa_newsqa-validation-2607", "mrqa_searchqa-validation-5613", "mrqa_naturalquestions-validation-8483", "mrqa_newsqa-validation-2198", "mrqa_newsqa-validation-2521", "mrqa_searchqa-validation-4305", "mrqa_triviaqa-validation-3131", "mrqa_naturalquestions-validation-5561", "mrqa_newsqa-validation-3434", "mrqa_triviaqa-validation-6554", "mrqa_hotpotqa-validation-3223", "mrqa_triviaqa-validation-1067", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-2181", "mrqa_squad-validation-4901", "mrqa_searchqa-validation-15581"], "EFR": 0.46875, "Overall": 0.6464153814935065}, {"timecode": 77, "before_eval_results": {"predictions": ["Gary Player,", "remains committed to British sovereignty", "The Kirchners", "the iPods were largely overshadowed by Tuesday's iPhone 4S news,", "45 minutes, five days a week.", "a \" unique set of circumstances.\"", "Kris Allen,", "Jason Chaffetz", "ore Gold,", "U.S. and Britain.", "Harry Nicolaides,", "Most of those who managed to survive the incident hid in a boiler room and storage closets", "April 2010.", "\"Zed,\" a Columbian mammoth whose nearly intact skeleton is part of what is being described as a key find by paleontologists at Los Angeles' George C. Page Museum.", "\"[The e-mails]", "eco videos", "his father", "Iran", "head injury.", "Antichrist", "African National Congress Deputy President Kgalema Motlanthe", "Hugo Chavez", "seven", "Anne Frank's diary.", "\"The Lost Symbol\"", "Matthew Fisher,", "Rawalpindi", "Colorado prosecutor", "Afghanistan,", "Climatecare,", "dental work", "Ireland.", "United States, NATO member states, Russia", "organized crime rings with ties to Europe, Asia, Africa and the Middle East.", "Hamas,", "Two pages -- usually high school juniors who serve Congress as messengers", "At least 40", "20,000", "Courtney Love,", "84-year-old", "The official said deciding the duties of the new prime minister has been a sticking point in the negotiations.", "three", "undergoing renovation.", "Naples home.", "Hanford nuclear site,", "November 26,", "sportswear", "Beijing", "hopes the journalists and the flight crew will be freed,", "improve health and beauty.", "help nations trapped by hunger and extreme poverty, donating billions of dollars on health aid during the past two decades.", "three preteen boys named Ed, Edd ( called `` Double D '' to avoid confusion with Ed ), and Eddy -- collectively known as `` the Eds ''", "meditation and acceptance practices", "Sumitra", "India and Pakistan", "allergic reaction", "a lie detector", "influenced by the music genres of electronic rock, electropop and R&B", "1963", "Black Abbots", "nurse", "Argentina", "Charles Baudelaire", "Sleepy Hollow"], "metric_results": {"EM": 0.546875, "QA-F1": 0.67900641938008}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.21052631578947364, 1.0, 0.19999999999999998, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.20689655172413793, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.18181818181818182, 0.0, 0.0, 0.5, 0.125, 1.0, 0.3076923076923077, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8823529411764706, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-2249", "mrqa_newsqa-validation-1968", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-1270", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-3321", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-1190", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-2493", "mrqa_newsqa-validation-923", "mrqa_newsqa-validation-3403", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-7058", "mrqa_hotpotqa-validation-4133", "mrqa_searchqa-validation-5877"], "SR": 0.546875, "CSR": 0.5635016025641026, "retrieved_ids": ["mrqa_squad-train-75283", "mrqa_squad-train-60818", "mrqa_squad-train-10160", "mrqa_squad-train-39956", "mrqa_squad-train-18668", "mrqa_squad-train-82305", "mrqa_squad-train-59822", "mrqa_squad-train-21207", "mrqa_squad-train-40054", "mrqa_squad-train-56788", "mrqa_squad-train-40427", "mrqa_squad-train-76682", "mrqa_squad-train-9399", "mrqa_squad-train-14495", "mrqa_squad-train-1040", "mrqa_squad-train-31900", "mrqa_squad-train-77561", "mrqa_squad-train-64736", "mrqa_squad-train-2598", "mrqa_squad-train-73573", "mrqa_squad-train-54539", "mrqa_squad-train-48497", "mrqa_squad-train-10246", "mrqa_squad-train-49893", "mrqa_squad-train-50588", "mrqa_squad-train-19066", "mrqa_squad-train-73456", "mrqa_squad-train-83501", "mrqa_squad-train-81961", "mrqa_squad-train-3355", "mrqa_squad-train-4924", "mrqa_squad-train-58485", "mrqa_hotpotqa-validation-1991", "mrqa_searchqa-validation-6730", "mrqa_triviaqa-validation-3972", "mrqa_searchqa-validation-14888", "mrqa_newsqa-validation-1510", "mrqa_searchqa-validation-2115", "mrqa_newsqa-validation-645", "mrqa_triviaqa-validation-6853", "mrqa_squad-validation-680", "mrqa_hotpotqa-validation-3420", "mrqa_newsqa-validation-3101", "mrqa_naturalquestions-validation-2582", "mrqa_searchqa-validation-11392", "mrqa_hotpotqa-validation-2228", "mrqa_squad-validation-9895", "mrqa_triviaqa-validation-2154", "mrqa_newsqa-validation-3048", "mrqa_naturalquestions-validation-4951", "mrqa_hotpotqa-validation-2214", "mrqa_newsqa-validation-2324", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-9896", "mrqa_searchqa-validation-10011", "mrqa_hotpotqa-validation-1321", "mrqa_searchqa-validation-8106", "mrqa_searchqa-validation-2673", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-7170", "mrqa_searchqa-validation-8208", "mrqa_triviaqa-validation-6554", "mrqa_triviaqa-validation-7530", "mrqa_squad-validation-7674"], "EFR": 0.5862068965517241, "Overall": 0.6698635748231654}, {"timecode": 78, "before_eval_results": {"predictions": ["the pupil", "the Silk Road", "norway", "George Rogers Clark", "amu", "ancus", "Sweden", "Volleyball", "John Alden", "Ghost World", "a Jellicle cat", "a cardinal directions", "Japan", "Madison Avenue", "Job", "hertz", "Art Deco", "Spider-Man", "Siddhartha Gautama", "Elie Wiesel", "Anna Friel", "Johnny Tremain", "a lieutenant", "The National Archives Building", "Nostradamus", "Madrid", "3:10 to Yuma", "Antarctica", "Ian Fleming", "Southern Christian Leadership Conference", "Moscow", "a Ford 917s", "(Cecilia) Beaux", "The Mormon Tabernacle Choir", "The Scarlet Letter", "(D. W. Griffith)", "Bangkok", "St. Louis", "positron", "Ted Kennedy", "Jefferson", "Jerusalem", "Pushing Daisies", "Cranberry", "Tzatziki sauce", "Ku Chiu", "United Healthcare Workers East", "sharlotka", "canals", "Abraham", "a kangaroo court", "between 11000 and 9000 BC", "Rachel Kelly Tucker", "works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "london", "kermadec Islands", "julius Caesar", "strongly associated with Gaia and Cybele", "The Danny Kaye Show", "2012", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \" Follow the Sun,\"  - the central attraction of golf remains at all the film's core.", "The switch had been scheduled for February 17, but Congress delayed the conversion", "Victor Mejia Munera.", "The oceans"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5927083333333334}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, true, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666665, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666669, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15154", "mrqa_searchqa-validation-11290", "mrqa_searchqa-validation-1478", "mrqa_searchqa-validation-9709", "mrqa_searchqa-validation-2424", "mrqa_searchqa-validation-14285", "mrqa_searchqa-validation-3286", "mrqa_searchqa-validation-14872", "mrqa_searchqa-validation-3381", "mrqa_searchqa-validation-3139", "mrqa_searchqa-validation-14996", "mrqa_searchqa-validation-9928", "mrqa_searchqa-validation-2662", "mrqa_searchqa-validation-3303", "mrqa_searchqa-validation-2552", "mrqa_searchqa-validation-3782", "mrqa_searchqa-validation-1423", "mrqa_searchqa-validation-6256", "mrqa_searchqa-validation-4445", "mrqa_searchqa-validation-9348", "mrqa_searchqa-validation-10164", "mrqa_searchqa-validation-11473", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-5752", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-5241", "mrqa_triviaqa-validation-3594", "mrqa_hotpotqa-validation-516", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-1424", "mrqa_newsqa-validation-875"], "SR": 0.515625, "CSR": 0.5628955696202531, "retrieved_ids": ["mrqa_squad-train-12255", "mrqa_squad-train-8209", "mrqa_squad-train-67304", "mrqa_squad-train-84803", "mrqa_squad-train-81918", "mrqa_squad-train-70390", "mrqa_squad-train-25378", "mrqa_squad-train-75875", "mrqa_squad-train-8724", "mrqa_squad-train-32260", "mrqa_squad-train-52043", "mrqa_squad-train-59374", "mrqa_squad-train-68063", "mrqa_squad-train-70596", "mrqa_squad-train-85834", "mrqa_squad-train-16410", "mrqa_squad-train-55189", "mrqa_squad-train-38822", "mrqa_squad-train-63359", "mrqa_squad-train-16562", "mrqa_squad-train-19521", "mrqa_squad-train-53975", "mrqa_squad-train-39580", "mrqa_squad-train-916", "mrqa_squad-train-50727", "mrqa_squad-train-65218", "mrqa_squad-train-531", "mrqa_squad-train-85621", "mrqa_squad-train-1033", "mrqa_squad-train-21976", "mrqa_squad-train-19711", "mrqa_squad-train-3859", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-512", "mrqa_triviaqa-validation-414", "mrqa_naturalquestions-validation-2024", "mrqa_newsqa-validation-131", "mrqa_hotpotqa-validation-1770", "mrqa_triviaqa-validation-2356", "mrqa_newsqa-validation-3992", "mrqa_naturalquestions-validation-4714", "mrqa_hotpotqa-validation-5265", "mrqa_searchqa-validation-57", "mrqa_searchqa-validation-13012", "mrqa_triviaqa-validation-1031", "mrqa_hotpotqa-validation-1844", "mrqa_searchqa-validation-5436", "mrqa_searchqa-validation-9769", "mrqa_naturalquestions-validation-2606", "mrqa_newsqa-validation-1899", "mrqa_hotpotqa-validation-2802", "mrqa_hotpotqa-validation-800", "mrqa_newsqa-validation-2198", "mrqa_triviaqa-validation-1904", "mrqa_hotpotqa-validation-674", "mrqa_hotpotqa-validation-4818", "mrqa_hotpotqa-validation-412", "mrqa_searchqa-validation-16716", "mrqa_triviaqa-validation-7592", "mrqa_hotpotqa-validation-1756", "mrqa_searchqa-validation-9135", "mrqa_triviaqa-validation-7047", "mrqa_naturalquestions-validation-4433", "mrqa_squad-validation-3374"], "EFR": 0.7419354838709677, "Overall": 0.7008880856982442}, {"timecode": 79, "before_eval_results": {"predictions": ["12.65 m ( 41.5 ft )", "De Wayne Warren", "a solitary figure who is not understood by others, but is actually wise", "Doug Pruzan", "a simple majority vote", "byte - level", "Rich Mullins", "September 19, 2017", "marriage officiant", "17th Century sources referring to Cardinal Richelieu after he was named to head the royal council in 1624", "Hermann Ebbinghaus", "Agostino Bassi", "An error does not count as a hit but still counts as an at bat for the batter", "low coercivity", "Marty J. Walsh", "British Columbia, Canada", "$66.5 million", "Middle Eastern alchemy", "the `` 0 '' trunk code", "up to 40.5 metres ( 133 ft ) in Miyako in T\u014dhoku's Iwate Prefecture, and which, in the Sendai area, traveled up to 10 km ( 6 mi ) inland", "Houston Dynamo", "Dan Stevens", "Bill Russell", "Conrad Lewis", "Ernest Rutherford", "Fa Ze YouTubers", "10 June 1940", "citizens", "performers must receive the highest number of votes, and also greater than 50 % of the votes", "Amanda Fuller", "`` The Forever People ''", "1997", "mitochondrial membrane", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "Michael Phelps", "William DeVaughn", "Virginia Dare", "1960s", "Aidan Gallagher", "2002", "Evermoist", "Pangaea or Pangea", "Instagram's own account", "their son Jack ( short for Jack - o - Lantern ) is born on Halloween 2023", "dress shop", "6,259 km ( 3,889 mi )", "February 27, 2007", "1963", "March 2, 2016", "the Mishnah ( Hebrew : \u05de\u05e9\u05e0\u05d4, c. 200 CE ), a written compendium of Rabbinic Judaism's Oral Torah", "the internal reproductive anatomy ( such as the uterus in females )", "Brundisium", "France", "krubera", "England", "April 1, 1949", "CBS", "\"green-card warriors\"", "Mumbai", "Brian David Mitchell,", "the Netherlands", "Florence", "Tiger Woods", "Cut your insurance in half"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6663392070776301}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [0.6666666666666666, 0.4, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.5, 0.1111111111111111, 1.0, 1.0, 0.2978723404255319, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3529411764705882, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 0.962962962962963, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.14285714285714288, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9508", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-4319", "mrqa_naturalquestions-validation-1285", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-3186", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-5001", "mrqa_naturalquestions-validation-2620", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3385", "mrqa_naturalquestions-validation-3297", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-7733", "mrqa_naturalquestions-validation-10182", "mrqa_naturalquestions-validation-5499", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-4751", "mrqa_naturalquestions-validation-335", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-4073", "mrqa_naturalquestions-validation-9005", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-4862", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-454"], "SR": 0.5625, "CSR": 0.562890625, "retrieved_ids": ["mrqa_squad-train-65557", "mrqa_squad-train-5092", "mrqa_squad-train-2084", "mrqa_squad-train-355", "mrqa_squad-train-42087", "mrqa_squad-train-61101", "mrqa_squad-train-79768", "mrqa_squad-train-31622", "mrqa_squad-train-56774", "mrqa_squad-train-54352", "mrqa_squad-train-31088", "mrqa_squad-train-8204", "mrqa_squad-train-17861", "mrqa_squad-train-34269", "mrqa_squad-train-7165", "mrqa_squad-train-38965", "mrqa_squad-train-525", "mrqa_squad-train-35346", "mrqa_squad-train-70635", "mrqa_squad-train-19668", "mrqa_squad-train-29584", "mrqa_squad-train-75285", "mrqa_squad-train-13124", "mrqa_squad-train-37336", "mrqa_squad-train-22077", "mrqa_squad-train-60885", "mrqa_squad-train-4133", "mrqa_squad-train-16869", "mrqa_squad-train-29738", "mrqa_squad-train-36755", "mrqa_squad-train-73272", "mrqa_squad-train-13246", "mrqa_hotpotqa-validation-534", "mrqa_hotpotqa-validation-1510", "mrqa_triviaqa-validation-170", "mrqa_searchqa-validation-475", "mrqa_squad-validation-10351", "mrqa_triviaqa-validation-5439", "mrqa_newsqa-validation-2635", "mrqa_triviaqa-validation-2324", "mrqa_triviaqa-validation-7209", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-8513", "mrqa_newsqa-validation-4010", "mrqa_triviaqa-validation-2141", "mrqa_newsqa-validation-406", "mrqa_searchqa-validation-12576", "mrqa_newsqa-validation-3302", "mrqa_triviaqa-validation-2179", "mrqa_searchqa-validation-10060", "mrqa_triviaqa-validation-6339", "mrqa_triviaqa-validation-5993", "mrqa_naturalquestions-validation-10114", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-714", "mrqa_triviaqa-validation-2168", "mrqa_naturalquestions-validation-5509", "mrqa_searchqa-validation-14691", "mrqa_searchqa-validation-9246", "mrqa_naturalquestions-validation-6901", "mrqa_hotpotqa-validation-5523", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-8846", "mrqa_hotpotqa-validation-1818"], "EFR": 0.5, "Overall": 0.6525000000000001}, {"timecode": 80, "UKR": 0.802734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1052", "mrqa_hotpotqa-validation-1088", "mrqa_hotpotqa-validation-1247", "mrqa_hotpotqa-validation-1292", "mrqa_hotpotqa-validation-13", "mrqa_hotpotqa-validation-1301", "mrqa_hotpotqa-validation-1473", "mrqa_hotpotqa-validation-1490", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-1691", "mrqa_hotpotqa-validation-1736", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-1856", "mrqa_hotpotqa-validation-189", "mrqa_hotpotqa-validation-1986", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-2111", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-2378", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2590", "mrqa_hotpotqa-validation-2604", "mrqa_hotpotqa-validation-2650", "mrqa_hotpotqa-validation-2873", "mrqa_hotpotqa-validation-2892", "mrqa_hotpotqa-validation-2903", "mrqa_hotpotqa-validation-2908", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-2952", "mrqa_hotpotqa-validation-2971", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-2984", "mrqa_hotpotqa-validation-307", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3175", "mrqa_hotpotqa-validation-3245", "mrqa_hotpotqa-validation-3313", "mrqa_hotpotqa-validation-3323", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3374", "mrqa_hotpotqa-validation-3428", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-3793", "mrqa_hotpotqa-validation-3934", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-4038", "mrqa_hotpotqa-validation-4076", "mrqa_hotpotqa-validation-4084", "mrqa_hotpotqa-validation-4123", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-4247", "mrqa_hotpotqa-validation-4249", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-4500", "mrqa_hotpotqa-validation-4510", "mrqa_hotpotqa-validation-4632", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-4708", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4818", "mrqa_hotpotqa-validation-4841", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-494", "mrqa_hotpotqa-validation-5172", "mrqa_hotpotqa-validation-5358", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-542", "mrqa_hotpotqa-validation-5427", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-5666", "mrqa_hotpotqa-validation-5719", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-5864", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-66", "mrqa_hotpotqa-validation-76", "mrqa_hotpotqa-validation-884", "mrqa_hotpotqa-validation-916", "mrqa_hotpotqa-validation-975", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-10159", "mrqa_naturalquestions-validation-10182", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-10355", "mrqa_naturalquestions-validation-10417", "mrqa_naturalquestions-validation-10493", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1797", "mrqa_naturalquestions-validation-1824", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-1920", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-214", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2379", "mrqa_naturalquestions-validation-2515", "mrqa_naturalquestions-validation-2620", "mrqa_naturalquestions-validation-2837", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-289", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3186", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-3425", "mrqa_naturalquestions-validation-3560", "mrqa_naturalquestions-validation-3569", "mrqa_naturalquestions-validation-3692", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-3930", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-4073", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4307", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-4736", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5072", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-5331", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-5425", "mrqa_naturalquestions-validation-5503", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6069", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-6901", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7410", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-757", "mrqa_naturalquestions-validation-7595", "mrqa_naturalquestions-validation-7629", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-7806", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7856", "mrqa_naturalquestions-validation-7892", "mrqa_naturalquestions-validation-7957", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-9608", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-9814", "mrqa_naturalquestions-validation-9871", "mrqa_naturalquestions-validation-9878", "mrqa_newsqa-validation-1013", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-1129", "mrqa_newsqa-validation-1183", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-1365", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-1547", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-175", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-183", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2002", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-2494", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-2856", "mrqa_newsqa-validation-2861", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2899", "mrqa_newsqa-validation-2992", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-3179", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-3520", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3639", "mrqa_newsqa-validation-3715", "mrqa_newsqa-validation-378", "mrqa_newsqa-validation-3780", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3865", "mrqa_newsqa-validation-3897", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3992", "mrqa_newsqa-validation-406", "mrqa_newsqa-validation-4060", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-454", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-61", "mrqa_newsqa-validation-632", "mrqa_newsqa-validation-698", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-946", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-10330", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-10616", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-10776", "mrqa_searchqa-validation-10999", "mrqa_searchqa-validation-11216", "mrqa_searchqa-validation-11247", "mrqa_searchqa-validation-11294", "mrqa_searchqa-validation-11425", "mrqa_searchqa-validation-1173", "mrqa_searchqa-validation-11898", "mrqa_searchqa-validation-1196", "mrqa_searchqa-validation-12085", "mrqa_searchqa-validation-12127", "mrqa_searchqa-validation-12151", "mrqa_searchqa-validation-1218", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-12360", "mrqa_searchqa-validation-12782", "mrqa_searchqa-validation-13014", "mrqa_searchqa-validation-13116", "mrqa_searchqa-validation-13765", "mrqa_searchqa-validation-13803", "mrqa_searchqa-validation-14285", "mrqa_searchqa-validation-14307", "mrqa_searchqa-validation-14471", "mrqa_searchqa-validation-14542", "mrqa_searchqa-validation-1497", "mrqa_searchqa-validation-15064", "mrqa_searchqa-validation-15365", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-15709", "mrqa_searchqa-validation-15716", "mrqa_searchqa-validation-15725", "mrqa_searchqa-validation-16016", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-16162", "mrqa_searchqa-validation-16346", "mrqa_searchqa-validation-16865", "mrqa_searchqa-validation-16910", "mrqa_searchqa-validation-191", "mrqa_searchqa-validation-1950", "mrqa_searchqa-validation-1966", "mrqa_searchqa-validation-2189", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-2481", "mrqa_searchqa-validation-2591", "mrqa_searchqa-validation-2673", "mrqa_searchqa-validation-2898", "mrqa_searchqa-validation-2943", "mrqa_searchqa-validation-3081", "mrqa_searchqa-validation-3092", "mrqa_searchqa-validation-324", "mrqa_searchqa-validation-327", "mrqa_searchqa-validation-3303", "mrqa_searchqa-validation-3381", "mrqa_searchqa-validation-3455", "mrqa_searchqa-validation-3838", "mrqa_searchqa-validation-4305", "mrqa_searchqa-validation-4320", "mrqa_searchqa-validation-4380", "mrqa_searchqa-validation-4509", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-4878", "mrqa_searchqa-validation-5060", "mrqa_searchqa-validation-5477", "mrqa_searchqa-validation-5971", "mrqa_searchqa-validation-6256", "mrqa_searchqa-validation-6697", "mrqa_searchqa-validation-6782", "mrqa_searchqa-validation-6814", "mrqa_searchqa-validation-6829", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-714", "mrqa_searchqa-validation-7162", "mrqa_searchqa-validation-7186", "mrqa_searchqa-validation-731", "mrqa_searchqa-validation-7322", "mrqa_searchqa-validation-7521", "mrqa_searchqa-validation-7741", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7880", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-7932", "mrqa_searchqa-validation-8166", "mrqa_searchqa-validation-8331", "mrqa_searchqa-validation-8481", "mrqa_searchqa-validation-8648", "mrqa_searchqa-validation-8691", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-8986", "mrqa_searchqa-validation-9284", "mrqa_searchqa-validation-9348", "mrqa_searchqa-validation-9438", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-10067", "mrqa_squad-validation-1023", "mrqa_squad-validation-10466", "mrqa_squad-validation-10483", "mrqa_squad-validation-1071", "mrqa_squad-validation-1116", "mrqa_squad-validation-1215", "mrqa_squad-validation-1251", "mrqa_squad-validation-1312", "mrqa_squad-validation-1856", "mrqa_squad-validation-2098", "mrqa_squad-validation-2434", "mrqa_squad-validation-2443", "mrqa_squad-validation-2458", "mrqa_squad-validation-2888", "mrqa_squad-validation-3202", "mrqa_squad-validation-343", "mrqa_squad-validation-3551", "mrqa_squad-validation-356", "mrqa_squad-validation-3633", "mrqa_squad-validation-3823", "mrqa_squad-validation-3953", "mrqa_squad-validation-4110", "mrqa_squad-validation-4430", "mrqa_squad-validation-4595", "mrqa_squad-validation-4870", "mrqa_squad-validation-5112", "mrqa_squad-validation-512", "mrqa_squad-validation-5590", "mrqa_squad-validation-5874", "mrqa_squad-validation-60", "mrqa_squad-validation-6255", "mrqa_squad-validation-6316", "mrqa_squad-validation-6324", "mrqa_squad-validation-6373", "mrqa_squad-validation-6393", "mrqa_squad-validation-6539", "mrqa_squad-validation-6657", "mrqa_squad-validation-6690", "mrqa_squad-validation-687", "mrqa_squad-validation-7068", "mrqa_squad-validation-7082", "mrqa_squad-validation-7144", "mrqa_squad-validation-7162", "mrqa_squad-validation-7209", "mrqa_squad-validation-7744", "mrqa_squad-validation-7937", "mrqa_squad-validation-805", "mrqa_squad-validation-8747", "mrqa_squad-validation-8761", "mrqa_squad-validation-8807", "mrqa_squad-validation-8881", "mrqa_squad-validation-9154", "mrqa_squad-validation-9578", "mrqa_squad-validation-9761", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-1076", "mrqa_triviaqa-validation-1123", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1183", "mrqa_triviaqa-validation-1335", "mrqa_triviaqa-validation-1355", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1657", "mrqa_triviaqa-validation-170", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-1965", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-2458", "mrqa_triviaqa-validation-2518", "mrqa_triviaqa-validation-2523", "mrqa_triviaqa-validation-2653", "mrqa_triviaqa-validation-2653", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-3025", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3064", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-3104", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3201", "mrqa_triviaqa-validation-3263", "mrqa_triviaqa-validation-3288", "mrqa_triviaqa-validation-3300", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-344", "mrqa_triviaqa-validation-3483", "mrqa_triviaqa-validation-3625", "mrqa_triviaqa-validation-3631", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3739", "mrqa_triviaqa-validation-3812", "mrqa_triviaqa-validation-3865", "mrqa_triviaqa-validation-393", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-401", "mrqa_triviaqa-validation-4086", "mrqa_triviaqa-validation-4146", "mrqa_triviaqa-validation-4167", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-4436", "mrqa_triviaqa-validation-4450", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4614", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-4891", "mrqa_triviaqa-validation-4923", "mrqa_triviaqa-validation-5101", "mrqa_triviaqa-validation-521", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-5265", "mrqa_triviaqa-validation-543", "mrqa_triviaqa-validation-5440", "mrqa_triviaqa-validation-5469", "mrqa_triviaqa-validation-5496", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5735", "mrqa_triviaqa-validation-5787", "mrqa_triviaqa-validation-5923", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-599", "mrqa_triviaqa-validation-6269", "mrqa_triviaqa-validation-6289", "mrqa_triviaqa-validation-6346", "mrqa_triviaqa-validation-6352", "mrqa_triviaqa-validation-6353", "mrqa_triviaqa-validation-6428", "mrqa_triviaqa-validation-6504", "mrqa_triviaqa-validation-6599", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-7039", "mrqa_triviaqa-validation-7062", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7319", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-7506", "mrqa_triviaqa-validation-7557", "mrqa_triviaqa-validation-7668", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-915", "mrqa_triviaqa-validation-935", "mrqa_triviaqa-validation-938"], "OKR": 0.900390625, "KG": 0.51484375, "before_eval_results": {"predictions": ["r Richard Attenborough and wife Sheila Sim", "Miranda v. Arizona", "oscar Wilde", "Vancouver Island", "violin", "Utrecht", "Vietnam", "Jane Austen", "george fox", "rescue", "henpecked", "Mikhail Gorbachev", "CBS", "jazz", "Earthquake", "jungle book", "douglas rush", "rococo", "gallons", "great Dane", "priestly", "Cambodia", "jujitsu", "Hunger Games", "head and neck", "11", "New Zealand", "the Prussian 2nd Army", "kitty in Boots", "Whisky Galore", "Tunisia", "50", "edward kennedy", "egremont", "penguin", "Google", "shoulder", "Iran", "downton Abbey", "bird", "Rudyard Kipling", "backgammon", "Amy Dorrit", "albion", "Germany", "beethoven", "exploits on the Island", "ear", "tree", "Imola Circuit", "trout", "Aldis Hodge", "Emmett Lathrop `` Doc '' Brown, Ph. D.", "North Atlantic Ocean", "1961", "Boston Herald", "Lord Chancellor of England", "\"Britain's Got Talent.\"", "Ashley \"A.J.\" Jewell,", "19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "Nebraska", "( Lewis) Carroll", "The top 100 largest libraries in the United States", "Aung San Suu Kyi"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6323164682539683}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true], "QA-F1": [0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6362", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-6256", "mrqa_triviaqa-validation-6973", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-7029", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-5170", "mrqa_triviaqa-validation-3763", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-1517", "mrqa_triviaqa-validation-2231", "mrqa_triviaqa-validation-255", "mrqa_triviaqa-validation-6858", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-672", "mrqa_triviaqa-validation-5818", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-2578", "mrqa_triviaqa-validation-1936", "mrqa_naturalquestions-validation-8062", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-4771", "mrqa_searchqa-validation-3317", "mrqa_searchqa-validation-6689", "mrqa_searchqa-validation-3618"], "SR": 0.5625, "CSR": 0.5628858024691358, "retrieved_ids": ["mrqa_squad-train-65704", "mrqa_squad-train-84824", "mrqa_squad-train-29336", "mrqa_squad-train-8775", "mrqa_squad-train-15298", "mrqa_squad-train-4211", "mrqa_squad-train-22582", "mrqa_squad-train-72280", "mrqa_squad-train-6367", "mrqa_squad-train-27529", "mrqa_squad-train-4098", "mrqa_squad-train-42425", "mrqa_squad-train-52065", "mrqa_squad-train-33422", "mrqa_squad-train-11902", "mrqa_squad-train-8106", "mrqa_squad-train-30880", "mrqa_squad-train-81698", "mrqa_squad-train-33752", "mrqa_squad-train-34893", "mrqa_squad-train-45177", "mrqa_squad-train-35153", "mrqa_squad-train-24633", "mrqa_squad-train-6583", "mrqa_squad-train-79109", "mrqa_squad-train-85099", "mrqa_squad-train-67699", "mrqa_squad-train-20931", "mrqa_squad-train-29863", "mrqa_squad-train-24497", "mrqa_squad-train-48160", "mrqa_squad-train-55674", "mrqa_searchqa-validation-9368", "mrqa_searchqa-validation-5936", "mrqa_hotpotqa-validation-3431", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-5009", "mrqa_triviaqa-validation-6002", "mrqa_squad-validation-9286", "mrqa_newsqa-validation-3290", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-3842", "mrqa_hotpotqa-validation-4642", "mrqa_triviaqa-validation-2038", "mrqa_hotpotqa-validation-2377", "mrqa_triviaqa-validation-2321", "mrqa_newsqa-validation-1718", "mrqa_triviaqa-validation-1501", "mrqa_searchqa-validation-8166", "mrqa_naturalquestions-validation-9162", "mrqa_searchqa-validation-12390", "mrqa_triviaqa-validation-6805", "mrqa_searchqa-validation-2691", "mrqa_triviaqa-validation-3732", "mrqa_newsqa-validation-1977", "mrqa_naturalquestions-validation-4872", "mrqa_hotpotqa-validation-2341", "mrqa_hotpotqa-validation-5522", "mrqa_newsqa-validation-933", "mrqa_naturalquestions-validation-4714", "mrqa_newsqa-validation-4152", "mrqa_naturalquestions-validation-9871", "mrqa_triviaqa-validation-7742", "mrqa_hotpotqa-validation-5556"], "EFR": 0.39285714285714285, "Overall": 0.6347423390652557}, {"timecode": 81, "before_eval_results": {"predictions": ["Angelina Jolie", "worcestercathedral.co.uk", "dal\u00ef\u00bf\u00bd", "van rijn", "Illinois", "bulgaria", "paul Maskey", "rafa nadal", "tartar sauce", "the Three Graces", "satyrs", "Verdi and his librettist Antonio Somma", "non-Orthodox synagogues", "martin van buren", "l Leeds", "albion", "Operation", "white", "Jay-Z", "Brian Clough", "honda", "Runcorn", "Vietnam", "special administrative zones", "vincent van gogh", "sakhalin", "Croatia", "NBA", "steel", "colonel bumpo", "Henri Paul", "breakdancing", "penguin", "Samuel Johnson", "sidecar", "bulgaria", "Victor Hugo", "endosperm", "the Adriatic Sea", "heartburn", "music Stories", "HMS Conqueror", "j.M.W.", "braille", "Standard Oil Company", "cynthia Nixon", "Hamlet", "Wat Tyler", "wirt", "126 mph", "Ukraine", "Eddie Murphy", "Pakistan", "Dante Pastula", "Thorgan", "senior men's Lithuanian national team", "(Radioisotopes and the Age of The Earth)", "almost 100", "Leg illegitimate victims", "in critical condition", "Superman", "Ericson", "The Towering Inferno", "member states on a voluntary basis"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6065476190476191}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.33333333333333337, 0.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8333333333333333]}}, "before_error_ids": ["mrqa_triviaqa-validation-6788", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-4599", "mrqa_triviaqa-validation-522", "mrqa_triviaqa-validation-6615", "mrqa_triviaqa-validation-4852", "mrqa_triviaqa-validation-1779", "mrqa_triviaqa-validation-4099", "mrqa_triviaqa-validation-5620", "mrqa_triviaqa-validation-2449", "mrqa_triviaqa-validation-1256", "mrqa_triviaqa-validation-6970", "mrqa_triviaqa-validation-4922", "mrqa_triviaqa-validation-3826", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3338", "mrqa_triviaqa-validation-6356", "mrqa_triviaqa-validation-2556", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-6467", "mrqa_triviaqa-validation-7737", "mrqa_triviaqa-validation-3108", "mrqa_triviaqa-validation-2287", "mrqa_hotpotqa-validation-727", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-1039", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-2843", "mrqa_newsqa-validation-1829", "mrqa_searchqa-validation-5224", "mrqa_naturalquestions-validation-10495"], "SR": 0.515625, "CSR": 0.5623094512195121, "retrieved_ids": ["mrqa_squad-train-82470", "mrqa_squad-train-48643", "mrqa_squad-train-78048", "mrqa_squad-train-22487", "mrqa_squad-train-36717", "mrqa_squad-train-18924", "mrqa_squad-train-11276", "mrqa_squad-train-70697", "mrqa_squad-train-72572", "mrqa_squad-train-16546", "mrqa_squad-train-29012", "mrqa_squad-train-32127", "mrqa_squad-train-60639", "mrqa_squad-train-81407", "mrqa_squad-train-45259", "mrqa_squad-train-3414", "mrqa_squad-train-30529", "mrqa_squad-train-7205", "mrqa_squad-train-70072", "mrqa_squad-train-16329", "mrqa_squad-train-23642", "mrqa_squad-train-42647", "mrqa_squad-train-16542", "mrqa_squad-train-74235", "mrqa_squad-train-58151", "mrqa_squad-train-38069", "mrqa_squad-train-37292", "mrqa_squad-train-12802", "mrqa_squad-train-47185", "mrqa_squad-train-3975", "mrqa_squad-train-52260", "mrqa_squad-train-1011", "mrqa_triviaqa-validation-5082", "mrqa_naturalquestions-validation-9650", "mrqa_triviaqa-validation-1176", "mrqa_searchqa-validation-10999", "mrqa_searchqa-validation-12968", "mrqa_triviaqa-validation-3970", "mrqa_naturalquestions-validation-8118", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-2168", "mrqa_naturalquestions-validation-10118", "mrqa_searchqa-validation-5936", "mrqa_hotpotqa-validation-4494", "mrqa_naturalquestions-validation-7020", "mrqa_triviaqa-validation-5759", "mrqa_hotpotqa-validation-5666", "mrqa_searchqa-validation-8348", "mrqa_naturalquestions-validation-3037", "mrqa_newsqa-validation-1537", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-5950", "mrqa_hotpotqa-validation-2080", "mrqa_squad-validation-2657", "mrqa_searchqa-validation-10011", "mrqa_newsqa-validation-3029", "mrqa_hotpotqa-validation-1893", "mrqa_squad-validation-9896", "mrqa_naturalquestions-validation-1336", "mrqa_triviaqa-validation-616", "mrqa_newsqa-validation-3085", "mrqa_triviaqa-validation-4405", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-1159"], "EFR": 0.3548387096774194, "Overall": 0.6270233821793862}, {"timecode": 82, "before_eval_results": {"predictions": ["london daguerre", "france", "tarn", "Toyota", "Sheffield", "the Strait of Messina", "piano", "Louis XVIII", "Pat Cash", "chile", "Wild Atlantic Way", "Kyoto Protocol", "underwater diving", "repechage", "soweto", "\ufffdSon of Sam\u201d", "peacock", "Rita Hayworth", "Miss Honey", "Imola Circuit", "Albania", "antelope", "all animals, no matter the shape or size, usually caused by a traumatic event at some point in life", "zephyrus", "Ivan Basso", "bullfighting", "1", "Playboy", "surrey", "Peter Ackroyd", "walford", "germanan eriksson", "thierry roussel", "arbousset", "death penalty", "Danny Alexander", "14", "Bangladesh", "phaethon", "Papua New Guinea", "Lady Gaga", "sunset boulevard", "raging bull", "ars Gratia Artis", "baloney cubed", "All Things Must Pass", "air", "tet", "Arabah", "d\u00e9j\u00e0 vu", "george graham", "energy moves from producers ( plants ) to primary consumers ( herbivores ) and then to secondary consumers ( predators )", "September 2, 1945", "special guest performers Beyonc\u00e9 and Bruno Mars", "Greg Gorman and Helmut Newton", "American jewelry designer", "Isabella II", "Mexico", "man", "Arizona", "Frdric Chopin", "Indiana Jones", "Batavia", "The Cosmopolitan of Las Vegas"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6559027777777777}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.1111111111111111, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-2664", "mrqa_triviaqa-validation-1948", "mrqa_triviaqa-validation-4315", "mrqa_triviaqa-validation-465", "mrqa_triviaqa-validation-545", "mrqa_triviaqa-validation-7581", "mrqa_triviaqa-validation-1936", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-5088", "mrqa_triviaqa-validation-1233", "mrqa_triviaqa-validation-4554", "mrqa_triviaqa-validation-2177", "mrqa_triviaqa-validation-4147", "mrqa_triviaqa-validation-1467", "mrqa_triviaqa-validation-5020", "mrqa_triviaqa-validation-6576", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-5396", "mrqa_hotpotqa-validation-4838", "mrqa_newsqa-validation-1105", "mrqa_newsqa-validation-784", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-16678"], "SR": 0.59375, "CSR": 0.5626882530120482, "retrieved_ids": ["mrqa_squad-train-62350", "mrqa_squad-train-80241", "mrqa_squad-train-82928", "mrqa_squad-train-16304", "mrqa_squad-train-26837", "mrqa_squad-train-86349", "mrqa_squad-train-70958", "mrqa_squad-train-50484", "mrqa_squad-train-39166", "mrqa_squad-train-24806", "mrqa_squad-train-57916", "mrqa_squad-train-42975", "mrqa_squad-train-23207", "mrqa_squad-train-70464", "mrqa_squad-train-68388", "mrqa_squad-train-4366", "mrqa_squad-train-37797", "mrqa_squad-train-31100", "mrqa_squad-train-48875", "mrqa_squad-train-64374", "mrqa_squad-train-56211", "mrqa_squad-train-63102", "mrqa_squad-train-36737", "mrqa_squad-train-39899", "mrqa_squad-train-53716", "mrqa_squad-train-2791", "mrqa_squad-train-72734", "mrqa_squad-train-26602", "mrqa_squad-train-72749", "mrqa_squad-train-83874", "mrqa_squad-train-23420", "mrqa_squad-train-26468", "mrqa_triviaqa-validation-7349", "mrqa_naturalquestions-validation-1904", "mrqa_newsqa-validation-177", "mrqa_searchqa-validation-16889", "mrqa_triviaqa-validation-1018", "mrqa_hotpotqa-validation-1865", "mrqa_newsqa-validation-3434", "mrqa_newsqa-validation-2081", "mrqa_hotpotqa-validation-2759", "mrqa_searchqa-validation-11295", "mrqa_hotpotqa-validation-3096", "mrqa_hotpotqa-validation-5526", "mrqa_naturalquestions-validation-8660", "mrqa_hotpotqa-validation-108", "mrqa_newsqa-validation-3579", "mrqa_naturalquestions-validation-3048", "mrqa_naturalquestions-validation-7650", "mrqa_hotpotqa-validation-278", "mrqa_triviaqa-validation-5818", "mrqa_triviaqa-validation-28", "mrqa_searchqa-validation-10669", "mrqa_triviaqa-validation-3172", "mrqa_hotpotqa-validation-4667", "mrqa_naturalquestions-validation-683", "mrqa_hotpotqa-validation-3806", "mrqa_triviaqa-validation-5370", "mrqa_newsqa-validation-6", "mrqa_hotpotqa-validation-4178", "mrqa_triviaqa-validation-7595", "mrqa_naturalquestions-validation-4288", "mrqa_hotpotqa-validation-5140", "mrqa_naturalquestions-validation-4416"], "EFR": 0.3076923076923077, "Overall": 0.6176698621408712}, {"timecode": 83, "before_eval_results": {"predictions": ["(Johnny) Depp", "The Green Arrow", "a parable", "Romeo and Juliet", "Spinal Tap", "Tennessee", "Detroit", "Ferris B Mueller's Day Off", "the United States", "Giza", "Ruth Bader Ginsburg", "Article VII", "touch", "Old Fashioned", "the Osmonds", "Bonnie and Clyde", "monodon", "the Indian School", "a chimp", "Indian reservations", "John Updike", "the Ganges", "vision", "Bright Lights and Brightness Falls", "a prostitution scandal", "coelacanth", "Northanger Abbey", "Cheers", "Heather", "Crosby, Stills & Nash", "Matt Leinart", "ABO", "Charles Edward Stuart", "an albatross", "Falklands", "taro", "a quip", "a lighthouse", "white", "Dan Rather", "Georgia-Pacific Corporation", "Buffalo Bill", "the Big Bang Theory", "a pig", "Harvard", "neurons", "Hawaii", "Pierian Spring", "a hobo", "dragonflies", "Bill Cosby", "May 19, 2017", "Bachendri Pal", "James Corden", "Pentecost", "humble pie", "black gangsters", "City and County of Honolulu", "Australian coast", "1992", "publicly criticized his father's parenting skills.", "President-elect Barack Obama", "Stella McCartney", "genocide"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6273065476190476}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.6666666666666665, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13516", "mrqa_searchqa-validation-4520", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-13936", "mrqa_searchqa-validation-1829", "mrqa_searchqa-validation-1455", "mrqa_searchqa-validation-4318", "mrqa_searchqa-validation-2790", "mrqa_searchqa-validation-15868", "mrqa_searchqa-validation-7320", "mrqa_searchqa-validation-6498", "mrqa_searchqa-validation-4565", "mrqa_searchqa-validation-2738", "mrqa_searchqa-validation-8018", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-5868", "mrqa_searchqa-validation-2457", "mrqa_searchqa-validation-9304", "mrqa_searchqa-validation-14371", "mrqa_searchqa-validation-15128", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-4821", "mrqa_searchqa-validation-2946", "mrqa_triviaqa-validation-4", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-3058", "mrqa_newsqa-validation-3660"], "SR": 0.53125, "CSR": 0.5623139880952381, "retrieved_ids": ["mrqa_squad-train-36712", "mrqa_squad-train-18445", "mrqa_squad-train-18431", "mrqa_squad-train-42833", "mrqa_squad-train-65572", "mrqa_squad-train-17534", "mrqa_squad-train-36564", "mrqa_squad-train-82809", "mrqa_squad-train-55209", "mrqa_squad-train-434", "mrqa_squad-train-46671", "mrqa_squad-train-48692", "mrqa_squad-train-10609", "mrqa_squad-train-13533", "mrqa_squad-train-73283", "mrqa_squad-train-17913", "mrqa_squad-train-76545", "mrqa_squad-train-41710", "mrqa_squad-train-51119", "mrqa_squad-train-46326", "mrqa_squad-train-23209", "mrqa_squad-train-69549", "mrqa_squad-train-11787", "mrqa_squad-train-42630", "mrqa_squad-train-2982", "mrqa_squad-train-79210", "mrqa_squad-train-2072", "mrqa_squad-train-19183", "mrqa_squad-train-32833", "mrqa_squad-train-5564", "mrqa_squad-train-85351", "mrqa_squad-train-13943", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-7151", "mrqa_newsqa-validation-2198", "mrqa_naturalquestions-validation-2438", "mrqa_newsqa-validation-2742", "mrqa_searchqa-validation-60", "mrqa_triviaqa-validation-166", "mrqa_triviaqa-validation-1283", "mrqa_hotpotqa-validation-4021", "mrqa_triviaqa-validation-308", "mrqa_naturalquestions-validation-2967", "mrqa_triviaqa-validation-2330", "mrqa_searchqa-validation-679", "mrqa_hotpotqa-validation-471", "mrqa_searchqa-validation-9800", "mrqa_triviaqa-validation-3249", "mrqa_naturalquestions-validation-5580", "mrqa_hotpotqa-validation-3356", "mrqa_naturalquestions-validation-8254", "mrqa_triviaqa-validation-7079", "mrqa_squad-validation-6324", "mrqa_naturalquestions-validation-3385", "mrqa_newsqa-validation-3250", "mrqa_searchqa-validation-12715", "mrqa_squad-validation-434", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2213", "mrqa_searchqa-validation-3481", "mrqa_triviaqa-validation-3437", "mrqa_triviaqa-validation-6466", "mrqa_hotpotqa-validation-1416", "mrqa_naturalquestions-validation-7393"], "EFR": 0.16666666666666666, "Overall": 0.589389880952381}, {"timecode": 84, "before_eval_results": {"predictions": ["1970s", "in Richmond, BC", "1930s", "Isabella Palmieri", "the status line", "each team has either selected a player or traded its draft position", "a major victory of the Civil Rights Movement", "1991", "Jaffa cakes are biscuit - sized cake", "roughly 230 million kilometres ( 143,000,000 mi )", "a jazz funeral without a body", "Palm Sunday celebrations", "Castleford", "fourth", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "wintertime", "to symbolize his guilt in killing the bird", "Robber Barons", "2001", "Lucius Verus", "marks the transition from summer to winter, in September ( Northern Hemisphere ) or March ( Southern Hemisphere ), when the duration of daylight becomes noticeably shorter and the temperature cools down considerably", "2004", "Renhe Sports Management Ltd", "Americans who served in the armed forces and as civilians", "Michael Crawford", "200 to 500 mg up to 7 ml", "gastrocnemius muscle", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "Terry Kath", "Austin, Texas", "1945", "Pebble Beach", "Andaman and Nicobar Islands", "midpiece", "Burj Khalifa", "Pangaea or Pangea", "mitochondrial membrane in eukaryotes or the plasma membrane in bacteria", "Johnny Cash", "former Sheriff Deputy Rick Grimes ( Andrew Lincoln )", "a virtual reality simulator accessible by players using visors and haptic technology such as gloves", "Kevin Spacey", "Human anatomy", "Natural - language processing", "10 years", "2026", "eleven", "I Believe", "In late as the 1890s, building regulations in London did not require working - class housing to have indoor toilets", "Fats Waller", "Joanna Moskawa", "1962", "l Loch Ness", "Lingerie football", "griffin", "Mick Jackson", "Queenston", "15", "Michelle Obama", "Consumer Product Safety Commission Tuesday,", "would have significant public health experience and understand how these processes work, how meat enters the chain of commerce,\"", "saddle bags", "The Tin Drum", "Francis Ouimet", "\"Taz\" DiGregorio,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6504968760673628}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, false, false, true, false, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.3076923076923077, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.4615384615384615, 1.0, 0.16666666666666669, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8181818181818181, 1.0, 0.2, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.5, 0.6153846153846153, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.06896551724137931, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-5483", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-8027", "mrqa_naturalquestions-validation-7017", "mrqa_naturalquestions-validation-7818", "mrqa_naturalquestions-validation-2208", "mrqa_naturalquestions-validation-735", "mrqa_naturalquestions-validation-8555", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-3319", "mrqa_naturalquestions-validation-6190", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-7679", "mrqa_naturalquestions-validation-5838", "mrqa_naturalquestions-validation-6797", "mrqa_naturalquestions-validation-960", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-9723", "mrqa_triviaqa-validation-2065", "mrqa_hotpotqa-validation-4692", "mrqa_newsqa-validation-1869", "mrqa_newsqa-validation-1826", "mrqa_searchqa-validation-7897", "mrqa_searchqa-validation-4132"], "SR": 0.5, "CSR": 0.5615808823529411, "retrieved_ids": ["mrqa_squad-train-23301", "mrqa_squad-train-25442", "mrqa_squad-train-62894", "mrqa_squad-train-44894", "mrqa_squad-train-78385", "mrqa_squad-train-64111", "mrqa_squad-train-16103", "mrqa_squad-train-86108", "mrqa_squad-train-58336", "mrqa_squad-train-29997", "mrqa_squad-train-52059", "mrqa_squad-train-65648", "mrqa_squad-train-14779", "mrqa_squad-train-61838", "mrqa_squad-train-65652", "mrqa_squad-train-12047", "mrqa_squad-train-57516", "mrqa_squad-train-39473", "mrqa_squad-train-40273", "mrqa_squad-train-50994", "mrqa_squad-train-85804", "mrqa_squad-train-46514", "mrqa_squad-train-19799", "mrqa_squad-train-38716", "mrqa_squad-train-3777", "mrqa_squad-train-3696", "mrqa_squad-train-32934", "mrqa_squad-train-6919", "mrqa_squad-train-27396", "mrqa_squad-train-72475", "mrqa_squad-train-33074", "mrqa_squad-train-67850", "mrqa_hotpotqa-validation-5240", "mrqa_triviaqa-validation-1018", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-1026", "mrqa_naturalquestions-validation-6727", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3434", "mrqa_searchqa-validation-6531", "mrqa_searchqa-validation-13110", "mrqa_triviaqa-validation-5810", "mrqa_naturalquestions-validation-6720", "mrqa_hotpotqa-validation-3988", "mrqa_squad-validation-7382", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-6356", "mrqa_searchqa-validation-5060", "mrqa_hotpotqa-validation-501", "mrqa_triviaqa-validation-192", "mrqa_naturalquestions-validation-2334", "mrqa_searchqa-validation-7238", "mrqa_triviaqa-validation-414", "mrqa_hotpotqa-validation-1791", "mrqa_searchqa-validation-7408", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-5522", "mrqa_newsqa-validation-2324", "mrqa_hotpotqa-validation-1835", "mrqa_searchqa-validation-5591", "mrqa_hotpotqa-validation-2639", "mrqa_searchqa-validation-12782", "mrqa_hotpotqa-validation-2171", "mrqa_newsqa-validation-2042"], "EFR": 0.0, "Overall": 0.5559099264705882}, {"timecode": 85, "before_eval_results": {"predictions": ["Rolex", "Vincent", "cycling", "ganges", "paul Maskey", "mollusks", "robert rygers", "Steve Jobs", "jane ostroff", "Nirvana", "Donna Summer", "frog", "geese", "a special messenger of Jesus Christ", "Sheryl Suzanne Crow", "Sir", "1", "Franklin delano Roosevelt", "neurons", "porridge", "oregon", "Swordfish", "earwax", "george best", "faggots", "11", "parson brown", "Australia and England", "pascal", "british Airways", "five", "Challenger", "The World is Not Enough", "Giglio", "Vienna", "glee", "David Hockney", "iron", "koreans", "bayern munich", "Jenni Richards", "bologna, Italy", "mexico", "May Day", "chilies", "Madagascar", "Beaujolais", "clapping", "kolkata", "rictly come dancing", "davie", "Nick Sager", "Forbes Burnham", "2007", "Dra\u017een Petrovi\u0107", "Costa del Sol", "early Romantic period", "first grand Slam,", "propofol,", "whether the reports about American Airlines are true or not doesn't really matter", "Treaty of Versailles", "Zinedine Zidane", "Macduff", "a newt"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6774553571428571}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-4852", "mrqa_triviaqa-validation-3601", "mrqa_triviaqa-validation-7627", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-2336", "mrqa_triviaqa-validation-7526", "mrqa_triviaqa-validation-2477", "mrqa_triviaqa-validation-6140", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-3610", "mrqa_triviaqa-validation-5128", "mrqa_triviaqa-validation-7158", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-1961", "mrqa_triviaqa-validation-5759", "mrqa_triviaqa-validation-1995", "mrqa_hotpotqa-validation-1634", "mrqa_newsqa-validation-1154", "mrqa_newsqa-validation-1946", "mrqa_searchqa-validation-4261"], "SR": 0.609375, "CSR": 0.5621366279069768, "retrieved_ids": ["mrqa_squad-train-9190", "mrqa_squad-train-50601", "mrqa_squad-train-64571", "mrqa_squad-train-65946", "mrqa_squad-train-57734", "mrqa_squad-train-46235", "mrqa_squad-train-37773", "mrqa_squad-train-17053", "mrqa_squad-train-1547", "mrqa_squad-train-28059", "mrqa_squad-train-31800", "mrqa_squad-train-27490", "mrqa_squad-train-27008", "mrqa_squad-train-53051", "mrqa_squad-train-33014", "mrqa_squad-train-38807", "mrqa_squad-train-16383", "mrqa_squad-train-41403", "mrqa_squad-train-79602", "mrqa_squad-train-69144", "mrqa_squad-train-48907", "mrqa_squad-train-17020", "mrqa_squad-train-57348", "mrqa_squad-train-73543", "mrqa_squad-train-29912", "mrqa_squad-train-76655", "mrqa_squad-train-33751", "mrqa_squad-train-76320", "mrqa_squad-train-23028", "mrqa_squad-train-2114", "mrqa_squad-train-37337", "mrqa_squad-train-15849", "mrqa_hotpotqa-validation-2042", "mrqa_triviaqa-validation-7545", "mrqa_triviaqa-validation-4512", "mrqa_hotpotqa-validation-76", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-3004", "mrqa_naturalquestions-validation-10454", "mrqa_newsqa-validation-2491", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-7720", "mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-5414", "mrqa_hotpotqa-validation-2465", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-3554", "mrqa_naturalquestions-validation-4961", "mrqa_hotpotqa-validation-234", "mrqa_triviaqa-validation-7390", "mrqa_newsqa-validation-1144", "mrqa_hotpotqa-validation-3245", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-7489", "mrqa_triviaqa-validation-5170", "mrqa_hotpotqa-validation-2047", "mrqa_hotpotqa-validation-961", "mrqa_searchqa-validation-5326", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-5483", "mrqa_searchqa-validation-6095", "mrqa_naturalquestions-validation-9162", "mrqa_searchqa-validation-5075", "mrqa_searchqa-validation-3286"], "EFR": 0.0, "Overall": 0.5560210755813954}, {"timecode": 86, "before_eval_results": {"predictions": ["Switzerland", "General Sir John Monash", "Tempo", "photographs, film and television", "Arthur Freed", "alt-right", "Runaways", "\"50 best cities to live in.\"", "La Liga", "first season", "8 May 1989", "Iran", "a polypeptide chain", "murder", "London", "SBS", "quantum mechanics", "Duncan", "February 12, 2014", "Forbes", "Anne and Georges", "David Villa S\u00e1nchez", "Double Agent", "Super Bowl XXIX", "White Horse", "Diamond Rio", "Quentin Coldwater", "Andrew Johnson", "The Curious Case of Benjamin Button", "Martha Wainwright", "Leafcutter John", "moth", "Bothtec", "Jim Thorpe", "De La Soul", "\"Love the Way You Lie\" (2012)", "Shropshire Union Canal", "early 17th-century", "a skerry", "Oliver Parker", "The Strain", "Kalokuokamaile", "Pac-12 Conference", "Roots: The Saga of an American Family", "five", "Jack Elam", "The Jeffersons", "The Rakes", "prevent the opposing team from scoring goals", "Cody Miller", "from 1908 to 1994", "The first series was recorded at Granada Studios in Manchester, but has since been recorded at The Maidstone Studios in Maidstone, Kent", "strings of eight bits ( known as bytes ) at a time", "The Witch and the Hundred Knight 2", "leopold", "Bill Haley & His comets", "the Most Rev and Rt Hon George Carey", "Amanda Knox's aunt Janet Huff", "Number Ones", "the Gulf of Aden, a body of water between Somalia and Yemen,", "(E.B.) White", "Andrew Jackson", "Jefferson", "Willa Cather"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6608313127844379}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.18181818181818182, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.8750000000000001, 0.0, 0.0, 0.4, 0.4444444444444445, 0.5714285714285715, 1.0, 0.15384615384615383, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2577", "mrqa_hotpotqa-validation-5632", "mrqa_hotpotqa-validation-3778", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-3231", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-2035", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-665", "mrqa_hotpotqa-validation-106", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-4507", "mrqa_hotpotqa-validation-4484", "mrqa_hotpotqa-validation-4326", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-2060", "mrqa_hotpotqa-validation-3788", "mrqa_naturalquestions-validation-5460", "mrqa_naturalquestions-validation-4319", "mrqa_naturalquestions-validation-3329", "mrqa_triviaqa-validation-5287", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-5047", "mrqa_newsqa-validation-3212", "mrqa_newsqa-validation-2558", "mrqa_searchqa-validation-1530"], "SR": 0.546875, "CSR": 0.5619612068965517, "retrieved_ids": ["mrqa_squad-train-71883", "mrqa_squad-train-66956", "mrqa_squad-train-26988", "mrqa_squad-train-38679", "mrqa_squad-train-26452", "mrqa_squad-train-17754", "mrqa_squad-train-71942", "mrqa_squad-train-56124", "mrqa_squad-train-79876", "mrqa_squad-train-18324", "mrqa_squad-train-11175", "mrqa_squad-train-58497", "mrqa_squad-train-33634", "mrqa_squad-train-82400", "mrqa_squad-train-26458", "mrqa_squad-train-82806", "mrqa_squad-train-65922", "mrqa_squad-train-53823", "mrqa_squad-train-34869", "mrqa_squad-train-3668", "mrqa_squad-train-40838", "mrqa_squad-train-81974", "mrqa_squad-train-47624", "mrqa_squad-train-11083", "mrqa_squad-train-81987", "mrqa_squad-train-14740", "mrqa_squad-train-7509", "mrqa_squad-train-22933", "mrqa_squad-train-33292", "mrqa_squad-train-76883", "mrqa_squad-train-69335", "mrqa_squad-train-21826", "mrqa_triviaqa-validation-4872", "mrqa_searchqa-validation-10027", "mrqa_searchqa-validation-9007", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-3937", "mrqa_hotpotqa-validation-2985", "mrqa_searchqa-validation-14322", "mrqa_triviaqa-validation-6091", "mrqa_hotpotqa-validation-4494", "mrqa_naturalquestions-validation-8669", "mrqa_searchqa-validation-5713", "mrqa_hotpotqa-validation-4133", "mrqa_searchqa-validation-6948", "mrqa_naturalquestions-validation-1664", "mrqa_triviaqa-validation-1334", "mrqa_hotpotqa-validation-5557", "mrqa_squad-validation-3998", "mrqa_hotpotqa-validation-66", "mrqa_naturalquestions-validation-328", "mrqa_squad-validation-6393", "mrqa_searchqa-validation-8348", "mrqa_triviaqa-validation-2556", "mrqa_newsqa-validation-3250", "mrqa_newsqa-validation-3004", "mrqa_naturalquestions-validation-3199", "mrqa_searchqa-validation-8513", "mrqa_triviaqa-validation-4573", "mrqa_naturalquestions-validation-5499", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-486"], "EFR": 0.0, "Overall": 0.5559859913793103}, {"timecode": 87, "before_eval_results": {"predictions": ["Edward R. Murrow", "Vision of the Future", "1754", "8 November 1978", "Hamlet", "Marty Ingels", "Milwaukee Bucks", "McLaren-Honda", "Ferengi Cockark", "The Spiderwick Chronicles", "American reality documentary television series", "Sarah Kerrigan, the Queen of Blades", "Qualcomm", "water", "10-metre platform event", "Cleveland Browns", "on the shore", "Guardians of the Galaxy Vol.  2", "November 15, 1903", "Bury St Edmunds", "Rothschild banking dynasty", "Mr. Church", "\"Bigger Than Both of Us\"", "Thomas Christopher Ince", "Pete Sell", "public house", "Los Angeles", "The Future", "Vyd\u016bnas", "al-Qaeda", "the Darling River", "Baldwin", "Michael Fassbender", "House of Commons", "William Finn", "Love Letter", "Indian", "Type 212", "Barnoldswick", "late 12th Century", "Bob Gibson", "The S7 series", "729", "tenure", "Frederick Alexander", "Robert Jenrick", "Somerset County, Pennsylvania", "Salford, Lancashire", "Conservative", "The Division of Cook", "\"Peshwa\" (Prime Minister)", "Prafulla Chandra Ghosh", "the retina", "Confederate forces", "sene", "DeLorean", "amelia earhart", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "Vivek Wadhwa,", "put him in \"solitary confinement.\"", "a snowmobile", "a snakes", "porcelain", "activation of alpha - 1 adrenergic receptors by norepinephrine released by post-ganglionic sympathetic neurons"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6406746031746031}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6, 0.0, 0.14285714285714285, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-4988", "mrqa_hotpotqa-validation-5843", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3554", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-908", "mrqa_hotpotqa-validation-958", "mrqa_hotpotqa-validation-5056", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-3464", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-4658", "mrqa_hotpotqa-validation-4751", "mrqa_hotpotqa-validation-3843", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-6888", "mrqa_triviaqa-validation-2525", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-4026", "mrqa_searchqa-validation-7328", "mrqa_searchqa-validation-5276", "mrqa_searchqa-validation-10831", "mrqa_naturalquestions-validation-836"], "SR": 0.546875, "CSR": 0.5617897727272727, "retrieved_ids": ["mrqa_squad-train-64563", "mrqa_squad-train-7917", "mrqa_squad-train-85183", "mrqa_squad-train-36085", "mrqa_squad-train-77868", "mrqa_squad-train-79129", "mrqa_squad-train-66232", "mrqa_squad-train-24281", "mrqa_squad-train-18587", "mrqa_squad-train-58894", "mrqa_squad-train-65810", "mrqa_squad-train-86050", "mrqa_squad-train-46969", "mrqa_squad-train-526", "mrqa_squad-train-79105", "mrqa_squad-train-65848", "mrqa_squad-train-7801", "mrqa_squad-train-64389", "mrqa_squad-train-59218", "mrqa_squad-train-71377", "mrqa_squad-train-18763", "mrqa_squad-train-69299", "mrqa_squad-train-108", "mrqa_squad-train-61023", "mrqa_squad-train-53001", "mrqa_squad-train-84036", "mrqa_squad-train-36478", "mrqa_squad-train-45133", "mrqa_squad-train-56948", "mrqa_squad-train-59519", "mrqa_squad-train-43753", "mrqa_squad-train-8465", "mrqa_triviaqa-validation-5020", "mrqa_searchqa-validation-2347", "mrqa_hotpotqa-validation-4298", "mrqa_hotpotqa-validation-412", "mrqa_triviaqa-validation-7627", "mrqa_naturalquestions-validation-5564", "mrqa_naturalquestions-validation-2851", "mrqa_hotpotqa-validation-4606", "mrqa_triviaqa-validation-3102", "mrqa_triviaqa-validation-7304", "mrqa_hotpotqa-validation-76", "mrqa_squad-validation-6091", "mrqa_newsqa-validation-2521", "mrqa_triviaqa-validation-476", "mrqa_naturalquestions-validation-9871", "mrqa_triviaqa-validation-3215", "mrqa_triviaqa-validation-3263", "mrqa_searchqa-validation-8018", "mrqa_naturalquestions-validation-2238", "mrqa_searchqa-validation-13367", "mrqa_newsqa-validation-715", "mrqa_naturalquestions-validation-3499", "mrqa_naturalquestions-validation-4319", "mrqa_triviaqa-validation-5439", "mrqa_naturalquestions-validation-1435", "mrqa_newsqa-validation-2913", "mrqa_naturalquestions-validation-1357", "mrqa_newsqa-validation-2533", "mrqa_naturalquestions-validation-7650", "mrqa_triviaqa-validation-728", "mrqa_searchqa-validation-2615", "mrqa_searchqa-validation-4745"], "EFR": 0.0, "Overall": 0.5559517045454545}, {"timecode": 88, "before_eval_results": {"predictions": ["outgoing Republican President George W. Bush", "le m\u00f4me", "germany", "Apollo", "Richard Wagner", "Atticus Finch", "The Peter Principle", "copper and zinc", "weight plates", "Dunfermline", "bison bison", "Edmund Cartwright", "Mary Poppins", "leicestershire", "black Wednesday", "Samoa", "james beattie", "daily Mirror", "copper", "olympus Mons", "Poland", "caffari", "wooden cow", "guatamala", "barry cryer", "wirral peninsula", "prawns", "James Hogg", "massively multiplayer online games", "fermanagh", "Colombia", "Kevin Painter", "llyn Padarn", "Anne Boleyn", "Muhammad Ali", "carmen Miranda", "Sandi Toksvig", "John McEnroe", "1982", "Estonia", "Sarajevo", "gluten", "an enclave is a country which is entirely enclosed by the territorial waters of another nation", "arthur ransome", "jim laker", "Ridley Scott", "five", "Simpsons", "adrian edmondson", "63 to 144 inches", "(1925-2013)", "September 29, 2017", "Walter Brennan", "from 13 to 22 June 2012", "Cuban-American Major League Clubs Series", "2015", "Spanish", "Lashkar-e-Tayyiba", "the \"surge\" strategy he implemented last year.", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.", "devil's food cake", "Michelangelo", "Missouri", "George Jetson"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7080965909090908}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9090909090909091, 0.9090909090909091, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-176", "mrqa_triviaqa-validation-4613", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-7041", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-6136", "mrqa_triviaqa-validation-7133", "mrqa_triviaqa-validation-4362", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-5415", "mrqa_triviaqa-validation-1988", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-1813", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-602", "mrqa_naturalquestions-validation-3589", "mrqa_hotpotqa-validation-3114", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-161"], "SR": 0.640625, "CSR": 0.5626755617977528, "retrieved_ids": ["mrqa_squad-train-45997", "mrqa_squad-train-46042", "mrqa_squad-train-76030", "mrqa_squad-train-66518", "mrqa_squad-train-79642", "mrqa_squad-train-8733", "mrqa_squad-train-40403", "mrqa_squad-train-58008", "mrqa_squad-train-50051", "mrqa_squad-train-60357", "mrqa_squad-train-33758", "mrqa_squad-train-396", "mrqa_squad-train-60505", "mrqa_squad-train-45587", "mrqa_squad-train-63614", "mrqa_squad-train-18703", "mrqa_squad-train-50331", "mrqa_squad-train-24579", "mrqa_squad-train-80144", "mrqa_squad-train-73695", "mrqa_squad-train-11330", "mrqa_squad-train-29481", "mrqa_squad-train-35070", "mrqa_squad-train-72929", "mrqa_squad-train-71718", "mrqa_squad-train-15717", "mrqa_squad-train-86298", "mrqa_squad-train-7024", "mrqa_squad-train-29603", "mrqa_squad-train-26194", "mrqa_squad-train-83994", "mrqa_squad-train-30960", "mrqa_searchqa-validation-12019", "mrqa_newsqa-validation-198", "mrqa_triviaqa-validation-2081", "mrqa_triviaqa-validation-6683", "mrqa_searchqa-validation-4068", "mrqa_naturalquestions-validation-836", "mrqa_hotpotqa-validation-4687", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8186", "mrqa_searchqa-validation-13367", "mrqa_searchqa-validation-3955", "mrqa_searchqa-validation-9991", "mrqa_triviaqa-validation-1676", "mrqa_newsqa-validation-2249", "mrqa_searchqa-validation-8235", "mrqa_searchqa-validation-10889", "mrqa_squad-validation-5", "mrqa_triviaqa-validation-782", "mrqa_hotpotqa-validation-4818", "mrqa_searchqa-validation-2552", "mrqa_newsqa-validation-775", "mrqa_triviaqa-validation-4745", "mrqa_searchqa-validation-9645", "mrqa_searchqa-validation-2851", "mrqa_triviaqa-validation-1334", "mrqa_newsqa-validation-3640", "mrqa_naturalquestions-validation-7058", "mrqa_newsqa-validation-2204", "mrqa_triviaqa-validation-2666", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7720"], "EFR": 0.0, "Overall": 0.5561288623595505}, {"timecode": 89, "before_eval_results": {"predictions": ["1", "a graphical user interface", "Scottie Pippen", "Vaseline", "savings rate", "silver", "Gone with the Wind", "the triangle", "Nelly", "Saint Telemachus", "Finding Nemo", "a tongue", "A Thousand Splendid Suns", "a shark", "Kampala", "Oprah Winfrey", "Dixie Chicks", "Apple pie", "California", "Best Buy", "the Adriatic", "Pope", "scallops", "Yemen", "David Geffen", "chariots", "Neruda", "the due process clause of the Fifth Amendment", "a mite", "Saturn", "the Nanny Diaries", "liquid crystals", "Robert Frost", "a dictum", "Nutella Cheesecake", "Crete", "Father Brown", "Leah", "The Outsiders", "the waltz", "Belch", "Jane Austen", "Wisconsin", "A Tale of Two Cities", "Q", "When Harry Met Sally", "Mexico", "a pumice", "John Molson", "Jan and Dean", "American novelist", "Janis Joplin", "all transmissions", "Sir Hugh Beaver", "Andorra", "m Michael Faraday", "g Gerald R. Ford", "1992", "The King of Chutzpah", "Niger\u2013Congo", "upper respiratory infection.", "Fernando Gonzalez", "At least 14", "as spies for more than two years,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.735842803030303}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, false, false], "QA-F1": [0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.8, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.7272727272727273]}}, "before_error_ids": ["mrqa_searchqa-validation-13576", "mrqa_searchqa-validation-1293", "mrqa_searchqa-validation-16479", "mrqa_searchqa-validation-11007", "mrqa_searchqa-validation-10986", "mrqa_searchqa-validation-12402", "mrqa_searchqa-validation-9056", "mrqa_searchqa-validation-946", "mrqa_searchqa-validation-1240", "mrqa_searchqa-validation-14490", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-13703", "mrqa_searchqa-validation-13789", "mrqa_searchqa-validation-6127", "mrqa_searchqa-validation-6422", "mrqa_searchqa-validation-1990", "mrqa_searchqa-validation-15735", "mrqa_searchqa-validation-550", "mrqa_naturalquestions-validation-9419", "mrqa_triviaqa-validation-7721", "mrqa_triviaqa-validation-1115", "mrqa_newsqa-validation-795", "mrqa_newsqa-validation-3145"], "SR": 0.640625, "CSR": 0.5635416666666666, "retrieved_ids": ["mrqa_squad-train-52272", "mrqa_squad-train-5133", "mrqa_squad-train-39723", "mrqa_squad-train-77224", "mrqa_squad-train-8880", "mrqa_squad-train-39393", "mrqa_squad-train-79313", "mrqa_squad-train-16725", "mrqa_squad-train-36054", "mrqa_squad-train-49231", "mrqa_squad-train-58678", "mrqa_squad-train-28776", "mrqa_squad-train-38571", "mrqa_squad-train-66691", "mrqa_squad-train-21644", "mrqa_squad-train-72297", "mrqa_squad-train-878", "mrqa_squad-train-63550", "mrqa_squad-train-72245", "mrqa_squad-train-72599", "mrqa_squad-train-25982", "mrqa_squad-train-42504", "mrqa_squad-train-32067", "mrqa_squad-train-68724", "mrqa_squad-train-49783", "mrqa_squad-train-76727", "mrqa_squad-train-3195", "mrqa_squad-train-15933", "mrqa_squad-train-73780", "mrqa_squad-train-35209", "mrqa_squad-train-57484", "mrqa_squad-train-34150", "mrqa_hotpotqa-validation-4399", "mrqa_hotpotqa-validation-5094", "mrqa_naturalquestions-validation-8272", "mrqa_searchqa-validation-1800", "mrqa_newsqa-validation-1661", "mrqa_searchqa-validation-3189", "mrqa_squad-validation-4256", "mrqa_hotpotqa-validation-2744", "mrqa_searchqa-validation-3762", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5271", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-10238", "mrqa_hotpotqa-validation-2903", "mrqa_hotpotqa-validation-2425", "mrqa_searchqa-validation-2247", "mrqa_newsqa-validation-1091", "mrqa_triviaqa-validation-6467", "mrqa_triviaqa-validation-5380", "mrqa_naturalquestions-validation-3942", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-3976", "mrqa_searchqa-validation-9135", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-1960", "mrqa_naturalquestions-validation-4751", "mrqa_searchqa-validation-4533", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-850", "mrqa_hotpotqa-validation-1190", "mrqa_searchqa-validation-2673", "mrqa_hotpotqa-validation-2342"], "EFR": 0.0, "Overall": 0.5563020833333333}, {"timecode": 90, "UKR": 0.798828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1052", "mrqa_hotpotqa-validation-106", "mrqa_hotpotqa-validation-1088", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-1247", "mrqa_hotpotqa-validation-1292", "mrqa_hotpotqa-validation-13", "mrqa_hotpotqa-validation-1301", "mrqa_hotpotqa-validation-1473", "mrqa_hotpotqa-validation-1490", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-1544", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-1691", "mrqa_hotpotqa-validation-1736", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-189", "mrqa_hotpotqa-validation-1986", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-2111", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-2212", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-2378", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2496", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2590", "mrqa_hotpotqa-validation-2604", "mrqa_hotpotqa-validation-2650", "mrqa_hotpotqa-validation-2873", "mrqa_hotpotqa-validation-2892", "mrqa_hotpotqa-validation-2903", "mrqa_hotpotqa-validation-2908", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-2952", "mrqa_hotpotqa-validation-2971", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-2984", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3175", "mrqa_hotpotqa-validation-3245", "mrqa_hotpotqa-validation-3323", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3374", "mrqa_hotpotqa-validation-3428", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-3793", "mrqa_hotpotqa-validation-3934", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-4038", "mrqa_hotpotqa-validation-4076", "mrqa_hotpotqa-validation-4084", "mrqa_hotpotqa-validation-4123", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-4249", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4484", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-4500", "mrqa_hotpotqa-validation-4632", "mrqa_hotpotqa-validation-4658", "mrqa_hotpotqa-validation-4708", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4818", "mrqa_hotpotqa-validation-4841", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-494", "mrqa_hotpotqa-validation-5172", "mrqa_hotpotqa-validation-5358", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-542", "mrqa_hotpotqa-validation-5427", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-5632", "mrqa_hotpotqa-validation-5666", "mrqa_hotpotqa-validation-5719", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-5864", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-66", "mrqa_hotpotqa-validation-727", "mrqa_hotpotqa-validation-76", "mrqa_hotpotqa-validation-884", "mrqa_hotpotqa-validation-916", "mrqa_hotpotqa-validation-975", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-10159", "mrqa_naturalquestions-validation-10417", "mrqa_naturalquestions-validation-10493", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-1797", "mrqa_naturalquestions-validation-1824", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-1920", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-214", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-2379", "mrqa_naturalquestions-validation-2515", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-2620", "mrqa_naturalquestions-validation-2837", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-289", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-3186", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-3425", "mrqa_naturalquestions-validation-3560", "mrqa_naturalquestions-validation-3569", "mrqa_naturalquestions-validation-3589", "mrqa_naturalquestions-validation-3692", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-4073", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4307", "mrqa_naturalquestions-validation-4319", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-4645", "mrqa_naturalquestions-validation-468", "mrqa_naturalquestions-validation-4736", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5072", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-5331", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-5425", "mrqa_naturalquestions-validation-5503", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6069", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-757", "mrqa_naturalquestions-validation-7595", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-7806", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7892", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-9608", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-9814", "mrqa_naturalquestions-validation-9871", "mrqa_naturalquestions-validation-9878", "mrqa_newsqa-validation-1013", "mrqa_newsqa-validation-1105", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-1129", "mrqa_newsqa-validation-1183", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-1365", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-161", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-175", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-183", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2002", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-2494", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-2664", "mrqa_newsqa-validation-2856", "mrqa_newsqa-validation-2861", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2899", "mrqa_newsqa-validation-2992", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-3179", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-3520", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3639", "mrqa_newsqa-validation-3715", "mrqa_newsqa-validation-3780", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3992", "mrqa_newsqa-validation-406", "mrqa_newsqa-validation-4060", "mrqa_newsqa-validation-454", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-61", "mrqa_newsqa-validation-698", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-946", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-10330", "mrqa_searchqa-validation-10597", "mrqa_searchqa-validation-10616", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-10776", "mrqa_searchqa-validation-10999", "mrqa_searchqa-validation-11247", "mrqa_searchqa-validation-11294", "mrqa_searchqa-validation-11898", "mrqa_searchqa-validation-1196", "mrqa_searchqa-validation-12085", "mrqa_searchqa-validation-12127", "mrqa_searchqa-validation-12151", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-12360", "mrqa_searchqa-validation-12402", "mrqa_searchqa-validation-12782", "mrqa_searchqa-validation-1290", "mrqa_searchqa-validation-12976", "mrqa_searchqa-validation-13014", "mrqa_searchqa-validation-13765", "mrqa_searchqa-validation-13789", "mrqa_searchqa-validation-13803", "mrqa_searchqa-validation-14285", "mrqa_searchqa-validation-14307", "mrqa_searchqa-validation-14471", "mrqa_searchqa-validation-1497", "mrqa_searchqa-validation-15064", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-15709", "mrqa_searchqa-validation-15716", "mrqa_searchqa-validation-15725", "mrqa_searchqa-validation-16016", "mrqa_searchqa-validation-16162", "mrqa_searchqa-validation-16311", "mrqa_searchqa-validation-16865", "mrqa_searchqa-validation-16910", "mrqa_searchqa-validation-1829", "mrqa_searchqa-validation-191", "mrqa_searchqa-validation-1950", "mrqa_searchqa-validation-2189", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-2591", "mrqa_searchqa-validation-2673", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-2898", "mrqa_searchqa-validation-2943", "mrqa_searchqa-validation-3081", "mrqa_searchqa-validation-3092", "mrqa_searchqa-validation-324", "mrqa_searchqa-validation-327", "mrqa_searchqa-validation-3303", "mrqa_searchqa-validation-3381", "mrqa_searchqa-validation-3455", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-3838", "mrqa_searchqa-validation-4320", "mrqa_searchqa-validation-4380", "mrqa_searchqa-validation-4509", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-4878", "mrqa_searchqa-validation-5060", "mrqa_searchqa-validation-550", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-5971", "mrqa_searchqa-validation-6122", "mrqa_searchqa-validation-6127", "mrqa_searchqa-validation-6137", "mrqa_searchqa-validation-6697", "mrqa_searchqa-validation-6829", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-714", "mrqa_searchqa-validation-7162", "mrqa_searchqa-validation-7186", "mrqa_searchqa-validation-731", "mrqa_searchqa-validation-7322", "mrqa_searchqa-validation-7521", "mrqa_searchqa-validation-7741", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7880", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-7932", "mrqa_searchqa-validation-8166", "mrqa_searchqa-validation-8331", "mrqa_searchqa-validation-8481", "mrqa_searchqa-validation-8648", "mrqa_searchqa-validation-8691", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-8986", "mrqa_searchqa-validation-9056", "mrqa_searchqa-validation-9284", "mrqa_searchqa-validation-9348", "mrqa_searchqa-validation-9438", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-10067", "mrqa_squad-validation-1023", "mrqa_squad-validation-10466", "mrqa_squad-validation-10483", "mrqa_squad-validation-1071", "mrqa_squad-validation-1215", "mrqa_squad-validation-1251", "mrqa_squad-validation-1312", "mrqa_squad-validation-1856", "mrqa_squad-validation-2098", "mrqa_squad-validation-2434", "mrqa_squad-validation-2458", "mrqa_squad-validation-2888", "mrqa_squad-validation-3202", "mrqa_squad-validation-343", "mrqa_squad-validation-3551", "mrqa_squad-validation-356", "mrqa_squad-validation-3823", "mrqa_squad-validation-4110", "mrqa_squad-validation-4870", "mrqa_squad-validation-5112", "mrqa_squad-validation-512", "mrqa_squad-validation-5590", "mrqa_squad-validation-5874", "mrqa_squad-validation-60", "mrqa_squad-validation-6255", "mrqa_squad-validation-6316", "mrqa_squad-validation-6324", "mrqa_squad-validation-6373", "mrqa_squad-validation-6393", "mrqa_squad-validation-6539", "mrqa_squad-validation-6657", "mrqa_squad-validation-6690", "mrqa_squad-validation-687", "mrqa_squad-validation-7068", "mrqa_squad-validation-7144", "mrqa_squad-validation-7162", "mrqa_squad-validation-7209", "mrqa_squad-validation-7937", "mrqa_squad-validation-805", "mrqa_squad-validation-8747", "mrqa_squad-validation-8761", "mrqa_squad-validation-8807", "mrqa_squad-validation-8881", "mrqa_squad-validation-9154", "mrqa_squad-validation-9578", "mrqa_squad-validation-9761", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-1076", "mrqa_triviaqa-validation-1123", "mrqa_triviaqa-validation-1125", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1335", "mrqa_triviaqa-validation-1355", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1467", "mrqa_triviaqa-validation-1657", "mrqa_triviaqa-validation-170", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-1948", "mrqa_triviaqa-validation-1965", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-2239", "mrqa_triviaqa-validation-2458", "mrqa_triviaqa-validation-2518", "mrqa_triviaqa-validation-2653", "mrqa_triviaqa-validation-2653", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-2798", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-3025", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3064", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-3104", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-3172", "mrqa_triviaqa-validation-3201", "mrqa_triviaqa-validation-3263", "mrqa_triviaqa-validation-3288", "mrqa_triviaqa-validation-3300", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-344", "mrqa_triviaqa-validation-3483", "mrqa_triviaqa-validation-3625", "mrqa_triviaqa-validation-3631", "mrqa_triviaqa-validation-3708", "mrqa_triviaqa-validation-3812", "mrqa_triviaqa-validation-3865", "mrqa_triviaqa-validation-393", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-401", "mrqa_triviaqa-validation-4086", "mrqa_triviaqa-validation-4110", "mrqa_triviaqa-validation-4146", "mrqa_triviaqa-validation-4167", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-4378", "mrqa_triviaqa-validation-4436", "mrqa_triviaqa-validation-4450", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4605", "mrqa_triviaqa-validation-4614", "mrqa_triviaqa-validation-4625", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-4814", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-5079", "mrqa_triviaqa-validation-5101", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-5265", "mrqa_triviaqa-validation-5306", "mrqa_triviaqa-validation-5415", "mrqa_triviaqa-validation-543", "mrqa_triviaqa-validation-5469", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5787", "mrqa_triviaqa-validation-5818", "mrqa_triviaqa-validation-5923", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-609", "mrqa_triviaqa-validation-6136", "mrqa_triviaqa-validation-6289", "mrqa_triviaqa-validation-6332", "mrqa_triviaqa-validation-6346", "mrqa_triviaqa-validation-6352", "mrqa_triviaqa-validation-6353", "mrqa_triviaqa-validation-6364", "mrqa_triviaqa-validation-6428", "mrqa_triviaqa-validation-6504", "mrqa_triviaqa-validation-6599", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6662", "mrqa_triviaqa-validation-6788", "mrqa_triviaqa-validation-6853", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-7039", "mrqa_triviaqa-validation-7062", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-7319", "mrqa_triviaqa-validation-7506", "mrqa_triviaqa-validation-7557", "mrqa_triviaqa-validation-7581", "mrqa_triviaqa-validation-7668", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-915", "mrqa_triviaqa-validation-938", "mrqa_triviaqa-validation-980"], "OKR": 0.849609375, "KG": 0.53125, "before_eval_results": {"predictions": ["the Harpe brothers", "McComb, Mississippi", "Loch Lomond", "American reality documentary television series", "Gweilo", "The Royal Family", "The Ninth Gate", "James G. Kiernan", "was the daughter of Dejazmatch Yilma Makonnen, governor of Harar and niece of Emperor Haile Selassie of Ethiopia", "Erreway", "Protestant Christian", "Eardwulf", "Bellagio and The Mirage", "Los Angeles Dance Theater", "albion", "Hampton University", "To SquarePants or Not to Square Pants", "Jenji Kohan", "1", "God Save the Queen", "Hibernian", "Oklahoma City", "Vincent Landay", "Randall Boggs", "October 22, 2012", "melodic hard rock", "in honour of Louis Mountbatten", "\"Slaughterhouse-Five\"", "Harry F. Sinclair", "Ghana Technology University College", "Bigfoot", "Cyclic Defrost", "England, Scotland, and Ireland", "Coal Miner's daughter", "Worcester", "1972", "Ang Lee", "Brad Silberling", "Blue", "Ealdorman of Devon", "La Scala, Milan", "Orson Welles", "(7 November 1951 \u2013 13 April 1987)", "Jeff Schaffer", "Ryan Babel", "Melbourne's City Centre", "Lincoln Riley", "the world", "Enigma", "University of Nevada, Reno", "largest Mission Revival Style building in the United States", "Muhammad", "18", "Harlem River", "Turkey", "one dollar", "sulfur dioxide", "1913,", "Juan Martin Del Potro.", "Amsterdam, in the Netherlands, to Ankara, Turkey,", "the Lord of the Rings", "a Jaguar", "smut", "semi-autonomous organisational units"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7771978021978021}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7692307692307692, 1.0, 1.0, 0.25, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.25, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4988", "mrqa_hotpotqa-validation-2588", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-3821", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-1189", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-1429", "mrqa_hotpotqa-validation-295", "mrqa_hotpotqa-validation-1313", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-2477", "mrqa_hotpotqa-validation-2708", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-1471", "mrqa_newsqa-validation-2098", "mrqa_searchqa-validation-9281", "mrqa_naturalquestions-validation-373"], "SR": 0.6875, "CSR": 0.5649038461538461, "retrieved_ids": ["mrqa_squad-train-4225", "mrqa_squad-train-25095", "mrqa_squad-train-60967", "mrqa_squad-train-69708", "mrqa_squad-train-23122", "mrqa_squad-train-59979", "mrqa_squad-train-14486", "mrqa_squad-train-78308", "mrqa_squad-train-63546", "mrqa_squad-train-76822", "mrqa_squad-train-57652", "mrqa_squad-train-62707", "mrqa_squad-train-27819", "mrqa_squad-train-50090", "mrqa_squad-train-29729", "mrqa_squad-train-49491", "mrqa_squad-train-24058", "mrqa_squad-train-72856", "mrqa_squad-train-51925", "mrqa_squad-train-28364", "mrqa_squad-train-42795", "mrqa_squad-train-12571", "mrqa_squad-train-60704", "mrqa_squad-train-33983", "mrqa_squad-train-66450", "mrqa_squad-train-16734", "mrqa_squad-train-7867", "mrqa_squad-train-21919", "mrqa_squad-train-5915", "mrqa_squad-train-32565", "mrqa_squad-train-30413", "mrqa_squad-train-60341", "mrqa_newsqa-validation-1260", "mrqa_triviaqa-validation-1114", "mrqa_naturalquestions-validation-1435", "mrqa_searchqa-validation-327", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-1699", "mrqa_hotpotqa-validation-4002", "mrqa_newsqa-validation-3990", "mrqa_hotpotqa-validation-4441", "mrqa_searchqa-validation-12151", "mrqa_naturalquestions-validation-7225", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-5455", "mrqa_triviaqa-validation-2883", "mrqa_newsqa-validation-161", "mrqa_triviaqa-validation-5600", "mrqa_squad-validation-6108", "mrqa_newsqa-validation-1551", "mrqa_searchqa-validation-1784", "mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-5507", "mrqa_naturalquestions-validation-2334", "mrqa_searchqa-validation-4355", "mrqa_naturalquestions-validation-9087", "mrqa_naturalquestions-validation-290", "mrqa_searchqa-validation-15735", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-3108", "mrqa_squad-validation-6361", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-14266", "mrqa_triviaqa-validation-6424"], "EFR": 0.0, "Overall": 0.5489182692307693}, {"timecode": 91, "before_eval_results": {"predictions": ["Terry Reid", "investment bank Friedman Billings Ramsey", "Robber Barons", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "LED illuminated display", "Bart Howard", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds, and also in the differential", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "the brain, muscles, and liver", "USS Chesapeake", "1977", "a fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "Charles Darwin and Alfred Russel Wallace", "the inverted - drop - shaped icon that marks locations in Google Maps", "Richard Stallman", "2004", "1940", "an armed conflict without the consent of the U.S. Congress", "can affect the perception of a decision, action, idea, business, person, group, entity", "heat", "Spain", "either two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "New England Patriots", "used obscure languages as a means of secret communication during wartime", "Zhu Yuanzhang", "The 1980 Summer Olympics", "Panic! at the Disco", "dorsal root ganglion", "drizzle, rain, sleet, snow, graupel and hail", "Karen Gillan", "2017", "Julie Adams", "1881", "Music supervisor and conductor Paul Gemignani", "Psychomachia, '' an epic poem written in the fifth century", "550 quadrillion Imperial gallons", "a trustee", "Jane Addams, Grace Abbott, Edith Abbott and Sophonisba Breckinridge", "1937", "voters gathered as a tribe the members would be well known enough to each other that an outsider could be spotted", "a December 28, 1975 NFL playoff game between the Dallas Cowboys and the Minnesota Vikings,", "Payson, Lauren, and Kaylie", "2015", "Dr. Lexie Grey", "September 6, 2007", "claims adjuster ( claim adjuster ), or claims handler ( claim handler )", "Taron Egerton", "1990", "smen", "T'Pau", "Fort Nelson", "card game", "Sparta", "World Famous Gold & Silver Pawn Shop", "Darkroom", "Louis \"Louie\" Zamperini", "Former Mobile County Circuit Judge Herman Thomas", "of cardiac arrest", "\"For weeks,", "Jefferson", "Babel", "James Bond", "Ponce de Len"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5906435486891408}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, false, false, true, false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, false, false, true, true, true, true, false, false, false, true, true, false, false], "QA-F1": [0.0, 0.7499999999999999, 1.0, 0.4, 0.6666666666666666, 0.2857142857142857, 1.0, 0.0, 0.3076923076923077, 0.4, 1.0, 0.0, 0.07142857142857142, 0.5, 0.33333333333333337, 1.0, 1.0, 1.0, 0.6086956521739131, 0.08888888888888888, 0.0, 1.0, 0.21052631578947367, 1.0, 0.14814814814814817, 1.0, 1.0, 1.0, 0.6666666666666666, 0.25, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.11764705882352941, 1.0, 0.5, 0.0, 0.375, 0.4, 1.0, 1.0, 0.3333333333333333, 0.3636363636363636, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-7704", "mrqa_naturalquestions-validation-5758", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-550", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-10331", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-2652", "mrqa_naturalquestions-validation-3419", "mrqa_naturalquestions-validation-2448", "mrqa_naturalquestions-validation-9773", "mrqa_naturalquestions-validation-5154", "mrqa_naturalquestions-validation-2777", "mrqa_naturalquestions-validation-3469", "mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-5819", "mrqa_naturalquestions-validation-3187", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-7309", "mrqa_naturalquestions-validation-8161", "mrqa_triviaqa-validation-5161", "mrqa_triviaqa-validation-1101", "mrqa_newsqa-validation-3596", "mrqa_newsqa-validation-3614", "mrqa_newsqa-validation-1175", "mrqa_searchqa-validation-2818", "mrqa_searchqa-validation-5579"], "SR": 0.421875, "CSR": 0.5633491847826086, "retrieved_ids": ["mrqa_squad-train-70038", "mrqa_squad-train-84001", "mrqa_squad-train-67396", "mrqa_squad-train-79196", "mrqa_squad-train-3535", "mrqa_squad-train-18645", "mrqa_squad-train-69785", "mrqa_squad-train-2845", "mrqa_squad-train-57708", "mrqa_squad-train-1274", "mrqa_squad-train-45151", "mrqa_squad-train-21427", "mrqa_squad-train-55743", "mrqa_squad-train-16177", "mrqa_squad-train-6424", "mrqa_squad-train-73919", "mrqa_squad-train-7409", "mrqa_squad-train-66890", "mrqa_squad-train-57811", "mrqa_squad-train-42429", "mrqa_squad-train-78539", "mrqa_squad-train-53422", "mrqa_squad-train-24772", "mrqa_squad-train-11426", "mrqa_squad-train-3437", "mrqa_squad-train-25670", "mrqa_squad-train-3781", "mrqa_squad-train-2580", "mrqa_squad-train-61585", "mrqa_squad-train-73512", "mrqa_squad-train-70269", "mrqa_squad-train-36316", "mrqa_newsqa-validation-3557", "mrqa_triviaqa-validation-4313", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-7624", "mrqa_triviaqa-validation-5047", "mrqa_searchqa-validation-11651", "mrqa_searchqa-validation-15560", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-1792", "mrqa_triviaqa-validation-5923", "mrqa_hotpotqa-validation-1692", "mrqa_searchqa-validation-2499", "mrqa_newsqa-validation-2086", "mrqa_naturalquestions-validation-10707", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1643", "mrqa_searchqa-validation-12893", "mrqa_triviaqa-validation-6922", "mrqa_triviaqa-validation-6548", "mrqa_hotpotqa-validation-426", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-9001", "mrqa_naturalquestions-validation-8474", "mrqa_triviaqa-validation-5658", "mrqa_searchqa-validation-8691", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-4345", "mrqa_newsqa-validation-1444", "mrqa_searchqa-validation-5713", "mrqa_hotpotqa-validation-1991", "mrqa_newsqa-validation-3305"], "EFR": 0.0, "Overall": 0.5486073369565216}, {"timecode": 92, "before_eval_results": {"predictions": ["Miller Lite", "beetle", "the south Saskatchewan", "Carlisle", "email", "tahrir", "vivian frost", "newbury", "detention", "manhattan", "portugal", "SpongeBob", "Farthings", "china", "Maine", "Thomas Cranmer", "george w. Bush", "is a federal republic composed of 50 states,", "james Sprat", "dennis kray", "conclave", "Dublin", "Aristotelian Tragedy", "feet", "amsterdam", "John Lennon", "Lusitania", "Anne of cleves", "Australia", "antelope", "Portugal", "botswana adopted its new name after becoming independent within the Commonwealth", "Philippines", "blood", "Spain", "Marilyn Monroe", "Jupiter Mining Corporation", "dry rot", "isambard", "Canada", "british", "Jinnah International", "India", "ethelbald", "Peter Paul Rubens", "John Ford", "six", "Mendip Hills", "Burma", "charlie taylor", "pancho Villa", "used in a compact layout to combine keys which are usually kept separate", "Jerry Leiber and Mike Stoller", "the third season", "Karl Johan Schuster", "Worcester", "Brown Mountain Overlook", "Lucky Dube,", "social media networks like Facebook, YouTube and Twitter,", "Michael Partain,", "Beauty and the Beast", "Luxembourg", "Hammurabi", "leucotomy"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5905982905982906}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, false], "QA-F1": [0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.1111111111111111, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-896", "mrqa_triviaqa-validation-90", "mrqa_triviaqa-validation-4916", "mrqa_triviaqa-validation-6053", "mrqa_triviaqa-validation-3295", "mrqa_triviaqa-validation-4823", "mrqa_triviaqa-validation-5356", "mrqa_triviaqa-validation-7272", "mrqa_triviaqa-validation-2729", "mrqa_triviaqa-validation-7276", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-572", "mrqa_triviaqa-validation-448", "mrqa_triviaqa-validation-1000", "mrqa_triviaqa-validation-3952", "mrqa_triviaqa-validation-3217", "mrqa_triviaqa-validation-413", "mrqa_triviaqa-validation-2071", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-5919", "mrqa_triviaqa-validation-6872", "mrqa_triviaqa-validation-2328", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-7264", "mrqa_hotpotqa-validation-2017", "mrqa_hotpotqa-validation-295", "mrqa_hotpotqa-validation-4122", "mrqa_newsqa-validation-4082", "mrqa_searchqa-validation-16895"], "SR": 0.515625, "CSR": 0.5628360215053764, "retrieved_ids": ["mrqa_squad-train-7727", "mrqa_squad-train-68720", "mrqa_squad-train-43949", "mrqa_squad-train-72523", "mrqa_squad-train-86332", "mrqa_squad-train-6141", "mrqa_squad-train-85902", "mrqa_squad-train-60617", "mrqa_squad-train-30966", "mrqa_squad-train-35712", "mrqa_squad-train-69837", "mrqa_squad-train-51491", "mrqa_squad-train-76403", "mrqa_squad-train-41023", "mrqa_squad-train-86090", "mrqa_squad-train-82685", "mrqa_squad-train-23387", "mrqa_squad-train-22723", "mrqa_squad-train-31793", "mrqa_squad-train-26024", "mrqa_squad-train-78641", "mrqa_squad-train-37067", "mrqa_squad-train-46281", "mrqa_squad-train-18055", "mrqa_squad-train-49022", "mrqa_squad-train-69772", "mrqa_squad-train-53945", "mrqa_squad-train-33483", "mrqa_squad-train-74589", "mrqa_squad-train-80281", "mrqa_squad-train-5146", "mrqa_squad-train-73056", "mrqa_triviaqa-validation-6024", "mrqa_triviaqa-validation-5595", "mrqa_triviaqa-validation-3263", "mrqa_searchqa-validation-13235", "mrqa_hotpotqa-validation-4763", "mrqa_naturalquestions-validation-2572", "mrqa_triviaqa-validation-2177", "mrqa_triviaqa-validation-6807", "mrqa_naturalquestions-validation-2894", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-2981", "mrqa_newsqa-validation-784", "mrqa_triviaqa-validation-4568", "mrqa_naturalquestions-validation-8161", "mrqa_naturalquestions-validation-5001", "mrqa_hotpotqa-validation-1865", "mrqa_hotpotqa-validation-1161", "mrqa_hotpotqa-validation-5455", "mrqa_triviaqa-validation-5296", "mrqa_newsqa-validation-2213", "mrqa_squad-validation-2337", "mrqa_naturalquestions-validation-9723", "mrqa_hotpotqa-validation-1372", "mrqa_hotpotqa-validation-2237", "mrqa_newsqa-validation-875", "mrqa_triviaqa-validation-331", "mrqa_triviaqa-validation-2192", "mrqa_triviaqa-validation-7523", "mrqa_squad-validation-7083", "mrqa_triviaqa-validation-3086", "mrqa_searchqa-validation-9928", "mrqa_hotpotqa-validation-3180"], "EFR": 0.0, "Overall": 0.5485047043010753}, {"timecode": 93, "before_eval_results": {"predictions": ["Peoria, Illinois", "Senator of the College of Justice", "1776", "Meghan Markle", "U.S. Bancorp", "Justin Adler", "BBC Formula One", "Coahuila, Mexico", "Atomic Kitten", "Ephedrine", "Colin Vaines", "Virginia", "racehorse breeder and owner", "Jim Kelly", "Australian", "the D\u00e2mbovi\u021ba River", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "Miracle", "Erich Maria Remarque", "Scott Mosier", "A Scholar Under Siege", "Dutch", "1999", "Mudvayne", "1947", "Easter Rising of 1916", "January 24, 2012", "General Sir John Monash", "\u00c6thelstan", "Middlesbrough F.C.", "can play as a striker or left winger", "5,112", "Jefferson Memorial", "May 1, 2011", "four", "Red and Assiniboine Rivers", "200", "15", "February 18, 1965", "future AC/DC founders Angus Young and Malcolm Young", "Goddess of Pop", "125 lb (57 kg)", "chocolate-colored", "1966", "March 14, 2000", "1927", "Gregg Popovich", "Princess Anne", "Neighbours", "Hall & Oates", "February 12, 2014", "northwest Washington", "1830", "Lake Powell", "cranes", "chariots", "Louisiana", "a \"stressed and tired force\" made vulnerable by multiple deployments,", "Citizens are picking members of the lower house of parliament,", "Tuesday", "The African Queen", "a cat", "Gibraltar", "Pure water is neutral, at pH 7 ( 25 \u00b0 C ), being neither an acid nor a base"], "metric_results": {"EM": 0.625, "QA-F1": 0.7140151515151516}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, false], "QA-F1": [0.0, 0.3636363636363636, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-694", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-347", "mrqa_hotpotqa-validation-5608", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-2577", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-3152", "mrqa_hotpotqa-validation-2728", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1077", "mrqa_hotpotqa-validation-1527", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2066", "mrqa_naturalquestions-validation-8652"], "SR": 0.625, "CSR": 0.5634973404255319, "retrieved_ids": ["mrqa_squad-train-27530", "mrqa_squad-train-59333", "mrqa_squad-train-78940", "mrqa_squad-train-25299", "mrqa_squad-train-3595", "mrqa_squad-train-65389", "mrqa_squad-train-71022", "mrqa_squad-train-57786", "mrqa_squad-train-28889", "mrqa_squad-train-35511", "mrqa_squad-train-4785", "mrqa_squad-train-16004", "mrqa_squad-train-78576", "mrqa_squad-train-11951", "mrqa_squad-train-40084", "mrqa_squad-train-48906", "mrqa_squad-train-21058", "mrqa_squad-train-3775", "mrqa_squad-train-64082", "mrqa_squad-train-86300", "mrqa_squad-train-11694", "mrqa_squad-train-5278", "mrqa_squad-train-57302", "mrqa_squad-train-47073", "mrqa_squad-train-42914", "mrqa_squad-train-29992", "mrqa_squad-train-58091", "mrqa_squad-train-4603", "mrqa_squad-train-44963", "mrqa_squad-train-45592", "mrqa_squad-train-78083", "mrqa_squad-train-58565", "mrqa_triviaqa-validation-4792", "mrqa_naturalquestions-validation-2837", "mrqa_newsqa-validation-1664", "mrqa_squad-validation-4019", "mrqa_triviaqa-validation-6872", "mrqa_naturalquestions-validation-7017", "mrqa_naturalquestions-validation-1719", "mrqa_hotpotqa-validation-4002", "mrqa_triviaqa-validation-6053", "mrqa_newsqa-validation-276", "mrqa_triviaqa-validation-4097", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-3419", "mrqa_hotpotqa-validation-534", "mrqa_triviaqa-validation-5993", "mrqa_triviaqa-validation-5009", "mrqa_searchqa-validation-7739", "mrqa_searchqa-validation-2162", "mrqa_naturalquestions-validation-5665", "mrqa_searchqa-validation-2248", "mrqa_newsqa-validation-3435", "mrqa_searchqa-validation-3318", "mrqa_newsqa-validation-1661", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-4568", "mrqa_newsqa-validation-2493", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-1421", "mrqa_searchqa-validation-4068", "mrqa_naturalquestions-validation-5460", "mrqa_hotpotqa-validation-850", "mrqa_searchqa-validation-4038"], "EFR": 0.0, "Overall": 0.5486369680851064}, {"timecode": 94, "before_eval_results": {"predictions": ["Aston Villa", "Guinea", "Mayflower", "four", "daily Mail Online", "the tartan", "Toy Story", "GM koreans", "lungs", "Periodic Table", "left book club", "argentina", "Columba", "Donald Sutherland", "capital of edinburgh", "Ethiopia", "Cardiff", "sternum", "pressure", "james", "germany", "a fluid", "bach", "squeeze", "Altamont Speedway Free Festival", "Robert Plant", "Jerry Seinfeld", "stern tube", "korea", "lemurs", "Sir Robert Walpole", "eight", "Andorra", "horse collar", "albion", "kunsky", "st Paul's Cathedral", "27", "Formula One", "squash", "macey connica", "Godwin Austen", "france", "Birdman of Alcatraz", "Bernardo Bertolucci", "Christopher Columbus", "the buck", "Godiva", "henry ford", "feet", "a dress", "1940s", "7.6 mm", "a hydrolysis reaction", "Neymar", "Parliamentarians (\" roundsheads\") and Royalists (\"Cavaliers\")", "5.3 million", "6-4", "al Qaeda", "UNICEF", "a B movie", "Florence", "Saturn", "the global village"], "metric_results": {"EM": 0.625, "QA-F1": 0.6661458333333333}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, true, true, true, true, false], "QA-F1": [0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8000000000000002, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-5663", "mrqa_triviaqa-validation-5528", "mrqa_triviaqa-validation-2197", "mrqa_triviaqa-validation-7026", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-2708", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-6804", "mrqa_triviaqa-validation-5559", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-1058", "mrqa_triviaqa-validation-7303", "mrqa_triviaqa-validation-4356", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-2214", "mrqa_triviaqa-validation-3908", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-7226", "mrqa_hotpotqa-validation-2959", "mrqa_newsqa-validation-3796", "mrqa_searchqa-validation-11091"], "SR": 0.625, "CSR": 0.5641447368421053, "retrieved_ids": ["mrqa_squad-train-19839", "mrqa_squad-train-86221", "mrqa_squad-train-24374", "mrqa_squad-train-71714", "mrqa_squad-train-77781", "mrqa_squad-train-63105", "mrqa_squad-train-80296", "mrqa_squad-train-81088", "mrqa_squad-train-59016", "mrqa_squad-train-31186", "mrqa_squad-train-58578", "mrqa_squad-train-84194", "mrqa_squad-train-62326", "mrqa_squad-train-49876", "mrqa_squad-train-82085", "mrqa_squad-train-9499", "mrqa_squad-train-34243", "mrqa_squad-train-71919", "mrqa_squad-train-56698", "mrqa_squad-train-25157", "mrqa_squad-train-30348", "mrqa_squad-train-60392", "mrqa_squad-train-23645", "mrqa_squad-train-49890", "mrqa_squad-train-21223", "mrqa_squad-train-47009", "mrqa_squad-train-69039", "mrqa_squad-train-33698", "mrqa_squad-train-71259", "mrqa_squad-train-48853", "mrqa_squad-train-10768", "mrqa_squad-train-52241", "mrqa_triviaqa-validation-1076", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-2024", "mrqa_newsqa-validation-1444", "mrqa_hotpotqa-validation-5735", "mrqa_triviaqa-validation-1916", "mrqa_newsqa-validation-1928", "mrqa_naturalquestions-validation-3186", "mrqa_hotpotqa-validation-5810", "mrqa_squad-validation-3930", "mrqa_newsqa-validation-3101", "mrqa_hotpotqa-validation-4433", "mrqa_naturalquestions-validation-8951", "mrqa_searchqa-validation-9551", "mrqa_naturalquestions-validation-4974", "mrqa_hotpotqa-validation-1416", "mrqa_triviaqa-validation-3622", "mrqa_searchqa-validation-12390", "mrqa_triviaqa-validation-2551", "mrqa_triviaqa-validation-5810", "mrqa_newsqa-validation-3687", "mrqa_triviaqa-validation-2578", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-6886", "mrqa_hotpotqa-validation-4038", "mrqa_naturalquestions-validation-6190", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-16889", "mrqa_searchqa-validation-9559", "mrqa_searchqa-validation-3303", "mrqa_squad-validation-2506"], "EFR": 0.0, "Overall": 0.5487664473684211}, {"timecode": 95, "before_eval_results": {"predictions": ["pilot and aviation", "air-cushioned sole", "local South Australian and Australian produced content", "Oryzomyini", "Eric Edward Whitacre", "2010", "Statutory List of Buildings of Special Architectural or Historic Interest", "pubs, bars and restaurants", "2004", "Van Diemen's Land", "Jim Kelly", "Stern-Plaza", "Edward James Olmos", "Girls' Generation", "1st round", "two or three acts", "Dra\u017een Petrovi\u0107", "Prussia", "David Wells", "the north bank of the North Esk", "two", "Argentine cuisine", "13th century", "Prudence Jane Goward", "Manchester United and the England national team", "Matt Groening", "Hazel Keech", "Minami-Tori-shima", "1993", "Jesus", "Sulla", "Riot Act", "Steve and Rudy", "right-hand", "black nationalism", "Futurama", "FC Bayern Munich", "Deftones", "\"Gangsta's Paradise\"", "Clitheroe Football Club", "Green Lantern", "Cleopatra", "The Fault in Our Stars", "Liesl", "How the Grinch Stole Christmas", "twin-faced sheepskin with fleece on the inside", "White Horse", "Albert Bridge, London", "Flavivirus", "Elise Marie Stefanik", "Francis Schaeffer", "off the northeast coast of Australia", "between 3.9 and 5.5 glucose / L ( 70 to 100 mg / dL )", "Speaker of the House of Representatives", "plaketon", "capture of Quebec", "cold comfort Farm", "red", "lightning strikes", "murders of his father and brother.", "a sheep", "Southern Christian Leadership Conference", "Berlin", "the brain and spinal cord"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6959483225108225}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false], "QA-F1": [0.0, 0.2666666666666667, 0.25, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.8, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.8571428571428572, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-1917", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2252", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-5178", "mrqa_hotpotqa-validation-1250", "mrqa_hotpotqa-validation-4210", "mrqa_hotpotqa-validation-1745", "mrqa_naturalquestions-validation-4710", "mrqa_naturalquestions-validation-9076", "mrqa_naturalquestions-validation-8982", "mrqa_triviaqa-validation-4415", "mrqa_triviaqa-validation-4334", "mrqa_newsqa-validation-2382", "mrqa_searchqa-validation-1780", "mrqa_naturalquestions-validation-7342"], "SR": 0.59375, "CSR": 0.564453125, "retrieved_ids": ["mrqa_squad-train-60769", "mrqa_squad-train-68970", "mrqa_squad-train-59698", "mrqa_squad-train-1794", "mrqa_squad-train-11724", "mrqa_squad-train-5731", "mrqa_squad-train-33126", "mrqa_squad-train-30827", "mrqa_squad-train-6764", "mrqa_squad-train-23497", "mrqa_squad-train-53995", "mrqa_squad-train-20834", "mrqa_squad-train-23866", "mrqa_squad-train-24329", "mrqa_squad-train-41160", "mrqa_squad-train-45820", "mrqa_squad-train-6003", "mrqa_squad-train-8645", "mrqa_squad-train-37170", "mrqa_squad-train-11179", "mrqa_squad-train-21098", "mrqa_squad-train-41259", "mrqa_squad-train-16187", "mrqa_squad-train-61206", "mrqa_squad-train-76148", "mrqa_squad-train-57274", "mrqa_squad-train-59725", "mrqa_squad-train-27798", "mrqa_squad-train-46140", "mrqa_squad-train-43625", "mrqa_squad-train-32541", "mrqa_squad-train-308", "mrqa_naturalquestions-validation-6435", "mrqa_triviaqa-validation-4584", "mrqa_hotpotqa-validation-3787", "mrqa_hotpotqa-validation-4284", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2480", "mrqa_naturalquestions-validation-10495", "mrqa_hotpotqa-validation-2080", "mrqa_naturalquestions-validation-2448", "mrqa_searchqa-validation-10027", "mrqa_searchqa-validation-9123", "mrqa_triviaqa-validation-2578", "mrqa_naturalquestions-validation-3048", "mrqa_newsqa-validation-1899", "mrqa_hotpotqa-validation-2257", "mrqa_newsqa-validation-140", "mrqa_searchqa-validation-15560", "mrqa_searchqa-validation-2103", "mrqa_hotpotqa-validation-4662", "mrqa_searchqa-validation-4509", "mrqa_searchqa-validation-1911", "mrqa_searchqa-validation-1423", "mrqa_triviaqa-validation-6922", "mrqa_searchqa-validation-2090", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-3942", "mrqa_triviaqa-validation-1759", "mrqa_triviaqa-validation-5499", "mrqa_squad-validation-4631", "mrqa_searchqa-validation-8030", "mrqa_triviaqa-validation-2411", "mrqa_hotpotqa-validation-2728"], "EFR": 0.0, "Overall": 0.548828125}, {"timecode": 96, "before_eval_results": {"predictions": ["Agra Cantonment - H. Nizamuddin Gatimaan Express", "year of the conception or birth of Jesus of Nazareth", "1987", "The current House of Representatives, formed following elections held in April 2015, has a total of 360 members who are elected in single - member constituencies using the simple majority ( or first - past - the - post ) system", "Pradyumna", "Carol Ann Susi", "the pyloric valve", "Ben Fransham", "Ephesus", "Mark Lowry", "Phillip Paley", "Germany", "Einstein", "1830", "positions 14 - 15, 146 - 147 and 148 - 149", "100", "James Madison", "Woodrow Strode", "Baaghi ( English : Rebel )", "Taylor Michel Momsen", "Panning", "31 March 1909", "$66.5 million", "pathology", "April 3, 1973", "corneum", "her abusive husband", "United Nations", "a recognized group of people who jointly oversee the activities of an organization", "pigs", "a take - it - or - leave - it contract, or a boilerplate contract", "16th century", "Phillipa Soo", "Brooks & Dunn", "May 31, 2012", "1,228 km / h ( 763 mph )", "October 27, 2017", "Kida", "~ 55 - 75 micrometers", "Miller's early production totals of 12.8 million barrels quickly increased to 24.2 million barrels by 1977", "Oona Castilla Chaplin", "the seven stages of a man's life, sometimes referred to as the seven ages of man : infant, schoolboy, lover, soldier, justice, Pantalone and old age", "Lulu", "the NFL", "Steve Russell", "thirteen British colonies that declared independence from the Kingdom of Great Britain, and became the first states in the U.S.", "Profit maximization", "Melbourne", "April 1, 2016", "Alamodome and city of San Antonio", "1,281,900", "m Phelps", "royal oak", "klankies", "France", "Province of Syracuse", "June 11, 1986", "1-0", "200", "Republican Gov. Bobby", "\"reshit\"", "John Deere", "gusts", "a curfew"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7410603062398398}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true, true, true], "QA-F1": [0.1818181818181818, 1.0, 0.0, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.326530612244898, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.06896551724137931, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.18181818181818182, 0.5, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3416", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-10550", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-4432", "mrqa_naturalquestions-validation-3112", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-3970", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-4953", "mrqa_triviaqa-validation-800", "mrqa_triviaqa-validation-7411", "mrqa_hotpotqa-validation-3107", "mrqa_newsqa-validation-340", "mrqa_newsqa-validation-2327", "mrqa_searchqa-validation-16252"], "SR": 0.6875, "CSR": 0.5657216494845361, "retrieved_ids": ["mrqa_squad-train-4017", "mrqa_squad-train-13375", "mrqa_squad-train-19754", "mrqa_squad-train-23621", "mrqa_squad-train-82079", "mrqa_squad-train-14160", "mrqa_squad-train-26484", "mrqa_squad-train-46722", "mrqa_squad-train-33818", "mrqa_squad-train-6326", "mrqa_squad-train-78722", "mrqa_squad-train-20240", "mrqa_squad-train-64905", "mrqa_squad-train-57031", "mrqa_squad-train-37198", "mrqa_squad-train-56889", "mrqa_squad-train-71419", "mrqa_squad-train-57139", "mrqa_squad-train-42527", "mrqa_squad-train-82348", "mrqa_squad-train-84894", "mrqa_squad-train-85827", "mrqa_squad-train-19403", "mrqa_squad-train-79672", "mrqa_squad-train-16800", "mrqa_squad-train-79902", "mrqa_squad-train-78968", "mrqa_squad-train-54409", "mrqa_squad-train-61045", "mrqa_squad-train-16933", "mrqa_squad-train-83114", "mrqa_squad-train-5802", "mrqa_newsqa-validation-1548", "mrqa_naturalquestions-validation-458", "mrqa_triviaqa-validation-4536", "mrqa_naturalquestions-validation-10238", "mrqa_searchqa-validation-7074", "mrqa_naturalquestions-validation-259", "mrqa_searchqa-validation-3703", "mrqa_triviaqa-validation-4573", "mrqa_newsqa-validation-3856", "mrqa_triviaqa-validation-7706", "mrqa_hotpotqa-validation-5521", "mrqa_triviaqa-validation-672", "mrqa_searchqa-validation-8804", "mrqa_hotpotqa-validation-1011", "mrqa_hotpotqa-validation-5394", "mrqa_hotpotqa-validation-2870", "mrqa_searchqa-validation-5528", "mrqa_triviaqa-validation-4317", "mrqa_hotpotqa-validation-5251", "mrqa_naturalquestions-validation-9871", "mrqa_searchqa-validation-8010", "mrqa_triviaqa-validation-7276", "mrqa_newsqa-validation-591", "mrqa_naturalquestions-validation-5758", "mrqa_newsqa-validation-2790", "mrqa_triviaqa-validation-7460", "mrqa_squad-validation-3373", "mrqa_naturalquestions-validation-8483", "mrqa_searchqa-validation-11661", "mrqa_naturalquestions-validation-3802", "mrqa_searchqa-validation-4506", "mrqa_naturalquestions-validation-1782"], "EFR": 0.0, "Overall": 0.5490818298969072}, {"timecode": 97, "before_eval_results": {"predictions": ["Tchaikovsky", "dark", "Candies", "the boll weevil", "a drop-down list", "Wikipedia", "Butch", "Buddhism", "Mozart", "Jonathan Swift", "lily", "ice cream", "Algeria", "Charles Dickens", "(Sergey) Brin", "Democrat Joe Lieberman", "American alternative rock band", "bread", "Yale", "Napoleon", "Paris", "the Black Forest", "Polarbears", "an ant", "Birkenstock", "Firebird", "Hafnium", "flax", "the Muse", "the Wachowski brothers", "Horace Rumpole", "Bush", "Steve Austin", "Kurt Warner", "zero", "a shop that specializes in gifts, fashionable clothes, accessories, or food", "the Beast", "Ratatouille", "pro bono", "Ben", "The Office", "All Groups", "Bigfoot", "Jackson Pollock", "glow", "Mona Lisa", "vietnam", "Crayola", "The Man in the Gray Flannel Suit", "Assimilation", "orange", "Isaiah Amir Mustafa", "1999", "Americans acting under orders", "mike hammer", "\"The Crow\"", "l. p. Hartley", "Tifinagh", "European Champion Clubs' Cup", "second largest", "North Korea", "Alcohol", "relax the smooth muscle in the gut and relieve cramping", "Prada"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6935461956521739}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, false, false, true, true, false, true, false, true], "QA-F1": [0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.08695652173913045, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6269", "mrqa_searchqa-validation-8394", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-12226", "mrqa_searchqa-validation-3811", "mrqa_searchqa-validation-10417", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-8538", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-10545", "mrqa_searchqa-validation-9435", "mrqa_searchqa-validation-8764", "mrqa_searchqa-validation-16354", "mrqa_searchqa-validation-7743", "mrqa_searchqa-validation-8775", "mrqa_searchqa-validation-3405", "mrqa_searchqa-validation-11006", "mrqa_searchqa-validation-13416", "mrqa_searchqa-validation-16144", "mrqa_searchqa-validation-4924", "mrqa_naturalquestions-validation-8759", "mrqa_triviaqa-validation-6442", "mrqa_hotpotqa-validation-3553", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-96"], "SR": 0.59375, "CSR": 0.5660076530612245, "retrieved_ids": ["mrqa_squad-train-63515", "mrqa_squad-train-28183", "mrqa_squad-train-84128", "mrqa_squad-train-69524", "mrqa_squad-train-26504", "mrqa_squad-train-15554", "mrqa_squad-train-2014", "mrqa_squad-train-33828", "mrqa_squad-train-53339", "mrqa_squad-train-78166", "mrqa_squad-train-71105", "mrqa_squad-train-74226", "mrqa_squad-train-71768", "mrqa_squad-train-76075", "mrqa_squad-train-54429", "mrqa_squad-train-35891", "mrqa_squad-train-31081", "mrqa_squad-train-9667", "mrqa_squad-train-63105", "mrqa_squad-train-71506", "mrqa_squad-train-38558", "mrqa_squad-train-17610", "mrqa_squad-train-31591", "mrqa_squad-train-69596", "mrqa_squad-train-70295", "mrqa_squad-train-62304", "mrqa_squad-train-68525", "mrqa_squad-train-67144", "mrqa_squad-train-42165", "mrqa_squad-train-11091", "mrqa_squad-train-32817", "mrqa_squad-train-9867", "mrqa_searchqa-validation-8632", "mrqa_triviaqa-validation-6922", "mrqa_searchqa-validation-7828", "mrqa_hotpotqa-validation-2213", "mrqa_newsqa-validation-2227", "mrqa_hotpotqa-validation-4122", "mrqa_hotpotqa-validation-4487", "mrqa_naturalquestions-validation-4427", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-1698", "mrqa_naturalquestions-validation-5017", "mrqa_newsqa-validation-1806", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-746", "mrqa_triviaqa-validation-3101", "mrqa_searchqa-validation-12243", "mrqa_hotpotqa-validation-2559", "mrqa_naturalquestions-validation-1038", "mrqa_triviaqa-validation-2777", "mrqa_triviaqa-validation-7133", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-3753", "mrqa_naturalquestions-validation-5580", "mrqa_naturalquestions-validation-7393", "mrqa_hotpotqa-validation-1577", "mrqa_triviaqa-validation-7118", "mrqa_naturalquestions-validation-4148", "mrqa_hotpotqa-validation-5140", "mrqa_squad-validation-5303", "mrqa_searchqa-validation-3286", "mrqa_newsqa-validation-466", "mrqa_newsqa-validation-591"], "EFR": 0.0, "Overall": 0.5491390306122449}, {"timecode": 98, "before_eval_results": {"predictions": ["Florence", "Pierre Trudeau", "grapefruit", "a dock", "Millard", "cornea", "lemonade", "Horace Rumpole", "croissant", "the light bulb", "Spider-Man", "Atlanta", "China", "Dick Tracy", "Latifah", "Van Allen", "beer", "Zen", "Asherah", "zenith", "baboon", "wine", "The Sopranos", "\"Baby Gays\"", "natural selection", "Massachusetts", "Battle of the Bulge", "an axle", "W. Somerset Maugham", "the Two Sicilies", "Trafalgar", "a constitution", "Sir Francis Drake", "the college of Charles", "Enrico Fermi", "Candy Crush", "the pituitary gland", "Alfred Hitchcock", "Hank Aaron", "reconnaissance", "Florida", "ectoplasm", "Thomas Jefferson", "Mercury", "Dante", "Columbus", "Joseph Haydn", "meringue", "Babe Zaharias", "the FBI", "kidney stones", "four", "William Whewell", "961", "wollem de zwijger", "food", "mMary seacole", "Orchard Central", "Fort Hood, Texas", "OutKast", "iPods", "suspend all", "Wednesday", "Nick Sager"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7276041666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3729", "mrqa_searchqa-validation-16354", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-14387", "mrqa_searchqa-validation-14517", "mrqa_searchqa-validation-16225", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-319", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-3993", "mrqa_searchqa-validation-4192", "mrqa_searchqa-validation-15328", "mrqa_searchqa-validation-6181", "mrqa_searchqa-validation-1366", "mrqa_searchqa-validation-5926", "mrqa_searchqa-validation-1848", "mrqa_searchqa-validation-221", "mrqa_searchqa-validation-9945", "mrqa_searchqa-validation-5756", "mrqa_naturalquestions-validation-307", "mrqa_triviaqa-validation-3273", "mrqa_triviaqa-validation-7667", "mrqa_triviaqa-validation-1611", "mrqa_hotpotqa-validation-2679", "mrqa_newsqa-validation-2040"], "SR": 0.609375, "CSR": 0.5664457070707071, "retrieved_ids": ["mrqa_squad-train-68242", "mrqa_squad-train-34241", "mrqa_squad-train-37456", "mrqa_squad-train-23902", "mrqa_squad-train-50535", "mrqa_squad-train-76744", "mrqa_squad-train-61757", "mrqa_squad-train-12698", "mrqa_squad-train-27753", "mrqa_squad-train-16186", "mrqa_squad-train-13971", "mrqa_squad-train-32282", "mrqa_squad-train-26099", "mrqa_squad-train-53755", "mrqa_squad-train-85518", "mrqa_squad-train-68141", "mrqa_squad-train-60089", "mrqa_squad-train-79069", "mrqa_squad-train-58528", "mrqa_squad-train-49320", "mrqa_squad-train-79505", "mrqa_squad-train-50000", "mrqa_squad-train-72279", "mrqa_squad-train-63268", "mrqa_squad-train-53368", "mrqa_squad-train-68492", "mrqa_squad-train-66942", "mrqa_squad-train-15185", "mrqa_squad-train-47021", "mrqa_squad-train-63613", "mrqa_squad-train-77587", "mrqa_squad-train-70276", "mrqa_searchqa-validation-2457", "mrqa_newsqa-validation-923", "mrqa_triviaqa-validation-7079", "mrqa_naturalquestions-validation-10218", "mrqa_newsqa-validation-960", "mrqa_hotpotqa-validation-2047", "mrqa_hotpotqa-validation-4433", "mrqa_naturalquestions-validation-9316", "mrqa_newsqa-validation-889", "mrqa_triviaqa-validation-2567", "mrqa_searchqa-validation-60", "mrqa_hotpotqa-validation-108", "mrqa_newsqa-validation-3687", "mrqa_squad-validation-10386", "mrqa_newsqa-validation-2939", "mrqa_searchqa-validation-10161", "mrqa_searchqa-validation-717", "mrqa_hotpotqa-validation-76", "mrqa_triviaqa-validation-4887", "mrqa_newsqa-validation-2621", "mrqa_squad-validation-2098", "mrqa_naturalquestions-validation-6069", "mrqa_hotpotqa-validation-4751", "mrqa_triviaqa-validation-5439", "mrqa_newsqa-validation-591", "mrqa_triviaqa-validation-1961", "mrqa_searchqa-validation-9559", "mrqa_naturalquestions-validation-4148", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-2511", "mrqa_triviaqa-validation-6113", "mrqa_searchqa-validation-10986"], "EFR": 0.0, "Overall": 0.5492266414141415}, {"timecode": 99, "UKR": 0.798828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1052", "mrqa_hotpotqa-validation-1088", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-1247", "mrqa_hotpotqa-validation-1268", "mrqa_hotpotqa-validation-1292", "mrqa_hotpotqa-validation-13", "mrqa_hotpotqa-validation-1301", "mrqa_hotpotqa-validation-1473", "mrqa_hotpotqa-validation-1490", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-1544", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1653", "mrqa_hotpotqa-validation-1691", "mrqa_hotpotqa-validation-1736", "mrqa_hotpotqa-validation-181", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-189", "mrqa_hotpotqa-validation-1986", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-2111", "mrqa_hotpotqa-validation-2113", "mrqa_hotpotqa-validation-2126", "mrqa_hotpotqa-validation-2212", "mrqa_hotpotqa-validation-2241", "mrqa_hotpotqa-validation-228", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-2342", "mrqa_hotpotqa-validation-2378", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-2469", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2496", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2590", "mrqa_hotpotqa-validation-2604", "mrqa_hotpotqa-validation-2873", "mrqa_hotpotqa-validation-2892", "mrqa_hotpotqa-validation-2903", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-2952", "mrqa_hotpotqa-validation-2984", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3175", "mrqa_hotpotqa-validation-3245", "mrqa_hotpotqa-validation-3323", "mrqa_hotpotqa-validation-3334", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3374", "mrqa_hotpotqa-validation-3428", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-3777", "mrqa_hotpotqa-validation-3780", "mrqa_hotpotqa-validation-3793", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-393", "mrqa_hotpotqa-validation-3934", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-4038", "mrqa_hotpotqa-validation-4076", "mrqa_hotpotqa-validation-4123", "mrqa_hotpotqa-validation-4236", "mrqa_hotpotqa-validation-4249", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-4356", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4484", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-4500", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-4632", "mrqa_hotpotqa-validation-4658", "mrqa_hotpotqa-validation-4708", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4818", "mrqa_hotpotqa-validation-4841", "mrqa_hotpotqa-validation-4855", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-494", "mrqa_hotpotqa-validation-5172", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5323", "mrqa_hotpotqa-validation-5358", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-542", "mrqa_hotpotqa-validation-5427", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5632", "mrqa_hotpotqa-validation-5666", "mrqa_hotpotqa-validation-5719", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-5835", "mrqa_hotpotqa-validation-5864", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-66", "mrqa_hotpotqa-validation-727", "mrqa_hotpotqa-validation-76", "mrqa_hotpotqa-validation-884", "mrqa_hotpotqa-validation-916", "mrqa_hotpotqa-validation-975", "mrqa_naturalquestions-validation-10114", "mrqa_naturalquestions-validation-10159", "mrqa_naturalquestions-validation-10417", "mrqa_naturalquestions-validation-10493", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-1797", "mrqa_naturalquestions-validation-1824", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-1920", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-214", "mrqa_naturalquestions-validation-2379", "mrqa_naturalquestions-validation-2515", "mrqa_naturalquestions-validation-2544", "mrqa_naturalquestions-validation-2620", "mrqa_naturalquestions-validation-2851", "mrqa_naturalquestions-validation-289", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-2971", "mrqa_naturalquestions-validation-3186", "mrqa_naturalquestions-validation-3205", "mrqa_naturalquestions-validation-3425", "mrqa_naturalquestions-validation-3569", "mrqa_naturalquestions-validation-3589", "mrqa_naturalquestions-validation-3627", "mrqa_naturalquestions-validation-3692", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-3958", "mrqa_naturalquestions-validation-4073", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4307", "mrqa_naturalquestions-validation-4319", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-4433", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4563", "mrqa_naturalquestions-validation-4740", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5053", "mrqa_naturalquestions-validation-5072", "mrqa_naturalquestions-validation-5199", "mrqa_naturalquestions-validation-5331", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-5425", "mrqa_naturalquestions-validation-550", "mrqa_naturalquestions-validation-5503", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5516", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5798", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-6019", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6069", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-6353", "mrqa_naturalquestions-validation-683", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7097", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7438", "mrqa_naturalquestions-validation-749", "mrqa_naturalquestions-validation-757", "mrqa_naturalquestions-validation-7595", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-7806", "mrqa_naturalquestions-validation-7849", "mrqa_naturalquestions-validation-7892", "mrqa_naturalquestions-validation-8633", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-9078", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-9608", "mrqa_naturalquestions-validation-9652", "mrqa_naturalquestions-validation-9871", "mrqa_naturalquestions-validation-9878", "mrqa_newsqa-validation-1013", "mrqa_newsqa-validation-1105", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-1129", "mrqa_newsqa-validation-1183", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-1365", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-1714", "mrqa_newsqa-validation-175", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-183", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2002", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-2494", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-2856", "mrqa_newsqa-validation-2861", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2899", "mrqa_newsqa-validation-2992", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-310", "mrqa_newsqa-validation-3179", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-3520", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3596", "mrqa_newsqa-validation-3639", "mrqa_newsqa-validation-3715", "mrqa_newsqa-validation-3780", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3992", "mrqa_newsqa-validation-406", "mrqa_newsqa-validation-4060", "mrqa_newsqa-validation-454", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-61", "mrqa_newsqa-validation-698", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-895", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-10330", "mrqa_searchqa-validation-10597", "mrqa_searchqa-validation-10616", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-11247", "mrqa_searchqa-validation-11294", "mrqa_searchqa-validation-11861", "mrqa_searchqa-validation-11898", "mrqa_searchqa-validation-1196", "mrqa_searchqa-validation-12085", "mrqa_searchqa-validation-12127", "mrqa_searchqa-validation-12151", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-12360", "mrqa_searchqa-validation-12402", "mrqa_searchqa-validation-12782", "mrqa_searchqa-validation-1290", "mrqa_searchqa-validation-12976", "mrqa_searchqa-validation-13014", "mrqa_searchqa-validation-13765", "mrqa_searchqa-validation-13789", "mrqa_searchqa-validation-13803", "mrqa_searchqa-validation-14285", "mrqa_searchqa-validation-14307", "mrqa_searchqa-validation-14387", "mrqa_searchqa-validation-14471", "mrqa_searchqa-validation-1497", "mrqa_searchqa-validation-15064", "mrqa_searchqa-validation-152", "mrqa_searchqa-validation-1564", "mrqa_searchqa-validation-15716", "mrqa_searchqa-validation-15725", "mrqa_searchqa-validation-16016", "mrqa_searchqa-validation-16162", "mrqa_searchqa-validation-16311", "mrqa_searchqa-validation-16354", "mrqa_searchqa-validation-16865", "mrqa_searchqa-validation-16895", "mrqa_searchqa-validation-16910", "mrqa_searchqa-validation-1829", "mrqa_searchqa-validation-191", "mrqa_searchqa-validation-1950", "mrqa_searchqa-validation-2189", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-2591", "mrqa_searchqa-validation-2673", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-2898", "mrqa_searchqa-validation-2943", "mrqa_searchqa-validation-3081", "mrqa_searchqa-validation-324", "mrqa_searchqa-validation-327", "mrqa_searchqa-validation-3303", "mrqa_searchqa-validation-3381", "mrqa_searchqa-validation-3405", "mrqa_searchqa-validation-3455", "mrqa_searchqa-validation-3565", "mrqa_searchqa-validation-3618", "mrqa_searchqa-validation-3838", "mrqa_searchqa-validation-419", "mrqa_searchqa-validation-4320", "mrqa_searchqa-validation-4380", "mrqa_searchqa-validation-4509", "mrqa_searchqa-validation-4609", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-4878", "mrqa_searchqa-validation-5060", "mrqa_searchqa-validation-550", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-5971", "mrqa_searchqa-validation-6122", "mrqa_searchqa-validation-6127", "mrqa_searchqa-validation-6137", "mrqa_searchqa-validation-6697", "mrqa_searchqa-validation-6821", "mrqa_searchqa-validation-6829", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-714", "mrqa_searchqa-validation-7162", "mrqa_searchqa-validation-7186", "mrqa_searchqa-validation-7322", "mrqa_searchqa-validation-7521", "mrqa_searchqa-validation-7741", "mrqa_searchqa-validation-7782", "mrqa_searchqa-validation-7786", "mrqa_searchqa-validation-784", "mrqa_searchqa-validation-7880", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-7932", "mrqa_searchqa-validation-8166", "mrqa_searchqa-validation-8331", "mrqa_searchqa-validation-8481", "mrqa_searchqa-validation-8648", "mrqa_searchqa-validation-8691", "mrqa_searchqa-validation-8941", "mrqa_searchqa-validation-8951", "mrqa_searchqa-validation-9056", "mrqa_searchqa-validation-9284", "mrqa_searchqa-validation-9348", "mrqa_searchqa-validation-9438", "mrqa_searchqa-validation-9679", "mrqa_squad-validation-10067", "mrqa_squad-validation-1023", "mrqa_squad-validation-10483", "mrqa_squad-validation-1071", "mrqa_squad-validation-1215", "mrqa_squad-validation-1251", "mrqa_squad-validation-1312", "mrqa_squad-validation-1856", "mrqa_squad-validation-2098", "mrqa_squad-validation-2434", "mrqa_squad-validation-2458", "mrqa_squad-validation-2888", "mrqa_squad-validation-3202", "mrqa_squad-validation-343", "mrqa_squad-validation-3551", "mrqa_squad-validation-356", "mrqa_squad-validation-3823", "mrqa_squad-validation-4110", "mrqa_squad-validation-5112", "mrqa_squad-validation-512", "mrqa_squad-validation-5590", "mrqa_squad-validation-5874", "mrqa_squad-validation-60", "mrqa_squad-validation-6255", "mrqa_squad-validation-6316", "mrqa_squad-validation-6324", "mrqa_squad-validation-6373", "mrqa_squad-validation-6393", "mrqa_squad-validation-6539", "mrqa_squad-validation-6657", "mrqa_squad-validation-6690", "mrqa_squad-validation-687", "mrqa_squad-validation-7068", "mrqa_squad-validation-7144", "mrqa_squad-validation-7209", "mrqa_squad-validation-7937", "mrqa_squad-validation-805", "mrqa_squad-validation-8747", "mrqa_squad-validation-8761", "mrqa_squad-validation-8807", "mrqa_squad-validation-8881", "mrqa_squad-validation-9154", "mrqa_squad-validation-9578", "mrqa_squad-validation-9761", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-1076", "mrqa_triviaqa-validation-1101", "mrqa_triviaqa-validation-1123", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1335", "mrqa_triviaqa-validation-1355", "mrqa_triviaqa-validation-1441", "mrqa_triviaqa-validation-1467", "mrqa_triviaqa-validation-1657", "mrqa_triviaqa-validation-170", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-1938", "mrqa_triviaqa-validation-1948", "mrqa_triviaqa-validation-1965", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-2239", "mrqa_triviaqa-validation-2518", "mrqa_triviaqa-validation-2653", "mrqa_triviaqa-validation-2729", "mrqa_triviaqa-validation-2798", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-287", "mrqa_triviaqa-validation-2911", "mrqa_triviaqa-validation-3025", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3036", "mrqa_triviaqa-validation-3064", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-3104", "mrqa_triviaqa-validation-3152", "mrqa_triviaqa-validation-3201", "mrqa_triviaqa-validation-3263", "mrqa_triviaqa-validation-3288", "mrqa_triviaqa-validation-3300", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-344", "mrqa_triviaqa-validation-3483", "mrqa_triviaqa-validation-3625", "mrqa_triviaqa-validation-3631", "mrqa_triviaqa-validation-3708", "mrqa_triviaqa-validation-3865", "mrqa_triviaqa-validation-393", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-401", "mrqa_triviaqa-validation-4086", "mrqa_triviaqa-validation-4110", "mrqa_triviaqa-validation-4146", "mrqa_triviaqa-validation-4167", "mrqa_triviaqa-validation-4320", "mrqa_triviaqa-validation-4378", "mrqa_triviaqa-validation-4436", "mrqa_triviaqa-validation-4450", "mrqa_triviaqa-validation-4450", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4605", "mrqa_triviaqa-validation-4614", "mrqa_triviaqa-validation-4625", "mrqa_triviaqa-validation-4710", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-4814", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-4871", "mrqa_triviaqa-validation-5079", "mrqa_triviaqa-validation-5101", "mrqa_triviaqa-validation-5265", "mrqa_triviaqa-validation-5306", "mrqa_triviaqa-validation-5415", "mrqa_triviaqa-validation-543", "mrqa_triviaqa-validation-5469", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5715", "mrqa_triviaqa-validation-5787", "mrqa_triviaqa-validation-5818", "mrqa_triviaqa-validation-5923", "mrqa_triviaqa-validation-5950", "mrqa_triviaqa-validation-609", "mrqa_triviaqa-validation-6136", "mrqa_triviaqa-validation-6289", "mrqa_triviaqa-validation-6346", "mrqa_triviaqa-validation-6352", "mrqa_triviaqa-validation-6353", "mrqa_triviaqa-validation-6364", "mrqa_triviaqa-validation-6504", "mrqa_triviaqa-validation-6599", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-6702", "mrqa_triviaqa-validation-6788", "mrqa_triviaqa-validation-6864", "mrqa_triviaqa-validation-6872", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-7039", "mrqa_triviaqa-validation-7062", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-7083", "mrqa_triviaqa-validation-7153", "mrqa_triviaqa-validation-7319", "mrqa_triviaqa-validation-7319", "mrqa_triviaqa-validation-749", "mrqa_triviaqa-validation-7506", "mrqa_triviaqa-validation-7557", "mrqa_triviaqa-validation-7581", "mrqa_triviaqa-validation-915", "mrqa_triviaqa-validation-938", "mrqa_triviaqa-validation-980"], "OKR": 0.828125, "KG": 0.53125, "before_eval_results": {"predictions": ["Niles", "Andrea Brooks", "July 14, 2017", "2018", "classical neurology", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Pure water is neutral, at pH 7 ( 25 \u00b0 C ), being neither an acid nor a base", "Peking", "Bart Howard", "2013", "Ozzie Smith, known as `` the Wizard of Oz ''", "about 1 nautical mile ( 2 km ) off - coast from Piraeus and about 16 kilometres ( 10 miles ) west of Athens", "George Harrison", "Charbagh structure", "Sarah Silverman", "Sophia Akuffo", "January 17, 1899", "IIII", "2014", "Natural - language processing", "six", "HTTP / 1.1", "The purse, which is fixed in United States dollars", "three", "Sohrai", "the Monsoons from the south atlantic ocean arrives in central Nigeria in July bringing with it high humidity, heavy cloud cover and heavy rainfall which can be daily occurrence lasting till September", "Cecil Lockhart", "Seton - Karr", "257,083", "March 23, 2018", "quarterback", "public sector ( also called the state sector )", "Carpenter", "2018", "1992", "Dan Stevens", "the episode `` Killer Within ''", "Disha Vakani", "Billy Gibbons of ZZ Top", "1999", "King Willem - Alexander", "based on a Yogiism, or quotation from Yogi Berra", "Exodus 20 : 1 -- 17", "a revolution or orbital revolution", "Ren\u00e9 Georges Hermann - Paul", "Horace Lawson Hunley", "bird nests created by edible - nest swiftlets using solidified saliva", "John Bull", "December 1, 1969", "1996", "Manley", "j. Edgar Hoover", "Francis Matthews", "hymenaeus", "1907", "1776", "Stapleton Cotton", "transit bombings", "eight-day journey", "101", "Spain", "Elijah", "Geneva", "27-year-old's"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6686495013286172}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, true, true, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, true, false, false, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.9268292682926829, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.8571428571428571, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-1784", "mrqa_naturalquestions-validation-9962", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5063", "mrqa_naturalquestions-validation-6117", "mrqa_naturalquestions-validation-819", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-2953", "mrqa_naturalquestions-validation-6797", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-10537", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-8099", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-1735", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1679", "mrqa_triviaqa-validation-2741", "mrqa_triviaqa-validation-2334", "mrqa_hotpotqa-validation-111", "mrqa_newsqa-validation-894", "mrqa_newsqa-validation-2494", "mrqa_searchqa-validation-3524"], "SR": 0.578125, "CSR": 0.5665625000000001, "retrieved_ids": ["mrqa_squad-train-25426", "mrqa_squad-train-46108", "mrqa_squad-train-72716", "mrqa_squad-train-64545", "mrqa_squad-train-2726", "mrqa_squad-train-11292", "mrqa_squad-train-81138", "mrqa_squad-train-5430", "mrqa_squad-train-29070", "mrqa_squad-train-36249", "mrqa_squad-train-66022", "mrqa_squad-train-85896", "mrqa_squad-train-15608", "mrqa_squad-train-81543", "mrqa_squad-train-21835", "mrqa_squad-train-38445", "mrqa_squad-train-15041", "mrqa_squad-train-20140", "mrqa_squad-train-66922", "mrqa_squad-train-71145", "mrqa_squad-train-39597", "mrqa_squad-train-82755", "mrqa_squad-train-64857", "mrqa_squad-train-8103", "mrqa_squad-train-32391", "mrqa_squad-train-14693", "mrqa_squad-train-27877", "mrqa_squad-train-68928", "mrqa_squad-train-68673", "mrqa_squad-train-82817", "mrqa_squad-train-78506", "mrqa_squad-train-60108", "mrqa_hotpotqa-validation-3877", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2806", "mrqa_newsqa-validation-1039", "mrqa_squad-validation-3635", "mrqa_newsqa-validation-3435", "mrqa_hotpotqa-validation-4236", "mrqa_triviaqa-validation-3642", "mrqa_newsqa-validation-3440", "mrqa_squad-validation-8295", "mrqa_triviaqa-validation-55", "mrqa_newsqa-validation-2533", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-2748", "mrqa_hotpotqa-validation-1803", "mrqa_searchqa-validation-6319", "mrqa_triviaqa-validation-4334", "mrqa_triviaqa-validation-2321", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-2744", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-9419", "mrqa_newsqa-validation-151", "mrqa_naturalquestions-validation-1044", "mrqa_newsqa-validation-3677", "mrqa_hotpotqa-validation-2341", "mrqa_searchqa-validation-9255", "mrqa_triviaqa-validation-4622", "mrqa_hotpotqa-validation-4436", "mrqa_naturalquestions-validation-8652"], "EFR": 0.0, "Overall": 0.5449531249999999}]}