{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8580, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "the Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "8.0", "the end of the 19th century", "peace", "$40,000", "the Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "about 3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings as well as structures dating from the 15th\u201318th centuries", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "10%", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis", "Uncle Tom's Cabin", "the liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.84375, "QA-F1": 0.8738095238095238}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-2798", "mrqa_squad-validation-1775", "mrqa_squad-validation-7552", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.84375, "CSR": 0.859375, "EFR": 1.0, "Overall": 0.9296875}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "the evolution of the German language and literature", "the Qur'an", "the Brotherhood", "high demand", "Tolui (1190\u20131232)", "human law", "the object's weight", "50%", "1960s", "two months", "his friends", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "lege-Khitays (Khitans)", "1960", "Captain America: Civil War", "political divisions", "linear", "Alta California", "Book of Common Prayer", "14", "Charleston, South Carolina", "fear of their lives", "hot winds", "intracellular pathogenesis", "Safari Rally", "10,005,721", "Philip Segal", "legon-complete knapsack problem", "1965", "how or whether this connection is relevant on microscales", "German Te Deum", "Stanford, California", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food", "plasmas", "their low ratio of organic matter to salt and water", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "brown", "guardian", "guardian", "black", "50 feet"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5884943181818182}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7408", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-4405", "mrqa_squad-validation-2547", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-2809", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-9015", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-164", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-8402", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3857"], "SR": 0.515625, "CSR": 0.7447916666666667, "EFR": 1.0, "Overall": 0.8723958333333334}, {"timecode": 3, "before_eval_results": {"predictions": ["10 employees", "1624", "Hangzhou", "in committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "a group that included priests, religious leaders, and case workers as well as teachers", "Vistula River", "1290", "21 October 1512", "427,652 people", "a double membrane", "August 1967", "German", "a single-step, 5-cylinder engine (no compound) with superheated steam", "four", "50 fund", "Arizona Cardinals", "Peanuts", "\"ctenes\" or \"comb plates\"", "the steroid hormone calcitriol", "Krak\u00f3w", "time", "since at least the mid-14th century", "the mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "a lack of remorse", "the fundamental means by which forces are emitted and absorbed", "A1 (Gateshead Newcastle Western Bypass", "Sun Life Stadium", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "John Houghton", "February 2015", "draftsman", "a tiny snail", "Orestes", "Galapagos Islands", "the U.S. government", "a gas (like water vapor) changes state to become a liquid", "the Forty-Davidson Museum", "a cocoa favorite", "a paint, ink or a plastic item represents a major raw", "the Mycenaean civilization", "a circadian clock", "the Belasco Theatre", "before", "a bank robber", "fibula", "The Anvil Chorus", "the South Pole", "the East Coast Main Line"], "metric_results": {"EM": 0.625, "QA-F1": 0.6654040404040404}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6937", "mrqa_squad-validation-6345", "mrqa_squad-validation-2192", "mrqa_squad-validation-4724", "mrqa_squad-validation-3347", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-10310", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.625, "CSR": 0.71484375, "EFR": 0.9583333333333334, "Overall": 0.8365885416666667}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue", "to spearhead the regeneration of the North-East", "R\u0113nos", "gambling", "the wing of the secular powers", "applied mathematics", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "experience, ideology, and weapons", "25", "October 2016", "Torchwood", "capturing prey", "c4", "livestock pasture", "Victorian", "1,300,000", "passing between carbon dioxide and oxygen", "20,000", "eight", "computational problem", "WZZM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward", "1745", "Battle of Olustee", "observer", "50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empires", "the domestic legislation of the Scottish Parliament", "sentence", "Michael Bloomberg", "Environmental Defense Fund", "innovative, exciting skyscrapers", "a cancerous tumor", "the war years", "the computer processing unit (CPU) market", "Matt Kuchar and Bubba Watson", "fastest circumnavigation of the globe", "the man facing up, with his arms out to the side", "the BBC's central London offices", "buddhism", "Manchester", "Noriko Savoie", "three", "change course", "Tsvangirai", "Wicked", "January 2", "honey", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.625, "QA-F1": 0.7062003968253969}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.2, 0.0, 0.8333333333333333, 0.4, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7606", "mrqa_squad-validation-9250", "mrqa_squad-validation-2982", "mrqa_squad-validation-7626", "mrqa_squad-validation-8874", "mrqa_squad-validation-4258", "mrqa_squad-validation-2984", "mrqa_squad-validation-8832", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-862", "mrqa_naturalquestions-validation-47", "mrqa_hotpotqa-validation-547"], "SR": 0.625, "CSR": 0.696875, "EFR": 1.0, "Overall": 0.8484375}, {"timecode": 5, "before_eval_results": {"predictions": ["a cadre of influential loyalists", "Doritos", "4000", "$37.6 billion", "Anglo-Saxons", "seven", "the Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "a seal", "Philip Howard", "Duke Richard II", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "French", "gold-trimmed logos", "the constitutional traditions common to the member states", "a placebo effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time", "Class II MHC", "two", "George Westinghouse", "by disrupting their plasma membrane", "reciprocating (piston) steam engines", "a residual of the force is observed between hadrons (the best known example being the force that acts between nucleons in atomic nuclei)", "gurus, mullahs, rabbis, pastors/youth pastors and lamas", "B cells", "a substantial number of deaths, injuries, and structural collapses", "at the Sweden-based photojournalism agency Kontinent, for which the two men work,", "a British teenage girl in Goa", "How I Met Your Mother", "France's famous Louvre museum", "Leo Frank", "the capital city", "Graziano Transmissioni", "opposition leaders", "204,000", "United's", "the release of the four men", "putting a personal and human face on the issue", "Ed McMahon", "at least $20 million to $30 million", "the Democratic VP candidate", "Friday", "Ali Larijani", "ballots", "Sodra nongovernmental organization", "sodium dichromate", "promotes fuel economy and safety", "a resting heart rate over 100 beats per minute", "heavy breeds", "Denmark", "Cincinnati", "Rossif Sutherland"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5830233134920635}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.28571428571428575, 0.0, 0.25, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-3087", "mrqa_squad-validation-353", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-6644", "mrqa_squad-validation-3263", "mrqa_squad-validation-10444", "mrqa_squad-validation-1852", "mrqa_squad-validation-2531", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.53125, "CSR": 0.6692708333333333, "EFR": 1.0, "Overall": 0.8346354166666666}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "it would undermine the law by encouraging general disobedience which is neither conscientious nor of social benefit.", "the University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "to increase the chloroplast's surface area for cross-membrane transport", "a computational resource", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "a straight line", "the autumn of 1991", "William Smith", "William Pitt", "KREEP", "Theory of the Earth to the Royal Society of Edinburgh", "Japan", "the Tuesday afternoon prior to the game", "the Working Group chairs", "laws of physics", "Denver's Executive Vice President of Football Operations and General Manager", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "a human", "a community drugstore", "a modified version of the sieve that considers 1 as prime would eliminate all multiples of 1", "nerves", "1700", "the Reichstag", "aldehydes and ketones", "DNC", "the heart, blood & blood vessels", "troggs", "six literal ordinary days", "Slovakia", "Diana the Princess", "the illegal slave trade.", "vena cava", "Virginia's", "bull's Eye", "Tartarus", "hor\u017fe", "Yul Brynner", "the Persian Achaemenid Empire", "the daily grind", "the German Count Ferdinand von Zeppelin", "San Francisco", "George IV", "aeolian process", "Edward R. Egan", "hor\u017fe", "the survivors of Oceanic Flight 815", "a comic book series by Robert Kirkman, Tony Moore, and Charlie Adlard", "Love Is All Around", "\"Everybody Comes to Rick's\"", "the International Maritime Bureau", "a form of liquid morphine used by terminally ill patients will remain on the market even though it is an \"unapproved drug,\"", "18"], "metric_results": {"EM": 0.5, "QA-F1": 0.5545296717171717}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11111111111111112, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6773", "mrqa_squad-validation-6230", "mrqa_squad-validation-5588", "mrqa_squad-validation-5054", "mrqa_squad-validation-464", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_squad-validation-9064", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-8993", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-14782", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-2340", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_hotpotqa-validation-1029", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.5, "CSR": 0.6450892857142857, "EFR": 1.0, "Overall": 0.8225446428571428}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "reduce growth", "K-9 and Company", "9.1 million", "U.S. economy consistently affords a lower level of economic mobility than all the continental European countries", "School corporal punishment", "cattle", "Mongol", "a maze of semantical problems and grammatical niceties", "five", "the \"gold standard\" of religion in minds of some or many Muslims.", "British", "Finsteraarhorn", "Abilene", "white", "The Sierra Freeway", "Thanksgiving", "Jacksonville", "Two thirds", "the Privy Council", "the nineteenth century", "the human development approach", "Daily Mail", "San Mateo", "Spanish", "300,000", "cryptomonads", "The Swahili", "hymn-writer", "starch", "Bryant", "Earth", "Pulitzer", "Rodeo", "hog", "Barack Obama", "Kenny G", "Demitasse", "a peacock", "Annapolis", "spring", "krukhit", "bark", "Allah", "Humans", "Pythons", "Cecil B. DeMille", "Nicole Kidman", "Faith Hill", "Ben Affleck", "Sandy", "the \"unconquerable will of the occupied territories\"", "particle", "Yardbird", "Kiruna", "Indonesia", "94", "Alexandria", "Perfume", "New Jersey Economic Development Authority", "Georgetown", "Essex Eagles", "Alzheimer's"], "metric_results": {"EM": 0.515625, "QA-F1": 0.559375}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7399", "mrqa_squad-validation-6220", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-7473", "mrqa_squad-validation-8189", "mrqa_squad-validation-3072", "mrqa_squad-validation-7565", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-7048", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-15487", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-3518", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-12687", "mrqa_naturalquestions-validation-10073", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.515625, "CSR": 0.62890625, "EFR": 1.0, "Overall": 0.814453125}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers", "BSkyB", "Kawann Short", "Daidu", "silent", "22", "the park", "1965", "tidal currents", "combustion", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the main opposition party", "Ireland", "Red", "around 1700", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Body of Proof", "seven-eighths", "Richelieu", "the Atlas Mountains", "Madrid", "the Danube", "eagles", "leather", "George Pullman", "red", "the Messiah", "Sappho", "possession", "the tonka bean", "the divisor", "Nyx", "Texas", "the Rooty Tooty Fresh 'N Fruity", "alzheimer", "Bill of Rights", "SAT", "Brasilia", "Henry David Thoreau", "alzheimer", "Dick Cheney", "3.9", "Gustave Eiffel", "Edward Hopper", "Central Intelligence Agency", "d'Artagnan", "the Rotunda", "1985", "alzheimer", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6056857638888888}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7803", "mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-866", "mrqa_squad-validation-9837", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-2653", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.546875, "CSR": 0.6197916666666667, "EFR": 1.0, "Overall": 0.8098958333333334}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "the main international treaty on climate change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "61", "Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence", "exploration is still continuing to determine if there are more reserves", "prep schools", "its soft power", "a strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "the most characteristic musical instrument in the region", "the Dutch Republic", "Alex Haley", "three", "the helmeted honeyeater", "4:51", "Khrushchev", "Hera", "the plague", "Ohky Chateau", "Cuba", "the Battle of Thermopylae", "the Khazars", "Kroc", "cricket", "white", "Washington State", "Carmen", "Genoa", "12", "tarn", "the novel", "the bison", "Anne Widdecombe", "the Equilateral triangle", "the Old Kent Road", "Tuesday", "the hydrates", "Ab Fab", "Massachusetts", "Cumbria", "California", "the Preamac River", "Kajagoogoo", "a berry", "Singapore", "Wigan", "Davos", "eight", "the \"eternal outsider, the sardonic drifter,\" someone who rebels against the social structure", "the Home Rule Party", "Janet Napolitano", "a powerful brand", "Oh, Oh,", "Bea Benaderet"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5886351495726496}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, false, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8784", "mrqa_squad-validation-9552", "mrqa_squad-validation-8273", "mrqa_squad-validation-9870", "mrqa_squad-validation-5376", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.515625, "CSR": 0.609375, "EFR": 1.0, "Overall": 0.8046875}, {"timecode": 10, "before_eval_results": {"predictions": ["tenggis", "environmental determinism", "4 August 2010", "King George III", "radio", "the 'Lord's Enclosure' (Mongolian: Edsen Khoroo)", "League of Augsburg", "Duarte Barbosa", "the Inner Mongolia region", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "United Kingdom", "296", "ghent", "a mulberry", "vitis", "yuri", "Ken Russell", "Dan Dare", "yuri", "Smiths", "Mike Tyson", "yuri", "Passover", "yuri", "a\u00e7aleidoscope", "Uranus", "a\u00e7ollon", "yuri Carlin", "crimea", "Sydney", "Los Angeles", "the Underground Railroad", "Robin Goodfellow", "blue", "a pomegranate", "Portugal", "football", "yuri Carey", "63 to 144 inches", "Titanic", "The Marriage Contract", "Christian Dior", "snail", "Mendip", "Wichita", "the Last Supper", "New Croton Reservoir", "andr\u00e9 3000", "Democritus", "Stephen King", "Venus Williams", "firefighter", "yuri", "yuri"], "metric_results": {"EM": 0.546875, "QA-F1": 0.599222132034632}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, false, true, true, false, true, false, false, false, false, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6285", "mrqa_squad-validation-6811", "mrqa_squad-validation-9391", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-5319", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-7535", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-4371", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-4926", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-2022", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_hotpotqa-validation-2340", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-8589"], "SR": 0.546875, "CSR": 0.6036931818181819, "EFR": 1.0, "Overall": 0.8018465909090909}, {"timecode": 11, "before_eval_results": {"predictions": ["homebound", "salvation", "jugs", "eurhamphaea vexilligera", "zaju", "uninterested in administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "a large public network", "public service", "Guy de Lusignan", "a \"tiger team\"", "t cells", "The European Commission", "the completed (or local) fields", "a force is required to maintain motion, even at a constant velocity", "Mongol and Turkic", "hez-bah-lah", "three", "puck", "morocco", "juliusi, Volterra, Cortona, Arezzo, Fiesole", "black light", "purple", "Pluto", "chromium", "purple", "Hague", "Vancouver Island", "puck", "george smiley", "nizhny Novgorod", "brown trout", "Beyonce", "Wordsworth", "morocco", "New Zealand", "Samuel Johnson", "Conrad Murray", "Mary Poppins", "brian Cerf", "purple leaf", "puck", "the Volga-Don canal", "Snow White and the Seven Dwarfs", "morocco", "lions", "purple flowers", "julma Kelly", "morocco", "Shanghai", "julie Forbush", "car", "Snake River Valley", "17 October 2006", "beer", "Hoover Dam", "Saturday's Hungarian Grand Prix", "\"The Ass of the Capuchins\"", "Edgar Allan Poe", "blue and twos"], "metric_results": {"EM": 0.375, "QA-F1": 0.4429315476190476}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6338", "mrqa_squad-validation-5460", "mrqa_squad-validation-4510", "mrqa_squad-validation-8135", "mrqa_squad-validation-4870", "mrqa_squad-validation-6530", "mrqa_squad-validation-10338", "mrqa_squad-validation-8226", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-2107", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-3314", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-6760", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.375, "CSR": 0.5846354166666667, "EFR": 1.0, "Overall": 0.7923177083333334}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "he broadened the foundations of the Reformation placing them on prophetic faith", "1.25 million", "720p high definition", "five", "Maria Goeppert-Mayer", "the International Association of Methodist-related Schools, Colleges, and Universities", "one", "a majority in Parliament", "President Mahmoud Ahmadine", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "Daniel Boone", "The Handmaid's Tale", "the pygmy chimpanzee", "The Fault in Our Stars", "car", "a puzzle video game", "1898", "the reservoir of the Bui Dam", "Total Nonstop Action Wrestling", "galt\u00fcr", "Archbishop of Canterbury", "1861", "the Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Alpine, New Jersey", "the Continental Army", "Robert Norton Noyce", "Ryan Guno", "Umar S. Israilov", "Corey Scott", "1933", "What's Up", "the Baudot code", "1959", "1887", "The Governor of Minnesota", "Marvel Comics", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point", "England", "Queen Catherine Parr", "a basilica", "1994", "Ricky Nelson", "in Wakanda and the Savage Land", "mercury", "gymnophobia", "opium", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "andrew johnson", "a spider", "in pre-Columbian times"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5968141233766233}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, true, false, true, false, false, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.1818181818181818, 1.0, 0.0, 0.0, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2249", "mrqa_squad-validation-4958", "mrqa_squad-validation-5889", "mrqa_squad-validation-9658", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-2706", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-1843", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.53125, "CSR": 0.5805288461538461, "EFR": 1.0, "Overall": 0.7902644230769231}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "Salamanca", "Jochi", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "impossible", "Southwest Fresno", "5,000", "Greek mathematician", "ABC News Now", "demolished by Boldt to make the land a more viable real estate asset", "\u00c9mile Girardeau", "Brownlee", "The Five Doctors", "The average fee is around \u20ac5,000 annually for most schools", "the Gulf South Conference (GSC)", "Earl Sinclair", "psycho-physical awareness", "Las Vegas", "Ranulf de Gernon", "2017", "downtown Dallas", "\"Love at First Sting\"", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics)", "16\u201321", "Vince Guaraldi", "Jack Boyd", "Michael Redgrave", "6th", "Highlands Course", "Hawaii", "a moth of the Gracillariidae family", "Marquis de Lafayette", "Bharatiya Janta Party (BJP)", "three", "Winter Haven Mall", "four", "\"The Process\"", "Mindy Kaling", "Surrey", "Claudio L\u00f3pez", "\"Uptown Funk\"", "FCI Danbury", "a few", "the \"Home of the Submarine Force\"", "Las Vegas", "Pope John X", "2013", "Anna Mae Aquash", "The Rwandan genocide", "Larnelle Harris", "Commander in Chief of the United States Armed Forces", "2009", "1982", "rod", "Chris Robinson", "\"CBTs\"", "shock waves", "\"I don't know who Bob Beamon is\"", "the Egyptian Goddess of Creation", "Richie Unterberger"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5458333333333334}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.5, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3176", "mrqa_squad-validation-6126", "mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_squad-validation-7792", "mrqa_squad-validation-7036", "mrqa_hotpotqa-validation-5829", "mrqa_hotpotqa-validation-4884", "mrqa_hotpotqa-validation-1009", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-3990", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.46875, "CSR": 0.5725446428571428, "EFR": 1.0, "Overall": 0.7862723214285714}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "quarter of the object", "half of all Americans combined", "December 1963", "1970", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "it then travelled along the Silk Road, reaching Crimea by 1343", "a kilogram-force", "ten times their own weight", "Quaternary", "1887", "ctenophores", "a symbiotic relationship", "quantifying the amount of resources needed to solve them", "Vistula", "quarter", "a handful of tweaks to Apple's iconic music-Player line", "a dorm parent mistreated students", "March 8", "Democrats and Republicans", "the Catholic League", "1,000 pounds", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "Friday", "Ameneh Bahrami", "stories of different women coping with breast cancer in five vignettes", "there were problems with the well and he should move his ship away", "a smile", "a quarter of bread", "Lance Cpl. Maria Lauterbach", "Hyundai Steel", "London", "more than 4,000 commercial farmers", "Val d'Isere, France", "a chaplain", "a municipal building in Baghdad's Sadr City,", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world", "Buddhism", "J.Crew", "U.S. Secretary of State Hillary Clinton", "\"I sort of had a fascination with John Dillinger", "boyhood experience in a World War II internment camp", "suppress the memories and to live as normal a life as possible", "about 4 meters (13 feet)", "the Irish capital", "Republican", "Utah County sheriff's spokesman Lt. Dennis Harris", "Allred", "Islamabad", "quarter a.m.", "March 26, 1973", "Indian Ocean", "quarter", "throw", "Sevens", "England", "Yemen", "el Greco", "dreams", "silver"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4049175650738151}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.3, 1.0, 0.0, 0.7777777777777778, 0.05, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.5384615384615384, 1.0, 1.0, 0.0, 0.26666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7456", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-1672", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-1765", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-1329", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_triviaqa-validation-3839", "mrqa_triviaqa-validation-740"], "SR": 0.3125, "CSR": 0.5552083333333333, "EFR": 0.9772727272727273, "Overall": 0.7662405303030303}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "Mercury", "prime", "50 fund", "the Camisards", "over $40 million through sponsors", "GTE", "1,100", "spin", "Oligocene,", "Melodie Rydalch,", "Darwin", "Little Rock military recruiting center", "March 24,", "the Beatles", "Jesus Christ", "Adriano", "Two of the dead were police officers.", "2007", "an unprecedented wave of buying amid the elections.", "\"She had a smile on her face, like she always does when she comes in here,\"", "19,600", "National Football League", "\"The Lost Symbol\"", "one of its diplomats", "vitamin injections that promise to improve health and beauty.", "two soldiers", "Atlanta", "resources", "\"We say to the people of Gaza, give more resistance and we will be with you in the field, and know that our victory in kicking out the invaders is your victory as well,", "two Emmys", "\"I have a very, very good family that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.", "\"Three Little Beers,\"", "Rwanda", "75.", "to kill members of the Zetas cartel from the state of Veracruz,", "closing these racial gaps", "a bond hearing Friday,", "President Bush", "Amstetten,", "African National Congress Deputy President Kgalema Motlanthe,", "\"It's hard for everyone... I thought it was better for me here,\"", "\"He lost his bid to Francisco de Narvaez, who leads a rival Peronist party, Union PRO, by a tally of 34.6 percent to 32.1 percent.", "\"I've always been fascinated by the political process ever since I was a kid.", "a strict interpretation of the law,", "saying Chaudhary's death was warning to management.", "Prime Minister Benjamin Netanyahu", "20% tax credit", "July 23.", "70,000", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.", "Robert Remak", "Tim McGraw", "Prussian", "cabbage", "game", "Beno\u00eet Jacquot", "blue", "John George Stewart", "The Left Book Club", "holography"], "metric_results": {"EM": 0.421875, "QA-F1": 0.48280836640211633}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444444, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 0.09523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.057142857142857134, 0.0, 0.29629629629629634, 0.0, 0.0, 1.0, 1.0, 0.1111111111111111, 0.2962962962962963, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3293", "mrqa_squad-validation-9016", "mrqa_squad-validation-427", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-3239", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-968", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-11133", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.421875, "CSR": 0.546875, "EFR": 1.0, "Overall": 0.7734375}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "the high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city \u2013 herded into the Warsaw Ghetto.", "the Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "Gary Kubiak", "housing bubble", "a total of 183 people, including 137 children, have been taken away since law enforcement officers raided the compound Thursday night,", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary manslaughter", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "in 1979", "the armed robbery and kidnapping of another victim,", "next year", "to overhaul domestic policies,", "Noriko Savoie", "Anil Kapoor", "Afghanistan and India", "Dr. Albert Reiter,", "\"The Significance of the Iranian Threat,\"", "to step up attacks against innocent civilians", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "your own environmental videos", "two women", "Queen Elizabeth's", "Sunday and two others throughout the night, rescue crews were not able to find the pilot or the five passengers from the plane,", "male veterans", "Yusuf Saad Kamel", "Hokeriet,", "11 healthy eggs", "don't believe the U.S. assertion that the system is needed to guard against imminent threats from Iran or North Korea.", "to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "1918-1919.", "in the 1950s,", "at least four of them.", "Brazil has saved $1 billion alone by producing its own generic versions of HIV/AIDS medicines and negotiating discounts for imported drugs.", "vegan bake sales", "\"The Rosie Show,\"", "Dodi Fayed", "Oxbow,", "gastrocnemius", "Ed Sheeran", "\"clock\"", "Australia", "three-part", "2001", "parishes", "U.S.", "George Blake", "Bogota"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5759102876290376}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, false, false, true, true, false, false, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 0.0, 1.0, 0.27272727272727276, 0.22222222222222224, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.08333333333333333, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.17142857142857143, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_squad-validation-626", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-837", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3962", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-1921", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.46875, "CSR": 0.5422794117647058, "EFR": 1.0, "Overall": 0.7711397058823529}, {"timecode": 17, "before_eval_results": {"predictions": ["low levels of development have relatively equal distributions of wealth", "a pharmacy practice residency and sometimes followed by another residency in a specific area.", "a method of imparting the basics of Christianity to the congregations", "wakes (sed vigilat) and experiences visions", "the \"Brompton Boilers\"", "12 January 1943,", "60,000", "Zagreus", "CBS", "17", "a temperate zone.", "Rod Blagojevich", "Mad Men", "St. Louis, Missouri.", "$50 less,", "Afghanistan's", "found his qualifications mean little as a refugee.", "collaborating with the Colombian government,", "Iran", "concerns about the missile defense system.", "Herman Cain", "Matthew Fisher,", "Peppermint oil, soluble fiber, and antispasmodic drugs can indeed help people with irritable bowel syndrome,", "in the north and west of the country,", "injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "introduce legislation Thursday to improve the military's suicide-prevention programs.", "$250,000", "first or second week in April.", "Derek Mears", "braving elements ranging from rain to wind and even one speeding ticket (which she says she talked her way out of).", "Gary Player", "Hamburg", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "fastest wind-powered boat on the planet is rapidly gaining momentum as speeds reach all-time highs.", "Virgin America", "Wellington, Florida,", "Daniel Wozniak", "22-year-old", "Osama bin Laden", "how health care can affect families.", "NATO", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.", "2002", "at checkposts and military camps in the Mohmand agency,", "its forces killed nine gunmen.", "Friday,", "\"Here Comes the Sun.", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "hid his money,", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Sky & Telescope", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan", "surrealism", "C.S. Lewis", "a number multiplied by itself will result in the", "sake", "Nova Scotia"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5113563149311988}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, false], "QA-F1": [0.6666666666666666, 0.4, 0.2105263157894737, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.125, 1.0, 0.12500000000000003, 0.0, 1.0, 0.0, 0.3529411764705882, 0.45454545454545453, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.20000000000000004, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-6359", "mrqa_squad-validation-2338", "mrqa_squad-validation-2408", "mrqa_squad-validation-5326", "mrqa_squad-validation-1570", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-1858", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-2583", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-401", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-4124", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_triviaqa-validation-1659", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-4857"], "SR": 0.40625, "CSR": 0.5347222222222222, "EFR": 1.0, "Overall": 0.7673611111111112}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "Baron Dieskau", "linear", "Advanced Steam", "Defensive ends", "\"the dot\"", "chastity", "European Court of Justice", "a bronze medal in the women's figure skating final,", "that U.S. Ambassador to Zimbabwe James McGee would be expelled from the country if he \"persisted in meddling in Zimbabwe's electoral process,\"", "UK", "\"Gandhi,\"", "Argentina", "Congress", "28", "New Haven, Connecticut, firefighter Frank Ricci", "Iraq's autonomous region of Kurdish Regional Government", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106.5 million", "because everybody around me likes Obama,\"", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Saudi Arabia", "\"All of our stations are overcrowded,\"", "mammoth's fossil", "\"global security, prosperity and freedom.\"", "a disgraceful anti-immigration and pro-racial-profiling law,", "Molotov cocktails, rocks and glass.", "opening 101 new jobs to British workers,", "Ben Roethlisberger", "Dr. Christina Romete", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong", "Vonn,", "in an interview Tuesday on CNN's \"Larry King Live,\"", "organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "\"Racism and racist conversations have no place today in America.", "Brazil", "a big shopping center", "trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "Pakistan's North West Frontier Province", "Casey Anthony,", "\"Let it Roll:", "Emma Watson and Dan Stevens", "2002", "a leak", "\"Taxman,\"", "Che Guevara", "Miller Brewing", "Elizabeth Tudor", "John Fogerty", "Garonne", "the giraffe", "cheese"], "metric_results": {"EM": 0.453125, "QA-F1": 0.528532586970087}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.12121212121212123, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.2857142857142857, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.2666666666666667, 0.19047619047619047, 1.0, 0.0, 0.16, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2702702702702703, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-900", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_newsqa-validation-2847", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-254", "mrqa_searchqa-validation-11385"], "SR": 0.453125, "CSR": 0.5304276315789473, "EFR": 0.9714285714285714, "Overall": 0.7509281015037594}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "safety Darian Stewart", "11", "killed through overwork", "Japanese", "Muqali,", "2011 and 2012,", "the Pittsburgh Steelers", "apartment building", "Aung San Suu Kyi", "Chuck Bass", "3rd District of Utah.", "that suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Johns", "three", "procedures", "an acid attack by a spurned suitor.", "those who managed to survive the incident hid in a boiler room and storage closets", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book", "\"He's as healthy as he can be -- no health problems whatsoever,\"", "stand down.", "Ashley \"A.J.\" Jewell,", "at least 17", "home in Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "rural up in rural California,", "was killed in an attempted car-jacking as he dropped his children off at a relative's house,", "Old Trafford", "the area of the 11th century Preah Vihear temple", "a floating National Historic Landmark,", "design and produce the Haeftling range.", "home in the Pacific Ocean territory of Guam within striking distance,", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Robert De Niro", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "CNN's Campbell Brown", "$60 billion on America's infrastructure.", "a month of training to get used to wearing the shoes", "Roberto Micheletti,", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani,", "that Clarkson  was depressed over a recent breakup, grabbed the gun and  took her own life.", "\"We wondered how can we protect our dogs' feet against glass,\"", "stone", "around 2.45 billion years ago", "Cambridge", "Colorado", "Bangor International Airport", "\"Grandmasters\"", "Suffragist", "Canterbury", "Tunisia", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6241002185056945}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.8, 0.0, 1.0, 0.5714285714285715, 0.0, 0.10526315789473685, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666665, 0.888888888888889, 1.0, 1.0, 0.5714285714285715, 0.1, 0.0, 0.0, 0.0, 0.0, 0.631578947368421, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.5714285714285715, 0.1818181818181818, 0.0, 1.0, 1.0, 0.35294117647058826, 0.15384615384615385, 0.0, 0.5, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-2944", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-2836", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-416", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-413", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782"], "SR": 0.484375, "CSR": 0.528125, "EFR": 1.0, "Overall": 0.7640625}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Norman Huguenots", "Hungarians", "De Materia Medica (Concerning medical substances)", "John D. Rockefeller", "seven professional schools", "sentence", "Beijing, China,", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "the United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Can't Get You Out of My Head", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956 ) and four since the advent of the Super Bowl ( Super Bowls XXI ( 1986 ), XXV ( 1990 ), XLII ( 2007 ),", "1969", "the eventual Super Bowl champion New England Patriots", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Wolfgang Hochstetter", "Yale University", "62", "the team", "November 2014", "Archduke Franz Ferdinand of Austria", "a central place in Christian eschatology", "October 1941", "peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "Shalimar Gardens", "Cee - Lo", "one of his kidnapper that he has a girlfriend named Abigail and that he wants to call her to say goodbye before they kill him", "the additives common to a complete tomato sauce and does not have the thickness of paste", "Conservative Party", "three times", "November 25, 2002,", "January 1, 2016", "Peter Greene", "31 March 1909", "Ed Sheeran", "two", "Alberto Salazar", "live animals", "American", "Hoosick,", "an engineering and construction company with a vast personal fortune.", "1.2 million", "Paul Galdone", "Robert Louis Stevenson", "Samoa", "Mugabe and China", "the remote area about 75 miles east of Yakima"], "metric_results": {"EM": 0.5, "QA-F1": 0.6298343794841639}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6, 1.0, 0.6, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.25, 1.0, 0.5945945945945945, 0.0, 0.0, 0.0, 0.896551724137931, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3086", "mrqa_squad-validation-6314", "mrqa_squad-validation-8027", "mrqa_squad-validation-7929", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-1244", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-8619", "mrqa_naturalquestions-validation-6991", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-660", "mrqa_newsqa-validation-2446"], "SR": 0.5, "CSR": 0.5267857142857143, "EFR": 0.96875, "Overall": 0.7477678571428572}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "Fresno Traction Company", "Parliament of the United Kingdom", "blue-green algae", "four", "Sauron", "the Washington metropolitan area", "the base 10 logarithm of the molar concentration, measured in units of moles per liter, of hydrogen ions", "the breast or lower chest of beef or veal", "Sargon II", "Tagalog or English", "around 1600 BC", "From 1976 to 1983", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford,", "in the 2nd century", "in the pancreas", "Kanawha Rivers", "1961", "iOS, watchOS, and tvOS", "rocks and minerals", "Michael Schumacher", "the foreign exchange option", "1957", "1776", "1963", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "Scarlett Johansson", "Transvaginal ultrasonography", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Sonepat, Panipat, Tilpat ( near Faridabad )", "1979", "Guy Berryman", "Tessa Virtue and Scott Moir", "Sophocles", "Tim Allen", "thick skin", "the middle Jaffa Cakes", "India", "Brazil, Turkey and Uzbekistan", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "the Major General of the Navy", "Clayton Mark's", "14,000", "Iran could be secretly working on a nuclear weapon", "Honduras", "Pardon of Richard Nixon", "Ellen DeGeneres", "12 April 1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5633720395209365}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, true, false, false, true, false, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.6666666666666666, 0.0, 0.7692307692307693, 1.0, 0.0, 0.0, 0.5, 1.0, 0.4, 0.7777777777777778, 1.0, 0.0, 0.0, 0.6666666666666666, 0.08333333333333333, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9392", "mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3883", "mrqa_hotpotqa-validation-427", "mrqa_hotpotqa-validation-3984"], "SR": 0.40625, "CSR": 0.5213068181818181, "EFR": 1.0, "Overall": 0.7606534090909091}, {"timecode": 22, "before_eval_results": {"predictions": ["at the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "Stanford University", "Stewart", "the Mongol and Turkic tribes", "1859", "Danny Lane", "John 6 : 67 -- 71", "new wave rock band The Fixx", "Andrew Johnson", "Hellenic polytheism", "Mark Jackson", "Manhattan Island", "British rock band", "In 2015", "breasts and genitals", "week 4", "L.K. Advani", "the House of the United States Congress", "Zachary John Quinto", "Sukhvinder Singh, Mahalaxmi Iyer", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton", "a single particle", "John Adams", "Lituya Bay in Alaska", "Manhattan, the Bronx, Queens", "Burbank, California", "Ricardo Chavira", "2014", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas", "Masha Skorobogatov", "on February 27, 2007", "Neil Patrick Harris", "8ft", "Owen Vaccaro", "food", "on the lateral side of the tibia", "Steve Trevor Jr.", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff / \ufffdrous 90 \u00b0N - 0 \u00b0 E", "London to Canterbury", "in the bloodstream or surrounding tissue", "2017", "February 28 or March 1", "1840s", "9 t ( 31.82 ft )", "Montgomery", "if he was not Romeo, then he would not be a Montague and she would be able to get married with no problem at all", "Hotel California", "Queen Elizabeth II", "\u00ef\u00bf\u00bd", "the American rock band Pearl Jam", "March 28, 1970", "Dan Tyminski", "British singer Robbie Williams", "in the southern port city of Karachi,", "at least nine", "Bashar al-Assad", "the Christian Bible", "ski and shoot"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4856171180184338}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.9473684210526316, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5714285714285715, 0.14814814814814814, 0.0, 1.0, 0.6666666666666666, 0.2857142857142857, 0.0, 0.0, 1.0, 0.5, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8148148148148148, 0.5, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-807", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-4904", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-3470", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_hotpotqa-validation-1458", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-4138", "mrqa_searchqa-validation-2112"], "SR": 0.359375, "CSR": 0.5142663043478262, "EFR": 0.9512195121951219, "Overall": 0.732742908271474}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "its many castles and vineyards", "below 0 \u00b0C", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "The Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd", "during prenatal development", "gaius caesar", "Tanvi Shah", "Article 1, Section 2", "the Constitution of India came into effect on 26 January 1950", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "James P. Flynn", "detritus", "September 27, 2017", "Johnny Logan", "1978", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando", "on February 10, 2017", "Alex Skuby", "Virginia", "March 2016", "from 1922 to 1991", "Tony Curran", "Bacon", "in an explosion", "Heather Stebbins", "Redenbacher family", "two amino acids", "10 national", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "a milling cutter", "Massachusetts Compromise", "Justin Timberlake", "Andrew Moray", "Alamodome and city of San Antonio", "asexually", "Anthony Caruso", "In 1871 A.D. Pt. Buddhiballav Pant", "eye", "The History Boys", "gaius caesar", "the White Knights of the Ku Klux Klan", "five", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "Phillip A. Myers", "middle-class suburb about an hour outside Cairo, Egypt.", "Antarctica", "spinal cord", "gaius caesar"], "metric_results": {"EM": 0.5, "QA-F1": 0.6335689484126983}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4444444444444445, 0.6666666666666666, 0.28571428571428575, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4444444444444445, 0.2857142857142857, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_squad-validation-8990", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-9707", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.5, "CSR": 0.513671875, "EFR": 0.96875, "Overall": 0.7412109375}, {"timecode": 24, "before_eval_results": {"predictions": ["circus", "no", "Stadtholder William III of Orange", "1933\u20131953", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "the first hole of a sudden-death playoff with Kentucky native Kenny Perry", "the onset and progression of Alzheimer's disease", "Disco", "\"Regno di Dalmazia\"", "Anil Kumar", "New York", "Charles Whitman", "C. H. Greenblatt", "\"The Thing\"", "the A541 Mold-Denbigh road", "Corendon Airlines", "86 ft", "Minneapolis", "Loch Duich", "Fatih Ozmen", "U.S.", "Pacific Place", "political commentator", "the Donny & Marie Showroom, at the Flamingo Las Vegas", "Westminster, London", "2016", "Steve Cuden", "New York", "Malcolm Mays", "\"Harper's Bazaar\"", "dementia", "on the Po di Volano, a branch channel of the main stream of the Po River, located 5 km north", "Guadalcanal Campaign", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "Verizon Wireless Arena", "Vic Chesnutt", "the high priest Bruteno", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "Musicology", "Portland, OR", "the Yoruba", "\"Lucky\"", "Charles Otto Puth Jr.", "2007", "2001", "1966", "Jeremy Clarkson", "Ryan Harris", "gaius caesar", "Joe Jackson", "a car claiming 280 miles per gallon", "2004", "genes", "Olive", "Stockholm"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5288776327838828}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.08333333333333334, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.30769230769230765, 0.6666666666666666, 0.4, 0.3333333333333333, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5531", "mrqa_squad-validation-7092", "mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3901", "mrqa_hotpotqa-validation-5516", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1849", "mrqa_hotpotqa-validation-4331", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-2659", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-5855", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930"], "SR": 0.453125, "CSR": 0.51125, "EFR": 0.9714285714285714, "Overall": 0.7413392857142858}, {"timecode": 25, "before_eval_results": {"predictions": ["A progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "the Anhaltisches Theater in Dessau", "Anna Clyne", "Terence Winter, based on the memoir of the same name by Jordan Belfort", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "The Slipper and the Rose", "Los Angeles", "Sharyn McCrumb", "acid house", "in Austria, south Germany, German Switzerland, and Slovenia at the end of the 18th century", "Capture of the Five Boroughs", "Miranda Leigh Lambert", "Shenandoah National Park", "Briton Allan McNish", "10 Years", "Haleiwa Ali'i Beach Park", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern part", "non-alcoholic", "Entrepreneur Media Inc.,", "the lead roles of Timmy Sanders and Jack", "PBS stations nationwide,", "second largest", "Citric acid", "in 1911", "michael andrew atherton", "Modest Petrovich Mussorgsky", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "torpedo boats", "1972", "Geographical Indication tag", "Ringo Starr", "the Celtics", "World Championship Wrestling", "1994", "TD Garden", "the Chechen Republic", "Chrysler", "Harvard University", "the EPs Sounds of the Season", "Tenochtitlan", "The Tax Reform Act of 1986", "michael andrew atherton", "the Mexican government", "The Cartoon Network", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "his 19-year-old son Krishna Rajaram", "michael andrew atherton", "to earn the nickname Super Eli", "purple"], "metric_results": {"EM": 0.4375, "QA-F1": 0.525123278478058}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.47058823529411764, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4444444444444445, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-4165", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-2056", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-973", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-4737", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_triviaqa-validation-1466", "mrqa_triviaqa-validation-453", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-364", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240", "mrqa_searchqa-validation-1374"], "SR": 0.4375, "CSR": 0.5084134615384616, "EFR": 0.9722222222222222, "Overall": 0.7403178418803419}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "Ruhr", "Dar es Salaam", "Heinkel He 178", "Victor Garber", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Anthony and Joe Russo", "late eighteenth century", "\"The Snowman\"", "1979", "Premier League club Liverpool and the England national team", "port city of Aden", "British", "second cousin", "2008", "Archie Andrews", "born 2 May 2015", "17 December 177026 March 1827", "Microsoft Windows, PlayStation 3 and Xbox 360", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Travolta", "Hall & Oates", "port of Mazatl\u00e1n", "striker", "Las Vegas Valley of Nevada", "1919", "Kevin Spacey", "\"Love Streams\"", "Michael Edwards", "\"The Rite of Spring\"", "Lake Wallace", "England", "1993", "Boston Celtics", "Eisenhower Executive Office Building", "6,396", "Adelaide Steamship Company", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "stadium", "English folk-song", "Hexachrome", "1600 BC", "Obi - Wan Kenobi", "1963", "linen", "Zeebrugge", "mexico", "more than 15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan", "mexico", "mexico"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5773695054945055}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2223", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-102", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_searchqa-validation-3515", "mrqa_searchqa-validation-13669"], "SR": 0.484375, "CSR": 0.5075231481481481, "EFR": 1.0, "Overall": 0.7537615740740741}, {"timecode": 27, "before_eval_results": {"predictions": ["Merritt Island", "pedagogic diversity", "Christian", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services", "Paper", "Alistair Grant", "Whitney Houston", "Goodyear Tire and Rubber Company", "Bonkyll Castle", "Cheick Tiot\u00e9", "Algernod Lanier Washington", "Josh Hartnett", "due to a leg injury", "Antonio Salieri", "American", "Europe", "What You Will", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "Supremes", "Cersei", "Kalokuokamaile", "Brigadier General Raden Panji", "Don Bluth", "1970", "Chief of the Operations Staff of the Armed Forces High Command (Oberkommando der Wehrmacht)", "Hong Kong Disneyland", "London", "I Should Have Known Better", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914 machine gun", "Consuelo Lopez", "Prussian army", "January 2004", "Peter Lawrence Buck", "South Park", "seven", "October 25, 1881", "J. Robert Oppenheimer", "Pradyumna", "Mark Jackson", "R / T", "Colossus", "Equatorial Guinea", "c3H8O3", "Victor Mejia Munera", "Chris Robinson and girlfriend Allison Bridges", "Somalia", "bromide", "septum", "light"], "metric_results": {"EM": 0.578125, "QA-F1": 0.621875}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1916", "mrqa_squad-validation-1075", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-2957", "mrqa_naturalquestions-validation-4039", "mrqa_triviaqa-validation-2051", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-6398"], "SR": 0.578125, "CSR": 0.5100446428571428, "EFR": 1.0, "Overall": 0.7550223214285714}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "Hanover", "Plas Johnson", "tenno", "Gordon Ramsay", "Gorbachev", "ragging on the weather and the civilian authorities and giving voice to all the concerns of the men in the trenches.", "colossus of rhodes", "Rameses II", "Anna (Julia Roberts)", "colossus of rhodes", "orchid", "Paddy Doherty", "rhodvirus", "colossus of rhodes", "the Central African Republic", "Chubby Checker", "most popular and enduring compositions", "Iran", "colossus gehotty", "colossus of rhodes", "colossus of ragelonne", "April", "Eric Morley", "ADHD and hypertension", "The Garrick Club", "Beauty and the Beast", "rhodes", "Manhattan", "Marc Norman", "The Greatest", "colossus Tom Parker", "off the coast of Northumberland", "colossus of rhodes", "saxophonist", "Seattle", "colossus gehyn Castle", "Cardiff", "Louisiana", "stromberg", "Tahrir Square", "Romanian", "bathtub curve", "Caine", "Snooty", "Borodin", "Crittenden", "colossus of rhodes", "Greek", "purple granadilla", "Thomas Lennon", "Haikou on the Hainan Island", "British associationists", "Denmark and Norway", "1966", "North America", "Florida's Everglades", "Garth Brooks", "glamorous, sexy and international.", "drive", "Glengarry Glen Ross", "shark"], "metric_results": {"EM": 0.375, "QA-F1": 0.4576388888888888}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, true, true, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, true, true, true], "QA-F1": [0.0, 0.5, 0.39999999999999997, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-256", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-4619", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-6730", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-4432", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-6096", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-627", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-1045", "mrqa_triviaqa-validation-6701", "mrqa_triviaqa-validation-3586", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-1004"], "SR": 0.375, "CSR": 0.5053879310344828, "EFR": 1.0, "Overall": 0.7526939655172413}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "the Kennedy Space Center ( KSC ) in Florida", "the Los Angeles Lakers", "James W. Marshall", "Blue laws", "Randy VanWarmer", "the U.S. Senate", "Emma Watson", "13.5 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "Pyeongchang County, Gangwon Province, South Korea", "the status line", "in the eye", "jimmy mancherson", "Triple Alliance of Germany", "Andrew Lloyd Webber", "1955", "the president - elect and the love interest to Candace, whom she uses to help her get her money back", "Buffalo Lookout", "Humpty Dumpty", "Charlene Holt", "1 US dollar", "Leonard Nimoy", "1960", "Sam's", "10.5 %", "the small intestine", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "belle", "1995", "Christine McVie", "technological advances in printing", "Cairo, Illinois", "in the 1970s and'80s", "in the Hebrew Bible", "lula ( Lesley Ann Warren )", "Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "The Miracles", "taxonomy", "leg", "big (1m88, 94kg)", "Charlie heston", "\"Twice in a Lifetime\"", "Nineteen Eighty-Four", "Bardot", "27,", "Long Island convenience store", "Mitt Romney", "Peter", "stomach", "bronchitis"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5847288676236045}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.21052631578947367, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-2225", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-6508", "mrqa_triviaqa-validation-3968", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1979", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.53125, "CSR": 0.50625, "EFR": 1.0, "Overall": 0.753125}, {"timecode": 30, "before_eval_results": {"predictions": ["San Jose State practice facility", "number of quality rental units", "major events also play a big part in tourism in Victoria", "(h, k)", "redwood", "corey", "Spanish Republic", "taximeter", "jaguar", "(PVM)", "Harry Reid", "charlie Foxx", "core", "forge", "The Edison Kinetoscope", "In No Country for Old Men", "Flowerbomb", "Blackbird", "Footprints", "charlie", "L.A. Kings", "The U.S. Census Bureau", "Tommy Lee Jones", "(St.) Jose Maria Escriva", "The Memory Keeper's daughter", "(1876)", "hubris", "Yahtzee", "Tony Danza", "HTML", "hives", "In the U.S. Census Bureau,", "(December 6, 1864)", "charlie sheen", "Pride and Prejudice", "(I am Spartacus)", "(I've got nothing against Welch's)", "Munich", "Michael Jordan", "(St.) Andrew's Day", "charlie", "Hikaru Sulu", "pulsatrix", "(pte brisee, an all butter", "Mount Nakadake", "pak thong koh", "Boston", "Fisher- Price", "Arctic Ocean", "the Italian flag", "squash", "Spain", "Thomas Chisholm", "May 2002", "year of the 1997 squad voted atop the final AP Poll", "Newfoundland", "The Odd Couple", "Monty Python's", "July 16, 1911", "Bryan Kocis", "The translation, published posthumously in 1759,", "Israel", "Adidas", "European Commission"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4057054924242424}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, true, false, true, false, false, false, false, false, true, true, false], "QA-F1": [0.0, 0.7499999999999999, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-315", "mrqa_squad-validation-7576", "mrqa_squad-validation-2965", "mrqa_searchqa-validation-4996", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-3963", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-11558", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-5162", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-2523", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-10080", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4602", "mrqa_hotpotqa-validation-4718", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3915"], "SR": 0.34375, "CSR": 0.501008064516129, "EFR": 1.0, "Overall": 0.7505040322580645}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "black", "Bill Cosby", "satirical erotic romantic comedy", "Ferengi spam Quark", "the Social Democratic Party of Austria", "January 21, 2017", "Bloomingdale Firehouse", "elizabeth Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court", "Bangkok, Thailand", "The Oklahoma Sooners", "Merrimack", "Gust Avrakotos", "\"The Late Late Show\"", "Mark Anthony \"Baz\" Luhrmann", "two", "The Indianapolis Motor Speedway", "Romagnol", "Angie Watts", "a family member", "Januaryis Lyn Joplin", "The Worm", "Eliot Cutler", "Mercury Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Emilio Escobar", "Asbury Park, New Jersey,", "Rockland", "\"Slaughterhouse-Five\"", "Shohola Falls", "wineries", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia, Pennsylvania", "Dobbs Ferry, New York", "Amityville in Suffolk County", "Sinngedichte", "The Highwayman", "Fuenlabrada", "Kevin Spacey", "Arizona State University", "Blue Grass Airport", "Lawton Chiles", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Lenny Jacobson", "Mowgli", "1935", "Harpy", "\"Wales\"", "The Miracles", "the Rockies", "anti-trust laws.", "Friday", "Blu Cantrell", "Ulysses S. Grant", "Belarus"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5649038461538461}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.8, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-500", "mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-3320", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-2614", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-2088", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-2570", "mrqa_hotpotqa-validation-2136", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-99", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-4268", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6898", "mrqa_searchqa-validation-6055", "mrqa_searchqa-validation-2446"], "SR": 0.453125, "CSR": 0.49951171875, "EFR": 1.0, "Overall": 0.749755859375}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 6", "jellyfish", "March", "Wooden clogs", "fauntleroy", "Dartmouth College", "i second that emotion", "Kofi Annan", "oxygen", "second that emotion", "Taggart", "i second that emotion", "the Atlantic Ocean", "i second that emotion", "Sven Goran Eriksson", "Stobart", "Lou Mitchell", "Brussels", "Cumberland's troops", "John Poulson", "Charles de Gaulle", "the Maastricht Treaty", "Jack Frost", "Saskatchewan", "i second that emotion", "the Solent", "vomiting", "the i second that emotion", "Bristol Aeroplane Company", "lettuce", "Stephen Hendry", "\u201cArgo\u201d", "Libra (\u264e) is the seventh astrological sign", "Surrey", "1971", "chippenham", "Budapest", "the Aconcagua Region", "Don Quixote", "i second that emotion", "stadtbahn", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong's", "Ray Charles", "very important", "customary", "Miller Brewing Company", "northwestern", "Sydney Opera House", "devastation", "her decades-long portrayal of Alice Horton", "love the trip route, which winds through the Rockies and climb to 9,000 feet.", "Peter Bogdanovich", "i second that emotion", "Cyprus"], "metric_results": {"EM": 0.375, "QA-F1": 0.4583814102564102}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, false, true, false, false, true, false, true, false, true, false, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.8, 0.0, 0.0, 0.0, 0.923076923076923, 0.8799999999999999, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3435", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-4986", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-7262", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-596", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539"], "SR": 0.375, "CSR": 0.49573863636363635, "EFR": 1.0, "Overall": 0.7478693181818181}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "Lana Del Rey", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown", "the Arctic Ocean", "Mitch Murray, who offered it to Adam Faith and Brian Poole", "blue", "Ultra Hand ''", "John Bull", "775 rooms", "eusebeia", "Rent", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Longline fishing", "Jesus'birth", "a habitat", "Simone Vangsness", "Central Germany", "Andrew Johnson", "Etienne de Mestre", "Aegisthus", "electors", "Julia Ormond", "Sauron's assistance", "1961", "ste\u026and / STAYND", "2013", "March 1", "published on November 12, 1976", "a usually red oxide formed by the redox reaction", "Spain", "MacKenzie Mauzy", "Paul Lynde", "in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "fled to exile in the Netherlands", "paid monument", "erosion", "March 2, 2016", "cranberry sauce", "1996", "Ray Charles", "18", "the Ramones", "The original building was completed in 1800", "Anglo - Norman French waleis", "Frank Theodore `` Ted '' Levine", "New Jersey", "May 2010", "built in France", "argo", "dennis taylor", "a centaur", "music lover", "cricket fighting", "dennis taylor", "rich", "\"Ivan the Terrible,\" a guard at the notorious Treblinka extermination camp.", "Islamabad", "Tunisia", "RAND", "bios & Profiles"], "metric_results": {"EM": 0.40625, "QA-F1": 0.49180282901145533}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.125, 0.3076923076923077, 1.0, 0.0, 0.18181818181818182, 0.6666666666666666, 0.0, 0.0, 0.7368421052631579, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4827586206896552, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-3942", "mrqa_naturalquestions-validation-7802", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-187", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_naturalquestions-validation-3396", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-5607", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2118", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.40625, "CSR": 0.4931066176470589, "EFR": 1.0, "Overall": 0.7465533088235294}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Zeebo", "7th century", "2018", "her abusive husband", "September 29, 2017", "molecular clouds", "transmission and final drive", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions forms the joint venture Bullwinkle Studios,", "Mahalaxmi Iyer", "1942", "Nick Sager", "London boroughs, Metropolitan Boroughs, unitary authorities, and district councils, who took over this power from the Justices of the Peace", "prophets and beloved religious leaders", "Assam elects 7 seats since 1956 and 6 seats since 1952", "Gastric acid, gastric juice or stomach acid", "Renishaw Hall, Derbyshire, England, UK", "accomplish the objectives of the organization", "sport utility vehicles", "Isabella Palmieri", "temperature at which the phase transition occurs", "Mind your Ps and Qs", "Germany", "20 November 1989", "the Spanish Dominican Tom\u00e1s de Torquemada", "Bob Gaudio and his future wife Judy Parker", "1975", "Mel Gibson", "Procol Harum", "Erica Rivera", "zinc - carbon cells", "a proprietary library classification system first published in the United States by Melvil Dewey in 1876", "2003", "Sebastian Lund", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "in various submucosal membrane sites of the body", "Flex SDK, a set of components that included charting, advanced UI, and data services ( Flex Data Services )", "Eagle Ridge Outdoor pool", "Phillip Schofield and Christine Bleakley", "animals react to threats with a general discharge of the sympathetic nervous system, preparing the animal for fighting or fleeing", "Ukraine", "Lula", "1840", "when the car comes to a halt", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Derrick Henry", "lowest air temperature record", "an episode typically ends as a cliffhanger showing the first few moments of Sam's next leap", "mounted inside the pedestal's lower level", "krave,", "dennis taylor", "Brian Close", "a hard rock/blues rock band", "Galleria Vittorio Emanuele II", "totalitarian governments", "he was escorted in his pajamas onto a military plane and flown out of the country, ousted Honduran President Jose Manuel Zelaya could return to power within days,", "Olympic medal", "Henry Ford", "Jaguar", "Abraham Lincoln", "a cancer"], "metric_results": {"EM": 0.359375, "QA-F1": 0.4769968484879584}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.13793103448275862, 1.0, 1.0, 1.0, 0.19999999999999998, 0.7499999999999999, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.7499999999999999, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4666666666666667, 0.06896551724137931, 0.0, 0.0, 0.0625, 1.0, 0.0, 0.0, 0.20000000000000004, 0.2758620689655173, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-904", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-15783", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.359375, "CSR": 0.4892857142857143, "EFR": 0.926829268292683, "Overall": 0.7080574912891986}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists who attacked it (bin Laden being a prime example),", "a supposed mild euphoric", "James McConkey", "Venezuela", "Kansas City", "the Ring", "Peter Pan", "dennis tMLipp", "the Arctic Ocean", "Charlesson-Morley", "help salmon and other fish to migrate upstream over or through a barrier to fish movement", "Lafayette", "Malcolm X", "depressed", "the Royal Marines Band", "Alexander Pushkin", "Australia", "Munich Crisis", "cuerpos son trasladados a la ciudad de Tehuacn", "in the United States works mostly at... and other groups concerned with jobs, workers, and working conditions", "the papacy", "Arkansas River Valley", "subclue 2", "Pierre-August Renoir", "tous les expressions mais c'est bien de savoir", "operas", "the Bavarian Alps", "Charles Keating Jr.", "Microsoft", "ferns", "Sony", "hawson", "Atlantic City", "Blackwater USA", "elephants", "American Airlines", "cingino Dam", "Odysseus", "Geronimo", "Kensington Palace", "Charles Bassett", "the Dutch Republic", "hawhatan", "the Wardrobe", "John Galt", "scratching on a", "Chicago Mercantile Exchange", "Las Vegas", "\"Tights: not just for dancing\"", "wheat", "Pablo Casals", "an ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "psychological horror", "John Morgan", "Hungarian Rhapsody No. 2 in C-sharp minor, S.244/2,", "Eleanor of Aquitaine", "Sen. Debbie Stabenow", "63", "\"perezagruzka' (the Russian word for reset,)"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4557291666666667}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, false, true, false], "QA-F1": [0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-13638", "mrqa_searchqa-validation-265", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-15160", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-16363", "mrqa_searchqa-validation-8694", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-10308", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3372", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.390625, "CSR": 0.48654513888888884, "EFR": 1.0, "Overall": 0.7432725694444444}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Mike Czerwien", "northwards at a speed of about 15 metres ( 49 feet ) per year", "at Lucknow in September 1906", "in the eighth episode of Arrow's second season", "National Industrial Recovery Act", "The User State Migration Tool", "the Battle of Antietam and Lincoln's Emancipation Proclamation", "William DeVaughn", "between 2 world Trade Center and 3 World Trade Center", "1.34 miles ( 2.16 km )", "Los Angeles", "layered systems of sovereignty, especially within the Holy Roman Empire", "Raza Jaffrey", "on 31 January 1934", "Filipino", "1773", "RAM", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Harishchandra", "Olivia Olson", "1990", "the Canadian rock band Nickelback", "Bill Pullman", "BC Jean", "( 2016 )", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "photoreceptors", "1980s", "in inorganic forms, such as calcium carbonate", "card verification data ( CVD )", "oversee the local church", "bohrium", "Britain", "Escherichia coli", "Austria - Hungary", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in De Inventione by Marcus Tullius Cicero", "Mike Czerwien", "103", "Vienna", "English", "Mexico", "Stalin", "$10.5 million", "Al Horford", "Andrew Johnson", "$22 million", "Lula da Silva", "his mother and his three children", "cotton", "Mark Antony", "Quinn", "Towcester"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6409712537391867}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 0.10526315789473685, 0.33333333333333337, 0.7142857142857143, 1.0, 0.0, 0.6, 1.0, 0.9523809523809523, 0.0, 0.0, 0.06451612903225805, 0.0, 0.4, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09523809523809523, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-2887", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-2833", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_hotpotqa-validation-4351", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161"], "SR": 0.546875, "CSR": 0.48817567567567566, "EFR": 0.9310344827586207, "Overall": 0.7096050792171482}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "Japan", "South Africa", "first among equals", "shine", "a cappella", "albinism", "peterloo massacre", "an aglet", "Saturday Night Live", "FC Bayern M\u00fcnchen", "winter", "Bonnie and Clyde", "English", "copper", "Dawn French", "Blackstar", "Florentius or the feminine form Florentia", "Orhan Pamuk", "Scooby Doo", "swaziland", "the elephant House", "Kent", "the Humber", "points based scoring system", "motor vehicles", "Kent", "Rodgers and Hammerstein", "Boy George", "Claudius Ptolemy", "Zelle", "Peter Flannery", "Sweet dreams", "medellin", "The Tempest", "carburetor", "brazilia", "Boulder Dam", "painkillers", "Saudi Arabia", "Belle de Jour", "boro", "the snow outside Mara\u2019s window slowed, spiky white stars melting into streaks on the pane", "rain", "blue", "Phobos and Deimos", "France", "Snowbell", "Kunsky", "death and dying", "Lady Penelope", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "fan interviews, previews and reviews of Arsenal matches", "Theo James Walcott", "Ben Ainslie", "two Metro transit trains that crashed the day before,", "heavy turbulence about 02:15 a.m.", "women coping with breast cancer in", "blankets", "the sunflower", "Madonna", "March 24,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.5967261904761905}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, false, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-6577", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-7512", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-6503", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-2982", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_hotpotqa-validation-1528", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.5625, "CSR": 0.4901315789473685, "EFR": 1.0, "Overall": 0.7450657894736843}, {"timecode": 38, "before_eval_results": {"predictions": ["Nieuwe Waterweg (\"New Waterway\")", "tyne", "liver", "40", "water", "cuba", "cuba", "galileo", "galileo", "galileo davis", "the head", "dogs", "hanover", "a moon", "Charles I of England", "adult aged 16 to 64 is in work", "scales", "Dirty Dancing", "galileo", "diana Ross", "albion", "a 1934 Austin seven box saloon", "Paul Anka", "galileo", "cuba", "galileo", "Blade Runner", "Jay-Z", "leopard", "cymbal", "air Bud", "La Dame aux cam\u00e9lias", "doris davis", "galileo", "South Africa", "Christian Dior", "scrobbesburh", "Killer whales", "galileo", "France", "raspberries", "pilgrimage", "Cyprus", "speed camera", "duke", "lizard", "george lewis", "galileo", "a sea horse", "30", "Tony Blair", "a quartz or feldspar", "54 Mbit / s", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Ray Lynn", "jazz", "cuba", "Kim Kye Gwan", "French Guiana", "Network Services", "heraldry", "PlayGirl"], "metric_results": {"EM": 0.40625, "QA-F1": 0.45892857142857146}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, false, false, false, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9180", "mrqa_triviaqa-validation-2224", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-2097", "mrqa_triviaqa-validation-1254", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5730", "mrqa_newsqa-validation-785", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.40625, "CSR": 0.4879807692307693, "EFR": 1.0, "Overall": 0.7439903846153846}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that\\'s no good\"", "aldi", "Midnight Cowboy", "charles", "dandruff", "Amanda Barrie", "a hoy", "Niger", "Stockholm", "Tangled", "dog", "georgia davis", "Bulls Eye", "georgia", "BWV 248", "Timothy Carroll", "charles Darwin", "pembrokeshire", "Kevin macdonald", "peppers", "Mesozoic", "charles Boyd", "Brunel", "georgia", "1957", "bristol", "charles", "leonangere", "acid-mediated coagulation", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "georgia tchaikovsky", "Shanghai", "charles i", "grow in St. James Parish", "Thursday", "Guru Nanak", "bleak house", "Inigo Montoya", "phosphorus", "charles horner", "Indianapolis", "lolita", "cuckoo", "Miss Marple", "Ford", "Alice Cooper", "Majorca", "watling blood", "Royal Bengal Tiger", "1.5 times the Schwarzschild radius", "Whoville", "television", "1999", "Sela Ann Ward", "The Cycle of Life", "forgery and flying without a valid license,", "137", "a log cabin", "St. Patrick's Day", "linebacker", "Sondheim"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5027281746031746}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, true, true, false, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 0.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-1895", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-2142", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-1116", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-1036", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-8554", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.4375, "CSR": 0.48671875, "EFR": 1.0, "Overall": 0.743359375}, {"timecode": 40, "before_eval_results": {"predictions": ["in the 19th Century", "Paramount Pictures", "Washington", "Thomas de Quincey", "the Black Death", "horse", "buffalo", "jimmy boyd", "a raven", "Sarajevo", "the Bill of Rights", "'Fine'", "Neighbours", "fezzik", "trumpet", "Westminster Abbey", "origami", "resistance of an unknown resistor", "Arabian Gulf", "avon", "fezzik", "avunculicide", "jack", "\u201cGone With the Wind\u2019", "a linesider", "Tomorrow Never Dies", "jimmy boyd", "a Great Dane", "Washington", "brazil", "New Hampshire", "jimmy i", "charlie Fenton", "japan", "purple rain", "fezzik", "b", "The Poseidon Adventure", "Venice", "2", "Southwest Airlines", "pears", "georgia", "The Comedy of Errors", "Chicago", "georgia", "first lady Betty Ford", "b", "upper fjords", "Radicalization", "fezzik", "Jack and Jill", "1998", "Tanvi Shah", "the EN World web site", "the 100th anniversary of the first \"Tour de France\" bicycle race", "a dimensionless quantity", "Janet", "more than 2.5 million", "researchers", "the Matrix", "Curb Your Enthusiasm", "a free lunch", "Inequality of opportunity"], "metric_results": {"EM": 0.328125, "QA-F1": 0.4005208333333333}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true], "QA-F1": [0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.19999999999999998, 0.0, 0.4, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9257", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-3739", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-5262", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4337", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-11519"], "SR": 0.328125, "CSR": 0.4828506097560976, "EFR": 1.0, "Overall": 0.7414253048780488}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "us", "us", "nixon", "asiatic Sarmatia", "paddy Clarke", "an abacus", "Robin Hood Men", "sisyphus", "Diego Velazquez", "South African", "london", "oregon", "Ken Russell", "james hazam", "us", "satirical", "david Bowie", "Neil Armstrong", "georgia Steiner", "james", "james turpin", "rust", "james nixon", "Wiltshire", "tbilisi", "james james", "othello", "fabric", "glenn close", "Lacock Abbey", "alex b", "domestic cat", "Anita Brookner", "james", "Margaret Thatcher", "Black Sea", "bagram", "Susie Dent", "a power outage", "Vienna", "The Archers", "london", "james philip Sousa", "Chester racecourse", "james boyd", "Marcella Detroit", "b", "aire", "brazil", "Dry Ice", "Pat McCormick", "April 2018", "2001", "from 1993 to 1996", "james Gandolfini", "September 23, 2016", "one of 10 gunmen who attacked several targets in Mumbai on November 26,", "June 6, 1944", "sniff out cell phones.", "a bassoon", "o.K. Corral", "butternut bonasus", "phoenicia"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5208333333333333}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.3333333333333333, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-7602", "mrqa_triviaqa-validation-7591", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-6097", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_naturalquestions-validation-1163", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.4375, "CSR": 0.48177083333333337, "EFR": 1.0, "Overall": 0.7408854166666667}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "some work rule issues.", "Eintracht Frankfurt", "Na'ameh", "aston villa", "Jeddah, Saudi Arabia,", "40", "his chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "Wednesday,", "Michelle Obama", "Alberto Fujimori", "Atlanta International Airport", "dancy-Power Automotive", "the \" Michoacan Family,\"", "64", "life in prison.", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "iran President Mahmoud Ahmadinejad", "ended his playing career at his original club of Argentinos Juniors in 2007", "on the set at \"E! News\"", "off Haiti's coast", "Madeleine K. Albright", "ice jam", "breast cancer", "Benazir Bhutto", "July", "U.S. senators", "zuma", "Larry Ellison", "Rihanna", "her fianc\u00e9,", "Cal Ripken Jr.", "Johannesburg", "cancer", "acid attack", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning,", "byproducts emitted during the process of burning and melting raw materials.", "about 5:20 p.m. at Terminal C", "Herman Thomas", "\"We say to the people of Gaza, give more resistance and we will be with you in the field,", "a man's lifeless, naked body", "\"release\" civilians,", "Dodi Fayed", "reduce this speed and we sail for about 5 days before we run out of battery,\"", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc", "pyotr tuesday", "Misery Chastain", "kennifer purdy", "italo Balbo", "Thorgan ganael Francis Hazard", "Braehead", "brazil", "japan", "Cy Young", "witherspoon"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4939622707915391}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.1111111111111111, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.8, 0.14634146341463414, 1.0, 1.0, 0.3636363636363636, 0.09090909090909091, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-49", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-1375", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-1641", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-5687", "mrqa_hotpotqa-validation-3610", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-10019"], "SR": 0.40625, "CSR": 0.4800145348837209, "EFR": 1.0, "Overall": 0.7400072674418605}, {"timecode": 43, "before_eval_results": {"predictions": ["25,033", "the House of Borromeo", "Washington, D.C.,", "1943", "a facelifted 850 saloon", "the Mountain West Conference", "Kevin Willis", "Western Europe,", "political thriller", "Continental AG", "The Blues, Town, or The Tractor Boys", "from 1989 until 1994", "the Distinguished Service Cross,", "\"50 best cities to live in.\"", "Bridgetown,", "Pakistani cinema", "Emmanuel ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "the office from 1556 to 1558,", "Galway", "\"My Backyard\"", "15 October 1988", "coaxial cables", "\"Northern Lights\"", "Anthony Davis of the New Orleans Pelicans,", "Malayalam fantasy comedy", "(1815\u20131867)", "August 11, 1946", "Charlie Kaufman", "May 26, 2010", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Brian A. Miller", "Christian Duguay", "1985", "Gal Gadot-Varsano", "Sarah Rafferty,", "a Boeing B-17 Flying Fortress", "Britney Spears's \"Femme Fatale Tour\"", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "the 2012 Summer Olympics", "Sony Studio Liverpool", "Brig Gen Augustine Warner Robins", "United Nations", "Alice's", "two occasions", "and trademark to be registered under the UK\u2019s Trade Mark Registration Act 1875,", "blue", "elbow", "Citizens of the lower house of parliament,", "the Employee Free Choice act", "the release of the four men", "a rake", "Jack the Ripper", "a carriage", "Teak"], "metric_results": {"EM": 0.578125, "QA-F1": 0.667311507936508}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-7240", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070"], "SR": 0.578125, "CSR": 0.48224431818181823, "EFR": 1.0, "Overall": 0.7411221590909092}, {"timecode": 44, "before_eval_results": {"predictions": ["British Prime Minister Edward Heath", "Sean Yseult", "William \"Bill\" Kristol", "over 12 million", "Lucha Underground Championship", "Conservatorio Verdi in Milan", "President of the United States", "\"the backside.\"", "\"Barracuda Frank\"", "The Future", "Newton Knight", "Andrew Joseph", "Denmark", "2015 Orange Bowl", "William Hesketh Lever", "death", "Fort Valley, Georgia", "Tom Hanks", "Vladimir Menshova", "Heart", "the Dominican Republic", "Humberside Airport", "2017 Major League Baseball (MLB) First-Year Player Draft", "Douglas Jackson", "wooden roller ride", "Blackpool Football Club", "William Lyon Mackenzie King", "Seth MacFarlane", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Chrysler", "Bruce Grobbelaar", "Honda Ballade", "ascona community", "Boston Celtics", "Austrian", "Division of Fawkner", "Socrates", "Caesars Entertainment Corporation", "Hindi", "Richard Masur", "Brian Patrick Friel", "Bad Religion", "\"Dr. Gr\u00e4sler, Badearzt\"", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Chaminade High School", "Gian Carlo Menotti", "Olympic bobsledder", "Mazda Capella", "102,984", "Roscoe Lee Browne", "1972 Dolphins were the third NFL team to accomplish a perfect regular season,", "John Goodman", "over 38 million", "The Spectator", "Easter Parade", "orchestral work", "last summer.", "almost 100", "into the Southeast,", "a pie", "Great Balls of Fire", "his own account of her life", "One Direction"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5903409090909091}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, true, false, true, true, false, true, true, false, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.33333333333333337, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3913", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-1153", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-2525", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1917", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-4710", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-12050"], "SR": 0.46875, "CSR": 0.4819444444444444, "EFR": 1.0, "Overall": 0.7409722222222221}, {"timecode": 45, "before_eval_results": {"predictions": ["the American Revolution", "a \"quod demonstrandum\"", "a red lion", "the Belgae", "Northern Exposure", "cocoa butter", "\"Don't Worry, be Happy\"", "Esther", "Warren Harding", "Lorne Greene", "minigolf", "Tuesday, October 18 6 a.m.", "Punxsutawney, Pennsylvania", "Bratislava", "yellow fever", "sea otters", "M&M's", "a \"franchise\"", "thy rod", "Nixon's 'dirty tricks' man,", "horse", "moon", "Mickey Mouse", "a stigma", "Assistant Prof.", "a \"piece of cellophane\"", "Medusa", "a spiral", "black", "musical notes", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "Helen of Sparta,", "a \"piece more sacred than the most sacred religious\"", "a circle", "Morrie Schwartz", "English Monarchs", "India", "the Beast", "a \"dirty blizzard\"", "Oklahoma Sooners Football", "one's head", "white bread and butter", "Rules of Order", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats", "Middle Eastern alchemy", "London", "Isle of Wight", "Tornado", "\"Queen In-hyun's Man\"", "Oneida Limited", "Michael Jordan", "Libreville, Gabon.", "two tickets to Italy by calling Expedia.", "\"The station was getting continuing inquiries, and Brett thought it would be best if he resigned,\"", "Cahaba"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5127959280303029}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 0.125, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-6832", "mrqa_searchqa-validation-7347", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-4671", "mrqa_searchqa-validation-14930", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-8692", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-3375", "mrqa_searchqa-validation-14560", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1744", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_naturalquestions-validation-9626", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3949", "mrqa_triviaqa-validation-888"], "SR": 0.421875, "CSR": 0.48063858695652173, "EFR": 1.0, "Overall": 0.7403192934782609}, {"timecode": 46, "before_eval_results": {"predictions": ["\"degrees of privilege\" to which they were entitled institutionally and legally,", "Jorge Lorenzo", "Malachy McCourt", "James Cameron", "mycelium", "Venus flytrap", "Abraham", "the playhouse theatre", "faggot", "anser", "a filly/mare", "Pluto", "Route 66", "the Taklamakan Desert", "Sindh\u016b River", "Astro-Santa Morph", "the Gobi Desert", "North Rhine", "Go West", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "snakes", "Sedgefield", "the northeast coast of Australia's state of Queensland", "Saddam Hussein", "Nadia Comaneci", "tank", "South Korea", "a pig", "X-Men Origins: Wolverine", "Carmen", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "6", "Potomac River", "the Pacific Ocean", "Luke", "Frankfurt", "chipmunk", "Goldie Hawn", "a pulsar", "Belgium", "\"Black Beauty\"", "a little extra juice and zest", "Bar\u00e7a", "\"Penthouse, The\"", "games where the player played, in whole or in part", "works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "clinical cloning", "early 7th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "the Louvre", "Speed Racer", "H.G. Wells", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.546875, "QA-F1": 0.62383658008658}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, true, true, true, false, false, true, true, true], "QA-F1": [0.42857142857142855, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3636363636363636, 0.6666666666666665, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-736", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-5015", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-5636", "mrqa_naturalquestions-validation-716", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-5109", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-2953", "mrqa_searchqa-validation-4652"], "SR": 0.546875, "CSR": 0.48204787234042556, "EFR": 1.0, "Overall": 0.7410239361702128}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "Venice", "Sinclair Lewis", "the bear", "definitely comes once a year.\"", "a binder", "Jonathan Demme", "k Czechoslovakia", "Dick Van Dyke", "isabella", "Tina Turner", "2010", "Belfast", "sahara", "perfume", "duke orsino", "iron", "Copenhagen", "The Apprentice", "a Plimsoll line", "Analytical Cubism", "sahara", "Advisory Council of Science and Industry", "eucharist", "Charlotte's Web", "Octopussy", "vegetable", "Charles Foster Kane", "Adam", "rowing", "kennie macDowell", "Call My Bluff", "a star", "Argentina", "frank mccourt", "salt or sugar", "Caroline Aherne", "zenyatta", "carbon dioxide", "soap", "Donna Summer", "a balustrade", "Nottingham", "gdansk Poland", "Welcome Stranger", "strathclyde Police", "April", "Chechnya", "potty bank", "a- Team", "football", "801,200", "Amartya Sen", "Sun Tzu", "bioelectromagnetics", "Pittsburgh", "Speedway World Championship", "and beautiful.", "36", "Sarah,", "Copenhagen", "Communist Manifesto", "Sara Smile", "tendon rupture"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5653409090909091}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-633", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-6956", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-3758", "mrqa_triviaqa-validation-4241", "mrqa_triviaqa-validation-1730", "mrqa_naturalquestions-validation-4953", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3780", "mrqa_searchqa-validation-15651", "mrqa_newsqa-validation-1804"], "SR": 0.515625, "CSR": 0.48274739583333337, "EFR": 1.0, "Overall": 0.7413736979166667}, {"timecode": 48, "before_eval_results": {"predictions": ["Firth of Forth", "Caesars Entertainment Corporation", "Supergirl", "\u00c6thelred the Unready", "\"Shaun the sheep\"", "British Airways", "William McKinley", "1905", "All Nippon Airways", "Mineola, New York", "Paradzhanov", "Strange Interlude", "Julia Compton Moore", "Olivia Newton-John", "argentina", "early Romantic period", "The Gettysburg Address", "Harold Edward Holt", "Washington Street", "Lauren Lane", "Babylon", "Ford Falcon", "New York State Route 907E", "\"novel with a key\"", "1827", "Kim Bauer", "FDA", "Edward James Olmos", "Bury St Edmunds, Suffolk, England", "Prussian", "\"O\" theatre", "Cuban-American Major League Clubs Series", "86", "American", "January 2004", "sulfur mustard H or HD blister gas", "the 45th Infantry Division", "2009", "5", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "August 14, 1848,", "Texas Tech University", "John McClane", "Larry Wayne Gatlin", "zenyatta", "371.6 days", "North Carolina", "Selinsgrove, in central Pennsylvania,", "his daughter", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "part of a VAT tribunal in 1991", "Salman Khan", "space shuttle", "basil", "world's most recognizable international advertising awards", "\"The Rosie Show,\"", "North Korea", "over 1,000 pounds", "Julius Caesar", "a desert", "the Library of Congress", "thylakoid membrane"], "metric_results": {"EM": 0.5, "QA-F1": 0.6416183868969195}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, false], "QA-F1": [0.6, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 0.9090909090909091, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.8695652173913043, 0.0, 0.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-4008", "mrqa_hotpotqa-validation-3680", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-775", "mrqa_hotpotqa-validation-3513", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-1399", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_triviaqa-validation-5844", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028", "mrqa_naturalquestions-validation-4685"], "SR": 0.5, "CSR": 0.4830994897959183, "EFR": 0.96875, "Overall": 0.7259247448979591}, {"timecode": 49, "before_eval_results": {"predictions": ["hitting a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John W. Henry", "James Woods", "James Mitchum", "4 April 1963", "1995", "Tom Shadyac", "Wendell Berry", "Power Rangers Turbo", "eastern", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five aerial victories", "Jean Cayrol", "the Seasiders", "musical research", "Dragon TV", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1928", "November 20, 1942", "September 26, 2010", "The O2 Arena", "1614", "Lucy Maud Montgomery", "Ryan Aguilera and Taio Cruz", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "the EN World web site", "Charles Russell", "KB", "Colonel Patrick John Mercer", "Golden Globe award", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf for Best Actor in 2013", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "the closing scene of the final episode of the first season", "`` Everywhere ''", "the birth centenary of Pandit Jawaharlal Nehru", "honda", "J. M. W. Turner", "Republic of Upper Volta", "56,", "\"The Democratic Republic of Congo\"", "Eintracht Frankfurt", "the US marines", "Hephaestus", "Amherst College", "two courses on the Black Sea coast in Bulgaria."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6818373466810966}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.25, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.2222222222222222]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1498", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-5896", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-1412", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-2296", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.5625, "CSR": 0.48468750000000005, "EFR": 1.0, "Overall": 0.7423437500000001}, {"timecode": 50, "UKR": 0.623046875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.818359375, "KG": 0.47109375, "before_eval_results": {"predictions": ["Disha Patani", "Eardwulf", "St Andrews, Fife, Scotland", "26,000", "Spain, Mexico and France", "1981", "RPG role-playing game system", "February 26, 1948", "Joe Henry Engle", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "A1 Recordings", "IFFHS World's Best Goalkeeper", "best player ever to play in the National Basketball Association", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages)", "May 5 to July 8, 2014", "June 11, 1973", "twenty-three episodes", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "northern", "Picric acid", "Las Vegas", "CBS's", "New Zealand food writer", "fantasy role-playing game", "polar explorer", "Dolly Records", "Bergen", "Matthieu Vaxivi\u00e8re", "Feyenoord's Sekou Ciss\u00e9", "1994", "the superhero Birdman", "Harrison County", "New York Yankees", "1903", "Charles Hastings", "Mark \"Chopper\" Read", "is variously described as \"gothic\", \"romantic\", and \"otherworldly\"", "VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Mercer University", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "21 December 2017", "1800", "The season seven premiere", "glycerol", "an umbrella", "intestines", "Ben Kingsley stars with Bollywood superstar Amitabh Bachchan", "1.2 million people.", "84-year-old", "Genesis 45", "the accused", "Steven Spielberg", "Mitch Murray"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6052011539264829}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8888888888888888, 1.0, 0.7368421052631579, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.42857142857142855, 0.6666666666666666, 0.25, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-532", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-517", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-3065", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-4130", "mrqa_hotpotqa-validation-4696", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_triviaqa-validation-1015", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770", "mrqa_searchqa-validation-1372"], "SR": 0.46875, "CSR": 0.484375, "EFR": 1.0, "Overall": 0.6793750000000001}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County", "Prince Antoni Radziwi\u0142\u0142", "Hordaland", "Charles Perrault's", "Wilton Mall", "the First Balkan War", "Australia and New Zealand", "Daniel Espinosa", "1942", "water", "Bury St Edmunds, Suffolk, England", "1981", "The Merry Wives of Windsor", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "Logan International Airport", "Blackpool Football Club", "Marvel Comics", "100 million", "Joseph McCarthy", "Volvo 850", "1978", "July 25 to August 4", "Sela Ann Ward", "\"She of Little Faith\"", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom", "Oracle Corporation", "Pittsburgh, Pennsylvania", "Benedict Arnold", "Nine-card Brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World.", "Nikolai Alexandrovich Morozov", "Bolivian folk troupe", "The Dragon", "two", "Outside", "Traumnovelle", "the Chechen Republic", "actress and model", "1995\u201396", "Granada", "Guangzhou, China", "British", "Jaguar Land Rover Limited", "Citgo Petroleum Corporation", "portrait painter", "B.R. Ambedkar", "Presley Smith", "the hydrological cycle or the hydrologic cycle", "William Snelgrave", "Joe Meek", "Melissa Duck", "in a tenement in the Mumbai suburb of Chembur,", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "independence", "Popular Science magazine", "a ton", "Church of Jesus Christ of Latter-day Saints", "John and Elizabeth Calvert"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5518622002997002}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.4, 0.0, 0.0, 0.6666666666666666, 0.7499999999999999, 0.5, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.1904761904761905, 1.0, 0.0, 0.0, 0.1818181818181818, 1.0, 0.5, 0.8, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.8, 1.0, 0.25, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-2929", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-2663", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-823", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-10", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-3348", "mrqa_hotpotqa-validation-5766", "mrqa_hotpotqa-validation-4565", "mrqa_triviaqa-validation-1467", "mrqa_triviaqa-validation-5002", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-4537", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.390625, "CSR": 0.4825721153846154, "EFR": 1.0, "Overall": 0.6790144230769231}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1968", "Physical", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "novel", "the National Society of Daughters of the American Revolution (NSDAR)", "Timmy Sanders", "Japan", "St Augustine's Abbey", "The Indianapolis Times", "Dan O'Bannon", "Jay Hanna \"Dizzy\" Dean", "UHF channel 44", "North Kesteven,", "West African descendants", "The Beatles", "\"Menace II Society\"", "September 1901", "March 31, 1995", "the Black Panther Party", "Pinellas County", "Benjamin Burwell Johnston", "Imagine", "Easy", "CBS", "\"Brickyard\"", "2012", "Candice Susan Swanepoel", "Benny Andersson", "Peter, Paul and Mary", "Kathleen O'Brien", "private equity", "the River North Esk in Midlothian, Scotland", "Paris", "Hard rock", "the individual who left the group in 2007", "\"Complex\" magazine", "Jimmy Ellis", "the University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "\"The Omega Man\"", "David Dunn", "William Bradford", "FieldTurf", "My Beautiful Dark Twisted Fantasy", "Benj Pasek and Justin Paul", "a hand injury", "Freedom Day 27 April 2000", "Johnny Cash & Willie Nelson", "the base of the right ventricle", "In May 1935, French Foreign Minister Pierre Laval", "France", "sport taekwondo", "The Tinkler", "since 1983.", "the legitimacy of that race.", "the Dukes of Norfolk", "Italy", "hot peppers", "a star"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6720858134920635}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.4, 1.0, 0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-557", "mrqa_hotpotqa-validation-2358", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-2209", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-787", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-933", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-7953", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_triviaqa-validation-4229", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.515625, "CSR": 0.4831957547169812, "EFR": 1.0, "Overall": 0.6791391509433963}, {"timecode": 53, "before_eval_results": {"predictions": ["the sky", "Friedrich Nietzsche", "the ship", "Lord Carnarvon", "Ireland", "Glaciers", "white", "the queen", "Aunt Bee", "Great Smoky Mountains National park", "the meadow", "the French and Indian War", "the king of France", "the malignant disease", "the Cannonball Run", "the sugar cane", "mUSEUMS", "The Crow", "the plain of Marathon", "John Keats", "Scott Peterson", "the Pacific Ocean", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "Fyodor Dostoyevsky", "Mike Rowe", "Resident Evil", "Daughter", "the French national holiday", "the United Arab Emirates", "Dramamine", "terence harris", "Oktoberfest", "Dred Scott", "the Empress Josephine", "Theodore Roosevelt", "the Tempest", "Cybertron", "Crystal Light", "the Yankees", "the nutrient", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "Jack London", "an ear", "Indira Gandhi", "the AWACS E-3", "the Director of National Intelligence", "Spondylodesis or spondylosyndesis", "2018", "Peter Paul Rubens", "weasel", "jareth", "1 December 1948", "Jack Benny Binion", "three centuries", "flying", "Michoacan", "\"gotten the balance right\"", "Carpenter"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5978422619047619}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, true, false, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.14285714285714288, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-2569", "mrqa_searchqa-validation-13330", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14893", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-11243", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-576", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2102", "mrqa_newsqa-validation-2821"], "SR": 0.53125, "CSR": 0.48408564814814814, "EFR": 1.0, "Overall": 0.6793171296296296}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "\"IRL\"", "phil Sedgmen", "Luke Campbell", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "(disease)", "Adrian Cronauer", "Copenhagen", "the Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googol", "in the world", "(SPX)", "Royle Family", "jazz improvisation", "Alamo", "Brazil", "bologna", "(disease)", "Michael Faraday", "George W. Bush", "(To Say Nothing of the Dog)", "haddock", "(disease)", "Tim Peake", "phil redmond", "tamales", "Argentina", "St Moritz", "(disease)", "Woody", "Jerry", "Sinclair Lewis", "mouse", "brazil", "Barry White", "Tim Burton", "Parchman Farm", "Canada", "the Hague Conventions", "Portugal", "silver", "Ishmael", "X&Y ( 2005 )", "`` Killer Within ''", "prenatal development", "13\u20133,", "My Beautiful Dark Twisted Fantasy", "\"The Worm\"", "\"The Golden Girls,\"", "most police officers don't have enough training to look past race while investigating a person\\'s legal status.", "the Bridgestone Invitational in Ohio in August.", "Easy Rawlins", "William McKinley", "the Scripps National Spelling Bee", "Berlin"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5963541666666666}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, false, true, false, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-6992", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-6426", "mrqa_triviaqa-validation-3384", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-1771", "mrqa_naturalquestions-validation-6206", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187"], "SR": 0.53125, "CSR": 0.48494318181818186, "EFR": 1.0, "Overall": 0.6794886363636363}, {"timecode": 55, "before_eval_results": {"predictions": ["forcibly injecting them with psychotropic drugs", "the man was dead,", "Republican Gov. Bobby Jindal", "is", "customers", "the United States", "South Dakota State Penitentiary", "the Iranian consulate,", "tried to fake his own death by crashing his private plane into a Florida swamp.", "right-wing paramilitaries.", "CNN", "opium poppies", "Bright Automotive,", "NASCAR.", "Clifford Harris,", "Muslim", "Coptic Christians", "television", "bollywood", "is", "urged NATO to take a more active role in countering the spread of the", "1831", "the Ku Klux Klan", "Sonia Sotomayor,", "pine beetles", "lower house of parliament,", "CNNI's Michael Holmes.", "Iran", "Daniel Radcliffe", "the \"deeply intimate portrait will provide viewers with a raw and honest look inside a musical dynasty.\"", "in the Ronald Reagan UCLA Medical Center,", "her father's grave.", "two", "remains unknown,", "$89", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "chile", "acid attack", "root out terrorists within its borders.", "July 8 at London's 20,000-capacity O2 Arena.", "he was released Friday and taken to the Australian embassy,", "Channel 4 has been criticized for creating a new television show which looks at how children as young as eight would cope without their parents for two weeks.", "Gustav's top winds", "Rwanda", "2", "Bob Johnson", "familiar answers.", "dance", "his club", "AMD, a competitor,", "two years", "the Confederate States", "Adam Sandler", "1,228 km / h ( 763 mph )", "Thom Yorke", "charlie sheen", "silversmith", "Joseph Ruttenberg", "International Federation of Competitive eating", "Valley Falls", "the Provisional Irish Republican Army", "Australia", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.484375, "QA-F1": 0.563159654887596}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, false, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, false, true, true, true, true, false, false, true, false, true, true, true], "QA-F1": [0.0, 0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.058823529411764705, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.4, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-1541", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-566", "mrqa_newsqa-validation-2697", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-3914", "mrqa_naturalquestions-validation-6888", "mrqa_naturalquestions-validation-5983", "mrqa_hotpotqa-validation-5224", "mrqa_hotpotqa-validation-698", "mrqa_searchqa-validation-1388"], "SR": 0.484375, "CSR": 0.4849330357142857, "EFR": 0.9696969696969697, "Overall": 0.673426001082251}, {"timecode": 56, "before_eval_results": {"predictions": ["Stratofortress", "peso", "the nucleus", "inflammatory", "1960", "Stalin", "Groundwater", "Ovulation", "Python", "William Proxmire", "George Orwell", "indigenous", "dining table", "Coach Carter", "Dinosaurs", "one small step", "Psycho", "a believer", "Athens", "extreme", "Botanical Gardens", "Olivia Newton", "Mickey Gilley", "Oral Roberts", "staff", "Constantinople", "Tin", "Atrato", "\"Nobody\")", "Dave Brubeck", "the Yellow Ribbon", "Stevie wonder", "Richmond, Virginia", "Jupiter", "the palpless male", "Apple", "depression", "a tomb", "Act One", "the", "Rhapsody", "the Ziegfeld Girl", "liquor", "Ronald", "Mount Kilimanjaro", "a militia", "Delaware", "Graceland", "the", "the boxer", "the oral stage", "John F. Kennedy", "Siddharth Arora / Vibhav Roy", "`` Gossip ''", "Munich", "the Circle", "12th", "Julie Kavner", "Benedict", "Markov Random Field", "\"Abbey Road.\"", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5046875}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2168", "mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-1616", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-11485", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-6050", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-2176", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658", "mrqa_hotpotqa-validation-1078", "mrqa_hotpotqa-validation-5280"], "SR": 0.4375, "CSR": 0.48410087719298245, "EFR": 1.0, "Overall": 0.6793201754385965}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "a symbol", "Merlin", "sculpture", "Alien", "think Big", "Mariachi", "when You Misinterpret Lyrics", "excruciating", "Kilimanjaro", "opinion", "Francis Ford", "pardon", "the Pope", "Calais", "(Y)", "Edison", "a tortugas", "Thomas Paine", "Isaac Newton", "American Wedding", "Anthony Michael Hall", "Tears for Fears", "the Jamestown Stamp", "the Rhine", "a blacksmith", "the Mohs scale", "Flint", "October 7th, 1913", "life", "the 1800s", "spiral", "George Stephanopoulos", "the egg", "Vijay Singh", "geometric", "Baton Rouge", "the Wilderness Road", "Chariots of Fire", "the newt", "Sweden", "pink", "an eyelid", "Hong Kong", "The Addams Family", "measles", "Sanders", "a more expensive in-house payment plan", "Churchill", "resolution", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "Zelah Clarke", "University of Oxford", "1,467", "\"Nina\"", "abuse.", "Paul Schlesselman", "Alwin Landry", "Israel"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6026041666666666}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-11647", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-2121", "mrqa_searchqa-validation-13325", "mrqa_searchqa-validation-1930", "mrqa_searchqa-validation-925", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-7951", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-10072", "mrqa_searchqa-validation-5688", "mrqa_triviaqa-validation-7432", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-2207"], "SR": 0.53125, "CSR": 0.4849137931034483, "EFR": 1.0, "Overall": 0.6794827586206897}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "super-yacht 'Wally Island'", "Turkey would be one of the most important allies going forward.", "tells stories of different women coping with breast cancer in five vignettes.", "The U.S. Department of Housing and Urban Development", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty.", "school", "Asashoryu", "attacked L.K. Chaudhary,", "China", "\"I never thought any of this was going to be easy,\"", "Akio Toyoda", "longest domestic relay in Olympic history,", "a man's lifeless, naked body", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition,", "detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify. Military commission judges also will be able to establish the jurisdiction of their own courts.", "183", "Nirvana", "Patrick McGoohan", "55-year-old", "Zimbabwe President Robert Mugabe", "new Touch,", "Siemionow", "International Polo Club Palm Beach in Florida.", "Mugabe and Tsvangirai", "The teen faces a lifelong recovery from his injuries,", "garden and pool", "Turkey can play an important role in Afghanistan as a reliable NATO ally. The question is: How can Turkey best help.", "Polo because \"it was the sport of kings.", "Kenyan capital of Nairobi", "cancer in 2001", "Saddam Hussein's Revolutionary Command Council.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "people", "Rev. Alberto Cutie", "U.N. aid", "bookstores", "Gov. Rod Blagojevich", "Graham's wife", "February 12", "Baja California Language College in Ensenada, Mexico", "suicides", "strict interpretation of sharia forbids girls from attending school, requires veils for women and beards for men,", "trading goods and services without exchanging money -- as a way to cope with tough economic times.", "two people", "two", "Some of them told CNN they couldn't afford to pay for cable or satellite TV service.", "71 percent of Americans consider China an economic threat to the United States,", "Ben Roethlisberger", "Taylor Michel Momsen", "Nick Grimshaw", "In late - 2011", "m69", "Zaire", "pasta", "DreamWorks Animation", "Debbie Harry", "2004", "a cord", "Bob Dylan", "Existentialism", "Nancy Walker"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5632150835275835}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.8, 0.15384615384615385, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.358974358974359, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.13333333333333333, 1.0, 0.2, 0.5, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.30769230769230765, 0.0, 0.0, 0.6363636363636364, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-659", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-2297", "mrqa_newsqa-validation-2846", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-535", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-717", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-14208"], "SR": 0.46875, "CSR": 0.4846398305084746, "EFR": 1.0, "Overall": 0.6794279661016949}, {"timecode": 59, "before_eval_results": {"predictions": ["Tulsa", "Pakistan", "IndyCar Series", "Vernon Kay", "Florida", "ten episodes", "Tyler Posey", "Cartoon Network", "Scandinavian design", "Sandy Bentley", "Pasek and Paul", "toxic chemical releases", "Oregon", "\"Mrs. Eastwood & Company\"", "Blackpool Football Club", "southwest Denver, Colorado", "Ted Kennedy", "Boeing EA-18G Growler", "News Corp", "Pennsylvania's", "Danielle Steel", "1970s and 1980s", "the New York Knicks", "Hazel Keech", "NATO", "from 1952 until 1971", "authoritarian", "AOL", "World War II", "coca wine", "Barack Obama", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "approximately 45%", "Christophe Lourdelet", "Best Supporting Actress", "New Jersey", "Ian Rush", "Erich Maria Remarque", "Australian", "the youngest TV director ever", "Arthur William Bell III", "California Shipbuilding Corporation", "Delaware River", "Jean Acker", "Anheuser-Busch InBev", "MG Car Company Limited", "Boston Celtics", "May 2008", "Hungarian Rhapsody No. 2", "before November 1", "Brian Steele", "35 to 40 hours per week", "Ceefax", "Dieppe", "hanover", "the iconic Hollywood headquarters of Capitol Records,", "228", "Ali Bongo,", "stocks", "Thomas Edison", "Han Solo", "Jeannie Longo-Ciprelli"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7073784722222223}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false], "QA-F1": [0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-1512", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5535", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5286", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-1869", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-4248", "mrqa_hotpotqa-validation-2977", "mrqa_naturalquestions-validation-215", "mrqa_searchqa-validation-10636", "mrqa_newsqa-validation-153"], "SR": 0.59375, "CSR": 0.4864583333333333, "EFR": 1.0, "Overall": 0.6797916666666667}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "Joan Rivers", "'overcharged.'\"", "95.", "Carrousel du Louvre,", "Tiger Woods", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she has had no contact with the family since her daughter's death.", "Russell", "eight Indian army troopers,", "269,000", "flooding", "\"Sesame Street's\" Grover,", "Patrick McGoohan", "ambassadors", "Afghan security forces", "Arkansas weatherman", "hanged in 1979", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "people", "'overcharged.'\"", "Ferrari", "Ashley \"A.J.\" Jewell", "\"not generals but businessmen\"", "$6.9 million", "India.", "in body bags on the roadway near the bus,", "Afghanistan,", "10 to 15 percent", "His flight Monday originated in Cairo, Egypt,", "Joan Rivers", "street cleaners and firefighters.", "the shoreline of the city of Quebradillas.", "At least 15", "the wildfires", "dress", "a monthly allowance,", "Too many glass shards left by beer drinkers in the city center,", "the legitimacy of that race.", "Nigeria", "Andrew Morris,", "and renewable energy at home everyday,\"", "Drottningtorget", "the driver", "\"To do so would take hours that we don't have to give right now.", "Orcrist", "Jesse McCartney", "the American Civil War", "T.S. Eliot", "green", "Australia", "1975", "1970", "Copenhagen", "Gerry Marsden", "Khartoum", "Stand by Me", "Italian"], "metric_results": {"EM": 0.5, "QA-F1": 0.556070916473877}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.631578947368421, 0.23076923076923075, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.04761904761904762, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.25, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-2810", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-1735", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-3687", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-3118", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-2599", "mrqa_triviaqa-validation-1267", "mrqa_searchqa-validation-6409"], "SR": 0.5, "CSR": 0.4866803278688525, "EFR": 0.96875, "Overall": 0.6735860655737705}, {"timecode": 61, "before_eval_results": {"predictions": ["peanut and milk", "flying a space shuttle", "Santaquin City, Utah, home", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "Johnny Carson", "Bob Bogle", "183", "Arctic north of Murmansk down to the southern climes of Sochi", "Sunday", "Filippo In Simonehi", "Sunni Arab and Shiite tribal leaders", "Tuesday afternoon.", "General Motors'", "Four Americans", "Mark Fields", "Lula da Silva", "\"It has never been the policy of this president or this administration to torture.", "the soldiers", "the body of the aircraft", "Venus Williams", "the college campus.", "The cervical cancer vaccine,", "Bright Automotive,", "Kingdom City,", "Europe,", "44 firearms, 650 pounds of marijuana, 435 pounds of cocaine and $7.8 million in cash", "fabric technique", "Zimbabwe's main opposition party", "Newcastle", "surgical anesthetic propofol", "she was humiliated by last month's incident, in which she was forced to painful remove the piercings", "CNN", "school", "Hurricane Gustav", "The cervical cancer vaccine, approved in 2006,", "two", "outfit from designer", "the two bodies out of the plant,", "misdemeanor assault charges", "the man facing up, with his arms out to the side. He is wearing socks but no shoes.", "British Prime Minister Gordon Brown's", "1,500 Marines", "Cambodian territory", "Arsene Wenger", "The local Republican Party", "the Gulf", "former Procol Harum bandmate Gary Brooker", "27,", "The Tupolev Tu-160 strategic bombers landed at Venezuela's Libertador military airfield and \"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "housing, business and infrastructure repairs,", "to be holed up in my home,", "toys or doorbell installations", "British citizens", "Justin Timberlake", "Greece", "Brighton", "eagle", "Umberto II", "\"Vera Cruz\"", "Lucille D\u00e9sir\u00e9e Ball", "Louis XIV", "the Bronx", "flamboyant", "South Africa"], "metric_results": {"EM": 0.59375, "QA-F1": 0.702386055046175}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [0.25, 0.0, 1.0, 0.15384615384615385, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.72, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2514", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-2168", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-237", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-3250", "mrqa_newsqa-validation-531", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_hotpotqa-validation-1214", "mrqa_hotpotqa-validation-2827"], "SR": 0.59375, "CSR": 0.4884072580645161, "EFR": 1.0, "Overall": 0.6801814516129032}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0", "portrait of William Shakespeare", "California-based", "200", "rapper T.I.", "media", "Friday,", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Arizona", "Iran could be secretly working on a nuclear weapon", "assassins", "56", "Taiwan, Hong Kong and Mongolia,", "His former Boca Juniors teammate and national coach Diego Maradona,", "Fernando Caceres", "Ferraris", "Kurt Cobain", "best-kept summer secret.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "a residential area in East Java", "\"Body Works\"", "diplomatic relations", "supermodel", "17", "1,073", "children that a French charity attempted to take to France", "fled Zimbabwe", "girls", "Israel", "food, music, culture and language of Latin America", "cancerous tumors.", "Tennessee.", "Bright Automotive,", "nuclear", "changed the business of music, to offering the world its first completely full-length computer-generated animated film with Animated's \" Toy Story\"", "\"Up,\"", "165-room", "whose daughter and granddaughter attend Oprah Winfrey's school in South Africa", "al Qaeda,", "the jury", "Susan Atkins", "Charlotte Gainsbourg and Willem Dafoe", "the infant who became the center of an international end-of-life debate,", "Omar", "China", "United States", "Nakheel Tower", "speaking out about a cause someone feels passionate about.", "25", "Anil Kapoor", "President Obama and Britain's Prince Charles", "Wembley Stadium", "a modulator molecule ( or allosteric regulator ) binds", "9.0 -- 9.1", "whooping cough", "Exile", "Mollie Ralston", "Robert Arthur Mould", "331", "the end", "Ruth Bader Ginsburg", "Long & his goodbye", "Seth", "peacock"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5405210802269627}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, false, false, false, true, false, true, false, false, false, false, true, true], "QA-F1": [0.6666666666666666, 0.4, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 0.9333333333333333, 0.0, 1.0, 0.15384615384615385, 0.4615384615384615, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.11764705882352942, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.26666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-1371", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-4598", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746"], "SR": 0.4375, "CSR": 0.4875992063492064, "EFR": 1.0, "Overall": 0.6800198412698413}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the Dalai Lama", "was killed by a police sniper's bullet", "to help women \" learn how to dance and feel sexy,\"", "the German Foreign Ministry,", "protective shoes", "Ten South African ministers and the deputy president", "Pakistan", "Japanese officials", "urged NATO to take a more active role in countering the spread of the", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "bench", "Sixteen", "poems telling of the pain and suffering of children just like her; girls banned from school, their books burned,", "(3 degrees Fahrenheit),", "Technological Institute of Higher Learning of Monterrey,", "Baseball Hall of Fame", "Golden Gate Yacht Club of San Francisco", "nearly 100", "a national telephone survey of more than 78,000 parents of children ages 3 to 17.", "ballots", "and renewable energy at home everyday,\"", "the Obama and McCain camps", "The Ministry of Defense", "part of the proceeds", "The minister later apologized, telling CNN his comments had been taken out of context.", "In a superb individual goal from midfielder Nani in the 27th minute as the Portugal international waltzed into the box and drilled in a low shot.", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars.\"", "civilians,", "March 3,", "peanuts, nuts, shellfish and fish tend to be lifelong,", "Dolgorsuren Dagvadorj,", "bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "could be secretly working on a nuclear weapon", "Buddhism, which consists of completing hundreds of hours of meditation in a short period of time.", "anti-Mafia judges Giovanni Falcone and Paolo Borsellino.", "after the president overturned the Cabinet's decision to sack the army chief.", "tranquil beaches,", "$1.5 million.", "Booches Billiard Hall,", "\"peregruzka\"", "for an independent homeland since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama : Revenge of the Island", "Kimberlin Brown", "a turlough, or turlach", "1910", "richard attenke", "Radio City Music Hall", "Vikram, Jyothika and Reemma Sen", "the Dutch Empire", "Royal Navy rank of Captain", "Department of Homeland Security", "France", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6064619939491642}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.0, 0.8235294117647058, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.14285714285714288, 0.0, 1.0, 0.10526315789473684, 0.0, 1.0, 0.0909090909090909, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.08695652173913043, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.4444444444444445, 1.0, 0.5, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-3886", "mrqa_newsqa-validation-1261", "mrqa_newsqa-validation-3075", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-2470", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-1127", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3692", "mrqa_newsqa-validation-2645", "mrqa_newsqa-validation-967", "mrqa_newsqa-validation-2353", "mrqa_newsqa-validation-372", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-7047", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_naturalquestions-validation-10396"], "SR": 0.515625, "CSR": 0.488037109375, "EFR": 1.0, "Overall": 0.6801074218750001}, {"timecode": 64, "before_eval_results": {"predictions": ["Brad Blauser,", "always be sportswear,", "15-year-old", "July 23.", "Alwin Landry", "a Korean-American missionary", "Chester Arthur Stiles,", "'overcharged.'\"", "Pakistan's High Commission in India", "Wednesday's", "Egyptian striker", "Adriano", "poems", "\"His information is not some big break in the case,\"", "Julissa Brisman,", "to sniff out cell phones.", "Longo-Ciprelli", "Switzerland", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944,", "\"I'm just getting started.\"", "precipitation", "more than 30", "his whole salary earned as a public official on public welfare,\"", "adopted new and more restrictive policies,", "laundromats", "rural California,", "Robert Park", "the 11th year in a row.", "83 eggs.", "future relations with Washington", "school.", "a plaque at the home of his great-grandfather", "authorizing killings and kidnappings by paramilitary death squads.", "a nuclear weapon", "Kitty Kelley", "\"The missile defense system is not aimed at Russia,\"", "Grand Ronde, Oregon.", "at the Stanlow oil refinery in western England,", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "stuck to with remarkably little internal drama.", "$3 billion,", "video", "Larry King", "\"explosion of violence.\"", "over ownership of the Falklands.", "Sen. Barack Obama", "jobs", "angular rotation", "360 \u00b0 - system", "Darlene Cates", "Colette", "crows", "douglas", "21 July 2015", "11", "January 15, 2016", "piano", "Palestine", "Barnard", "Chiltern Hills"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5134695165945167}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, true, false, false, true, true, false, false, true, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.36363636363636365, 1.0, 0.6666666666666666, 0.4, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.3888888888888889, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-3055", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-2205", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2349", "mrqa_newsqa-validation-980", "mrqa_newsqa-validation-8", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3859", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-1988", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-2333", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516"], "SR": 0.4375, "CSR": 0.4872596153846154, "EFR": 1.0, "Overall": 0.6799519230769231}, {"timecode": 65, "before_eval_results": {"predictions": ["banned substance cortisone.", "Larry King", "The Ski Train", "housing, business and infrastructure repairs,", "Brian Smith.", "Port-au-Prince harbor", "South Korea", "Israel", "Nigeria,", "Mexico", "two Metro transit trains", "short- and long-range weapons", "Denver", "\"He hears what I'm saying, but there's just no coming through,\"", "the single-engine Cessna 206", "no need for such humility.", "police", "could be secretly working on a nuclear weapon", "Harris, whose real name is Clifford Harris, was arrested without incident in midtown Atlanta.", "Carol Kelley,", "Republican senators", "\"I'm certainly not nearly as good of a speaker as he is.\"", "April 22.", "Manuel Mejia Munera", "outfit from designer", "five", "Ozzy Osbourne", "Sarah,", "Steven Chu", "pro-democracy activists", "eight.", "Fullerton, California,", "Hawaii", "Bill Haas", "\"A Lion Among Men.\"", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Zapata Reyes,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Kr\u00f8yer", "Narayanhiti Royal Palace", "Arlington National Cemetery", "Adam Yahiye Gadahn,", "Turkey", "his company Polo because \"it was the sport of kings.", "Texas", "books and CDs and DVDs.", "her resources", "a million", "her 8th-grade graduation,", "A 19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "it -- you know -- black is beautiful,\"", "serialism", "N\u0289m\u0289n\u0289", "Delivery of the genome is also important by specific binding to external receptors of the host cell", "Einstein", "Nova Scotia", "pyrotechnic", "the Battelle Energy Alliance", "Chicago, in Lake County, Illinois", "Eran Kolirin.", "sea-monkeys", "Clemson University", "Herod", "leopard"], "metric_results": {"EM": 0.453125, "QA-F1": 0.580406746031746}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false], "QA-F1": [0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.09523809523809523, 0.0, 0.22222222222222224, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3233", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4053", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-498", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-10519", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_hotpotqa-validation-3069", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.453125, "CSR": 0.4867424242424242, "EFR": 1.0, "Overall": 0.6798484848484849}, {"timecode": 66, "before_eval_results": {"predictions": ["Melbourne.", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "uranium enrichment activities.", "U.S. Army", "a space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Columbia, Missouri.", "Both men were hospitalized and expected to survive,", "Harris won two awards", "Pfc. Bowe Bergdahl", "many different", "President Bush", "$530 million,", "the Employee Free Choice act", "Sadat signed the Camp David peace treaty with Israel", "Thomas, 48,", "The worst snowstorm to hit Britain", "the wisecracking youngster Arnold Drummond on TV's \" Diff'rent Strokes\" from the late 1970s to the mid-1980s.", "Madonna", "look at the content of the speech, not just the delivery.", "the Bush administration's controversial system of military trials for some Guant Bay detainees.", "a traditional form of lounge music that flourished in 1940's Japan.", "Larry King", "250,000", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "managing his time.", "for close to 5,000 percent,", "Omar", "Scotland Originating from the bogs of Finland,", "Mugabe's opponents", "The Hutus were considered inferior,", "\"the subjects of an active investigation by the Indiana Securities Division,\"", "January", "The Great Barrier Reef -- which is composed of about 2,900 individual reefs and is off the northeast coast of Australia", "Millvina Dean,", "Dwayne Carter, as he is known legally, pleaded guilty to felony gun charges in a deal with prosecutors October 2009.", "Sovereign Wealth Funds", "fake his own death by crashing his private plane into a Florida swamp.", "The blaze comes nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "Apple Inc.", "38,", "terrorists operating within its borders.", "Henrik Stenson", "in 1995", "\"The Angels family has suffered a tremendous loss today,\"", "depression", "Goa", "Why he's more American than a German,", "\"We've got more work to do to ensure that government treats all its citizens equally, to fight injustice and intolerance in all its forms and to bring about that more perfect union,\"", "demonstrations", "American Indian allies", "Naturalization Act of 1790", "el Cid of Castile", "blancmange", "apples with red skins", "Sandia National Laboratory", "Dr. Gr\u00e4sler, Badearzt", "cancer", "Joplin", "Italy", "potomac", "Balaam then sets out in the morning with the princes of Moab"], "metric_results": {"EM": 0.359375, "QA-F1": 0.47647713221762134}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.2222222222222222, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.33333333333333337, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.07407407407407407, 0.0, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 0.0, 0.043478260869565216, 0.4, 0.0, 0.28571428571428575, 0.0, 1.0, 0.4, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-3301", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-1140", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-1088", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-7350", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_searchqa-validation-12973", "mrqa_naturalquestions-validation-230"], "SR": 0.359375, "CSR": 0.48484141791044777, "EFR": 1.0, "Overall": 0.6794682835820895}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "siegfried", "candles", "Jaipur", "tea", "Palaeozoic Era", "Martin Pipe", "Wordsworth", "Ginger Rogers", "theatre", "sodium tetraborate decahydrate", "United States Dollars", "peregrines", "Dm", "Type I muscle, Type II A and Type II B", "Track & Field", "Derby Stakes", "Easter Parade", "Basketball", "HMS Amethyst", "pig", "sargfried", "the Colonel Bogey March", "Cyprus", "King George VI", "ankle joint", "Skye terrier", "man-made", "flea", "white robe", "Big Bopper", "NBA", "L. P. Hartley", "Leander", "siegfried", "randomness", "Miss Scarlet", "green", "Amelia Earhart", "James Hogg", "lacrimal fluid", "Loki", "The Virgin Spring", "Max Immelmann", "Cain", "1879", "Los Angeles", "Loch Ness", "isosceles", "black", "ballet", "the New York Yankees", "1967", "thermodynamic temperature", "Bolshoi Theatre", "My Boss, My Hero", "mermaid", "death squad killings", "Atlantic Ocean.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "the bumblebee", "12 to 36 months"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6423498376623377}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-153", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-1541", "mrqa_triviaqa-validation-2717", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-497", "mrqa_triviaqa-validation-2825", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_naturalquestions-validation-8352"], "SR": 0.609375, "CSR": 0.4866727941176471, "EFR": 1.0, "Overall": 0.6798345588235295}, {"timecode": 68, "before_eval_results": {"predictions": ["hotel barge", "smen", "the northern borders of West Virginia and Kentucky", "the Americans", "Australia", "2018", "California's Del Norte Coast", "Zebra", "257,083", "southwestern part of the island", "the Anglo - Saxon King Harold Godwinson", "the Allies", "Shawn", "if the concentration of a compound exceeds its solvents", "the Soviet Union", "1623", "the eye ( of ) round", "1957", "360", "electron shells", "through a series of ducts", "Lori McKenna", "Wisconsin", "Tbilisi", "to indicate a temperature interval, a difference between two temperatures or an uncertainty", "1799", "The Epistle of Paul to the Philippians", "His last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles", "Elvis Presley", "2009", "Best Picture", "long - standing policy of neutrality", "291 episodes", "Cairo, Illinois", "Lana Del Rey", "spacewar", "22", "4 January 2011", "New Zealand to New Guinea", "Boston Celtics center Bill Russell", "Seattle, Washington", "the pituitary gland", "2014", "Buddhism", "the 7th century", "semi-autonomous organisational units", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "1956", "decem", "mwestwood", "huff & puff", "Brad Silberling", "1941", "Nick on Sunset theater in Hollywood", "July", "new Touch,", "from another Latin American country comes and imposes him with arms.", "bonobo", "toward the front", "the Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5699771246898264}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.16666666666666666, 1.0, 0.14285714285714288, 1.0, 0.25, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.7692307692307692, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.5714285714285715, 0.3076923076923077, 1.0, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-10704", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-2251", "mrqa_newsqa-validation-3931", "mrqa_searchqa-validation-12035"], "SR": 0.453125, "CSR": 0.48618659420289856, "EFR": 0.9714285714285714, "Overall": 0.674023033126294}, {"timecode": 69, "before_eval_results": {"predictions": ["Whitechapel", "Uganda", "definitely maybe", "Brazil", "Pleiades", "64 squares", "bristol", "Sunshine State", "pink", "tin", "Anita Roddick", "e pluribus unum", "Black Swan", "Ely", "deuteranopia", "Cambodian", "Prussian Landsturm", "Russia", "1925 novel", "cooperative", "180", "blue", "Marvin Hart", "Judi Dench", "Andre Agassi", "goshawk", "The Times", "john le Carr\u00e9", "Papua New Guinea", "Albania", "zoological", "mata hari", "needs", "polo", "gulliver", "Standard & Poor's", "Saturday Night Live", "Bayern Munchen", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "Cleopatra", "barrels", "One Canada Square", "Snoopy", "corvidae", "Hunting of the Snark", "mineworkers", "Tokyo Metropolitan Assembly", "siegfried", "Walter Mondale", "the reactor core", "the plane crash in 1959", "Scotty Grainger Jr.", "The Kingkiller Chronicle", "3.9 mi", "$1.5 million.", "Christianity and Judaism,", "took her own life.", "Space Shuttle orbiter", "Smithfield", "Aleksandr Solzhenitsyn", "10 Years"], "metric_results": {"EM": 0.5, "QA-F1": 0.5463068181818183}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-3373", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-3541", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-9025"], "SR": 0.5, "CSR": 0.48638392857142854, "EFR": 1.0, "Overall": 0.6797767857142858}, {"timecode": 70, "before_eval_results": {"predictions": ["mrs michael caulkins", "three", "high jump", "Albert Einstein", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "grapevine", "teaching evolution", "Philip Larkin", "wropshire", "Kent", "rabbit", "Jack Brabham", "Peterborough Independent Supporters Association", "hanover", "fundamental square root", "canary", "Pete Sampras", "Prussia", "Red sea", "cats", "The French Connection", "George Orwell", "chamber of Secrets", "Milan", "Dubai", "ceeLo green", "photography", "Justin Bieber", "Greece", "Mahjong", "scar", "\"Stars on 45 Medley\"", "richmond & Gloucester", "Jim Bowie", "turkish", "Margaret Streep", "Achille Lauro", "anthony greig", "stop motion effects", "Claremorris", "Ellis Island", "the South Pacific Ocean", "trapezoid", "Dick Advocaat", "john Huston", "starry starry night", "Anthony Hopkins", "George W. Bush", "Moscow", "1988", "Jim Justice", "Spanish", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman is in critical condition", "2009", "Uzbekistan.", "Jerry Rice", "leotard", "Ford", "hips"], "metric_results": {"EM": 0.53125, "QA-F1": 0.56875}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-6644", "mrqa_triviaqa-validation-841", "mrqa_triviaqa-validation-6805", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-1704", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-3881", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-7032", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_naturalquestions-validation-10001", "mrqa_naturalquestions-validation-4207", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3653", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-2817"], "SR": 0.53125, "CSR": 0.4870158450704225, "EFR": 1.0, "Overall": 0.6799031690140845}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "The Inside Story of America's Race to the Moon", "Kim Sung-su,", "Burma", "French, English and Spanish.", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "Aerol\u00edneas Argentinas", "October 15, 2013.", "Neha Sharma", "Japan", "Quentin Coldwater, a young man who discovers and attends a college of magic in New York.", "1812", "Kew", "Apprendi v. New Jersey", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "Kristin McGee", "11", "tempo", "7 miles", "2016", "Pollywood", "Dana Andrews", "July 25 to August 4", "1950s", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "Major League Soccer", "The special economic zone (SEZ)", "Darkroom", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001,", "detention camp", "France", "Wordsworth", "spain", "give detainees greater latitude in selecting legal representation", "\"wipe out\" the United States if provoked.", "two years,", "Yahtzee", "Hinduism.", "60 Minutes", "The closest approach to the original sound"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7776041666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-4051", "mrqa_hotpotqa-validation-1398", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-4412", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.71875, "CSR": 0.490234375, "EFR": 1.0, "Overall": 0.680546875}, {"timecode": 72, "before_eval_results": {"predictions": ["the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "showed such a disregard for the life and safety of others as to amount to a crime and deserve punishment", "around 100,000", "2004", "the NFL", "in Latin manuscripts of the First Epistle of John at 5 : 7 -- 8", "Bob Dylan, George Harrison, Jeff Lynne", "Tony Orlando and Dawn", "2014 Winter Olympics in Sochi, Russia", "Pir Panjal Range in Jammu and Kashmir", "with nearby objects", "Kansas", "1881", "the final episode of the series", "Wisconsin", "the motion of the continents is linked to seafloor spreading", "the stems and roots of certain vascular plants", "Mahalangur Himal sub-range of the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "the Rock", "The 111th edition of the World Series", "Massachusetts", "Mark Jackson", "Jack Van Hay", "antimeridian", "visible cross", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane, resulting in an electrical potential or ion concentration difference across the membrane", "Kida", "Selena Gomez", "an iron -- nickel alloy and some other elements", "Christopher Allen Lloyd", "Procol Harum", "Tom Smothers", "the federal government", "2005 novel The Book thief by Markus Zusak", "Wembley Stadium and Olympic Stadium", "Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "the cell is undergoing the metaphase of cell division", "73", "Bosnia and Herzegovina", "the resting phase", "1853", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "seven", "Ben Savage", "No. 16 seed", "Josh Hutcherson", "Daya Jethalal Gada", "system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "Gunpei Yokoi", "the Alamodome", "Amy Johnson", "post-modernism", "Bermuda", "win world titles in all four of the lowest weight classes", "their unusual behavior, such as the number of men killed and the manner of the attacks.", "Neymar", "22", "opium", "Roger Federer", "satirical", "a prostitute", "Ashlee Simpson", "italy"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5204488245618759}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, true, true, false, false, true, true, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.8095238095238095, 0.15384615384615385, 1.0, 1.0, 0.0, 0.5, 1.0, 0.2857142857142857, 1.0, 0.5, 1.0, 0.4, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666667, 0.25, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8235294117647058, 0.375, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1694", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9551", "mrqa_naturalquestions-validation-8610", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-1909", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_triviaqa-validation-5754", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-2034", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-15285", "mrqa_searchqa-validation-3407", "mrqa_triviaqa-validation-4962"], "SR": 0.421875, "CSR": 0.4892979452054794, "EFR": 1.0, "Overall": 0.6803595890410958}, {"timecode": 73, "before_eval_results": {"predictions": ["The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person", "Kirstjen Nielsen", "May 2017", "Barbara Windsor", "ninth w\u0101", "British Ultra code", "Bart Millard", "Jesse Wesley Williams", "Lucius Verus", "1910", "Munilla Construction Management", "John Smith", "Joanne Wheatley", "`` Everywhere ''", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "India", "Taylor Michel Momsen", "Magnavox Odyssey", "The Lightning Thieves", "2015", "1971", "Sara Gilbert", "1962", "Help!", "John Smith", "Norman Thayer Jr", "Arnold Schoenberg", "the Election Commission of India", "203", "Sam and Dean help him he will return Sam's soul, but if they don't help him they will send Sam back to Hell", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Cecil B. DeMille", "1878", "to `` help bring creative projects to life ''", "Joan Baez", "Joseph Nye Welch", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Sichuan", "wooden", "Kevin the Gerbil", "Tampa", "1874", "January 28, 2016", "Jaipur", "fifth", "July", "taro", "The Match Game", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7253720238095238}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true], "QA-F1": [0.8666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-8183", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-4104", "mrqa_naturalquestions-validation-9644", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2866", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-249", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-270", "mrqa_searchqa-validation-2100"], "SR": 0.640625, "CSR": 0.4913429054054054, "EFR": 0.9565217391304348, "Overall": 0.6720729289071681}, {"timecode": 74, "before_eval_results": {"predictions": ["Raiders", "Russell Stover", "a circle", "a franchise", "the Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "the masses", "Pakistan", "a blitz", "New Wave", "a commune", "a ring", "the Thames", "a chanteuse", "hockey", "Denmark", "David", "The Color Purple", "whales", "Jane Addams", "Queen Elizabeth", "Tanzania", "Biosphere 2", "an inch", "Dasein", "Henry Wadsworth Longfellow", "Fred Thompson", "Geneva", "humility", "white", "Twelve Thirty", "D.E., diatomite", "$9", "swing", "Titicaca", "Existentialism", "ashes", "Julius Caesar", "George Freeth", "Isaac Newton", "Charles I", "Kevin Costner", "Antichrist", "a clef", "uranium", "Louisiana", "The Hot Chick", "composting", "2016", "January 15, 2010", "four", "Spey", "Popeye", "Denmark", "Eleven monasteries", "4,530", "Steve Prohm", "six", "the Airbus A330-200", "the self-styled revolutionary Symbionese Liberation Army", "Manitobaowoc"], "metric_results": {"EM": 0.609375, "QA-F1": 0.66015625}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14913", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-14823", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-9751", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-15658", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-7832", "mrqa_naturalquestions-validation-8909", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-1307", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-1572", "mrqa_hotpotqa-validation-3458"], "SR": 0.609375, "CSR": 0.49291666666666667, "EFR": 1.0, "Overall": 0.6810833333333334}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "James Bolam", "the main highway entrance at California State Route 1,", "The term `` AWD '', or all - wheel drive, is used for any vehicle which drives on all four wheels, but may not be designed for off - road use", "Turing", "John B. Watson", "hydrogen", "Spain", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "the 9th century", "Asuka", "Jason Momoa", "John Pyper - Ferguson", "the President", "Spanish missionaries", "Gustav Bauer", "art of Persian Safavid dynasty from 1501 to 1722", "white blood cell in a vertebrate's immune system", "around 2.45 billion years ago ( 2. 45 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "Golde", "March 31, 2017", "a small synovial joint between the malleus ( hammer ) and the incudomalleolar joint", "born November 28, 1973", "Gupta Empire", "a half - life of 10.756 years", "3 ( 55 -- 69 % ) & 4 ( 40 -- 54 % )", "the summer of 1979", "John Roberts", "Spanish / Basque", "Arlington National Cemetery in Virginia, United States of America", "December 1349", "Glenn Close", "Robert Remak", "the Yankees", "Joseph came up with the band's name while studying All My Sons by Arthur Miller", "International System of Units", "Rigg", "the synthesis of adenosine triphosphate ( ATP ), a molecule that stores energy chemically in the form of highly strained bonds", "Bill Patriots", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "the underground organization of the Irish Republican Brotherhood", "Lake Windermere", "1967", "Yubin, Yeeun", "1912", "sedative.", "the sailboat", "'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's Disease", "Patrick Henry", "Samuel Joel \" Zero\" Mostel"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6910461216886301}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.9032258064516129, 0.0, 1.0, 0.3157894736842105, 0.0, 1.0, 0.0, 0.5, 0.5, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.888888888888889, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-5882", "mrqa_naturalquestions-validation-7514", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-2810", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-2232", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-2348", "mrqa_hotpotqa-validation-3909"], "SR": 0.578125, "CSR": 0.4940378289473685, "EFR": 0.9629629629629629, "Overall": 0.6739001583820663}, {"timecode": 76, "before_eval_results": {"predictions": ["Tintoretto", "Scotch", "repechage", "Scotland", "Victoria Rowell", "Costa Brava", "Northumberland", "poultry", "Toby", "SS Normandie", "Bleak HouseBleak House", "four", "indus valley", "photo-sharing", "jaws", "Charlie Cairoli", "Hague", "Adidas", "Coldplay", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "antipope", "Patrick Kielty", "about 3 minutes", "Joey Tribbiani", "Red Crescent ambulance", "Robin Ticciati", "Margaret Thatcher", "Hooky Street", "Sam & Mark", "Andrew Lloyd Webber", "Bonn", "lieutenant general", "snake", "coral sea", "David", "Madonna", "a hole-in-one", "beer", "elbow", "Ice Age", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Desdemona", "Hawley Harvey", "fifty-six", "196 BC", "1979", "1976", "Gupta Empire", "Rogue One: A Star Wars Story", "2004", "Rwandan genocide", "Steve Williams", "winter storm", "the death of Kandi Burruss' former fianc\u00e9, Ashley \"A.J.\" Jewell,", "seasonal affective disorder", "a timing gun", "Vienna", "four years"], "metric_results": {"EM": 0.546875, "QA-F1": 0.600390625}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, false, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6962", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-7046", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-1430", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2600", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-1839", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-1278", "mrqa_triviaqa-validation-1602", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_triviaqa-validation-3403", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.546875, "CSR": 0.494724025974026, "EFR": 1.0, "Overall": 0.6814448051948052}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1884", "Queensland", "M2M", "Helen Mirren", "FX", "president of Guggenheim Partners", "Diamond Rio", "Lola Dee", "New York State Route 908F", "UFC 50: The War of '04", "a heroine who experienced many tragedies, mostly at the hands of her controlling ex-husband, the villainous James Stenbeck ( Anthony Herrera)", "Rounders", "24 hours a day and 7 days a week", "O", "half of the Nobel Prize", "glee", "Chris Pratt and Neil Corbould", "intelligent design advocate", "2 November 1902", "March", "Daughter of Saint John of Gom\u00e9ia", "2006", "highest commissioned SS rank", "Dziga Vertov", "Loch Lomond", "National Football League", "brothers", "James Franco", "London", "Kelly Bundy", "British", "Spitsbergen in Svalbard, Norway", "followed his father into the Military Band of Hanover, before migrating to Great Britain in 1757 at the age of nineteen", "around 8000 BC", "1982", "Peter O'Toole", "Australia women's national soccer team", "Leonarda Cianciulli", "5% abv draught beer", "Biola University", "drama", "response-oriented therapy", "John Surtees", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau", "A bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Joanne Wheatley", "Mel Gibson", "1980s", "San Francisco", "michelle Dill", "Vancouver", "onto the college campus.", "$106,482,500", "15-year-old's", "Cleopatra", "Chevron", "JANE KOKAN", "green tambourine"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6828399843148842}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, false, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3076923076923077, 0.7499999999999999, 0.21052631578947367, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8000000000000002, 0.8, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.34782608695652173, 1.0, 0.0, 1.0, 0.8000000000000002, 1.0, 0.0, 1.0, 0.0, 0.5, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-3829", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-2907", "mrqa_triviaqa-validation-6460", "mrqa_searchqa-validation-4417", "mrqa_searchqa-validation-5368"], "SR": 0.5625, "CSR": 0.4955929487179487, "EFR": 1.0, "Overall": 0.6816185897435898}, {"timecode": 78, "before_eval_results": {"predictions": ["the sidewalk between Division Street and East Broadway", "14 June 1940", "Nigel Lythgoe", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "1956", "Atlanta, Georgia", "management team", "The legislation made two amendments to the Social Security Act of 1935", "1990", "Ali", "1980", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "skeletal muscle", "the process always begins when energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "September 1947", "April 10, 2018", "internal reproductive anatomy", "December 14, 2017", "September 19, 1977", "DNA replication", "1956", "between 8.7 % and 9.1 %", "Symphony No. 40 in G minor", "Divyanka Tripathi", "Queenstown ( now Cobh ) in Ireland", "Einar Bj\u00f8rndalen", "31 December 1960", "following graduation with a Bachelor of Medicine, Bachelor of surgery degree and start the UK Foundation Programme", "the winter solstice", "from 1992 to 2013", "George Strait", "All Hallows'Day", "November 1961", "midpiece", "2009", "$19.8 trillion", "7000301604928199000", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "St. Louis Cardinals", "Dorothy Gale", "Sachin Tendulkar", "the peacekeeping force", "Andrew Lloyd Webber", "cat", "Q", "Shadow Foreign Secretary", "sheepskin", "5,922", "1866", "2", "2006,", "nine", "Lake Superior", "River Thames", "Charles Gounod", "red"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6471742105933282}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.06060606060606061, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.8823529411764706, 0.0, 1.0, 0.5, 0.4, 1.0, 0.28571428571428575, 1.0, 0.0, 0.5, 0.5714285714285715, 0.0, 0.8, 1.0, 0.0, 0.4, 0.4, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2832", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-1538", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-10620", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5102", "mrqa_newsqa-validation-3539", "mrqa_newsqa-validation-3297", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-10079", "mrqa_searchqa-validation-1302"], "SR": 0.53125, "CSR": 0.49604430379746833, "EFR": 1.0, "Overall": 0.6817088607594937}, {"timecode": 79, "before_eval_results": {"predictions": ["memoir", "The 2003 LSU Tigers football team represented Louisiana State University (LSU) during the 2003 NCAA Division I-A football season", "1858", "heavy metal", "Edison Koon-hei Chen", "1875", "The satirical News Network", "his most brilliant student", "Juilliard School", "The 1st World Outgames", "1812", "Peach tree", "1952", "Oregon Ducks", "Victorian England", "The War of '04", "Australian", "The fictional character Spider-Man, a comic book superhero created by Stan Lee and Steve Ditko and featured in Marvel Comics publications,", "Alpine climate and landscapes, in particular for skiing and mountaineering", "Baudot code.", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "Sydney", "NCAA Division I Football Bowl Subdivision", "motor ships", "\"an unusually impressive imposter\"", "Shameless", "from 1241 until his death in 1250", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1926", "London", "Bulgarian-Canadian", "James Mitchum", "Nick on Sunset theater", "Ken Rutherford", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "the giant jellyfish or the hair jelly", "Byzantine Greek culture and Eastern Christianity", "Max", "smeagol", "Melbourne", "paddington bear", "8,", "Muslim Eid-ul-Adha", "\"This is not something that anybody can reasonably anticipate,\"", "Richmond, Virginia", "Venezuela", "the Stone Age", "rally"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6994619963369964}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 0.0, 0.1, 0.4615384615384615, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.33333333333333337, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4744", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-808", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-3221", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-3440", "mrqa_hotpotqa-validation-4171", "mrqa_hotpotqa-validation-3388", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-4416", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_searchqa-validation-11106", "mrqa_newsqa-validation-4059"], "SR": 0.578125, "CSR": 0.4970703125, "EFR": 1.0, "Overall": 0.6819140625}, {"timecode": 80, "before_eval_results": {"predictions": ["Tribune", "the chardonnay", "\"Silent Cal\"", "beach volleyball", "American singer-songwriter John Mellencamp", "hot springs", "Wizard", "PlayStation", "pro bono", "President George W. Bush", "epitaphic", "hobbit", "a dragon", "rats", "Sorbonne", "The Merry Wives of Windsor", "kowtow", "Mars", "a finches", "Brazil", "Mars", "Jericho", "Jane Addams", "Johnny Depp", "Punch", "Mountain Dew", "alchemy", "Lon Chaney", "pane", "a katzenjammer Kids", "Cuisinart", "travertine", "Robert Dole", "the Ross Ice Shelf", "director", "America", "the coast", "Pinocchio", "the Czech Republic", "the Opera house", "a bison", "go in Gr", "Alex Rover", "Cleopatra VII", "the Mummy", "Buck", "the bollworm", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "June 3, 1937", "53", "The Lightning Thief", "Brazil", "Edinburgh", "georgia", "Christina Claire Ciminella", "University of California", "Saturday Night Live", "Sheik Mohammed Ali al-Moayad", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy", "Joanne Wheatley"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5776041666666667}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9625", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-14558", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-11708", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813"], "SR": 0.53125, "CSR": 0.4974922839506173, "EFR": 1.0, "Overall": 0.6819984567901234}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "Tasmanian", "Indonesia", "The Generation Game", "A Few Good Men", "redhead", "fourteen", "Spanish", "Georgia", "Olivia Smith", "panda", "bread and wine", "Turkey", "Anastasia Dobromyslova", "every ten years", "Matterhorn", "Lake Placid", "$50", "Liverpool", "Count Basie", "Manhattan", "arch", "Esmeralda's Barn night", "Abu Dhabi", "India", "Mallard", "Ambroz Bajec-Lapajne", "Apollo", "1963", "Bologna", "grizzly Adams", "Coleraine", "Joe", "Timothy", "Addis Ababa", "motorcycle", "kidney", "Triumph", "salsa", "Mark Twain", "episode of season one", "Yosemite", "Microsoft", "40", "First World War", "purple", "USS Thresher", "7", "southampton", "100 years", "Pope Benedict XVI", "Dean Roland", "Orlando", "LED illuminated", "41st", "Mel Blanc", "Mauthausen-Gusen", "entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "antihistamine and an epinephrine", "children's", "Danny Elfman", "Bolivia", "a leap year", "Wyatt Earp"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5959602591036415}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.33333333333333337, 0.19999999999999998, 1.0, 1.0, 0.0, 0.11764705882352941, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-4361", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-3650", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-14665"], "SR": 0.53125, "CSR": 0.49790396341463417, "EFR": 0.9666666666666667, "Overall": 0.6754141260162603}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "GZA of Wu-Tang Clan", "Illinois", "1,691", "Melville, NY, USA", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "local level banking organizations", "Tufts University", "Hammer", "Sir Christopher Wren", "Isla de Xativa", "his uncle", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Akosua Busia", "5.3 million", "six", "a polypeptide chain", "Brady John Haran", "Minette Walters", "Syracuse University", "first", "Florida Panthers", "2010", "Hallett Cove", "Juan Manuel Mata Garc\u00eda", "Malayalam", "Pittsburgh Steelers", "pronghorn", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "American actor, comedian, screenwriter, and film producer", "the Kentucky Music Hall of Fame", "Taoiseach", "50 Greatest Players in National Basketball Association History (also referred to as NBA's 50th anniversary All-Time Team or NBA's Top 50)", "American", "the Corps of Discovery, with William Clark", "pubs, bars and restaurants", "Andrew Johnson", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "over 80% of the vote", "illnesses", "Thomas Joseph \"T. J. Lavin", "the bank's own funds", "16 December 1908", "President Lyndon Johnson", "Celsius", "pertussis", "Johannesburg", "admitting they learned of the death from TV news coverage,", "Juri Kibuishi, 23, of Irvine, police", "the sins of the members of the church,", "Superman (It\\'s not Easy)", "Nixon", "an obtuse angle", "hms Warfield Simpson"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6445381576038904}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.5517241379310345, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.0, 1.0, 0.4, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-4045", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-605", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2045", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5115", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-1186", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-8087", "mrqa_searchqa-validation-5760", "mrqa_triviaqa-validation-3774"], "SR": 0.53125, "CSR": 0.49830572289156627, "EFR": 1.0, "Overall": 0.6821611445783133}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys:", "Mantle & Maris", "the Titanic disaster", "Ecosystem Services Flows", "Bill Clinton", "Graceland", "Cambodian Peak", "a elevator", "David Copperfield", "Schwarzenegger", "\"Jabberwocky\"", "W", "a goatherd", "a Beautiful Mind", "the union", "a Vampire Project", "the Horn of Africa", "a wind instrument", "Mrs. Miniver", "The Office", "Italy", "a keynote", "a sheep", "Casey Jones", "\"Coward\"", "Hope", "the navy", "Dresden", "a flippant", "Arkansas", "Marcel Duchamp", "a pillage", "toilet paper", "sesame seeds", "New Zealand", "\"to play dead\"", "Right to Your Door", "a bees", "Janet Reno", "a solar eclipse", "Gianlorenzo Bernini", "Essen", "Clover Hill", "Thailand", "Lazarus", "a cereal", "Pamela Anderson", "Dr. Seuss", "JUNEAU", "Scott McClellan", "Edd Kimber", "six", "Steffy Forrester", "Twin sisters", "John Denver", "Gargantua", "2017", "four", "Lester", "India", "1959", "two", "her abusive husband"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6895833333333334}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-3848", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-15322", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-12607", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-3590"], "SR": 0.65625, "CSR": 0.5001860119047619, "EFR": 1.0, "Overall": 0.6825372023809524}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony", "roof", "Cuisinart", "the lungs", "the Bloody Massacre", "shredded", "Simon Bolivar", "Little Red Riding Hood", "Abigail Adams", "the Bank of America", "Cleopatra", "Colorado", "a diamond", "Pablo Picasso", "Arlington House", "Pope John Paul II", "the hood", "Aulis", "South Dakota", "natural selection", "Department of the Interior", "the king", "the White King", "Schembechler", "Gucci", "Vermont", "a chimp", "Mixtikl 7", "The Man in the Iron Mask", "New Zealand", "Heidi Klum", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Doctor Moreau", "an organ", "wheat", "tundra", "Peter Falk", "AARP", "JEWELRY", "\"the Flag of the United States of America\"", "herb", "stiletto", "cheese", "University of Kentucky", "Bora Bora", "Titanic", "1760", "the \"Fisherman\\'s ring\"", "RBIs", "Continuous Linked Settlement", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "bach", "london", "34.9 miles", "California Adventure", "Acharacle", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe", "baku"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6901127518315018}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.9743589743589743, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-8754", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-7797", "mrqa_searchqa-validation-728", "mrqa_searchqa-validation-1686", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-15036", "mrqa_searchqa-validation-11856", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-1219", "mrqa_triviaqa-validation-2374", "mrqa_hotpotqa-validation-5024", "mrqa_newsqa-validation-1793", "mrqa_triviaqa-validation-5654"], "SR": 0.578125, "CSR": 0.5011029411764706, "EFR": 1.0, "Overall": 0.6827205882352941}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "an Old Lady", "Opechancanough", "Samuel Langhorne Clemens", "Margaret Mitchell", "The Wanderers", "a hangover", "endodontist", "a desktop microcomputer", "South Dakota", "Hercule Poirot", "Frasier", "George B. McClellan", "Soundgarden", "Maximilian I", "Superman Returns", "John Gotti", "I.M. Pei", "The Name of the Rose", "a Continental Congress", "Norway", "Meriwether Lewis", "\"Where there is hatred, let me sow love... where there is despair, hope\"", "Steve McQueen", "The Firebird", "\"Sweet Home\"", "Vietnam War", "Sheridan", "Mike Huckabee", "a Bill of Rights", "Peter Sellers", "St. Mark", "Jon Stewart", "Howard Dean", "Pogo", "an emotion", "Manitoba", "Madonna", "a turban", "the Perseid Meteor Shower", "Holstein Friesian", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Winston Churchill", "Torvill & Dean", "The Black Eyed Peas", "\"I think, therefore I am\"", "the Kingdom of Serbia", "beloved religious leaders", "1987", "Toy Story", "Harriet Tubman", "The Great British Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Juliet,", "Vicente Carrillo Leyva,", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.625, "QA-F1": 0.6989025297619048}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.5714285714285715, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-295", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-4518", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-9907", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-625", "mrqa_searchqa-validation-3999", "mrqa_naturalquestions-validation-2819", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-4027", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.625, "CSR": 0.5025436046511628, "EFR": 1.0, "Overall": 0.6830087209302326}, {"timecode": 86, "before_eval_results": {"predictions": ["a cob", "Barbara Walters", "Europe and Asia", "hoover", "Robert Frost", "Rivera", "coffee", "a leopard", "Buena Park", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "a Constellations", "de Gaulle", "electrolyte", "Bernini", "Ovid", "Pablo Escobar", "Abraham Lincoln", "Anne", "modified", "a pinnipeds", "Bank of America", "copper", "a push", "Kiss Me, Kate", "foot-work", "plutonium", "bismutite", "iron", "Amistad", "Robert Redford", "The Simpsons", "Betty Jameson", "Universal Studios Hollywood", "the Russian Empire", "goat cheese", "an Achilles' heel", "red", "Sweden", "\"David Cassidy: Man Undercover,\"", "Kashmir", "\"A pyramid unfinished\"", "The Empire Strikes Back", "Nelson's Column", "Billy Bob Thornton", "Clark", "a pepper", "Will & Grace", "Robber Barons", "De Waynene Warren", "2017", "Venezuela", "Conway Twitty", "golf", "\"dialogues des Carm\u00e9lites\"", "England", "66,900", "between June 20 and July 20.", "software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6614583333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-14947", "mrqa_searchqa-validation-6192", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-6375", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11379", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-1851", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_searchqa-validation-5382", "mrqa_searchqa-validation-1268", "mrqa_naturalquestions-validation-9523", "mrqa_hotpotqa-validation-1763", "mrqa_hotpotqa-validation-38"], "SR": 0.59375, "CSR": 0.5035919540229885, "EFR": 1.0, "Overall": 0.6832183908045978}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Burt Bacharach", "the zona glomerulosa of the adrenal cortex in the adrenals gland", "the late 19th and early 20th centuries", "Tom Jones", "The Deal (2015 film)", "Bonnie Franklin", "Violet", "Route 37 East", "Martian Manhunter", "Easy", "\"\u00c9cole des Beaux-Arts\" in Paris", "Gareth Barry", "Bob Day", "Bambi: Eine Lebensgeschichte aus dem Walde", "1896", "iPod Classic", "2017", "The Timekeeper", "July 8, 2014", "Ben Ainslie", "torpedoes", "Dante", "Miami Gardens, Florida", "Colorado Rockies", "Netherlands", "Dallas", "Tia Carrere", "four", "Jim Davis", "Kurt Vonnegut", "Labrador Retriever", "Mumbai", "1837", "Blackpool Football Club", "Diondre Cole", "DS Virgin Racing Formula E Team", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them", "1943", "Paradise, Nevada", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "1885", "2015", "the Northrop F-15 Reporter (later RF-61)", "Gareth Barry", "Gambaga", "March 2012", "English", "Kairi", "1978", "ase", "Turducken", "3000 BC", "Damian Green", "Gary Oldman", "Alanis Morissette", "the Employee Free Choice Act", "\"peregruzka\"", "Port-au-Prince", "Wimbledon", "Brazil", "Rocky & Bullwinkle", "baseball"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6724826388888888}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2294", "mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-5679", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_searchqa-validation-14393"], "SR": 0.640625, "CSR": 0.5051491477272727, "EFR": 1.0, "Overall": 0.6835298295454545}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "the first to utilize Audio-Animatronics", "Continental Army", "1874", "Park Yong-gyu", "January 16, 2013", "James Taylor", "Apple Lisa", "S Pictures' \"Veyyil\"", "the Duke and Duchess of Gloucester", "Umina Beach", "from 1989 until 1994", "Adelaide Miethke", "Chevalier Field", "Consigliere", "\"The Philadelphia Story\"", "7", "The Bologna Process", "Peoria, Illinois", "Iran", "Lorne Michaels", "Philip K. Dick", "Texas Longhorns football", "O", "\"An All-Colored Vaudeville Show\"", "the full 24 hours", "German Shepherd", "The Vaudevillains", "Iftikhar Ali Khan Pataudi", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "rhythm and blues dance", "Carrefour S.A.", "Premier League", "Bob Zmuda", "Eddie Albert", "Chicago", "Ford Island", "\"The Times Higher Education Guide\"", "Derry City F.C.", "Beverly Hills", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "The International Imitation Hemingway Competition", "Coll\u00e8ge de France", "the Norwegian language", "Oklahoma State", "Akshay Kumar", "2015", "diastema ( plural diastemata )", "Thames Street", "Tom Stoppard", "Brazil", "Dube, one of South Africa's most famous musicians, was killed in an attempted car-jacking", "an average of 25 percent", "super-yacht designers Wally", "pound", "\"Livin' On A Prayer\"", "the U.S. Electoral College", "gunga Din"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6810267857142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.8, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-812", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-5078", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-3335", "mrqa_hotpotqa-validation-37", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-2211", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_searchqa-validation-6483", "mrqa_searchqa-validation-8904", "mrqa_triviaqa-validation-7531"], "SR": 0.578125, "CSR": 0.5059691011235955, "EFR": 1.0, "Overall": 0.6836938202247191}, {"timecode": 89, "before_eval_results": {"predictions": ["Michael Manasseri", "disappearances", "World War II", "Indiana Governor Mike Biden", "Mickey Gilley", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "The Itchy & Scratchy Show", "First Street", "5249", "the Dutch Empire", "The production requires a ballerina to play the innocent and fragile White Swan", "The Notorious B.I.G.", "October 20, 2017", "Antilocapra americana", "The Lord\\'s Resistance Army", "1965", "1943", "Big 12 Conference in the National Collegiate Athletic Association (NCAA)", "1959", "31 January 1933", "geographically localised community within a larger city, town, suburb or rural area", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Billund", "the University of Kentucky", "The Sun", "Lee Byung-hun", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "American Boeing B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Berthold Heinrich K\u00e4mpfert", "Lismore", "EQT Plaza in Pittsburgh, Pennsylvania", "Panthera pardus", "Prudential Center", "ten", "Conservatorio Verdi", "north", "the State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Hank Aaron", "golf", "World War II", "santayana", "putting your child's safety and livelihood into other hands,\"", "an annual road trip,", "102", "vinegar", "say I was holier than thou, I said I tried", "saliva", "Venus Williams"], "metric_results": {"EM": 0.625, "QA-F1": 0.6781994047619048}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 0.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-5509", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-1222", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-4336", "mrqa_naturalquestions-validation-10513", "mrqa_triviaqa-validation-6118", "mrqa_triviaqa-validation-4535", "mrqa_newsqa-validation-3736", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464", "mrqa_searchqa-validation-3153"], "SR": 0.625, "CSR": 0.5072916666666667, "EFR": 1.0, "Overall": 0.6839583333333333}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeletons", "Joaquin Phoenix", "jennessee Whiskey", "scalp", "a motorcycle", "New Coke", "Barbara Bush", "staff", "University of Hawai'i at Manoa", "leg", "Sandra Oh", "The Omega Man", "van gogh", "jet streams", "Atlanta", "Alanis Morissette", "paddington bear", "doodles Iben Bredahl Jessen", "a skyscraper", "1953", "Edward R. Murrow", "Cheetah Rivera", "Rick", "seven", "Nike", "antelope", "Sweden", "Lamborghini", "the U.S. Code", "John Philip Sousa", "oregano", "australia", "hanged What She Could", "the Patriot", "Martha\\'s Vineyard", "Mike Gretzky", "bread", "Transformers: The Autobots: Earth Wars", "An American in Paris", "Taiwan", "The Parent Trap", "Mesa Air Group", "David Turley", "\"Gentleman Jim\" Corbett", "Michael Jackson", "The Firebird", "Sicily", "Bill Frist", "currency of the Caribbean", "apocrypha", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "poland", "Big Fat Gypsy Wedding", "Vishal Bhardwaj", "1990", "Big Machine Records", "to pay him a monthly allowance,", "Aung San Suu Kyi", "75.", "quality of teaching and learning in American schools"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5472090409590409}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 0.15384615384615385]}}, "before_error_ids": ["mrqa_searchqa-validation-10892", "mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-7340", "mrqa_searchqa-validation-12132", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-11867", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-11552", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-13611", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-8040", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_triviaqa-validation-1894", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.515625, "CSR": 0.5073832417582418, "EFR": 1.0, "Overall": 0.6839766483516484}, {"timecode": 91, "before_eval_results": {"predictions": ["the Channel Tunnel", "Hawaii", "Crayola", "a giant", "lubricant", "a giant jelly beans", "the Chesapeake", "I", "Darl Bundren", "The Sound and the Fury", "the Suez Canal", "Stephen Hawking", "Ecuador", "New York City", "local", "acetylene", "a scrapple", "Thompson", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "Dr. Quinn", "oblique", "Cracker Jack", "Ford", "a high jump", "a phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "France", "sausage", "venison", "South Africa", "a packer", "the Gifted", "the Andes", "Ovid", "1937", "Grendel", "bread", "Mogul", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "a tentacle", "the sound barrier", "the Federal Republic of Germany", "a jazz funeral without a body", "Nala", "Etienne de Mestre", "People\\'s Dispensary for Sick Animals", "genus", "kendo", "Rawlings", "Adam Levine", "Syracuse", "Stuttgart", "the crossover", "both houses of the legislature", "Bed and breakfast"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6208333333333333}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-15688", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-8947", "mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-5611", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_hotpotqa-validation-1014", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.578125, "CSR": 0.5081521739130435, "EFR": 1.0, "Overall": 0.6841304347826087}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie", "the (indirect rule)", "a gossip", "jaw", "a referendum", "an alfalfa", "Phaedra", "Franklin Delano Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "Daniel", "(RAAF)", "Mozart", "air.", "Abu Musab al-Zarqawi", "Phil of the Future", "the velocity", "the Secret", "an acre", "ancora", "Benjamin Harrison", "William Conrad", "Denver", "the Burning Bush", "a gastropod", "tribes", "Australia", "(Ken) Rogen", "Edouard Manet", "Geoffrey Rush", "Frdric Chopin", "a zipper", "Dallas", "Amman", "Van Halen", "The Joint Committee on Intelligence", "Lou Gehrig\\'s", "grapes", "Nancy Lopez", "the Magic Mountain", "Hudson Bay", "delude", "Aboite", "a den", "a loaf of bread", "a mead", "The Mossad", "a menagerie", "an aide-de-camp", "Judith Aline Keppel", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "plutocracy", "Diego Velazquez", "Shut the *freak* up", "The Panther", "paracyclist.", "XXIV Summer Universiade", "Asashoryu", "the world's tallest building,", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6148065476190476}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-5282", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-16477", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-9061", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-3311", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-12520", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-10773", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-766", "mrqa_triviaqa-validation-6160", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.53125, "CSR": 0.5084005376344086, "EFR": 1.0, "Overall": 0.6841801075268817}, {"timecode": 93, "before_eval_results": {"predictions": ["Labor", "Standard Oil", "Ciudad de los Reyes", "English", "the Archbishop", "Clark", "India", "The Carpenters", "Wyoming", "Mary Stuart", "the Crimean War", "an elbow", "a thermostat", "a bad speed", "a sapphire", "a florida", "a limey", "grace", "gasoline", "the Davis Cup", "Blackbeard", "William III", "Emily Dickinson", "a syllable", "Simon Wiesenthal", "Mercury and Venus", "San Antonio de Bxar", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "whee'en", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "flautas", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a bat", "Munich", "Lance Armstrong", "Jimmy Carter", "(Barbara) Cartland", "Canongate", "The War of the Worlds", "January 17, 1899", "in which there is a decline in population density", "about 13,000 astronomical units ( 0.21 ly )", "Jessica", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO as well.", "a cancerous tumor.", "in Hamburg", "Charles Quinton Murphy"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7063322368421052}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, false, false], "QA-F1": [0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.10526315789473685, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-5561", "mrqa_searchqa-validation-10246", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-9606", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-12927", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-12174", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_searchqa-validation-10500", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-8832", "mrqa_newsqa-validation-852", "mrqa_newsqa-validation-3138", "mrqa_hotpotqa-validation-751"], "SR": 0.640625, "CSR": 0.5098071808510638, "EFR": 1.0, "Overall": 0.6844614361702128}, {"timecode": 94, "before_eval_results": {"predictions": ["assassination", "the hemorrhage", "a pachycephalosauridae", "Janet Reno", "Harvard", "Don Quixote", "The Turn of the Screw", "David Lynch", "John the Baptist", "pine", "Bill Hickok", "green", "hydrogen", "an whee", "the lava", "the bacillus", "Jamaica", "the Sacher Torte", "Hillary Clinton", "a coyote", "CVS", "Sulfur", "the Confessions of Nat Turner", "Jacques Marquette", "the upper teeth", "Hannibal Lecter", "a bug", "Thomas Jefferson", "a millimeter", "Megan Fox", "Alexander", "icebreakers & energizers", "the Battle of the Little Bighorn", "Marie Curie", "the Russian Blue", "The Graduate", "Nebraska", "\"E-T\"", "lemon", "John", "LOUIS XIV", "stone", "a yellow page", "Toyota", "Scout Finch", "Liechtenstein", "the Joker", "Pulp Fiction", "Mao Zedong", "Neptune", "the Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson and Peter Vale", "Sir Giles Gilbert Scott", "Andrew Jackson", "Athlete", "HackThis Site", "\"Traumnovelle\" (\"Dream Story)", "1985", "Manuel Mejia Munera", "seven", "at least 300", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.5, "QA-F1": 0.5760416666666667}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-246", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-14178", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-16681", "mrqa_searchqa-validation-3017", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-4784", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-4855", "mrqa_searchqa-validation-9813", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-7314", "mrqa_searchqa-validation-4989", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-11462", "mrqa_naturalquestions-validation-4399", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3822", "mrqa_newsqa-validation-3607"], "SR": 0.5, "CSR": 0.5097039473684211, "EFR": 1.0, "Overall": 0.6844407894736843}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "(George) McCartney", "a genie", "a cassowary", "Atonement", "a palette", "ice cream", "Cherry", "Tajikistan", "Theology", "Forrest Gump", "a piles", "a hot dog", "Guy Ritchie", "Dixie", "Alfred Nobel", "Karen Blixen-finecke", "The World\\'s Best desk", "Sindbad", "a ziggurat", "the toe", "Pennsylvania", "The War of the Worlds", "Hercules", "Steve Jobs", "Waylon Jennings", "Manwich", "salinity", "Julius Caesar", "Lady Jane Grey", "Eugene V. Debs", "Texas", "Troy", "Antoinette Perry", "The Crucible", "the rabbit", "Battlestar Galactica", "Rugby School", "Titan", "Francis", "Exodus", "Arthur Miller", "Billie Holiday", "Seal", "improv", "Scrabble", "2016", "a raccoon", "Jammu & Kashmir", "The Barbary Coast", "a skunk", "Neal Dahlen", "egg", "Reverend J. Long", "bridge", "Morocco", "cheese, pickles, and onions", "Scholastic UK", "FIFA Women\\'s World Cup", "Great Lakes and Midwestern", "St. Louis", "three out of four", "2002", "The restaurant will be serving its fast burgers in the Carrousel du Louvre,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.694798519736842}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.125, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8421052631578948]}}, "before_error_ids": ["mrqa_searchqa-validation-13433", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-2598", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-2950"], "SR": 0.640625, "CSR": 0.5110677083333333, "EFR": 1.0, "Overall": 0.6847135416666666}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "The Paris Sisters", "Holiday Inn Hotels & Resorts", "Kaley Christine Cuoco", "1858", "`` Everywhere ''", "T.S. Eliot", "norm that sovereigns had no internal equals within a defined territory and no external superiors as the ultimate authority within the territory's sovereign borders", "30 October 1918", "Spain", "Meri", "\"d `` always envisioned '' a `` talking section at the end '' on the song, but did not really know what `` to do with it ''", "Nicole Gale Anderson", "Tiffany Adams Coyne", "Greek mythology", "Eddie Murphy", "20 November 1989", "Ben Savage", "Genoese merchant sailor Manuel Pessanha ( Pesagno )", "`` Reveille ''", "Charles Carroll of Carrollton", "is from Hebrew \u05d4\u05d5\u05e0\u05d0, \u05e0\u05d0 h\u00f4\u0161\u00ee\u02bf\u00e2 - n\u0101 and related to Aramaic \u05d0\u05d5\u05e8\u05e2\u05e0\u05d4", "the Hudson Bay", "March 11, 2018", "Khrushchev", "Ciara Brady", "International Border ( IB )", "Ancylostoma duodenale", "between Weston Road and Highway 11 ( Yonge Street )", "Wakanda and the Savage Land", "the player character is recruited into the Grey Wardens, an ancient order that stands against demonic forces known as `` Darkspawn ''", "1988", "the Jos Plateau", "The Union's forces were slow in positioning themselves, allowing Confederate reinforcements time to arrive by rail", "Majandra Delfino", "August 29, 2017", "a convergent plate boundary", "ancient Mesopotamia", "the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "Matt Monro", "Bill Russell", "Kryptonite", "May 2017", "31 December 1960", "April 15, 2018", "Mahatma Gandhi", "1913", "1985", "big - distance two - way", "early 1950s", "(John) Ritchie", "Apocalypse Now", "Gower", "11,163", "Jaguar Land Rover", "His son", "powerful anesthetic and sedative.", "Courtney Love,", "the park bench facing Lake Washington", "poetry", "East of Eden", "Andes", "1919"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5884001635285054}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 0.9302325581395349, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3478260869565218, 0.2, 0.0, 0.0, 0.0, 0.11764705882352941, 0.0, 0.3333333333333333, 1.0, 0.0, 0.07142857142857142, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5468", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-3206", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-4197", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-1155", "mrqa_newsqa-validation-3612", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.53125, "CSR": 0.5112757731958764, "EFR": 0.9333333333333333, "Overall": 0.6714218213058419}, {"timecode": 97, "before_eval_results": {"predictions": ["off - premises sales in one form or another on Sundays at some restricted time", "Dr. Rajendra Prasad", "2001 -- 2002", "New England", "Game 1", "two reservoirs in the eastern Catskill Mountains", "mid-1970s", "Bart Cummings", "Billie `` The Blue Bear ''", "Arnold Schoenberg", "2000 BC", "mindfulness", "wagen VIII Maus", "Response header fields", "Ian Hart", "the contestant makes a thirty - second call to one of a number of friends ( who provide their phone numbers in advance ) and reads them the question and answer choices", "in the 1898 Treaty of Paris", "Massachusetts", "Rocinante", "Paul Hogan", "360 members", "March 14", "the stock market crash of October 29, 1929", "Frankel", "prenatal development", "senators", "Lysander", "Shakespearean actresses and car salespeople", "Procol Harum", "2018", "Pantalone", "James Rodr\u00edguez", "phosphate nucleotides", "Hathi Jr", "interstitial and intravascular compartments", "1983", "Instagram's own account", "Nestorian '' churches such as the Church of the East reject it", "in the pachytene stage of prophase I of meiosis", "Qutab Ud - Din - Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Robert Jordan", "American swimmer Michael Phelps", "Brittany Paige Bouck", "In the repeated sinking of American merchant ships in early 1917, Wilson asked and obtained a declaration of war in April 1917", "Isabela Moner", "April 29, 2009", "Laodicea", "Gibraltar", "red, white, and blue", "U.S. Fund for UNICEF", "Salt Lake City", "euro", "golfers of all time", "1 September 1864", "Thomas Christopher Ince", "Katarina Witt", "38", "\"The Da Vinci Code\"", "Barbara Streisand", "Brave New World", "a phobia", "cryogenics", "anxiety"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5929942635945926}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.9090909090909091, 0.33333333333333337, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.7777777777777778, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.36363636363636365, 1.0, 0.5714285714285715, 0.0, 0.7368421052631579, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-9953", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-8849", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-8424", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-2354", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-786", "mrqa_searchqa-validation-15118"], "SR": 0.46875, "CSR": 0.5108418367346939, "EFR": 0.9117647058823529, "Overall": 0.6670213085234094}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs.", "Laurence Fishburne", "Rockbridge County", "Mumbai, Maharashtra", "Atlanta", "\"perfect Strangers,\"", "public", "Nelson County", "survival horror", "\"boundary river\"", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks", "\"The Simpsons Spin-Off Showcase\"", "Puente Hills Mall", "neo-Nazi", "model", "homosexual or bisexual", "Adam Dawes", "1621", "Steven selling", "Chief of the Operations Staff of the Armed Forces High Command", "1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "British", "1968", "Longford", "Dirk Werner Nowitzki", "highland regions of Scotland", "The Jayhawks football team", "London", "Timothy Dalton", "1924", "Valley Falls", "Klasky Csupo", "The Hungry Hustlerz: Starvation Is Motivation", "Russian film industry", "2008", "the midnight sun", "John R. Leonetti", "1976", "Anthony Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "The Sun (United Kingdom)", "their unusual behavior", "1952", "used stone tools", "`` 200 ''", "Dmitri Mendeleev", "honda", "Utah", "moby dick", "The train in front had stopped", "More than 22 million", "to host the Olympic Games in Rio de Janeiro.", "\"Free Bird\"", "Great Expectations", "Matt Damon", "lizards"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6273065476190477}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.4, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-1204", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-290", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-745", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-4943", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-2375", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-2759", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-14674"], "SR": 0.578125, "CSR": 0.5115214646464646, "EFR": 1.0, "Overall": 0.6848042929292929}, {"timecode": 99, "UKR": 0.5859375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.833984375, "KG": 0.45703125, "before_eval_results": {"predictions": ["The 2007 Trail Appliances", "The English Electric Canberra", "Alemannic", "aired on PBS stations", "The Bears", "1987", "Salisbury", "KKR & Co", "526", "Annie Ida Jenny No\u00eb Haesendonck", "Gouverneur K. Warren", "The Grandmaster", "satirical erotic romantic comedy", "\"The Process\"", "Vikram", "1949", "BAFTA TV Award Best Actor", "Durham, North Carolina", "midfielder", "Levi Weeks", "219", "Esteban Ocon", "S6", "Lamar Hunt", "Black Mountain College", "You Can Be a Star", "People v. Turner", "in 1853", "1977", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "City of Ghosts", "Ludwig van Beethoven", "Beijing", "Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan Hypersport", "the Monongahela River", "YouTube channel", "August 19, 2016", "3 mi", "Field Marshal Lord Gort", "Neighbourhood", "Miracle", "1979", "Trent (Arnold)", "18", "2011", "the last Ice Age", "North Carolina", "wish FM", "John Galliano", "GM and Chrysler,", "Arlington National Cemetery's Section 60,", "Seoul", "circumnavigate", "a dash", "a fifteenth anniversary", "Mollusca"], "metric_results": {"EM": 0.625, "QA-F1": 0.6795386904761904}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, false, true, false, false, true, true, false, true, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-3155", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-3889", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-4683", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-4402", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2788", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6862", "mrqa_newsqa-validation-2457", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-10055", "mrqa_searchqa-validation-5045"], "SR": 0.625, "CSR": 0.51265625, "EFR": 1.0, "Overall": 0.677921875}]}