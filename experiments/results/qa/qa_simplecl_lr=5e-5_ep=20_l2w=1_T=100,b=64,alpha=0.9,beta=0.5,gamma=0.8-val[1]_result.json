{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8300, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "the 1970s", "Sunni Arabs from Iraq and Syria", "P,NP-complete, orNP-intermediate", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "The E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "the Council of Chalcedon", "complicated definitions", "coordinating lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation of a drug treatment for an individual", "2014", "late 1970s", "30% less steam", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "fossils in sedimentary rocks", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act, commonly referred to as the Cat and Mouse Act, was an Act of Parliament passed in Britain under Herbert Henry Asquith's Liberal government in 1913", "Howard Wolowitz", "Daenerys", "Raabta"], "metric_results": {"EM": 0.75, "QA-F1": 0.7924520613732451}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.06451612903225806, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-9931", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_squad-validation-5178", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.75, "CSR": 0.7578125, "EFR": 0.9375, "Overall": 0.84765625}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "second use of the law", "free", "1973", "September 1969", "Mansfeld", "Warsaw Stock Exchange", "390 billion individual trees divided into 16,000 species", "a suite of network protocols created by Digital Equipment Corporation", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "the geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "427,652", "1898", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "severed all relations with his family", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "coordinating proteolytic activation of complement molecules", "Alaska", "120 m ( 390 ft )", "the eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "six points", "Merrimac", "the Atlantic Ocean, the Gulf of Mexico and the Straits of Florida"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7645255717418546}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.375, 0.0, 0.4, 0.888888888888889, 0.4444444444444445, 1.0, 0.4, 1.0, 0.4736842105263158, 0.38095238095238093, 0.0, 1.0, 1.0, 0.16666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-5788", "mrqa_squad-validation-4415", "mrqa_squad-validation-4725", "mrqa_squad-validation-1841", "mrqa_squad-validation-1146", "mrqa_squad-validation-1220", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_searchqa-validation-3996"], "SR": 0.6875, "CSR": 0.734375, "EFR": 0.95, "Overall": 0.8421875}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "the Dutch Cape Colony in South Africa, the Dutch East Indies, the Caribbean, and several of the English colonies of North America, and Quebec", "12 December 2007", "six", "redistributive taxation", "rubisco", "recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "Stromules", "Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three sites", "Von Miller", "Africa", "clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown San Bernardino", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "Novalee and Americus", "September 1973", "the One Ring", "the middle of the 15th century", "6 March 1983", "James G. Kiernan", "horror fiction", "26,000"], "metric_results": {"EM": 0.65625, "QA-F1": 0.757503434065934}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857144, 0.5, 1.0, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3023", "mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-10293", "mrqa_squad-validation-4759", "mrqa_squad-validation-126", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_squad-validation-384", "mrqa_squad-validation-2644", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433"], "SR": 0.65625, "CSR": 0.71484375, "EFR": 1.0, "Overall": 0.857421875}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle (near present-day Erie, Pennsylvania)", "wireless", "Beyonc\u00e9 and Bruno Mars", "the Yuan dynasty", "same-gender marriages", "red algae red", "after their second year", "1960s", "the freedom to provide services\" under TFEU article 56", "Napoleon", "Immunology", "geophysical surveys", "topographic", "130 million cubic foot (3.7 million cubic meter)", "The committee created the 50 fund as its philanthropic initiative and focuses on providing grants to aid with youth development, community investment and sustainable environments", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "Cisco Systems", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "a thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "a guilty plea", "the kettle and the Cricket, at one and the world", "Gandhi in South Africa", "Vlad the Impaler", "The Little Foxes", "a consumer-level analog-recording and cassette format of magnetic tape for video", "Leonard Nimoy", "Earth's orbital period is 365 & this fraction of a day", "1994 U.S. Amateur", "1867 to 1877", "Marshall Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "Seminyak Beach", "the new nightspot Teddy's made this presidential Hollywood hotel a happening # Quiz # Question. 0:29", "LASER abbreviation", "the Flying Trunk ride at Tivoli", "Juno", "a genus (scientific group) called Sphagnum", "why", "Daya", "anemophobia- Fear of air drafts or wind.(Ancraophobia)", "American", "Enrique Torres"], "metric_results": {"EM": 0.5, "QA-F1": 0.5638602543290043}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14285714285714285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-390", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-14338", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073", "mrqa_newsqa-validation-496"], "SR": 0.5, "CSR": 0.671875, "EFR": 0.96875, "Overall": 0.8203125}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "the total number of state transitions, or steps, the machine makes before it halts and outputs the answer (\"yes\" or \"no\")", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "fell from his horse while hunting", "the member state cannot enforce conflicting laws", "the work of British bacteriologist J. F. D. Shrewsbury", "canals", "inversely to member state size", "Europe", "he never studied Greek, a required subject; and he was illiterate in Czech", "colonies", "$37.6 billion", "Kenyan athletes", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center in San Jose", "Variable lymphocytes receptors", "the Edict of Fontainebleau", "Levi's Stadium", "ten million", "the Lippe", "Video On Demand content", "time and storage", "semester calendar beginning in early September and ending in mid-May", "member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "the League of the Three Emperors", "the field of science", "143,007", "East Asia", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "out of a hat", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "the monkey chew on hot peppers", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.6875, "QA-F1": 0.8144198683261183}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 0.4, 0.9090909090909091, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 0.9, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-6218", "mrqa_squad-validation-4919", "mrqa_squad-validation-4517", "mrqa_squad-validation-4210", "mrqa_squad-validation-1187", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_squad-validation-3943", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.6875, "CSR": 0.6744791666666667, "EFR": 1.0, "Overall": 0.8372395833333334}, {"timecode": 6, "before_eval_results": {"predictions": ["the 1540s", "the courts of member states", "the dot", "three", "a negative long-term impact on the health of the city's residents", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "to overthrow a government (or to change cultural traditions, social customs, religious beliefs, etc...revolution doesn't have to be political", "entertainment", "A vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "the Silk Road", "San Diego", "Central Poland", "the University of Chicago Laboratory Schools (a private day school for K-12 students and day care), the Sonia Shankman Orthogenic School (a residential treatment program for those with behavioral and emotional problems), and four public charter schools", "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "Spanish", "Structural geologists", "president and CEO of ABC", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "John Rockwell", "the Sinclair Oil and Refining Corporation", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "the Jasenovac concentration camp", "Rabat", "between 11 or 13 and 18", "Heather Elizabeth Langenkamp", "Henry Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI) (Lithuanian: \"Vilniaus oro uostas\" )", "Bury St Edmunds, Suffolk, England", "The WB supernatural drama series \"Charmed\"", "Lily Hampton", "Liverpool and England international player Alex Oxlade-Chamberlain (born 15 August 1993)", "the University of Oregon", "Rickie Lee Skaggs", "48,982", "the Ashanti Region", "25.2", "Algeria", "a novel", "the Eastern part", "the fresco walls in the Stanza della Segnatura", "the Atlantic City Boardwalk"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7104358611408916}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 0.24390243902439024, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5714285714285715, 0.7499999999999999, 0.33333333333333337, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-5213", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-913", "mrqa_squad-validation-7983", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_naturalquestions-validation-2159", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-13072"], "SR": 0.578125, "CSR": 0.6607142857142857, "EFR": 0.9629629629629629, "Overall": 0.8118386243386243}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland, the Dutch Republic, the Electorate of the Palatinate", "the working fluid", "a suite of network protocols", "American Baptist Education Society", "Dutch", "a particular input", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "a modern canalized section", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "a small fraction of the flow is diverted off the island of Mainau into Lake \u00dcberlingen", "computer programs", "The General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "a deterministic Turing machine", "Bart Starr", "allotrope", "Karluk Kara-Khanid ruler", "Perth", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "Alfred Edward Housman", "Hanoi", "Sevens", "The fennec fox", "Bart Conner", "fantasy role-playing game", "Martin \"Marty\" McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Cody Miller", "140 to 219", "the \"Father of Liberalism\"", "Christophe Lourdelet", "Pablo Escobar", "African descent", "Mexico City", "Sleeping Beauty", "Disneyland", "8 December 1985", "Dinah Doll", "Omar Bongo", "Wheat Chex", "Ray Harroun", "Emily Blunt", "David Tennant"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7247501885369532}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.33333333333333326, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-4673", "mrqa_squad-validation-1771", "mrqa_squad-validation-9287", "mrqa_squad-validation-1819", "mrqa_hotpotqa-validation-1898", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2127", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.640625, "CSR": 0.658203125, "EFR": 1.0, "Overall": 0.8291015625}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "complex forms of life", "railroad", "Revolutionary civil disobedience", "during the compression stage relatively little work is required to drive the pump, the working fluid being in its liquid phase at this point", "Lunar Excursion Module", "the Zwickau prophets", "six years", "700", "the 5th Avenue laboratory fire of March 1895", "the history of arms", "two independent mechanisms", "minor", "Fringe or splinter movements", "17", "lower temperatures", "the architect or engineer", "1917", "Columbus Avenue and West 66th Street", "teachers through the web in order to earn supplemental income", "stratigraphic correlation", "commensal flora", "a + bi", "Dallas, Texas", "Central Asian Muslims", "made tape recordings of the show", "1330 Avenue of the Americas", "Alberta and British Columbia", "Pimp My Ride", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "jet-powered tailless delta wing high-altitude strategic bomber", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham", "A55 North Wales Expressway", "Ranulf de Gernon", "\u00c6thelstan", "West Tambaram", "44", "Division I", "Harriet Tubman", "Crawley Town", "Dragon TV", "Greek-American", "A diastema ( plural diastemata )", "Shirley Horn", "Iran", "Bigfoot", "Papua New Guinea", "Renoir\u00b4s", "Manchester"], "metric_results": {"EM": 0.625, "QA-F1": 0.7133463541666667}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.6875000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.5, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3461", "mrqa_squad-validation-3391", "mrqa_squad-validation-3405", "mrqa_squad-validation-2238", "mrqa_squad-validation-9859", "mrqa_squad-validation-7643", "mrqa_squad-validation-5972", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_triviaqa-validation-3170", "mrqa_triviaqa-validation-1423"], "SR": 0.625, "CSR": 0.6545138888888888, "EFR": 1.0, "Overall": 0.8272569444444444}, {"timecode": 9, "before_eval_results": {"predictions": ["$159 million", "centrifugal governor", "Orange County", "chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules", "Edict of Fontainebleau", "Museum of the Moving Image in London", "he sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "pivotal event in the Arab Muslim world", "the youngest publicly documented people to be identified as transgender", "John Alexander", "David Michael Bautista Jr.", "the fourth Thursday of November", "American actor", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen James Ireland", "Marko Tapani \" Marco\" Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "2500 ft", "Central Park", "Robert John Day", "Amazigh", "James Tinling", "Italy", "79th Masters Tournament", "Kristoffer Rygg", "University of Kentucky College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "al-Maghrib wa'l-Andalusia", "22 million", "morphine sulfate oral solution 20 mg/ml", "renoir", "renoir"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6494255791153027}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7173", "mrqa_squad-validation-4147", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.5625, "CSR": 0.6453125, "EFR": 1.0, "Overall": 0.82265625}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "Timucuan Ecological and Historic Preserve", "suburban shopping areas", "early vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "C. J. Anderson", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "immune responses beginning to decline at around 50 years of age due to immunosenescence", "counterflow", "lithium-ion battery developer John B. Goodenough", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "machine gun", "Cybermen", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "Standard Model", "Tolui", "Rhine-Ruhr region", "course of study", "Prevenient grace", "Kansas State", "Gladstone Region", "Chris Pine", "Yoo Seung-ho", "the Battle of the Philippines", "NCAA Division I", "The Onion", "Mickey's Once Upon a Christmas", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Naruto", "Tom Jones", "Russell Humphreys", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European culture", "first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Central Europe", "New Jersey", "Massachusetts", "Ector County", "Jim Davis", "Buck Owens", "World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the cat", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "Lebanon's Mediterranean coastline", "Onomastic Sobriquets In The Food And Beverage Industry", "the bin"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6493315994406111}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7269", "mrqa_squad-validation-5010", "mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-6495", "mrqa_squad-validation-8072", "mrqa_squad-validation-9815", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3072", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.546875, "CSR": 0.6363636363636364, "EFR": 0.9655172413793104, "Overall": 0.8009404388714734}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "100\u2013150 species", "Philo of Byzantium", "The climate is cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "second oil shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "a new element", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "It educates the consumer on how much they are paying for having a low-MPG car and encourages them to get into a more efficient vehicle", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "the power-sharing deal with the MDC offshoot is part of larger deal that has not been signed by anyone", "lack of a cause of death", "200", "a very small number of young people taking drugs", "opposition party members", "Missouri", "Reid's dismissal", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "Employee Free Choice", "Bush administration", "the blasts were timed to go off during the height of rush hour", "It is done with the parents' full consent", "the best-of-three series", "Kaka", "Christopher Savoie", "Dan Parris, 25, and Rob Lehr", "Fayetteville, North Carolina", "two", "$2 billion", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "Dr. Christina Romete", "Ark of the Covenant", "Jean F Kernel ( 1497 -- 1558 )", "The truth was", "Richmond", "1994", "The Conjuring", "The Gallipoli Campaign", "a large bay that protrudes northeast from Lake Huron into Ontario, Canada", "Nowhere Boy"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6253443276072586}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, false, false, true, false, true, true, false, false, true, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 0.20689655172413793, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.8, 0.8571428571428571, 0.0, 0.0, 0.5714285714285714, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-4611", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-3637", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-2344", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.484375, "CSR": 0.6236979166666667, "EFR": 0.9696969696969697, "Overall": 0.7966974431818182}, {"timecode": 12, "before_eval_results": {"predictions": ["C\u00e9loron threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "every good work designed to attract God's favor is a sin.", "Napoleon", "mass production", "Arley D. Cathey", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives,", "1227", "lower lake", "three", "Elders", "587,000", "Private Bill Committees", "Bruno Mars", "the Catechism", "beneath the university's Stagg Field", "Ian Botham", "Pyotr Ilich Tchaikovsky", "Vincent Motorcycle Company", "Al Shean", "Salvador Allende", "Harold Pinter", "Honolulu, Hawaii", "Erik Thorvaldson", "Apollon", "1940 Rodgers and Hart musical Pal Joey", "Mary Jane Grant", "green", "Indonesia", "supreme religious leader of all the subordinate priests", "Antonio Stradivari", "European Atomic Energy Community (Euratom)", "Christine Keeler", "Paradise", "Jack Nicholson", "four", "Netherlands", "\"Sugar Baby Love\"", "Coretta Scott King", "Sean", "John Denver", "Stage 1", "Travis", "The Show", "Robert Kennedy", "Q", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "a French author and philosopher", "barber", "John Bromwich, Evonne Goolagong Cawley, Lew Hoad and Margaret Smith Court", "Murrah Federal Office Building", "Evita", "a litter of pipes on the mantelpiece", "fortified complex at the heart of Moscow", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley's Club", "\"It is very easy for comments to be taken out of context and create unnecessary drama -- especially between us women,\"", "a delegation of American Muslim and Christian leaders", "Anne of Cleves", "University of South Carolina", "Juan Martin Del Potro."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5907903439153439}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, true, true, true], "QA-F1": [0.962962962962963, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.4444444444444445, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.2, 1.0, 0.8571428571428571, 0.4, 0.05555555555555556, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10141", "mrqa_squad-validation-2262", "mrqa_squad-validation-7974", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6696", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987"], "SR": 0.484375, "CSR": 0.6129807692307692, "EFR": 0.9090909090909091, "Overall": 0.7610358391608392}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "aaron", "moles", "leucippus", "Kwajalein Atoll", "Catherine of Aragon", "Calvin Coolidge", "Steve McQueen", "Portugal", "alton", "1/6", "komando Pasukan Khusus", "garrow-in-Furness,", "a liquid form", "zanesville", "Lucas McCain", "tardigrades", "matt-gilding", "aniridia", "Charles A. Carpenter", "River Forth", "woe", "NOW Magazine", "pampered Red Fox", "Italy", "Canada", "typhoid fever", "Pavarotti", "action figure", "al Bundy", "2010", "a gas", "Venezuela", "aaron", "temperature inversion", "40", "phrenology", "San Francisco", "Fall 1998", "Regulus", "Anderson Silva", "Drillers Stadium", "one", "Virgin America", "John Grisham", "Administrative Professionals Day", "Iran's parliament speaker", "Dutch side Heerenveen were eliminated despite a 5-0 home victory over FK Ventspils."], "metric_results": {"EM": 0.515625, "QA-F1": 0.5609375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.515625, "CSR": 0.6060267857142857, "EFR": 1.0, "Overall": 0.8030133928571428}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Michelle Gomez", "University of Aberdeen", "private citizen", "the most cost efficient bidder", "ocular", "UTC+11:00", "thigh", "Olympia", "Chornobyl", "kung fu grip", "andrew johnson", "the boys", "amber", "Princeton University", "The executioner's Song", "180 degree", "Kazakhstan", "anamosa", "andrew johnson", "The Comedy of Errors", "anneoAC", "television", "knife", "fiery light", "Cologne", "Henley", "journal", "Kosovo", "andrew johnson", "Central Park", "tennis", "laurel", "cowboys", "andrew johnson", "odocoileus virginianus", "kung fu grip", "kung fu grip", "the United Nations", "and girls", "accordion", "andrew johnson", "George S. Klein", "Augusta", "counter clockwise", "2013", "Nick Hornby", "parachutes", "December 24, 1973", "David Weissman", "bikinis", "Dalai Lama", "a child's Garden of Verses", "Israel"], "metric_results": {"EM": 0.4375, "QA-F1": 0.47135416666666663}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, true, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-9402", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-405", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-14700", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.4375, "CSR": 0.5947916666666666, "EFR": 1.0, "Overall": 0.7973958333333333}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "Deabolis", "April 20", "Latin Rhenus", "1996", "wine", "German-Swiss", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "Word-Cross", "Paula Abdul", "Strongsville", "Flemish", "Mastercard", "Robert C. Stempel", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "a tan or brown macule", "a casino", "Toronto Maple", "Zsa Zsa Gabor", "a performance process known as method acting", "Utah", "sugarcane", "(Rabbit) Angstrom", "Johann Strauss II", "joey", "pro bono", "Foggia", "the Fun Factory", "a beer", "(Manfred von Richthofen)", "Nacho Libre", "copper", "black magic or of dealings with the devil", "the plant that killed Socrates", "Jeffrey Wigand", "poetry", "The Runza Way", "meager", "Casablanca", "squadrons", "Gustav Kirchhoff", "a geisha", "a mermaid", "Altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a Tin Star", "\"black\"", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "three", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5854166666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-12150", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-12729", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_newsqa-validation-2036"], "SR": 0.53125, "CSR": 0.5908203125, "EFR": 1.0, "Overall": 0.79541015625}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite tribe", "respiration", "1997", "late 1920s", "\u00a34.2bn", "27 July 2008", "unequal", "October 1973", "military troops", "Isiah Bowman", "an assembly center", "Ominde Commission", "the Weser River", "Evita", "Ho Chi Minh", "(round about, in a circle around, or encircling)", "the Inuit", "Detroit Rock City", "the Blue Jays", "Walt Whitman", "Ray Bradbury", "crimes committed out of hatred for someone's race", "King Julien", "Nicolas Sarkozy", "the Rubicon", "(Larry) Martin", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Rodham Clinton", "King Philip", "Bellerophontes", "Balaam", "business school", "the Caine Mutiny", "the 100 Greatest Guitarists", "F. W. Woolworth Company", "(John) Coltrane", "Peace Sign Flag", "oxygen", "the Sphinx", "Jan Hus", "USA Network", "Mavericks", "Onegin", "Macy's", "a spinning jenny", "Santa Claus", "Dennis Haysbert", "Medical Malpractice", "federal, provincial, and municipal governments and public school boards", "attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "Michoacan Family", "( Brad Blauser)", "his salary", "the punishment for the player"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6114955357142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.5, 1.0, 0.0, 1.0, 0.2, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_squad-validation-3132", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-13648", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_newsqa-validation-1148"], "SR": 0.515625, "CSR": 0.5863970588235294, "EFR": 0.967741935483871, "Overall": 0.7770694971537002}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Benjamin Vail", "the telephone ring", "the Party of National Unity", "22 miles", "the duke", "Phillip Marlowe", "piracy", "Cliff Lee", "The Crystal Method", "Puerto Rico", "the Mausoleum", "Anacondas", "Syria", "Belgian World Airlines", "The Old Man", "French", "Joe Louis", "the lion", "d'Artagnan", "the Bayeux Tapestry", "a small front porch", "Inner Mongolia", "Sunni", "notes", "Hawking", "Cicero", "Memphis", "Mountain Dew", "A Streetcar Named Desire", "Quilt", "FRAM", "the House of Representatives", "a Belgian-owned Canadian beer company", "Michael Moore", "Oman", "Chevy", "an artless girl", "Pennsylvania", "Don Juan", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Ronald Reagan", "Fiddler on the Roof", "Ethiopian", "six 50 minute ( one - hour with advertisements ) episodes", "1992", "a salt", "Bromley", "the Ruul", "Cartoon Network", "a small child", "you love the environment and hate using fuel", "Rabbani, a former Afghan president who had been leading the Afghan peace council,", "a nuclear weapon", "ten golf movies ever made"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6467013888888888}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-6418", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-1272", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1920", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-14282", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-10594", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-6024", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-463", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-4110"], "SR": 0.59375, "CSR": 0.5868055555555556, "EFR": 1.0, "Overall": 0.7934027777777778}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXI", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity measures", "same-gender marriages", "the 2006 Israel-Lebanon conflict", "the mid-18th century", "orange", "A Raisin in the Sun", "Sistine Chapel", "White Russia", "a letter T", "a trowel", "Big Bang", "the Monkees", "endodontist", "Saturn", "the chalk cliffs", "Genoa", "Galt", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Seattle", "polyantha", "The Hampton Inn", "25", "the Civil War", "Copeina arnoldi", "Paul McCartney", "omega-3", "preston", "Bachman Turner Overdrive", "VOD", "Imgrum", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "Finnegans Wake", "Wordsworth", "Iceland", "bears", "an earthquake", "Judas", "elephant", "Dabrowski Mazurka", "Finland", "a covert operation", "our country", "May 2010", "Camp David", "Guanabara Bay", "Thailand", "gender queer", "Minister for Social Protection", "Berga", "the estate", "Bill Irwin", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5959465579710145}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-14195", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-12757", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-2870"], "SR": 0.484375, "CSR": 0.5814144736842105, "EFR": 1.0, "Overall": 0.7907072368421053}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "genetically modified plants", "the Earth", "53,000", "one", "Israeli poet", "two", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "the results show moved to Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "mindfulness", "Charlene Holt", "Captain Leland Stottlemeyer", "2010", "electron shells", "Cornett family", "Acid rain", "October 22, 2017", "they can not be produced using currently available resources", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Lex Luger", "Toledo", "board of trade", "a cladding of a different glass, or plastic", "Abraham Gottlob Werner", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another", "Ancylostoma duodenale", "March 1", "the Lykan", "the nature of Abraham Lincoln's war goals", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "a man called Lysander", "Jupiter", "east", "15", "John Robert Cocker", "Silvan Shalom", "a puzzle video game", "a palace", "an olfactory nerve", "Eucalyptus", "a lion", "nitrogen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.630765639589169}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.28571428571428575, 0.4705882352941177, 0.0, 0.2, 0.8, 1.0, 1.0, 0.6666666666666666, 0.2222222222222222, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-880", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-2379", "mrqa_triviaqa-validation-2227", "mrqa_triviaqa-validation-6753"], "SR": 0.515625, "CSR": 0.578125, "EFR": 0.9354838709677419, "Overall": 0.756804435483871}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape of a 15-year-old girl on the campus of Richmond High School in Northern California", "Haitian earthquake survivors would engage in a massive and deadly ocean migration to South Florida", "7,000", "Wednesday", "201-262-2800", "different women coping with breast cancer in five vignettes", "over 1,000 pounds", "peace with Israel", "Mutassim", "from Texas and Oklahoma to points east", "a polo match", "Jackson's father", "Amstetten", "computer problems", "Silvan Shalom", "Jonathan Breeze", "Steve Jobs", "12-hour-plus shifts of backbreaking labor", "prisoners", "June 2004", "consumer confidence", "5:20 p.m.", "North vs. South,", "India", "1964", "Davidson", "Swat Valley", "this month", "1979", "the United States", "GospelToday", "Akio Toyoda", "There's no chance of it being open on time.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks", "Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "Michael Schumacher", "Hurricane Gustav", "gun", "a pair of white boxer shorts", "children that a French charity attempted to take to France from Chad for adoption", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter festivals", "Whitsunday", "the Dee", "\"Dumb and Dumber\"", "the Oklahoma Sooners", "Earl Warren", "a converging lens", "autu", "Bart Allen", "2015"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5573288393806486}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.8750000000000001, 0.8571428571428571, 1.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.2857142857142857, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 0.052631578947368425, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2466", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_triviaqa-validation-3226", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.46875, "CSR": 0.5729166666666667, "EFR": 1.0, "Overall": 0.7864583333333334}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne", "occupational stress among teachers", "San Diego-Carlsbad-San Marcos metropolitan area", "the chief electrician position", "Newton", "static friction, generated between the object and the table surface", "the assassination of US President John F. Kennedy the previous day", "responsibility for the abductions", "Union Station", "Casalesi Camorra clan", "Kenneth Cole", "in a muddy barley field owned by farmer Alan Graham outside Bangor,", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.\"", "\"Golden Girls\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "Louisiana's Larry King", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad", "Amanda Knox", "jazz", "$530 million in debt", "Barney Stinson,", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two", "Bill", "J.G. Ballard", "Randy Phillips", "Sarah", "\"It got me thinking about what I would want to do when I got out of the game.", "1981", "\"17 Again,\"", "Chevron", "$81,8709", "Republicans", "EU naval force", "Chris Robinson", "Omar Bongo", "the Delta Queen steamboat", "Hyundai Steel", "skeletal dysplasia,", "London Heathrow's Terminal 5", "racism is not at play", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military action because we're getting frustrated seems to me somewhat dangerous.", "The White House Executive Chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\"", "\"Nor\u00fehymbra r\u012bce\"", "Ophelia", "Elena Ceausescu", "Argentinian", "Mercedes-Benz Superdome", "Otto von Bismarck"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6033744900932401}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.25, 0.8, 1.0, 0.4, 0.13333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-1285", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-2036", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-3424", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-251", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-1056"], "SR": 0.484375, "CSR": 0.5688920454545454, "EFR": 0.9696969696969697, "Overall": 0.7692945075757576}, {"timecode": 22, "before_eval_results": {"predictions": ["a high energy single terminal vacuum tube of his own design that had no target electrode", "WMO Executive Council and UNEP Governing Council", "the Bible", "New York and Virginia,", "two", "glowed even when turned off", "five female pastors", "water in a very dark and very cold place.", "sovereignty over them.", "April 6, 1994", "Prague", "backbreaking labor,", "a federal judge in Mississippi on March 22,", "\"There are not enough, so we are trying.\"", "$22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery", "$55.7 million", "The Real Housewives of Atlanta", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need. We need Barack Obama as the next president of the United States.", "military trial system", "Michael Jackson", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain", "male veterans struggling with homelessness and addiction.", "the longest domestic relay in Olympic history,", "Zimbabwe's main opposition party", "No. 1", "four", "Four bodies", "Friday", "Kingdom City", "Rima Fakih", "Tuesday night", "an mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "brain signals", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning -- the FDA's strongest -- to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Fakih", "the Isthmus of Corinth", "Nalini Negi", "( 2017 - 12 - 10 )", "Runcorn", "collarbone", "the bounding line", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Viva Zapata", "# Quiz # Question."], "metric_results": {"EM": 0.421875, "QA-F1": 0.5535389600187395}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.5, 0.19999999999999998, 0.23529411764705882, 0.7272727272727273, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.6666666666666666, 0.05714285714285714, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-379", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.421875, "CSR": 0.5625, "EFR": 1.0, "Overall": 0.78125}, {"timecode": 23, "before_eval_results": {"predictions": ["the phycobilin phycoerytherin is responsible for giving many red algae their distinctive red color", "was lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition", "Behind the Sofa", "Tulsa, Oklahoma", "56", "in Yemen", "2005", "Karen Floyd", "four Americans", "the two bodies out of the plant,", "Haiti", "Susan Boyle", "Saturday", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy Jackson", "Dangjin", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over", "threatening messages", "\"I have never thought about taking children away from their father, never,\"", "some Egyptians -- young and old -- have ever cast ballots.", "fake his own death", "\"in the interest of justice.\"", "martial arts,", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "Queen Elizabeth's birthday", "seeking help from Pakistani officials,", "Zuma", "haute, bandeau-style little numbers", "nine", "Iraq wants to see a much greater presence of U.S. companies in his country to help spur greater spending and investment on the country's infrastructure", "September 11, 2001", "about 50", "a group of teenagers", "in body bags on the roadway near the bus,", "al Fayed's security team", "Desmond Tutu", "$17,000", "Toy Story", "$81,88010", "to provide school districts with federal funds", "a transformiation, change of mind, repentance, and atonement", "Jason Lee", "sleep takes its name are a result of the brain trying to scan the events in the dream world", "nounA", "Kent", "beer and soft drinks", "five aerial victories.", "the Cherokee River", "Boxerloyal,", "James A. Lovell", "Florida"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5896056732246248}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.2666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.07692307692307691, 0.0, 0.5, 0.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.45161290322580644, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_newsqa-validation-1493", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3039", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.53125, "CSR": 0.5611979166666667, "EFR": 1.0, "Overall": 0.7805989583333334}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria,", "Taina Barioz of France", "Unseeded Frenchwoman", "him to step down as majority leader.", "United Nations World Food Program vessels carrying food and relief supplies to war-torn Somalia,", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "his club", "like the video-game challenge of continuously trying to best your own fuel economy", "1979", "Heshmat Tehran Attarzadeh", "great jazz", "an antihistamine and an epinephrine auto-injector for emergencies", "Bangladesh,", "Michael Arrington,", "one out of every 17 children under 3 years old", "President Sheikh Sharif Sheikh Ahmed", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Royal Variety Show.", "military personnel", "placed behind the counter.", "11", "one Iraqi soldier,", "40 former U.S. Marines or sons of Marines who lived at Camp Lejeune", "her fianc\u00e9", "racial intolerance.", "very aggressive.", "Carrillo Leyva", "Symbionese Liberation Army", "$8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "who is responsible for causing it and what should be done about it", "black is beautiful", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "Drug trafficking is a transnational threat, and therefore national initiatives have their limitations.", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "Washington.", "27 Awa", "Mark Obama Ndesandjo", "\"Dance\"", "Russia's role in the international community.", "\"Steamboat Bill, Jr.", "adultery", "the nucleus", "Vienna and that invitations would be issued to `` all the Powers engaged on either side in the present war ''", "Sebastian Lund ( Rob Kerkovich )", "Jimmy Carter", "Tom Watson", "Sandi Toksvig", "The Spyker F1 Team", "Viscount Cranborne", "Lake Buena Vista, Florida", "Iceland", "wedlock", "carbon"], "metric_results": {"EM": 0.46875, "QA-F1": 0.575813943001443}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, false, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.4, 0.0909090909090909, 1.0, 0.4, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.33333333333333337, 0.05555555555555555, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.0, 1.0, 0.0, 0.1142857142857143, 1.0, 0.0, 1.0, 0.4, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4128", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-1109", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685"], "SR": 0.46875, "CSR": 0.5575, "EFR": 1.0, "Overall": 0.77875}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Anthony Hopkins", "New Zealand", "Tamar", "rhododendron", "16", "specialist", "beetle", "phylum", "Wayne Allwine", "Westminster Abbey", "holographic method", "Pelias", "Barry White", "Northumbria", "Harvard", "cricket", "Seymour Hersh,", "quant", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "dandruff", "four", "elegant and restrained", "Prophet Joseph Smith,", "Huntington Beach,", "palladium", "the moon", "13", "a petticoat", "The Virgin Spring", "Canada", "Winston Churchill", "Stockholm", "Peter Parker", "Goldie Myerson", "Salvatore Ferragamo,", "bullfight", "Sparks", "Ginger Rogers", "Plymouth Rock", "Comedy Playhouse", "citric", "Charles Darwin", "John", "Miss Scarlet", "Marie Van Brittan Brown", "Southern California", "1995", "Bourbon", "Taylor Swift", "Rihanna", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "Rima Fakih is a Muslim with Lebanese heritage,", "Amy Bishop,", "calathus", "the Louvre", "independent, medium-sized university enrolling approximately 7300 students in five colleges and schools."], "metric_results": {"EM": 0.5, "QA-F1": 0.5921174719887956}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9523809523809523, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.1764705882352941, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-147", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.5, "CSR": 0.5552884615384616, "EFR": 0.96875, "Overall": 0.7620192307692308}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\",", "third", "affordable housing", "Mao Zedong", "Verona", "Pontiac", "elephants", "charcoal", "Frank McCourt", "jules Verne", "joseph smith", "clement", "Schengen Area", "red-white-and-blue", "city of chicago", "Famous Players", "Gary Puckett and The Union Gap", "Gerald Durrell", "joseph", "chieftains", "jason", "can eat and drink anything", "Halifax", "Noises Off", "joseph smith", "Stephen Potter", "Carlos the Jackal", "Edwina Currie", "gfstr\u00f6m", "Jeremy Thorpe", "1768", "\u201cFor Gallantry,", "Tuesday's child", "chicago", "Cahaba", "The Good Life", "Tahrir Square", "osmium", "clement figure", "27", "Jack Ruby", "tintoretto", "england Coates", "Saudi Arabia", "Lester", "Thailand", "Sydney", "dove", "Tunisia", "Prince Philip", "clement", "Tokyo", "Edgar Lungu", "3 cent", "a resting heart rate over 100 beats per minute", "672", "\"Linda McCartney's Life in Photography\", \"Some Like It Hot\", \"Kubrick's Napoleon: The Greatest Movie Never Made\", \"Marc Newson: Works\", and \"Saturday Night Live: The Book\",", "The Frost Place", "Twitter", "Juan Martin Del Potro", "27", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5420386904761905}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, false, true, true, false, false, false, false, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.3571428571428571, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.484375, "CSR": 0.552662037037037, "EFR": 0.9696969696969697, "Overall": 0.7611795033670034}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80 percent", "more than 70", "forced Tesla out leaving him penniless", "Benazir Bhutto", "nuclear program.", "at least 27 Awa", "(l-r) Paul McCartney, Yoko Ono Starr", "FBI Special Agent Daniel Cain,", "acid", "Wally", "1993", "after Wood went missing off Catalina Island,", "Rima Fakih", "Afghanistan", "Everglades", "closed on 366 for eight wickets", "1950s", "64", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos,", "$163 million (180 million Swiss francs)", "unwanted baggage", "around 3.5 percent of global greenhouse emissions", "oaxaca", "Orbiting Carbon Observatory", "Switzerland", "Kenneth Cole", "Janet and La Toya,", "Nine out of 10 children", "hours", "combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "it pulls the scab and it cracks, and it starts to bleed.\"", "al-Shabaab", "posting a $1,725 bail", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "Opry Mills,", "\" Number Ones\"", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "Obama", "\"gotten the balance right\"", "The oceans", "hit their victims' fingers with bricks, snip their backs open with wire cutters, carve them up with knives or simply shoot them", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "June 22, 1942", "between 1923 and 1925", "gilda", "Nahum Tate", "table Tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire State Building", "Benjamin Disraeli", "red"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6482502052545156}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.28571428571428575, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 0.8, 0.8, 1.0, 0.5, 0.0, 1.0, 0.06896551724137931, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-850", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-14496", "mrqa_searchqa-validation-15354"], "SR": 0.546875, "CSR": 0.5524553571428572, "EFR": 1.0, "Overall": 0.7762276785714286}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai Steel", "Monday night", "Florida", "rescue from a war-torn nation.", "40", "brutalized", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "the IV cafe.", "Arizona", "northward in May and June,", "Tetris,", "outside influences in next month's run-off election,", "aid to Gaza,", "rolled over Tuesday near Campbellton, Texas, killing two people and injuring more than a dozen,", "suppress the memories and to live as normal a life as possible;", "Tuesday in Los Angeles.", "immediate release into the United States of 17 Chinese Muslims", "the area was sealed off,", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "fuel economy", "\"project work\"", "\"Oprah: A Biography,\"", "80 percent of a woman's face", "20,000-capacity O2 Arena.", "to try to make life a little easier for these families by organizing the distribution of wheelchair,", "Ozzy Osbourne", "$50", "Australian officials", "Beatle's", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "At least 38", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events", "\"17 Again,\"", "Kabul,", "22", "Steven Gerrard", "12.3 million", "killing one Iraqi soldier,", "Rima Fakih", "Old Trafford", "to help bring creative projects to life ''", "season two", "Mary Elizabeth Patterson", "b-F", "The Fifth Amendment", "Nepal", "Merck and Co", "Fort Albany", "Knoxville, Tennessee", "grey", "transpiration", "hypomanic"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5577638461684513}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.25, 0.0, 0.4, 0.3636363636363636, 0.0, 0.4444444444444445, 0.0, 0.0, 1.0, 1.0, 0.0, 0.31578947368421056, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-7116", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.4375, "CSR": 0.5484913793103448, "EFR": 0.9722222222222222, "Overall": 0.7603568007662835}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen atmosphere", "Betty Meggers", "priests and virgins", "US - grown fruit", "the sex organs", "August von Mackensen", "diffuse interstellar medium", "August 6 and 9, 1945", "Doug Diemoz", "Jamestown", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "Iran", "cleanmgr. exe", "July 4", "pick yourself up and dust yourself off and keep going '", "John Garfield as Al Schmid", "to cross the world's oceans", "October 12, 1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "Cadillac", "Brenda", "a ranking used in combat sports,", "Husrev Pasha", "Jodie Sweetin", "palmar aspect of these fingers", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii et Spiritus Sancti", "al - Khulaf\u0101\u02beu ar - R\u0101shid\u016bn", "Lake Powell", "a decorative ornament", "September 6, 2019", "two senators,", "substitute good", "Marries Betty", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Prafulla Chandra Ghosh of the Indian National Congress", "economic recession", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "people in the 20th century who used obscure languages as a means of secret communication during wartime", "Donny Osmond", "phoenicus", "George W. Bush,", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday's", "Rickey Henderson", "Russia", "Manny Ramirez"], "metric_results": {"EM": 0.375, "QA-F1": 0.5167786682403618}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 0.9090909090909091, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.7142857142857143, 0.5714285714285715, 0.19047619047619047, 0.4, 0.0, 0.0, 1.0, 0.0, 0.3846153846153846, 1.0, 1.0, 0.0, 0.5, 0.5, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.13333333333333336, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.19354838709677422, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.18181818181818182, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3937", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10678", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-5753"], "SR": 0.375, "CSR": 0.5427083333333333, "EFR": 0.95, "Overall": 0.7463541666666667}, {"timecode": 30, "before_eval_results": {"predictions": ["a route to the destination is discovered and an entry is added to the switching table in each network node through which the connection passes", "Pleurobrachia", "1953", "AT&T", "first settlers of a region pioneers.", "Chingachgook", "shoes.", "nine", "Rashid Akmaev,", "acetylene", "a word, why confine myself to commonly used words,", "fiber.", "a fox's", "What's in a name?", "Winston Rodney", "sand", "Nanjing", "Montana", "a rabbit", "Louis XIV", "GILBERT & SullIVAN", "QVC", "the Belgae", "Joe Lieberman", "the Boston Marathon.", "fibreboard", "tin", "Florence Henderson", "Frida Kahlo", "refused to attend the victor's inauguration,", "\"Y\" 2 \"K\": An Eskimo", "Fat man, you shoot a great game of pool", "Hair", "William Randolph Hearst", "pumice", "ale", "primate", "telephone operator.", "a song performed by English pop punk band Busted.", "Casey Jones", "\"The New Colossus\"", "yelped in pain when the bee stung.", "Wagner", "Sarah,", "\"I think you're the most attractive of all my parents' friends.", "middleweight champion", "bronchodilators", "forty", "neon lamp", "a remarkable chain of lakes along the corridor of the Sangamon River", "Lexus' new RC Fbased GT3", "Earl Long", "Neil Patrick Harris", "Manuel `` Manny '' Heffley", "1999", "vitamin D", "five", "Alberto juantorena", "R&B", "Awake", "Doctor of Philosophy", "Pakistan's", "in Seoul.", "Sonia Sotomayor"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4694196428571429}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [0.14285714285714282, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-3579", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-2436", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.4375, "CSR": 0.5393145161290323, "EFR": 1.0, "Overall": 0.7696572580645161}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the macula", "a cylinder", "Merriam-Webster", "Joseph Conrad", "Diners' Club", "Christian Dior", "August Wilson", "William Shakespeare", "Notre Dame", "the Tablecloth", "Tate", "(John) Schaar", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania", "Mike Huckabee", "Queen", "Beta-blocker", "a brass Monopoly plate", "the gampi tree", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin", "Prince William", "Betty Suarez", "an R", "a white dairy cattle", "New Jersey", "the Elbow River", "Matt LeBlanc", "Marissa Jaret Winokur", "John Ford", "kismet", "Willy Wonka", "a warship", "aluminum", "General McClellan", "Ned Kelly", "a piles of papers", "a gravitational field", "Isis", "a bow", "Heroes", "on the two tablets", "a patient with end - stage renal disease", "seven", "Dr. A.G. Ekstrand", "Rocky Marciano", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Peretti", "two years,", "Lee Probert", "Tuesday on CNN's \"Larry King Live.\""], "metric_results": {"EM": 0.453125, "QA-F1": 0.5125}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16314", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-12751", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-16714", "mrqa_searchqa-validation-1379", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-10042", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_triviaqa-validation-2878", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-313", "mrqa_newsqa-validation-2123"], "SR": 0.453125, "CSR": 0.53662109375, "EFR": 1.0, "Overall": 0.768310546875}, {"timecode": 32, "before_eval_results": {"predictions": ["the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "Black Death", "Elton John", "John Stuart Mill", "Oblivion", "CIA", "pianissimo", "Rickey Henderson", "Indira Gandhi", "D. carota ssp. maritimus", "John Grunsfeld", "Angkor Wat", "Montreal", "Galileo Descartes", "a quark", "Show Boat", "Rudy Giuliani", "the First Amendment", "Virginia", "Thor", "New Jersey", "The Omega Man", "a walk-in pantry", "the barrel", "Summer Olympics", "Hugo Chvez", "Jewel", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Aidan Quinn", "Tiger Woods", "Los Angeles", "the north wind", "King Richard III", "Labour", "the pen", "Mexico", "Douglas Adams", "Strindberg", "Hawaii", "Stephen Crane", "France", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "Lewis Carroll", "Part 2", "Coconut Cove", "a pianoforte", "a trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "The son", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.625, "QA-F1": 0.7067954646580218}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, true], "QA-F1": [0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.08695652173913042, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-5449", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-1755", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-8063", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-9313", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767", "mrqa_newsqa-validation-3926"], "SR": 0.625, "CSR": 0.5392992424242424, "EFR": 0.9583333333333334, "Overall": 0.7488162878787878}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "(pathogens, an allograft) trigger a destructive immune response", "the man facing up, with his arms out to the side.", "about 5:20 p.m.", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"I think she's wacko.\"", "Saturday,", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "Most of the 103 children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans,", "forgery and flying without a valid license,", "Little Rock military recruiting center", "the Clunkers program promotes fuel economy", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship", "different women coping with breast cancer in", "a missile", "Police", "a cancer-causing toxic chemical.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space", "CNN", "no chance", "St. Louis, Missouri.", "he and the other attackers were from Pakistan and asked for a meeting with Pakistan\\'s High Commission.", "two to three years.", "two", "a bald Bard with a small beard, and bags under his eyes.", "the self-styled revolutionary Symbionese Liberation Army", "a fracas in a nightclub bar in the north-western of England city on December 29 of last year.", "two tickets to Italy on Expedia.", "Colombia.", "a welcoming, bright blue-purple", "resources", "1981", "Los Angeles", "16", "Pope Benedict XVI", "India in Mumbai", "NATO", "$40 and aslice of bread", "Kgalema Motlanthe,", "the Ming dynasty", "George II", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "Erika Girardi", "\" Terry the Tomboy\"", "Araminta Ross", "Mrs. Potts", "Pe peanut Chocolate", "the Brave"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6377124669312169}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.08, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7999999999999999, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.07407407407407407, 0.5714285714285715, 1.0, 0.0, 0.7499999999999999, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8000000000000002, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6585", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-1063", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-3668", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.515625, "CSR": 0.5386029411764706, "EFR": 1.0, "Overall": 0.7693014705882353}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "weren't taking it well.", "Washington State's decommissioned Hanford nuclear site,", "Yemen,", "bankruptcy", "nearly $2 billion in", "is a businessman, team owner, radio-show host and author.", "Abu Zubaydah,", "Spaniard Carlos Moya", "South African teenager Caster Semenya won the women's 800 meters gold medal", "children of street cleaners and firefighters.", "Joan Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers,", "Honduran", "Brazil", "three different videos that we like and want to know which ones you think are the best.", "strife in Somalia,", "Roy", "WBO welterweight title", "members of the Mohler family", "Meredith Kercher.", "former U.S. soldier Steven Green exhibited clear symptoms of acute stress disorder in Iraq and that a military psychiatric nurse-practitioner failed to diagnose the troubled infantryman and pull him out of combat.", "Demi Moore and Alicia Keys", "work together to stabilize Somalia and cooperate in security and military operations.", "Friday,", "a lump in Henry's nether regions was a cancerous tumor.", "20", "Matthew Fisher,", "$1.5 million", "Matt Kuchar and Bubba Watson", "40", "Big Three", "glamour and hedonism", "J. Crew.", "Department of Homeland Security Secretary Janet Napolitano", "543", "The patient,", "Robert Gates", "Israel", "2,700-acre", "confirmed that Coleman, 42, was being treated there after being admitted on Wednesday.", "in Seoul,", "Nicole", "Holding the Olympic medal she and her mom always wanted,", "next week.", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "Indian monks", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "(Bokm\u00e5l)", "Beer", "Revengers Tragedy", "1972", "Black Elk Speaks", "The Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5524003988518791}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3157894736842105, 0.0, 1.0, 1.0, 0.25, 1.0, 0.18181818181818182, 0.9090909090909091, 0.15384615384615385, 1.0, 0.4, 0.0, 1.0, 1.0, 0.8333333333333333, 1.0, 0.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.16, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2628", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2418", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_hotpotqa-validation-4378", "mrqa_searchqa-validation-7879"], "SR": 0.421875, "CSR": 0.5352678571428571, "EFR": 1.0, "Overall": 0.7676339285714285}, {"timecode": 35, "before_eval_results": {"predictions": ["they walked to the Surveyor, photographed it, and removed some parts which they returned to Earth.", "Border Reiver", "July 4,", "rum", "Nantucket", "an Islamic leadership position", "Northeastern Area State & Private Forestry", "Malibu", "Sisyphus", "sound absorption", "Australia's", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Prospero", "Purple", "the Black Sea", "the Battle of the Bighorn", "Shakers", "a bellwether", "Predeterminism", "potato chips", "Boxer", "The Spiderwick Chronicles", "Mabel", "Las Vegas", "Brandeis University", "the Rose Bowl", "Degas", "Jackie Kennedy", "light tunais", "Napa", "Italy", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Sadat", "a sundae", "Mary Shelley", "50 million", "Volitan Lionfish", "Richards", "Baby Boys", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Ra", "Lou Gehrig", "meaning and origin.", "1949", "Aamir Khan", "My Gorgeous Life", "British", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6223958333333333}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true], "QA-F1": [0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-9952", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12977", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827"], "SR": 0.546875, "CSR": 0.5355902777777778, "EFR": 1.0, "Overall": 0.7677951388888888}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia", "nothing gained", "silver", "Supernanny", "the Atlantic", "Cincinnati", "a mosque", "Henry Hudson", "the Peashooter", "dry ice", "Roosevelt", "Entourage", "eels", "Philadelphia", "The Museum of Modern Art", "the Unicorn", "John C. Frmont", "Russia", "Peabodys", "Hermann Hesse", "the Taj Mittal", "the diet", "Carmen", "Margaret Mitchell", "Claude Frollo", "Mark Knopfler", "Troilus", "a gloomy landscape", "Burt Reynolds", "Sphinx", "Louis Armstrong", "Mecca", "American New Wave", "Arby\\'s", "coffee", "a chivalry", "Robert Burns", "The Incredible Hulk", "Atlanta", "the Memphis Belle", "Burkina Faso", "the Central Pacific", "the office of solicitor general", "Icelandic", "a wolf", "The NFL", "Piaf", "Ivan IV", "a prologue", "the tree", "an investor couple", "Jack Gleeson", "Phil Hurtt", "snakes", "Massachusetts", "City of Starachowice", "Richard Boleslawski", "2009", "Democratic", "a meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.640625, "QA-F1": 0.6938244047619048}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-9131", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-1409", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_triviaqa-validation-1125", "mrqa_hotpotqa-validation-2000", "mrqa_newsqa-validation-3951"], "SR": 0.640625, "CSR": 0.5384290540540541, "EFR": 1.0, "Overall": 0.769214527027027}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "Impressionist", "Sanders", "oats", "Mitt Romney", "Ivan", "Sally Field", "1927", "Eritrea", "pi", "tin", "Lake Pontchartrain", "a turtleneck", "W", "Marriott", "France", "Canada", "The Secret", "gold", "collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Mississippi River", "Sam Pipes", "Euclid\\'s", "Eva Peron", "Cain", "Ed Asner", "X-Men", "the Louvre", "chinook", "Prison Break", "one", "Maine", "a small portion of goat milk", "Meg", "The Sonnets", "tennis", "the prince", "Peter Bogdanovich", "Johnny Mathis", "Jesus", "Streisand", "the Cenozoic Era", "nolo contendere", "Jr. Walker", "Czech Republic", "a fish", "the NIRA", "John Ernest Crawford", "beta decay", "France", "menelaus Menelaus", "Mariette", "Ike Barinholtz", "\"The Little Prince\"", "Australian", "the sins of the members of the church,", "$22 million", "\"17 Again\"", "Nelson County"], "metric_results": {"EM": 0.609375, "QA-F1": 0.65625}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, false, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-16789", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-6003", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-5179", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-2766", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-6998", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-12168", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6487", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900"], "SR": 0.609375, "CSR": 0.540296052631579, "EFR": 1.0, "Overall": 0.7701480263157895}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition", "Holden", "Joseph McCoy", "Leptospirosis", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "brushes", "a chino", "forgetting Sarah Marshall", "Witness", "Martha Tabram", "3800", "William Shatner", "phylum", "Spain", "the brain", "Bermuda\\'s", "Macbeth William Shakespeare", "comedy", "Mary Poppins", "Casowasco Camp", "The Fresh Prince of Bel-Air", "Nod", "watermelon", "the bathwater", "second", "Livin' on A Prayer", "Sherlock Holmes", "chocolate", "Marie Antoinette", "Ford", "Marie Curie", "Roger B. Taney", "congruent", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "Harry Potter and the Philosopher Stone", "Manganese", "forests", "Olympia", "Waylon Jennings", "William Holden", "Brazil", "British", "Marlee Matlin", "Scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "the different levels of importance of human psychological and physical needs", "one", "Norfolk Island", "American brothers", "sexual activity", "Sam Tick", "Sandro Bondi refused to attend", "voluntary manslaughter", "\"deep sorrow\"", "Pygmalion"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6260416666666666}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.1, 1.0, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-1783", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-600"], "SR": 0.5625, "CSR": 0.5408653846153846, "EFR": 1.0, "Overall": 0.7704326923076923}, {"timecode": 39, "before_eval_results": {"predictions": ["Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana", "a Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "The Bridge on the Kwai", "the Fall of Constantinople", "an", "Jefferson", "Ezra Pound", "a river", "a q-tip", "Alaska", "Dixie", "a nonprofit institution that helps improve policy and decisionmaking", "Warren Harding", "engrave", "Gracie", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "conformation", "Ratatouille", "neurons", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "a marathon", "Purple Rain", "a herb", "a plan", "GIGO", "Johannes Brahms", "Charleston", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo Clinic", "Led Zeppelinthe", "a Tesla coil", "Denmark, Norway and Schleswig - Holstein", "Anna Murphy", "March 15, 1945", "Charles Darwin", "a cricket stadium", "Miles Morales", "Honey Irani", "a Small World", "the Kalahari Desert", "a Christian farmer who took exception to her \"inappropriate behavior\" while filming a music video on his land.", "Bob Dole", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5163690476190476}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-4408", "mrqa_searchqa-validation-16066", "mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-15434", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-7830", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_searchqa-validation-11250", "mrqa_searchqa-validation-9903", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-3278", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.421875, "CSR": 0.537890625, "EFR": 1.0, "Overall": 0.7689453125}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "a 2003 South Korean horror film", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000", "Yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133", "We Need a Little Christmas", "Tsavo East National Park", "the New York Islanders", "1345 to 1377", "nearly 80 years", "Jean Acker", "the Championship", "The Gettysburg Address", "Whitney Houston", "Premier League club Manchester United and the England national team", "Stravinsky\\'s \"The Rite of Spring\"", "1", "26,000", "Kristin Scott Thomas", "Edwin Mah Lee", "1958", "1993", "American burlesque", "Afro-Russian", "Loretta Lynn", "Lancashire, England", "a Boeing B-17 Flying Fortress", "1994\u201395", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "Ployer Peter Hill", "Mindy Kaling", "1988", "Leon Uris", "Erika Mitchell Leonard ( born 7 March 1963 ), known by her pen name E.L. James", "Mason Alan Dinehart III", "Tevye", "Sir Tom Finney", "CameroonCameroon", "blood", "by military personnel to hazardous materials", "two", "Iggy Pop invented punk rock.", "a riddle", "the Mayor of Casterbridge", "Leonardo DiCaprio", "a narcissistic ex-lover who did the protagonist wrong,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7105530753968254}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4749", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_naturalquestions-validation-6326"], "SR": 0.578125, "CSR": 0.5388719512195121, "EFR": 1.0, "Overall": 0.7694359756097561}, {"timecode": 41, "before_eval_results": {"predictions": ["a fumble", "10", "did not identify any of the dead.", "England", "2005", "4,000", "The Valley Swim Club", "an angry mob.", "normal maritime", "Sri Lanka", "Touma, who was seven months pregnant,", "average of 25 percent", "was sentenced in a New Jersey court for fatally shooting a limo driver", "Al Nisr Al Saudi", "50,000", "piano", "$250,000", "a \"prostitute\"", "Zed\\'s fossil", "tax", "Brazil", "acute stress", "Russia and China", "Facebook and Google,", "through a facility in Salt Lake City, Utah,", "Manmohan Singh's Congress party", "Haiti", "Tuesday afternoon", "Pakistan", "23 years.", "head injury.", "Bahrain", "an open window", "Leo Frank", "Paul McCartney", "off Haiti's coast", "President Robert Mugabe", "don't have to visit laundromats", "three", "Diversity", "on-loan David Beckham claimed his first goal in Italian football.", "\"He is more American than German.\"", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died,", "Authorities in Fayetteville, North Carolina,", "Suwardi", "the Taliban", "Hillary Clinton", "Rihanna", "angular rotation", "the right side of the heart", "54 Mbit / s", "in the County of Gloucestershire", "B-24 Liberator", "Super Sugar Crisp", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "FMCSA"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7445419597763347}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.5333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.625, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-1227", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-10945"], "SR": 0.640625, "CSR": 0.5412946428571428, "EFR": 1.0, "Overall": 0.7706473214285714}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Arizona.", "Zimbabwean government", "Italian Serie A", "Darrel Mohler", "dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "MDC offshoot is part of larger deal that has not been signed by anyone.", "42", "Tuba is taking on the swords of the Taliban.", "global climate change.", "80 percent", "1979", "Ben Hogan biopic \"Follow the Sun,\"", "Elena Kagan", "CBS, CNN, Fox and The Associated Press.", "an auxiliary lock", "1-1", "AbdulMutallab", "Myanmar", "\"We don't see at this point any indication of an individual out in the neighborhoods committing additional crimes or homicides,", "Marcus Schrenker,", "Bienvenido Latag of the Philippine National Police.", "poems telling of the pain and suffering of children", "the program was made with the parents' full consent.", "Barack Obama", "The Red Cross, UNHCR and UNICEF", "Russian supermodel and philanthropist", "debris", "not guilty of affray", "capital murder and three counts of attempted murder", "Basel", "at least 17", "Daytime Emmy Lifetime Achievement Award.", "state senators who will decide whether to remove him from office", "31 meters (102 feet)", "nude beaches.", "how preachy and awkward cancer movies can get.", "her father's", "partially submerged in a stream in shark River Park in Monmouth County", "three", "Islamabad", "partying", "Capitol Hill,", "its nuclear ambitions are for peaceful means,", "1940's", "March 22,", "think are the best.", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"Antichrist\"", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Orion", "brown", "Selfie", "23 March 1991", "England", "Los Alamos National Laboratory", "Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6495265858958292}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.10526315789473685, 0.0, 0.5714285714285715, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.5333333333333333, 0.5, 0.4, 0.0, 0.9, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-564", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1297", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.515625, "CSR": 0.5406976744186047, "EFR": 1.0, "Overall": 0.7703488372093024}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "legitimacy of that race.", "88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "that the assassination program, not the 2007 increase in U.S. forces in the war zone known as \"the surge,\" is primarily responsible for the reduction of violence in Iraq.", "hardship for terminally ill patients and their caregivers,", "Araceli Valencia,", "Zac Efron", "finance", "$2 billion", "pesos ($42 billion)", "1937,", "The station", "Karthik Rajaram,", "lifeless, naked body", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Afghanistan's restive provinces", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "could be secretly working on a nuclear weapon is a major development, but not one that should lead the U.S. to consider a military strike against the Tehran regime,", "that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Hyundai", "100 percent", "Saturday about 20 feet above flood stage.", "Afghanistan,", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Indian Tribe", "a Muslim with Lebanese heritage,", "South Africa,", "Barack Obama", "helicopters and unmanned aerial vehicles", "U.S. Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "54 bodies", "14 people were dead in the center,", "$50 less,", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960", "Villa Park", "landless farmers", "pool", "1822", "The Dressmaker", "Trilochanapala", "frosted", "a buffalo", "ruby slippers", "parietal"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6109632554945055}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, false, true, true, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.5, 0.0, 1.0, 0.5, 0.8571428571428571, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.15, 0.923076923076923, 0.42857142857142855, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.484375, "CSR": 0.5394176136363636, "EFR": 1.0, "Overall": 0.7697088068181819}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Chris Eubank Jr.", "Florida", "Benj Pasek and Justin Paul", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Highlands", "Stonecoast MFA Program in Creative Writing", "Guadalcanal", "Dan Crow", "\"War & Peace\"", "Hamilton County, Ohio", "\"What Are Little Girls Made Of?\"", "Berea College", "Omaha Nighthawks", "Luca Guadagnino", "Charmian Carr", "Germany and other parts of Central Europe,", "New York Islanders", "Amy Smart", "26,788", "the Troubles", "1967", "Marktown", "nationality law", "Radcliffe College", "James Abram Garfield", "Ford", "weighed against the feather of truth", "India", "Lutheranism", "Charmed", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "1st Marquess of Westminster", "4,000", "Henry Luce", "I'm Shipping Up to Boston", "American", "Scottish singer and \"Britain's Got Talent\"", "Chinese", "sixth - largest country by total area", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "dependable Camry", "Steven Green", "in a hotel,", "Chaucer", "rattlesnake", "suspicion", "healthy"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5724330357142857}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, false, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-733", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-4454", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-13986", "mrqa_searchqa-validation-4414"], "SR": 0.484375, "CSR": 0.5381944444444444, "EFR": 1.0, "Overall": 0.7690972222222222}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "Indian Ocean waters near the Gulf of Aden,", "three", "crocodile eggs", "Colorado prosecutor", "Polis", "on Saturday.", "on the family's blog", "in July for A Country Christmas,", "to sniff out cell phones.", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Sharon Bialek", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Bob Dole,", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie meals that he could prepare.", "Heshmatollah Attarzadeh", "Use the ireport form", "government", "Nine out of 10 children", "police", "Raymond Soeoth of Indonesia and Amadou Diouf of Senegal in West Africa,", "the jaws of a crocodile", "a bronze medal", "more than 200.", "Congress", "Susan Boyle", "military ID cards,", "Phillip A. Myers.", "Obama's", "Gyanendra,", "she does not expect enough additional evidence to surface for that finding to be revised.", "Casey Anthony,", "officers at a Texas  airport", "Arnoldo Rueda Medina,", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers,", "two weeks ago", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Dennis Rodman, Tom Green and Brian McKnight,", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Arsene Wenger", "slavery", "Kat ( Jessie Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan )", "enkuklios paideia or `` education in a circle '' -- of late Classical and Hellenistic Greece", "Enid Blyton", "Johnny Mathis", "48 Hours", "Champion Jockey", "Luca Guadagnino", "Kiki Sheppard", "Maya Angelou", "it's a month after her last race and a", "1-1/2 fl.", "Vickers Vimy"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6079387839256261}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.33333333333333337, 0.888888888888889, 0.5263157894736842, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.07407407407407407, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.7499999999999999, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-691", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1582", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431"], "SR": 0.515625, "CSR": 0.5377038043478262, "EFR": 1.0, "Overall": 0.7688519021739131}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "\"The Apple Inc. co-founder Steve Wozniak and his partner show off their moves on \"Dancing With the Stars.\"", "without bail", "12.3 million", "Mexico", "Real Madrid", "Vivek Wadhwa,", "Brett Cummins,", "Indian Army", "Saturday", "Nicole", "legitimacy of that race.", "Adidas", "Dennis Davern,", "Africa.", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "\"Nothing But Love\"", "allegedly involved in forged credit cards and identity theft", "June 6, 1944,", "Middle East and North Africa,", "2-1", "October 19,", "\"It was a wrong thing to say,", "Seoul,", "promotes fuel economy and safety while boosted the economy.", "Amyotrophic Lateral Sclerosis", "eight", "Siri.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback forest-", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place,", "38", "Her husband and attorney, James Whitehouse,", "children's education.", "two", "most gigantic pumpkins in the world,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "Discworld", "Japan", "foxhunting", "New York", "travel diary", "16,116", "\"Cry-Baby\"", "sap", "a bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7241744725580932}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.09523809523809525, 0.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.13793103448275862, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.6875, "CSR": 0.5408909574468085, "EFR": 1.0, "Overall": 0.7704454787234043}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Airlines", "A Rush of Blood to the Head", "5", "Chicago", "The Ones Who Walk Away from Omelas", "child actor", "Dennis Kux", "drawing the name out of a hat", "Brett Eldredge", "Indian Super League", "two or three", "Badfinger", "Lady Frederick Windsor", "point coloration with a pale body and relatively darker extremities,", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1930s and 1940s", "5,112", "1992", "retail, office and residential", "14,673", "6'5\"", "Mickey Gilley", "Switzerland\u2013European Union relations", "German shepherd", "Mexican", "December 24, 1973", "1933", "Tremont, Maine", "Ulver and the Troms\u00f8 Chamber Orchestra", "1730", "London Luton Airport", "the Salzburg Festival", "Britney Spears", "Afghanistan", "1991\u201392", "Imelda Marcos", "Randall Boggs", "Part II", "Boston", "lion", "Royal", "World War II", "Knoxville", "Three's Company", "Doomtree", "Labour", "Linda McCartney's Life in Photography", "Erich Maria Remarque", "September 14, 2008", "79", "Buffalo Bill", "Romania", "Zephyr, Billy Cobham, Alphonse Mouzon, the James Gang, Deep Purple, and Moxy", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "the Rotunda", "Bank of England"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6506184787434788}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-5435", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.5625, "CSR": 0.5413411458333333, "EFR": 1.0, "Overall": 0.7706705729166666}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "Helsinki", "sushi", "offensive", "Vulcan", "the hexameters of Miles Standish", "Fawn Hall", "waive", "kenya", "Barnum", "Johnny Weissmuller", "negative electrode", "a torque wrench", "gold", "Marlon Brando", "Middle high German", "Renoir", "University of Kentucky", "the ruddy", "Brussels", "Macbeth", "General Lee", "$18.2 billion", "Fyodor Dostoevsky", "Martin Luther", "Clue", "London", "Norway", "Andrew Johnson", "seven", "Mike Connors", "Citation", "Jim Inhofe", "sancire", "Corpus Christi", "South Africa", "an ostrich", "the constitution", "not", "keller", "Desperate Housewives", "Galileo", "Canada", "Anne Hathaway", "a strike", "the bat", "West Virginia", "James Monroe", "movie theater", "Chain of Rocks", "critic", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambidextrous", "chariot", "Humberside Airport", "more than 265 million", "100 million", "help rebuild the nation's highways, bridges and other public-use facilities.", "head injury.", "The pontiff reiterated the Vatican's policy on condom use as he flew from Rome to Yaounde,", "Charles"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6303308823529412}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, false, false, true, false, true, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.9411764705882353, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_hotpotqa-validation-2171", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663", "mrqa_triviaqa-validation-1959"], "SR": 0.546875, "CSR": 0.5414540816326531, "EFR": 1.0, "Overall": 0.7707270408163265}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Colorado", "Pamela Anderson", "carioca", "Treasure Island", "Pocahontas", "improvised", "(Whizzer) White", "electric", "an inhalant or deodorant", "the magnum", "Ferris B Mueller", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "a draft horse", "Ernest Lawrence", "rodeo", "fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "king", "Department of Homeland Security", "the Black Sea", "a leotard", "Bulworth", "a shovelfuls", "the mouthpiece", "Cuba", "the Fellowship of the Ring", "Olivia Newton-John", "bug spray", "Manhattan", "Feb 1, 2012", "Leontyne Price", "a compost", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "Charles Askegardshe", "the Pierian spring", "Hungary", "a burnoose", "Philadelphia", "peanut butter", "Viet Thanh Nguyen", "cork", "Lex Luthor", "food and clothing", "( Schwarzenegger ) and his companion, the thief Malak ( Walter )", "Master Christopher Jones", "hieroglyphic", "Meadowbank", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "the incident Sunday evening", "three", "poems", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.484375, "QA-F1": 0.5359375}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, false, true, true, false, false, true, false, false, false, false, true, false, false, false, true, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.13333333333333333, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-2388", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-13674", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-2737", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301"], "SR": 0.484375, "CSR": 0.5403125, "EFR": 1.0, "Overall": 0.77015625}, {"timecode": 50, "UKR": 0.74609375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.82421875, "KG": 0.4875, "before_eval_results": {"predictions": ["Fatih Ozmen", "a facelifted 850 saloon", "Skyscraper", "Cadillac", "Norway", "picaresque", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hilo", "Robert Downey, Jr.", "Continental", "band director", "Visigoths", "Anaheim", "Reinhard Heydrich", "Big Ben", "Standard Oil", "The Longest Yard", "Chiwetel Ejiofor", "president", "19th-century", "Lady Antebellum", "Stratfor", "the 43rd President of the United States", "Tottenham Hotspur", "1958", "Vixen", "a scholar during the Joseon Dynasty", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Santa Fe", "the Henry Jackson Society", "Adelaide Lightning", "Operation Neptune", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "50 km north-northeast of Bologna", "authored the Morrill Land- Grant Acts of 1862 and 1890,", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "American", "hamburgers", "Liverpool", "little hairs", "Luigi Segre", "United States House of Representatives", "February 9, 2018", "1980", "Nacio Herb Brown", "Geoff Hurst", "Precambrian", "Mull", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "the shootings,", "neurological disease", "Paul Newman", "Puccini", "John Candy", "milk and honey"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5859375}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 0.0, 0.0, 0.0, 0.4, 0.2, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-3791", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2137", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-355", "mrqa_searchqa-validation-13015"], "SR": 0.46875, "CSR": 0.5389093137254901, "EFR": 1.0, "Overall": 0.719344362745098}, {"timecode": 51, "before_eval_results": {"predictions": ["1979", "a Native American", "The Chiltern Shakespeare Company", "1898", "Stacey Kent", "31 December 1908 \u2013 20 September 2005", "Arthur Freed", "Elizabeth Kekaikuihala Keka\u02bbaniauokalani Kalaninuiohilaukapu La\u02bbanui", "Gothic Revival", "Rochester", "J. Robert Oppenheimer", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "air-cushioned sole", "The White Knights of the Ku Klux Klan", "WikiLeaks", "Nine-card Brag", "Montana State University", "Tool", "the Wikimedia Foundation", "Flashback: The Quest for Identity in the United States", "ARY Films", "1987", "dementia", "two Grammy awards", "Port of Boston", "Switzerland", "Las Vegas", "1961", "Rochdale,", "the Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward position", "2012", "the United States", "Dame Eunice Kennedy Shriver Jr.", "35", "Mark Neary Donohue Jr.", "Peach", "Italian", "Tom Rob Smith", "Archie Andrews", "George Lawrence Mikan, Jr.", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force", "Separate Tables", "devonian sea", "aknow", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "October 9.", "J. H. Ingraham", "hunter sauce", "The Quest of Erebor", "carbon"], "metric_results": {"EM": 0.609375, "QA-F1": 0.680792297979798}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.2666666666666667, 0.5, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-5442", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-1452", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-4525", "mrqa_hotpotqa-validation-2206", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.609375, "CSR": 0.5402644230769231, "EFR": 1.0, "Overall": 0.7196153846153847}, {"timecode": 52, "before_eval_results": {"predictions": ["Carrie", "King Henry VIII", "lead", "the Rose Bowl", "the VC-25", "amber", "Denmark", "terriers", "Katrina & the Waves", "Nazareth", "freestyle", "men", "cancer", "Colonel Jack O'Neill", "Lou Reed", "General Robert E. Lee", "Norway, Sweden, Finland", "Emma Peel", "canvas", "succulents", "The X-Files", "Frankie Muniz", "a blue whale", "Georgian Bay", "the coding system", "kinetic", "Santera", "Starsky and Hutch", "a lighthouse", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Sixberry", "a river", "Zeus", "Bob Fosse", "Ankara", "condensation", "eight", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "the revolutionary army", "southern Eritrea", "Applebee's", "John Tyler", "Daniel Craig", "humility", "programming", "Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "when mixing solvents or changing their temperature", "Doctor Zhivago", "Bristol", "(Roger) Bowls", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1961", "South America and Africa.", "the clothes we make for the runway", "fake his own death by crashing his private plane into a Florida swamp.", "Stockton & Darlington"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5188601762820513}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, false, false, true, false, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, true, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.625, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6153846153846153, 0.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-4668", "mrqa_searchqa-validation-13812", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-16018", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-10899", "mrqa_searchqa-validation-15002", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-15500", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.46875, "CSR": 0.5389150943396226, "EFR": 1.0, "Overall": 0.7193455188679245}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Saint Etienne", "After Shawn's kidnapping", "to manage the characteristics of the beer's head", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "cleansing ritual", "birch", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Andy Cole and Shearer", "season two", "in the sequence of pieces of DNA called genes", "global crowdfunding platform focused on creativity and merchandising", "tropical desert climate", "David Motl", "the Atlantic coast of Africa", "Wisconsin", "December 19, 1971", "2017", "the German government", "bacteria", "the magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "Lulu", "1961 during the Cold War", "111", "Brazil, Turkey and Uzbekistan", "the Bactrian", "13", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "compound sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophie Monk and Eddie Perfect", "Coriolis force", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Daya Jethalal Gada", "over 74 languages", "warning signs", "various submucosal membrane sites of the body", "a noble gas", "Department of Health and Human Services", "four distinct levels", "Janie Crawford", "Justin Timberlake", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "David Suchet", "Paul Gauguin", "extreme", "creeks, fringing the southwest mouth of Lagos Lagoon,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds).", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "off the coast of", "the Northwest Territories", "Uncle Vanya", "a robe", "the death of a pregnant soldier whose body was found Saturday morning in a motel,"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5737800603371723}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.7692307692307692, 0.8, 0.08333333333333334, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 0.25, 1.0, 0.0, 0.5, 0.4615384615384615, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.3076923076923077, 0.41379310344827586, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3076923076923077, 0.4444444444444445, 0.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-3898", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-6745", "mrqa_triviaqa-validation-4748", "mrqa_hotpotqa-validation-3974", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459", "mrqa_newsqa-validation-2516"], "SR": 0.421875, "CSR": 0.5367476851851851, "EFR": 0.9459459459459459, "Overall": 0.7081012262262262}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "one of the seven heavenly virtues", "Tex - Mex cuisine is characterized by its heavy use of shredded cheese, meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "George Harrison", "Kanawha Rivers", "1803", "President pro tempore of the Senate", "3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "My Heart Will Go On ''", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Coldplay", "Arkansas", "Bangalore, India", "Lawrence John Wargrave", "Atlanta", "Magic Johnson", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "Kirstjen Nielsen", "cylinder of glass or plastic that runs along the fiber's length", "no embryo", "741 weeks", "Zimbabwe", "(EBU)", "Sarah Palin", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison,", "China's government accused the ship of violating Chinese and international laws during its patrols,", "beautiful childhood", "Tater Tots", "Yemen", "quod erat demonstrandum", "Coffeyville"], "metric_results": {"EM": 0.5, "QA-F1": 0.6279676013191837}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 1.0, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.4347826086956522, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.060606060606060615, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 1.0, 0.8, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 0.8571428571428572, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.14285714285714288, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-6203", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-940", "mrqa_hotpotqa-validation-2751", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-8575"], "SR": 0.5, "CSR": 0.5360795454545455, "EFR": 0.90625, "Overall": 0.700028409090909}, {"timecode": 55, "before_eval_results": {"predictions": ["11 : 15 p.m.", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "the Royal Navy's frigate HMS Shannon", "\"The team, which became known as the Lisbon Lions, managed by Jock Stein", "Columbia River Gorge in the U.S. states of Oregon and Washington", "the Northeast Monsoon or Retreating Monsoon", "2013", "American country music group The Nitty Gritty Dirt Band", "living and organic material", "annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves", "product / market fit", "London", "Incumbent Democratic mayor Marty J. Walsh", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Ernest Rutherford", "depolarization of the cardiac muscle begins at the sinus node", "the sacroiliac joint", "png HTTP / 1.1", "the Brewster family", "1 mile ( 1.6 km )", "pop ballad", "1985", "during meiosis", "16 May 2007", "Arnold Schoenberg", "an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "in Hittite and Mesopotamian laws and treaties", "Scarlett Johansson", "InterContinental Hotels Group family of brands", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "dead stratified squamous, keratinized", "2007", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries", "10,605", "Ryan Evancic", "Sebastian Vettel", "Alamodome in San Antonio, Texas", "Megatron", "prokaryotic microorganisms", "depending on the gender of the reigning monarch", "pathology", "Joe Marsden", "\"Celebrity Big Brother\"", "(Roger) Casement", "James Garner", "Boston, Massachusetts", "Robert Jenrick", "Robert Matthew Hurley", "urging more help for military members, especially for those returning from war.", "five", "TNT series", "(Ryan) Cheatham", "Christopher Ciccone", "Eiffel Tower", "Teddy Riley"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5747670962418352}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, true, false, false, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4615384615384615, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.9333333333333333, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.14285714285714288, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5714285714285715, 0.0, 1.0, 0.7096774193548387, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.09090909090909093, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-2098", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-4388", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-46", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-14136"], "SR": 0.46875, "CSR": 0.5348772321428572, "EFR": 0.9705882352941176, "Overall": 0.7126555934873949}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "September 1939", "Harishchandra", "16", "1877", "1999", "Old Trafford", "Tami Lynn", "complementary to U + 2234 \u2234 therefore ( HTML & # 8756 ; &there4 ; )", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "Aernoutsz", "4 September 1936", "heat", "1940", "Authority", "prima aprilis ends at noon of April 1st", "DJ", "The claims process starts at noon Eastern Time and ends 24 hours later", "Francisco Pizarro", "a habitat", "Ben Faulks", "Lady Gaga", "negatively affect a person's personal, work, or school life, as well as sleeping, eating habits, and general health", "1989", "Liam Cunningham", "Dody Goodman", "Walter Pauk", "May 1979", "the septum", "Gentry Buddhism", "the forex market", "`` I Believe ''", "Sir Ernest Rutherford", "Nigel Lythgoe, Mia Michaels, and Adam Shankman", "December 2, 2013", "gastrocnemius", "Art Carney", "elaborated as early as in 1651 by Thomas Hobbes in his Leviathan", "March 26, 1973", "11 February 2012", "on location", "President Lyndon Johnson", "week 4 of development", "a Christmas Tree", "1840", "2007", "Branson", "first baseman", "Tumi Inc.", "Shiel", "\"Heavy metal musician Ozzy Osbourne", "Polo because \"it was the sport of kings.", "the music label that owns them", "ego", "Nova Scotia", "Sir Isaac Newton", "\"Love Letter\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.6649591630130313}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, false, true, false, true, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, true, true, true, true, false, false, false, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.17391304347826086, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.5714285714285715, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 1.0, 0.5882352941176471, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4303", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-7452", "mrqa_naturalquestions-validation-2821", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-7852", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-7486", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-5421", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-10569"], "SR": 0.515625, "CSR": 0.5345394736842105, "EFR": 0.967741935483871, "Overall": 0.7120187818336163}, {"timecode": 57, "before_eval_results": {"predictions": ["the Old French tailleur ( `` cutter '' )", "Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "The Golden Gate Bridge", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "between 0.5 % and 1 %", "the Pearl Harbor attack", "Monk's", "Fred E. Ahlert", "the birth of a Sim", "Ozzie Smith", "Mark Jackson", "1983", "Resident Commissioner", "January 2018", "all land - living organisms, both alive and dead", "September 30", "pigs", "Gerald Ford", "September 8, 2017", "1998", "a political ideology", "Spektor", "converging lenses", "Cell nuclei", "1946", "Thursdays", "Henry Haller", "the scale used for a composition is usually indicated by a key signature at the beginning to designate the pitches that make up that scale", "Phone - a- Friend", "to refer to a god of the Ammonites", "P.V. Sindhu", "Carpenter", "Asuka", "Wilt Chamberlain", "Klaus Meine", "Uzbekistan", "the UNESCO / ILO Recommendation concerning the Status of Teachers", "a document of the United States Department of Defense", "an inward spiral", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "during prenatal development", "high - energy phosphates in skeletal muscle", "Ronnie Dunn", "England", "Felicity Huffman", "1908", "Sir Henry Cole", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Fomento Econ\u00f3mico Mexicano, S.A.B. de C.V.", "\"Irish Chekhov\"", "Charlie Wilson", "Mosteller,", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "the Mayan settlement"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5739780618686869}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false, false, true, true, true, true, false], "QA-F1": [0.6666666666666666, 0.19999999999999998, 1.0, 0.14285714285714288, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.36363636363636365, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.125, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.24, 0.0, 0.9600000000000001, 1.0, 0.8, 0.4, 0.25, 0.0, 1.0, 1.0, 0.3, 0.8181818181818181, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-9251", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-5825", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.453125, "CSR": 0.533135775862069, "EFR": 0.9142857142857143, "Overall": 0.7010467980295566}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "mid-size four - wheel drive", "1986", "North Dakota", "July 18, 2013", "Deuteronomy", "in digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979 -- 80 season", "son of Edward", "iron", "the Reverse - Flash", "Los Angeles, California", "the Declaration of Independence", "a Genoise sponge base, a layer of orange flavoured jam and a coating of chocolate", "`` Lady Arbuthnot's Chamber", "Nebuchadnezzar", "Prince Akeem Joffer", "17 - year - old", "between 1923 and 1925", "the brain and spinal cord", "Seattle, Washington", "October 1898", "Yosemite National Park", "Emma Watson", "LED illuminated display", "cranberry sauce", "1917", "January 2004", "Bonnie Plunkett ( Allison Janney )", "smen", "Mount Sinai", "Macon Blair", "the genome", "to identify persons who are unable or don't want to drive", "Convention was founded with the dual purpose of abolishing the monarchy and drafting a new constitution", "four", "tectonic", "Steve Russell", "peace between two entities ( especially between man and God or between two countries )", "New York University", "intermematic space", "the Northeast Monsoon", "13 February", "291", "the early 1960s", "Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "March 1995", "Zuzu & Zaza", "dysmenorrhea", "1960", "Justin Trudeau", "2006", "Walldorf", "superhero roles as the Marvel Comics characters Steve Rogers / Captain America in the Marvel Cinematic Universe", "crude oil", "Peppermint oil, soluble fiber, and antispasmodic", "U.S. Navy", "ferry", "Leland Stanford", "Oaxaca", "Nepal"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5435267325553703}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, false, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, false, true, true, false, false, true, true, true, true, false, false, true, true, true, true, false, false, false, false, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.9411764705882353, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.3076923076923077, 0.6666666666666666, 0.0, 0.0, 0.2857142857142857, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.14285714285714288, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5263157894736842, 0.0, 0.21052631578947367, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-4506", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-7024", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-8847", "mrqa_triviaqa-validation-3434", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_newsqa-validation-2428", "mrqa_searchqa-validation-10231"], "SR": 0.40625, "CSR": 0.5309851694915254, "EFR": 0.9210526315789473, "Overall": 0.7019700602140946}, {"timecode": 59, "before_eval_results": {"predictions": ["a modulator molecule ( or allosteric regulator ) binds", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic", "9", "a useless, time - wasting activity", "head coach of the Philadelphia Eagles of the National Football League ( NFL )", "February 2011", "Audrey II", "Tim Russert", "Masha Skorobogatov", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "by January 2018", "American country music singer George Strait", "lowest air temperature record was set on 21 July 1983, with \u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F ) at Vostok Station", "Herman Hollerith", "94 by 50 feet", "transmission", "Gibraltar", "chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "January 12, 2017", "The Miracles", "to provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Marie Fredriksson ( vocals ) and Per Gessle ( vocals and guitar )", "Long Island", "1988", "German", "a castle", "Michael Crawford", "the Devastator", "the final episode of the series", "April 2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 3", "1950s", "Napoleon Bonaparte", "XXXX", "by the early - to - mid fourth century", "Made a decision to turn our will and our lives over to the care of God as we understood Him", "De pictura", "starting on January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "A diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Pink Floyd", "Chicago", "Dijon", "Lucas Stephen Grabeel", "15,024", "model", "the test results by the medical examiner's office,", "teenage", "Sunday", "Vietnam", "the cello", "Richard", "Michael Badalucco"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6479320923335582}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.5, 0.5333333333333333, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.6415094339622641, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.9090909090909091, 0.2580645161290323, 0.0, 0.7499999999999999, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-1629", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-9195", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-5300", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-3750", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_newsqa-validation-3928", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-7581"], "SR": 0.53125, "CSR": 0.5309895833333333, "EFR": 0.9666666666666667, "Overall": 0.71109375}, {"timecode": 60, "before_eval_results": {"predictions": ["a for - profit business, nonprofit organization, or a government agency", "1996", "used their knowledge of Native American languages as a basis to transmit coded messages", "Gilbert", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "the United States Court of Appeals for the Armed Forces", "silk floss tree", "Ferm\u00edn Francisco", "Fats Waller", "coffee", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Bob Parr / Mr. Incredible", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Lorenzo Lamas", "Mahatma Gandhi", "people of the United States", "the eighth season", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "April 2010", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Pink Floyd", "ummat al - Islamiyah", "Uzbekistan", "Parashara ( c. 400 -- c. 500 AD ), the author of V\u1e5bksayurveda ( the science of life of trees )", "Domhnall Gleeson", "local teas and medicines", "agriculture", "St. John's, Newfoundland and Labrador", "from the Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "Brooklyn Heights, New York, at 10 Stigwood Avenue", "1902", "non-nomadic agrarian societies", "DRM", "Peter Sellers", "Colonel Thomas Andrew \u201cTom\u201d Parker", "Atlantic Ocean", "mistress of the Robes", "Australian Electoral Division", "Kris Allen", "Kurt Cobain's", "\"Empire of the Sun,\"", "Hector Berlioz", "The Killing Fields", "Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6733682124035385}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, false], "QA-F1": [0.11111111111111112, 0.0, 0.06666666666666667, 0.6666666666666666, 0.0, 1.0, 0.9142857142857143, 1.0, 0.18181818181818182, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.18181818181818182, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 1.0, 0.0, 1.0, 1.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6956521739130436, 0.5, 0.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-5932", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-1282"], "SR": 0.5625, "CSR": 0.5315061475409837, "EFR": 0.8571428571428571, "Overall": 0.6892923009367682}, {"timecode": 61, "before_eval_results": {"predictions": ["March 21, 2016", "to form a higher alkane", "shared until 2010 -- 11, when Dimitar Berbatov and Carlos Tevez both scored 20 goals that season to tie for the award", "Jason Marsden", "New Mexico", "In 1889", "Poems : Series 1", "William the Conqueror", "March 2, 2016", "2018", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Emma Watson", "Acts passed by the Congress of the United States and its predecessor, the Continental Congress, that were either signed into law by the President or passed by Congress after a presidential veto", "In 2018", "beginning every day at 8 am", "the 2009 model year", "no more than 4.25 inches ( 108 mm )", "Judi Dench", "Madhouse", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "1836", "Thomas Jefferson's", "Elijah Wood", "Space is the Place", "Brad Dourif", "counter clockwise direction around the Sun", "Joanne Wheatley", "vice president", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Madeline Reeves", "1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "lower motor neurons, the efferent nerves that directly innervate muscles", "1773", "Union", "American country music duo Brooks & Dunn", "\"Kippis\"", "south america", "The Pilgrim's Progress", "Bourbon County", "Argentina", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "One of Osama bin Laden's sons", "Jack London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6801671424839528}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.09523809523809523, 1.0, 1.0, 0.6666666666666666, 0.24000000000000002, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.06896551724137931, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5714285714285715, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.4444444444444445, 0.0, 0.8, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-9099", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.578125, "CSR": 0.532258064516129, "EFR": 0.9259259259259259, "Overall": 0.703199298088411}, {"timecode": 62, "before_eval_results": {"predictions": ["1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "Byzantine Greek culture and Eastern Christianity", "short - circuit - proof extra-low voltage transformers for toys or doorbell installations", "microfilament", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "diametrically opposite the South Pole", "Uber A.", "Eduardo", "M\u00e1ximo Gomez and Antonio Maceo", "1971", "Leo Arnaud", "Emmanuelle Chriqui", "Carlos Alan Autry Jr.", "12 : 00 CET", "Hollywood, Los Angeles, California", "Merry Clayton", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "courts", "1912", "George Harrison", "Djokovic", "James Hutton", "January 1923", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Canadian - built Bombardier Dash - 8 Q 400 turboprop aircraft", "a database maintained by the United States federal government, listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh ; born November 30, 1985 )", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the fourth season", "Phillip Paley", "2004", "Jakkur, Bangalore, India", "New Orleans going north through Chicago and to New York", "from the port of Nueva Espa\u00f1a to the Spanish coast", "10.5 %", "Interior Highlands region", "White House Executive Chef", "Bangladesh -- India border", "Bart Millard", "an informal term for mother", "F.W. de Klerk", "Midnight Cowboy", "Austrian", "indie and metal music groups,", "Selden", "Muslims as Americans.", "the day before.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Chastity", "the Entente Council", "Chief Oshkosh", "River Welland"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5830916530135279}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, true, false, false, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.0, 0.25, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7272727272727273, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.0, 0.8108108108108109, 1.0, 1.0, 0.375, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.28571428571428575, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-2892", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-10321", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-7639", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-342", "mrqa_triviaqa-validation-7273", "mrqa_triviaqa-validation-5245", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.484375, "CSR": 0.5314980158730158, "EFR": 1.0, "Overall": 0.7178621031746031}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "end of the 2015 season", "the closing of the atrioventricular valves and semilunar valves, respectively", "Farrow / Previn / Allens", "sacroiliac joint", "Identification of alternative plans / policies", "Cuernavaca, Durango, and Tepoztl\u00e1n", "electronic computers", "the Internal Revenue Service", "Numbers 22 : 28", "Bhupendranath Dutt", "George III's German - born wife, Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "on a bread plate, sometimes in the napkin ), napkin, and flatware ( knives and spoons to the right of the central plate, and forks to the left )", "Dan Cryer", "Jakkur, Bangalore, India", "in a thousand years", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "the Kennedy Space Center ( KSC ) in Florida", "enabled business applications to be developed with Flash", "Forbes Burnham", "Saturday", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "the court from its members", "Alicia Vikander", "282,846", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "ten times", "Lori Rom", "a Czech word, robota", "\" The Chief '' Bitterbuck -- A Washita Cherokee death - row inmate, convicted of killing a man in a drunken brawl over a pair of boots", "Cameron Fraser", "Austin and Pflugerville", "three times", "the misuse or `` taking in vain '' of the name of the God of Israel", "four", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "Azpeitia, Spain", "Lana Del Rey", "The Matterhorn", "calypso", "JP Richardson", "the Pentagon and World Trade Center", "Pisgah National Forest", "Johnnie Ray", "Robert Mugabe", "Capitol Hill.", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionism", "the Pussycat Dolls", "tuberculosis", "May 4"], "metric_results": {"EM": 0.421875, "QA-F1": 0.55056505994006}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6153846153846153, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 0.761904761904762, 1.0, 1.0, 1.0, 0.5714285714285715, 0.4, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 0.18181818181818182, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.9523809523809523, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-5515", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7492", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-3482", "mrqa_hotpotqa-validation-3339", "mrqa_hotpotqa-validation-4240"], "SR": 0.421875, "CSR": 0.52978515625, "EFR": 0.8648648648648649, "Overall": 0.6904925042229729}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra Fort", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan,", "Kunta Kinte", "the network's National Football League and Major League Baseball", "Pittsburgh", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Burwell Johnston", "Nia Temple Sanchez", "Vanessa Hudgens", "top division of Mexican football, Liga MX", "Amber Laura Heard", "Peter Seamus O'Toole", "March 8, 1942", "Michael Stipe", "January 30, 1930", "Doctor", "Government of Ireland", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "the first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes of Balquhither\"", "Westminster system", "Ionolyce", "Ellie Parker", "Janis Lyn Joplin", "King of France", "Sam Waterston", "Transporter 3 (French: Le Transporteur 3)", "March 14, 2000", "Gauteng province, South Africa", "Vietnam War", "Bill Walton", "Darling River", "Brian Keith Bosworth (born March 9, 1965), nicknamed \"The Boz,\"", "140 million", "American", "Teri Garr", "the employer", "the 1965 -- 66 season", "Wyoming", "Wee Jimmy Krankie and his father,", "spiders", "The government late Tuesday afternoon announced it would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "The clothing must be black, red or white, and women in the impoverished city are concerned that they will not be able to purchase clothing that conforms to the order,", "trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Billy Corgan", "Manila", "FSA Taylor Sheldon", "Southport, North Carolina"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5584494498556998}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, true, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, false, false, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.8, 0.8, 0.0, 0.4444444444444445, 0.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.5, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.19999999999999998, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.06060606060606061, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5671", "mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-4198", "mrqa_hotpotqa-validation-2632", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-5596", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2569", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1066", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071", "mrqa_searchqa-validation-16474"], "SR": 0.40625, "CSR": 0.5278846153846154, "EFR": 1.0, "Overall": 0.717139423076923}, {"timecode": 65, "before_eval_results": {"predictions": ["Stephen Lee", "the sitcom \"Arrested Development\"", "Bernard King", "September 30, 2017", "339,520", "New York Giants", "the Swiss tourism boom", "Eliot Cutler", "1946 Winecoff Hotel fire", "Odense Boldklub", "Stephen", "Scott Eastwood", "Gweilo", "Tufts College", "Amedeo,", "1942", "The Wu-Tang Clan", "For Love Alone", "Love the Way You Lie", "Hard rock", "G\u00e9rard Depardieu", "from several different Nazi concentration camps", "Summerlin, Clark County", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse", "Kings Point, New York", "Robbie Gould", "The Gang", "Baldwin", "Port Clinton", "November 20, 1942", "Wayne Conley", "on the Australian coast", "Faith", "turns out to be a terrible date", "the Celtics", "Girl Meets World", "CHO", "eight", "the regime of Emperor Napoleon III", "Purple drank", "Jim Harrison", "George Barnewall", "Arabella Churchill", "Lester Ben \"Benny\" Binion", "two Grammy awards", "S7 series", "2017", "Aibak", "1999", "Thomas Jefferson", "Luxembourg", "Golda Meir", "muffin man", "President Bill Clinton", "as many as 250,000", "Vernon Forrest", "Coretta Scott King", "blown", "Dracula", "Jamie Lee Curtis"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6877489697802197}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false], "QA-F1": [0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.5, 0.25, 0.4, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1941", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_newsqa-validation-368", "mrqa_naturalquestions-validation-1925"], "SR": 0.53125, "CSR": 0.5279356060606061, "EFR": 1.0, "Overall": 0.7171496212121211}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Sheffield Wednesday", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December 7,", "Anthony Joshua", "George III", "Zsa Zsa Gabor", "ambidextrous", "Louis Daguerre", "Richard Feynman", "kenya", "an international award given each year to a living architect", "Guy the Gorilla", "from a familiar animal as well as information that we could not get from a visible light picture", "Port Moresby", "green", "Kursk", "pyrotechnic", "China", "Annie Lennox", "a boar", "Olympics", "Echidna", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "George Washington John Adams", "Ellice Islands", "Meta", "an official population of Aberdeen's 32 local government council areas and the United Kingdom's 37th most populous built-up area", "northern Skye", "a violin", "The Spice Girls", "Mr Loophole", "Istanbul", "a drinking song", "Texas", "Pablo Picasso", "the Yalta Conference", "Rajasthan", "Saintpaulia ionantha", "Indonesian", "Glee", "the 15th Hussars", "Ratonhnhak\u00e9 : ton and Haytham Kenway", "Djokovic", "1912", "fennec", "1991", "Nikolai Trubetzkoy", "Vernon Forrest,", "Linda Hogan", "development of two courses on the Black Sea coast in Bulgaria.", "N.C. Wyeth", "viruses", "Steve Wynn", "a substitute good"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6241319444444444}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2689", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-2232", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-104", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-1689", "mrqa_triviaqa-validation-6737", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_triviaqa-validation-3214", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-4090", "mrqa_newsqa-validation-2391"], "SR": 0.546875, "CSR": 0.5282182835820896, "EFR": 1.0, "Overall": 0.7172061567164179}, {"timecode": 67, "before_eval_results": {"predictions": ["$199", "Thailand", "Les Bleus", "tranquil beaches,", "flooding", "Bundesliga", "Secretary of State", "Obama", "21 percent", "Fernando Caceres", "an Italian and six Africans", "no evidence", "America's Cup", "Cambodian territory", "Uzbekistan.", "voluntary manslaughter", "Jenny Sanford", "celebrity-inspired names", "Miami Beach, Florida,", "\"Wolfman,\"", "cell phones", "two contestants.", "Fiona MacKeown", "a male-dominated organization", "Graeme Smith", "former U.S. secretary of state.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "54-year-old", "\"Nothing But Love\" comeback tour,", "helicopters and boats, as well as vessels from other agencies,", "hanging a noose in a campus library,", "tickets to Italy", "Oxbow,", "There were no reports of ground strikes or interference with aircraft in flight,", "21-year-old", "Jacob Zuma,", "Toffelmakaren.", "former Procol Harum bandmate Gary Brooker", "a civil disturbance call,", "Pew Research Center", "from a donor cadaver.", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "Hold On", "a central place in Christian eschatology", "Phil Mickelson", "Dumbo", "Yardbirds", "1969", "\"$10,000 Kelly,\"", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Julie Taymor", "Marilyn Monroe", "director", "violence within relationships to exercise power and control"], "metric_results": {"EM": 0.640625, "QA-F1": 0.687983630952381}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2271", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_naturalquestions-validation-833", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.640625, "CSR": 0.5298713235294117, "EFR": 1.0, "Overall": 0.7175367647058823}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "son of Gabon's former president", "to put a lid on the marking of Ashura", "from the capital, Dhaka, to their homes in Bhola for the Muslim festival of Eid al-Adha.", "off Somalia's coast.", "General Motors", "AS Roma beat Lecce 3-2", "President Barack Obama", "Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday in Los Angeles.", "an American who entered the country illegally", "2000", "at least 300", "Thursday,", "is always hot and humid and it rains almost every day of the year.", "Israeli", "The drama of the action in-and-around the golf course", "2008.", "root out terrorists within its borders.", "25", "Zed,", "Ciudad Juarez,", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford", "in a remote part of northwestern Montana", "genocide", "identity theft", "Bailey, Colorado,", "U.S. Justice Department", "Venus Williams", "an off-campus party", "\"How I Met Your Mother,\"", "British", "six", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington", "well over 1,000 pounds", "to halt fighting between Somali forces and Islamic insurgents.", "his past and his future", "Mombasa, Kenya,", "a loanword of the Visigothic word guma `` man ''", "Taron Egerton as Johnny", "Italy", "Hard Times", "purpurea", "Nellie Melba", "The King of Hollywood", "1947", "the backside", "Sweden", "garcinia", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6044460747585747}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.13333333333333333, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-1280", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-4976", "mrqa_triviaqa-validation-4494", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.515625, "CSR": 0.5296648550724637, "EFR": 1.0, "Overall": 0.7174954710144927}, {"timecode": 69, "before_eval_results": {"predictions": ["in humans", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Australia's Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Kevin Sumlin", "Las Vegas", "Professor Eobard Thawne", "Hathi Jr", "a liquid crystal on silicon ( LCoS ) ( based on an LCo S chip from Himax ), field - sequential color system, LED illuminated display", "Spektor", "Reveille", "Bill Russell", "The Parable of the Unjust Judge", "by October 1986", "http://www.example.com/index.HTML", "343 m / s in air", "1996", "Carol Worthington", "September 6, 2019", "1972", "1902", "uprooted", "down to the ground", "Battle of Antietam", "U.S. Route 340 ( US 340 )", "Clarence Anglin", "Andrew Garfield", "under normal conditions", "the 1980s", "Pasek & Paul", "a 1920 play R.U.R.", "prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "White House Executive chef", "extremely wealthy", "25 years after the release of their first record", "a bank", "One Night in the Tropics", "Waylon Jennings", "Rent", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "eucalyptus", "inflation", "Christies Foxhunters", "John M. Dowd", "December 17, 1974", "Northrop F-15 Reporter", "26", "The woman", "as soon as 2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6736078993042308}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, true, true, false, true, true, false, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.918918918918919, 1.0, 1.0, 0.5714285714285715, 0.0, 0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.625, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.17391304347826084, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9056", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-1178", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_hotpotqa-validation-993"], "SR": 0.5625, "CSR": 0.5301339285714286, "EFR": 0.9285714285714286, "Overall": 0.7033035714285714}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a specific task when executed by a computer", "January 2, 1971", "minced meat", "St. Louis Cardinals", "Bonhomme Carnaval", "until 1792", "Longliners", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "Upstate New York", "Carol Ann Susi", "a stem", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "Friedman Billings Ramsey", "the NFL", "on the world map", "1 January 1904", "a password recovery tool for Microsoft Windows", "a minimum number of hours defined as such by his / her employer", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer ( SCNT )", "The UN General Assembly", "Benzodiazepines", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "May 31, 2012", "John De Vito", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "Beorn", "North Dakota", "John F. Kennedy", "100,000", "1967", "Rajasthan", "Sodor", "eye", "44,300", "2008", "Anglo-Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "LEWIS CARROLL", "Thailand", "500-room"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6350842281356988}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.058823529411764705, 0.11764705882352942, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333333, 1.0, 0.0, 0.0, 0.07999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.578125, "CSR": 0.5308098591549295, "EFR": 0.9259259259259259, "Overall": 0.702909657016171}, {"timecode": 71, "before_eval_results": {"predictions": ["David O. Dykes", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Striding Edge", "photographer", "clown", "Titanic", "Brundisium", "Hadrian", "Madagascar", "Barbizon school", "Michel Denance", "Manet", "Rodney", "shuttle Columbia", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "'Hansel and Gretel' cottage", "autom\u00f3viles", "Glasgow", "Hep Stars", "sonja Henie", "12", "Lord Snooty", "Greyfriars Bobby", "Rudolf Hess", "Chartered Institute for the Management of Sport and Physical Activity", "Stieg Larsson", "Music Stories", "1957", "le Menech", "steel", "Rotherham United", "Joseph Priestley", "greyhound", "World Cup of Tennis", "Periodic Table", "equatorial guinea", "a region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Cuban", "ab initio", "Patience", "Chubby Checker", "Quentin Tarantino", "establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three 16th hole", "San Francisco", "after 5 years, it was earning $300,000,000 a year", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "January", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "for businesses hiring veterans as well as job training for all service members leaving the military.", "40 lashings", "the Civil War", "in the inverse relationship exhibited by price/earnings ratios and the rate of inflation in the past.", "a monoplane", "UFC Fight Pass"], "metric_results": {"EM": 0.546875, "QA-F1": 0.589422084623323}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, true, true, true, false, false, false, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4210526315789474, 0.5, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-127", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-1065", "mrqa_triviaqa-validation-5241", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5039", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-8965", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-15899"], "SR": 0.546875, "CSR": 0.5310329861111112, "EFR": 1.0, "Overall": 0.7177690972222222}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby Darin", "Thames", "Altamont Speedway", "The Jetsons", "26 miles", "a tibia and fibula", "jellyfish", "Samson", "Connecticut", "daedalus", "girolamo", "augusta", "a goad", "peter parker", "14", "aircraft", "m\u0101ori", "tonto", "hippocampus", "Frank Miller", "tennis", "Orwell", "Atlantic Ocean", "The Treaty of Waitangi", "Chatsworth house", "stella mccartney", "british", "eyes", "a chainsaw", "augusta", "augusta", "taurine cattle", "augusta", "Venezuela", "Southwest Airlines", "SUNSET BOULEVARD", "Johnny Colla", "Derwent", "sesame", "Laos", "Sam Allardyce", "Petain", "Ryan O' Neal", "Miami", "Bill Haley & His comets", "bolognese sauce", "1768", "Joan Rivers", "rome", "William Refrigerator Perry", "Ghana", "in the Near East", "observing the magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "in the U.S. Holocaust Memorial Museum", "Robert Barnett", "Diego Milito", "Rembrandt Harmenszoon van Rijn", "Dumbo the Flying elephant", "Casey at the Bat: A Ballad of the Republic Sung in the Year 1888", "snake"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5585202991452991}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, true, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.923076923076923, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 0.6666666666666666, 0.5, 0.4, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7364", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-8205", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2420", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.4375, "CSR": 0.5297517123287672, "EFR": 1.0, "Overall": 0.7175128424657534}, {"timecode": 73, "before_eval_results": {"predictions": ["Celtic", "Speedway World Championship", "Mercer University", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Mount Rainier, Washington", "Lady Victoria Hervey and Cherie Blair", "racehorse breeder", "SS-Unterscharf\u00fchrer", "Eddie Albert", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis, Indiana", "sitters", "Premier League", "Sleepy Hollow", "Jane Mayer", "Obafemi Martins", "Knowlton School", "143,007", "Philadelphia", "7", "American former model, actress and television host", "1967", "Carl David Tolm\u00e9 Runge", "king Duncan", "St Andrews Agreement", "Royal College of Music", "4145 ft", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "major intersections", "American schoolteacher", "People v. Turner", "William Harold \"Bill\" Ponsford", "Faysal Qureshi", "one", "Mortal Kombat X", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "parashiyot ( plural ) or parshahs ( anglicized pluralization )", "paramitas", "1881", "eric", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Pixar", "Christianity and Judaism", "blintze", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6415950656185031}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, true, true], "QA-F1": [1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 0.6, 0.0, 1.0, 0.3076923076923077, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8918918918918919, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-5222", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-635", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5795", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-4514", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621", "mrqa_searchqa-validation-13349"], "SR": 0.53125, "CSR": 0.5297719594594594, "EFR": 0.9666666666666667, "Overall": 0.7108502252252251}, {"timecode": 74, "before_eval_results": {"predictions": ["the Jesuits", "ribonucleic acid (RNA)", "the ketchup", "a igloo", "a house fly", "Timberland", "Rick Perry", "Burma", "Latvia", "the spleen", "Auf Wiedersehen", "rely", "Ramesses II", "the Bartles & Jaymes Premium Wine Cooler", "the esophagus", "Dallas Cowboys", "the Bible", "a disco group", "Marie Tussaud", "Biscay", "the Ziz", "March", "Magellan", "Kevin Spacey", "a brothel", "the Sun", "The Aviator", "Gioachino Rossini", "Mexico", "a tail", "Nashville", "the Hanging Gardens", "the Starfighter", "Billy Crystal", "skin cancer", "LaSalle", "Qubec", "pope", "Mimi Bobeck", "Fuchsia excorticata", "Moonlighting", "Corpus Christi", "the Mentor", "Ruth Bader Ginsburg", "Edward R. Murrow", "the Indian Ocean", "in vitro fertilisation", "Diogenes", "pastries", "a chocolate milk drink", "the Electric Company", "the following day", "Roger Dean Stadium", "March 31, 2013", "\"Lady Madonna\"", "Celsius", "Jeremy Irons", "Perfect 10", "Jennifer Grey", "Donald Wayne Johnson", "demolishing American third seed Venus Williams in the final of the Sony Ericsson Open in Miami on Saturday.", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5904017857142856}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, false, false, false, false, true, true, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-3193", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-976", "mrqa_triviaqa-validation-6455", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-801"], "SR": 0.53125, "CSR": 0.5297916666666667, "EFR": 1.0, "Overall": 0.7175208333333333}, {"timecode": 75, "before_eval_results": {"predictions": ["eleven", "American singer - songwriter Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "From 1900 to 1946", "a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "2009", "1963", "The Satavahanas", "Central Board of Artisans", "they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK and Olivia", "28 July 1914", "Lager", "as low as 908 mbar ( hPa ; 26.81 inHg )", "North Atlantic Ocean", "2017", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "on the fictional Iron River Ranch, Colorado", "everyone on board", "American singer - songwriter - actress Debbie Gibson", "Lula", "31 January 1934", "Austin", "southeastern United States", "gastrocnemius", "Daniel A. Dailey", "the winter solstice", "President Yahya Khan", "Ramanaa", "the host by fermenting dietary fiber into short - chain fatty acids ( SCFAs ), such as acetic acid and butyric acid, which are then absorbed by the host", "20 year - old Kyla Coleman", "Bill Belichick", "September 1972", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish / Basque", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Mae Jones", "Motorola", "Neil Young", "an attributive and non-attributive noun", "Chuck Noland", "many forested parts of the world", "arithmetic", "archery", "red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie meals", "0-0 draw", "Hapsburg", "Mexico", "the coyote", "Majid Movahedi"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6611496822476515}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 0.5714285714285715, 1.0, 1.0, 0.4, 1.0, 0.4, 0.7027027027027027, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9863013698630138, 1.0, 0.5, 0.6, 1.0, 0.4615384615384615, 0.05714285714285714, 0.0, 1.0, 1.0, 1.0, 0.11764705882352942, 0.0, 0.5, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.8, 0.0, 0.9787234042553191, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3308", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-4341", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-9367", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-5571", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-1646"], "SR": 0.46875, "CSR": 0.5289884868421053, "EFR": 0.9705882352941176, "Overall": 0.7114778444272446}, {"timecode": 76, "before_eval_results": {"predictions": ["$657.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "Total Drama World Tour", "Christopher Lloyd", "senators", "robbery", "the fictional town of West Egg on prosperous Long Island", "the Peace of Westphalia of 1648", "a concept", "Jughead Jones", "American rock band Los Lonely Boys", "the Great Plains and U.S. Interior Highlands region", "cakes", "Kiss", "18 September to 31 October", "Julie Adams", "during World War II", "Anthony Quinn", "January 2004", "Ella Eyre", "Hank J. Deutschendorf II", "Tennesseeitans", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins", "southern Turkey", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1945", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2017", "October 28, 2007", "Laura Vallejo", "an anembryonic gestation", "acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "a Nativity scene", "IV", "No. 16 seed", "Saphira hatches", "September 2017", "a feminine form of the Hebrew Yohannan, `` God forgave / God gratified ''", "Ace", "Spike", "regulatory site", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "InterContinental Hotels Group", "Mainland Greece", "Jason Flemyng", "the Isthmus of Corinth", "Norman Mailer", "a Bristol Box Kite", "EMI", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million", "San Diego", "CNN.com", "jazz", "the echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6596032013795172}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true], "QA-F1": [0.21052631578947367, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7999999999999999, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7368421052631579, 0.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.6153846153846153, 1.0, 1.0, 1.0, 0.07407407407407408, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-2953", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170", "mrqa_searchqa-validation-14736"], "SR": 0.578125, "CSR": 0.5296266233766234, "EFR": 0.9259259259259259, "Overall": 0.7026730098605098}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Alessandro di Mariano Filipepi", "palladium", "Pulsar", "Seth", "honda", "\"Erroneous\" Number One", "Ozzy Van Halen", "Jesseka", "FIFA World Cup", "Elizabeth I", "June", "Italy", "1960s", "Mel Brooks", "Belgium", "chloroplasts", "Paul Dukas", "San Marino", "Uranus", "rum", "apple", "arbroath", "Roddy Doyle", "discus thrower", "Separate Tables", "a multiple telegraph, using Morse code to convey several messages simultaneously, each at a different pitch", "Beatrix Potter", "magpie", "comets", "swimming", "Kansas City", "Ra\u00fal Castro", "Space Oddity", "Scotland", "a larva", "Illinois", "green", "Splash", "South Africa", "menorah", "Good Will Hunting", "gollum", "otters", "John McCarthy", "John Mortimer", "Cheerios", "line code", "in the family Sturnidae ( starlings and mynas ) native to Asia", "Liam Cunningham", "Muno", "Madrid", "Las Vegas Outlaws", "E22", "security breach", "at checkposts and military camps in the Mohmand agency,", "Mashhad", "St Bernard", "France", "Barnard College", "the equator,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6436011904761905}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.19999999999999998, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-149", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-3964", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.578125, "CSR": 0.5302483974358974, "EFR": 1.0, "Overall": 0.7176121794871795}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "vatican", "April", "Al Pacino", "vatican", "by increasing the number of arcs", "Mr. Golding", "a group of nerve cell bodies located in the autonomic nervous system", "vitamin B3", "Director General of the Security Service", "a 965-foot ocean liner", "Funchal", "bachelor", "pasta joke", "Northern Ireland", "the name of the issuing country", "Marcel Duchamp", "The Quatermass Experiment", "Mumbai", "daedalus", "1875", "a raven", "hound", "Susie", "Estimate", "$12$", "Narendra Modi", "Richard Wagner", "Quentin Tarantino", "vatican", "a formal farewell", "Kitzb\u00fchel", "Tunisia", "Crystal Gayle", "steppes steppe", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "fifa", "Darrin", "hit and start", "the Holy Land", "Eva Herzigov\u00e1", "David Hockney", "vatican", "\"Zulu\"", "horror fiction", "Colombia", "the Emerald Isle", "1 - 2 spinal nerve segments above the point of entry", "magnetic stripe `` anomalies '' on the ocean floor", "the Northern Kingdom of Israel, Samaria", "English folk-song", "Martin O'Malley", "1992", "sculptures", "Sunday's strike", "Kenyan forces who have entered Somalia,", "The Old Man and the Sea", "Edward of Carnarvon", "the Cranberries", "the administration said there were no radar outages and said it had not lost contact with any planes during the computer glitches."], "metric_results": {"EM": 0.40625, "QA-F1": 0.5239325778388277}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, false, false, true, false, false, true, false, false, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.30769230769230765, 0.6666666666666666, 0.25, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.9, 1.0, 0.7692307692307693, 0.5714285714285715, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5620", "mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-5155", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-3903", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-7920", "mrqa_hotpotqa-validation-2327", "mrqa_newsqa-validation-2485", "mrqa_newsqa-validation-2233", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.40625, "CSR": 0.5286787974683544, "EFR": 1.0, "Overall": 0.7172982594936709}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "river argent", "HMS amethyst", "nacion giuseppe", "tomato", "Kyoto Protocol", "Fancy Dress Shop", "Bull Moose Party", "know", "Jake LaMotta", "resistance of an unknown resistor", "hitler", "nacion argentino", "indigestion", "discretion", "Ye Shiwen", "The Apprentice", "george Washington", "Corinth Canal", "human rights lawyer", "Iceland", "ascot", "apples", "giuseppe", "gangsters", "doe", "macduff", "UKIP", "Andes", "south Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "Rambo", "Julian Assange", "IT Crowd", "ilie nastase", "carters", "giuseppe", "Mr. Curtis", "terms of endearment", "giuseppe chicago", "giuseppe", "1790", "greenock", "may be tried by everyone for high blood pressure and palpitations", "driving Miss Daisy", "orchid", "Hilary Swank", "abdeen", "at the center of the Northern Hemisphere", "1800 to 1850", "eight hours ( UTC \u2212 08 : 00 )", "just 18 minutes", "China", "Sri Lanka Freedom Party", "Raiders of the Lost Ark", "Afghanistan's Helmand province,", "Rodong Sinmun", "theology", "Fred Astaire", "sanctions", "February"], "metric_results": {"EM": 0.5, "QA-F1": 0.5499599358974359}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.23076923076923078, 0.6, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-4020", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-944", "mrqa_triviaqa-validation-5872", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-3226", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_hotpotqa-validation-306", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-1857", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-2116"], "SR": 0.5, "CSR": 0.5283203125, "EFR": 1.0, "Overall": 0.7172265624999999}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Eleanor Roosevelt", "senators", "2", "in the dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Jason Momoa", "1969", "Billy Joe Walker", "2003", "5 : 7 -- 8", "the Canadian Rockies continental divide east to central Saskatchewan", "H CO", "Miami Heat", "2018", "four", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas", "0.05 ( 5 % )", "Tom Burlinson, Red Symons and Dannii Minogue", "a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "Tulsa, Oklahoma", "Kristy Swanson", "Joanna Moskawa", "Charles R Ranch, County Road 24, Las Vegas, New Mexico, USA", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation from the Great Plains whose historic territory, known as Comancheria", "United Nations", "as of October 1, 2015", "2026", "318", "Director of National Intelligence", "Michael Crawford", "\u03c4\u1f78 \u1f44\u03bd\u03bf\u03bc\u03b1 \u03c4\u03bf\u1fe6 \u03ba\u03b1\u03c4\u03c1\u1f78\u03c2", "Kida", "February 10, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "Lagaan : Once Upon a Time in India", "1996", "American rock band Los Lonely Boys", "appearances", "the foreign exchange market ( FX )", "The Hustons", "Sunday Post", "Karl Pilkington", "peking", "1860", "\"Back to December\"", "Ringo Starr", "\"Up\" mixes allegory with adventure and dumb imaginative exuberance.", "\"Empire of the Sun,\"", "off east  Africa", "modify", "olly Ringwald", "faerie", "the skull & crossbones"], "metric_results": {"EM": 0.625, "QA-F1": 0.7198159377387319}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, true, false, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.5714285714285715, 1.0, 0.33333333333333337, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.7058823529411764, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.09090909090909093, 0.0, 0.3333333333333333, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10102", "mrqa_naturalquestions-validation-10081", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-7286", "mrqa_hotpotqa-validation-5254", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045"], "SR": 0.625, "CSR": 0.5295138888888888, "EFR": 0.9166666666666666, "Overall": 0.7007986111111111}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "shanghai", "Cleopatra", "nuclear warheads", "capitals", "a Pepperoni Pizza Stuffed Bell Peppers", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Alois Alzheimer", "Marcia Clark", "Jenny", "gestation", "ravens", "J.R. Tolkien", "James Franco", "the Blue Ridge Mountain range", "Guyana", "a mixture of iron oxide and aluminum oxide", "buddha", "Apple", "Southampton, Virginia", "barbels", "Zach / Again", "Naples", "Cecilia Tallis", "a feeling of sadness about something that you did or did not do", "Chloe Lattanzi", "Virginia", "the College of William", "a dog", "Louisiana", "Matthew Vassar", "Japan's", "a table setting", "The Police", "Air France", "Metastasio", "Heracles", "a trudge", "The Moody Blues", "Albert Camus", "Volvo", "Rhode Island", "Falsetto", "the Chagos Archipelago", "a hypodermic syringe", "Charlotte Corday", "a nanosecond", "Didelphodon vorax", "Mason Alan Dinehart", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "a great deal on location", "2010", "drum kit", "Madagascar", "Tom Hiddleston", "Estadio Victoria", "Allerdale", "Mugabe's", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5411830357142857}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, false, true, false, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-1183", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-15178", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-9895", "mrqa_searchqa-validation-8284", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-13394", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-2097", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-2110", "mrqa_naturalquestions-validation-5526", "mrqa_triviaqa-validation-7122", "mrqa_hotpotqa-validation-868", "mrqa_newsqa-validation-3390"], "SR": 0.4375, "CSR": 0.5283917682926829, "EFR": 0.9722222222222222, "Overall": 0.711685298102981}, {"timecode": 82, "before_eval_results": {"predictions": ["USS Nautilus", "the Hopi", "China", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Doric order", "My Therapist", "Marilyn Monroe", "souvlaki", "Richard III", "the bald eagle", "the Louvre", "4,047", "the Galapagos Islands", "Malle Babbe", "the Black Sox Scandal", "small", "pomegranate syrup", "Constantine", "the Aleutian", "alchemy", "nouveau", "autobahn", "Germanic", "the quail", "curtsy", "lacrosse", "Toronto", "hard", "\"King David\"", "Riboflavin", "plumes", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "The Hobbit", "the Red Sox", "Garry Shandling", "Yale University", "Graceland", "the Caspian Sea", "laces", "\"The Robert E. Lee Memorial\"", "Brunswick", "Westminster Abbey", "Superbad", "the Granite State", "1885", "$2.187 billion", "On the west", "Austria", "acai berry", "the Benedictine Order", "Pansexuality", "authorship of Titus Andronicus", "American actor, singer and a DJ", "Drew Kesse,", "the couple's surrogate", "eight-week", "2010"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6003472222222223}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.22222222222222224, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-2505", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-2798", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_searchqa-validation-5031", "mrqa_searchqa-validation-4122", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-3145", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-1388", "mrqa_hotpotqa-validation-943"], "SR": 0.53125, "CSR": 0.5284262048192772, "EFR": 1.0, "Overall": 0.7172477409638554}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "the Office", "Jesus", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "a vulture", "Nantucket", "Ebony", "a college of Oxford or Cambridge", "Algeria", "Joseph Haydn", "(Richard) Cheney", "the black market", "a number", "Saturday Night Fever", "Japan", "Neapolitan", "pea", "the Skyscraper", "White blood cells", "a trifle", "florida", "Qubec", "Larry McMurtry", "Kellogg", "Helen", "a sweatshirt", "a kilogram", "Napoleon", "wood", "the Spmi region", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "AT&T", "Pancho Gonzales", "the Aleutians", "the Mormon", "Lady Jane Grey", "Tommy Tutone", "the crescent moon", "Iraq", "an Earthworm", "Copernicus", "poblano", "Mr. Safire", "the Dominican monastery of this Church", "from London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "Casablanca", "T. R. M. Howard", "Parlophone", "9:20 p.m. ET Wednesday.", "U.N.", "1995", "1,500"], "metric_results": {"EM": 0.53125, "QA-F1": 0.590625}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, true, true, false, true, false, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-10063", "mrqa_searchqa-validation-10095", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-6397", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-1916", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-537", "mrqa_newsqa-validation-3579"], "SR": 0.53125, "CSR": 0.5284598214285714, "EFR": 1.0, "Overall": 0.7172544642857142}, {"timecode": 84, "before_eval_results": {"predictions": ["Russia", "Anne Boleyn", "Judas", "Windsor", "Douglas", "comrade", "The Great Gatsby", "a foxes", "Sexuality", "Salaries", "Solomon", "(Roger) Federer", "a bicycle", "Johnson County", "Jericho", "a push", "Solzhenitsyn", "foolish", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "the Iroquoian family", "the Philippines", "St Mark", "Eragon", "The Beatles", "Louisiana", "Mexico", "Jolly Roger", "engrave", "Daisy Miller", "\"A Land- scape with Animals\"", "X", "a ship", "Kamehameha", "a fox", "Jamestown", "Jerry Maguire", "the Ross Sea", "oyster", "a monkey", "Candlestick", "Zimbabwe", "a bowstring", "Patty Duke", "Pronoun", "Hoffmann", "Calico", "Frankie Muniz", "during his first appearance", "A complex sentence", "40", "Mars", "Nowhere Boy", "August", "an Anglo-Saxon tumulus (or \"barrow\")", "Richa Sharma", "Haiti", "financial gain,", "in a Nazi concentration camp,", "Golfer Tiger Woods"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6536458333333333}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-5876", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-109", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-14335", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-9404", "mrqa_triviaqa-validation-2049", "mrqa_hotpotqa-validation-5599", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.578125, "CSR": 0.5290441176470588, "EFR": 1.0, "Overall": 0.7173713235294118}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Kanga", "Italian", "Eggs Benedict", "the Taj Mahal", "Ayn Rand", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Morse", "Strawberry Fields", "The Hague", "Geena Davis", "pharmacy", "Kit Carson", "the NFL", "Doolittle", "air", "Shakespeare in Love", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "the NIV", "The X-Files", "Babar the elephant", "Mensa International", "Edward Hopper", "oratorios", "steak", "the python god", "a toddler", "the Salt Lake City", "Italy", "watermelon", "the Warsaw Pact", "Sparta", "the Sunday New York Times", "anode", "boldly go", "The National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "hair", "the Texas Rangers", "Paxil", "H CO ( equivalently OC ( OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine.", "evicted not because of anything they did,", "Why he's more American than a German,", "Charles Sherrington"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7378472222222223}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-15693", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692"], "SR": 0.6875, "CSR": 0.5308866279069768, "EFR": 1.0, "Overall": 0.7177398255813954}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy Feet", "a sprint", "the Himalayan mountains", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "the Palatine hill", "California", "the Mississippi", "Alpha", "Quebec", "abalone", "The Texas Chainsaw Massacre", "a rotunda", "a oak leaf cluster", "Le djeuner", "Plutarch", "Mediolanum", "(O) Corin", "Shropshire", "a hemodialysis", "Afghanistan", "satin", "Lady Godiva", "Job", "Vasco da Gama", "Millard", "chino", "Finnegans Wake", "aleikum", "the black market", "professor of higher education", "S-waves", "Maastricht", "Delilah", "synapses", "croissants", "Jalisco", "the respiratory organs", "fuchsia", "metacarpal", "grade & grave", "Warsaw", "parsnips", "the Mercury Seven", "Taiwan", "Gettysburg", "beach volleyball", "trout", "\"On a Slow Boat to China\"", "1959", "the first season of NCIS", "$75,000", "zimbabwe", "15", "stonemason\\'s Yard", "Agent Carter", "\"Shadow of a Doubt\" (1943)", "Manhattan, New York City", "56", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6587053571428572}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-4065", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8200", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-8225", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_naturalquestions-validation-9595", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-24"], "SR": 0.59375, "CSR": 0.5316091954022988, "EFR": 1.0, "Overall": 0.7178843390804597}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists", "Michael Crawford", "Richa Sharma", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "protect the genome", "1 US dollar", "Geoffrey Zakarian", "$72", "Mary Elizabeth ( Margaret Hoard )", "Melinda Dillon", "Paris", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Francis Ford Coppola", "$66.5 million", "helps digestion by breaking the bonds linking amino acids", "slavery", "The Osmonds", "a political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "Taiwan", "Anakin Skywalker", "Alexander Salkind", "one", "Thomas Lennon", "Ed Roland", "Kevin Garnett", "a star", "Uzbekistan", "Selena Gomez", "Washington", "the 2nd century", "Triple threat", "1998", "shared", "foreign investors", "Napoleon", "the inverted - drop - shaped icon that marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool", "Robber baron", "December 20, 1951", "Watson", "Aconcagua", "bake Off", "garmisch-Partenkirchen", "Noah Levenstein", "zona glomerulosa", "Nicole Kidman", "last summer.", "to get involved in service and volunteerism in their communities.", "longo-Ciprelli", "banker", "eyelid", "the Cubs", "thief"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6453073818882642}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.3636363636363636, 0.5454545454545454, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5925925925925926, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.10256410256410257, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-6424", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-1656", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.5625, "CSR": 0.5319602272727273, "EFR": 0.9285714285714286, "Overall": 0.7036688311688312}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff", "a bag", "Federer", "from Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "\"Mammograms are known to be uncomfortable,\"", "\"The three were seized early Monday after police raided a bus station in Sargodha, a city located about 120 miles (190 km) south of Islamabad in Pakistan's Punjab province.", "Salt Lake City, Utah,", "And it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "Formagruppen", "to protect ocean ecology, address climate change and promote sustainable ocean economies.", "Rocky Ford brand cantaloupes", "these planning processes are urgently needed and have been a long time in coming.", "In the last four weeks, authorities arrested three men with suicide vests who were plotting to carry out the attacks,", "\"I would like to present you with a little gift that represents what President Obama and Vice President Biden and I have been saying and that is: 'We want to reset our relationship and so we will do it together.'\"", "club managers,", "Long Island", "90", "FBI", "Reggae legend Lucky Dube,", "the Kurdish militant group in Turkey", "14", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin", "a Justice Department motion filed last week in support of the Defense of Marriage Act -- which effectively bars the federal government from recognizing same-sex unions.", "Europe,", "for not doing more since taking office.", "immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guant Bay, Cuba.", "Greeley, Colorado,", "a grocery store", "pro-democracy activists clashed Friday with Egyptian security forces in central Cairo,", "drugs", "Daniel Radcliffe", "1.2 million", "\"It was a wrong thing to say, something that we both acknowledge,\"", "12.3 million", "Krishna Rajaram,", "a long-range missile", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Hamas", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "\" And the United States can learn much from Turkey's expertise on Afghanistan and Pakistan -- not the kind of society the Taliban has been providing.", "Yemen.", "10 municipal police officers", "And there's Russell, a chubby Boy Scout -- or \"Wilderness Explorer\" -- who turns up on Carl\\'s porch when he least expects it.", "central business district of Bangkok", "Idriss Deby hopes the journalists and the flight crew will be freed,", "a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "Hague Conventions", "Chris Hemsworth", "prime minister", "England and Ireland", "beef", "Suleiman", "woodland", "Ramadan"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5816005609242838}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.058823529411764705, 1.0, 0.0, 0.0, 0.13333333333333333, 1.0, 0.5555555555555556, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.24000000000000002, 0.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 0.28571428571428575, 0.09523809523809523, 0.33333333333333337, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-6846"], "SR": 0.484375, "CSR": 0.5314255617977528, "EFR": 1.0, "Overall": 0.7178476123595505}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron (133 ARS)", "Kim So-hyun", "president of Guggenheim Partners", "Comedy Central", "9\u201310 March 1945,", "2011", "Standard Oil Company", "during the early 1970s", "Asiana Town", "rock and roll", "Rockland County", "Manitowoc County, Wisconsin,", "south-east", "1967", "alcoholic drinks for consumption on the premises", "Fiat Chrysler Automobile Factory of Turin", "Chrysler", "Australia", "gorillas", "Eyes Wide Shut", "Joshua Rowley", "Robert Digges Wimberly Connor", "Brad Wilk", "the Beatles and the Rolling Stones", "Baden-W\u00fcrttemberg, Germany", "2001 NBA All-Star Game", "\"Rated R\"", "95 AD", "1614", "French", "\"Detective Comics\" #225 (Nov. 1955)", "Mondays", "Michael Jordan", "Snowball II is killed off,", "HSBC Building", "1987", "Kalokuokamaile,", "17 October 2006", "melodic hard rock", "the Irish Parliamentary Party", "Channing Tatum and Jenna Dewan", "1822", "Mulberry", "Suspiria", "Immediate Media Company", "popular sovereignty clause of the law", "Scandinavian design", "Buck Owens", "Big Machine Records", "postal delivery", "Flaw", "October 27, 2016", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Davy Crockett", "forearm", "Tigris", "Kgalema Motlanthe,", "Piers Morgan Tonight", "misdemeanor assault charges", "Florida", "The Partridge Family", "Mickey Spillane", "housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6276041666666667}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [0.8, 0.0, 0.4, 0.4, 1.0, 1.0, 0.6666666666666666, 0.8, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4603", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-163", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-247", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-3752", "mrqa_hotpotqa-validation-1556", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-2672", "mrqa_hotpotqa-validation-4542", "mrqa_hotpotqa-validation-5440", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-1728", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.53125, "CSR": 0.5314236111111111, "EFR": 1.0, "Overall": 0.7178472222222222}, {"timecode": 90, "before_eval_results": {"predictions": ["Jackie DeShannon", "Ardeth Bay", "2003", "singer", "Pakistan", "1754", "Na Na", "Bundesliga club VfL Wolfsburg", "d\u00edsabl\u00f3t", "David Villa", "Adrian Peter McLaren", "2013", "an early colonist of South Australia,", "The Birds", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Diamond White", "25 November 2015", "Craig William Macneill", "January 14,", "2,664", "Tamil", "Objectivism", "Chicago", "Gatwick Airport", "Riot Act", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Sir Seretse Khama", "Scandinavian design", "Mike Pence", "Barack Obama's Cabinet", "Flexible-fuel vehicle", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian Church", "138,535", "Ryukyuan people", "1972", "Potsdam", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravity", "consistency", "South Africa", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailing", "Robert", "dolls", "\"Thunderball\"", "CO2", "Shout"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6771834935897436}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2564102564102564, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4945", "mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-3261", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-2734", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-4050", "mrqa_newsqa-validation-386", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743"], "SR": 0.609375, "CSR": 0.5322802197802198, "EFR": 1.0, "Overall": 0.7180185439560439}, {"timecode": 91, "before_eval_results": {"predictions": ["Wiener-Dog", "the Rockbot", "the Jaguar S-Type", "the Gateway Arch", "Friday", "Sabino Canyon", "Johnny Depp", "Babe Ruth", "Donna Mills", "Arkansas", "Cus D'Amato", "Iustitia", "modern", "the prairie-wolf", "bucolic", "Tito Puente", "Hydrogen", "Ben Jonson", "Hodgkin\\'s", "Margaret", "Las Vegas", "San Francisco", "the 1940s", "Mary Baker Eddy", "Bank One Corp.", "William & Mary", "the Wright Brothers", "Badminton", "John Deere", "height", "Chrysler", "Reptiles", "Georgia Bulldogs", "Key lime pie", "Lettuce", "Haroun", "bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "Mesopotamia", "Marat", "Cetshwayo", "Bay of Montevideo", "the bank's own funds and signed by a cashier", "a spirit-lifting jingle", "Bobby Brown,", "Bath", "1.5 million", "Macomb County", "Kristoffer Rygg", "Veracruz", "Monday", "eight", "English Wesleyan minister and biographer"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6755208333333333}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-1820", "mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-13516", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-3331", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-12942", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_hotpotqa-validation-2255", "mrqa_newsqa-validation-4011", "mrqa_hotpotqa-validation-4539"], "SR": 0.5625, "CSR": 0.5326086956521738, "EFR": 0.9642857142857143, "Overall": 0.7109413819875776}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Constantin Brancusi", "Quantico, Virginia", "the East River", "William Shakespeare", "All\\'s Well That ends Well", "yors", "Alaska", "Sputnik I", "Richmond", "Sturm und Drang", "Java", "the baritone", "Blanche DuBois", "inseparable", "vulcanization", "Wuthering Heights", "Ali", "Rome", "Dead Man\\'s Chest", "Charles de Gaulle", "Chesterfield, Virginia", "the wolf", "Josephine", "salt", "a felony", "Rossini", "Oman", "Lapland", "Tom Canty", "Roman Polanski", "Didion", "a frigate", "Baltimore", "the Bay of Bengal", "John Morton", "Clinton", "Terrific", "time", "six sides", "Olympia", "Ship of Fools", "Haunted", "yang", "gel", "Margaret Mitchell", "Frances", "Vin Diesel", "cremation", "the French & Indian War", "a manic episode", "central Saskatchewan", "lighter", "a scuffle with the Beast Folk", "Elektra", "Germany", "Caernarfon", "Nairobi, Kenya", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20,\"", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.5625, "QA-F1": 0.642361111111111}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, true, false, true, false, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-4155", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-6877", "mrqa_searchqa-validation-2418", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-11893", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_searchqa-validation-4465", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6984", "mrqa_triviaqa-validation-6867"], "SR": 0.5625, "CSR": 0.5329301075268817, "EFR": 1.0, "Overall": 0.7181485215053763}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Alice Cooper", "Tony Orlando", "Irene Bedard", "2017", "drivers who were 2016 Pole Award winners, former Clash race winners, Former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "17 December 1968", "Pacific Grove", "in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form", "Audrey II", "January 2017", "NIRA", "1922", "Jacqueline Bouvier", "Justin Timberlake", "The Chainsmokers", "13 May 1787", "The Province", "his brother", "Seattle, Washington", "honey bees", "Article 1, Section 2, Clause 3", "Bill Irwin", "Napoleon", "Hem Chandra Bose", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "ice giants", "hyperinflation", "1939", "Richard Masur", "Al Foster", "the Philippines", "Sauron", "Lana Del Rey", "a statistical advantage for the casino that is built into the game", "159", "The Third", "Chemistry professor E.H.S. Bailey and his colleagues were returning by train to Lawrence after a conference", "works in a bridal shop", "activates a relay which will handle the higher current load", "limited period of time", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood", "Snowshoe", "February 13, 1946", "Square Enix", "Congo River", "Jason Chaffetz", "The Da Vinci Code", "humiliate", "Khrushchev", "Julie Andrews", "the Headless Horseman", "Leo Frank"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6260453088578088}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.7272727272727273, 0.0, 0.30769230769230765, 1.0, 0.2, 0.0909090909090909, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-9264", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3305", "mrqa_hotpotqa-validation-102", "mrqa_newsqa-validation-3374"], "SR": 0.546875, "CSR": 0.5330784574468085, "EFR": 0.9310344827586207, "Overall": 0.7043850880410858}, {"timecode": 94, "before_eval_results": {"predictions": ["the theory of direct scattering and inverse scattering", "Thon Maker", "Battle of Chester", "youngest TV director ever", "19 February 1927, Halifax", "Siduri", "film playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado.", "Revengers Tragedy", "Japan", "rural", "8", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "Pantone Matching System", "Las Vegas Boulevard", "intelligent design", "Anthony Herrera", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas City", "nearly 80 years", "Chevrolet Corvette Stingrays", "Field of Dreams", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "\"Pour le M\u00e9rite\"", "David Robert Jones (8 January 1947 \u2013 10 January 2016)", "Drowning Pool", "outside of casinos", "the Food and Agriculture Organization", "Saturday Night Fever", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "Holinshed's Chronicle", "2018", "Bangalore University", "25 October 1921", "Australian", "Bonkyll Castle", "February 5, 2015", "Zeffirelli", "giant planet", "alveolar bone", "Dortmund - Ems Canal", "Hugh Quarshie", "vivian china", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "Iran", "Easter Island", "Eli Whitney", "Today Show", "25"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7623883928571429}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.25, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.47619047619047616, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-4047", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-3989", "mrqa_naturalquestions-validation-2703", "mrqa_triviaqa-validation-514", "mrqa_newsqa-validation-726"], "SR": 0.65625, "CSR": 0.534375, "EFR": 1.0, "Overall": 0.7184375}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies worldwide", "Ben Ainslie", "1978", "Spoorloos", "Scott Mosier", "1950", "Roy Spencer", "(Vishnu)", "U.S. Route 71", "World of Wonder", "London Review of Books", "Russian", "Han Solo", "July 25", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer, songwriter, actress, and radio and television presenter", "Northern Lights", "coca wine", "Mach number", "Terrina Chrishell Stause", "Maine", "Encore Las Vegas", "\"Baa, Baa, Black sheep\"", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "President John F. Kennedy", "racing", "Mandarin", "Kevin Spacey", "Deputy Vice-Chancellor", "Song Il-gon", "Teen Titans Go!", "Mickey Mouser", "three", "left-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "to kill on a hunt", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers", "Metro-Goldwyn-Mayer", "P.O.S", "My Backyard", "Sun Woong", "American professional boxer", "Aloe Vera of America", "creeks", "1992", "the Kingdom of Great Britain", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "38 feet", "The Da Vinci Code", "Dogpatch Labs", "iceberg", "a battery", "Victoria", "Venus Williams"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6483382936507937}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, false, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.5, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-1059", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5447", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-5568", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-226", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-181", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_naturalquestions-validation-360", "mrqa_newsqa-validation-3838", "mrqa_searchqa-validation-14503", "mrqa_searchqa-validation-9695"], "SR": 0.5625, "CSR": 0.53466796875, "EFR": 1.0, "Overall": 0.71849609375}, {"timecode": 96, "before_eval_results": {"predictions": ["Prince Sung-won", "1927", "16,116", "the 2012 Summer Olympics", "at the end of the 18th century", "1942", "The Highwaymen", "\"Estadio de L\u00f3pez Cort\u00e1zar\"", "Syracuse", "Kim Jong-hyun", "the Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "the Games of the Olympiad", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3", "chocolate-colored", "Norman Graham Hill", "1908", "Neneh Cherry", "American rapper Eminem", "Love Streams", "In a Better World", "the Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "imp My Ride", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "Indian", "John Francis Kelly", "early Romantic period", "approximately $700 million", "the Sun", "Bhushan Patel", "1692", "the power to regulate interstate commerce", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "colonel", "Conan Doyle", "isosceles", "put a lid on the marking of Ashura", "Pakistan's", "homicide", "bread pudding", "leather", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.65625, "QA-F1": 0.8142744408369409}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.3333333333333333, 0.8, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.18181818181818182, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3971", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-447", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-3210", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2789"], "SR": 0.65625, "CSR": 0.5359213917525774, "EFR": 0.9545454545454546, "Overall": 0.7096558692596064}, {"timecode": 97, "before_eval_results": {"predictions": ["Eddie Redmayne", "Caucasus", "David Bowie", "Joe Davis", "Granada in Spain", "Treaty of Brest-Litovsk", "Karl Marx", "The Paramounts", "Marilyn Monroe", "aggressive", "October 4, 1957", "around 1926", "transsexual", "Fred Astaire", "gretzubrg, and Verona", "The Professionals", "The northern part of the island", "Monday's child (rhyme)", "a plane", "Rudyard Kipling", "1921", "Trainspotting", "Emilia", "avocado", "Frans Hals", "conservative New Democracy", "Ford", "soybean", "Frank Sinatra", "1826", "w W Jacobs", "Parthenon", "Paddy Doherty", "Doctor Universalis", "ap\u00e9ritif", "an elephant", "Bobby Fischer", "end", "Westminster Abbey", "Canada", "Sheidi Klum", "eGBERT 827 - 839", "Tombstone", "located in the Atlantic Ocean,", "Mr. Men and Little Miss", "worcester Cathedral", "Mars", "December 7, 1941", "the stapes", "Nadia Comaneci", "Neil Armstrong", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "VAQ-135", "95 AD", "170", "\"Sesame Street's\" Grover, how to make gnocchi with Mario Batali, and the ins and outs of prettying up your home with any number of programs on HGTV.", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "from 1922 to 1991"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5546875}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, true, true, true, true, false, false, true, false, false, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-6742", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-4459", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-6617", "mrqa_triviaqa-validation-5738", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3536", "mrqa_triviaqa-validation-329", "mrqa_triviaqa-validation-4302", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-6624", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-1718", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-3100", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.484375, "CSR": 0.5353954081632653, "EFR": 1.0, "Overall": 0.718641581632653}, {"timecode": 98, "before_eval_results": {"predictions": ["sent an e-mail to reporters Wednesday with the subject line \"Vice presidential...\"", "Afghanistan's", "the mine", "Several suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags", "his health and about a comeback.", "poems", "then-presidential candidate Barack Obama,", "a woman", "581", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "The remains of Cologne's archive building following the collapse on Tuesday afternoon.", "Former Mobile County Circuit Judge Herman Thomas", "celebrities", "Iraqi economy.\"", "Phillip A. Myers.", "\"Swingin' Down the Lane.\"", "share personal information.", "Argentinean and 255 British", "Sheik Mohammed Ali", "Iraqi Prime Minister Nouri al-Maliki", "Egypt", "\"It was incredible. We've had so much rain, and yet today it was beautiful. The rain held off wherever Muhammad Ali went,\"", "Jennifer Arnold and husband Bill Klein,", "Pacquiao returned home to a hero's welcome in his native Philippines on Friday after wresting the WBO welterweight title from Miguel Cotto on a 12th round technical knockout in Las Vegas.'", "Austin, Texas,", "17-month", "pay him a monthly allowance,", "Manmohan Singh's", "Barack Obama: \"I'm certainly not nearly as good of a speaker as he is.\"", "death squad killings", "100 meter", "sniff out cell phones.", "Fort Bragg in North Carolina.", "American Bill Haas", "Consumer Reports", "28", "step up.\"", "42 years old", "since 1983.", "health ailment or beauty concern.", "almost 100", "the leader of a drug cartel that set off two grenades during a public celebration in September, killing eight people and wounding more than 100.", "Derek Mears", "\"we take this issue seriously,\"", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "fifth successive season", "Haeftling", "on the table", "Asuka", "Bart Millard", "nismo", "arch", "Jane Austen", "the Marx Brothers film", "Indian", "World War I", "a hostage", "Shakespeare in Love", "W. Somerset Maugham", "Leicestershire"], "metric_results": {"EM": 0.5, "QA-F1": 0.6323054386191058}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.9210526315789475, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.4285714285714285, 0.8333333333333333, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.4, 0.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.19354838709677416, 1.0, 0.0, 0.0, 1.0, 0.2666666666666667, 0.36363636363636365, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-2549", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-2749", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-5314", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-14191"], "SR": 0.5, "CSR": 0.5350378787878788, "EFR": 0.9375, "Overall": 0.7060700757575757}, {"timecode": 99, "UKR": 0.734375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.80859375, "KG": 0.5140625, "before_eval_results": {"predictions": ["Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "2", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "global peace", "The Ducks", "Arkansas", "the 2011 Pulitzer Prize in General Nonfiction", "Golden Gate", "GZA, \"Grandmasters\"", "Broadcasting House in London", "lead female role of London Tipton", "Barney Miller", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "The Heirs", "Saturday Night Live", "strongly associated with Gaia and Cybele,", "Tumi Holdings, Inc.", "Black Ravens", "SM Lifestyle City", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Nelson County", "Kang and Kodos", "25 million", "Cleopatra VII Philopator", "James G. Kiernan", "a member of the influential and political, Detroit rock band, the MC5", "James City County", "North African Arab", "Linda Ronstadt", "the United Kingdom", "August 19, 2013", "the Neotropical realm", "The Omega Man", "five", "Stephen John Coogan", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "The term was first used in tennis", "Frank Zappa", "1991", "applea", "Fred Trueman", "Scotland", "Chesley", "Fernando Torres", "Friday,", "Lifeboat", "the yottabyte", "his job,", "Benazir Bhutto"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6993131868131868}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, false, true], "QA-F1": [0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5, 1.0, 0.5, 0.5714285714285715, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.05128205128205128, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2031", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5872", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2083", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-14144"], "SR": 0.5625, "CSR": 0.5353125000000001, "EFR": 1.0, "Overall": 0.71846875}]}