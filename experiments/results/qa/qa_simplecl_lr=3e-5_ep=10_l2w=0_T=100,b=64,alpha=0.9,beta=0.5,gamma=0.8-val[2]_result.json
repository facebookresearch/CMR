{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4110, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "1.1 \u00d7 1011 metric tonnes", "The Daily Mail", "Uncle Tom\u2019s Cabin", "The liver", "No man", "Martina Hingis", "Ukraine does not have real established and ratified borders with Russia"], "metric_results": {"EM": 0.859375, "QA-F1": 0.8760416666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_squad-validation-4181", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.859375, "CSR": 0.8671875, "EFR": 1.0, "Overall": 0.93359375}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "evolution of the German language and literature", "a Latin translation of the Qur'an", "the Brotherhood", "high wages", "Tolui", "human law", "the object's weight", "over half", "1960s", "two months", "Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "hot winds blowing from nearby semi-deserts", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "the breadth of sizes", "1965", "whether this connection is relevant on microscales", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "low ratio of organic matter to salt and water", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "time goes", "guardian", "guardian", "black", "50 feet"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6565002705627705}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2289", "mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3857"], "SR": 0.609375, "CSR": 0.78125, "EFR": 1.0, "Overall": 0.890625}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "in committee", "19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "a group that included priests, religious leaders, and case workers as well as teachers", "Vistula River", "1290", "21 October 1512", "427,652", "double membrane", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "\"ctenes\" or \"comb plates\"", "calcitriol", "Warsaw", "time", "since at least the mid-14th century", "the mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "Prime ideals", "The Three Doctors", "Malik Jackson", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Johann Tetzel", "English", "a lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "gauge bosons", "A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "a tiny snail", "a son should not kill his own mother", "the Galapagos Islands", "Connecticut", "the water vapor becomes liquid", "the best minds in the travel industry", "Amaranth", "a major raw", "Mycenaean civilization", "the body that regulates its rhythmic and periodic cycles", "the Empire State Building", "the Normandy Landings", "Evelyn \"Billie\" Frechette", "the shinbone or shankbone", "The Anvil Chorus", "Roald Amundsen", "the Royal Border Bridge"], "metric_results": {"EM": 0.625, "QA-F1": 0.6455627705627706}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-2192", "mrqa_squad-validation-3347", "mrqa_squad-validation-1036", "mrqa_squad-validation-3673", "mrqa_squad-validation-6737", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-22", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_searchqa-validation-6338", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.625, "CSR": 0.7421875, "EFR": 1.0, "Overall": 0.87109375}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue", "to spearhead the regeneration of the North-East", "Rhenus", "gambling", "the wing of the secular powers", "compiled a cubic interpolation formula for his astronomical calculations", "Zhongtong", "11.1%", "1538", "Deacons", "New Testament", "their prestige, \"experience, ideology, and weapons\",", "25 percent", "May 2013", "Torchwood (2006\u20132011) and The Sarah Jane Adventures (2007\u20132011", "capturing prey", "gana and thylakoids", "livestock pasture", "Ford", "1,300,000", "rubisco starts accidentally adding oxygen to sugar precursors", "two tumen (20,000 soldiers)", "eight", "algorithm", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "Battle of Olustee", "observer status", "50-yard line", "3D printing technology", "Malkin Athletic Center", "24\u201310", "8.0", "empires", "domestic legislation of the Scottish Parliament", "a patient's quality of life", "New York City Mayor Michael Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "innovative, exciting skyscrapers", "a lump in Henry's nether regions", "World War II", "semiconductors", "Tim Clark, Matt Kuchar and Bubba Watson", "fastest circumnavigation of the globe in a powerboat", "the man facing up, with his arms out to the side", "the foyer of the BBC building in Glasgow, Scotland", "Buddhism", "Manchester City", "Noriko Savoie", "three", "change course", "Tsvangirai", "A Lion Among Men", "the Federal Communications Commission required television stations to air anti-smoking advertisements at no cost to the organizations providing such advertisements", "a miracle food", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6838947510822511}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.2, 1.0, 0.0, 0.4, 1.0, 1.0, 0.8, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.2666666666666667, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7606", "mrqa_squad-validation-9250", "mrqa_squad-validation-8231", "mrqa_squad-validation-9645", "mrqa_squad-validation-7626", "mrqa_squad-validation-8874", "mrqa_squad-validation-4258", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-1643", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_squad-validation-2798", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-2212", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-1366", "mrqa_hotpotqa-validation-547"], "SR": 0.59375, "CSR": 0.7125, "EFR": 1.0, "Overall": 0.85625}, {"timecode": 5, "before_eval_results": {"predictions": ["with money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Doritos", "4000 years", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "chloroplasts are surrounded by a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "a seal", "Philip Howard", "King Ethelred II of England", "capturing three traders and killing 14 people of the Miami nation, including Old Briton", "three", "Spanish", "Golden Super Bowl", "constitutional traditions common to the member states", "pharmacological effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two", "George Westinghouse", "by disrupting their plasma membrane", "internal combustion engines", "indirectly", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "Goa", "How I Met Your Mother", "France's famous Louvre museum", "Leo Frank", "Thessaloniki", "Graziano Transmissioni", "opposition parties", "204,000", "Newcastle retained fourth place with a 3-1 victory over Blackburn, who remained in the relegation zone.", "release of the four men", "first lady Michelle Obama is weighing in on the issue by focusing on how health care can affect families.", "Ed McMahon", "this will be the first time any version of the Magna Carta has ever gone up for auction,", "Barack Obama", "at the University of Alabama in Huntsville", "Obama", "ballots", "Sodra nongovernmental organization", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "promotes fuel economy and safety while boosted the economy.", "heart rate that exceeds the normal resting rate", "Suffolk Punch", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7125277194211017}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, false], "QA-F1": [0.7000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.5, 0.0, 0.0, 0.8, 0.0, 0.4, 1.0, 0.0, 0.11764705882352941, 0.09523809523809525, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-8715", "mrqa_squad-validation-1090", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-6644", "mrqa_squad-validation-10444", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-3935", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.609375, "CSR": 0.6953125, "EFR": 1.0, "Overall": 0.84765625}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational resource", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "world line", "1991", "William Smith", "William Pitt", "geochemical component called KREEP", "the Earth must be much older than had previously been supposed in order to allow enough time for mountains to be eroded and for sediments to form new rocks at the bottom of the sea", "Japan", "Super Bowl Opening Night", "Working Group chairs", "laws of physics", "Broncos", "noisiest", "three-dimensional", "issues under their jurisdiction", "unsuccessful", "human", "they are homebound", "eliminate all multiples of 1", "nerves", "1700", "New Germany", "polysaccharides", "Governor of Vermont from 1991 to 2003", "the circulatory", "troggs", "God created everything in six days.", "Bratislava,", "Diana, the Princess.", "slave trade.", "vena cava", "a scallop", "bull's-eye", "Tartarus", "sky is known", "Nancy Reagan", "the Persian Achaemenid Empire.", "LAP", "Count Ferdinand von Zeppelin", "huge.", "Duke of Clarence", "a millimeter.", "\"Popeye\"", "Judas!", "survivors of Oceanic Flight 815", "pinball machine", "Love Is All Around", "Los Angeles Dance Theater", "Somalia", "field 14 unapproved narcotics that are widely used to treat pain.", "18"], "metric_results": {"EM": 0.5625, "QA-F1": 0.629431216931217}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.07407407407407407, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-10477", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-6337", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-13281", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.5625, "CSR": 0.6763392857142857, "EFR": 0.9642857142857143, "Overall": 0.8203125}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction of the dinosaurs", "oxygen", "encourage growth in richer countries", "K-9 and Company", "9.1 million", "little", "Asian, African and Caribbean countries", "cattle", "Mongol", "semantical problems and grammatical niceties", "five", "the \"gold standard\" of religion in minds of some or many Muslims.", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "equality deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "starch", "Bryant", "Earth", "tornado", "Rod Steiger", "hoo-hoo, the barn type", "John Sexton", "Kenny G", "coffee", "Chazz Michael Michaels", "Alberta", "Season", "kissanhnta", "bark beetles", "Allah", "bones", "Python", "Cecil B. DeMille", "Ada", "Faith Hill", "Ben Affleck", "U.S.", "V", "time", "Yardbird and Bird", "Sweden", "Vietnam", "hydrogen", "Alexandria", "Perfume: The Story of a Murderer", "New Jersey Economic Development Authority's 20% tax credit", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.515625, "QA-F1": 0.581737012987013}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7468", "mrqa_squad-validation-1938", "mrqa_squad-validation-6220", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_squad-validation-7565", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-1586", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-3893", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_searchqa-validation-7551", "mrqa_hotpotqa-validation-4891", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.515625, "CSR": 0.65625, "EFR": 1.0, "Overall": 0.828125}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers of the show", "BSkyB", "Kawann Short", "Daidu in the north", "silent film", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement (ODM-K)", "Bannow Bay", "Red Army", "20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "Happy Endings", "seven-eighths", "the cardinal de Richelieu", "the Atlas Mountains", "Madrid", "the Danube", "Yahweh", "leather", "George Pullman", "plums", "Jesus Christ", "Sappho", "Possession", "the tonka bean", "the divisor", "Hypnos", "Texas", "IHOP", "a white breed", "the Bill of Rights", "the ACT", "Brasilia", "Henry David Thoreau", "the Santa Ana winds", "Dick Cheney", "the sun", "Gustave Eiffel", "Edward Hopper", "the CIA", "d'Artagnan", "painted Caves", "1985 -- 1993", "apple", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.625, "QA-F1": 0.6826202876984128}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3478", "mrqa_squad-validation-8421", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.625, "CSR": 0.6527777777777778, "EFR": 1.0, "Overall": 0.8263888888888888}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education of Topeka", "15 May 1525", "The Walt Disney Company", "Dundee", "Over 61 per cent", "During the Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "Exploration is still continuing to determine if there are more reserves", "prep schools", "soft power", "strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "the honeyeater", "4:51", "Khrushchev", "Rhea", "the root", "Elton John", "Cuba", "the Battle of Thermopylae", "Preamble", "Kroc", "cricket", "white", "Wash.", "Preamble", "Italy", "a fifth part of 15", "tarn", "100; or 25", "the Buffalo bison", "Ann Widdecombe", "an equilateral triangle", "the Old Kent Road", "Tuesday", "Preamscopic", "Ab Fab", "Massachusetts", "Barrow", "California", "the Susquehanna River", "80\u2019s", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "Hoffa", "Home Rule Party", "Janet Napolitano", "J. Crew", "Deval Patrick", "Preamble"], "metric_results": {"EM": 0.5, "QA-F1": 0.5720486111111112}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.2666666666666667, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2920", "mrqa_squad-validation-9552", "mrqa_squad-validation-8273", "mrqa_squad-validation-9870", "mrqa_squad-validation-3013", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-5586", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-2988", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.5, "CSR": 0.6375, "EFR": 0.96875, "Overall": 0.803125}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio network", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "Roman Catholic", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "the mouth", "stone", "Ken Russell", "Dan Dare", "hera", "Smiths", "Mike Tyson", "hera", "Pesach", "Brian Deane", "kaleidoscope", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "the Underground Railroad", "puck", "\"beyond violet\"", "a\u00e7ai", "Portugal", "football", "Serena Williams", "63 to 144 inches", "the Titanic", "William Tell", "Christian Dior", "the snail", "Mendip Hills", "Wichita", "eukharisti\u0101", "New Croton Reservoir", "The Way You Move", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "Ponty Mython", "Roman Polanski"], "metric_results": {"EM": 0.671875, "QA-F1": 0.6866477272727273}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6263", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-4926", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397"], "SR": 0.671875, "CSR": 0.640625, "EFR": 1.0, "Overall": 0.8203125}, {"timecode": 11, "before_eval_results": {"predictions": ["method by which the medications are requested and received", "salvation", "stoves", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju variety show", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network", "public service", "Guy de Lusignan", "tiger team", "b cells", "The European Commission", "completed (or local) fields", "fundamental error", "Mongol and Turkic tribes", "hera", "five", "Whist", "caesar", "Toscana", "albinism", "black", "Pluto", "chromium", "black gold", "The Hague", "Vancouver Island", "Ironside", "gollancz", "nizhny Novgorod", "black spots", "Beyonce", "Wordsworth", "Man V Food", "Queen Elizabeth II", "Samuel Johnson", "Conrad Murray", "caesar", "Bennett Cerf", "green leaf", "morocco", "caesar", "Shrek", "morocco", "lions", "rhododendron", "Bob Fosse", "morocco", "Shanghai", "sweden", "boat lifts", "snake River Valley", "17 October 2006", "beer", "Las Vegas to Arizona", "Saturday's Hungarian Grand Prix", "Capuchin Church of the Immaculate Conception", "Edgar Allan Poe", "bobby"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5594494047619047}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-8252", "mrqa_squad-validation-6530", "mrqa_triviaqa-validation-4198", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-1269", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.515625, "CSR": 0.6302083333333333, "EFR": 1.0, "Overall": 0.8151041666666666}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith.", "1.25 million", "1080i HD", "five", "Maria Goeppert-Mayer", "International Association of Methodist-related Schools, Colleges, and Universities", "one", "a majority in Parliament", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "General Pharmaceutical Council (GPhC)", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas.", "The Handmaid's Tale", "chimpanzee", "The Fault in Our Stars", "car car", "video", "1961", "400 MW", "Total Nonstop Action Wrestling", "galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Walt Disney World Resort in Lake Buena Vista, Florida", "David Villa", "Red and Assiniboine Rivers", "Bergen County, New Jersey,", "Continental Army", "Jack Kilby", "Ryan Babel", "Umar Israilov", "July 16, 1971", "1933", "The Heirs", "Baudot code", "1959", "1887", "Mark Dayton", "Marvel Comics", "The Weeknd", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point du Sable", "England", "Paul W. S. Anderson", "a basilica", "1994", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "drug trade, which has increased dramatically since the American-led invasion to remove the hard-line Islamist government of the Taliban in October 2001.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "andrew johnson", "dapple-grey", "pre-Columbian times"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6955357142857143}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2, 1.0, 0.0, 0.19999999999999998, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-6320", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-383", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.640625, "CSR": 0.6310096153846154, "EFR": 1.0, "Overall": 0.8155048076923077}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "The Rocket", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "a maze of semantical problems and grammatical niceties", "\"Southwest Fresno\"", "5,000", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "The Five Doctors", "a certain number of teacher's salaries are paid by the State", "NCAA Division II", "Adrian Lyne", "his most brilliant student", "Las Vegas", "Ranulf de Gernon, 4th Earl of Chester", "2017", "Dealey Plaza", "Rudolf Schenker", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics)", "16\u201321", "Vince Guaraldi", "Tony Burke", "Michael Redgrave", "6th", "Highlands Course", "Hawaii", "unclearambar styracif", "Marquis de Lafayette", "Bharatiya Janta Party (BJP)", "three", "Winter Haven", "four", "The Process", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "My Beautiful Dark Twisted Fantasy", "FCI Danbury", "a few", "\"Home of the Submarine Force\"", "Las Vegas", "Pope John X", "(2007)", "Arlo Looking Cloud", "Rwandan genocide", "Larnelle Harris", "The President of the United States negotiates treaties with foreign nations,", "2015, 2017", "1982", "rod", "Chris Robinson", "\"G unclear Girl\"", "shock wave", "unclear", "the Egyptian Goddess of Creation", "Eric Burdon"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6250496031746031}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7142857142857143, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3176", "mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_squad-validation-7792", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-3272", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-2732", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.546875, "CSR": 0.625, "EFR": 1.0, "Overall": 0.8125}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "Only the series from 2009 onwards", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "Spreading throughout the Mediterranean and Europe,", "mass", "ten times their own weight", "Quaternary", "1887", "other ctenophores", "symbiotic relationship with vitamin D", "mathematical models of computation", "Vistula River", "100 to 150", "Apple's new clock faces for folks who use the tiny player's 1.5-inch screen as a watch", "the school.", "March 8", "Democrats and Republicans", "the Catholic League", "Half Moon Bay", "\"He is obviously very relieved and grateful that the pardon was granted,\" Dean said.", "Friday", "Movahedi", "different women coping with breast cancer in five vignettes", "there were problems with the well and he should move his ship away.", "moody", "$40 and a quarter of bread", "Lance Cpl. Maria Lauterbach", "South Korea", "London", "more than 4,000 commercial farmers off their land, destroying Zimbabwe's once prosperous agricultural sector.", "in Lienz, France earlier this year.", "the results by a chaplain about 1:45 p.m., per jail policy.", "three people in connection with the attack, including a suspect \"fleeing the scene [who] tested positive for explosive residue", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "a $158 green skirt and $298 bead and rhinestone cardigan", "U.N. officials", "\"I sort of had a fascination with John Dillinger when I was about 10, 11 years old, for some reason,\"", "boyhood experience in a World War II internment camp", "suppress the memories and to live as normal a life as possible", "about 4 meters (13 feet) high", "Dublin", "Democrat", "a Utah jail", "Mandi Hamlin and her lawyer, celebrity attorney Gloria Allred,", "Islamabad", "7 p.m.", "March 26, 1973", "Indian Ocean", "argument form", "the foot corresponding to which hand you intend to throw with perpendicular to the line", "Sevens", "England", "Yemen", "portraitist", "peter", "mercury"], "metric_results": {"EM": 0.359375, "QA-F1": 0.46031217046842043}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, true, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.125, 1.0, 1.0, 0.0, 1.0, 0.0, 0.27272727272727276, 1.0, 0.6666666666666666, 0.8750000000000001, 0.05, 0.0, 0.8000000000000002, 0.0, 0.0, 0.0, 0.13333333333333333, 0.2857142857142857, 0.1818181818181818, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.0, 0.2222222222222222, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-6565", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-1329", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.359375, "CSR": 0.6072916666666667, "EFR": 1.0, "Overall": 0.8036458333333334}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "prime", "50 fund", "Camisards", "over $40 million", "GTE.", "1,100 tree species", "spin", "Oligocene", "D.S. District Judge Dale Kimball", "Charles Darwin", "a Little Rock military recruiting center", "March 24,", "the Beatles", "Robert Park", "Amir Zaki", "Eleven", "2007", "a dozen", "\"She had a smile on her face, like she always does when she comes in here,\"", "56", "the National Football League", "\"The Lost Symbol\"", "Heshmat Tehran Attarzadeh", "IV cafe.", "18 federal agents and two soldiers", "Atlanta", "resources", "senior", "two Emmys", "\"To all of our valiant men and women, know that the American people believe in you, support you and are 100 percent behind you, and we thank God every day that you have our back.\"", "Dean Martin, Katharine Hepburn and Spencer Tracy", "Rwanda", "75", "eradication of the Zetas cartel from the state of Veracruz, Mexico,", "closing these racial gaps.", "a bond hearing", "President Bush", "Amstetten,", "African National Congress Deputy President Kgalema Motlanthe,", "spiral into economic disaster.", "he lost his bid to Francisco de Narvaez, who leads a rival Peronist party, Union PRO, by a tally of 34.6 percent to 32.1 percent.", "Ralph Cifaretto", "a strict interpretation of the law,", "saying Chaudhary's death was warning to management.", "Iran", "20% tax credit", "July 23.", "70,000 or so are estimated to be there now.", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Schleiden and Schawnn", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "blue", "Capitol Building", "The Left Book Club", "holography"], "metric_results": {"EM": 0.4375, "QA-F1": 0.531619798026048}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.057142857142857134, 0.0, 0.29629629629629634, 0.0, 1.0, 1.0, 1.0, 0.6923076923076924, 0.2962962962962963, 0.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-4349", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-3678", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-11133", "mrqa_searchqa-validation-1335", "mrqa_triviaqa-validation-6296"], "SR": 0.4375, "CSR": 0.5966796875, "EFR": 1.0, "Overall": 0.79833984375}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand people", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "British East Africa (as the Protectorate was generally known) and German East Africa", "several hundred thousand, some 30% of the city", "Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary homicide", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "1979", "murder", "next year", "his plans to overhaul domestic policies,", "Christopher Savoie", "Anil Kapoor", "Afghanistan and India", "Dr. Albert Reiter,", "\"theoretically\" Iran could develop a nuclear bomb within the next year.", "\"whole ethos is one of violence\" and that it had \"made a brutal choice to step up attacks against innocent civilians,\"", "Matthew Fisher,", "cancer,", "Courtney Love,", "us to step up.\"", "\"Walk -- Don't Run\" and \"Haw Hawaii Five-O\"", "your own environmental videos", "two women", "Queen Elizabeth's birthday", "Monday,", "First Stop Resource Center and Housing Program", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs", "expressed concerns about the missile defense system.", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "Fullerton, California,", "September 28, 1918,", "1950s,", "U.S. troops", "a government-run health facility that provides her with free drug treatment.", "vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "al Fayed's", "Oxbow,", "gastrocnemius", "Ed Sheeran", "20", "Australia", "three-part", "2001", "vingtaines (or, in St. Ouen, cueillettes),", "Joe Louis", "George Blake", "Bogota"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6553498584748585}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.27272727272727276, 0.22222222222222224, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3636363636363636, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_triviaqa-validation-6739"], "SR": 0.5625, "CSR": 0.5946691176470589, "EFR": 0.9642857142857143, "Overall": 0.7794774159663866}, {"timecode": 17, "before_eval_results": {"predictions": ["lower levels", "a pharmacy practice residency", "questions and answers", "\"anima non sic dormit),", "Captain Francis Fowke,", "12 January", "60,000", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich", "\"Sesame Street\"", "St. Louis, Missouri.", "$50 less,", "Afghanistan's restive provinces", "fled Zimbabwe and found his qualifications mean little as a refugee.", "7 Awa", "Iran", "Russian concerns that the defensive shield could be used for offensive aims.", "Sharon Bialek", "Matthew Fisher,", "books on the condition, which is characterized by bouts of diarrhea and constipation.\"", "in the north and west of the country,", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "introduce legislation Thursday to improve the military's suicide-prevention programs.\"", "$250,000", "first or second week in April.", "Derek Mears", "a motor scooter", "Gary Player", "sieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "kite boards have developed has helped... but there is still a lot of people out there that want to achieve these records,\"", "Virgin America", "Palm Beach, Florida,", "Daniel Wozniak,", "22-year-old", "santa bin Laden", "how health care can affect families.", "santa Maria Costa,", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "at checkposts and military camps in the Mohmand agency,", "all the attackers were Pakistanis,", "Friday,", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "slapped over and was beaten when he refused.\"", "$162 billion in war funding without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Jokai crater", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "7", "rice wine", "Halifax"], "metric_results": {"EM": 0.5, "QA-F1": 0.5837174368772035}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3529411764705882, 0.5217391304347826, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.07999999999999999, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-2408", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-4124", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_triviaqa-validation-1659", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.5, "CSR": 0.5894097222222222, "EFR": 1.0, "Overall": 0.7947048611111112}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "New France's governor, the Marquis de Vaudreuil", "linear", "Advanced Steam movement", "Defensive ends", "the dot", "chastity", "European Court of Justice", "bronze medal in the women's figure skating final,", "\"trying to steal the election\" and \"intimidating the population and election officials as well.\"", "UK", "\" Teen Patti\" (\"Card Game\")", "Argentina", "Congress", "28", "New Haven, Connecticut, firefighter Frank Ricci,", "the project, which is designed to promote private sector investment in a variety of gas-related industries, on September 21.", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures are necessary,", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "Bahrain", "because that Somalia-based terrorist organization Al Shabaab may have been plotting an attack timed to coincide with the event,", "\"Zed,\"", "because this administration recognizes the importance of Turkey and wants to engage with it from the start.", "because the federal government isn't actively engaged in border enforcement is both dishonest and reckless.", "bricks and concrete on protesters from atop a six-story building.", "\"wildcat\" strikes,", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "Hong Kong from other parts of Asia, such as India and mainland China,", "Lindsey Vonn", "in an interview Tuesday on CNN's \"Larry King Live.\"", "organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "race", "Brazil", "Saluhallen,", "trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "outside the Iranian consulate in Peshawar", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger.", "\"Sunny Afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6345937375068567}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.21052631578947367, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.9142857142857143, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.14285714285714285, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.16, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-2708", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-3823", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611"], "SR": 0.546875, "CSR": 0.587171052631579, "EFR": 0.896551724137931, "Overall": 0.741861388384755}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Darian Stewart", "11", "unless he were removed from the school, Tesla would be killed through overwork.", "Japanese", "Muqali,", "2011 and 2012", "Pittsburgh Steelers", "apartment building", "Aung San Suu Kyi", "(The Frisky)", "the 3rd District of Utah", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "30", "procedures", "acid attack by a spurned suitor.", "most of those who managed to survive the incident hid in a boiler room and storage closets", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to it right now,\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "to trail the illegal traffic.\"", "a book.", "he was in good health, contrary to media reports he was diagnosed with skin cancer.", "stand down.", "Ashley \"A.J.\" Jewell,", "at least 17", "from her father's home in Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "rural California,", "off the front pages for the first time in days.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "the Delta Queen steamboat", "the Haeftling range.", "Pacific Ocean territory of Guam", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "Blagojevich", "Sen. Barack Obama", "protective shoes", "public-sector labor unions launching a general strike,", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "glass shards", "Sedimentary rock", "2.45 billion years ago", "London", "Colorado", "Bangor International", "\"Grandmasters\"", "Suffragist", "Canterbury", "Tatooine", "the Lone Ranger", "Bonnie and Clyde"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6724033641796799}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.9523809523809523, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.10526315789473685, 0.07692307692307693, 1.0, 1.0, 0.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.8333333333333333, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.7142857142857143, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.5, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.4, 1.0, 1.0, 0.4210526315789474, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-816", "mrqa_squad-validation-1326", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-14663"], "SR": 0.53125, "CSR": 0.584375, "EFR": 0.9666666666666667, "Overall": 0.7755208333333333}, {"timecode": 20, "before_eval_results": {"predictions": ["Hostmen", "Greg Brady", "Fort Caroline", "Hungarians", "De Materia Medica", "John D. Rockefeller", "four", "mistreatment from government officials.", "Beijing, China,", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Cathy Dennis and Rob Davis", "91.9 by 49.2", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater pearls", "1962", "Buddhism", "1978", "1927, 1934, 1938, 1956 )", "1969", "Miami Dolphins", "Joseph Heller", "90 \u00b0 N 0 \u00b0 W", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "team", "September 2014 and PlayStation 3 and Xbox 360 in November 2014", "Archduke Franz Ferdinand of Austria, heir presumptive to the Austro - Hungarian throne", "in Christian eschatology", "October 1941", "peace between two entities", "mughal garden", "Cee - Lo", "after Shawn's kidnapping", "generally lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour Party", "three times", "November 25, 2002, by the Homeland Security Act of 2002", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two", "Alberto Salazar", "live animals", "American", "Hoosick, Rensselaer", "CEO of an engineering and construction company with a vast personal fortune.", "1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Samoa", "Russia and China", "Washington State's decommissioned Hanford"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6766109557327459}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8421052631578948, 0.625, 0.3333333333333333, 1.0, 0.4, 0.0, 0.0, 0.0, 0.967741935483871, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-6314", "mrqa_squad-validation-8027", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-8934", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-2446"], "SR": 0.546875, "CSR": 0.5825892857142857, "EFR": 0.896551724137931, "Overall": 0.7395705049261083}, {"timecode": 21, "before_eval_results": {"predictions": ["66 million years ago", "Spanish", "an attack on New France's capital, Quebec", "the Fresno Traction Company", "Westminster", "blue-green algae", "24 of the 32 songs", "their bearers", "the Washington metropolitan area", "the molar concentration, measured in units of moles per liter, of hydrogen ions", "the breast or lower chest of beef or veal", "the ruling city of the Northern Kingdom of Israel,", "Tagalog or English", "around 1600 BC", "July 2010", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "Keith Hernandez and Willie Stargell", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford, an African - American woman in her early forties", "the 2nd century", "in the pancreas", "Elk and Kanawha Rivers", "1961", "the latest version", "rocks and minerals", "Michael Schumacher", "the derivative financial instrument", "Introduced in 1957", "1775", "1995", "President Friedrich Ebert", "2018", "Ireland", "Kit Harington", "the teenage porcupine punk rocker", "the embryo", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "In the 1979 -- 80 season", "Guy Berryman", "Canadian ice dancers Tessa Virtue and Scott Moir", "c. 497 / 6", "Tim Allen as Luther Krank", "thick skin", "in small packs, and in larger and smaller sizes", "India", "three", "his waterfront home on Chesapeake Bay, south of Annapolis in Maryland", "cricket", "the Major General of the Army", "Marktown", "14,000", "that Iran could be secretly working on a nuclear weapon", "Honduras", "pardoning Richard Nixon", "Ellen DeGeneres", "12 April 1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.328125, "QA-F1": 0.4940361150287621}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 0.9333333333333333, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 0.3636363636363636, 0.8, 0.0, 0.4, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.7777777777777778, 1.0, 0.0, 1.0, 0.6666666666666666, 0.08, 0.0, 0.5714285714285715, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-1003", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-1870", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-3013", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-4641", "mrqa_hotpotqa-validation-1675", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3883", "mrqa_searchqa-validation-843", "mrqa_hotpotqa-validation-427", "mrqa_hotpotqa-validation-3984"], "SR": 0.328125, "CSR": 0.5710227272727273, "EFR": 1.0, "Overall": 0.7855113636363636}, {"timecode": 22, "before_eval_results": {"predictions": ["the mouth of the Monongahela River (the site of present-day Pittsburgh, Pennsylvania)", "Stanford University", "linebacker", "Mongol and Turkic tribes", "1859 and 1865", "Danny Lane", "in the New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16 )", "The Fixx", "Andrew Johnson", "Hellenism", "Mark Jackson", "Manhattan Island", "the Chainsmoker", "annual income of US $11,770", "al - khimar", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "Tanvi Shah", "the North Shore, at locations in Beverly, Essex, Gloucester, Swampscott, Lynn, Middleton, Tewksbury, and Salem", "a single particle", "Thomas Jefferson", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "Burbank, California", "Grace Zabriskie", "2014", "Yuzuru Hanyu", "Glenn Close", "Kanawha", "flawed democracy", "China", "Scott Belden", "Masha Skorobogatov", "February 27, 2007", "Felony Snicket", "8ft", "Owen Vaccaro", "food", "the lateral side", "Steve Trevor Jr.", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff / \ufefe 90 \u00b0N - 0 \u00b0 E", "London", "in the bloodstream or surrounding tissue following surgery, disease, or trauma", "2017", "March 1", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "if he was not named Romeo he would still be handsome and be Juliet's love", "the dark underbelly of the American Dream", "the Queen", "\u00ef\u00bf\u00bd", "the American rock band Pearl Jam", "2005", "Dan Tyminski", "the family", "in the southern port city of Karachi,", "at least nine", "Bashar al-Assad", "the New Revised Standard Version of the Bible", "Biathlon"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5813616877761614}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.4210526315789474, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 0.8, 0.4444444444444445, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8148148148148148, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.5, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-3631", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-6201", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-9457", "mrqa_naturalquestions-validation-3470", "mrqa_triviaqa-validation-4546", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-4138"], "SR": 0.453125, "CSR": 0.5658967391304348, "EFR": 0.9714285714285714, "Overall": 0.7686626552795031}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "The Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd", "in the central part of each developing bone", "Ali", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash in Hindi, Urdu and Punjabi", "Article 1, Section 2, Clause 3", "the Constitution of India came into effect on 26 January 1950", "Richard Bremmer", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "James P. Flynn", "detritus", "September 27, 2017", "Ireland", "1978", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "on February 10, 2017", "Alex Skuby", "Jamestown settlement in the Colony of Virginia", "March 2016", "from 1922 to 1991", "Tom Sawyer", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "two amino acids joined by a single peptide bond or one amino acid with two peptide bonds", "`` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "female - only species that reproduces by producing an egg through parthenogenesis", "Thomasmary DeCamp", "1871", "eye", "The History Boys", "sturgeon", "White Knights of the Ku Klux Klan", "five books, with two chapters in each book, with a cumulative total of 528 aphoristic sutras, about rules of reason, logic, epistemology and metaphysics", "Mot\u00f6rhead", "Kingman Regional Medical Center,", "Phillip A. Myers. A staff sergeant in the U.S. Air Force,", "Osama bin Laden", "Antarctica", "axon", "mushroom"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6053905122655123}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 0.28571428571428575, 0.0, 0.2857142857142857, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.2222222222222222, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.18181818181818182, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.16, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.484375, "CSR": 0.5625, "EFR": 0.9696969696969697, "Overall": 0.7660984848484849}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man; justification rather depends only on such faith as is active in charity and good works", "Jim Thorpe", "1996", "the onset and progression of Alzheimer's disease.", "Disco", "Kingdom of Dalmatia", "the Indian School of Business", "New York", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin Button\" (2010)", "A55", "Corendon Dutch Airlines", "86", "Capella", "sea loch", "Fatih Ozmen", "U.S.", "Pacific Place", "served as the Attorney General of Michigan from 1999 to 2003", "Paradise, Nevada", "Westminster, London", "2016", "Wildhorn", "New York University School of Law", "Crips", "Harper's and Queen", "dementia", "Ferrara", "Guadalcanal Campaign", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Lee Alexander", "Black Friday", "Archbishop of Canterbury", "TD Garden", "James Victor Chesnutt", "the Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "musical research", "Portland", "Yoruba", "\"Lucky\"", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "1966", "Jason Clarkson", "Ryan Harris", "Medellin", "Joe Jackson", "alternative-energy vehicles parked", "in the first near-total face transplant in the United States,", "genes", "olive", "Stockholm"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6041695283882784}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 0.5, 0.8571428571428571, 1.0, 0.7499999999999999, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.4, 0.4, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-4105", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-2172", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-979", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-2659", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930", "mrqa_newsqa-validation-1676"], "SR": 0.453125, "CSR": 0.558125, "EFR": 0.9428571428571428, "Overall": 0.7504910714285714}, {"timecode": 25, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "forces acting at ninety degrees to each other have no effect on the magnitude or direction of the other", "Fox Network", "the Anhaltisches Theater", "Anna Clyne", "Martin Scorsese and written by Terence Winter, based on the memoir of the same name by Jordan Belfort", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom,", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "American", "Acid house", "at the end of the 18th century", "The Five Boroughs", "Miranda Lambert", "Shenandoah National Park", "BBC Formula One coverage on TV, radio and online", "10 Years", "Haleiwa Ali'i Beach Park", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles", "PBS stations nationwide,", "second largest", "acid", "in 1911", "Lola Dee", "The Five", "Walt Disney Feature Animation", "The 2017\u201318 Premier League", "torpedoes", "1972", "Geographical Indication tag", "Ringo Starr", "Celtics", "World Championship Wrestling", "The 1994 United States Senate election in New York was held on November 8, 1994", "TD Garden", "the Chechen Republic", "Chrysler", "The Institute for Advanced Study", "2005", "Tenochtitlan", "The Tax Reform Act of 1986", "Lou Gehrig", "Mexico", "Thundercats", "he fears a desperate country with a potential power vacuum that could lash out.", "the Catholic League", "Krishna Rajaram,", "michael", "\"Death, be not\" this \"though some have called thee mighty and dreadful, for thou art not so\"", "green"], "metric_results": {"EM": 0.625, "QA-F1": 0.6898313492063493}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, true, true, false, false, true, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10397", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5750", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-5167", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.625, "CSR": 0.5606971153846154, "EFR": 1.0, "Overall": 0.7803485576923077}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Jesus", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "\"Histoires ou contes du temps pass\u00e9\"", "Orchard Central", "Tom Hiddleston", "late eighteenth century", "The Snowman", "Class of '77", "Premier League club", "port city of Aden", "British", "Prince Louis of Battenberg", "2008", "Archie Andrews", "2 May 2015", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Joseph Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "racehorse breeder and owner", "unincorporated", "1919", "Kevin Spacey", "Love Streams", "Michael Edwards", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast", "Una Healy", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "CMYKOG", "1600 BC", "Anthony Daniels", "1963", "a peplos", "Car", "Nutshell", "15,000", "10 to 15 percent", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan", "held by the Kong family", "postcards"], "metric_results": {"EM": 0.5, "QA-F1": 0.5877117673992673}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.6666666666666666, 0.33333333333333337, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1884", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_searchqa-validation-3515"], "SR": 0.5, "CSR": 0.5584490740740741, "EFR": 1.0, "Overall": 0.779224537037037}, {"timecode": 27, "before_eval_results": {"predictions": ["immediately north of Canaveral at Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Sir Matthew Alistair Grant", "Whitney Houston", "Sumitomo Rubber Industries", "Bonkyll Castle", "Cheick Isma\u00ebl Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "due to a leg injury", "Antonio Salieri", "American", "Europe", "cesario", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "Cersei Westerister", "Kalokuokamaile", "Indonesische Onafhankelijkheidsoorlog", "Don Bluth", "2009", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "Don It Be", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914 machine gun", "James Brolin", "Germany's position in a Europe", "January 2004", "co-founder and lead guitarist", "ten", "seven", "October 25, 1881", "J. Robert Oppenheimer", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "c3H8O3", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "off east  Africa", "bromide", "nasal septum", "Warp Drive"], "metric_results": {"EM": 0.53125, "QA-F1": 0.624312082289056}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3840", "mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-1660", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-3634", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-2957", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-15622", "mrqa_searchqa-validation-6398"], "SR": 0.53125, "CSR": 0.5574776785714286, "EFR": 1.0, "Overall": 0.7787388392857143}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools and day schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation (NSF)", "hanover", "Henry Mancini", "japn", "Gordon Ramsay", "Mikhail S. Gorbachev", "M*A*S*H\"", "sub rosa", "Charlton Heston", "Anna (Julia Roberts)", "a scythe", "orchid", "Paddy Doherty", "smallpox", "the Hanging Gardens of Babylon", "Libya", "Yeehaw", "F\u00fcr Elise", "Khomeini\u2019s Iran", "David Copperfield", "William Hickey", "Milady de Winter", "April", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "Belle", "David Beckham", "New York City", "Tom Stoppard", "The Greatest", "New Netherland Institute", "the British charts", "a Scotsman\u2019s bonnet", "saxophonist", "Seattle", "the Union Inn", "Cardiff", "Baton Rouge", "Stromberg", "Tahrir Square", "Romanian", "bathtub curve", "Michael Caine", "Snooty", "Borodin", "Jesse James", "Meerkat", "Greek", "passion fruit", "Thomas Lennon", "Hainan Island", "Thomas Hobbes", "Denmark and Norway", "June 4, 1931", "North America", "Florida's Everglades.", "Trisha Yearwood", "glamorous, sexy and international.", "drive", "glengarry Glen Ross", "shark"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6191964285714285}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, true, false, true, true, false, true, true, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, true], "QA-F1": [0.0, 0.28571428571428575, 0.39999999999999997, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-3804", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-2313", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-6701", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004"], "SR": 0.53125, "CSR": 0.556573275862069, "EFR": 0.9666666666666667, "Overall": 0.7616199712643679}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS and NBC", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Tim Duncan", "James W. Marshall", "Blue laws", "Randy VanWarmer", "Both the Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "Bill Condon", "between 8.7 % and 9.1 %", "2018", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "in Pyeongchang County, Gangwon Province, South Korea", "status line", "retina", "jimmy johnson", "Triple Entente", "Andrew Lloyd Webber", "1955", "Charles Frederickson ( Nick Sager )", "Buffalo Lookout", "Humpty Dumpty and Kitty Softpaws", "Charlene Holt", "close to 5,770 guaranies", "the original Star Trek television series", "in 1936, when she was 10 years old", "Sam", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "Kristy Swanson", "Anna Faris", "early to mid-2000s", "Fleetwood Mac", "technological advances in printing, and improved economics of distribution", "Cairo, Illinois", "in the 1970s and'80s", "in the books of Exodus and Deuteronomy", "Wyatt `` Dusty '' Chandler ( George Strait )", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century.", "January 2, 1971", "The Miracles", "biological taxonomy", "forearm", "jimmy adrian", "Charlie Sheen", "\"Twice in a Lifetime\"", "George Orwell", "Bardot", "teenager", "Long Island convenience store", "Mitt Romney", "jimmy", "high fever", "dancing with the stars"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5898563936063936}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7692307692307693, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.45454545454545453, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6153846153846153, 1.0, 0.0, 0.2857142857142857, 0.5714285714285715, 0.56, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-5069", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-7346", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1958", "mrqa_newsqa-validation-1979", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426"], "SR": 0.484375, "CSR": 0.5541666666666667, "EFR": 1.0, "Overall": 0.7770833333333333}, {"timecode": 30, "before_eval_results": {"predictions": ["Santa Clara", "quality rental units", "cultural tourism and sports tourism", "a circle", "( Sequoia sempervirens)", "Rugrats", "Spanish Republic", "(cabriolet)", "coyote", "The Sun Also Rises", "Harry Reid", "Ray", "axis", "forge", "boxing", "In No Country for Old Men", "(Les Fleurs du mal)", "Blackbird", "Footprints", "Caliban", "LA Kings", "U.S. Census Bureau", "Tommy Lee Jones", "Zacchaeus", "The Memory Keeper's daughter", "(1874-1876)", "high pride", "Yahtzee", "Tony Micelli", "Chemical Markup Language", "hives", "74.3", "William S. Hart", "Joshua", "Pride and Prejudice", "corey", "Kosher Wines", "Munich", "Michael Jordan", "Candlemas", "corey", "Hikaru Sulu", "tropical rainforests", "dough", "kyushu", "honey", "Boston", "corey corey", "Arctic Ocean", "the Italian flag", "squash", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Odd Couple", "Monty Python's Spamalot", "1911", "Bryan Kocis", "her translation of and commentary on Isaac Newton's book \"Principia\"", "Israel", "top designers", "anti-trust laws."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6466145833333334}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.7499999999999999, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2965", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-768", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-15027", "mrqa_searchqa-validation-10357", "mrqa_searchqa-validation-4597", "mrqa_searchqa-validation-5162", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4718", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-3054"], "SR": 0.5625, "CSR": 0.5544354838709677, "EFR": 1.0, "Overall": 0.7772177419354839}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "Ferengi cocktails Quark", "Christian Kern", "June 26, 1970", "Bloomingdale Firehouse", "Elena Marie Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court Judge Aharon Barak", "Bangkok", "Oklahoma Sooners", "Merrimack", "Charlie Wilson", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Ravenna", "Anita Dobson", "a family member", "Janis Lyn Joplin", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Rockland", "Slaughterhouse-Five", "Adventures of Huckleberry Finn", "wineries", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Town of Oyster Bay", "Sinngedichte", "Highwayman", "Fuenlabrada, in the autonomous community of Madrid", "Kevin Spacey", "Arizona State University.", "Blue Grass Airport", "Lawton Chiles", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Isabella Palmieri", "Hathi Jr.", "1935", "fredus", "\"Slow\"", "Cruisin", "the Moffat Tunnel, which passes underneath the Continental Divide.", "the European Commission", "Friday,", "Burgundy", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7448517628205128}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.4, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_searchqa-validation-6055"], "SR": 0.65625, "CSR": 0.5576171875, "EFR": 1.0, "Overall": 0.77880859375}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 Lunar Module (LM) \"Eagle\"", "jellyfish", "March", "a shoe", "Fauntleroy", "the World Health Organization", "Eat porridge", "Kofi Annan", "oxygen", "the right to print was strictly controlled in England", "Taggart Season 23 Episode 4", "Che Amanwe and Chi Eekway", "the Gulf of Mexico", "Ladee-Lo", "Sven Goran Eriksson", "\"Nation shall not lift up sword against nation, neither shall they learn war any more.\"", "Jackson Street", "Brussels", "Flora MacDonald", "John Poulson", "Charles de Gaulle Airport", "a euro", "Jack Frost", "Saskatchewan (province)", "Laurent Planchon", "the Solent", "vomiting", "the Red Lion", "Bristol Aeroplane Company", "lettuce", "Steve Davis", "\"Argo\u201d", "Gemini", "Surrey", "1971", "the Fosse Way", "Budapest", "the Coquimbo Region", "Inca Garcilaso de la Vega (Peruvian historian and writer) died in C\u00f3rdoba, Spain", "borax", "a \"third track\"", "Jamaica", "Peter Nichols", "Diana Dors", "Kent", "Vickers-Armstrong's", "Ray Charles", "the tenderness", "customary units", "Miller Brewing", "northwestern Italian coast", "Sydney Opera House", "the earthquake's aftermath", "her decades-long portrayal of Alice Horton on the soap opera \" abuses of our Lives,\"", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\"", "Peter Bogdanovich", "a collared dove", "the Federal Council of Churchesthe predecessor of the National Council of..."], "metric_results": {"EM": 0.40625, "QA-F1": 0.4882034632034632}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.7000000000000001, 0.12121212121212123, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-4241", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-4986", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-7262", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-4028", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.40625, "CSR": 0.553030303030303, "EFR": 1.0, "Overall": 0.7765151515151515}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "Lana Del Rey", "1,228 km / h ( 763 mph )", "New England Patriots", "Doc '' Brown", "Antarctica", "Mitch Murray", "blue", "Gunpei Yokoi", "John Bull", "775 rooms", "eusebeia", "waiting tables at the Moondance Diner", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "long line", "Jesus'birth", "a habitat", "Kirsten Simone Vangsness", "Central Germany", "Andrew Johnson", "Etienne de Mestre", "atreus", "electors", "Julia Ormond", "Sauron", "1961", "shakespeare", "2013", "March 1", "novelization", "redox", "Spain", "Steffy Forrester", "Paul Lynde", "reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "`` Jocelyn Flores", "abdicated in November 1918", "paid monument", "erosion", "March 2, 2016", "stuffing", "1996", "Ray Charles", "16", "Ramones", "1800", "Norman French waleis", "Frank Theodore `` Ted '' Levine", "New Jersey", "May 2010", "France", "Heath Ledger", "jimmy ride", "a centaur", "music lover", "cricket fighting", "Luis Edgardo Resto", "drama that pulls in the crowds", "a Ukrainian -- is accused of involvement during World War II in killings at a Nazi German death camp in Poland.", "Islamabad", "Tunisia", "RAND", "atlantic"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5322205563371735}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, true, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.06451612903225806, 1.0, 1.0, 1.0, 0.18181818181818182, 0.6666666666666666, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8205128205128205, 0.0, 0.4210526315789474, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.1818181818181818, 0.09999999999999999, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-1640", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_triviaqa-validation-5607", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2118", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.46875, "CSR": 0.5505514705882353, "EFR": 1.0, "Overall": 0.7752757352941176}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Zeebo", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar medium", "Automobile drivetrains", "Universal Pictures, which holds the library of predecessor companies DreamWorks Animation and Classic Media, and who in turn with copyright holder Ward Productions", "Sukhvinder Singh, Mahalaxmi Iyer and Vijay Prakash", "March 14, 1942", "Nick Sager", "London boroughs, Metropolitan boroughs, unitary authorities, and district councils", "prophets", "state legislators of Assam", "Gastric acid, gastric juice or stomach acid, is a digestive fluid formed in the stomach and is composed of hydrochloric acid ( HCl ), potassium chloride ( KCl ) and sodium chloride ( NaCl )", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "sport utility vehicles", "Lenny Jacobson", "temperature at which the phase transition occurs", "Mind your Ps and Qs", "Germany's failure to destroy Britain's air defences to force an armistice ( or even outright surrender ) as the first major German defeat in World War II", "20 November 1989", "Tom\u00e1s de Torquemada", "Bob Gaudio and his future wife Judy Parker", "1975", "Irene Bedard and Mel Gibson", "Procol Harum", "Erica Rivera", "lead - acid or 1.5 volts for zinc - carbon cells", "a four - page pamphlet in 1876", "2003", "Sebastian Lund", "Wednesday, 5 September 1666", "California State Route 1", "The management team", "to encounter antigens passing through the mucosal epithelium", "Flex SDK, a set of components that included charting, advanced UI, and data services ( Flex Data Services )", "Steveston Outdoor pool", "Nicky Slater", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Lula", "1850", "braking to a full stop", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Tennesseeitans", "\u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F ) at Vostok Station", "a cliffhanger showing the first few moments of Sam's next leap", "on a bronze plaque and mounted inside the pedestal's lower level", "Cheerios", "kunigunde Mackamotski", "Brian Close", "a hard rock/blues rock band, they have also been considered a heavy metal band, although they have always dubbed their music simply \"rock and roll\"", "Galleria Vittorio Emanuele II", "every aspect of public and private life", "Zelaya and Roberto Micheletti, the politician who was appointed president hours after Zelaya's June 28 removal, reached an agreement late Thursday to form a government of national reconciliation.", "Olympic medal", "Henry Ford", "Toyota", "Abraham Lincoln", "a cancer is the leading cause of death, and it's all the more devastating because it remains a complex"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5553867047997039}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.16666666666666669, 0.4444444444444445, 0.5, 1.0, 0.3636363636363636, 1.0, 0.3333333333333333, 0.14814814814814814, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 0.5, 0.5714285714285715, 1.0, 1.0, 0.0, 0.26666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.06896551724137931, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.2758620689655173, 0.0, 0.8421052631578948, 0.0, 0.42857142857142855, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-6182", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.40625, "CSR": 0.5464285714285715, "EFR": 0.9473684210526315, "Overall": 0.7468984962406016}, {"timecode": 35, "before_eval_results": {"predictions": ["repressing those domestic Islamists who attacked it (bin Laden being a prime example), and increasing aid to Islamic groups (Islamist madrassas around the world and even aiding some violent Islamist groups)", "euphoric", "the seven Wonders of the Ancient World", "Venezuela", "Austria", "Ring Magazine", "Peter Pan", "d'Agnolo", "the Arctic Ocean", "air pressure", "can be used for the design and analysis of fish passages (including fish ladders),", "Lafayette", "Elijah Muhammad", "the doldrums", "Co-Founder", "Alexander Pushkin", "Australia", "the Munich Crisis", "Mexico", "a night shift", "first bishop of Rome", "Arkansas", "a hard Day's Night of the Living Dead", "Pierre-August Renoir", "mister", "operas", "Innsbruck", "Charles Keating Jr.", "Microsoft", "a fern", "Sony", "the Norse gods", "Atlantic City", "Blackwater USA", "elephants", "CNN", "a cingino Dam", "Odysseus", "Geronimo", "Kensington Palace", "wilson", "the Netherlands", "Pocahontas", "the Witch and the Wardrobe", "John Galt", "the amygdala", "Chicago Mercantile Exchange", "Las Vegas", "danskin", "the state's State Seal", "Madrid Symphony Orchestra", "a ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "psychological horror", "John Morgan", "Hungarian Rhapsody No. 2 in C-sharp minor, S.244/2", "Eleanor of Aquitaine", "Sen. Debbie Stabenow", "63", "the word that's on the button turns out to be also true."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5554015456989246}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, true, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false, false, true, true, false, true, false, true, true, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, false], "QA-F1": [0.12903225806451613, 1.0, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9699", "mrqa_searchqa-validation-11665", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-7868", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-265", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-8008", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-7270", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-5219", "mrqa_searchqa-validation-16094", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_hotpotqa-validation-3372", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.46875, "CSR": 0.5442708333333333, "EFR": 1.0, "Overall": 0.7721354166666666}, {"timecode": 36, "before_eval_results": {"predictions": ["electric lighting", "James W. Marshall", "Terrell Suggs", "the orbit of the Moon", "Lucknow", "2013 -- 14 television season", "National Industrial Recovery Act ( NIRA )", "The User State Migration Tool ( USMT )", "the Second Battle of Manassas", "William DeVaughn", "the National September 11 Memorial plaza", "Southend Pier", "Santa Monica", "sovereign states", "Brian Steele", "31 January 1934", "Filipino", "1773", "RAM", "May 31, 2012", "April 1917", "Bart Cummings", "October 27, 1904", "Harishchandra", "Olivia Olson", "1990", "Billy Gibbons", "Bill Pullman", "Beyonc\u00e9", "The Divergent Series : Ascendant", "Frankie Muniz", "stratum lucidum", "60", "Hasmukh Adhia", "four", "a retina", "the 1980s", "in soils", "card verification value ( CVV )", "oversee the local church", "bohrium", "Britain", "Escherichia coli", "Archduke Franz Ferdinand of Austria", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in the basic curriculum -- the enkuklios paideia or `` education in a circle '' -- of late Classical and Hellenistic Greece", "Mike Czerwien", "103", "Vienna", "English", "Mexico", "Benedict XVI", "$10.5 million", "Al Horford", "Andrew Johnson", "$22 million", "Workers' Party", "his mother, Katherine Jackson, his three children and undisclosed charities.", "cotton", "Dennis Haysbert", "Quinn", "Towcester"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6456631042568541}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.18181818181818182, 1.0, 0.18181818181818182, 0.888888888888889, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.5714285714285715, 0.08333333333333334, 1.0, 0.5, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.09523809523809523, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-5411", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-4212", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_hotpotqa-validation-4351", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953", "mrqa_searchqa-validation-13161"], "SR": 0.5625, "CSR": 0.5447635135135135, "EFR": 0.9285714285714286, "Overall": 0.736667471042471}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "Massachusetts", "South Africa", "first among equals", "(1996)", "a cappella", "albinism", "Henry Hunt", "an aglet", "Saturday Night Live", "Bayern M\u00fcnchen", "brazil", "boston brow", "brazil", "copper", "Jennifer Saunders", "bbc", "brazil", "Doris Lessing", "Scooby-Doo", "swaziland", "brazilia", "Kent", "a bumber", "points based scoring system", "brazil", "Kent", "Rodgers and Hammerstein", "Boy George", "Galileo Galilei", "gertrud Margarete", "Lee Ingleby", "Marilyn Manson", "brazil", "The Tempest", "a carburetor", "brazilia", "Boulder Dam", "long-term effects", "Saudi Arabia", "Belle de Jour", "Morecambe", "abba", "rain", "blue", "the American astronomer Asaph Hall", "France", "geena Davis", "kunsky", "dying", "Rosamund Pike", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo James Walcott", "Ben Ainslie", "the District of Columbia near Takoma Park, Maryland.", "thunderstorms", "different women coping with breast cancer in", "the &quot", "a sunflower", "Madonna's", "March 24,"], "metric_results": {"EM": 0.5, "QA-F1": 0.5368107769423559}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7368421052631579, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-69", "mrqa_triviaqa-validation-3349", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-7117", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-2982", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291", "mrqa_searchqa-validation-7454"], "SR": 0.5, "CSR": 0.5435855263157895, "EFR": 1.0, "Overall": 0.7717927631578947}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "tyne", "a liver", "40", "table salt", "Bears", "cuba", "norma", "Phil Redmond", "Stevie Wonder", "a head", "hound", "hanover", "a moon", "Charles I", "workless", "scales", "Dirty Dancing", "goddess of Revenge", "Diana Ross", "a man of gold", "a 1934 Austin seven box saloon", "Paul Anka", "carthaginians", "cuba", "a prince", "Blade Runner", "Jay-Z", "leopard", "a drum kit", "cuba", "le Dame aux cam\u00e9lias", "Andrew Mitchell", "flidelio", "South Africa", "Christian Dior", "railway lines", "Killer whales", "Georgia", "France", "raspberries", "fasting", "Cyprus", "speed camera", "Earl", "lizard", "bridge", "frauds", "a sea horse", "even numbers", "Tony Blair", "quartz or feldspar", "54 Mbit / s, plus error correction code,", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Ray Lynn", "piano", "an impromptu memorial for the late singer at the \"Stone Circle,\" a neolithic monument in the grounds of the venue.", "the women without feeling that its legal system has been slighted, according to analyst Mike Chinoy.", "French Guiana", "cablevision", "arms", "Tiger Woods"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5190848214285715}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, true, true, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.0, 0.8, 1.0, 0.75, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-3942", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6603", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5730", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.46875, "CSR": 0.5416666666666667, "EFR": 1.0, "Overall": 0.7708333333333334}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "alivo", "Midnight Cowboy", "norma", "seborrheic dermatitis", "Amanda Barrie", "heavy barge", "Cameroon", "central Stockholm", "Tangled", "dogs", "norman Douglas", "Bulls Eye", "abon which the sun scarce designs to shed its light", "normz bajec-Lapajne", "Timothy Carroll", "Jane Austen", "pembrokeshire Coast National Park", "Kevin Macdonald", "peppers", "cenozoic", "jimmy Boyd", "isambard Kingdom Brunel", "norman", "1957", "exeter", "carlefranche", "butter and oil", "micelles", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "e. T. A. Hoffmann", "Shanghai", "Spain", "farms the world\u2019s supply \u2013 all 12 acres of it", "Tuesday", "Guru Nanak", "bleak house", "Inigo Montoya", "phosphorus", "little Jack Horner", "Indianapolis", "norman haze", "cuckoo", "Miss Marple", "Ford", "Alice Cooper", "moctorca", "norman", "Royal Bengal Tiger", "a spherical boundary of zero thickness", "norman", "was an American newspaper based in New York City.", "1999", "Sela Ann Ward", "The Cycle of Life", "forgery and flying without a valid license,", "137", "a flagpole", "St. Patrick's Day", "linebacker", "Sondheim"], "metric_results": {"EM": 0.390625, "QA-F1": 0.44220102813852813}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6497", "mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-10", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-6153", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-2142", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-8554", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-16910", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-807", "mrqa_naturalquestions-validation-9755"], "SR": 0.390625, "CSR": 0.537890625, "EFR": 0.9743589743589743, "Overall": 0.7561247996794871}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players", "norway", "de Quincey", "the black death", "horse", "buffalo", "Octavian", "a dove", "Sarajevo", "the Bill of Rights", "smith", "Neighbours", "mutiny on the Bounty", "trumpet", "Westminster Abbey", "origami", "resistance of an unknown resistor", "the Arabian Gulf", "devon", "abon", "avunculicide", "smith", "\u201cTote the weary Load,\u201d", "diesel", "Tomorrow Never Dies", "Sudan", "dogs", "norway", "norway", "New Hampshire", "James I", "charlie fenton", "the Philippines", "purple", "smith", "abon", "hell Upside Down", "Venice", "10", "Southwest Airlines", "a dog", "deaver", "Comedy of Errors", "chicago", "glyn Jones", "gerry douglas", "crossword clue", "the Skagerrak", "radicalization", "avon", "Humpty Dumpty", "1998", "Tanvi Shah", "the EN World web site", "the 100th anniversary of the first \"Tour de France\"", "Mach number (M or Ma)", "Janet and La Toya", "more than 2.5 million", "researchers", "the Matrix", "devon devon", "nibelung", "Inequality of opportunity was higher"], "metric_results": {"EM": 0.359375, "QA-F1": 0.428125}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.25, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999]}}, "before_error_ids": ["mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-3343", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-6152", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-7642", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4337", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.359375, "CSR": 0.5335365853658536, "EFR": 0.9512195121951219, "Overall": 0.7423780487804877}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "norway", "hula hoops", "nixon", "henry vii", "roddy dennis", "abacus", "Robin Hood's Holy Grail", "aisyphus", "Velazquez", "South African", "caracas", "london", "tchaikovsky", "oliver Twist", "Scotland", "true Stories", "David Bowie", "Buzz Aldrin", "Raymond Williams", "popowo", "Dick Turpin", "rust", "james krakowski", "pembroke County", "tbilisi", "Mel Gibson", "jealousy", "nine", "glenn close", "Lacock Abbey", "spencer twat", "domestic cat", "anita Brookner", "jameson", "Golda Meir", "Black Sea", "bagram", "Susie Dent", "a power outage", "Vienna", "Archers", "a clown", "james vii vii", "henry gee", "james b Boyd", "shakespears Sister", "Marx Brothers", "tyne", "v.V. of Amsterdam", "Dry Ice", "Pat McCormick", "19 June 2018", "2001", "1993 to 1996", "Michael Rispoli", "September 29, 2017", "he and the other attackers were from Pakistan", "June 6, 1944", "sniff out cell phones.", "a bassoon", "the o.K. Corral", "butternut squash", "vii"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5718084273182957}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.3333333333333333, 0.10526315789473685, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-174", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-4885", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-6097", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_hotpotqa-validation-2625", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.515625, "CSR": 0.5331101190476191, "EFR": 1.0, "Overall": 0.7665550595238095}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics", "a shortfall in their pension fund and disagreements on some work rule issues.", "Eintracht Frankfurt", "Comoros Islands", "revolution of values", "Jeddah, Saudi Arabia", "40", "his chest", "\"I'm just getting started.\"", "Manny Pacquiao", "$250,000", "Wednesday,", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "Salt Lake City, Utah", "dancy-Power Automotive Group", "the federal chamber of deputies", "64", "New Delhi, India", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "Iran's parliament speaker", "ended his playing career", "\"E! News\"", "South Florida", "william s. Cohen", "ice jam", "toxic smoke from burn pits", "Benazir Bhutto", "July", "U.S. senators", "South Africa", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9", "Cal Ripken", "Johannesburg", "cancer", "acid attack", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning,", "says it recycles 100% of its byproducts which supplies 80% of the operation energy at the plant.", "about 5:20 p.m.", "Former Mobile County Circuit Judge Herman Thomas", "played key roles in the chemical attack on the Kurdish town of Halabja in 1988", "a man's lifeless, naked body", "\"release\" civilians", "Trevor Rees", "the shipping industry -- responsible for 5% of global greenhouse gas emissions,", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc", "spain", "Misery", "marquis de Portago", "Antonio Lippi", "Thorgan ganael Francis Hazard", "Renfrew", "norwegian", "johnny weissmuller", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.5, "QA-F1": 0.5737717301862039}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true], "QA-F1": [1.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.8000000000000002, 1.0, 0.7272727272727273, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.0, 0.6, 0.10810810810810811, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-2479", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-3610", "mrqa_searchqa-validation-6881"], "SR": 0.5, "CSR": 0.5323401162790697, "EFR": 1.0, "Overall": 0.7661700581395349}, {"timecode": 43, "before_eval_results": {"predictions": ["twelfth most populous", "the House of Borromeo", "Washington, D.C.,", "1943", "a facelifted 850 saloon", "The Mountain West Conference", "the National Basketball Association (NBA)", "Western Europe", "movie scripts", "Schaeffler AG", "English football league system", "1989 until 1994", "the Distinguished Service Cross", "\"50 best cities to live in.\"", "Bridgetown", "Lollywood and Pollywood films", "Emmanuel ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "my Backyard", "2008", "coaxial", "Northern Lights", "three different covers", "Malayalam cinema", "held in Kingdom of Dalmatia", "August 11, 1946", "Vincent Landay", "May 26, 2010", "Estadio de L\u00f3pez Cort\u00e1zar", "Cartoon Network Studios", "Nicolas Vanier", "1985", "Wonder Woman", "Meghan Markle", "Texas Raiders", "a Portuguese dancer and choreographer", "Joe Scarborough", "English", "76,416", "Bonkyll Castle", "second cousin once removed", "2012 Summer Olympics", "Studio 33 (PS) and Sony Studio Liverpool (PS2)", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "under the UK\u2019s Trade Mark Registration Act 1875,", "blue", "elbow", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "the Employee Free Choice act in Lafayette Square in Washington on Monday.", "the release of the four men", "backyard BBQ season", "Jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6879733541418325}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.08695652173913042, 1.0, 0.4444444444444445, 1.0, 1.0, 0.29629629629629634, 0.5333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070", "mrqa_newsqa-validation-2345", "mrqa_searchqa-validation-260"], "SR": 0.609375, "CSR": 0.5340909090909092, "EFR": 1.0, "Overall": 0.7670454545454546}, {"timecode": 44, "before_eval_results": {"predictions": ["British", "Sean Yseult", "Washington, D.C.", "over 12 million", "sexy Star", "Conservatorio Verdi", "President of the United States", "the backside", "\"Barracuda Frank\"", "The Future", "the Knight Company", "Adam Karpel, Alex Baskin, Douglas Ross, Gregory Stewart, Scott Dunlop, Stephanie Boyriven and Andy Cohen", "Denmark", "December 31, 2015", "Margarine Unie", "death", "Fort Valley, Georgia", "Tom Hanks", "Vladimir Valentinovich Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool Football Club", "William Lyon Mackenzie King", "Ted", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Chrysler", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "The Division of Fawkner", "Socrates", "American singer Toni Braxton", "Hindi", "Richard Masur", "Irish Chekhov", "311", "Dr. Gr\u00e4sler, Badearzt", "Alexandre Dimitri Song Billong", "Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "estimated population of 102,984", "Roscoe Lee Browne", "Super Bowl VIII", "William Crystal", "over 38 million", "Spectator", "Easter Parade", "The first performance of Elgar\u2019s \u2018Enigma\u2019 Variations", "last summer.", "almost 100", "into the Southeast,", "the jeffersons tv show", "a stick to fish the filemot frith for treasures", "heresy", "One Direction"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6747702205882353}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 0.8, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-2525", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-1825", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_hotpotqa-validation-2104", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10536", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-3263"], "SR": 0.5625, "CSR": 0.5347222222222222, "EFR": 1.0, "Overall": 0.7673611111111112}, {"timecode": 45, "before_eval_results": {"predictions": ["American Revolution", "quod erat demonstrandum", "Elizabeth II", "gaius Julius Caesar", "Northern Exposure", "cocoa butter", "Kokomo", "Esther", "Warren Harding", "Monty Hall", "miniature golf", "Bill Hemmer", "February 2, 1886", "Pannonia", "Yellow Fever", "a sea otter", "M&M's", "\"franchise\"", "thy rod and thy staff", "Charles W. (Chuck) Colson, 42, of McLean, Va.", "dressage", "astronomer", "Mickey Mouse", "a bud or eye", "Associate Professor", "a \"piece of cellophane for easier removal\"", "Medusa", "a spiral staircase", "tabby", "musical notes", "Voyager 1", "Farsi (Persian)", "insulin", "objects", "China", "Helen of Troy", "Vegetarianism", "peace sign", "Morrie Schwartz", "English Monarchs These 2", "Rajasthan", "sexy Beast", "a \"piece of manry\"", "NFL", "a samt ar-ras", "White bread and butter", "Robert's Rules Process for handling a Main Motion", "William Wordsworth", "brushes", "a \"dwarf planet\"", "Haroun", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London, England", "Isle of Wight", "Peppercorn class", "Queen In-hyun's Man", "Oneida Community", "Daniel Richard \" Danny\" Green, Jr.", "Libreville, Gabon.", "two tickets to Italy on Expedia.", "Brett thought it would be best if he resigned,\"", "Cahawba, Dallas County"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5859375}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.8, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-14930", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-14560", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-2997", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-1151", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-11722", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-5435", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3949", "mrqa_triviaqa-validation-888"], "SR": 0.46875, "CSR": 0.5332880434782609, "EFR": 1.0, "Overall": 0.7666440217391304}, {"timecode": 46, "before_eval_results": {"predictions": ["\"degrees of privilege\"", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "a torture in many prisoners escorted off to reveal the room that is a scene was consigned", "Faggot", "a gaggle", "California Chrome", "Pluto", "Route 66", "the Taklamakan Desert", "Sindh", "Movie", "the Great Victoria Desert", "German", "the British pop band Go West", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Neptune", "Birmingham", "snakes", "Sedgefield", "the Coral Sea", "Saddam Hussein", "Nadia Comaneci", "trenches", "South Korea", "pigs", "sequel, maybe", "Carmen", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "a hundred symbols", "Potomac", "Argentina", "Luke", "Frankfurt", "Mouse", "Goldie Hawn", "pulsar", "Belgium", "horses", "liqueurs", "Benfica", "Penthouse", "Games played", "works in a bridal shop", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11", "\"Twilight\"", "the museum itself.", "Speed Racer", "H.G. Wells", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6738078327922078}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.125, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5714285714285715, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-445", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-5123", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-4088", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-2953", "mrqa_searchqa-validation-4652"], "SR": 0.609375, "CSR": 0.534906914893617, "EFR": 1.0, "Overall": 0.7674534574468085}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "Palazzo delle Prigioni,", "Sinclair Lewis", "a bear suit", "Renard", "pigments", "jodie Foster", "Vaclav Havel", "Dick Van Dyke", "Isabella", "Tina Turner", "1789", "Portstewart", "glasses", "perfumer", "twelfth night", "iron", "germany", "The Apprentice", "kent", "Cubism for Kids", "sahara", "commonwealth Institute of Science and Industry", "eukharistos", "Charlotte's Web", "Octopussy", "silks", "Charles Foster Kane", "Lorne Greene", "rowing", "Corin Redgrave", "call My Bluff", "a", "sahara", "Angela McCourt", "oats", "Caroline Aherne", "Home Guard", "starch", "soap", "Donna Summer", "a balustrade", "nottingham", "gdansk", "Welcome Stranger", "taggart", "sextilis", "Chechnya", "a police janitor", "a- Team", "football", "1,281,900", "CV Raman", "Sun Tzu", "bioelectromagnetics", "Foxborough, Massachusetts", "1952", "\"golden city,\"", "people", "Michelle Obama", "kbenhavn", "the Proletariat", "sara", "fluoroquinolone"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5392992424242424}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-7450", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-4081", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-5096", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-736", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-3758", "mrqa_triviaqa-validation-4665", "mrqa_triviaqa-validation-1730", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-7020", "mrqa_newsqa-validation-1804"], "SR": 0.484375, "CSR": 0.5338541666666667, "EFR": 0.9696969696969697, "Overall": 0.7517755681818182}, {"timecode": 48, "before_eval_results": {"predictions": ["East Lothian", "Caesars Entertainment Corporation", "Supergirl", "\u00c6thelred the Unready", "shaun the sheep", "Stephen Mangan", "William McKinley", "1905", "all Nippon Airways", "Mineola, New York", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "mash-Up", "1986", "early Romantic period", "Gettysburg address", "Harold Edward Holt", "Washington Street", "Lauren Lane", "Babylon", "Ford Falcon", "New York State Route 907E", "The Company", "1827", "Kim Bauer", "$700 million", "Edward James Olmos", "Suffolk, England", "prussian", "o", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard", "45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "1848", "Texas Tech University", "John McClane", "Larry Wayne Gatlin", "924", "Edward Michael \" Mike\"/\"Spanky\" Fincke", "North Carolina", "Selinsgrove, Pennsylvania", "Augusta Ada King-Noel, Countess of Lovelace (\"n\u00e9e\" Byron; 10 December 1815 \u2013 27 November 1852)", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "cake", "angad Bedi", "space shuttle Challenger", "basil", "Clio Awards", "\"The Rosie Show,\"", "California-based Current TV -- media venture launched by Clinton's former vice president, Al Gore.", "well over 1,000 pounds).", "aprony", "the dead man", "the Library of Congress", "the thylakoid membrane"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6641945954106281}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8695652173913043, 0.19999999999999998, 0.0, 0.5, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 0.0, 0.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-4008", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-659", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-775", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-2595", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028", "mrqa_naturalquestions-validation-4685"], "SR": 0.59375, "CSR": 0.5350765306122449, "EFR": 0.9615384615384616, "Overall": 0.7483074960753533}, {"timecode": 49, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John W. Henry", "James Woods", "James Mitchum", "4 April 1963", "1995", "Steve Carell", "Wendell Berry", "Love Hina", "eastern India", "novelty songs, comedy, and strange or unusual recordings dating from the early days of phonograph records to the present", "OutKast", "five aerial victories", "Jean Cayrol", "the Seasiders", "Musicology", "Dragon TV", "Appalachian Mountains", "Bay Ridge, Brooklyn", "Nick Hornby", "over 1.6 million", "1928", "1969", "February 20, 2011", "North Greenwich Arena", "1988", "Lucy Maud Montgomery", "Eminem, Bad Meets Evil, Akon, Christina Aguilera and Taio Cruz", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "Golden Globe Award", "southwest Denver, Colorado near Bear Creek", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "Dutch", "Terry Malloy", "Golden Calf", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "Cee - Lo", "Everywhere", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Honda", "J. M. W. Turner", "Republic of Upper Volta", "56,", "Nkepile Mabuse", "Eintracht Frankfurt", "Presley O'Bannon", "Hephaestus", "Amherst College", "two courses"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6461334862892525}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3547", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-1434", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-5896", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-1259", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.5625, "CSR": 0.535625, "EFR": 1.0, "Overall": 0.7678125}, {"timecode": 50, "UKR": 0.69921875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.826171875, "KG": 0.46484375, "before_eval_results": {"predictions": ["Sushant Singh Rajput and Disha Patani", "\u00c6thelred I", "Fife, Scotland", "about 26,000", "Spain, Mexico and France", "1981", "OS DATA", "February 26, 1948", "the National Aviation Hall of Fame class of 2001", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union.", "A1 Recordings, Freebandz and Epic Records", "IFFHS World's Best Goalkeeper", "Suggsy Bogues", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "May 5 to July 8, 2014", "June 11, 1973", "twenty-three", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "northern mockingbird", "Picric acid", "Las Vegas", "ESPN's", "bringing French cuisine to the American public with her debut cookbook, \"Mastering the Art of French Cooking\", and her subsequent television programs", "fantasy role-playing game", "feats of exploration", "Dolly Records", "Bergen County", "Marlon St\u00f6ckinger", "Feyenoord's Sekou Ciss\u00e9, WS Woluwe's Bassilia Sakanoko, UTA Arad's Leoh Digbeu", "the quarter finals", "the superhero Birdman", "Biloxi", "New York Yankees", "1996", "King Kal\u0101kaua", "Mark \"Chopper\" Read", "e esoteric darkwave", "IATA: VNO, ICAO: EYVI", "zoonotic", "122,067", "the High Court of Admiralty", "Mercer Bears", "Kate Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "21 December 2017", "1800", "the Behavioral Analysis Unit", "glycerol", "an umbrella", "the animal\u2019s", "is the most high-profile amalgamation of Indian and western talent yet,", "1.2 million people.", "84-year-old", "Jacob's", "the prosecution may give a testified defendant full immunity, which means the defendant", "Steven Spielberg", "Mitch Murray"], "metric_results": {"EM": 0.5, "QA-F1": 0.6207331730769231}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, false, false, true], "QA-F1": [0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7692307692307693, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.09523809523809523, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.25, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.30769230769230765, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4070", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-45", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-4054", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_triviaqa-validation-1015", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770", "mrqa_searchqa-validation-1372"], "SR": 0.5, "CSR": 0.5349264705882353, "EFR": 1.0, "Overall": 0.7050321691176471}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County", "Prince Antoni Radziwi\u0142\u0142", "S\u00f8nsberg", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia", "Daniel Espinosa", "1942", "water sprite", "Bury St Edmunds, Suffolk, England", "1981", "What You Will", "Cartoon Network Too", "MG Cars", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "Logan International Airport", "Blackpool Football Club", "Nick Fury: Agent of S.H.I.E.L.D.", "100 million", "James Gregory", "Volvo 850", "1978", "July 25 to August 4", "Ann", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom during World War II", "Oracle", "Pittsburgh", "John Andr\u00e9", "Three-card brag", "1942", "new buildings, structures, projects, or even designs that are deemed to be comparable to the seven Wonders of the World", "Nikolai Morozov", "its inspiring interpretations of traditional music of pre-Hispanic and contemporary music of the Andes", "Der Frieden", "two", "Outside", "Traumnovelle", "Chechen Republic", "actress and model", "The football manager who recruited David Beckham managed Manchester United's fourth season in the Premier League", "Sierra Nevada mountains", "Guangzhou, China", "British", "Jaguar Land Rover", "Citgo Petroleum Corporation", "artist", "B.R. Ambedkar", "Presley Smith", "hydrological cycle or the hydrologic cycle", "b Bryn Mawr", "Jet Harris", "Melissa Duck", "in a tenement in the Mumbai suburb of Chembur,", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "their culture, religion and national identity.", "Popular Science", "Hammer", "Latter-day Saints", "more and more suspicious of the way their business books were being handled."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6512744026806527}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, false, true, false, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, false, false, true, true, true, false, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.0, 1.0, 0.7499999999999999, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.15999999999999998, 0.6666666666666666, 0.0, 1.0, 0.1818181818181818, 1.0, 0.5, 1.0, 0.2666666666666667, 0.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-2929", "mrqa_hotpotqa-validation-5466", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-5677", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-10", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-5766", "mrqa_triviaqa-validation-1467", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-5108", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.53125, "CSR": 0.5348557692307692, "EFR": 1.0, "Overall": 0.7050180288461538}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods are often social communities with considerable face-to-face interaction among members", "1928", "Physical", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "novel", "the National Society of Daughters of the American Revolution (NSDAR)", "Timmy Sanders", "Japan", "St Augustine's Abbey in Canterbury, Kent", "The Indianapolis Times", "Alien", "Dizzy Dean", "UHF channel 44", "North Kesteven, Lincolnshire,", "West African descendants", "The Beatles", "\"Menace II Society\"", "September 1901", "March 30, 2025", "Black Panther Party", "Pinellas County", "Ben Johnston", "Imagine", "Evan Jonigkeit (pronounced \"John-a-kite\",born August 25, 1983)", "CBS Corporation", "\"Brickyard\"", "2012", "Candice Swanepoel", "Benny Andersson", "Peter Yarrow and Stookey", "Kathleen O'Brien", "private equity, credit and hedge fund investment strategies", "the north bank of the North Esk", "Paris", "rock music", "Yeeun, Sunmi and Hyerim", "\"Complex\" magazine", "WBC/WBA heavyweight champion Joe Frazier", "University College of North Staffordshire", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "\"The Omega Man\"", "David Dunn", "William Bradford", "FieldTurf", "my Beautiful Dark Twisted Fantasy", "Benj Pasek and Paul", "a hand injury", "the \u01c0Xam people", "U2", "the pulmonary arteries", "In May 1935, French Foreign Minister Pierre Laval allegedly asked Stalin to improve the situation of Catholics in the USSR", "France", "Taekwondo", "The Tinkler.", "since 1983", "the legitimacy of that race.", "the Dukes of Norfolk", "Italy", "peppers", "a star"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6925177527151212}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.4, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-557", "mrqa_hotpotqa-validation-2358", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-5131", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-7953", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.5625, "CSR": 0.5353773584905661, "EFR": 1.0, "Overall": 0.7051223466981132}, {"timecode": 53, "before_eval_results": {"predictions": ["a calendar", "Friedrich Nietzsche", "give up the ship", "Carnarvon", "Ireland", "Glaciers", "bdellium", "Marie Antoinette", "Aunt Bee", "the national park", "the meadow", "Pennsylvania", "Henri II", "the malignant disease", "Cannonball Run", "a light tan color", "Henry Wadsworth", "The Crow", "the Marathon", "John Keats", "(Scott) Peterson", "a large country", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "Dostoyevsky", "Mike Rowe", "Resident Evil", "Daughter", "the French army", "the UAE", "Dramamine", "a tiny little blue Korbat", "the Oktoberfest", "Dred Scott", "the Empress Josephine", "President McKinley", "Staten Island", "Transformers", "the Crystal Light Raspberry Ice", "the Yankees", "the declaration of saturated fat", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "a skull and", "Indira Gandhi", "the AWACS E-3 Sentry", "the Director of National Intelligence", "the graft fuses the two vertebrae together", "2018", "Peter Paul Rubens", "weasel", "David Bowie", "1 December 1948", "Lester Ben \"Benny\" Binion", "three centuries", "forgery and flying without a valid license,", "Michoacan state,", "\"gotten the balance right\"", "Carpenter"], "metric_results": {"EM": 0.546875, "QA-F1": 0.631063988095238}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, false, false, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25000000000000006, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-7535", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-5257", "mrqa_searchqa-validation-13330", "mrqa_searchqa-validation-14893", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15712", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-15504", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-11962", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-3729", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-15822", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821"], "SR": 0.546875, "CSR": 0.5355902777777778, "EFR": 1.0, "Overall": 0.7051649305555555}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "318/92", "Phil Sedgmen", "Anthony Joshua", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "Waffen SS", "Adrian Cronauer", "Copenhagen", "Spice Girls", "indigo", "Heston Blumenthal", "South Africa", "John le Carr\u00e9", "a googol", "the American Falls", "$SPX", "Mrs Merton", "jazz", "Alamo", "Brazil", "baloney cubed", "in 1844", "Michael Faraday", "George W.", "Montmorency", "hot-smoked haddock", "Happy Ever After", "Tim Peake", "Phil Redmond", "tamales", "Argentina", "St Moritz", "Good Neighbors", "Woody", "Jerry", "Sinclair Lewis", "mouse", "brazil", "Barry White", "Robin", "Parchman Farm", "Canada", "the Hague Conventions", "Portugal", "silver", "Moby Dick", "`` Fix You ''", "`` Killer Within ''", "prenatal development", "13\u20133", "My Beautiful Dark Twisted Fantasy", "\"The Worm\"", "\"Maude\"", "that the legislation will foster racial profiling, arguing that most police officers don't have enough training to look past race while investigating a person's legal status.", "in July", "Easy Rawlins", "William McKinley", "the Scripps National Spelling Bee", "Prussia"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6588541666666666}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-6992", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-7744", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-5753", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-3131", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-12187", "mrqa_searchqa-validation-14797"], "SR": 0.59375, "CSR": 0.5366477272727272, "EFR": 0.9615384615384616, "Overall": 0.6976841127622377}, {"timecode": 55, "before_eval_results": {"predictions": ["ensure that detainees are not drugged unless there is a medical reason to do so.", "the man was dead,", "CNN's Larry King", "is the eradication of the Zetas", "customers", "the United States", "in Iraq", "the Iranian consulate,", "crashing his private plane into a Florida swamp.", "the twins on narcotics-trafficking charges.", "CNN Moscow Correspondent", "is almost eradicated in the north and west of the country,", "Bright Automotive,", "NASCAR", "T.I.", "Muslim", "Coptic Christians", "a new television show which looks at how children as young as eight would cope without their parents for two weeks.", "is", "a clear strategy that was stuck to with remarkably little internal drama", "urged NATO to take a more active role in countering the spread of the", "in modern-day Haiti on Christmas Day 1492", "the Ku Klux Klan", "the full Senate Sotomayor,", "pine beetles", "lower house of parliament,", "Republicans", "Iran", "Harry Potter", "publicly criticized his father's parenting skills.", "in the Ronald Reagan UCLA Medical Center,", "was hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "from 18 years to life in prison", "remains unknown,", "60 euros -- $89", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Naturalist Charles Darwin", "acid attack", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy in Bangkok,", "looks at how children as young as eight would cope without their parents for two weeks.", "top winds", "rwanda", "twice", "Bob Johnson", "the \"bystander effect\"", "\"Dancing With the Stars.\"", "his club", "Microsoft", "two years", "the Confederate States", "Sylvester Stallone", "1,228 km / h ( 763 mph )", "Thom Yorke", "Charlie Sheen", "silversmith", "middleweight boxing legend", "the International Federation of Competitive Eating", "Valley Falls", "the Provisional Irish Republican Army", "Australia", "the Lone Ranger", "Australia"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5851188773564345}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true], "QA-F1": [0.6, 0.4, 0.8, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.7368421052631579, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.35, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.2857142857142857, 0.25, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.9, 0.08695652173913043, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.4, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-1877", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-475", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-2028", "mrqa_newsqa-validation-766", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-1541", "mrqa_newsqa-validation-419", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_hotpotqa-validation-5224", "mrqa_hotpotqa-validation-698", "mrqa_searchqa-validation-1388"], "SR": 0.453125, "CSR": 0.53515625, "EFR": 1.0, "Overall": 0.705078125}, {"timecode": 56, "before_eval_results": {"predictions": ["a long-range, subsonic, jet-powered strategic bomber", "peso", "the nucleus", "steroids", "USS Troopers", "Stalin", "a shallow water table", "a fertilized egg implantation in the uterus", "Python", "William Proxmire", "George Orwell", "the Takana", "wood", "Coach Carter", "Brachiosaurus", "a giant leap for mankind", "Psycho", "Greatest Hits", "Athens", "reality", "animal park", "\" Please Mr. Please\"", "Mickey Gilley", "Oral Roberts", "staff", "Constantine", "tin", "the Little Calumet River", "Jules Verne", "Dave Brubeck", "the Arsenal", "Stevie Wonder", "Richmond, Virginia", "Jupiter", "spiders", "Apple", "depression", "the Mausolus", "Act One", "a blue star sapphire", "Rhapsody", "the Ziegfeld Follies", "Sunshine Moonshine", "Ronald", "Mount Kilimanjaro", "a militia", "Delaware", "Graceland Plaza", "the Soviet Air Forces", "Don", "the 'oral phase' (first stage)", "John F. Kennedy", "Siddharth Arora / Vibhav Roy", "in the pouring rain at a rest stop", "Munich", "the Central Line", "12th", "Julie Kavner", "Benedict of Nursia", "Markov Random Field", "\"Abbey Road.\"", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5416666666666666}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, true, true, false, false, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, false, false, true, true, false, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2168", "mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-1616", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-11485", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-279", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-1463", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658", "mrqa_hotpotqa-validation-5280"], "SR": 0.484375, "CSR": 0.534265350877193, "EFR": 1.0, "Overall": 0.7048999451754386}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "the demon", "Merlin", "sculpture", "Alien", "Dallas' new slogan \"Live Large. Think Big.\"", "Mariachi", "Madonna", "excruciating", "Kilimanjaro", "beliefs", "Francis Ford Coppola", "Edgar Allan Poe", "the pope", "Calais", "Twenty", "New York", "tortuga", "Thomas Paine", "Isaac Newton", "American Wedding", "Anthony Michael Hall", "Tears for Fears", "Jamestown", "the Rhine", "blacksmith", "the mohs scale", "Katharine McPhee", "October 7, 1913", "Prince", "Cnut", "spiral", "Dan Eggen and Elizabeth Williamson", "alevin", "(Vijay) Singh", "geometric", "Baton Rouge", "Daniel Boone", "chariots of Fire", "notophthalmus", "Sweden", "clouds", "an eyelid", "Hong Kong", "The Addams Family", "a bacterium", "Sanders", "Bait-and-switch", "Churchill", "resolution", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "Zelah Clarke", "University of Oxford", "1,467", "\"Vision of Love\"", "abuse", "Paul Schlesselman of West Helena, Arkansas,", "Alwin Landry's", "Israel"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6522569444444444}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, false, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-6635", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-2637", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-2121", "mrqa_searchqa-validation-1930", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-5688", "mrqa_triviaqa-validation-7432", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3265"], "SR": 0.578125, "CSR": 0.5350215517241379, "EFR": 1.0, "Overall": 0.7050511853448276}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "super-yacht", "cooperating with Turkey in engaging with the Taliban in Pakistan and Afghanistan.", "tells stories of different women coping with breast cancer in five vignettes.", "housing, business and infrastructure repairs,", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "improve health and beauty.", "the school.", "Asashoryu", "attacked L.K. Chaudhary, the chief executive of an Italian car parts manufacturing company.", "China", "\"I never thought any of this was going to be easy,\"", "\"It is I, the chief executive officer, the one on the very top, should be responsible for this,\"", "ancient rituals in Olympia,", "a man's lifeless, naked body", "admitting they learned of the death from TV news coverage,", "detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "183", "Nirvana", "Patrick McGoohan,", "55-year-old", "Zimbabwe President Robert Mugabe", "new Touch,", "The woman who received the first-ever near-total face transplant in the United States", "International Polo Club Palm Beach in Florida.", "Mugabe and Tsvangirai", "the teens charged in the October 12 attack in Deerfield Beach, Florida.", "1000 square meters in forward deck space", "Turkey can play an important role in Afghanistan as a reliable NATO ally. The question is: How can Turkey best help", "Polo because \"it was the sport of kings. It was glamorous, sexy and international.\"", "a three-story residential building in downtown Nairobi.", "cancer", "Hussein's Revolutionary Command Council.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "ten people", "The Rev. Alberto Cutie", "funded by a German company and affiliated with the group Bread for the World.", "magazine", "FBI Special Agent Daniel Cain,", "Graham's wife", "February 12", "Oaxaca, Mexico", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "strict interpretation of sharia forbids girls from attending school, requires veils for women and beards for men, and bans music and television.", "trading goods and services without exchanging money", "two people,", "11 countries", "Some of them told CNN they couldn't pay for cable or satellite TV service.", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing.", "Ben Roethlisberger", "Taylor Michel Momsen", "Nick Grimshaw", "November 2016", "motorway (Coventry)", "Zaire", "toasts", "DreamWorks Animation", "Debbie Harry", "2004", "a cord", "timothy Guthrie", "Existentialism", "William Windom"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5572430000555001}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.0, 0.2, 1.0, 0.6153846153846153, 0.56, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 0.13333333333333333, 0.7000000000000001, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.2222222222222222, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.41666666666666663, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-659", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-535", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-2946", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.46875, "CSR": 0.5338983050847458, "EFR": 1.0, "Overall": 0.7048265360169491}, {"timecode": 59, "before_eval_results": {"predictions": ["James Archer", "Pakistan", "DTM", "Vernon Kay", "Florida", "ten episodes", "Tyler Posey", "Betty Cohen", "Scandinavian design", "the Bentley Twins", "Pasek and Paul", "publicly available", "Oregon", "Mrs. Eastwood & Company", "Blackpool Football Club", "Denver, Colorado", "Edward M. Kennedy", "Boeing EA-18G Growler", "21st Century Fox", "Pennsylvania's", "Danielle Fernandes Dominique Schuelein- Steel", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "North Atlantic Treaty Organisation", "from 1952 until 1971", "more extreme nationalist, and nativist ideologies, as well as authoritarian tendencies", "AOL Inc.", "World War II", "coca wine", "Thomas Perez", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "Best Supporting Actress", "New Jersey", "Ian James Rush", "Erich Maria Remarque", "Australian", "youngest TV director ever", "Arthur William Bell III", "California Shipbuilding Corporation", "Delaware River", "Jean Acker", "Anheuser-Busch", "MG Car Company Limited", "Boston Celtics", "May 2008", "Hungarian Rhapsody No. 2", "from the playing season, or before November 1", "Will", "employment in which a person works a minimum number of hours defined as such by his / her employer", "Ceefax", "Dieppe Raid", "Herrenhausen", "Capitol Records,", "228", "son of Gabon's former president", "stocks", "Thomas Alva Edison", "Han Solo", "Jeannie Longo-Ciprelli"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6356552301864802}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, false, false, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.6666666666666665, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3076923076923077, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 0.5, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.09090909090909091, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-5066", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-2131", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5286", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-3496", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2695", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-2977", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-8673", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6758", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-10636", "mrqa_newsqa-validation-153"], "SR": 0.53125, "CSR": 0.5338541666666667, "EFR": 1.0, "Overall": 0.7048177083333333}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "that NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "the plane was in fine condition at takeoff,", "Rivers", "'overcharged.'\"", "Alison Sweeney,", "Carrousel du Louvre,", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "Carl", "at least 25 dead", "269,000", "flooding", "The Frisky", "Patrick McGoohan,", "Syria and Iraq", "Afghan security forces", "The Arkansas weatherman", "hanged in 1979", "\"I don't plan to be one of those people who, as soon as they turn 18, suddenly buy themselves a massive sports car collection or something similar,\"", "sports cars", "Bush", "people", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell,", "\"not generals but businessmen\"", "Best Picture winner \"Slumdog Millionaire\" (No. 4)", "India", "body bags on the roadway near the bus,", "south of Kabul in the eastern Afghan province of Logar,", "10 to 15 percent", "No reason was given for the denial.", "Joan Rivers", "an engineering and construction company", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "At least 15", "the fires", "a one-of-a-kind navy dress with red lining", "a monthly allowance,", "Too many glass shards left by beer drinkers in the city center,", "the legitimacy of that race.", "Nigeria", "Andrew Morris,", "the catamaran", "Drottningtorget", "the driver", "the family's blog", "his cousin D\u00e1in", "Jesse McCartney", "the American Civil War", "T.S. Eliot", "67", "Australia", "18 December 1975", "1970", "Copenhagen", "The Pacemakers", "Khartoum", "Stand by Me", "Italian"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6081510709302937}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, false, false, true, false, false, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.1395348837209302, 0.19047619047619047, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8333333333333333, 1.0, 0.923076923076923, 0.26666666666666666, 1.0, 0.5, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-199", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-2402", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-2599", "mrqa_triviaqa-validation-1267", "mrqa_hotpotqa-validation-4172", "mrqa_searchqa-validation-6409"], "SR": 0.484375, "CSR": 0.5330430327868853, "EFR": 1.0, "Overall": 0.7046554815573771}, {"timecode": 61, "before_eval_results": {"predictions": ["series of monthly meals", "The retired Navy F-14 fighter pilot is the commander of the current space shuttle mission to repair and upgrade the Hubble Space Telescope.", "Santaquin City, Utah, home", "It has not", "Ed McMahon", "Bob Bogle", "183", "the Arctic north of Murmansk down to the southern climes of Sochi by way of St Petersburg and Moscow,", "4-1 Serie A win at Bologna", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "Tuesday afternoon", "General Motors'", "two soldiers and two civilians from the Defense and State departments", "Mark Fields", "Luiz Inacio Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "16 Indiana National Guard soldiers", "the body of the aircraft", "American third seed Venus Williams in the final of the Sony Ericsson Open in Miami", "onto the college campus.", "The cervical cancer vaccine,", "Bright Automotive,", "The planned Kingdom City project", "Europe,", "$7.8 million in cash", "Polo because \"it was the sport of kings.", "The elections are slated for Saturday.", "United", "surgical anesthetic propofol", "was humiliated by last month's incident,", "CNN", "school,", "The eye of Hurricane Gustav", "The cervical cancer vaccine, approved in 2006,", "two", "outfit from designer", "recovery workers still were trying to get the two bodies out of the plant, which makes Slim Jim food products.", "second-degree aggravated battery.", "the man facing up, with his arms out to the side.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines", "Cambodia", "Arsene Wenger", "The local Republican Party", "the Gulf", "former Procol Harum bandmate Gary Brooker in the House of Lords,", "27,", "if Russian long-range bombers should need to land in Venezuela, we would not object to that either.", "housing, business and infrastructure repairs,", "travel with privately armed guards.", "toys or doorbell installations", "British citizens", "Justin Timberlake", "Greece", "Brighton", "eagle", "Umberto II", "\"The Longest Yard\"", "Lucille D\u00e9sir\u00e9e Ball", "Louis XIV", "The Bronx", "flamboyant", "South Africa"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6995539568209805}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, true, true, true], "QA-F1": [0.0, 0.2727272727272727, 1.0, 0.5, 0.0, 1.0, 1.0, 0.7407407407407407, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.0, 1.0, 0.4444444444444444, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4347826086956522, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.11764705882352941, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-237", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2306", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-2149", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_hotpotqa-validation-2827"], "SR": 0.578125, "CSR": 0.5337701612903225, "EFR": 0.9629629629629629, "Overall": 0.697393499850657}, {"timecode": 62, "before_eval_results": {"predictions": ["0-0 draw away to Saudi Arabia", "portrait of William Shakespeare", "Current TV", "200", "T.I.", "media", "Friday,", "the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Arizona", "the report should spur U.S. diplomacy to prevent Iran from developing nuclear weapons", "two suicide bombers,", "56,", "April 28", "former Boca Juniors teammate", "Former Argentina international defender Fernando Caceres", "license plate \"BADBUL,\"", "Kurt Cobain", "nude beaches", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "a residential area in East Java", "\"Body Works\"", "diplomatic relations", "supermodel", "10 below", "1,073", "the children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "fled Zimbabwe", "girls around 11 or 12.", "passengers on the Miva Marmara", "food, music, culture and language of Latin America", "a cancerous tumor.", "Tennessee.", "Bright Automotive,", "nuclear weapon", "full-length computer-generated animated film with Pixar's \"Toy Story\"", "\"Up,\"", "165-room", "her daughter and granddaughter attend Oprah Winfrey's school in South Africa considers the talk-show host heaven-sent,", "al Qaeda,", "potential jurors", "Susan Atkins,", "Charlotte Gainsbourg and Willem Dafoe", "daughter, Zeina,", "Omar", "Chinese President Hu Jintao", "United States", "Burj Dubai tower", "when speaking out about a cause someone feels passionate about.", "25", "Anil Kapoor.", "President Obama and Britain's Prince Charles", "Wembley Stadium", "regulatory site", "40.5 metres", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Bob Mould", "331", "2008", "Ruth Bader Ginsburg", "The Big Sleep", "Seth", "peacock"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5702396972544999}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [0.5, 0.4, 0.0, 1.0, 0.25, 0.0, 1.0, 0.0, 0.0, 0.10526315789473685, 0.0, 1.0, 0.0, 0.8571428571428571, 0.5, 0.5, 1.0, 0.5, 1.0, 0.5714285714285715, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.05263157894736842, 1.0, 1.0, 0.26666666666666666, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 0.5, 0.4, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3044", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-831", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-3409", "mrqa_hotpotqa-validation-4598", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746"], "SR": 0.4375, "CSR": 0.5322420634920635, "EFR": 1.0, "Overall": 0.7044952876984126}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult or threaten the crown.", "closing these racial gaps.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "the New York Philharmonic Orchestra in North Korea", "for the shootings, handed over the AR-15 and two other rifles and left the cabin.", "The Detroit, Michigan, radio station promotion held three years ago was like a class to help women \"learn how to dance and feel sexy,\"", "the German Foreign Ministry,", "$89", "South African ministers and the deputy president", "Pakistan", "Japanese officials", "urged NATO to take a more active role in countering the spread of the narcotics trade.", "poor.", "bench", "Sixteen", "poems", "(3 degrees Fahrenheit),", "Technological Institute of Higher Learning of Monterrey,", "\"I saw guys who were 34, 35, 36 years old -- still young guys -- about to get out of the game,", "Golden Gate Yacht Club of San Francisco", "nearly 100", "a national telephone survey of more than 78,000 parents of children ages 3 to 17.", "ballots", "and renewable energy at home everyday,\"", "the Obama and McCain camps to promote mental health and recovery.", "Battlefield helicopter crews", "proceeds", "The minister later apologized, telling CNN his comments had been taken out of context.", "United's", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars\"", "civilians,", "March 3,", "peanuts, nuts, shellfish and fish tend to be lifelong,", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Christianity and Judaism,", "Casalesi Camorra clan", "after the party made a poor showing last year against another Communist movement.", "tranquil beaches,", "$1.5 million", "Booches Billiard Hall,", "'overcharged.'\"", "for an independent homeland since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama World Tour", "Kimberlin Brown", "a turlough, or turlach", "1910", "Kirk Douglas", "Rockefeller Center, New York City", "Vikram, Jyothika and Reemma Sen", "the Dutch Empire", "Royal Navy rank of Captain", "Department of Homeland Security", "France", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6842309398787594}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, true, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.42857142857142855, 1.0, 1.0, 0.0, 0.14285714285714285, 0.4827586206896552, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16216216216216214, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.5714285714285715, 0.0, 0.5, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.22222222222222224, 0.33333333333333337, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-1261", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-181", "mrqa_newsqa-validation-1286", "mrqa_newsqa-validation-2261", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-2470", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-967", "mrqa_newsqa-validation-372", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-6683", "mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-2986", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_naturalquestions-validation-10396"], "SR": 0.5625, "CSR": 0.53271484375, "EFR": 1.0, "Overall": 0.70458984375}, {"timecode": 64, "before_eval_results": {"predictions": ["prisoners at the South Dakota State Penitentiary", "sportswear,", "15-year-old", "July 23.", "Alwin Landry", "an American who entered the country illegally from China", "Chester Arthur Stiles, 38,", "United States", "Pakistan's High Commission in India", "Wednesday.", "Premier League club side Wigan Athletic in northern England.", "Adriano", "poems", "Sgt. Barbara Jones", "A 22-year-old college student in Boston, Massachusetts,", "to sniff out cell phones.", "Longo-Ciprelli", "\"The Screening Room\"", "helping to plan the September 11, 2001, terror attacks,", "June 6, 1944", "\"I'm just getting started,\"", "\"The precipitation will briefly transition back to light snow or flurries Saturday before ending Saturday afternoon,\"", "more than 30", "$30.2 million", "refused to refer the case of Mohammed al-Qahtani based on later interrogations", "free laundry service.", "rural California,", "Robert Park", "11th year in a row.", "83 eggs.", "future relations between the Middle East and Washington.", "the school.", "a plaque at the home of his great-grandfather", "death squad killings", "a nuclear weapon", "Kitty Kelley", "\"The missile defense system is not aimed at Russia,\"", "Oregon State Senior Sergeant David Petersen after he was able to catch up with six exotic sports cars on a stretch of Highway 18 near Grand Ronde, Oregon.", "for a construction project at the Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "no internal drama. He won it with unparalleled fundraising and an overwhelming ground game. And he won it after facing various challenges and turning them to his advantage.", "$3 billion,", "link", "Bobby Jindal", "he acted in self defense in punching businessman Marcus McGhee.", "potential revenues from oil and gas", "Sen. Barack Obama", "no airbags, credit and other key indicators.", "turntable", "360 \u00b0 - system", "Darlene Cates", "Colette", "crows", "Rhys Williams", "26 August 2013", "11", "January 15, 2016", "piano", "4.5%", "Barnard College", "Chiltern Hills"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6400675119836304}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, false, false, true, true, false, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5833333333333334, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 0.4, 0.19999999999999998, 0.30769230769230765, 1.0, 1.0, 1.0, 1.0, 0.8571428571428572, 1.0, 0.0, 1.0, 0.10526315789473685, 0.2857142857142857, 1.0, 0.15384615384615383, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-2205", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-827", "mrqa_newsqa-validation-8", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3907", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-3474", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516", "mrqa_searchqa-validation-4278"], "SR": 0.515625, "CSR": 0.5324519230769231, "EFR": 1.0, "Overall": 0.7045372596153847}, {"timecode": 65, "before_eval_results": {"predictions": ["drug test after taking a medicine that contained the banned substance cortisone.", "Larry Zeiger", "The Ski Train", "housing, business and infrastructure repairs,", "Joe Harn", "Port-au-Prince harbor", "Saudi Arabia", "Israel", "Nigeria,", "Mexico", "two Metro transit trains that crashed the day before,", "identity documents", "Denver, Colorado.", "\"He hears what I'm saying, but there's just no coming through,\"", "the single-engine Cessna 206", "no need for such humility.", "Angelo Nieves, an Orange County Sheriff's Department commander,", "could be secretly working on a nuclear weapon", "arrested Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Carol Fowler", "Glenn McConnell, Senate president pro tempore,", "I think that people are going to be focused now that we've [get] alternative views on how to move our country forward.", "April 22.", "Manuel Mejia Munera", "outfit from designer", "one of five Lebanese prisoners who Israel will release in exchange for two Israeli soldiers, Ehud \"Udi\" Goldwasser and Eldad Regev.", "Ozzy Osbourne", "Michelle Obama", "Carol Browner", "Molotov cocktails, rocks and glass.", "eight.", "Silver Spring, Maryland,", "U.S. intelligence official", "Bill Haas", "A Lion Among Men.", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Kr\u00f8yer", "Gyanendra,", "all faiths", "Gadahn, also known as Azzam", "Turkey", "Polo because \"it was the sport of kings.", "Texas and Oklahoma", "\u00a320 million ($41.1 million) fortune", "resources", "a million", "New York", "19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "\"Marketers are finally waking up to it -- you know -- black is beautiful,\"", "Arnold Schoenberg", "Comancheria", "assemble a stable, protective protein shell to protect the genome", "Einstein", "Nova Scotia", "pyrotechnic", "the Battelle Energy Alliance", "Lake County, Illinois", "Eran Kolirin", "a novelty pet", "Clemson", "Herod", "leopard"], "metric_results": {"EM": 0.40625, "QA-F1": 0.47866210246724955}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, false, true, false, false], "QA-F1": [0.18181818181818182, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.09090909090909091, 0.0, 0.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 0.07407407407407407, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.25, 1.0, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.35294117647058826, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3233", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-467", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4053", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3792", "mrqa_newsqa-validation-208", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.40625, "CSR": 0.5305397727272727, "EFR": 0.9736842105263158, "Overall": 0.6988916716507176}, {"timecode": 66, "before_eval_results": {"predictions": ["the Australian Open.", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "a nuclear weapon", "green-card warriors", "a space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Booches Billiard Hall,", "Two U.S. filmmakers were injured", "T.I., whose real name is Clifford Harris, was arrested Saturday just hours before he was scheduled to perform", "Bowe Bergdahl", "many different", "President Bush", "$17,000", "Employee Free Choice act", "the assassination of President Mohamed Anwar al-Sadat", "Judge Herman Thomas", "snowstorm to hit Britain", "Arnold Drummond", "Madonna", "\"I'm certainly not nearly as good of a speaker as he is.\"", "the Bush administration's controversial system of military trials for some Guant Bay detainees.", "The 27-year-old American has made a name for himself singing enka, a traditional form of lounge music that flourished in 1940's Japan.", "Larry King", "as many as 250,000 unprotected civilians", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "managing his time.", "a month ago", "Omar", "Scotland", "Mugabe's opponents", "a Tutsi ethnic minority and the Hutu majority had been at odds even before 1994.", "his business dealings for possible securities violations", "January", "\"bleaching\"", "Millvina Dean,", "\"The Block is Hot\" and \"Lollipop,\"", "Sovereign Wealth Funds", "fake his own death by crashing his private plane into a Florida swamp.", "was found in a hotel near Fort Bragg.", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "Apple Inc.", "38,", "terrorists operating within its borders.", "Henrik Stenson", "1995", "a red minivan ran a red light and struck two vehicles at an intersection,", "fear of losing their licenses to fly.", "Anjuna beach in Goa", "\"You can go from rags to riches there. People still believe in that. It is not something that has gotten lost,\"", "\"We've got more work to do to ensure that government treats all its citizens equally, to fight injustice and intolerance in all its forms and to bring about that more perfect union,\"", "Television demonstrations", "American Indian allies", "the Naturalization Act of 1790", "Sigurd the Dragonslayer", "blancmange", "apples", "Manhattan Project", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "Joplin", "Italy", "I.M. Pei", "Balaam continues to press God, and God finally permits him to go but with instructions to say only what he commands"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5616708417123176}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.09523809523809525, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.4, 0.0, 1.0, 0.2105263157894737, 0.5, 0.4166666666666667, 1.0, 0.2857142857142857, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 0.5, 0.043478260869565216, 0.6666666666666666, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-3593", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_naturalquestions-validation-230"], "SR": 0.453125, "CSR": 0.5293843283582089, "EFR": 1.0, "Overall": 0.7039237406716418}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "national Socialist government", "candelabrum", "Jaipur", "tea", "geopark", "Martin Pipe", "Wordsworth", "Ginger Rogers", "palace of culture of the Podshipnikov Zavod", "sodium tetraborate decahydrate", "siam", "peregrines", "the 7th", "muscle tissue", "Track & Field", "Derby Stakes", "Easter Parade", "Basketball", "HMS Amethyst", "lion", "sargento", "old WWII whistling tune, the Colonel Bogey March", "Cyprus", "King George VI", "ankle joint", "Greyfriars", "honeycomb", "flea", "a white robe", "Big Bopper", "NBA", "L. P. Hartley", "leander", "siegfried", "entropy", "Miss Scarlet", "green", "Amelia Earhart", "James Hogg", "lacrimal", "Loki Laufeyiarson", "Virgin Spring", "manfred von Richthofen", "God", "1879", "Los Angeles", "Loch Lomond", "isosceles", "black", "ballet", "the New York Yankees", "1967 onwards", "0 \u00b0 C", "Bolshoi Theatre", "My Boss, My Teacher", "mermaid", "death squad killings", "the Atlantic Ocean.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "the hiccup", "the bumblebee", "12 to 36 months old"], "metric_results": {"EM": 0.546875, "QA-F1": 0.65078125}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, true, true, true, true, false, false, true, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.75, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-4575", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-1541", "mrqa_triviaqa-validation-543", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6429", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_hotpotqa-validation-3584", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_searchqa-validation-7851", "mrqa_naturalquestions-validation-8352"], "SR": 0.546875, "CSR": 0.5296415441176471, "EFR": 1.0, "Overall": 0.7039751838235294}, {"timecode": 68, "before_eval_results": {"predictions": ["hotel barge  Bed and breakfast", "smen", "the city of Cairo, Illinois", "the Americans", "Australia", "2018", "along the coast of northern California", "zebra", "257,083", "the island of Puerto Rico", "King Harold Godwinson", "the new government", "Shawn", "if the concentration of a compound exceeds its solubility", "the Soviet Union", "1603", "the `` round '', the rear leg of the cow", "from 1957", "360", "electron shells", "the human body", "Lori McKenna", "Wisconsin", "Tbilisi", "centigrade", "1799", "Epistle of Paul to the Philippians", "His last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "Elvis Presley", "2009", "Best Picture, Best Director for Fincher, Best Actor for Pitt and Best Supporting Actress for Taraji P. Henson", "long - standing policy of neutrality", "291 episodes", "Cairo, Illinois", "Lana Del Rey", "Steve Russell", "12", "from 4 January 2011", "New Zealand to New Guinea", "Boston Celtics center Bill Russell", "Seattle, Washington", "the temporal lobes", "2010", "Buddhist", "first composed in the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units", "Diego Tinoco", "Henry Selick", "substitute good", "to provide school districts with federal funds", "1956", "april", "fearful man, all in coarse gray with a great iron on his leg", "huff & puff", "Brad Silberling", "1941", "Nickelodeon Studios", "July in the Philippines", "iCloud service will now be integrated into the iOS 5 operating system. It will work with apps and allow content to be stored", "Thursday", "bonobo", "side", "Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6270627474004491}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, true, false, false, false, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false, true, true], "QA-F1": [0.7499999999999999, 1.0, 0.888888888888889, 1.0, 0.14285714285714288, 1.0, 0.888888888888889, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.09999999999999999, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.4, 0.5714285714285715, 0.3076923076923077, 1.0, 1.0, 0.0, 0.4615384615384615, 0.5, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2347", "mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-10389", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_newsqa-validation-3405", "mrqa_newsqa-validation-2251", "mrqa_searchqa-validation-12035"], "SR": 0.453125, "CSR": 0.5285326086956521, "EFR": 0.9714285714285714, "Overall": 0.6980391110248447}, {"timecode": 69, "before_eval_results": {"predictions": ["Whitechapel", "Uganda", "definitely maybe", "Brazil", "Artemis", "three phases", "Bristol City Council", "Florida", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "Cambridge", "daltonism", "Cambodian", "Prussian Landsturm", "Russia", "1925 novel", "neers' Society, Ltd.", "three", "blue", "Marvin Hart", "Judi Dench", "Andre Agassi", "hache battle-ax", "The Times", "le Carr\u00e9", "germania", "Albania", "zoological", "mata hari", "a pyramid", "polo", "gulliver", "Rating Organization", "Saturday Night Live", "Bayern Munchen", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "Marcus Antonius", "silks", "One Canada Square in Canary Wharf,", "Snoopy", "corvidae", "\"The Hunting of the Snark\"", "Union of Post Office Workers", "Tokyo Metropolitan Assembly", "knaresborough", "Walter Mondale", "fresh nuclear fuel", "the plane crash", "Scotty Grainger Jr.", "The Kingkiller Chronicle", "3.9 mi", "$1.5 million.", "Buddhism", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "Space Shuttle orbiter", "Smithfield", "Aleksandr Solzhenitsyn", "10 Years"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5328125}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.8, 1.0, 1.0, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-3373", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-3541", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-9025"], "SR": 0.453125, "CSR": 0.5274553571428571, "EFR": 1.0, "Overall": 0.7035379464285715}, {"timecode": 70, "before_eval_results": {"predictions": ["richmond fetter", "five", "high jump competition", "ejaz Khan", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "vine", "teaching evolution in violation of a Tennessee state law.", "Philip Larkin", "shropshire", "Kent", "rabbit", "jack Brabham", "Peterborough United", "hanover", "square", "atare", "pancho", "prussian", "the Red sea", "cats", "The French Connection", "Eric Blair", "moaning Myrtle", "richmond", "Dubai", "ceeLo Green", "photographer", "Justin Bieber", "Greece", "m\u00e1qu\u00e8", "scar", "stars on 45 Medley", "Trimdon, County Durham", "Jim Bowie knife", "turkish", "meryl Streep", "Achille Lauro", "Botham", "stop motion effects", "Claremorris", "Ellis Island, in Upper New York Bay,", "Fiji", "tripezoid", "Zeljko Petrovic", "john Huston", "maggie best", "richard vii", "richard grant", "Moscow", "in 2005", "the governor of West Virginia, who is elected to a four - year term at the same time as presidential elections", "Spanish", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman", "2010", "Uzbekistan.", "Jerry Rice", "leotard", "Ford", "mienten"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5753494769119769}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false], "QA-F1": [0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.36363636363636365, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.38095238095238093, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-841", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-4502", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-3881", "mrqa_triviaqa-validation-993", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-5662", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-1672", "mrqa_triviaqa-validation-7032", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-3326", "mrqa_naturalquestions-validation-10001", "mrqa_naturalquestions-validation-4207", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232", "mrqa_searchqa-validation-2817"], "SR": 0.515625, "CSR": 0.5272887323943662, "EFR": 0.967741935483871, "Overall": 0.6970530085756474}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "The Dragon", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "Moon Shot: The Inside Story of America's Race to the Moon", "Kim Sung-su,", "Burma", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "L\u00edneas A\u00e9reas", "October 15, 2013", "Neha Sharma", "the Netherlands", "Quentin Coldwater", "1853", "Kew", "Alleyne v. United States", "River Shiel", "from 1993 to 1996", "Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "Dean Winters", "11", "tempo", "7 miles", "2016", "Pollywood", "Fred Derry", "July 25 to August 4", "1950s", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "special economic zone (SEZ)", "darkroom", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001,", "detention camp", "France", "Wordsworth", "spain", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "\"wipe out\" the United States if provoked.", "two years,", "Yahtzee", "Hinduism", "60 Minutes", "The closest approach to the original sound"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7747916666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-1669", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-4051", "mrqa_hotpotqa-validation-1398", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_triviaqa-validation-4907"], "SR": 0.71875, "CSR": 0.5299479166666667, "EFR": 1.0, "Overall": 0.7040364583333334}, {"timecode": 72, "before_eval_results": {"predictions": ["U + 2234 \u2234 therefore", "the defendant owed a duty to the deceased to take care", "100,000", "2004 American biblical drama film directed by Mel Gibson, written by Gibson and Benedict Fitzgerald, and starring Jim Caviezel as Jesus Christ, Maia Morgenstern as the Virgin Mary and Monica Bellucci as Mary Magdalene", "the host community", "15th century", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "her sister", "2014 Winter Olympics in Sochi, Russia", "the Pir Panjal Range in Jammu and Kashmir", "larger parallax than farther objects", "Kansas", "1885", "the final episode of the series", "Wisconsin", "the magnetic stripe `` anomalies '' on the ocean floor", "the stems and roots of certain vascular plants", "the Mahalangur Himal sub-range of the Himalayas", "Americans who served in the armed forces and as civilians during World War II", "an Islamic shrine located on the Temple Mount in the Old City of Jerusalem", "New York Mets", "Massachusetts", "Mark Jackson", "John Coffey", "antimeridian", "visible cross", "The reduced chemical compounds are oxidized by a series of respiratory integral membrane proteins with sequentially increasing reduction potentials with the final electron acceptor being oxygen", "Kida", "Selena Gomez", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "George David Weiss", "the federal government", "2013", "England", "Forsyth Street at the foot of the Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "The original chromosome and the copy", "79 official PGA Tour events", "the League of Communists of Yugoslavia party", "The majority of eukaryotic cells spend most of their time in interphase", "1853", "the nucleus with densely coiled chromatin fibres, surrounded anteriorly by an acrosome, which contains enzymes used for penetrating the female egg", "at the age of seven, survived the massacre of his clan perpetrated by his brother, Itachi, who spared Sasuke's life because he did not consider him worth killing", "Ben Savage", "Virginia", "Tom Hanks", "Jodha Akbar", "system of state ownership of the means of production", "Gunpei Yokoi", "the Alamodome and city of San Antonio", "de Havilland Moth", "architectural", "Bermuda", "win world titles in four weight classes", "their unusual behavior", "Neymar", "22", "opium", "Roger Federer", "parody", "a prostitute", "Julian Casablancas", "norwegian"], "metric_results": {"EM": 0.421875, "QA-F1": 0.49471228249625815}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false], "QA-F1": [0.22222222222222224, 1.0, 0.07999999999999999, 0.05882352941176471, 0.0, 0.5, 0.3076923076923077, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.896551724137931, 0.0, 0.33333333333333337, 0.2857142857142857, 0.16666666666666669, 0.0, 0.0, 0.07407407407407407, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.2857142857142857, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-7892", "mrqa_naturalquestions-validation-3243", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-2124", "mrqa_naturalquestions-validation-9230", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-6641", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-1909", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-1421", "mrqa_triviaqa-validation-5754", "mrqa_triviaqa-validation-48", "mrqa_searchqa-validation-3407", "mrqa_searchqa-validation-1943", "mrqa_triviaqa-validation-4962"], "SR": 0.421875, "CSR": 0.5284674657534247, "EFR": 1.0, "Overall": 0.703740368150685}, {"timecode": 73, "before_eval_results": {"predictions": ["the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Kirsten Nielsen", "December 14, 2017", "Barbara Windsor", "ninth w\u0101", "British Ultra code", "Bart Millard", "Jesse Wesley Williams", "Spencer Treat Clark", "1910", "FIGG Bridge Engineers", "Lenin", "Joanne Wheatley", "Everywhere", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "india", "Taylor Michel Momsen", "Magnavox Odyssey", "The Lightning thief", "2015", "1971", "Sara Gilbert", "1962", "Help!", "John Smith", "Katharine Hepburn", "Arnold Schoenberg", "the Election Commission of India", "203", "he would return Sam's soul, but if they don't help him he will send Sam back to Hell", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Marty Stuart", "Charlton Heston", "1877", "to `` help bring creative projects to life ''", "Joan Baez", "Joseph Nye Welch", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Hummer", "wooden clog", "KevRoland Rat and Friends", "Tampa", "1980", "January 28, 2016", "Jaipur", "five", "July", "taro", "You Bet Your Life", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6910153935976304}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, false, true, true, false, false, true, true, true, true], "QA-F1": [0.9696969696969697, 0.21052631578947367, 0.5, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.24, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-4500", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-10049", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-249", "mrqa_hotpotqa-validation-2215", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-270"], "SR": 0.609375, "CSR": 0.5295608108108107, "EFR": 0.96, "Overall": 0.6959590371621621}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland Raiders", "Russell Stover", "hub", "restaurant", "the Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "Manic Street Preachers", "chinea", "A blitz", "New Wave", "a commune", "a ring", "the Thames", "The Record Company", "ice hockey", "Hans Christian Andersen", "David", "The Color Purple", "whales", "Jane Addams", "Judi Dench", "Tanzania", "Biosphere 2", "an inch", "death", "Longfellow", "Fred Thompson", "Geneva", "humility", "white", "The Mamas", "Diatomaceous earth", "the debt ceiling", "Homer", "Sesli Szlk", "Existentialism", "ashes", "Julius Caesar", "kevin", "Isaac Newton", "Charles I", "Kevin Costner", "The Aviator", "clef", "uranium", "Louisiana", "The Hot Chick", "composting", "2016", "August 2, 1990", "four", "Spey", "papeye", "Denmark", "Trappist beer", "4,530", "Steve Prohm", "seven", "Airbus A330-200", "Symbionese Liberation Army", "Manitowoc County, Wisconsin"], "metric_results": {"EM": 0.65625, "QA-F1": 0.71875}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-10631", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-15658", "mrqa_searchqa-validation-16348", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-7832", "mrqa_triviaqa-validation-7472", "mrqa_hotpotqa-validation-1307"], "SR": 0.65625, "CSR": 0.53125, "EFR": 1.0, "Overall": 0.704296875}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "John Nightingale", "the main highway entrance at California State Route 1,", "a marketing term for a vehicle that is both four - wheel - drive and primarily a road car", "Turing", "John B. Watson", "118", "Spain", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "the 9th century", "Asuka", "Jason Momoa", "Emily Perkins", "the President", "Spanish missionaries", "Gustav Bauer", "the art of the Persian Safavid dynasty from 1501 to 1722", "a vertebrate's immune system", "around 2.45 billion years ago", "Golde", "March 31, 2017", "incudomalleolar joint", "Gina Tognoni / to\u028an\u02c8jo\u028ani / ( born November 28, 1973 )", "the Gupta Empire", "a half - life of 10.756 years and a maximum decay energy of 687 keV", "a graded basis, consisting of pass grades 1 ( threshold 85 %, a distinction ), 2 ( 70 -- 84 % ), 3 ( 55 -- 69 % )", "during the summer of 1979", "Charles Evans Hughes", "Spanish / Basque", "U.S. service members who have died without their remains being identified", "December 1349", "Glenn Close", "Robert Remak", "the Yankees", "while studying All My Sons by Arthur Miller, a play about a man whose choice to send out faulty airplane parts for the good of his business and family caused the death of twenty one pilots during World War II", "U.S. National Institute of Standards and Technology ( NIST )", "Rigg", "a series of complexes that transfer electrons from electron donors to electron acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions, and couples this electron transfer with the transfer of protons ( H ions ) across a membrane", "Bill Patriots", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "a f\u00e8in", "Haystacks", "1967", "Yubin, Yeeun", "100 metres", "sedative", "a sailboat matching the description of the missing 38-foot boat was found overturned about 5:15 p.m. Saturday, authorities said.", "\"peregruzka,\" which means 'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's Disease", "Patrick Henry", "Samuel Joel \" Zero\" Mostel"], "metric_results": {"EM": 0.59375, "QA-F1": 0.710966455469873}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.33333333333333337, 0.4444444444444445, 1.0, 0.0, 0.2222222222222222, 0.4, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9859154929577464, 0.15384615384615385, 1.0, 0.1111111111111111, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.11764705882352941, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-8004", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-7514", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-3076", "mrqa_triviaqa-validation-2810", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_hotpotqa-validation-3909"], "SR": 0.59375, "CSR": 0.5320723684210527, "EFR": 0.9230769230769231, "Overall": 0.6890767332995951}, {"timecode": 76, "before_eval_results": {"predictions": ["Tintoretto", "drambuie", "repechage", "Harris with Harris", "Victoria Rowell", "Cami de Repos", "Northumberland", "birds for meat and eggs", "Steerpike", "SS Normandie", "Chesney Wold", "four", "the Indus valley", "Selfie", "Jaws", "Charlie Cairoli", "The Hague", "Adidas", "Coldplay", "Passepartout", "Switzerland", "basketball", "Elizabeth II", "sistine Chapel", "Patrick Kielty", "8 minutes", "jimmy Tribbiani", "magen David", "Schumann", "Margaret Thatcher", "Hooky Street", "Darius Danesh", "Andrew Lloyd Webber", "Bonn", "vice-admiral", "snake", "Coral Sea", "Constantine III", "Madonna", "a hole-in-one", "Millerlite beer", "leg", "Ice Age", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Emilia", "Hawley Harvey Crippen", "fifty-six", "1822", "1979", "1976", "Gupta Empire", "Rogue One", "2004", "Rwandan genocide", "Steve Williams", "winter storm", "fight outside of an Atlanta strip club", "seasonal affective disorder", "a timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6723672161172162}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-7046", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2600", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-1241", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-212", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-1278", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3332", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.59375, "CSR": 0.5328733766233766, "EFR": 1.0, "Overall": 0.7046215503246753}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1801", "Captain Cook's Landing Place", "M2M", "Lady Victoria Hervey", "@X Television Festival", "president of Guggenheim Partners", "Diamond Rio", "Johnnie Ray", "master builder", "UFC 50: The War of '04", "Anthony John Herrera", "Rounders", "24 hours a day and 7 days a week", "\"La Nouba\", \"Myst\u00e8re\", \"Alegr\u00eda\", and \"Quidam\"", "Nobel Prize in Physics", "glee", "Chris Corbould and Neil corbould", "intelligent design", "2 November 1902", "December", "orisha", "2006", "highest commissioned SS rank", "Dziga Vertov", "The Bonnie Banks o' Loch Lomond", "National Football Conference", "brothers", "James Franco", "London", "Kelly Bundy", "British", "Ny-\u00c5lesund", "his father into the Military Band of Hanover, before migrating to Great Britain in 1757 at the age of nineteen", "around 8000 BC", "2002", "Audrey Hepburn", "The \"unofficial national anthem\" of Australia", "Leonarda Cianciulli", "pale lager", "Biola University", "playwright", "psychoanalysis", "Formula One motor race held at the N\u00fcrburgring on 5 August 1962", "Park Yong-gyu", "Mot\u00f6rhead", "Nassau County", "bass", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "Edd Kimber", "Mel Gibson", "1987", "San Francisco", "johnson johnson", "Vancouver", "college campus.", "$106,482,500", "15-year-old's", "Cleopatra", "arm & Hammer", "JANE KOKAN", "tambourine"], "metric_results": {"EM": 0.515625, "QA-F1": 0.622162472943723}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, false, false, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.4, 0.7499999999999999, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3333333333333333, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3636363636363636, 1.0, 0.0, 0.0, 0.20000000000000004, 1.0, 1.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2100", "mrqa_hotpotqa-validation-5222", "mrqa_hotpotqa-validation-4484", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5469", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-2730", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-6460", "mrqa_newsqa-validation-2168", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.515625, "CSR": 0.5326522435897436, "EFR": 1.0, "Overall": 0.7045773237179487}, {"timecode": 78, "before_eval_results": {"predictions": ["the sidewalk between Division Street and East Broadway", "1941", "Nigel Lythgoe", "depolarization of the cardiac muscle begins at the sinus node", "1956", "Atlanta, Georgia", "The management team", "1935", "1990", "Ali", "1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "in the fascia surrounding skeletal muscle", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "1947", "April 10, 2018", "internal reproductive anatomy", "May 2017", "September 19, 1977", "DNA replication begins at specific locations, or origins of replication, in the genome", "1956", "between 8.7 % and 9.1 %", "Great G minor symphony ''", "Divyanka Tripathi", "Newfoundland", "Ole Einar Bj\u00f8rndalen", "31 December 1960", "following graduation with a Bachelor of Medicine, Bachelor of surgery degree and start the UK Foundation Programme", "pre-Christian festivals that were celebrated around the winter solstice", "1992", "George Strait", "All Hallows'Day", "November 1961", "midpiece", "2004", "$19.8 trillion", "7000301604928199000", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "Hellenic Polytheism", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Sachin Tendulkar", "member states", "Andrew Lloyd Webber", "domestic cat", "Q", "Adam Werritty", "sheepskin", "5,922", "1866", "two", "2006", "nine", "Lake Superior", "the River Thames", "Andrea Chnier", "red"], "metric_results": {"EM": 0.625, "QA-F1": 0.7045036764705883}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5882352941176471, 1.0, 0.0, 0.6666666666666666, 0.5714285714285715, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-10495", "mrqa_newsqa-validation-3297", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-10079", "mrqa_searchqa-validation-1302"], "SR": 0.625, "CSR": 0.5338212025316456, "EFR": 0.9583333333333334, "Overall": 0.6964777821729957}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "2004 Nokia Sugar Bowl", "1858", "indie and metal", "Edison Koon-hei Chen", "1875", "The The satirical News Network", "his most brilliant student", "Juilliard School", "1st World Outgames", "1812", "Peach", "1885", "Oregon Ducks", "Victorian England", "The War of '04", "Tennessee", "\"Spider-Man\" Trilogy", "Alpine climate and landscapes", "Baudot code", "Rockhill Furnace, Pennsylvania", "Carl Perkins", "Florida", "42,972", "Estadio Victoria", "Boston Celtics", "Aqua", "Sydney", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "\"Southland\" (2009\u20132013)", "between 1252 and 1259", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis James Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1926", "England", "Canadian", "James Mitchum", "Nick on Sunset", "Javed Miandad", "Switzerland", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "the Roman Empire", "Max", "peter", "Melbourne", "paddington bear", "8,", "millions of Americans", "\"This is not something that anybody can reasonably anticipate,\"", "Richmond", "Venezuela", "the Stone Age", "rally"], "metric_results": {"EM": 0.625, "QA-F1": 0.6796378968253969}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false], "QA-F1": [0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-808", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-5073", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-4981", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4399", "mrqa_hotpotqa-validation-3440", "mrqa_hotpotqa-validation-5216", "mrqa_naturalquestions-validation-2794", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-4059"], "SR": 0.625, "CSR": 0.5349609375, "EFR": 1.0, "Overall": 0.7050390625}, {"timecode": 80, "before_eval_results": {"predictions": ["a tribune", "Beaujolais Blanc", "Calvin Coolidge", "beach volleyball", "a 1982 hit rock song written and performed by American singer-songwriter John Mellencamp, then performing as \"John Cougar.\"", "hot springs", "the Philosopher's Stone", "PlayStation", "pro bono", "American politician and businessman", "an epitaphic inscription", "glenda", "a dragon", "a rat", "Jussieu 75252 Paris cedex 05, France", "Merry Wives of Windsor", "kowtow", "Mars", "Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "alchemy", "Lon Chaney", "pane & pasta", "a katzenjammer", "Cuisinart", "a travertine", "Bob Dole", "Ross Ice Shelf", "director", "China", "a grizzly bear", "Pinocchio", "Czech Republic", "an opera house", "a bison", "visit Greece", "Jodie Foster", "Cleopatra VII", "the Mummy: Tomb of the Dragon Emperor", "Buck", "the beetle", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "June 25, 1938", "53", "Lightning thief", "Brazil", "Edinburgh", "karst massifs", "Naomi", "University of California", "Saturday Night Live", "Mohammed Mohsen Zayed,", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy,", "Joanne Wheatley"], "metric_results": {"EM": 0.5625, "QA-F1": 0.617376893939394}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-6570", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9625", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-12524", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-3111", "mrqa_searchqa-validation-11708", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_newsqa-validation-813"], "SR": 0.5625, "CSR": 0.5353009259259259, "EFR": 1.0, "Overall": 0.7051070601851852}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "the Tasmanian government", "Indonesia", "The Generation Game", "The Firm", "redhead", "fourteen", "Spain", "Georgia", "Olivia Smith", "sows", "bread and wine", "Turkey", "Anastasia Dobromyslova", "every ten years", "Matterhorn", "Lake Placid", "$1", "Liverpool", "the Count Basie Orchestra", "Manhattan", "an arch", "the Esmeralda's Barn night", "Al Buheirah Corniche", "Hyderabad", "Mallard", "Laurent Planchon", "Apollo", "1963", "Bologna", "a bear", "Coleraine", "Rebbie Jackson", "Timothy", "Addis Ababa", "motorcycle", "kidney", "endurance", "chilis", "Mark Twain", "Doctor Who", "Yosemite National Park", "Microsoft", "40", "the First World War", "passion fruit", "HMS Thetis", "a logic", "Southampton", "100 years", "Pope Benedict XVI", "Ed Roland", "Orlando", "an LCoS chip from Himax ), field - sequential color system, LED illuminated display", "41st", "Mel Blanc", "Mauthausen\u2013Gusen", "three masked men who stole four Impressionist paintings worth about $163 million (180 million Swiss francs) Sunday in a heist police characterized as \"spectacular.\"", "an antihistamine and an epinephrine auto-injector", "\"A Lion Among Men.\"", "Danny Elfman", "Bolivia", "a leap year", "Morgan"], "metric_results": {"EM": 0.625, "QA-F1": 0.6522781277630416}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.7586206896551725, 1.0, 1.0, 0.5, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-4361", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-6437", "mrqa_triviaqa-validation-5153", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-992", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-14665"], "SR": 0.625, "CSR": 0.5363948170731707, "EFR": 0.875, "Overall": 0.6803258384146341}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "GZA", "Illinois", "1,691", "Melville, NY", "Western Europe", "girls", "March 14, 2000", "Regional Rural Bank", "Tufts University,", "law", "birthplace of Sir Christopher Wren", "Isla de Xativa\" and also known as Isla Grande de Tierra del Fuego", "her gaoler's family", "Blue Origin", "Bruce R. Cook", "1953", "Javed Miandad", "February 12, 2014", "Akosua Busia", "5.3 million", "six", "a polypeptide chain", "Brady Haran", "Minette Walters", "Syracuse University", "three-part", "Florida Panthers", "2010", "Adelaide", "Juan Manuel Mata Garc\u00eda", "Malayalam", "Pittsburgh Steelers", "pronghorn", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "his role as a pedestrian in \"I'm Gonna Git You Sucka\" in 1988", "Kentucky Music Hall of Fame", "Taoiseach", "50th anniversary of the founding of the National Basketball Association (NBA)", "American", "Corps of Discovery, with William Clark", "pubs, bars and restaurants", "Andrew Johnson", "Minnesota", "power directly or elect representatives from among themselves to form a governing body, such as a parliament", "illnesses", "T. J. Lavin", "drawn on the bank's own funds and signed by a cashier", "31 March 1909", "President Lyndon Johnson", "Celsius", "whooping cough", "Johannesburg", "from TV news coverage,", "Juri Kibuishi, 23, of Irvine,", "the sins of the members of the church,", "Superman", "Richard Nixon", "90", "Edward VIII"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6150145580522418}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.33333333333333337, 0.5, 1.0, 1.0, 0.0, 0.0, 0.375, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5882352941176471, 1.0, 0.5, 0.35294117647058826, 0.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615385, 0.09090909090909091, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-4045", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-1187", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-845", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-4368", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2045", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-4519", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.515625, "CSR": 0.536144578313253, "EFR": 0.967741935483871, "Overall": 0.6988241777594248}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys: Confessions of a Bad Girl", "Roger Maris", "the Titanic disaster", "Physics", "the impeachment trial of President William Jef-", "Graceland", "Cambodia", "a elevator", "Edward Murdstone", "Schwarzenegger", "\"Jabberwocky\"", "Tittifill", "a goat", "\"A Beautiful Mind\"", "the unions", "Dracula", "the Horn of Africa", "a bagpipes", "Mrs. Miniver", "The Office", "Moravia", "a keynote", "sheep", "Casey Jones", "the \"Coward of the County\"", "Hope", "the navy", "Dresden", "flippant", "Arkansas", "Duchamp", "a sloop", "a toilet paper", "Sesame seeds", "New Zealand", "a \"to play dead like a\"", "the Monty Hall problem", "bees", "Janet Reno", "a connecticut yankee in king arthur's court", "Michelangelo", "AgustaWestland", "Appomattox", "Thailand", "Lazarus", "a cereal", "\"to be a California beachbum\"", "the Steptoe", "Whitehorse", "Scott McClellan", "Most home bakers took part in a bake - off to test every aspect of their baking skills", "six", "Taylor Hayes", "Twin sisters", "John Denver", "Gargantua", "2017", "four", "Lester", "India", "1959", "two remaining crew members", "her abusive husband"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6189732142857143}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, false, false, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.7142857142857143, 0.5, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7445", "mrqa_searchqa-validation-6754", "mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-3958", "mrqa_searchqa-validation-7313", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-7382", "mrqa_searchqa-validation-5144", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-10493", "mrqa_newsqa-validation-1331"], "SR": 0.578125, "CSR": 0.5366443452380952, "EFR": 0.9259259259259259, "Overall": 0.6905609292328043}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony", "a roof", "Cuisinart", "lungs", "the Boston Massacre", "ghost", "Simon Bolivar", "Little Red Riding Hood", "Abigail Adams", "Bank of America", "Cleopatra", "Colorado Springs", "diamond", "Pablo Picasso", "Arlington House", "John Paul II", "the hood", "Herakles", "South Dakota", "natural selection", "Secretary of the Interior", "Cyrus the Younger", "the White King", "Bo Schembechler", "Gucci", "Vermont", "a chimp", "a computer desktop extender", "The Man in the Iron Mask", "New Zealand", "Heidi Klum", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Dr. Moreau", "organs", "wheat", "tundra", "Peter Falk", "AARP", "Tiffany", "the Flag", "the herb", "the stiletto", "cheese", "the University of Kentucky", "Bora Bora", "Titanic", "the French Revolution", "the \"Fisherman's ring\"", "RBIs", "the forex market", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways", "Venetian", "the largest sphere", "Disney California Adventure", "Acharacle", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe", "Baku"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7410428113553114}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 0.9743589743589743, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-728", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-6001", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-1137", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_searchqa-validation-3800", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-2374", "mrqa_newsqa-validation-1793", "mrqa_triviaqa-validation-5654"], "SR": 0.640625, "CSR": 0.5378676470588235, "EFR": 1.0, "Overall": 0.7056204044117648}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "an Old Lady", "Opechancanough", "Samuel Langhorne Clemens", "Margaret Mitchell", "Fuller", "a hangover", "endodontist", "a desktop microcomputer", "South Dakota", "Hercules Poirot", "Frasier", "McClellan", "Soundgarden", "Maximilian", "Superman", "Flavor Flav", "I.M. Pei", "the Rose", "a Continental Congress", "Norway", "Meriwether Lewis", "\"Where there is hatred, let me sow love... where there is despair, hope\"", "Steve McQueen", "Firebird", "\"Sweet Home\"", "the Vietnam War", "Garfield", "Mike Huckabee", "a Bill of Rights", "Peter Sellers", "St. Mark", "Jon Stewart", "Howard Dean", "Pogo", "a manager", "Manitoba", "Madonna", "a turban", "Perseid", "Holstein", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Churchill", "Torvill and Dean", "Jagged Little Pill", "cogito", "the Kingdom of Serbia", "prophets and beloved religious leaders", "it was released as the B - side of the `` Tramp '' single in 1987, and as its own single in 1988", "Toy Story", "Harriet Tubman", "Bake Off", "HC Davos", "Native American", "The Soloist", "Mildred,", "Vicente Carrillo Leyva,", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6773701832706767}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.5714285714285715, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 0.7499999999999999, 0.10526315789473684, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-295", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-4518", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-3006", "mrqa_searchqa-validation-7163", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-2188", "mrqa_searchqa-validation-14158", "mrqa_searchqa-validation-16360", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-1491", "mrqa_triviaqa-validation-1386", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.5625, "CSR": 0.5381540697674418, "EFR": 1.0, "Overall": 0.7056776889534884}, {"timecode": 86, "before_eval_results": {"predictions": ["a cob", "Barbara Walters", "the Aegean Sea, the Dardanelles-Sea of Marmora-Bosporus", "hoover", "\"Stopping by Woods on a Snowy Evening,\"", "bach", "coffee", "the Frogs", "Knott\\'s Berry Farm", "Narnia", "poland", "Frida Kahlo", "24", "Baroque", "Cepheus", "de Gaulle", "electrolysis", "Bernini", "Ovid", "Pablo Escobar", "Abraham Lincoln", "Anne Boleyn", "modify", "a protective transparent membrane", "Bank of America", "copper", "a blackjack", "Kiss Me, Kate", "Errol Flynn", "plutonium", "Bi", "iron", "Amistad", "Will Smith", "The Simpsons", "the Ladies Professional Golf Association", "Universal Studios Hollywood", "the Russo-Japanese War", "Camembert", "an Achilles' heel", "red", "Sweden", "a member of the musical Partridge family", "Jammu & Kashmir", "a pyramid unfinished", "The Empire Strikes Back", "Nelson's Column", "Billy Bob Thornton", "Clark", "lima beans", "Will & Grace", "Robber Barons", "De Wayne Warren", "2017", "Venezuela", "The Coalminer's Daughter", "golf", "Dialogues des Carm\u00e9lites", "England,", "35,124", "between the ages of 14 to 17.", "The syndicate, founded by software magnate", "in the affidavit, mostly replying in the affirmative when House prosecutor David Ellis asked whether the portions of the affidavit were accurate.", "Missouri River"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6639632936507935}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, false, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.888888888888889, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.16666666666666666, 0.5714285714285715, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1629", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-5981", "mrqa_searchqa-validation-11379", "mrqa_searchqa-validation-813", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-12860", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-9585", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_searchqa-validation-5382", "mrqa_naturalquestions-validation-9523", "mrqa_triviaqa-validation-7114", "mrqa_hotpotqa-validation-1763", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-2461", "mrqa_newsqa-validation-563"], "SR": 0.59375, "CSR": 0.5387931034482758, "EFR": 1.0, "Overall": 0.7058054956896551}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Burt Bacharach", "the zona glomerulosa (from and into the tubular fluids, respectively) of the kidney", "19th and early 20th centuries", "\"Tom Jones\"", "\"No. 3\"", "\"The Dick Van Dyke Show\", \"One Day at a Time\"", "Violet", "82", "\"Grimjack\" (from First Comics)", "Easy", "on First Street in downtown Dayton, Ohio,", "Gareth Barry", "Robert John Day", "Bambi, a Life in the Woods", "in 1896", "Apple iPod 4G", "2017", "The Timekeeper", "July 8, 2014", "Ben Ainslie", "torpedo boats", "Xherdan Shaqiri", "Miami Gardens, Florida", "the Miami Marlins", "the Netherlands", "Dallas", "Tia Carrere", "four", "Jim Davis", "Kurt Vonnegut", "Labrador Retriever", "Gurgaon", "1837", "Blackpool F.C.", "Diondre Cole", "DS Virgin Racing Formula E Team", "explores the lives of those that either own exotic animals or have been captured for illegally smuggling them,", "1943", "Las Vegas", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "in 1885", "2015", "Northrop P-15 Reporter", "Gareth Barry", "Gambaga", "March 2012", "English", "Kairi", "1978", "ase", "Gooducken", "3000 BC", "Robert Devereux", "Gary Oldman", "Alanis Morissette", "the Employee Free Choice act", "\"peregruzka\"", "Port-au-Prince", "Wimbledon", "Brazil", "John C. Calhoun", "Major League Baseball"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5726742875180375}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, true, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.33333333333333337, 0.9090909090909091, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4444444444444445, 1.0, 0.4, 0.2, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2294", "mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-4882", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-4214", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-1902", "mrqa_hotpotqa-validation-1456", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_naturalquestions-validation-5058", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_searchqa-validation-14393", "mrqa_searchqa-validation-4094", "mrqa_triviaqa-validation-1259"], "SR": 0.484375, "CSR": 0.5381747159090908, "EFR": 1.0, "Overall": 0.7056818181818182}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "the first to utilize Audio-Animatronics", "Continental Army", "1874", "Park Yong-gyu", "January 16, 2013", "James Taylor", "a multi-control USB mouse", "\"Veyyil\" (2006)", "Victoria, Duchess of Kent", "Umina Beach", "from 1989 until 1994", "Adelaide Laetitia \" Addie\" Miethke", "Chevalier Field", "Consigliere", "Orson Welles", "33-member", "The Bologna Process", "American", "Iran", "Lorne Michaels", "Philip K. Dick", "Texas Longhorns football team", "O", "\"An All-Colored Vaudeville Show\"", "\"Jour polaire\"", "German Shepherd", "Aiden English", "Iftikhar Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "rhythm and blues dance", "1,462", "Premier League", "Andrew G. Kaufman", "Eddie Albert", "Chicago", "Ford Island", "The Times Higher Education Guide", "Derry City F.C.", "Beverly Hills", "Boston, Massachusetts", "two", "Black Mountain College", "47,818", "1970", "The International Imitation Hemingway Competition", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State", "Akshay Kumar", "2015", "diastema", "Thames Street", "Tom Stoppard", "brazil", "Dube attempted to escape but died almost instantly from his wounds.", "an average of 25 percent", "super-yacht designers Wally", "a charcuterie", "Livin' On A Prayer", "the electoral college", "Rudyard Kipling"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6956845238095237}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.16666666666666669, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5055", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-812", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-3050", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-3335", "mrqa_hotpotqa-validation-2226", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_searchqa-validation-6483"], "SR": 0.59375, "CSR": 0.5387991573033708, "EFR": 1.0, "Overall": 0.7058067064606741}, {"timecode": 89, "before_eval_results": {"predictions": ["Richard Masur", "various bigfoot-like sightings, giant snakes and \"thunderbirds.\"", "World War II", "Mike Pence", "Mickey Gilley's", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "The Itchy & Scratchy Show", "First Street", "5249", "the Dutch Empire", "\"Lebedinoye ozero\"", "Bad Boy Records", "October 20, 2017", "Antilocapra americana", "Lord's Resistance Movement", "1965", "1943", "the Big 12 Conference in the National Collegiate Athletic Association (NCAA)", "1959", "14 August 1867", "Neighbourhood", "Warsaw", "Ezeiza International Airport", "Sesame Street", "Billund", "the University of Kentucky", "The Sun on Sunday", "The Good, the Bad, the Weird", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "The Boeing B-17 Flying Fortress", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Berthold Heinrich K\u00e4mpfert", "Lismore", "EQT Plaza in Pittsburgh, Pennsylvania", "Panthera pardus", "Newark, New Jersey", "ten", "Conservatorio Verdi", "north", "Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "Raymond Benson", "World War II", "George Santayana", "putting your child's safety and livelihood into other hands,\"", "an annual road trip,", "102", "a salad bottle", "he experimented with marijuana but didn't inhale", "saliva", "Venus Williams"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7202369678932179}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-1222", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-4896", "mrqa_hotpotqa-validation-4166", "mrqa_newsqa-validation-3736", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464", "mrqa_searchqa-validation-3153"], "SR": 0.65625, "CSR": 0.5401041666666666, "EFR": 1.0, "Overall": 0.7060677083333333}, {"timecode": 90, "before_eval_results": {"predictions": ["exoskeletons", "Joaquin Phoenix", "Russet Potatoes", "the integument", "Harley-Davidson", "New Coke", "Abigail Adams", "unions", "University of Hawaii at Manoa", "the leg", "Cristina Yang", "The Omega Man", "Vincent van Gogh", "Sumbawa", "Winnipeg", "Best I Really", "Paddington Bear", "Braigo Labs", "a skyscraper", "1950", "Best Match", "Cheetah Rivera", "Czech Resistance", "six", "Nike", "bck", "Sweden", "Lamborghini", "notary", "John Philip Sousa", "oros ganos", "New South Wales", "the temperance work", "Ho Chi Minh", "Martha\\'s Vineyard", "Best Hit, Actually 25", "a cobbler or apple crisp", "Autobots & the Decepticons", "Rhapsody in Paris", "Taiwan", "The Parent Trap", "Go Airlines", "Gustave Eiffel", "\"Gentleman Jim\" Corbett", "Michael Jackson", "Firebird", "Sicily", "Bill Frist", "a cupronickel coin", "apocrypha anlam", "Agatha Christie", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "poland", "Celebrity Big Brother", "Shabana Azmi", "1990", "Big Machine Records", "a monthly allowance,", "Aung San Suu Kyi", "75.", "faster in other nations than in the United States"], "metric_results": {"EM": 0.453125, "QA-F1": 0.4916666666666667}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, false, true, true, false, false, false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-10892", "mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-9950", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-10254", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-16072", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-11867", "mrqa_searchqa-validation-16647", "mrqa_searchqa-validation-2561", "mrqa_searchqa-validation-2091", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-11552", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-14495", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-8040", "mrqa_searchqa-validation-12430", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_hotpotqa-validation-2216", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1993"], "SR": 0.453125, "CSR": 0.5391483516483517, "EFR": 1.0, "Overall": 0.7058765453296704}, {"timecode": 91, "before_eval_results": {"predictions": ["the Channel Tunnel", "Hawaii", "Edwin Binney & Smith", "giant", "grease", "banana & Chocolate Top Banana Bar", "Lake Ontario", "the word of the language", "The Great American Novel", "The Sound and the Fury", "the Suez Canal", "Stephen Hawking", "Ecuador", "Chicago", "the Federal Communications Commission", "acetylene", "a scrapple", "Tennessee", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "Dr. Quinn", "slanting", "Cracker Jack", "Ford", "the High Jump", "the phoenix", "Florence", "Alice", "Sid Vicious", "sand", "Monaco", "orange", "Venison", "South Africa", "a packer", "the Gifted", "the Andes", "Ovid", "1937", "Grendel", "LaVIAR", "basidiomycetes", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "eyes", "the sound barrier", "Cyprus", "the members of the actual club", "Nala", "Etienne de Mestre", "the PDSA Dickin Medal", "2.1", "kenjutsu", "Rawlings", "Adam Levine", "Syracuse University", "Stuttgart", "the rabbit-ear antennas on his old-fashioned television", "for prison systems to monitor and detect cell signals.", "Botel"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6646577380952381}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, true], "QA-F1": [0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285714, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-15688", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-7773", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-7631", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-2466", "mrqa_triviaqa-validation-6520", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-6932", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.609375, "CSR": 0.5399116847826086, "EFR": 1.0, "Overall": 0.7060292119565217}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie Meeber", "Kwara", "yenta", "orthodontics", "a referendum", "alfalfa", "Phaedra", "Franklin D. Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "Daniel", "Australia", "Mozart", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "the velocity", "The Secret", "a acre", "ancora", "Benjamin Harrison", "William Conrad", "Jericho", "the burning bush", "a pteropod", "Indian tribes", "Australia", "ER", "Le djeuner sur l'herbe", "(The Help, Juno) provided the voice for Peach", "Frdric Chopin", "a zipper", "ABC", "Amman", "Van Halen", "The House Permanent Select Committee on Intelligence", "amyotrophic lateral sclerosis", "a grape", "Nancy Lopez", "Der Zauberberg", "Hudson Bay", "Beguile", "Hoosier", "the house of prayer", "bread", "a mead", "the Mossad", "a mnagerie", "an aide-de-camp", "Judith Aline Keppel", "two - stroke engines and chain drive", "a Native American nation from the Great Plains", "plutocracy", "de Goya", "It does ily mean? I love you", "Panther", "paracyclist", "the XXIV Summer Universiade", "Asashoryu,", "(3,281 feet) high.", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6075148809523809}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, false, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-5282", "mrqa_searchqa-validation-16477", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-9061", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-12520", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-9804", "mrqa_searchqa-validation-1688", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-8538", "mrqa_searchqa-validation-10396", "mrqa_searchqa-validation-9193", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_triviaqa-validation-6160", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.53125, "CSR": 0.5398185483870968, "EFR": 1.0, "Overall": 0.7060105846774194}, {"timecode": 93, "before_eval_results": {"predictions": ["the Department of Labor", "Standard Oil", "the glaciers", "English", "archbishop", "Clark", "India", "The Carpenters", "Wyoming", "Mary", "the Crimean War", "the elbow", "a thermostat", "a bad decision", "a sapphire", "florida", "trailers", "grace", "a wagons", "the Davis Cup", "Blackbeard", "William III", "Emily Dickinson", "the paranza", "Simon Wiesenthal", "Mercury and Venus", "Conrad Hilton", "SeaWorld", "a quadrille", "We Own the Night", "spontaneous", "Dickens", "Halloween", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "a Tacos", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a fruit-eating bat", "Munich", "Lance Armstrong", "Jimmy Carter", "the queen of romance novels", "Sir Walter Scott", "War of the Worlds", "January 17, 1899", "in which there is a decline in population density", "about 13,000 astronomical units ( 0.21 ly )", "Betty", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO's Membership Action Plan,", "a lump in Henry's nether regions was a cancerous tumor.", "Sunday.", "Charles Quinton Murphy"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7136239035087719}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473685, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-10246", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-9606", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-12927", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-5690", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_searchqa-validation-12016", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-8832", "mrqa_triviaqa-validation-6109", "mrqa_newsqa-validation-852", "mrqa_newsqa-validation-4022", "mrqa_hotpotqa-validation-751"], "SR": 0.65625, "CSR": 0.5410571808510638, "EFR": 1.0, "Overall": 0.7062583111702128}, {"timecode": 94, "before_eval_results": {"predictions": ["assassination", "fever", "fossilis", "Janet Reno", "Harvard University", "Don Quixote", "The Turn of the Screw", "David Lynch", "Thomas G Nazareth", "pine", "Wild Bill Hickok", "4D", "hydrogen", "rum", "lava", "anthrax", "Jamaica", "Sacher Torte", "Hillary Clinton", "a coyote", "CVS (pharmacy)", "Sulfur", "the Confessions of Nat Turner", "Marquette", "overbite", "The Silence of the Lambs", "a bug", "Thomas Jefferson", "a millimeter", "Megan Fox", "Eurydice", "an event", "the Battle of the Little Bighorn", "Marie Curie", "The Russian Blue", "Dustin Hoffman", "Nebraska", "E-T", "vodka", "John", "LOUIS XIV", "painted Caves", "Yellow pages", "jaguar", "Scout Finch", "Liechtenstein", "the joker", "Pulp Fiction", "Mao Zedong", "Nereid", "Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Charles & Eddie", "Sir Giles Gilbert Scott", "Andrew Jackson", "Athlete", "HackThis Site", "\"Traumnovelle\"", "1985", "Manuel Mejia Munera", "7", "Six", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States."], "metric_results": {"EM": 0.515625, "QA-F1": 0.5962797619047618}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, true, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.42857142857142855, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-13563", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-16681", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-4784", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-9652", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-11462", "mrqa_naturalquestions-validation-4399", "mrqa_triviaqa-validation-4115", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-5124", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3607"], "SR": 0.515625, "CSR": 0.5407894736842105, "EFR": 1.0, "Overall": 0.7062047697368421}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "a genie", "a cassowary", "Robbie Turner", "a palette", "ice", "Cherry", "Tajikistan", "Theology", "Forrest Gump", "a stack", "a hot dog", "Ritchie", "\"Dixie\"", "Nobel", "Karen Blixen", "Oklahoma", "Sindbad", "the ziggurat", "the toe", "Pennsylvania", "\"War of the Worlds\"", "Hercules", "Steve Jobs", "J. P. \"The Big\"", "a manwich", "2", "Caesar", "Jane Grey", "Eugene V. Debs", "Texas", "Troy", "Antoinette Perry", "The Crucible", "the rabbit", "Battlestar Galactica", "Ofsted", "Titan", "Francis", "2:8", "Arthur Miller", "Billie Holiday", "Seal", "Improv", "Scrabble", "2016", "a moose", "Jammu & Kashmir", "\"Barbary Coast\"", "a skunk", "Neal Dahlen", "pigment", "Reverend J. Long", "bridge", "mauritania", "lettuce", "Scholastic UK", "FIFA Women's World Cup", "Great Lakes and Midwestern", "Columbia, Illinois,", "three out of four", "2002", "\"There are already many other restaurants in the mall, so we will only be one of the many restaurants that offer visitors their products.\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6421874999999999}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.06666666666666667]}}, "before_error_ids": ["mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-3494", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-12897", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-13537", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-571", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-2598", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-621", "mrqa_newsqa-validation-2950"], "SR": 0.5625, "CSR": 0.541015625, "EFR": 1.0, "Overall": 0.70625}, {"timecode": 96, "before_eval_results": {"predictions": ["2017 -- 18 network television season", "Lill - Babs", "InterContinental Hotels & Resorts", "Kaley Christine Cuoco", "1877", "Everywhere", "T.S. Eliot", "international relations based on sovereign states", "30 October 1918", "St. Augustine", "Meri", "\" Peggy Lipton, who knew Vincent Price, suggested Price for the vocal part, which Price agreed to do", "Nicole Gale Anderson", "Tiffany Adams Coyne", "Scheria", "Eddie Murphy", "20 November 1989", "Ben Savage", "Genoese merchant sailor Manuel Pessanha ( Pesagno )", "`` Reveille ''", "Thomas Stone", "meaning `` save, rescue, savior ''", "the Canadian Rockies continental divide east to central Saskatchewan", "from June 11, 2002 to April 7, 2016", "Khrushchev", "Addie Horton", "the International Border ( IB )", "Ancy lostoma duodenale", "the road is travelled by funeral convoys for fallen Canadian Forces personnel from CFB Trenton to the coroner's office in Toronto", "King T'Chaka of the African nation Wakanda", "the player", "1988", "the Southern Hemisphere", "The Union's forces", "Majandra Delfino", "September 19, 2017", "a convergent plate boundary", "ancient Mesopotamia", "The show takes place on the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "Matt Monro", "Bill Russell", "Kryptonite", "May 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "MFSK and Olivia", "around 1940", "(John) Ritchie", "Apocalypse Now", "Gower", "11,163", "Jaguar Land Rover Limited", "His son", "propofol,", "Courtney Love,", "the park bench facing Lake Washington", "a score", "East of Eden", "Aconcagua", "1919"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6588828310680334}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.07142857142857144, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.4, 0.18181818181818182, 1.0, 1.0, 1.0, 0.4, 0.23529411764705882, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0625, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.8, 0.8, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9367", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-937", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-1155", "mrqa_hotpotqa-validation-3348", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.5625, "CSR": 0.5412371134020619, "EFR": 0.9285714285714286, "Overall": 0.6920085833946981}, {"timecode": 97, "before_eval_results": {"predictions": ["Some states prohibit selling alcoholic beverages for on - and off - premises sales in one form or another on Sundays at some restricted time", "Dr. Sachchidananda Sinha", "2001 -- 2002", "New England", "2007", "the New Croton Reservoir in Westchester and Putnam counties", "from the 1960s to the mid-1970s", "Bart Cummings", "Billie `` The Blue Bear ''", "Arnold Schoenberg", "1500 BC", "meditation", "Panzerkampfwagen VIII Maus", "An empty line", "Ian Hart", "the contestant makes a thirty - second call to one of a number of friends ( who provide their phone numbers in advance ) and reads them the question and answer choices", "1902", "In every colony except Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices", "Frankel", "Human fertilization", "senators", "Lysander", "the fairy tale `` The Little Ariel '' by Hans Christian Andersen", "Procol Harum", "2018", "William Shakespeare's As You Like It", "James Rodr\u00edguez", "Nucleotides", "Hathi Jr", "interstitial and intravascular compartments", "1983", "Instagram's own account", "Revelation was the last book accepted into the Christian biblical canon", "when matching regions on matching chromosomes break and then reconnect to the other chromosome", "Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Robert Jordan", "American swimmer Michael Phelps", "Don McMillan", "U.S. was not officially tied to the Allies by treaty", "Isabela Moner", "April 29, 2009", "Smyrna ( Revelation 2 : 8 - 11 )", "Gibraltar", "red, white, and blue", "small orange collection boxes distributed to millions of trick - or - treaters", "Salt Lake City", "Schengen Area", "The King", "March, 1904", "Tom Ince", "Katarina Witt", "At least 38", "\"The Da Vinci Code\"", "Barbara Streisand's", "Brave New World", "a phobia", "Cryogenics", "anxiety disorder"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5881741955960706}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.8, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 0.0, 0.6363636363636364, 1.0, 1.0, 0.7692307692307692, 1.0, 1.0, 1.0, 0.36363636363636365, 1.0, 0.5714285714285715, 0.3636363636363636, 0.07142857142857144, 0.4, 0.14285714285714288, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-9953", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-786"], "SR": 0.453125, "CSR": 0.5403380102040816, "EFR": 0.9142857142857143, "Overall": 0.6889716198979592}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "an American painter and writer who wrote the autobiography \"The Bite in the Apple\" about her relationship with Apple co-founder Steve Jobs", "Gene Serdena", "Rockbridge County", "Mumbai, Maharashtra", "Savannah", "\"Perfect Strangers,\"", "public", "Nelson County", "video game", "\"boundary river\"", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp).", "alcoholic drinks for consumption on the premises", "\"The Simpsons 138th Episode Spectacular\"", "Puente Hills Mall", "neo-Nazi ideology", "forensic psychiatrist", "Bisexuality", "Adam Dawes", "1621", "Steven Selling", "Oberkommando der Wehrmacht", "1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "British", "1968", "Shamrock Rovers", "Dirk Werner Nowitzki", "the highland regions of Scotland", "Kansas State", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "The Hungry", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "1976", "Anthony Lynn", "Samuel Beckett", "Bay Ridge, Brooklyn", "Amii Anne J. Grove", "their unusual behavior", "1952", "to start fires, hunt, and bury their dead", "In February 2011, following the events of `` Lauren '', during an attack on the task force, she was wounded and miscarriageried the baby", "Dmitri Mendeleev", "honda", "Utah", "The Carpet-Bag", "the worst subway train accident in the history of the Washington Metropolitan Area Transit Authority.", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "to host the Olympic Games in Rio de Janeiro.", "\"Free Bird\"", "Great Expectations", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7112319359562007}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.5, 0.0, 0.28571428571428575, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.4, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-745", "mrqa_hotpotqa-validation-1971", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2375", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_triviaqa-validation-1771", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668"], "SR": 0.640625, "CSR": 0.5413510101010102, "EFR": 1.0, "Overall": 0.7063170770202021}, {"timecode": 99, "UKR": 0.697265625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.78125, "KG": 0.46484375, "before_eval_results": {"predictions": ["The 2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "the Dover Area School District", "The Bears", "1979", "Salisbury", "KKR & Co", "526 people", "Annie Ida Jenny No\u00eb Haesendonck", "the Cold Spring Historic District", "The Grandmaster", "satirical erotic romantic comedy", "\"The Process\"", "Vikram", "1949", "BAFTA TV Award", "Cameron Indoor Stadium", "midfielder", "Levi Weeks", "219 passengers", "Esteban Ocon", "S6", "Lamar Hunt", "Black Mountain College", "\"You Can Be a Star\"", "People v. Turner", "1853", "1977", "wine", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "\"Kosthany Phnom Bokor\"", "Ludwig van Beethoven", "Rabat", "Boltzmann machine", "Dusty Dvoracek", "XVideos", "The Lykan Hypersport", "Richard Arthur", "New York City", "May 4, 2004", "3 mi", "Field Marshal Lord Gort", "Neighbourhood", "Miracle", "1979", "Trent Alexander-Arnold", "eleven", "2011", "the last Ice Age", "North Carolina", "wish FM", "John Galliano", "Mark Fields", "Arlington National Cemetery's Section 60,", "Seoul", "circumnavigate", "the question mark", "15", "Mollusks"], "metric_results": {"EM": 0.65625, "QA-F1": 0.729017857142857}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, false, false, false, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true], "QA-F1": [0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-614", "mrqa_hotpotqa-validation-3155", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-6862", "mrqa_searchqa-validation-517"], "SR": 0.65625, "CSR": 0.5425, "EFR": 1.0, "Overall": 0.697171875}]}