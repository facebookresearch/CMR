{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=10_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=100.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=10_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4130, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "Los Angeles Times", "the Broncos", "anticlines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "Rhenus", "Pacific", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "corpses", "United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "squared integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "Swedex GmbH & Co KG", "More than 1 million", "2011", "market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Taoism", "Matthew 16:18", "the U.S.-flagged Maersk Alabama", "Rwanda", "revelry", "his health", "Hugo Vihlen", "the outskirts of a small Southern town"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7848958333333333}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-5112", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-9655", "mrqa_squad-validation-7763", "mrqa_squad-validation-4772", "mrqa_squad-validation-7728", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-4274", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.71875, "CSR": 0.7734375, "EFR": 0.7777777777777778, "Overall": 0.7756076388888888}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "the coast of Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "presidential representative democratic republic", "the grace that \"goes before\" us", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "Arizona Cardinals", "1991", "Mercury/Gemini", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "pharmacists are expected to become more integral within the health care system", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "The Spice Girls", "Documents", "the company's factory in Waterford City, Ireland", "nitrogen", "Christopher Nolan", "the Florida current feeds the Gulf Stream that flows east of Cape Hatteras", "six", "It always begins with the music", "conductor", "Illinois", "Rafael Palmeiro Corrales", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.8125, "QA-F1": 0.8289835164835164}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.3076923076923077, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-235", "mrqa_squad-validation-3967", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936"], "SR": 0.8125, "CSR": 0.7864583333333334, "EFR": 0.8333333333333334, "Overall": 0.8098958333333334}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "monumental size", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "beautiful voice", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "The Commission's President", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "Edict of Nantes", "reserved to, and dealt with at, Westminster", "multiple revisions", "philanthropic initiative", "integer factorization", "necessity", "Isel", "adapted quickly and often married outside their immediate French communities", "U. S. Secretary of Housing and Urban Development", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "hydrogen ion gradient", "the late 19th century", "Channel Islands", "in no way", "Alberich", "charleston", "raising the spice level", "Churchill Downs", "the Ghent-Terneuzen Canal", "charleston", "\"shake Ambridge [the village where The Archers is set] to the core\u201d", "Germany", "study insects and their relationship to humans", "the limbic system", "Allan Border", "George Fox", "Maryland", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorgate", "\"Krabby Road\""], "metric_results": {"EM": 0.640625, "QA-F1": 0.6685763888888889}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-801", "mrqa_squad-validation-9286", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_hotpotqa-validation-437", "mrqa_hotpotqa-validation-3821"], "SR": 0.640625, "CSR": 0.75, "EFR": 0.8260869565217391, "Overall": 0.7880434782608696}, {"timecode": 4, "before_eval_results": {"predictions": ["higher plants", "Parliament of Victoria", "Zaha Hadid", "the Marquis de Vaudreuil", "Science and Discovery", "Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of ways", "Battle of Olustee", "the port city of Kaffa in the Crimea", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "2010", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "the Italian government", "22", "planned attacks in the southern port city of Karachi", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "a new model is simply out of their reach", "Muslim", "This will be the first time any version of the Magna Carta has ever gone up for auction", "a wedding", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "a woman who may have been contacted through a Craigslist ad", "one", "celebrity-inspired names", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "colticelli"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7049163244843393}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 0.28571428571428575, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.15999999999999998, 1.0, 1.0, 0.0, 0.32, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-9456", "mrqa_squad-validation-7094", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.671875, "CSR": 0.734375, "EFR": 0.8571428571428571, "Overall": 0.7957589285714286}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "Connectional Table", "Deformational", "a high-level marketing manager", "500,000", "Ofcom", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches", "2011", "algae", "part of a rule connected with civil disobedience", "June 1978", "Milton Latham", "1914", "the Philippines", "the Broncos", "1950s to 2011", "the characteristics of the conquering peoples", "German Te Deum", "1795", "Bermuda 419", "by compressing and cooling", "Infinity Broadcasting Corporation", "semi-legal", "1972", "rudimentary", "1957", "mother-of-pearl", "Gene Barry", "President of the United States negotiates treaties with foreign nations, but treaties enter into force if ratified by two - thirds of the Senate", "used in a compact layout to combine keys which are usually kept separate", "from an Ohio newspaper on 8 February 1925", "President since Woodrow Wilson, with the notable exception of Herbert Hoover, has made at least one State of the Union report as a speech delivered before a joint session of Congress", "radius R", "Panning", "Justin Timberlake", "the following 15 countries or regions have reached an economy of at least US $2 trillion by GDP in nominal or PPP terms", "member states on a voluntary basis. As of 31 December 2013, the total size of the peacekeeping force is 98,200 police", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's opened its first three stores in Canada", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "the seven ages of man : infant, schoolboy, lover, soldier, justice, Pantalone and old age", "most episodes feature a storyline taking place in the present ( 2016 -- 2018, contemporaneous with airing )", "Morgan Freeman reprising his role as detective Alex Cross", "David Gahan", "the Overlook Hotel in his 1977 bestseller The Shining and its 1980 film adaption of the same name, as well as the location for the 1997 miniseries", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "people prepare for the long Lenten fast", "Jaipur", "Johan Persson and Martin Schibbye", "The anti-torpedo boat origin of this type of ship is retained in its name in...   capital ships[?] - Encyclopedia - Kids.Net.Au", "Newport County moved to Rodney Parade for the 2012/13 season after being at Newport Stadium for 18 years."], "metric_results": {"EM": 0.578125, "QA-F1": 0.676618118093844}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2666666666666667, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3846153846153846, 0.1111111111111111, 0.0, 0.13793103448275862, 0.0, 1.0, 1.0, 0.8333333333333333, 0.4, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 0.3636363636363636, 0.5, 0.08333333333333334, 0.5833333333333334, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-4836", "mrqa_squad-validation-9552", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-7488", "mrqa_squad-validation-3473", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.578125, "CSR": 0.7083333333333333, "EFR": 0.7777777777777778, "Overall": 0.7430555555555556}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "social and political action", "1936", "New Birth", "gold", "a 3\u20130 lead", "Vivienne Westwood", "reduction", "disease", "TGIF", "Confucian propriety and ancestor veneration", "the rediscovery of \"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "a chain or screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "teachers in publicly funded schools", "at the end of the season", "10", "Jacob", "African-Americans", "\"creates the precedent and possibility for undue regulation, censorship and legal abuse.\"", "Chuck Bass", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Stuttgart on Sunday", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "the United States, Japan, Russia, South Korea and China", "first five Potter films", "know what's important in life", "children ages 3 to 17", "two suicide bombers", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "Her husband and attorney, James Whitehouse", "we want to ensure we have all the capacity that may be needed over the course of the coming days", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "Mike Gatting", "Colgate University", "The Church of Christ, Scientist", "unsaturated fats are comprised of lipids that contain?", "Luke 6 : 67 -- 71"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7437220614530397}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.08695652173913043, 0.0, 0.0, 1.0, 0.2, 0.5, 1.0, 0.5, 0.8571428571428571, 1.0, 0.0, 0.7499999999999999, 0.5, 0.2666666666666667, 1.0, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.75]}}, "before_error_ids": ["mrqa_squad-validation-800", "mrqa_squad-validation-486", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-1267", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-3193", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.640625, "CSR": 0.6986607142857143, "EFR": 0.782608695652174, "Overall": 0.7406347049689441}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "return to his side", "increased trade with poor countries", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism in the Small Catechism", "Jim Gray", "unequal", "July 1969", "Hitler's secret police demanded to know if they were hiding a Jew in their house.", "a yellow chlorophyll precursor", "spontaneous", "the courts of member states", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "Belgrade", "\u00a320,427", "21 October 1512", "James O. McKinsey", "dance Your Ass Off", "\"Freshman Year\" experience", "India", "Zulfikar Ali Bhutto", "at the country's third-largest oil refinery", "April 24 through May 2.", "Krishna Rajaram", "early detection and helping other women cope with the disease.", "250,000", "Timothy Masters", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jared Polis", "William S. Cohen", "\"Dance Your Ass Off.\"", "military trials for some Guant Bay detainees.", "Gary Brooker", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian.", "a \"stressed and tired force\" made vulnerable by multiple deployments", "Japan", "condition", "\"Empire of the Sun,\"", "Norman given name Robert", "stronger with an unfair advantage.", "Matthew Ward Winer", "Doc Holliday", "Baltic Sea", "Mustique", "green"], "metric_results": {"EM": 0.625, "QA-F1": 0.6982802983307016}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.9032258064516129, 1.0, 1.0, 0.5333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.3636363636363636, 0.0, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.10256410256410256, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6115", "mrqa_squad-validation-7533", "mrqa_squad-validation-2448", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-3938", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-417", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-991"], "SR": 0.625, "CSR": 0.689453125, "EFR": 0.7916666666666666, "Overall": 0.7405598958333333}, {"timecode": 8, "before_eval_results": {"predictions": ["7 February 2009", "The British provided medical treatment for the sick and wounded French soldiers", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe.", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday afternoon", "Journey's End", "immediate", "Levi's Stadium", "Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan", "Einstein", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington Railway", "autonomy", "Islamic", "$12.9 million", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic is the reason for his longevity in the movie business.", "finance", "terminal brain cancer.", "attracted some U.S. senators who couldn't resist taking the vehicles for a spin.", "Employee Free Choice act", "separated", "Animal Planet", "crashing his private plane into a Florida swamp.", "FAA said.Flights at Atlanta's Hartsfield-Jackson International Airport were delayed Tuesday afternoon.", "54 bodies", "early detection and helping other women cope with the disease.", "Diversity", "$250,000", "make sure water continues flow through the river channel and not spread out over land.", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president", "2050", "Alfredo Astiz, a former Navy captain whose boyish looks and deceitful ways", "Abdullah Gul", "Carl Froch", "The Everglades, known as the River of Grass,", "The original chromosome and the copy are now called sister chromatids", "Gibraltar territory currently contains an 800 m long section of the isthmus that links the Rock with mainland Spain.", "New Orleans, Louisiana", "early 1630s, a craze developed in Holland for this flower, with many investors paying huge sums for individual bulbs", "MIBs mission statement: protecting the earth from the scum of the universe.", "eat too many chockies, these, & you may find yourself crook, \"sick\"", "Get the latest St. Louis Blues news, scores, stats, standings, rumors, and more from ESPN."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6653798045922659}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0909090909090909, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 0.3076923076923077, 1.0, 0.0, 0.2857142857142857, 0.0, 0.11764705882352941, 0.5, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3910", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-1710", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.59375, "CSR": 0.6788194444444444, "EFR": 0.6153846153846154, "Overall": 0.6471020299145299}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "\"hoos\"", "30%\u201350% O2 by volume", "very badly disposed towards the French, and are entirely devoted to the English.", "United States", "CRISPR sequences", "six", "300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "the substance of the statement", "Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "providing the basic securities that Turkey can be a great partner.", "an average of 25 percent", "a gym", "Jennifer Arnold and husband Bill Klein, who both have skeletal dysplasia, a bone-growth disorder that causes dwarfism,", "environmental and political events.", "he fears a desperate country with a potential power vacuum that could lash out.", "at least two and a half hours.", "Elin Nordegren", "Europe, Asia, Africa and the Middle East", "6,000", "banned substance cortisone.", "President Clinton.", "delivered three machine guns and two silencers to the hip-hop star,", "Morgan Tsvangirai.", "policing the world and Africa", "future relations between the Middle East and Washington.", "in a canyon in the path of the blaze", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school, their books burned, as the hard-core Islamic militants spread their reign of terror across parts of Pakistan.", "strife in Somalia", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia, Illinois", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "they did not know how many people were onboard.", "London", "after Shawn's kidnapping", "the immediate physical and social setting in which people live or in which something happens or develops.", "William Tell", "OutKast", "Groundhog Day", "he really didn't mean t", "a singer who takes a job working with a struggling carnival."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6037884861302381}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.08, 0.4, 0.0, 0.5217391304347825, 1.0, 0.0, 1.0, 1.0, 0.2, 1.0, 0.5, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 0.1111111111111111, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-3687", "mrqa_squad-validation-9194", "mrqa_squad-validation-9484", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.515625, "CSR": 0.6625, "EFR": 0.5806451612903226, "Overall": 0.6215725806451613}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction motor", "The Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "the primary endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "Friday", "pelvis and sacrum -- the triangular bone within the pelvis.", "issued his first military orders as leader of North Korea", "8 to 10 inches of snow", "Willem Dafoe", "Maude", "Phillip A. Myers.", "Koreans", "two weeks after Black History Month was mocked in an off-campus party that was condemned by the school.", "58", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Touma", "Dangjin", "e-mails", "Chinese President Hu Jintao", "magazine", "burns over about two-thirds of his body, according to the hospital's associate director, Dr. Carl Schulman.", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next.", "President Bush", "Jeffrey Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "kabinett - Wines made with fully ripened grapes.", "Lionsgate.", "James Lofton", "Mysticism", "hair-like structures that help paramecium move around."], "metric_results": {"EM": 0.65625, "QA-F1": 0.7167850378787879}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5454545454545454, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_triviaqa-validation-7134", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.65625, "CSR": 0.6619318181818181, "EFR": 0.9545454545454546, "Overall": 0.8082386363636364}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "The combination of hermaphroditism and early reproduction", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company under the Office of Alien Property (OAP) seal. John G. Trump,", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching.", "Elway", "Philo of Byzantium", "36 acres", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "sum of divisors", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "David Copperfield", "The Soup Dragon", "antelope", "nipples", "Triassic Periods", "cooperative", "Anastasia Dobromyslova", "Lady Gaga", "9", "Blake Griffin", "radish", "Robert Ludlum", "a great power", "(.mov)", "The Donington Grand Prix Collection is, quite simply, the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live", "Hebrew", "London Underground Piccadilly Line", "Wisconsin", "orangutan", "Manet", "The Magic Finger", "Massachusetts", "2005", "1969", "Chrysler", "dolt", "Venice", "a peplos.", "Enrico Caruso", "Elizabeth Arden", "collapsible support assembly", "Sir Hardy Amies", "Liechtenstein", "the 14th most common surname in Wales and 21st most common in England", "Rob Davis", "Cody Miller", "Brown Square Station", "Nazi Germany", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "Jamaica", "Buddhism"], "metric_results": {"EM": 0.59375, "QA-F1": 0.670737333736004}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, false, false, false, true, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 1.0, 0.23076923076923078, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4444444444444444, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-3759", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983"], "SR": 0.59375, "CSR": 0.65625, "EFR": 0.6538461538461539, "Overall": 0.6550480769230769}, {"timecode": 12, "before_eval_results": {"predictions": ["Southern Border Region", "70-50's", "Panini", "new laws or amendments to existing laws as a bill; a committee of the Parliament can present a bill in one of the areas under its remit", "anti-colonial movements", "Rhine Valley", "A", "by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "cases of an express wish of the people to withdraw from the EU", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "because the nationalisation law was from 1962, and the treaty was in force from 1958, Costa had no claim.", "Eternal Heaven", "Ness Point", "John Mayer", "Leonard Cheshire", "Val Doonican", "Virgil", "France", "T.S. Eliot", "Eric Pickles", "spy Who Loved Me", "Vladivostok", "Sheryl Crow", "Telstar", "Camellia sinensis", "AFC Wimbledon", "Charles Hawtrey", "Malaysia", "cosmology", "gin", "George Clooney", "Eric Coates", "James Chadwick", "\"No one was saved\"", "Monopoly", "champagne", "extended period of abundant rainfall lasting many thousands of years.", "the United States", "Brigit Forsyth", "William Lamb, 2nd Viscount Melbourne", "state of Japan", "The History of Troilus and Cressida", "David Lean", "Kent", "Renoir\u00b4s", "Standard Motor Company", "white", "Switzerland", "soda water", "people of France to the people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Derek Mears", "federal states in the heart of...", "The Goat Amalthea", "\"The Screening Room\""], "metric_results": {"EM": 0.546875, "QA-F1": 0.5989746980170367}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8387096774193548, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9452", "mrqa_squad-validation-6655", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-4222", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_triviaqa-validation-3503", "mrqa_naturalquestions-validation-594", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_searchqa-validation-8450", "mrqa_searchqa-validation-9647", "mrqa_newsqa-validation-3860"], "SR": 0.546875, "CSR": 0.6478365384615384, "EFR": 0.7931034482758621, "Overall": 0.7204699933687002}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi (Rhazes)", "Georgia", "articles 1 to 7", "the Black Death", "their own militia", "days, weeks and months", "Over 61", "quality of a country's institutions", "cilia", "friction", "Sky Digital", "2005", "force", "business", "John Connally", "saffron  Saffron", "hymenaeus", "Zeus", "a chemical", "the Suez Canal", "Brigit Forsyth", "call My Bluff", "March 10, 1997", "crazed Holiday", "The Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "reptile", "strong cold southwest wind", "table tennis", "the journal of medicine", "penhaligon", "Gandalf", "thaddeus sholto", "Jinnah International Airport", "Monday", "capital of Venezuela", "beads", "soap", "highball", "Avro Lancaster", "\"Follow You Follow Me\"", "covey Brooker", "melon balm leaves and flowers", "harrods", "2007", "Christina Ricci", "Scarface", "pale yellow", "aluminium", "bubba", "June 12, 2018", "Filipino American", "London", "Lambic", "Nook", "Steven Green", "reedes", "cunY-CoLAG", "emperor", "\"Every Breath You Take\""], "metric_results": {"EM": 0.484375, "QA-F1": 0.5980034722222223}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.7499999999999999, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-6463", "mrqa_squad-validation-4908", "mrqa_squad-validation-6933", "mrqa_squad-validation-2920", "mrqa_triviaqa-validation-7204", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-6708", "mrqa_triviaqa-validation-4981", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-8598", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-13371"], "SR": 0.484375, "CSR": 0.6361607142857143, "EFR": 0.8181818181818182, "Overall": 0.7271712662337663}, {"timecode": 14, "before_eval_results": {"predictions": ["seven", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium, and the San Francisco Bay Area's Levi's Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "sleep", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "declining state of mind", "13 May 1899", "The Deadly Assassin and Mawdryn undead", "radioisotope thermoelectric generator", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat in the hat", "2020", "1974", "332", "1936", "Authority", "senior enlisted sailor", "Spanish moss", "Chinese cooking for over 400 years", "Vienna", "2 World Trade Center", "Kevin Spacey", "1 November", "2.5", "white blood cell", "Bangladesh -- India border", "President", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "January 12, 2017", "United States", "claims adjuster", "the nucleus", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection, irritation, or allergies", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column", "three", "nee", "sausages", "Kew Gardens", "Nikita Khrushchev", "$500,000", "young self-styled anarchists", "reaper", "shIELD", "in the foyer of the BBC building in Glasgow, Scotland", "a thick stack of paper"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6556862408424908}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, true, false, true, false, false], "QA-F1": [0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5333333333333333, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.5, 0.2857142857142857, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.9333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-653", "mrqa_squad-validation-2339", "mrqa_squad-validation-1454", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-10656", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_searchqa-validation-726", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.546875, "CSR": 0.6302083333333333, "EFR": 0.7586206896551724, "Overall": 0.6944145114942528}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "The Late Late Show", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "musicians", "CBS", "Jean Ribault", "Tetzel", "visitation of the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "60", "Seattle, Washington", "Battle of Antietam", "Nicolas Anelka", "In Time", "2nd century", "Glenn Close", "four times", "Agostino Bassi", "five", "Malibu, California", "the church at Philippi", "Dutch navy captain Jurriaen Aernoutsz", "September 2017", "Professor Kantorek", "1546", "Bud '' Bergstein", "Bhupendranath Dutt", "a warrior", "Dr. Lexie Grey", "Majandra Delfino", "December 19, 1971", "Uruguay", "Alex Skuby", "Thomas Middleitch", "The National Legal Aid & Defender Association", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "Director of National Intelligence", "Defence Against the Dark Arts", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal", "burt Hammersmith", "Rachel Kelly Tucker", "Bohemia", "earwigs", "Code 02PrettyPretty", "musician", "the parliament", "the abduction of minors", "Nevada", "laureate", "Stage Stores,", "1881"], "metric_results": {"EM": 0.5, "QA-F1": 0.6092247596153846}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, false, true, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_squad-validation-551", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_newsqa-validation-2674", "mrqa_searchqa-validation-5103"], "SR": 0.5, "CSR": 0.6220703125, "EFR": 0.65625, "Overall": 0.63916015625}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "Arizona Cardinals", "Bert Bolin", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Western Xia", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Vancouver", "Office", "SAVE", "Scandinavian Airlines System Aktiebolag", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award Best Actor", "Jello Biafra drew on Nardwuar's face with a marker pen", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson, David Michener, and the team of John Musker and Ron Clements,", "Sir William McMahon", "the North Sea", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "the CAC/PAC JF-17 Thunder", "Delacorte Press", "Neighbourhoods", "Secretariat", "Wake Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of France", "\"Southern Living\" Reader's Choice Awards", "William Shakespeare", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Alticor", "Parlophone Records", "South Africa", "Surrey", "The Girl", "Charles Russell", "Boyd Gaming", "three different covers", "1991", "Glenn Close", "Florence Glenda Ballard", "Neighbours", "Ewan McGregor", "2011", "pippa passes", "a enslaved African American who led", "power-sharing talks", "Brown-Waite, along with Republican Rep. Shelley Moore Capito of West Virginia."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6474770021645022}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.3636363636363636, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-5514", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-3521"], "SR": 0.5625, "CSR": 0.6185661764705883, "EFR": 0.8571428571428571, "Overall": 0.7378545168067228}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional", "inner chloroplast membrane", "Charlie Harper", "steveland Hardaway Morris", "beaver", "La Boh\u00e8me", "formic acid", "torc", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Plato", "Fuller's", "a reference mark", "Nick Hornby", "\"The Two Gentlemen of Verona\"", "Charles V", "England", "Lagertha", "weight plates", "\"big house\"", "Hadrian", "France", "flea", "Moonee Ponds, a suburb in Melbourne, Victoria", "Hamburg", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "In 2014/15, only six have won the title", "Robert Cummings", "John Mayer", "British public", "In 1906, Finland became the first country in the world to grant women full political rights.", "3000m", "Scotland", "Russia", "Travis Tritt and Marty Stuart", "The Union", "New Jewel Movement", "sub-Saharan Africa", "U.S. 93", "Anjuna beach in Goa", "Lev Ivanov", "\"s h! du'y van", "two", "jeopardy/1870_Qs.txt at master  jedoublen/jeopardy", "\"The Sunday Thing\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.5726934523809524}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-5052", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_triviaqa-validation-2812", "mrqa_naturalquestions-validation-767", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-3198", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.515625, "CSR": 0.6128472222222222, "EFR": 0.7741935483870968, "Overall": 0.6935203853046594}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "1994", "Coppolas and, technically, the Farrow / Previn / Allens", "Anna Faris", "mainland greece", "inability to comprehend and formulate language", "Splodgenessabounds", "Tyrion", "electron donors", "Meredith Quill", "1985", "19 state rooms", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Alice", "20 November 1989", "Coton in the Elms", "55 -- 69 %", "Ella Eyre", "1995", "Identification of alternative plans / policies", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "arterioles", "July 21, 1861", "Dr. Addison Montgomery", "capital and financial markets", "an optional message body", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "universal significance", "September 2017", "moral", "Rising Sun Blues", "Part 2", "Dumbo", "the duke of Monmouth\u2019s rebellion", "Christian", "Robert L. Stone", "2008", "Yemen", "jegna", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6735148225957049}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 1.0, 0.2857142857142857, 0.0, 0.0, 0.8, 1.0, 0.19999999999999998, 1.0, 0.0, 0.6666666666666666, 0.4, 0.28571428571428575, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6242", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-7111", "mrqa_hotpotqa-validation-4735"], "SR": 0.59375, "CSR": 0.611842105263158, "EFR": 0.5769230769230769, "Overall": 0.5943825910931174}, {"timecode": 19, "before_eval_results": {"predictions": ["Luther reviews and reaffirms, on the one hand, what has been called the \"second use of the law,\"", "black", "Illinois Country", "Jaime Weston", "1978", "high art and folk music", "warming", "the mid-sixties", "270,000", "Long troop deployments", "CNN.com", "a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother, a key witness in the case,", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "32 percent", "sovereignty over them", "Tuesday", "forgery and flying without a valid license", "Anil Kapoor", "19", "President Obama", "unwanted baggage from the 80s", "The Louvre", "snowstorm", "exotic sports cars", "eggs", "Mutassim", "Thursday and Friday", "\"Steamboat Bill, Jr.\"", "NATO fighters", "alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone", "\u00a341.1 million", "Kingman Regional Medical Center", "CNN", "Manmohan Singh", "Michael Jackson", "be silent", "40 militants", "Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Louisiana", "Southeast", "the last person known to have seen Haleigh the night she disappeared from the family's rented mobile home.", "Steven Chu", "tells Larry King her son has strong values.", "Moe and Sana Maraachli", "back at work", "the initial necropsy or animal autopsy", "27", "Derek Hough", "John Adams, a leader in pushing for independence, had persuaded the committee to select Thomas Jefferson to compose the original draft of the document", "parsley", "Zager & Evans", "Robert Matthew Hurley", "fourth term", "\"adult theatre - You must be 21 and able to prove it.", "(Oliver) Cromwell", "Lapland", "2000", "Emad Hashim"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5629682239057239}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, false, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, true], "QA-F1": [0.14814814814814814, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.8333333333333333, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_triviaqa-validation-7208", "mrqa_searchqa-validation-328", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-5120"], "SR": 0.453125, "CSR": 0.60390625, "EFR": 0.8571428571428571, "Overall": 0.7305245535714285}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "Rhenus", "1331", "Death wish Coffee", "L", "Cameroon", "1994", "ballots", "polo", "three empty vodka bottles,", "strategy, plans and policy", "Bobby Darin", "Felipe Massa", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "humiliated", "composer", "the punishment", "Caylee Anthony, 2,", "Amanda Knox's aunt", "well over 1,000 pounds", "Iran's nuclear program", "12 shades of violet, including a welcoming, bright blue-purple during the day, a softer violet hue after dusk", "using recreational drugs", "ceo Herbert Hainer", "Brett Cummins,", "The Valley swim Club", "inmates", "Elspeth Cameron-Ritchie", "\"E! News\"", "six members of Zoe's Ark", "jobs", "saying Tuesday the reality he has seen is \"terrifying.\"", "waterboarding at least 266 times on two top al Qaeda suspects,", "Mexican's attorney general's office responded with a statement saying that it would investigate the video and any group that tries to take justice into its own hands.", "Republicans", "goes into when I got out of the game.", "Saturday's killing of a 15-year-old boy", "The official said deciding the duties of the new prime minister has been a sticking point in the negotiations.", "a 57-year old male", "North Korea intends to launch a long-range missile in the near future,", "Angola", "Matthew Fisher", "jund Ansar Allah", "boogeyman", "referred the case of Mohammed al-Qahtani to prosecutors", "Sea World in San Antonio", "guard", "about 50 formal applications", "Ku Klux Klan", "MGM prohibited the release until The Wizard of Oz ( 1939 ) had opened", "Branford College", "Bolton, Bury, Oldham, Rochdale, Stockport, Tameside, Trafford, Wigan, and the cities of Manchester and Salford.", "stamens", "Malayalam movies", "August 17, 2017", "a jacket, gloves or a briefcase", "By the 1950s, scientists were able to do this to frogs; mice followed, in the '80s", "Hodel", "access to US courts", "Coldplay"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5438595547970547}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2, 0.0, 0.0, 1.0, 0.9523809523809523, 0.5, 1.0, 0.5, 0.8, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.14814814814814814, 1.0, 0.0, 0.888888888888889, 0.923076923076923, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.4, 1.0, 0.18181818181818182, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.22222222222222224, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-1888", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-10284", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-3783"], "SR": 0.390625, "CSR": 0.59375, "EFR": 0.6153846153846154, "Overall": 0.6045673076923077}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "Splash", "Nicola Adams", "copper and zinc", "Austria, Prussia, Russia, France, and also Poland,", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "breast", "Madonna's", "Glasgow", "satellite", "Australia", "giblet", "Pearson PLC", "Irish Setter", "American Civil War", "Loch Awe", "celibacy", "Tasmania", "medium-sized cat, fine-boned, long, and firmly muscled.", "Taiwan", "Harrisburg", "mink mink,", "glockenspiel", "Dr John Sentamu", "Baka hunter-gatherers", "Cruella de Vil", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "Charles V", "the community", "Russell Crowe", "Theodore Roosevelt", "skipper", "Puck", "Erewhon", "chamomile", "Ireland", "tarn", "Atlantic", "Albert Square", "Newbury", "the Old Testament", "70 million people, at that time 21 % of the world's entire population", "Target Corporation", "Sister, Sister", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "EYBistro", "Swamp Fox", "prisoners' rights and better conditions for inmates, like Amnesty International.", "talk show queen Oprah Winfrey.", "Mom"], "metric_results": {"EM": 0.5625, "QA-F1": 0.608974358974359}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, false, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-3569", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2484", "mrqa_searchqa-validation-11802", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.5625, "CSR": 0.5923295454545454, "EFR": 0.75, "Overall": 0.6711647727272727}, {"timecode": 22, "before_eval_results": {"predictions": ["coughing and sneezing", "1765", "along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "Vicodin, generically known as hydrocodone", "Rome", "Robert Peary", "pearls", "blackbird Hundreds.", "Carrie Underwood", "liqueur liquor", "Nero", "mooglemb.com", "Langston Hughes", "Jimmy", "madge Larabee", "Orquestra", "riata", "unFINISHED", "USS LST 325", "rhodesian ridgebacks", "David Beckham", "Arturo Toscanini", "economics", "Miracle in the Andes", "arches", "Montenegro", "discus", "thick slice of bread", "basidiomycota", "james", "Ally McBeal", "Idi Amin Dada", "agricultural green & yellow", "a body, or a personal item associated with a saint", "terracotta", "Gaius Cassius Longinus", "lawyer, businessman, former politician", "masa harina", "50 seconds", "the Vikings.", "74 Fairfield Street", "summer", "typhoid fever", "a coastal inlet formed by the partial submergence of an unglaciated river valley.", "baviere-quebec.org", "Williamsburg", "\"Wire Rope Express\"", "University of Missouri-St. Louis", "hydrogen peroxide & yeast creates foam, steam & notably causes heat to be given off", "John Knox", "the internal reproductive anatomy", "$657.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "epidemiology is the study and analysis of the distribution and determinants of health and disease conditions in defined populations", "jape", "Tesco", "A4", "Graham Hill", "Battelle Energy Alliance", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services.", "debris", "$10 billion", "out in the woods"], "metric_results": {"EM": 0.328125, "QA-F1": 0.4098015761328455}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.6666666666666666, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.21052631578947367, 0.45454545454545453, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10104", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-13026", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-12564", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16257", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-2327", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-1118", "mrqa_hotpotqa-validation-68"], "SR": 0.328125, "CSR": 0.5808423913043479, "EFR": 0.7906976744186046, "Overall": 0.6857700328614762}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "Atlantic", "cat", "the daughter of Tony Richardson and Vanessa Redgrave", "Basel, Switzerland", "The Argonauts", "PromPromPrometheus", "Altamont Speedway Free Festival", "John F Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a multi-user real-time virtual world described entirely in text", "Italy", "khaki", "magma", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "the Mendip Hills", "Barack Obama", "the Earth", "Nafea Faa Ipoipo?", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "New Netherland", "Justin Trudeau", "aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations", "Manchester City", "Love Is All Around", "William Golding", "Sally Ride", "Influenza", "Fife", "Money Saving", "Adidas", "the \"Rabbit Hole\"", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "the opponent's", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "The Wall Street Journal Europe", "fox", "60 Minutes", "Earth"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6995251225490196}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848", "mrqa_searchqa-validation-1586"], "SR": 0.65625, "CSR": 0.583984375, "EFR": 0.8181818181818182, "Overall": 0.7010830965909092}, {"timecode": 24, "before_eval_results": {"predictions": ["limited coercion", "the chosen machine model", "Fox", "1997", "a suite of network protocols", "Noriko Savoie", "15", "the first home series defeat on Australia in almost 16 years", "between Pyongyang and Seoul", "killed a man, the latter cheated on his wife.", "11", "change course", "Damon Bankston", "Chaffetz", "money or other discreet aid for the effort if it could be made available,", "Sarah", "normal maritime traffic", "environmental", "Italy in the quarterfinals,", "Afghan security forces", "Saturday", "38", "70,000 or so", "climatecare, one of Europe's most experienced providers of carbon offset,", "E! News", "coach", "Steve Williams", "McDonald's", "writing her short stories (she has already published one book) and shows me a cartoon character she has created called \"Tomato Man.\"", "five female pastors", "2008", "Diego Maradona", "Dog patch Labs", "The drama of the action in-and-around the golf course", "two", "Itawamba County School District", "Romney", "EU naval force", "Plymouth Rock", "Liza Murphy", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "police", "former U.S. secretary of state", "At least 33", "five", "improve health and beauty.", "Texas is among a growing number of state governments going after them.", "that students often know ahead of time when and where violence will flare up on campus.", "Damon Bankston", "Krishna Rajaram", "Sunday, when a man wearing an explosives-laden vest drove a motorcycle rigged with bombs into a group of police recruits in eastern Baghdad.", "killing", "a feminine name", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "Northern Ireland", "radar", "art", "16th", "23", "South America", "freestyle", "Florence Nightingale", "the Kingdom of the Crystal Skull"], "metric_results": {"EM": 0.4375, "QA-F1": 0.621887912135757}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, true, true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.5, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.5555555555555556, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 0.0, 1.0, 1.0, 0.12121212121212123, 0.5, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 0.5, 1.0, 1.0, 0.16666666666666669, 1.0, 0.0, 1.0, 0.07692307692307693, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7272727272727273]}}, "before_error_ids": ["mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-3169", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-3826"], "SR": 0.4375, "CSR": 0.578125, "EFR": 0.6666666666666666, "Overall": 0.6223958333333333}, {"timecode": 25, "before_eval_results": {"predictions": ["50th anniversary special", "Thomas Savery", "Vicodin, generically known as hydrocodone", "Eastern crops", "22,000 years ago", "violent separatist campaign", "Eleven", "269,000", "the recent theft in Switzerland of two paintings by Pablo Picasso, Bjoern Quellenberg,", "38 feet", "Eintracht Frankfurt", "150", "a man had been stoned to death by an angry mob.", "NATO fighters", "41", "Los Alamitos Joint Forces Training Base", "Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "Isla Grande Airport in San Juan,", "the Russian air force", "34", "President Obama ordered the eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "around 3.5 percent of global greenhouse emissions.", "Amanda Knox's aunt", "\"several pieces of aircraft equipment were at fault or had broken down.\"", "ensuring that all prescription drugs on the market are FDA approved", "customers", "Tom Baer", "Pakistan", "The oceans are growing crowded, and governments are increasingly trying to plan their use.", "bikinis -- haute, bandeau-style little numbers", "Brian Mabry", "iTunes, which completely changed the business of music,", "Sunday.Maurice Clemmons, 37, was shot and killed early Tuesday by Seattle police.", "60 euros -- $89 --", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment", "Some truly mind-blowing structures are being planned for the Middle East.", "first name", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "2006", "San Diego County.", "Debora Harris, Joyce Mims, Tonya Miller, Quithreaun Stokes, Sheila Farrior.", "The Taliban has threatened to kill Bergdahl if foreign troops continue targeting civilians in the name of search operations in Ghazni and Paktika provinces,", "@", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "number two, the U.N. forces", "heart", "Hyderabad", "Sinai Peninsula or simply Sinai ( / \u02c8sa\u026ana\u026a / ; Arabic : \u0633\u064a\u0646\u0627\u0621\u200e S\u012bn\u0101\u02bc", "to stay, abide", "Las Vegas Boulevard, commonly referred to as the Las Vegas strip, or the strip, is where many of the flashier and best known casinos operate.", "Jackson Pollock", "Lyrical", "McComb, Mississippi", "October 4, 1970", "King Duncan", "Brasstown Bald", "thimble", "\"to choose, select\" (take the long way home) late... event, at a gambling casino"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4675962894712895}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, true, true, false, false, false, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.27027027027027023, 1.0, 1.0, 0.0, 0.07407407407407408, 0.6666666666666666, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.1111111111111111, 0.0, 0.4, 0.888888888888889, 1.0, 0.8, 1.0, 0.1818181818181818, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.16666666666666669, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8068", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1434", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_triviaqa-validation-1422", "mrqa_triviaqa-validation-1677", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-1982", "mrqa_searchqa-validation-11832", "mrqa_searchqa-validation-9476"], "SR": 0.390625, "CSR": 0.5709134615384616, "EFR": 0.6923076923076923, "Overall": 0.6316105769230769}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "pro-democracy activists", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot", "Hong Kong's Victoria Harbor", "2002", "seven", "the legitimacy of that race.", "the sight of celebrity pontificating about the plight of the environment", "three", "Monday", "Scarlett Keeling", "two years", "1980,", "regulators in the agency's Colorado office", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify. Military commission judges also will be able to establish the jurisdiction of their own courts.", "July", "Akshay Kumar", "Graham's wife", "collaborating with the Colombian government,", "\"disagreements\" with the Port Authority of New York and New Jersey,", "June 2004", "Michelle Rounds", "Bowie", "the death of Prince George's County police Cpl. Richard Findley,", "Phil Spector", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "Izzat Ibrahim al-Douri,", "dependable Camry", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March.", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "in his 60s,", "overthrow the socialist government of Salvador Allende in Chile", "Miguel Cotto", "9 a.m.", "the repeal of the military's \"don't ask, don't tell\" policy", "military veterans", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units", "6 - 6 with one win against a team from the lower Football Championship Subdivision ( FCS )", "Bongos", "Superintendent Norman Mullet", "the innermost digit of the forelimb", "1974", "25 million", "Peoria, Illinois", "Hawaii", "large water near the bottom, as deep as 477 m but typically 75-150 m", "Lear", "Ottoman Empire"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6691945207570207}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-9563", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-4159", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.609375, "CSR": 0.572337962962963, "EFR": 0.76, "Overall": 0.6661689814814815}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "John Dillinger,", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen", "Brazil's response to the HIV/AIDS fight has been widely praised and adopted as a model around the world.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Angels", "eight Indian army troopers, including one officer, and 17 militants,", "\"There's no chance of it being open on time.", "Karen Floyd", "14", "in a Starbucks this summer.", "BADBUL", "98", "2008", "near the Somali coast", "Paul Ryan", "state senators who will decide whether to remove him from office", "Dr. Jennifer Arnold and husband Bill Klein,", "Pakistan's combustible Swat Valley,", "South Dakota State Penitentiary", "Iran", "last month's Mumbai terror attacks", "know what's important in life,", "in July", "Both of the 103 children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans,", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "At least 38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "Formagruppen", "fractured pelvis and sacrum", "Wednesday at the age of 95", "abduction of minors", "gun", "Aniston, Demi Moore and Alicia Keys", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "apteka", "Vermont's largest city", "beta blockers"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7599915199974293}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38095238095238093, 1.0, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5333333333333333, 0.3636363636363636, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.3076923076923077, 1.0, 0.6666666666666666, 0.8, 0.0, 0.0, 0.0, 1.0, 0.06451612903225806, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-560", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-2108", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-14535"], "SR": 0.640625, "CSR": 0.5747767857142857, "EFR": 0.9130434782608695, "Overall": 0.7439101319875776}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "rule", "1981", "forgery and flying without a valid license,", "comments he made after his new boss, golffer Adam Scott, defeated Woods at the Bridgestone Invitational in Ohio in August.", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "Genocide Prevention Task Force.", "if they persist and go forward, we will take it up in appropriate channels.\"", "semiconductors", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "13", "\"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has", "Anil Kapoor.", "the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "\"The Rosie Show,\"", "Form Design Center.", "the guerrillas detained and \"executed\" eight people on February 6 in the town of Rio Bravo because the Indians were gathering information about the rebels to give to the Colombian military.", "Christianity and Judaism", "the Dalai Lama's current \"middle way approach,\"", "Russia", "8 p.m. local time Thursday", "Passers-by", "one day,", "executive director of the Americas Division of Human Rights Watch,", "an estimated 750 hostages in Colombia.", "nearly 100 people", "Matthew Fisher", "The Ski Train", "Boys And Girls alone", "brewer", "AbdulMutallab,", "attracted some U.S. senators who couldn't resist taking the vehicles for a spin.", "inconclusive", "about 5:20 p.m. at Terminal C when a man walked through an exit on the public side to the secure \"sterile\" side for passengers", "environmental and political events", "$250,000", "byproducts emitted during the process of burning and melting raw materials.", "School-age girls", "a little more than 5,600 people every year, and about 10 percent of those cases are hereditary.", "a million", "Sen. Arlen Specter", "Deutschneudorf,", "new legislation that would let prisons jam cell-phone signals within their walls.", "a deceased organ donor,", "bragging about his sex life", "a vertebral column ( spine )", "January to May 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "Festival of Britain on London's South Bank.", "Douglas Hofstadter", "\"The Dark Tower\" series", "American", "Marmee takes care of her 4 girls while her husband is away serving as an army chaplain in the Civil War.", "Castle Rock", "fish"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6563258853725275}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.9655172413793104, 1.0, 0.1, 0.0, 1.0, 0.4, 0.9565217391304348, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.631578947368421, 1.0, 0.25, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.1935483870967742, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9810", "mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-755", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-229", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_hotpotqa-validation-5376", "mrqa_searchqa-validation-7309", "mrqa_searchqa-validation-9830"], "SR": 0.53125, "CSR": 0.5732758620689655, "EFR": 0.7, "Overall": 0.6366379310344827}, {"timecode": 29, "before_eval_results": {"predictions": ["stagnant", "poison", "438,000", "Marty Ingels", "coaxial", "Pakistan A", "Everbank Field.", "7 members appointed by the chief executive.", "Battle of Dresden", "Arabella Churchill,", "1965", "Charles de Gaulle Airport", "fifth", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Province of Syracuse", "1963", "coca wine", "puzzle", "Knoxville, Tennessee", "Washington, D.C.", "Oryzomyini", "Tom Kartsotis", "November 6, 2009", "Wayman Tisdale", "Mexico", "Srinagar", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500 acres", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Shohola Falls", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Whittlesey's unit", "Floridians", "Virginia", "NBA Slam Dunk Contest", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "Somerset County, Pennsylvania", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes, once in 1954 and again in 1981.", "IB Diploma Program and the IB Career - related Program for students aged 15 to 18", "Richard Parker", "southernmost tip of the South American mainland", "Charlotteton Heston", "allergic reaction", "Peter Townsend.", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist follows the recent theft in Switzerland of two paintings by Pablo Picasso, Bjoern Quellenberg,", "Russia", "peel and devein shrimp", "Australia"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6508276400134954}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.5333333333333333, 0.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.15384615384615383, 0.3157894736842105, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8164", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-4716", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3895", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-4356", "mrqa_naturalquestions-validation-9130", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-4033", "mrqa_searchqa-validation-2585", "mrqa_searchqa-validation-6793"], "SR": 0.578125, "CSR": 0.5734375, "EFR": 0.7407407407407407, "Overall": 0.6570891203703704}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "deforestation", "Prussian army general, adjutant to Frederick William IV of Prussia", "London", "Dave Thomas", "a cooperative where farmers pool their resources in certain areas of activity", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations.", "ten years of probation", "In Pursuit", "Bolton", "Monty Python's Flying Circus", "Kansas City crime family", "Werner Nowitzki", "the Cecil B. DeMille Award honoree", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E", "New Jersey", "Norse mythology", "86,112", "Celtic", "Ouse and Foss", "United States and Canada", "British", "Apatosaurus", "1910", "American", "Frank Thomas' Big Hurt", "\"Polovtsy\"\u2014the name given to the Kipchaks and Cumans by the Rus' people", "Margarine Unie", "Winecoff Hotel fire", "mentalfloss.com", "The Seduction of Hillary Rodham", "2005", "Lambic", "Ubisoft", "Argentina", "Larry Alphonso Johnson Jr.", "Mike Mills", "nuclear weapons", "Joseph E. Grosberg", "Chelsea Does", "276,170", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "The video was filmed along the Californian coast at The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "New York", "American athlete Al oerter", "Aston Villa", "2005", "228", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6968755906255906}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8, 1.0, 1.0, 0.9189189189189189, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-4511", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.59375, "CSR": 0.5740927419354839, "EFR": 0.6923076923076923, "Overall": 0.633200217121588}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "Silent Snow, Secret Snow", "Knott's Berry Farm", "Iowa", "A People's History of the United States", "Nassau", "mollusks", "Dr. Anthony Gallo", "Martin Van Buren", "a network of seven Shinkansen passenger and... in the fleet of France's Train  Grande Vitesse", "Rigoletto", "aardwolf", "Beijing", "Roger Bannister", "Rich Clune", "Death Valley", "Yves Saint Laurent", "Many unique characteristics of caribou set them apart from other members of the cervidae", "a college student at Wittenberg", "the fleet", "Anna Mary Robertson", "Luna", "Neville's Superette", "georgia hjalian", "a bear", "a charleston", "George Harrison", "John Cleese", "a polarized electron source consisting of a 3-electrode photocathode gun and a flashlamp-", "Milton Berle", "george herbert walker bush", "Patrice Lumumba", "lunar module", "a Spanish conquistador", "Dan Marino", "Mars", "a clownfish", "E = mc2", "Guru Pitka", "Las Vegas", "soy", "a butterfly", "heavy drinking", "orangutan", "Baja California", "soothsayer", "Yitzhak Rabin", "Samuel Anoints David", "Gettysburg National Military Park", "Jack Gleeson", "thirteen", "Buddhism", "Jean Bernadotte", "Portugal", "Tom Evans", "Johnson & Johnson", "acidic", "20 March to 1 May 2003", "has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\" leaving them \"vulnerable to disruption,\"", "knocking the World Cup off the front pages for the first time in days.", "12.3 million people worldwide"], "metric_results": {"EM": 0.5, "QA-F1": 0.5255567528735632}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.06896551724137931, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-1768", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-12657", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-13033", "mrqa_naturalquestions-validation-5896", "mrqa_triviaqa-validation-4765", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-3574"], "SR": 0.5, "CSR": 0.57177734375, "EFR": 0.90625, "Overall": 0.739013671875}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62", "Herbert Henry Asquith", "40", "Libya", "Shania Twain", "Sheffield Wednesday", "glucagon", "The New York Yankees", "rapid eye movement", "green, red, white", "Ann Dunham", "Saddam Hussein", "French", "Jim Branning", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New", "Prince Andrew and Sarah Ferguson", "Mercury", "a power factor of one means that the real power is equivalent to the apparent power", "Tom Jones", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "S\u00e3o Paulo", "optimism", "aged 75", "Jennifer Lopez", "1664", "Morgan Choir", "GOREWon", "Downton Abbey", "Martina Hingis", "a prominent Derry sept", "cyclops", "Watch with Mother", "Michael Miles", "Sheryl Crow", "Gulliver's Travels", "Pomona", "Milan", "Mike Skinner", "Appalachian Mountains", "a black Ferrari", "a branch of mathematics", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "Campbell's", "Kirkcudbright", "the soldiers", "cortisone", "providing the basic securities", "Juno", "a typeface", "lungs"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5818452380952381}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, false, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-778", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-6378", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-6656", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.515625, "CSR": 0.5700757575757576, "EFR": 0.6774193548387096, "Overall": 0.6237475562072337}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "Knutsford", "insulin", "a Caesar salad", "Hudson Bay", "florida", "can contribute to other problems such as asthma, sinus or ear conditions, or trouble sleeping.", "abigail Masham", "Getafix", "Brighton", "Belfast", "wind", "fire insurance", "Robin Hood Men in Tights", "West Point", "Andy Warhol", "Spain", "John T. Cable", "Peking", "solar system", "tomato and eggplant", "Moldova", "Mitsubishi", "Dartford Warblers", "Franz Liszt", "Estimate", "a paceline", "clon", "Pet Sounds", "Madness", "Buxton", "discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "Manila", "beaver", "Mel Blanc", "Envy", "Moffitt", "Ellen Morgan", "Phil Woolas", "5000 meters", "racing", "casein", "Newfoundland and Labrador", "crow", "Yellowstone", "St. Thomas", "Philippines", "Hugh Laurie", "Buddhism", "Chris Martin", "Ohio", "Port Melbourne", "\u00c6thelwald Moll", "Scarface", "forgery and flying without a valid license,", "In Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory", "Liza Murphy", "Spock", "Astana", "Andorra, Belgium, Germany, Italy, Luxembourg"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6365327380952381}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-1395", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-1699", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-1620", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-11382"], "SR": 0.609375, "CSR": 0.5712316176470589, "EFR": 0.68, "Overall": 0.6256158088235295}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business", "steppes steppe", "Bologna, Italy", "George Santayana", "opossum", "Alice Cooper", "diastolic", "trumpet", "Peter Kay", "The Cry", "Stockton & Darlington Railway", "Appalachian Mountains", "Herald of Free Enterprise", "ballet", "epic disasters", "george West", "lizard", "Blackburn Lancashire", "Frankie Laine", "The Mystery of Edwin Drood", "pommel horse", "cardinal", "Dick Van Dyke", "Egremont", "Numb3rs", "Francisco de Goya", "phrixus", "Basil Feldman", "Canada", "ink", "soap", "Some Like It Hot", "Mull", "Ireland", "Mike Meyers", "sea horse", "plutonium", "magma", "Passepartout", "welcome", "Norway", "Denmark", "Shrek", "26 miles", "Cleveland Brown", "Heston Blumenthal", "One Direction", "Flint", "Uranus", "Stringer", "Charles Lindbergh", "November 1999", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "beer stein", "Pittsburgh", "Pakistan's High Commission in India", "raising its alert level, while the country's media went into overdrive trying to predict how this oblique and erratic state would respond.", "Hunter S. Thompson", "ballet", "Howard Carter"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6314136904761904}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.32, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-5976", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-4664", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.53125, "CSR": 0.5700892857142856, "EFR": 0.7333333333333333, "Overall": 0.6517113095238094}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "Leonardo da Vinci", "Matlock", "American Civil War", "Ethiopia", "ticks and mites", "Arafura Sea", "wooden Cow", "Euphrates", "Austria", "to make wrinkles in one's face", "Spain", "Carousel", "bullfighting", "Mike Brady, a widowed architect", "Tenor", "meat", "fidelio", "Guys and Dolls", "Julian Fellowes", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "Ghana", "sandstone Trail", "L. Pasteur", "jane fonda", "rachmaninoff", "Finland", "stars with gravity", "Mille Miglia", "caves", "blackboard Jungle", "silver", "Muriel Spark", "Happy Birthday to You", "seven", "opossum", "Pickwick", "presliced bread", "The Bridge", "raven", "jordan", "genetically engineered", "nelsons", "Etruscans", "Ken Burns", "Hyde Park Corner", "Great Britain", "e. T. A. Hoffmann", "Mujib", "Libra", "Donna", "season four", "the atrioventricular node, along the Bundle of His and through bundle branches", "yubin, Yeeun", "tomato", "senate election in Minnesota, 2002", "workers' hiring of hundreds of foreign workers for a construction project at the Lindsey oil refinery in eastern England.", "L'Aquila earthquake", "March 24", "sesli Szlk", "September", "Pocahontas"], "metric_results": {"EM": 0.5625, "QA-F1": 0.61171875}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.33333333333333337, 0.08333333333333333, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3182", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_naturalquestions-validation-1091", "mrqa_hotpotqa-validation-1247", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228"], "SR": 0.5625, "CSR": 0.5698784722222222, "EFR": 0.75, "Overall": 0.6599392361111112}, {"timecode": 36, "before_eval_results": {"predictions": ["Americans", "Kim", "Acacias", "branson", "Gordon Ramsay", "Manchester City", "Robert Kennedy", "nitrogen oxides", "Margot Betti", "Manchester Airport", "Portuguese", "Travelocity", "The Avengers", "thrifton", "comets", "Paul Simon", "disciples", "canola", "Tina Turner", "Benjamin Barker", "Arsenal", "Bolivia", "John Donne", "Uranus", "Rio Grande", "Percheron", "The Graduate", "US", "Ginger Rogers", "James I", "One Foot in the Grave", "Bronx Mowgli", "Bob Anderson", "George Santayana", "Finger Tab", "wales", "Wee Jimmy Krankie and his father", "tasan de torquemada", "Daniel Barenboim", "Canada", "a Cuba trapped in a time long forgotten", "Lake Union", "ghee", "George III", "ed Sheeran", "a figure of speech consisting of words that imitate the sounds associated with the objects or actions they refer to", "black clay pipe", "June", "David Graham", "Ceylon", "Screwdrivers", "Kansas City Chiefs", "G minor", "My Summer Story", "1974", "Nightmares", "Amberley Village", "lack of a cause of death and the absence of any soft tissue on the toddler's skeletal remains", "President Obama", "kerstin and the two parts of her family", "cixi", "Brigham Young", "month of June", "chalk quarry"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5282118055555556}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, true, true, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.25, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-422", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-4040", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_hotpotqa-validation-5545", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-2849"], "SR": 0.484375, "CSR": 0.5675675675675675, "EFR": 0.6666666666666666, "Overall": 0.617117117117117}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "the roofs of the choir side - aisles", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "49 cents", "1876", "geologist James Hutton", "17.69278 \u00b0 N 17.44667 \u00b0", "joy of living", "420", "George Strait", "the slogan used to describe the six nations that have had sovereignty over some or all of the current territory of the U.S. state of Texas", "1990", "Shawn", "Kiss", "January to May 2014", "Los Angeles", "September 28, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "By 1770 BC", "Niveditha, Diwakar, Shruti", "two parties", "Jane Lynch", "mitochondria or chloroplasts", "Anakin", "Travis Tritt and Marty Stuart", "1983", "the Bee Gees", "Matt Czuchry", "Pradyumna", "compulsory registration of births with the United Kingdom government", "On the west", "Psychomachia", "the New Jersey Devils of the National Hockey League ( NHL ) and the Seton Hall Pirates men's basketball", "two", "0.30 in ( 7.6 mm )", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Lisa Stelly", "the Hudson Bay", "The Maginot Line", "France", "Dumbo", "purple", "Charles Guiteau", "Gettysburg Address", "iTunes, iTunes Radio, and iTunes Music", "$273 million", "India", "Jeddah, Saudi Arabia", "Desperate Housewives", "Cannonball Run", "chilpancingo", "Tuesday"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7263283876627067}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, true, false, true, false, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.32000000000000006, 0.0, 0.0, 1.0, 0.9523809523809523, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.6, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.25, 0.7272727272727273, 1.0, 0.3333333333333333, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-4028", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-7642", "mrqa_hotpotqa-validation-5119", "mrqa_searchqa-validation-2335"], "SR": 0.609375, "CSR": 0.5686677631578947, "EFR": 0.72, "Overall": 0.6443338815789473}, {"timecode": 38, "before_eval_results": {"predictions": ["Isaac Newton", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in the pancreas", "Joseph M. Scriven", "Lady Gaga", "Chicago metropolitan area", "president", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "Notts County", "nobiliary particle", "Stephen A. Douglas", "1984", "a loanword", "Pakistan", "2018", "Tagalog", "Bryan Cranston", "thylakoid membranes", "a mental disorder characterized by at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "Wake County", "late 1922", "18 Divisional Round", "602", "stable, non-radioactive rubidium", "Membership is believed to cost between $10,000 and $30,000", "the studies and developments department of the French firm R2E Micral", "1931", "University of Oxford", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "Southern Cause", "Randy", "the Infamy Speech of US President Franklin D. Roosevelt", "Joseph Stalin", "into the intermembrane space", "tectonic", "Idaho", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "Sir John Major", "Roddy Doyle", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below", "Henry Ford", "David McCullough", "Rendezvous with Rama", "CERN", "Portugal"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6015270881079704}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, true, false, true, true], "QA-F1": [1.0, 0.09523809523809525, 0.0, 1.0, 0.5, 0.6363636363636364, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 0.4, 1.0, 0.4, 0.4666666666666666, 0.3333333333333333, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-2743", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-3219"], "SR": 0.515625, "CSR": 0.5673076923076923, "EFR": 0.8064516129032258, "Overall": 0.686879652605459}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "ATP, generated by the root respiration", "Philippe Petit", "Sicob show in Paris", "January 2004", "southwest and along the Yangtze ; it is planted in March to June and harvested in October and November and also contributed about 34 percent to total rice output in the 1980s", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "heavy metal", "March 12, 2013", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "XXXX", "Gestaltism", "53", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Cymbre Walk", "Richard Crispin Armitage", "Brooks & Dunn", "Dirk Benedict", "Bonnie Aarons", "late 2018 or early 2019", "interstellar medium", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "John F. Kelly", "Santiago Ram\u00f3n y Cajal", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "1960s", "is a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Tad '' Stone", "Mark Jackson", "Michael Buffer", "one faith, one baptism, one God and Father of all, who is over all and through all and in all", "on location", "federal government", "New England", "Cody Fern", "the name of the war, the tariff", "prophets and beloved religious leaders", "saliva", "Juan Manuel de Ayala", "Prophet Joseph Smith, Jr.", "funny Folks", "1909", "John Duigan", "179", "Princess Diana", "Mikkel Kessler", "curfew", "Pearl", "spiny dogfish", "Fast Food Nation", "ABBA"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5837456059942473}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, true, false, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.1212121212121212, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.4347826086956522, 0.3076923076923077, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4444444444444445, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.17142857142857143, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.7499999999999999, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-302", "mrqa_searchqa-validation-8323"], "SR": 0.46875, "CSR": 0.56484375, "EFR": 0.7352941176470589, "Overall": 0.6500689338235295}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"His treatment met the legal definition of torture. And that's why I did not refer the case\" for prosecution.", "eight Indian army troopers, including one officer, and 17 militants", "piers Morgan", "breast self-examination", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "Zimbabwe President Robert Mugabe", "two weeks ago", "NATO", "Switzerland", "Monday", "second", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "he wants to spend billions to revitalize the nation's economy, a plan the campaign of his likely Republican opponent said would slow economic growth with higher taxes", "T.I.", "state of baja", "Robert Barnett", "$627", "41", "Nick Adenhart", "a strict interpretation of the law", "Derek Mears", "sylt", "rural Tennessee", "Tuesday afternoon", "southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "all faiths", "Ali Bongo", "The Transportation Security Administration", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "two pages -- usually high school juniors who serve Congress as messengers", "A Brazilian supreme court judge", "all the actors", "Operation Crank Call", "help rebuild the nation's highways, bridges and other public-use facilities", "East Java", "SSM Cardinal Glennon Children's Medical Center", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2019", "P.V. Sindhu", "Mexico", "Snickers candy bars", "monoceros", "abbot", "Anaheim, California", "uncle", "Bergen", "embalming", "Cartagena", "a graphical user interface", "German Shepherds have a two - layer coat which is close and dense with a thick undercoat"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6575892631053888}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 0.47058823529411764, 0.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.4, 0.3870967741935484, 0.13953488372093023, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 1.0, 1.0, 0.9523809523809523, 0.3076923076923077, 0.4, 0.0, 1.0, 0.9411764705882353, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5384615384615384, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.5, 0.10526315789473682]}}, "before_error_ids": ["mrqa_newsqa-validation-3817", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-3209", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.46875, "CSR": 0.5625, "EFR": 0.7647058823529411, "Overall": 0.6636029411764706}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "1890s", "Stephen A. Douglas", "1998", "displacement", "the modern state system", "Megan Park", "the currency used by the institutions of the European Union", "Kate Walsh", "September 14, 2008", "Trace Adkins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51 war against Khmelnytsky Uprising in Ukraine", "2002", "they find cool, dark, and moist areas", "pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "international aid as one of the largest financial inflows to developing countries", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "combination of interspecific hybridization and parthenogenesis", "David Joseph Madden", "1902", "the Dutch figure of Sinterklaas", "Yuzuru Hanyu", "to provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "A firm, flexible cup - shaped device worn inside the vagina to collect menstrual flow", "pigs", "General George Washington", "Spanish", "Virgil Tibbs", "an integral membrane protein that builds up a proton gradient across a biological membrane", "the sinoatrial node", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements )", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "Intertropical Convergence Zone ( ITCZ )", "Missouri River", "the right to be served in facilities which are open to the public", "frontal lobe", "10 June 1940", "Tandi", "Alberich", "the middle ear", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "the project, which is designed to promote private sector investment in a variety of gas-related industries, on September 21.", "Denver, Colorado.", "Provincial Reconstruction Team for the Sadr City and Adhamiya districts of Baghdad City", "the United States", "Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6560816102756892}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5263157894736842, 0.6666666666666666, 0.7000000000000001, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-2387", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_triviaqa-validation-2114", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518", "mrqa_searchqa-validation-1237"], "SR": 0.53125, "CSR": 0.5617559523809523, "EFR": 0.8333333333333334, "Overall": 0.6975446428571428}, {"timecode": 42, "before_eval_results": {"predictions": ["Egypt", "vaporization of water also absorbs heat ; it thereby cools the smoke, air, walls, and objects that could act as further fuel", "in Middlesex County, Province of Massachusetts Bay", "chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "its population", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "to bring", "Foreign minister Hermann M\u00fcller and colonial minister Johannes Bell", "Ceramic art", "the Soviet Union's 1976 achievement of thirteen gold medals", "Covington, Kentucky", "New Mexico", "reduces the back pressure, which in turn reduces the steam consumption, and thus the fuel consumption", "December 15, 2017", "Paradise, Nevada", "L.K. Advani", "differential erosion", "Glenn Close", "Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "electricity generation, power distribution, and power transmission on the island", "Tsetse can be distinguished from other large flies by two easily observed features", "Norman Greenbaum", "notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "compasses", "Charlotte Thornton", "the Northeast Monsoon or Retreating Monsoon", "March 16, 2018", "President Lyndon Johnson", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "reproduces by producing an egg through parthenogenesis", "1926", "Durban, South Africa", "starting in 1560s", "Frankie Muniz", "Lou Rawls", "between 1765 and 1783", "Thor", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "two", "prostate cancer", "wyvern", "Lord Fauntleroy", "a rabbit with a fob", "yellow"], "metric_results": {"EM": 0.46875, "QA-F1": 0.61909120248964}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [0.6666666666666666, 0.0, 0.5384615384615384, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 0.9, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.09090909090909093, 1.0, 0.8, 0.14814814814814814, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 0.0625, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5611", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.46875, "CSR": 0.559593023255814, "EFR": 0.7058823529411765, "Overall": 0.6327376880984952}, {"timecode": 43, "before_eval_results": {"predictions": ["1985", "February 27, 2007", "pick yourself up and dust yourself off and keep going", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "Blue with a harp of gold", "Miami Heat", "1981", "As late as the 1890s, building regulations in London did not require working - class housing to have indoor toilets ; into the early 20th century,", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Augustus Waters", "jules Marey", "Virgil Ogletree", "a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus", "active absorption of water from the soil by the root", "Alex Ryan", "a habitat", "2018", "Advanced Systems Format ( ASF )", "100", "Toledo", "embryo", "the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "Paradise, Nevada", "Alicia Vikander", "annually in late January or early February", "Ashoka", "the name of a work gang", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority ( PREPA )", "Bumblebee", "into the Christian biblical canon", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "armored fighting vehicle", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "during the winter of the 2017 -- 18 network television season on CBS", "New York City", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "Caparra", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "winter", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bonauto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "The federal government has set aside nearly $2 billion in stimulus funds to clean up Washington State's decommissioned Hanford nuclear site, once the center of the country's Cold War plutonium production.", "\"We want to reset our relationship and so we will do it together.'\"", "Michigan", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.4375, "QA-F1": 0.6007339718277218}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 0.8333333333333333, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 0.888888888888889, 1.0, 0.0, 0.5714285714285715, 0.4444444444444444, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.18181818181818182, 0.0, 0.9189189189189189, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.25641025641025644, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-151", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-9723", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-3938", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-2425", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977"], "SR": 0.4375, "CSR": 0.5568181818181819, "EFR": 0.8055555555555556, "Overall": 0.6811868686868687}, {"timecode": 44, "before_eval_results": {"predictions": ["fixed annual carriage fees of \u00a330m for the channels with both channel suppliers able to secure additional capped payments if their channels meet certain performance-related targets.", "aluminum foil", "Laurel, Mississippi", "his writings about the outdoors, especially mountain-climbing.", "Indianola", "life insurance", "the British military on suspicion of being an American sympathizer in the American Revolutionary War.", "1992", "Cher", "eastern", "Jim Harrison", "Toronto", "Tomorrowland", "fennec", "United States Army", "stop motion animation", "Jean Acker", "4,530", "Leucippus", "Caesars Entertainment Corporation", "Mary Ellen Mark", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "Northrop P-61 Black widow", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony awards", "1991\u201392", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "OutKast", "Richard Street", "Democratic Republic of the Congo", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer.", "South America", "2006", "perjury and obstruction of justice", "Operation Overlord", "Mary Elizabeth Hartman", "over 9,000 employees", "Rosalind Bailey", "potential of hydrogen", "Alamodome in San Antonio, Texas", "Carrie", "The Finger Tab", "Kent", "almost 9 million", "Ethiopia", "2008", "'lying under oath'", "Moses", "Chapter 5", "Jeff Barry and Andy Kim"], "metric_results": {"EM": 0.515625, "QA-F1": 0.615779532967033}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, false, false], "QA-F1": [0.07692307692307693, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2837", "mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2933", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_triviaqa-validation-6953", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.515625, "CSR": 0.5559027777777779, "EFR": 0.8064516129032258, "Overall": 0.6811771953405018}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "in September 1903", "the power to regulate interstate commerce", "Naomi Wallace", "Jenson Alexander Lyons", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "King James II of England", "God Save the Queen", "526", "Scotland", "AC/DC", "Gesellschaft mit beschr\u00e4nkter Haftung", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Sully", "Manhattan Project", "Asia-Pacific War", "Romantic", "Hugh Dowding, (24 April 1882 \u2013 15 February 1970)", "AMC Entertainment Holdings, Inc.", "the New York Islanders", "Fennec fox", "1978", "six different constructors taking the first six positions.", "French", "Pacific Place", "the Female Socceroos", "\"Bad Blood\"", "\"SexyBack\"", "5320 km", "Giuseppe Verdi", "Chief Minister of Tamil Nadu", "Sacramento Kings", "Walldorf, Baden-W\u00fcrttemberg", "Fife", "Fyvie Castle", "Aamina Sheikh, Hasan Ahmed, Neelam Muneer, Zaheen Tahira, Ismat Zaidi, Sami Khan and Faisal Qureshi", "the British Army", "power directly or elect representatives from among themselves to form a governing body, such as a parliament.", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Frances Ethel Gumm", "Switzerland", "Model T", "NATO's International Security Assistance Force", "2,000", "Cyprus", "American singer-songwriter, multi-instrumentalist, and actor.", "Saudi Arabia", "Geraldine A. Ferraro", "two"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6220510647440795}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 0.5, 0.5714285714285715, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.3333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.23529411764705882, 1.0, 0.09090909090909091, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-4054", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-1326", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-2129", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-3604", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_triviaqa-validation-6575", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-8327"], "SR": 0.546875, "CSR": 0.5557065217391304, "EFR": 0.7586206896551724, "Overall": 0.6571636056971514}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican National Committee's website address is GOP.com", "1996", "five", "Greenland sharks", "The Word", "President Abraham Lincoln", "St Jude", "Anthoonij van Diemenslandt", "the death penalty in those states.", "xerophyte", "Jackie Robinson", "Staten Island", "Dian Fossey", "MI5", "Harrow", "creme anglaise", "a sauce of lemon juice, parsley, salt, pepper, and drawn butter", "pork", "curling", "Victoria Coren", "Gettysburg", "Chile", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck", "Mercury", "Venus", "Barack Obama", "Canada", "bologna Has a First Name: It's F-O-R-G-T-E-N", "Dominican Republic", "Bowie", "Stephen King", "Hinduism", "caryatid", "feet", "Great Britain returned Manila and Havana to Spain while Spain granted Florida to Great Britain. Great Britain also returned Guadaloupe, Saint Lucia, Goree, Martinique, and Indian trading posts to France.", "Mary Poppins", "Glyn Jones", "Port Moresby", "Connecticut", "Quentin Blake", "whooping cough", "daily paper had been published in the UK for thirty four years.", "(1939\u20131945)", "halal is an Arabic word that means \"permissible.\"", "beginning in 2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1987", "a fan", "Jeddah, Saudi Arabia", "death", "Beatrix Potter", "Dan Eggen and Elizabeth Williamson", "Reader's Digest", "the king"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6139029820985467}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, true, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.06451612903225806, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 0.0, 0.25, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-1660", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-1584", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_hotpotqa-validation-252", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-6488"], "SR": 0.546875, "CSR": 0.5555186170212766, "EFR": 0.896551724137931, "Overall": 0.7260351705796038}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "allergic reaction", "David Beckham", "on Scottish soil took place on a nearby moor at Culloden", "Runic", "Bourbon", "sport of rugby", "Planck", "rotherham United", "conduction", "Misery", "Styal", "stately", "Blind Beggar", "Mr Brainwash", "floroy Burrell (United States)", "parlophone", "Wild Atlantic Way", "John Denver", "Ankh-Morpork", "noddy Goes To Toyland", "Lackawanna 6", "Brazil", "pong", "muezzin", "window", "a ship", "bovary", "Apollo 11", "flit", "Nikola Tesla", "tom h Henderson", "Evita", "sperm whale", "Rocky Graziano", "east fife", "St Pancras International Station", "person", "presliced bread", "Dilbert", "Aristotelian Tragedy", "dimittis", "French", "Medea", "Burgundy", "cribbage", "w/e 17th May 2008", "Johannesburg", "France", "Muffin Man", "Seoul", "Prince James, Duke of York and of Albany ( later King James II & VII )", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Veracruz, Mexico", "Kuwait-based Wataniya Airways", "Robert Frost", "King Henry VIII", "Pueblo", "Mitsubishi Lancer OZ Rally"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6021464646464647}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.18181818181818182, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.888888888888889]}}, "before_error_ids": ["mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-1189", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-5130", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.546875, "CSR": 0.5553385416666667, "EFR": 0.8620689655172413, "Overall": 0.708703753591954}, {"timecode": 48, "before_eval_results": {"predictions": ["Route sixty-six", "sesame Street", "minced tomatoes", "cabbage", "australia", "Mr. Magoo", "chobus", "Ash tree", "marsupials", "New Zealand", "slide whistles", "60", "goldfinger", "1984", "a fish included in the pike family, Esocidae", "Mongol Empire", "1875", "tax collector", "penny", "santara", "Yorkists", "bagram", "maggie", "Chrysler", "fur hat", "korky the cat", "civil law", "United States", "Brazil", "pei Tang", "biathlon", "Idaho Falls", "Charlie Chan", "Vienna", "white", "jaws", "Paul Rudd", "mouse", "Scotland's", "jodhpurs", "Orson Welles", "Sanskrit", "menorah", "Dutch", "Texas", "Super Bowl Sunday", "a quant pole", "Little Tommy Stout", "ravens", "Rhododendron", "Ireland", "Chuck Noland", "Virginia", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park", "2010", "through Greece, the birthplace of the Olympics, before being transported to Canada for what will be the longest domestic torch relay in the games' history,", "10 below", "Nearly all", "turtle", "the American Kennel Club", "Omaha", "George Glenn Jones"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5032188146997929}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false], "QA-F1": [0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913042, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-2687", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-3092", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-5082", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-6306", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-16460", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.4375, "CSR": 0.5529336734693877, "EFR": 0.75, "Overall": 0.6514668367346939}, {"timecode": 49, "before_eval_results": {"predictions": ["sledge", "Iran", "alcohol", "frenchman", "jockey", "Daniel Boone", "Thames Street", "Theodore Roosevelt", "satyrs", "a fish known for being very good to eat.", "La Boh\u00e8me", "IBM", "wishbone", "garrick club", "Lackawanna six", "Barnaby Rudge", "britten", "American Civil War", "dark", "dyan Cannon", "Jimmy Robertson", "Florence", "tsar Ivan IV", "victoria", "Severn", "Australian", "South Africa", "perennial", "Nicaragua", "Churchill", "war of Roses", "Chemnitz", "analytics", "chubs, whitefish, squawfish, rainbows, cutthroats, and bull trout", "ap\u00e9ro", "jane n Norton", "belize", "American Folk Song", "hair loss", "cycling", "Charlie Drake", "Robin Hood's A Holy Grail", "Chris Martin", "flintstone", "George Gently", "rugby", "honda", "deacon Blues", "11", "tobacco", "heifer", "depending upon its supply market finds or sets a value to it that continues to change as the supply of money is changed with respect to the economy's demand", "Tom Selleck", "New Orleans", "both imbued with superhuman abilities after being bitten by radioactive/genetically-altered spiders.", "Texas Tech University", "Loughborough Technical Institute", "Herman Cain", "the United States", "air support", "George Babbitt", "Oklahoma", "ladies who Lunch", "four"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5222966269841269}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, true, false, false, false, true, false, true, false, false, true, false, true, false, false, true, true, false, true], "QA-F1": [0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.07142857142857144, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-3615"], "SR": 0.453125, "CSR": 0.5509375000000001, "EFR": 0.7428571428571429, "Overall": 0.6468973214285715}, {"timecode": 50, "UKR": 0.818359375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.734375, "KG": 0.49140625, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "Kansas", "the Docile Don", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland", "37", "Tufts University", "Owsley Stanley", "\"The Late Late Show\"", "Kongo", "Harold Lipshitz", "Spanish", "Ted", "1945", "69.7 million litres", "Neneh Mariann Karlsson", "Sunyani", "antelope", "Comodoro Arturo Merino Ben\u00edtez International Airport, Santiago, Chile", "Scotty Grainger Jr.", "9", "CR-X", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1898", "Nicolas Winding Refn", "devotional", "Giovanni", "Laban Movement Analysis", "Cecily Strong", "Sam Waterston", "invoicing", "seasonal television specials", "nearly 8 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "playback singer", "1901", "Pope John X.", "BAFTA Award for Best Production Design", "VAQ-135", "Alex Skuby", "American country music group The Nitty Gritty Dirt Band", "English", "'Q'", "FBI", "jug", "EMI", "UNICEF", "9 a.m.", "George Byron", "Van Helsing", "kufic", "a long-range missile"], "metric_results": {"EM": 0.53125, "QA-F1": 0.665470467032967}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, true, true, false, true, false, false], "QA-F1": [0.8, 0.5, 0.5714285714285715, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.5, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4615384615384615, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-5783", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1652", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-7487", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.53125, "CSR": 0.5505514705882353, "EFR": 0.9, "Overall": 0.6989384191176471}, {"timecode": 51, "before_eval_results": {"predictions": ["Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143,007", "Atat\u00fcrk Museum Mansion", "Realty Bites", "24 NCAA sports", "Razor Ramon", "Morita therapy", "Forbes, New South Wales", "St. George, Maine", "Heart", "Lithuanian national team", "International Boxing Hall of Fame", "35", "Conservatorio Verdi", "Lester Ben \"Benny\" Binion", "Smoothie King Center", "World Outgames", "Homebrewing", "Umberto II", "Presbyterian Church", "neuro-orthopaedic", "in their home country", "North Sea", "17 October 2006", "67,575", "Oxford", "\"OS DATA\"", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "English", "Eric Edward Whitacre", "largest Mission Revival Style building in the United States", "180", "George Adamski", "\"Hand of Thrawn\" novels", "Switzerland national team", "McKenna's Fort", "Scunthorpe", "British comedian", "Cook's Landing Place", "Summer Olympic Games", "1942", "1970", "Royal Albert Hall and The Kennedy Center", "Budget Rent a Car System, Inc.", "Japan", "lion", "1959", "Donna Mills", "Is this the feeling I need to walk with / Tell me why I can't be there where you are / There's something missing in my heart", "400 feet ( 122 m )", "Alabama", "Blanche", "maxilla", "Microsoft", "4.6 million", "officialdom and its pronouncements and reaction from activists.", "tea rose", "John Pershing", "black Russian", "Rear Window"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6387801995798319}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, true, true, true, false, true, false, true, true], "QA-F1": [0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.5714285714285715, 0.8, 0.0, 0.5, 1.0, 0.0, 1.0, 0.4, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.5, 1.0, 0.5, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 0.7499999999999999, 1.0, 1.0, 0.5, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1260", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-3576", "mrqa_hotpotqa-validation-673", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653"], "SR": 0.484375, "CSR": 0.5492788461538461, "EFR": 0.6666666666666666, "Overall": 0.6520172275641025}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", ", and differentiating voters from non-voters must have been done", "3 lines of reflection", "up to 100,000 write / erase cycles", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel", "once again be hosted by Camping World Stadium in Orlando", "Advanced Systems Format ( ASF )", "the Ramones", "Al Pacino", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "Gospel of Matthew", "30 years after Return of the Wars", "a leonine contract, a take - it - or - leave - it contract, or a boilerplate contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1960", "The British colonial government fell in the region of modern Nova Scotia after several disastrous campaigns in 1757", "1972", "Columbia River Gorge", "coercivity", "2010", "malicious software", "Cyndi Grecco", "differs in ingredients", "1900", "dorsally on the forearm", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "Terry Kath", "birch", "one person", "The Parlement de Bretagne", "password recovery tool for Microsoft Windows", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "September 1995", "late - September through early January", "currency option", "1623", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas", "the medulla oblongata", "2018", "Gibraltar, a British Overseas Territory, located at the southern tip of the Iberian Peninsula", "Howard Caine", "May 3, 2005", "Andy Cole", "patch", "comedy playhouse", "Gerry Adams", "teenage actor or teen actor", "Saoirse Ronan", "Revolution Studios", "The Kirchners", "north London rivals Tottenham", "Gordon Brown", "veterans", "yellow fever", "winter", "Netflix"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6868478641456583}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.3137254901960785, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.4, 0.058823529411764705, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-49", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-1203", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-3959", "mrqa_triviaqa-validation-1896", "mrqa_triviaqa-validation-364", "mrqa_hotpotqa-validation-3162", "mrqa_newsqa-validation-318", "mrqa_searchqa-validation-4527"], "SR": 0.59375, "CSR": 0.5501179245283019, "EFR": 0.7692307692307693, "Overall": 0.6726978637518142}, {"timecode": 53, "before_eval_results": {"predictions": ["Alston", "Model of cosmology", "Handel", "Green Acres", "daily gourmet lifestyle and food magazine", "Clark Coconut Zagnut", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Eagle Airlines", "her coronation", "Vermont", "Calvin Coolidge", "candy store", "salmon", "pudd'nhead Wilson", "Kuala Lumpur", "tapir", "France", "Spam", "Hector Berlioz 7", "When these are less than 5 minutes apart & last about a minute, you'll know they are 11 minutes apart.", "a small cylindrical goat cheese", "Tuesday", "Dragon", "centaur", "Mentor", "commander of the Lebanese armed forces", "Manifest Destiny", "Al Gore", "unique access technologies", "Bali", "\"The Streets of Philadelphia\"", "Cyprus", "glucosamine", "Madagascar", "works that had a major impact", "a celebration, stunt, spectacle", "busby", "Susan Faludi", "Dr. Dre", "Al Lang Stadium", "Fidel Castro", "fudge", "Transcontinental Railroad, 4.0, 0.5, 70789", "Service Employees International Union", "goldfish", "auxin", "a dive in which the diver bends in midair to touch the toe, keeping the legs straight, and then... Verb, 1. jackknife - dive into the water bending the body at the waist at a right", "yellowtail", "Nitrides of boron & silicon are used to make crucibles", "between the Mediterranean Sea to the north and the Red Sea in the south", "Tokyo", "Zeus", "Van Morrison", "antelope", "beverage distribution system", "Rocky Mountain Institute", "21", "stolperstein", "nearly 2,000", "insurgent small arms fire", "3,000 kilometers (1,900 miles)", "Lambic"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5529761904761905}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false, true, true, true, false, false, true, true, false, false, true, true, false, false, true, false, false, true, false, false, true, true, true, false, false, true, true, true, false, false, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.07142857142857142, 1.0, 0.0, 0.9, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-7039", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-7425", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1851", "mrqa_searchqa-validation-2596", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-1108", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-7952", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_searchqa-validation-379", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-1000", "mrqa_triviaqa-validation-7747", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-1792"], "SR": 0.46875, "CSR": 0.5486111111111112, "EFR": 0.8235294117647058, "Overall": 0.6832562295751634}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "state legislators of Assam", "in a nearby river bottom", "stems and roots of certain vascular plants", "Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas ''", "1987", "John F. Kennedy", "in teaching elocution", "on the Isle of FERNANDO 'S!, a fictional location based in Puerto de la Cruz, Tenerife", "seven", "1999", "Rashida Jones", "Hook", "Bush", "tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai", "approximately 11 %", "Bell Labs, his rival", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "1998", "Guy Berryman", "Ming dynasty", "for the red - bed country of its watershed", "Thomas Jefferson", "The Intolerable Acts", "National Industrial Recovery Act", "semi-autonomous organisational units within the National Health Service in England", "Jeff Gillen", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg", "1885", "San Francisco, California", "Zeebo", "Somatic motor neurons", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps, McGregor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "Philippines", "driving Miss Daisy", "Goddess of Revenge", "Marine Corps Air Station Kaneohe Bay", "PlayStation 4", "December 5, 2015", "Seminole Tribe", "Defense of Marriage Act", "Alinghi", "Eiffel Tower", "barnacles", "dog", "Christian"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6591998118410658}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.4615384615384615, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-4645", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.546875, "CSR": 0.5485795454545455, "EFR": 0.6896551724137931, "Overall": 0.6564750685736677}, {"timecode": 55, "before_eval_results": {"predictions": ["Edward III", "golf", "purple", "a pianoforte", "Ascot", "Litas", "Loretta Lynn", "Survivor Series", "Born to Be Wild", "chop suey", "Ross MacManus", "Coronation Street", "TV Tropes", "South Africa", "Saddam Hussein", "New Zealand", "Mediterranean", "Bobby Sands", "mauritania", "Hans Lippershey", "Bolivia", "Bob Giraldi", "Mozambique Channel", "ash", "Edward VII", "Edward VI", "testicles", "Guatemala", "muralitharan", "Caroline Aherne", "Byron", "S\u00e8vres", "Mau Mau", "Kipps: The Story of a Simple Soul", "gums", "Serena Williams", "capital of Togo", "Pegida", "Alberich", "Utrecht", "1709", "Mitford sisters", "Kansas", "Miles Morales", "vine plagues", "Skylab", "ostrich", "Hugh Quarshie", "a boat", "Batman", "korea", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jack Ridley", "Linux Format", "Stage Stores", "26", "it would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Shanghai", "Kool-Ade", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6145833333333334}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-5428", "mrqa_triviaqa-validation-4809", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-5391", "mrqa_searchqa-validation-4261"], "SR": 0.609375, "CSR": 0.5496651785714286, "EFR": 0.6, "Overall": 0.6387611607142857}, {"timecode": 56, "before_eval_results": {"predictions": ["France", "Bolivia", "The Telegraph", "liver", "Portugal", "Drunk", "Galway Bay", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "George Eliot", "Standing at the north-west corner of the central business district", "koftas", "Benazir Bhutto", "bowler", "Sam Mendes", "Tara King", "way back Attack", "eight", "mustelids", "godiva", "darius danesh", "Mexico", "Towy", "katia", "1984", "New York", "one", "Shintoism", "Sussex County", "George III", "Mickey Mouse", "oxygen", "Prince Albert", "Talavera de la Reina", "quietly", "Dodoma", "radiohead", "Wilson", "Loch lomond", "Pyrenees", "south Korea", "gelatine", "Papua New Guinea", "the Suez Canal", "North Yorkshire", "a\u00e9roport roissy-Charles de Gaulle", "Sankt Moritz, Switzerland", "French Revolution", "old Kent Road", "one of the Vikings nine realms", "An acetate / \u02c8\u00e6s\u026ate\u026at /", "iron", "Johnson", "Chris Pine", "Yorgos Lanthimos", "Tottenham ( ) or Spurs", "one of the shocks of the year", "off Somalia's coast.", "Shanghai", "cape", "Pershing", "governess", "a Maine politician"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6140625}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333]}}, "before_error_ids": ["mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-1331", "mrqa_triviaqa-validation-5070", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-501", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_hotpotqa-validation-4052"], "SR": 0.53125, "CSR": 0.549342105263158, "EFR": 0.8666666666666667, "Overall": 0.6920298793859649}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "michelle helborn", "micelles", "lee", "Rudolf Nureyev", "Jessica", "placebo", "weather", "lake placid", "Vatican City as a sovereign and independent papal state", "contractions", "William Boyd", "Cecilia", "karolina mladenovic", "Morecambe & Wise", "maggie Gilkeson", "butcher", "variolae vaccinae", "fox hunting", "Stockholm", "France", "vertigo", "sense of smell", "Lunar Prospector probe", "chemnitz", "rue", "yellow", "raven", "caracas", "Ennio Morricone", "British", "chancel gaunt", "timesigns", "turandot", "dRC", "mauna Kea", "eat porridge", "Howard Keel", "marriage", "boutros Ghali", "Germany", "Sinclair Lewis", "western or southern border of the Texas counties of El Paso, Hudspeth, Presidio, Brewster (where the river's sweeping curve gives Big Bend National Park its name)", "Garden of Gethsemane", "decision tree", "2", "knowledge", "France", "Kristiania", "keirin", "selenium", "an vehicle that is both four - wheel - drive and primarily a road car", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "Michael Jackson's comeback concerts in London have been postponed until next year because producers can't be ready in time for the July debut,", "a group of college students of Pakistani background", "Perseid", "accordion", "films", "michelle wahlberg"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6020833333333333}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, false, true, true, false, false, true, true, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5042", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-883", "mrqa_triviaqa-validation-4653", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-7431", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-7268", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-2091", "mrqa_triviaqa-validation-4990", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-4857", "mrqa_naturalquestions-validation-10066", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-2238", "mrqa_searchqa-validation-15487", "mrqa_searchqa-validation-16209"], "SR": 0.515625, "CSR": 0.548760775862069, "EFR": 0.7741935483870968, "Overall": 0.6734189898498331}, {"timecode": 58, "before_eval_results": {"predictions": ["rubbings", "Jonah", "Hughe", "city of Constantinople", "Jacqueline Susann", "Bolivia", "Hudson River", "bones", "Nassau's all-night party Junkanoo parade", "Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "rubies", "deep Woods", "Siberia", "louis p Pitt the Younger", "five", "Friday the 13th", "largest city in New Hampshire", "Godfather", "UVB", "Nostradamus", "jihad", "harpoons", "mandy manilow", "financial services", "Conrad Hilton Jr.", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "the enemy line", "bald eagle", "menudo", "Panax", "hurricanes", "sons", "Kashmir", "airport", "nu", "TriviaBistro.com", "statistic", "Journey Under the Sea", "brothers", "lethal", "me", "beryl", "dome", "19 July 1990", "Incudomalleolar joint", "Louis XV", "Malawi", "Mansion House", "senior", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Auckland", "becoming bald or fear of being around bald people."], "metric_results": {"EM": 0.5, "QA-F1": 0.5610119047619048}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-3868", "mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-11218", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-16487", "mrqa_searchqa-validation-3807", "mrqa_searchqa-validation-5458", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225", "mrqa_triviaqa-validation-2596"], "SR": 0.5, "CSR": 0.5479343220338984, "EFR": 0.875, "Overall": 0.6934149894067796}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "Jeopardy", "distillation", "Leonard Bernstein", "magnesium", "Attendolo", "Danube", "the albatross", "\"Se sitcom\"", "the Smashing Pumpkins", "words", "Ohio State", "Sherman", "Pakistan", "Theology of God", "Leinster", "Sally Field", "Barbara Cartland", "rum", "a Pringles can", "Paul Hamm", "profundo", "Shushenskoye", "Nimble", "Forrest Gump", "Clue", "a pair of black magpies", "#5367", "alternating current", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "Marshall", "General Motors", "Saint Vincent", "ambassador to Vietnam", "silk", "W", "Unicorn", "Scrabble", "humerus", "Saturday Night Fever", "Petruchio", "Philippines", "mushrooms", "Ernesto Che Guevara", "Yale University", "Oscar Wilde", "Aphrodite", "Dian Fossey", "a map", "an iron -- nickel alloy and some other elements", "ABC", "a legal case in certain legal systems", "pear", "Melbourne", "The Big Bopper", "Ringo Starr", "Do Kyung-soo", "Hanna", "Majid Movahedi", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "\"We take this issue seriously,\"", "Priam"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6427083333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-9674", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-116", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-12241", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-10544", "mrqa_searchqa-validation-16858", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-4918", "mrqa_searchqa-validation-15230", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777"], "SR": 0.578125, "CSR": 0.5484375, "EFR": 0.8148148148148148, "Overall": 0.6814785879629629}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "close to 50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Carlos Almeida da Cunha", "four", "Sippin' on Some Syrup", "A Nero Wolfe Mystery", "Arnold", "Sami Brady", "the University of Kentucky", "five", "Gust Avrakotos", "Sim Theme Park", "a facelifted 850 saloon", "its riverside location", "1950s", "Julie Taymor", "actress", "James Edward Kelly", "Spanish", "Indiana University", "lower Manhattan", "Homeland", "2016", "American Airlines", "green and yellow", "Champion Jockey", "March 2012", "Tom Courtenay", "Erinsborough", "2015", "Vladimir Valentinovich Menshov", "The Birds", "Londonderry", "York County, Maine", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "1949", "Savannah River Site", "\u00c6thelred I", "God", "Swiss", "Emperor Augustus", "World War I", "October 4, 1970", "Clayton Mark's", "five", "Rodney Crowell", "invisible `` factors ''", "near major hotels and in the parking areas of major Chinese supermarkets", "scales", "d\u00fcsseldorf", "Apollo", "Anil Kapoor", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "Arthur E. Morgan III", "quarantina", "the Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6211538461538462}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, false, false, false, true, true, false, true, false, true, false, true, false, false, true, false, true, true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.0, 1.0, 0.8, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.15384615384615383, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-5741", "mrqa_hotpotqa-validation-3314", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3132", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-5717", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-3666", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.53125, "CSR": 0.548155737704918, "EFR": 0.8666666666666667, "Overall": 0.6917926058743169}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaels", "Chicago Bears", "girls aged 11 to 18", "Taylor Swift", "Adolfo", "Freeform", "Cartoon Network", "1983", "Rio Gavin Ferdinand", "264,152", "2,664", "841", "Cher", "Australian Broadcasting Corporation (ABC)", "MG Car Company Limited", "Walt Disney and Ub Iwerks", "1979", "15", "1898", "Larry Lucchino", "Bolton", "Argentinian", "Them", "137\u201373", "John Snow", "New York and New Jersey campaign", "2013\u201314", "Melbourne Storm", "University of Nevada, Las Vegas", "21", "dziga Vertov", "Friday", "Oklahoma Sooners", "2012", "7pm", "1866", "Gaahl", "Serie B", "1887", "Isabella (Belle) Baumfree", "RAF Tangmere, West Sussex", "North Holland", "Don Bluth", "Golden Calf", "Furious 7", "the final of 2011 AFC Asian Cup", "Julia Kathleen McKenzie", "Mercer", "1951", "35,124", "154 days", "September 30", "James P. Flynn", "the Western Bloc ( the United States, its NATO allies and others )", "his finger", "President Barack Obama", "Bacofoil", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "protecting 50,000 jobs in the last 18 months and would continue to shed jobs without this program.", "forcibly drugging", "James Watt", "T.S. Eliot", "ANastasia", "Games"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6206358924839528}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 0.3636363636363636, 0.6666666666666666, 0.4, 0.0, 0.2666666666666667, 0.06896551724137931, 0.25, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-4233", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-826", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-5180", "mrqa_triviaqa-validation-7611", "mrqa_triviaqa-validation-7564", "mrqa_triviaqa-validation-6998", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129"], "SR": 0.515625, "CSR": 0.5476310483870968, "EFR": 0.7741935483870968, "Overall": 0.6731930443548386}, {"timecode": 62, "before_eval_results": {"predictions": ["the \"Acad\u00e9mie royale d'architecture\"", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode", "the Processional Way", "a card (or cards) during a card game", "water", "Sean Yseult", "law", "October 5, 1937", "Hillsborough County", "Charles Nungesser", "Burning Man", "Love Streams", "Group Captain Peter Townsend", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "Somerset County, Pennsylvania", "John Nicholas Galleher", "German", "Gareth Jones", "consulting", "April", "1978", "actor, producer, and director", "Melanie Owen", "1983", "Gujarat", "143,007", "May 4, 1924", "jewelry designer", "Axl Rose", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "Mountbatten family", "dice", "Kal Ho Naa Ho", "Dungeness", "Lancashire", "25 October 1921", "Canadian comedian", "Martin O'Neill", "Stratfor", "Reginald Engelbach", "American", "Black Friday", "Minneapolis", "Jean Erdman", "5.7 million", "during Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard Seddon", "the heart", "San Antonio", "to take the Rio Group to a new level by creating the organization.", "the unveiling of a plaque at the home of his great-grandfather and by making Ali the first honorary \"freeman\" of the town.", "Bob Bogle", "circumference", "Silk Road", "a shooting-brake", "2001"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6426880411255411}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-515", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-2535", "mrqa_hotpotqa-validation-5232", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-197", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-7093", "mrqa_searchqa-validation-12404"], "SR": 0.53125, "CSR": 0.5473710317460317, "EFR": 0.8, "Overall": 0.6783023313492064}, {"timecode": 63, "before_eval_results": {"predictions": ["the of", "a pair of 1981 datings", "The Pound of flesh", "The largest", "the beluga whale", "Vladimir Cyrillovitch", "tuna", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "Mendoza", "Mjollnir", "Orange", "astride", "Borneo", "Bastille", "The", "Raleigh", "whipped cream", "tuna", "King Duncan", "Jean-Michel Basquiat", "Led Zeppelin", "The Hidden Blade", "Dutchman", "The Talk of Tv", "the outskirts of a small Southern town", "Lieutenant", "John Tyler", "Milwaukee", "the Epistle", "Wall Street", "sake", "Notre Dame", "The Port of Portland", "The Marquis de La Fayette", "The Indianapolis 500", "Toy Story", "improv", "Sarah Jessica Parker", "13-letter collective name for any & all forms of water", "Boris Godunov", "Oscar Wilde", "Captain William Bligh", "weaving", "Pope John Paul II", "Greenland", "John", "The Marx Brothers", "watermelon", "Phillip Schofield and Christine Bleakley", "duodenum", "Reverend J. Long", "violin", "sexual imagination", "a mountain peak", "Garrett Morris", "The Beatles' 1966 US tour", "12 mi east-southeast of Bridgeport", "Susan Atkins", "almost 9 million", "Three thousand", "al-Maliki"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5359002976190476}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false, false, false, true, true, false, false, false, true, false, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5714285714285715, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.28571428571428575, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-13774", "mrqa_searchqa-validation-16653", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-12387", "mrqa_searchqa-validation-6512", "mrqa_searchqa-validation-9768", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-7670", "mrqa_searchqa-validation-15074", "mrqa_searchqa-validation-14769", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-16930", "mrqa_searchqa-validation-8527", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-8555", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-9337", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.46875, "CSR": 0.546142578125, "EFR": 0.7352941176470589, "Overall": 0.6651154641544117}, {"timecode": 64, "before_eval_results": {"predictions": ["the most gigantic pumpkins in the world", "Seminole Tribe", "billions of dollars in Chinese products each year,", "green-card warriors", "228", "love and loss", "2005", "contaminated groundwater, hundreds of buildings used for plutonium enrichment that need to be torn down, and underground tanks that are full of radioactive sludge.", "consumer confidence", "Fernando Gonzalez", "southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "The pilot, whose name has not yet been released,", "Jared Polis", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah, overloading", "Russia", "Ali Larijani", "Sunday", "her husband and her abductors", "France", "41,280", "be silent", "iTunes", "Kenya invoked the U.N. charter allowing military action in self-defense against its largely lawless neighbor.", "\"gotten the balance right\"", "100 to 150", "10", "Quiet Nights", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "Iran and Egypt", "123 pounds of cocaine and 4.5 pounds of heroin", "engineering and construction", "grabbed the gun and  took her own life.", "fractured pelvis and sacrum", "five", "to step up", "12 years after the discovery of Hettrick's stabbed and sexually mutilated corpse in a field near his trailer.", "Paris", "Mashhad", "summer", "only one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda", "Garth Brooks", "Oxbow", "an Iranian court", "different women coping with breast cancer", "Michael Schumacher", "Luiz Inacio Lula da Silva", "the release of the four men", "2006", "12.9 - kilometre ( 8 mi )", "Tim Passmore", "Theodosius I", "David Pearson", "Estonia", "not unusual", "Anne Elizabeth Alice Louise", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Hipparchus", "President Woodrow Wilson", "the middle"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5837963799723669}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5555555555555556, 0.2222222222222222, 1.0, 0.21052631578947367, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.25, 1.0, 1.0, 0.6, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-44", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-1745", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-1644", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-10515", "mrqa_searchqa-validation-11117", "mrqa_searchqa-validation-709"], "SR": 0.453125, "CSR": 0.5447115384615384, "EFR": 0.7714285714285715, "Overall": 0.672056146978022}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "Dillinger and his gang rampaged through the American Midwest, staging jail breaks, robbing banks, and killing 10 men and wounding seven along the way.", "North Korea's announcement has triggered international consternation.", "February 12", "Mandi Hamlin", "Israel Defense Forces", "\"falling space debris,\"", "at a Little Rock military recruiting center", "voluntary depletion", "if you don't get to the hospital to have surgery to drain the fluid, \"the deterioration can happen very quickly,\"", "Chris Robinson", "Grease", "Cipro", "34", "24 illnesses in multiple states,\"", "15,000", "\"A good vegan cupcake has the power to transform everything for the better,\"", "The Sopranos", "government", "September,", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "South Africa", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano", "using injectable vitamin supplements because the quantities are not regulated.", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "400 years ago", "Gulf of Aden,", "Obama", "31 meters (102 feet) long and 15 meters (49 feet) wide", "Caylee Anthony,", "the immorality of these deviant young men does not provide solutions that prevent gang rape from happening.", "Wednesday", "managing his time", "not including co-pays or deductibles", "bipartisan", "us to step up.\"", "he acted in self defense in punching businessman Marcus McGhee.", "education about rainforests.", "as adults", "drug cartels", "Texas is among a growing number of state governments going after them.", "Trevor Rees", "28 passengers,", "Espinoza", "Ed McMahon,", "London Heathrow's Terminal 5", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center", "Genocide Prevention Task Force", "243 days", "Kirstjen Nielsen", "August 5, 1937", "20", "Wisconsin", "Mr Loophole", "Arlo Looking Cloud", "Queenston Delta", "1694", "the Golden Fleece", "Gustav", "Amish TV", "6teen"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6167443941292625}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, false, true, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0, 0.5714285714285714, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.10526315789473685, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-4147", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-9728", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4692", "mrqa_searchqa-validation-5235"], "SR": 0.515625, "CSR": 0.5442708333333333, "EFR": 0.9032258064516129, "Overall": 0.6983274529569892}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "sonar", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Castile", "about a mile north of the village of Dunvegan,", "arcelorMittal Orbit", "lodges", "Joseph Stillwell", "Estonia", "the solar system", "coelacanths", "Charleroi", "Dennis Potter", "Calcium", "Eric Coates", "Geoffrey Cox", "Mel Brooks", "The California condor", "Ohio", "turbine", "Hattie Jacques,", "police drama The Bill", "0 for 7", "Hamlet", "Johannesburg", "Crackerjack", "Bleak House", "Carousel", "Spain", "minder", "special sauce", "Les Dennis", "Kansas City", "Hard Times", "Tuscany", "18 meters", "Singapore", "Scooby-Doo", "Pakistan International Airlines", "gold, red, blue, black and white", "France", "Tomorrow Never Dies", "jaundice", "Hong Kong", "Chuck Yeager", "lisping Violet- Elizabeth Bott", "Canada", "stamp collecting", "Moby Dick", "Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "a sociological perspective", "21 July 2015", "Bern", "28 June 1945", "\"a violent and brutal extremist group with a number of individuals affiliated with al Qaeda.", "25", "Pakistan intelligence institutions and its army", "Yves Saint Laurent", "Rush", "Yogi Berra", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.625, "QA-F1": 0.6898809523809524}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-2091", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-1709", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-5331", "mrqa_triviaqa-validation-7476", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-613", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-7017", "mrqa_newsqa-validation-2682"], "SR": 0.625, "CSR": 0.5454757462686567, "EFR": 0.875, "Overall": 0.6929232742537313}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "the federal government", "Kevin Corrigan", "August 9, 1945", "after obtaining the consent of the United Kingdom", "a cake", "Olivia Olson", "Tokyo", "Pyeongchang County, South Korea", "602", "April 7, 2016", "5.7 million customer accounts", "Initially, all games in the International Series were held in London", "the President", "David Joseph Madden", "new wave rock band The Fixx", "at night", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "the Royal Air Force ( RAF )", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US privacy Act to Europeans and gives them access to US courts", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "18th century", "Mariah Carey", "Spektor", "H CO", "seven", "September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "Soviet Union", "elected", "sport utility vehicles", "Elk and Kanawha Rivers", "American country music duo The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash in 1959", "Sir Mix - a-Lot", "June 1991", "October 15, 1997", "New Guinea", "Frank Oz", "1954", "2010", "Missouri River", "edward I", "lute", "Bulgaria", "John Churchill, 1st Duke of Mindelheim", "Gregg Popovich", "Asiana Town building", "Jaime Andrade", "Eleven people died and 36 were wounded in the Monday terror attack,", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi (Persian)", "hyperbole"], "metric_results": {"EM": 0.578125, "QA-F1": 0.686408848826612}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.3333333333333333, 0.18181818181818182, 1.0, 0.4, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8333333333333334, 0.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-8958", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-6365", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-5828", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-2886", "mrqa_newsqa-validation-335"], "SR": 0.578125, "CSR": 0.5459558823529411, "EFR": 0.7407407407407407, "Overall": 0.6661674496187363}, {"timecode": 68, "before_eval_results": {"predictions": ["German state of North Rhine-Westphalia", "Roberta Flack", "sesame seed", "youngest", "September 19", "Barnaby Rudge", "Buddha", "makwanent", "1963", "discus", "tabloid", "the elephant house", "goteddsday", "California", "Jews of Iberia (in Hebrew, Latvia, Ukraine, and Belarus)", "Romanian", "svyatoy vasily Blazhenny", "Peru", "the keel", "Evander Holyfield", "middies", "Buddhist", "New Orleans", "soda", "fat, vegetables (eggplant, garlic, onion) that are cooked in olive oils and wine", "Richie McCaw", "brash2", "Ken Burns", "Paddy Doherty", "Barry and Yvonne", "omega", "Hungary", "So Solid Crew", "blues-rock", "Pennsylvania", "caucausus", "referendums", "malain", "Jupiter", "woodentop", "tiddler", "two", "julian paladini", "Wide Area Augmentation System", "they were strong and stubborn.", "flannel", "B\u00e9la Bart\u00f3k", "Hugh Dowding", "Montpelier", "month of month", "Arthur, Prince of Wales", "annual income of US $11,770", "318", "Chris Rea", "Tomasz Adamek", "scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine.", "March 30, 2025", "Knox's parents, Curt Knox and Edda Mellas,", "Dubai", "rabbit hole, if you will, of", "held", "Russia", "heavy-metal fan", "tumaczenie na polski"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4745287698412698}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.19999999999999998, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5714285714285715, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.4444444444444445, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-2194", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-1649", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7645", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-6849", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-2964", "mrqa_triviaqa-validation-3236", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-361", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-10485", "mrqa_searchqa-validation-7826"], "SR": 0.4375, "CSR": 0.5443840579710144, "EFR": 0.6944444444444444, "Overall": 0.6565938254830918}, {"timecode": 69, "before_eval_results": {"predictions": ["California", "Jeffrey Archer", "Chicago", "California Chrome", "Dar es Salaam", "Sarah Keays", "Miss Marple", "Elkie Brooks", "UPS", "Novak Djokovic.", "piano", "Cambridge", "Bennet", "Westlife", "glycerol", "lacey addams", "Doubting Castle", "insect", "australian", "geoff", "Harry Shearer", "9-13 years", "pirate day", "penny", "Spice Girls", "48 Hours", "AFC Wimbledon", "france", "Tombstone", "Friedrich Nietzsche", "Cambridge", "South Africa", "Bagram", "Pygmalion", "bajan", "blackcurrant liquor", "Dieppe", "dengue fever", "Left Book Club", "triathlon", "Gabriel Byrne and Kevin Spacey", "the act of cleaving or splitting into parts", "Something in The Air", "sound and light", "Par", "jack Russell terrier", "prairie", "raclette", "Denali", "The Magic Circle", "Yalta Conference", "to start fires, hunt, and bury their dead", "London", "Cordelia", "London Luton Airport", "Sarah", "Antigua & Barbuda, Argentina, South Africa, Fernando P\u00f3, S\u00e3o Tom\u00e9, Madagascar, Mauritius, Mayotte, R\u00e9union, Seychelles,", "he said Chaudhary's death should serve as a warning to management,", "\"the evidence and investigatory effort has minimized the likelihood that Haleigh's disappearance is the work of a strangers.\"", "\"remained at the bottom of the hill surviving on leaves and water from a nearby creek,\" the report said.", "Vanilla Ice", "Wordsworth", "Voltaire", "Mars Hill, 150 miles ( 240 km ) to the northeast"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5298992153679654}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, false, true, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.5, 0.5454545454545454, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.08333333333333333, 0.08, 1.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2042", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-5378", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-4970", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627", "mrqa_searchqa-validation-3002", "mrqa_naturalquestions-validation-6046"], "SR": 0.453125, "CSR": 0.5430803571428571, "EFR": 0.8285714285714286, "Overall": 0.6831584821428571}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew - Somerville", "compound sentence", "New South Wales", "Ashrita Furman", "No Secrets", "1994", "2010", "12 November 2010", "1 October 2006", "1977", "2018", "Missouri", "Vincent Price", "1966", "Frederick Chiluba", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "1999", "the Maryland Senate's actions", "Latitude", "anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Van Halen", "$100", "the referee", "Bonhomme Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W", "If These Dolls Could Talk", "around 2011", "Seton Hall Pirates", "ulnar nerve", "late - 2011", "British Indian Association", "many forested parts of the world", "Western Australia", "Carol Worthington", "1830", "exposures such as alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "thanksgiving for a good harvest", "November 28, 1973", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "Jakkur, Bangalore, India", "Anthony Hopkins", "Jesus Christ", "1996", "holography", "Spanish", "marty vinterberg", "Gillian Leigh Anderson", "the theory of direct scattering and inverse scattering", "45th Infantry Division", "\"it should stay that way.\"", "2009", "an open window that fits neatly around him.", "Dutchman", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6911596930438842}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, true], "QA-F1": [1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.823529411764706, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.7142857142857143, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.8333333333333333, 0.5714285714285715, 1.0, 1.0, 0.23529411764705882, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.7499999999999999, 1.0, 0.4444444444444445, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-2384", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_newsqa-validation-2658", "mrqa_newsqa-validation-3858", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.546875, "CSR": 0.5431338028169015, "EFR": 0.7241379310344828, "Overall": 0.6622824717702768}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "inner core", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama Action", "left of the dinner plate", "zinc silicate primer and vinyl topcoats", "off the rez", "either in front or on top of the brainstem", "March 14, 1942", "Aegisthus", "Epithelium", "Erika Mitchell Leonard", "The Chainsmoker", "Vincent Price", "Pakistan", "Tessa Peake - Jones", "an expected or free or continuously changing behaviour and may have a given individual social status or social position", "United Nations Peacekeeping Operations", "it is part of the normal flora of the human colon and is generally commensal, but can cause infection if displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "Noahic Covenant", "Shirley Mae Jones", "heat transfer by thermal radiation may be minimized by silvering flask surfaces facing the gap", "Luke 6 : 67 -- 71", "August 19, 2016", "Sets heart in mediastinum and limits its motion", "scrolls", "Terrell Suggs", "Cecil Lockhart", "August 22, 1980", "retinal ganglion cell axons and glial cells", "letter series", "August 21", "the National Park Service's Shenandoah National Park in the Blue Ridge Mountains of Virginia", "The `` Southern Cause ''", "1955", "electrons from electron donors to electron acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions", "2", "Montreal Canadiens", "in 2009", "3 September", "The tower has three levels for visitors, with restaurants on the first and second levels", "product-market fit", "Wyatt `` Dusty '' Chandler ( George Strait )", "last book accepted into the Christian biblical canon", "In the 1920s, Louis W. Sauer developed a weak vaccine for whooping cough at Evanston Hospital ( Evanston, IL )", "ice giants", "on what became known to locals as `` Black Monday '', and continued into the mid-1980s", "Camellia sinensis", "euratom", "Mumbai", "Frank Fertitta, Jr.", "Coronation Street", "Michael Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "complicated and deeply flawed", "a house party in Crandon, Wisconsin,", "butterflies", "Rocky Mountain spotted fever", "$500", "drug labs, markets and convoys,\""], "metric_results": {"EM": 0.421875, "QA-F1": 0.5415397764066526}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5714285714285715, 0.888888888888889, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.12121212121212122, 0.0, 0.12903225806451613, 1.0, 1.0, 0.7272727272727273, 0.75, 1.0, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.08, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.5714285714285715, 0.4444444444444445, 0.11764705882352941, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.967741935483871, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-1617", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.421875, "CSR": 0.5414496527777778, "EFR": 0.7837837837837838, "Overall": 0.6738748123123123}, {"timecode": 72, "before_eval_results": {"predictions": ["University of Michigan", "Afghanistan", "a foam", "suffrage", "greenleaf", "Marcia Clark", "salty", "a cloudy day", "Philip Berrigan", "wheat", "Carole King", "Spain", "Pro-Jig Clamp Set", "Christo Vladimirov Javacheff", "Wichita", "U.S. Department of Agriculture", "Gilligan's Island", "Penelope", "Tom Harkin", "Channel Islands", "Krackel", "Penelope", "pronouns", "bonobos", "Harry's Harbor", "Veep", "Hornet", "lullaby", "Burma Ruby stone", "Pan's Labyrinth", "Hans Christian Andersen", "John Irving", "singular", "rockers", "the Aegean Sea, the Dardanelles-Sea of Marmora-Bosporus", "Xerox", "extra virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "drug war", "dali", "Lee Harvey Oswald", "Custer", "Newton's", "breath", "Stockholm", "Alaska", "a puff", "Mausolus of Caria", "qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew", "micah", "Saint Cecilia", "Germany", "1989 until 1994", "600", "80 percent of the woman's face", "Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.5, "QA-F1": 0.5701636904761904}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.5, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1459", "mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3351", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-15033", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-614", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-16212", "mrqa_searchqa-validation-14147", "mrqa_searchqa-validation-11913", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-6286", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681"], "SR": 0.5, "CSR": 0.5408818493150684, "EFR": 0.875, "Overall": 0.6920044948630137}, {"timecode": 73, "before_eval_results": {"predictions": ["Hairspray", "Happy Days", "Brown", "Bolivia and Paraguay", "New Hampshire", "grasshopper", "the commander", "Sure", "1876", "to worry.", "an observer", "Humphrey Bogart", "Maryland", "Lowenbrau", "the pen", "Herod", "the Lone Ranger", "Malaysia", "Georgetown University", "Barry Goldwater", "Goofy", "Walter Payton", "Mount Everest", "Marcus Garvey", "Crossword", "the Bufflehead", "the Tom Thumb", "St. John's Island", "the Mad Hatter", "serotonin", "Cincinnati", "the New Jersey Devils", "a concert grand", "ketchup", "peanut butter", "the most famous person from each of Michigan's 83 counties", "the Heartbreakers", "Tuscany", "Tunisia", "Parks", "inch", "Paris", "William Henry Harrison", "Corinthian", "a gram", "Bern", "Prada", "Chicago", "anything inside you", "the Pinta", "possible", "October 22, 2017", "Terrell Owens", "as the second single from the duo's debut studio album, Skrillex and Diplo Present Jack \u00dc ( 2015 )", "Tipping Point", "Scotland", "the dogger Bank", "NBA 2K16", "ethereal wave", "Ron Goldman", "MAD Men", "the assassination program,", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.625, "QA-F1": 0.6788194444444444}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4387", "mrqa_searchqa-validation-14786", "mrqa_searchqa-validation-16935", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-11051", "mrqa_searchqa-validation-12562", "mrqa_searchqa-validation-13507", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-4837", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-2988", "mrqa_searchqa-validation-7656", "mrqa_searchqa-validation-10595", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15975", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-5148", "mrqa_newsqa-validation-510"], "SR": 0.625, "CSR": 0.5420185810810811, "EFR": 0.9166666666666666, "Overall": 0.7005651745495495}, {"timecode": 74, "before_eval_results": {"predictions": ["Wholesale", "The Tyger", "Thunder Road", "The Last Supper", "Baccarat", "Rook", "Harlem", "Hertogenbosch", "a multi-hulled watercraft", "Addiction", "a cricket", "India", "Children of Men", "Skagway, Alaska", "a petition", "Hippolyta", "a phylum", "John Galt", "Spinach", "milk", "energy", "an imaginative tale", "World War I", "Student Loans", "Francis Slay", "Itzhak Perlman", "Wolfgang Johannes Puck", "dachshund", "the Monitor", "Cyprus", "La Crosse", "Coffee milk", "a baseball movie", "Hot Lips", "Isadora Duncan", "Pig Latin", "the Little Debbie Snacks", "Richard Cheney", "a black Toyota Prius", "USA", "Aristotle", "Cook County Hospital", "The Eagles", "An American Tail", "a Starline Tours Los Angeles bus tour", "an argyle", "Toyota", "a wallaby", "shoes", "Mark Twain", "Thomas Gibson", "30 October 1918", "Mel Tillis", "Michael Moriarty", "James Bolam", "pawns", "India", "House of Habsburg-Lorraine", "Oberst-Gruppenf\u00fchrer", "Kansas\u2013Nebraska Act", "Orbiting Carbon Observatory,", "South Africa", "Tuesday", "two"], "metric_results": {"EM": 0.5625, "QA-F1": 0.634375}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12847", "mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-8228", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-9320", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-4180", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-6327", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-16455", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-7628", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-7027", "mrqa_searchqa-validation-9788", "mrqa_naturalquestions-validation-4288", "mrqa_hotpotqa-validation-686"], "SR": 0.5625, "CSR": 0.5422916666666666, "EFR": 0.8571428571428571, "Overall": 0.6887150297619047}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "following the 2017 season", "China", "1908", "at specific locations, or origins of replication, in the genome", "Javier Fern\u00e1ndez", "Lloyd Webber", "silk floss tree", "American country music group The Nitty Gritty Dirt Band", "Gustav Bauer, the head of the new government", "November 2016", "Empiricism", "the problems and / or goals", "Augustus Waters", "east of the Canadian Arctic Archipelago", "Johnson, a lifelong Democrat and the Republican majority in Congress over how best to deal with the defeated Southern states following the conclusion of the American Civil War", "Song of Songs", "Johnny", "its vast territory was divided into several successor polities", "an abbreviation from the initial components in a phrase or a word, usually individual letters ( as in NATO or laser ) and sometimes syllables", "Sheev Palpatine", "Divyanka Tripathi", "September 24, 2012", "Only two men, Lex Luger and Rick Rude, have held the championship for a continuous reign of one year ( 365 days ) or more", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "homicidal thoughts of a troubled youth", "John C. Reilly", "Daniel A. Dailey", "Mickey Mantle", "addition", "December 15, 2016", "Kid Creole and the Coconuts", "AD 1 immediately follows the year 1 BC", "2010", "microfilament", "1983", "John Roberts", "President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Podujana Peramuna, led by former president Mahinda Rajapaksa, secured the most seats and local authorities.", "1773", "Buddhist missionaries", "introverted Sensing ( Si ), Extroverted Thinking ( Te )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "to London St Pancras", "t.S. Eliot", "Russell Humphreys", "Lieutenant Colonel Horace Meek Hickam", "Rihanna", "The minister later apologized, telling CNN his comments had been taken out of context.", "fractured pelvis and sacrum -- the triangular bone within the pelvis.", "2001", "short sale", "Blackbird", "Patrick Dempsey", "September 25, 2017"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5446513122294372}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.7142857142857143, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.3636363636363636, 0.16666666666666666, 0.08333333333333333, 1.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.125, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.0, 0.2666666666666667, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-4370", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-4308", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.453125, "CSR": 0.5411184210526316, "EFR": 0.7714285714285715, "Overall": 0.6713375234962407}, {"timecode": 76, "before_eval_results": {"predictions": ["makes Maria a dress to wear to the neighborhood dance", "Walter Mondale", "state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "in 1942", "awarded to the team that lost the pre-game coin toss", "21 May 2007", "at least 28", "Donald Trump", "23 hours, 56 minutes, and 4 seconds", "Universal Pictures and Focus Features", "multiple", "restarting play after a minor infringement", "A footling breech", "The Hunger Games : Mockingjay -- Part 2 ( 2015 )", "the President of India", "to signify cunnilingus", "28 %", "Elvis Presley", "N\u0289m\u0289n\u0289", "JackScanlon", "July 2014", "Elijah Wood", "head - up display", "Doug Pruzan", "In 1984", "Donna Reed", "inside the cell nucleus", "pathology", "1986", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Bali, Indonesia", "a German World War II super-heavy tank", "limited period of time", "a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "Pittsburgh Steelers ( 6 -- 2 )", "40 %", "Janie Crawford's `` ripening from a vibrant, but voiceless, teenage girl into a woman with her finger on the trigger of her own destiny", "in the east", "April 2, 2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "St. Louis Blues", "around 1872", "Idaho's Snake River Valley", "starch", "carbon", "on the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery F.C.", "Phelan Beale", "one", "Government Accountability Office report", "ethnic Somalis by rebels and Ethiopian troops are rampant.", "double-breasted", "Heroes", "a passage", "since 1983"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5459173638861139}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.25, 0.6666666666666666, 1.0, 0.0, 0.26666666666666666, 0.0, 0.2, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.30769230769230765, 0.4615384615384615, 0.6666666666666666, 0.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-10195", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-2782", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-3250", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.4375, "CSR": 0.5397727272727273, "EFR": 0.6388888888888888, "Overall": 0.6445604482323232}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes virus, (Another name for shingles is herpes zoster.)", "MUD1", "Roddy Doyle", "Charles Dickens", "Prussia", "Rudyard Kipling", "SpongeBob SquarePants", "Exile", "an enclave which is entirely enclosed by another nation.", "South Dakota", "Brian Close", "a caterpillar", "Leeds", "Edinburgh", "writing home.", "cricketer", "Switzerland", "Neptune", "Vimto", "phobia or phobia", "edgbaston", "carry On", "Egypt", "sense of taste", "snare drum", "pangea", "sauce", "hurdles", "The Centaurs", "tallest building in the world", "American football", "Looney Tunes", "Beatrix Potter", "Giglio Island", "Copenhagen", "\"Upper Haight\"", "Geoffrey Rush", "Harry patch", "(Nursery Comics)", "Sight & Sound", "Inigo Jones", "sonar", "Nelson Mandela", "Today", "hope chest", "Utah", "Mark Darcy", "reptilian", "an ancient supercontinent", "Salyut 1", "guadeloupe", "Evermoist", "62", "Matthew Gregory Wise", "1861", "Zola", "Limbo", "12.3 million", "July", "Dick Cheney", "New Hampshire", "a miniskirt", "a fathom", "$163 million (180 million Swiss francs)"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5942978896103897}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false], "QA-F1": [0.3636363636363636, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-5462", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-7005", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-2233", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-1976", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-479", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-3484", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-2402", "mrqa_newsqa-validation-4029"], "SR": 0.515625, "CSR": 0.539463141025641, "EFR": 0.7096774193548387, "Overall": 0.6586562370760959}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "he acted in self defense in punching businessman Marcus McGhee.", "1964", "\"he was walking back through the crowd it was the word on everyone's lips,\"", "\"momentous discovery\"", "al-Aqsa mosque", "Pragyan Ojha two but Dilshan proved a formidable opponent.He continued his superb 2009 with 10 boundaries and two sixes to reach three figures for the 11th time in Tests.", "as soon as 2050,", "Sylt", "media", "in the southern city of Najaf.", "Sen. Barack Obama", "10 municipal police officers", "changed Hollywood.", "pizza, the other for the drug ketamine.", "Brian David Mitchell,", "Defense of Marriage Act", "Joshua", "Brazil forward Ronaldinho", "Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "hackers who commandeer your computer are bad enough.", "\"OK,\"", "start a dialogue of peace based on the conversations she had with Americans along the way.\"", "al Qaeda", "Manmohan Singh's", "help the convicts find calmness in a prison culture", "J. Crew", "one day,", "10,000", "Meira Kumar", "antihistamine and an epinephrine auto-injector", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's", "Arthur E. Morgan III", "million dollars", "bribing other wrestlers to lose bouts, compounding the view that corruption was prevalent in the sport.", "Eleven people died and 36 were wounded in the Monday terror attack,", "they don't feelMisty Cummings has told them everything she knows.\"", "10 below", "Steven Gerrard", "8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Carol Browner", "conviction of Peru's ex-president is a warning to those who deny human rights", "Brazil", "10", "the return of a fallen U.S. service member", "supermodel", "Horseshoe Bartender", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "16 seasons", "e pluribus unum", "well", "China", "Capture of the Five Boroughs", "Jim Diamond", "pornographicstar", "God", "petroleum", "Fannie Farmer", "democracy and personal freedom"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5664387189044897}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.11764705882352941, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.8571428571428571, 0.0, 0.5, 1.0, 0.0, 0.0, 0.1, 1.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.35294117647058826, 0.16666666666666669, 0.18181818181818182, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.2758620689655173, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-168", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-2378", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-7235", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-16904", "mrqa_searchqa-validation-15636"], "SR": 0.46875, "CSR": 0.5385680379746836, "EFR": 0.5882352941176471, "Overall": 0.6341887914184661}, {"timecode": 79, "before_eval_results": {"predictions": ["1866", "Ulysses S. Grant", "the Yangtze River", "Jacob", "Queen Anne", "the New York Times", "Scotland", "Oklahoma", "the Communist Party of China", "the nuclear submarine, the USS Nautilus", "Sir Humphry Davy", "the northeastern landmass and islands, bordering the Pacific", "24 hours", "smallpox", "Dead Sea", "the fairway", "Hill Street Blues", "elevation", "Mao Zedong", "Harriet M. Welsch", "Mickey Mouse", "Xerox", "blitz", "Jamaica", "gossip", "an exothermic reaction", "the Chocolate Factory", "Morocco", "Surf's Up", "Yao Ming", "the Department of the Treasury", "fashion designer Jason Wu", "Andrew Marvell", "fruits", "Bollywood", "Love Theme from \"Titanic\"", "Take Me Out to the Ballgame", "a parapet", "Joe Lieberman", "the World's Fair", "coffee", "Nike", "Prime Minister Margaret Thatcher", "gas masks", "Suriname", "Pearl", "PotBS", "Switzerland", "Vestals", "The Lord of the Rings: The Return of the King.", "President Raul Castro", "H CO ( equivalently OC (OH ) )", "in a thousand years", "W. Edwards Deming", "Clara Wieck", "Douglas Trendle", "Warwick Davis", "Ricky Marco i Vives", "edith Cavell", "Forbes", "45 minutes, five days a week.", "22", "John Demjanjuk,", "2,579"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6884469696969697}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.7272727272727272, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.8, 0.4, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-11663", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-7549", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-5740", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-15823", "mrqa_searchqa-validation-8650", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-5346", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-2118"], "SR": 0.546875, "CSR": 0.538671875, "EFR": 0.7241379310344828, "Overall": 0.6613900862068964}, {"timecode": 80, "before_eval_results": {"predictions": ["Homebrewing", "the German Empire", "Tim Whelan", "the North Shore", "Virgin", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "10", "sacred mountains", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "the Royal Festival Hall", "Manor of the More", "Commonwealth of England, Scotland, and Ireland", "Workers' Party", "those who work with animals believe to be the line between using animals for entertainment purposes and abusing them.", "his exploration and settlement", "six", "Mauthausen-Gusen", "Adrian Peter McLaren", "Distillery", "Theodore Anthony Nugent", "New York", "Viscount Cranborne", "The Princess and the Frog", "the Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Martins", "Boulder High School in Boulder, Colorado", "Dutch", "November of that year", "Boston, Massachusetts", "Kaley Christine Cuoco", "Brendan O'Brien", "Delphine Software International", "University of Kentucky College of Pharmacy", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31 - member Senate and a 150 - member House of Representatives", "May 31, 2012", "Billie Jean King", "Vienna", "Malaysia", "Akio Toyoda", "Iran's nuclear program.", "alternative-energy", "Bix", "syllables", "Court Jester", "M&M's"], "metric_results": {"EM": 0.5625, "QA-F1": 0.670217803030303}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, false, false, true, false, true, true, true, false, false, true, false, true, true], "QA-F1": [0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.7272727272727272, 1.0, 0.19999999999999998, 0.19999999999999998, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-237", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-1305", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-5476", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-3760", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-870"], "SR": 0.5625, "CSR": 0.538966049382716, "EFR": 0.8571428571428571, "Overall": 0.6880499063051146}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "Allies of World War I", "Acid house", "Esteban Ocon", "Lady Frederick Windsor", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham, Alabama", "Nobel Prize in Physics", "Adam Karpel", "blues", "1991", "Windermere, Cumbria", "Sir Frank P. Lowy", "Hermione Baddeley", "Metrolink", "South Australia", "1698", "Tulsa", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John W. Henry", "2009", "McLaren-Honda", "Alexandre Dumas, p\u00e8re, and Paul Meurice", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Dar es Salaam", "English Electric Canberra", "1 September 1864", "Washington, D.C.", "the Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoon Fridays", "The Company", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Michael Redgrave", "Tyrann Devine Mathieu", "1933", "British Columbia, Canada", "The Great Gatsby", "willow", "The Sand Trap", "Kim Clijsters", "Mombasa, Kenya", "hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "Elementary", "The New York Times", "voltage", "Willa Cather"], "metric_results": {"EM": 0.5, "QA-F1": 0.6074739044168391}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, true, false, false, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.2608695652173913, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_triviaqa-validation-873", "mrqa_triviaqa-validation-388", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.5, "CSR": 0.5384908536585367, "EFR": 0.8125, "Overall": 0.6790262957317073}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Harriet Walter", "Algernod Lanier Washington", "Conservative Party", "four", "July 23, 1971", "Turkmenistan", "the Earth", "Standard Oil", "2006", "Norwegian", "The Late Late Show", "Ryukyuan people (\u7409\u7403\u6c11\u65cf, Ry\u016bky\u016b minzoku, Okinawan: \"Ruuchuu minzuku\") (also Lewchewan or Uchinaanchu", "Commanding General", "\"50 best cities to live in.\"", "Mike Mills", "Parlophone", "January 15, 2016", "IATA: VNO, ICAO: EYVI", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "The Worm", "Herman's Hermits", "Nikhil Banerjee", "810", "German", "Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Tom Rob Smith", "Novel", "Gabriel Iglesias", "3,384,569", "Gambaga", "2 March 1972", "The parkway", "Teatro Carlo Felice", "every aspect of public and private life", "Gary Ross", "Hanford Site", "Commissioner", "Sam Tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epithelium", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "Ringo Starr", "1882", "off the coast of Dubai", "Sunday's security breach", "not doing more", "Linux", "polio", "the treble clef", "gun charges,"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7798115079365079}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-4899", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732"], "SR": 0.6875, "CSR": 0.5402861445783133, "EFR": 0.85, "Overall": 0.6868853539156626}, {"timecode": 83, "before_eval_results": {"predictions": ["Brookline, Massachusetts", "Metacomet", "Chicago", "Leon Trotsky", "the loaf", "a large chart", "the masthead", "Martin Van Buren", "Ugly Betty", "The Pooh", "Rigoletto", "Alexander Graham Bell", "(Vijay) Singh", "the fog", "a modem", "China", "the Boston Red Sox", "the United States", "Mussolini", "the human breast", "Jane's Electro-Optic Systems", "Christo", "a psychiatrist", "Ichiro Suzuki", "Sam Cooke", "Africa", "the banjo", "Grant", "Belle Watling", "Mozart", "American alternative rock band", "the asylums", "Lord Byron", "the meninges", "Douglas MacArthur", "3M Company", "The Rolling Stones", "Edie Falco", "USA", "Oneonta College", "1936", "the CN Tower", "The Hurricane", "inheritance", "Annapolis", "the cardinal", "Japan", "spongiform encephalopathy", "Prince Edward Island", "Hindu", "the pronghorn", "January 2, 1971", "San Francisco", "Moscazzano", "cliff thorburn", "guizhou Province", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul John Manafort Jr.", "1959", "The son of Gabon's former president", "the United States", "mid November"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6164806547619047}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-889", "mrqa_searchqa-validation-3392", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8713", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-13489", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-14502", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-16297", "mrqa_searchqa-validation-8682", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-3923", "mrqa_naturalquestions-validation-8884"], "SR": 0.53125, "CSR": 0.5401785714285714, "EFR": 0.8666666666666667, "Overall": 0.6901971726190477}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "Captain James Hook", "Jabez Stone", "William Howard Taft", "olive brine", "Pemmican", "Olivia Newton-John", "Oahu", "Joseph Smith", "Arthropoda", "Harry S. Truman", "Capricorn", "Diane Arbus", "Albuquerque", "Thomas Jefferson", "legislation", "tofu", "Old School", "the Distant Early Warning Line", "King Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "Indies Unlimited", "Robert Bruce", "Zinc", "oxys", "Gargantua", "Elke Sommer", "hoof wall", "Robin Williams", "Philadelphia", "laundry soap", "Giuseppe Garibaldi", "The Five People You Meet in Heaven", "anglerfish", "the Jaguar S-Type R", "Thomas Jefferson Family Cemetery", "Mahatma Gandhi", "Brazil", "Jim Thorpe", "comedy series", "Dustin Hoffman", "William Shakespeare", "descend", "Roy Ellsworth Harris", "Haunted Mansion", "Rembrandt", "Gilligan's Island", "your timehare", "the Colorado Rep11blican", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Tom Robinson", "Andy Serkis", "South Africa", "dance", "Charlie Drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun", "Asashoryu", "angry over the treatment of Muslims,", "former U.S. secretary of state", "Newcastle Falcons"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5769097222222221}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.8, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6978", "mrqa_searchqa-validation-5645", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-12089", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-11112", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16304", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-5050", "mrqa_naturalquestions-validation-6465", "mrqa_triviaqa-validation-3196", "mrqa_newsqa-validation-1128"], "SR": 0.484375, "CSR": 0.5395220588235294, "EFR": 0.8484848484848485, "Overall": 0.6864295064616756}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "Postcards from the Edge", "birds", "Virginia", "hot chocolate", "Elementary, my dear Watson", "Ramadan", "William Shakespeare", "The Carol Burnett Show", "To a Mouse", "Gertrude Stein", "pontiff", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tupsa", "an object oriented programming", "Nova Scotia", "cocoa", "tuna", "Absinthes", "Hypatia", "marsupial", "quid", "Lincoln", "Anthony Newley", "Swimmer's Ear", "Henry", "5", "Cyrillic", "Jeff Probst", "John Travolta", "Nasser", "The Moment of Truth", "Laura", "Africa", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Katrina", "pineapple", "Bill & George Clinton", "the Black Sea", "May 12, 1907", "dollar", "Young Frankenstein", "Shout", "to form a higher alkane", "comprehend and formulate language", "eusebeia", "Venezuela", "The Shootist", "Sega Dreamcast", "National Society of Daughters of the American Revolution", "Johnny Galecki", "44,300 people", "it has not intercepted any", "At least 88", "went missing off Catalina Island, near the California coast, following an argument the couple had.", "\"It appears that there was a struggle between the victim and the suspect in the threshold of the hotel room immediately prior to the shooting,\""], "metric_results": {"EM": 0.484375, "QA-F1": 0.5813701923076923}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.33333333333333337, 0.5, 0.0, 0.9743589743589743]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-13276", "mrqa_searchqa-validation-6865", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-7459", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-9410", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-11816", "mrqa_searchqa-validation-15430", "mrqa_searchqa-validation-10463", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-16963", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-6281", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-13742", "mrqa_searchqa-validation-2063", "mrqa_naturalquestions-validation-4881", "mrqa_hotpotqa-validation-4024", "mrqa_hotpotqa-validation-3436", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.484375, "CSR": 0.5388808139534884, "EFR": 0.8484848484848485, "Overall": 0.6863012574876673}, {"timecode": 86, "before_eval_results": {"predictions": ["John Garfield as Al Schmid", "at a given temperature", "season ten", "October 28, 2007", "seven units of measure", "absorbed the superhuman powers and the psyche of Carol Danvers", "in Egypt", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "5 : 7 -- 8", "between the stomach and the large intestine", "Gupta Empire", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "Egypt", "the base of the right ventricle", "Lager", "Pepsi", "Destiny's Child", "position in blackjack relative to the player", "Russell Huxtable", "Husrev Pasha", "an alien mechanoid", "The Osmonds", "735 feet ( 224 m )", "It acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "September 8, 2017", "SURFACE WASA OF ROOTS", "Iowa ( 36.6 % )", "Matt Flinders", "1 October 2006", "bh\u0101va", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Egypt", "nasal septum", "IETF protocols", "January 1, 1976", "parthenogenesis", "Identification of alternative plans / policies", "Ludacris", "JackScanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "the retina", "Donna Mills", "Donna", "Annette Crosbie", "Bobby Kennedy", "Minder", "leopard", "Patricia Arquette", "Association of Commonwealth Universities", "the Crocker National Bank", "101", "two", "Like a Rock", "a cat", "George III", "Norway"], "metric_results": {"EM": 0.5, "QA-F1": 0.6186288980305041}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, true, false, true, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true], "QA-F1": [0.5714285714285715, 0.5454545454545454, 0.0, 1.0, 0.4, 0.761904761904762, 0.0, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.4, 0.11764705882352942, 0.0, 1.0, 0.0, 1.0, 0.0, 0.72, 0.0, 1.0, 0.75, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-10526", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-613", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-988", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-6294", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-1572", "mrqa_searchqa-validation-1808", "mrqa_searchqa-validation-366"], "SR": 0.5, "CSR": 0.538433908045977, "EFR": 0.875, "Overall": 0.6915149066091953}, {"timecode": 87, "before_eval_results": {"predictions": ["Province of Syracuse", "Guardians of the Galaxy Vol.  2", "Arlo Looking Cloud", "Jyothika Sadanah", "Franco-Prussian War", "Hirsch index rating", "Cody Miller", "1951", "Teenitans Go!", "A skerry", "Book of Judges", "torpedo boats and later submarines", "9 February 1971", "San Francisco, California", "Three's Company", "9,984", "Nasim Pedrad", "Marktown, Clayton Mark's planned worker community in Northwest Indiana", "the Rose Theatre", "1 million acre", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "237 square miles", "Shakespeare's reputation", "Balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden, on the southern coast", "Noel Gallagher", "Michael Rispoli", "U2 360\u00b0 Tour", "James Ager", "Scarface", "the Austro-Hungarian Army", "St. George", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "Nova Planta Decree of Majorca and Ibiza", "Helsinki, Finland", "Urijah Faber", "four operas", "3 May 1958", "The Thomas Crown Affair", "Bharat Ratna", "November 11, 1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Oklahoma", "Sam Kinison", "Ferdinand Magellan", "those at the bottom of the economic government whom the state ( in Roosevelt's view and in the general social humanitarian approach ) needed to help", "1920s", "Blue laws", "James Hargreaves", "Puff the Magic Dragon", "Hindi", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "flooding", "composer of \"Phantom of the Opera\" and \"Cats\" and the \"Harry Potter\" films were recorded there.", "FontSpace", "Bath", "Atlanta", "a greeting which is used by some on birthdays, and by others in response to `` Merry Christmas '' and `` Happy New Year ''"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6569575968013468}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.19999999999999998, 0.5, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.07407407407407408, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.13333333333333333, 0.0, 1.0, 1.0, 0.12121212121212123]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4507", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-681", "mrqa_naturalquestions-validation-5215", "mrqa_triviaqa-validation-3809", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-2094", "mrqa_searchqa-validation-2044", "mrqa_naturalquestions-validation-9361"], "SR": 0.5625, "CSR": 0.5387073863636364, "EFR": 0.9285714285714286, "Overall": 0.702283887987013}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus shifts", "250,000", "Ameneh Bahrami", "40", "state senators", "Internet broadband deal with a Chinese firm.", "by text messaging", "Hawaii", "Carrefour", "Brazil's", "it's historical, inspiring, creative, romantic and beautiful.", "\"Common Access Cards,\"", "Her husband and attorney, James Whitehouse,", "helping to plan the September 11, 2001, terror attacks, and believe he may have sought to participate, possibly as the \"20th hijacker.\"", "Empire of the Sun", "the burning World Trade Center", "because the Indians were gathering information about the rebels to give to the Colombian military.", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "time", "the earthquake's devastation.", "Jason Chaffetz", "summer", "southern port city of Karachi, Pakistan's largest city and the capital of Sindh province.", "stolen the personal credit information of thousands of unsuspecting American and European consumers", "having trained law enforcement personnel watching people as they enter the mall", "Ricardo Valles de la Rosa", "Islamabad", "Toffelmakaren", "Wednesday", "Microsoft", "1995", "Araceli Valencia", "Casalesi Camorra", "Nigeria", "201-262-2800", "South Africa", "very dark and very cold place.", "France", "President Obama", "Tuesday", "contact the insured drivers who have failed to comply", "Mashhad", "Plymouth Rock", "Alina Cho", "Spaniard Carlos Moya", "last week", "gym or facing days of bad weather.", "AbdulMutallab", "10", "second", "Central Germany", "Rust", "gastrocnemius muscle", "Granada", "Cedar", "Portugal", "June 17, 2007", "England", "Black Elk", "hollandaise", "Kwanzaa", "\"to look like\"", "Javan leopard"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6119126099594849}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, false, false, true, true, false, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.125, 0.0, 1.0, 0.4615384615384615, 1.0, 0.6153846153846153, 1.0, 0.19047619047619047, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5555555555555556, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.0, 0.5, 0.7272727272727273, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-3110", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-706", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2369", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-929", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1201", "mrqa_triviaqa-validation-6987", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749"], "SR": 0.515625, "CSR": 0.5384480337078652, "EFR": 0.7419354838709677, "Overall": 0.6649048285157665}, {"timecode": 89, "before_eval_results": {"predictions": ["Salt Lake City, Utah", "10 below", "Shemsu Sirgaga", "killing rampage.", "HSH Nordbank Arena", "they did not receive a fair trial.", "federal officers' bodies", "American Bill Haas", "Larry Ellison", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "rising disposable income and an increasing interest in leisure pursuits, a growing number of courses, more television coverage and availability of EU funds,", "Joan Rivers", "The public endorsement", "Phoenix, Arizona, police", "KBR", "a Muslim and a Coptic family", "Alicia Keys", "two years", "the body of the aircraft", "North Korea", "will not support the Stop Online Piracy Act,", "pattern matching.", "Teen Patti", "almost 9 million", "U.S. senators", "the situation of America wielding a big stick for the last eight years.'\"", "London and Buenos Aires", "she returned to Pakistan in October after President Pervez Musharraf signed an amnesty lifting corruption charges.", "acquire nuclear weapons", "President Obama", "a bank", "two", "four people believed to be illegal immigrants", "At least 38", "Sri Lanka", "The BBC", "\"wipe out\" the United States if provoked.", "Sunday", "is a city of romance, of incredible architecture and history.", "Stella McCartney", "clogs", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Alicia Keys", "ALS6", "The EU naval force", "over 1,000 pounds", "time", "help make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "Lindsey Vonn", "three", "postero - medially towards the optic chiasm", "Hugo Weaving", "aragonite", "Lester", "Olympia", "Bruce R. Cook", "Los Angeles, California", "86,112", "Lewis Carroll", "a soap opera", "CPI", "The Cross Foxes Inn"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5819378707616967}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false], "QA-F1": [0.7272727272727273, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.1, 0.19354838709677416, 1.0, 1.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 0.11764705882352941, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-3753", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3058", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-436", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_hotpotqa-validation-2460", "mrqa_searchqa-validation-6689", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.453125, "CSR": 0.5375, "EFR": 0.8571428571428571, "Overall": 0.6877566964285714}, {"timecode": 90, "before_eval_results": {"predictions": ["Bessie Smith", "anthrax", "Eris", "larynx", "(7)", "Ebony", "Chicago", "Sartre", "Wordsworth", "St. Louis", "James K. Polk", "Harpy", "lacrosse", "Naples", "a Dormouse", "Jews", "a cow pie.", "Daylight", "Words", "the White Sea", "Doctor Dolittle", "Graceland", "Mitch Albom", "the beaver", "earthquakes", "\"Breezes Of\"", "acting", "The Bionic Woman", "5000", "wrinkles", "Narnia", "comet Tempel 1", "Cedar of Lebanon", "Kamehameha", "(Elbert) Gary", "epitaphic", "crowded", "\"Duke\"", "Orlans", "The JimiHendrix", "Pulp Fiction", "Hester Prynne", "a loose single layered two-piece made of soft materials like silk", "the flag carrier and largest airline of the Republic of China", "a bagpipe", "a stork", "cruises", "Henry David Thoreau", "Encephalitis", "Cuba", "Sydney", "Hudson Bay", "restored to life", "The long - hair gene is recessive", "the Canaries", "Another Day in paradise", "The Danelaw", "Donald Wayne Johnson", "Robert A. Iger", "Manchester Airport", "Iowa,", "16", "Japan", "financial gain"], "metric_results": {"EM": 0.5625, "QA-F1": 0.5869791666666666}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7652", "mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-9946", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-4217", "mrqa_searchqa-validation-2011", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-7563", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-14528", "mrqa_searchqa-validation-10975", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-4827", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-4724", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-1662"], "SR": 0.5625, "CSR": 0.5377747252747253, "EFR": 0.9285714285714286, "Overall": 0.7020973557692307}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff, Wales", "keirin", "feather Middleweight", "Christopher Nolan", "German poet", "a highball", "Conan Doyle", "Godfigu", "a heart", "six", "Bashir", "dog sport", "The Double", "arsenic", "alphabets", "Mickey Mouse", "clove", "The Welcome Stranger", "recorder", "The UAE", "Genesis", "Ladysmith", "californium", "Robert Guerrero", "Arizona Diamondbacks", "\u00ef\u00bf\u00bd", "Goldie Myerson", "Marc Brunel", "to the tooth,\" meaning that it still has a little bite.", "William Shakespeare", "1960s", "Some Like It Hot", "Beaujolais", "morphine", "The National Council for the Unmarried Mother and her Child", "Sarajevo", "Roger of Montgomery", "the knight, some clergymen, members of the middle class, and a few peasants.", "bullfighting", "Leicestershire", "cycling", "Ukraine", "bedding", "Switzerland", "Shanghai", "Duke Orsino", "gallon low's birthday", "the Swordfish", "France", "Australia", "France", "Augustus Waters", "1898", "January 1923", "South Asian Games", "Rana Daggubati", "four", "1,500", "a group of teenagers", "38 feet", "Lafayette", "turquoise", "birds", "2010"], "metric_results": {"EM": 0.5, "QA-F1": 0.587019751082251}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 0.5, 1.0, 0.8571428571428571, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-600", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-1651", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-2067", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-5567", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-2053", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-64", "mrqa_hotpotqa-validation-369", "mrqa_hotpotqa-validation-3814", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-11134"], "SR": 0.5, "CSR": 0.5373641304347826, "EFR": 0.875, "Overall": 0.6913009510869565}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Thomas Staubach", "from 1979 to 2013", "two", "2001", "Meghan Markle", "2006", "alcoholic drinks", "Seoul", "Dutch", "43rd Vice President of the United States from 1981 to 1989", "political correctness", "Russell Humphreys", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "Tuesday, January 24, 2012", "over 3 million", "Mazda", "Jack St. Clair Kilby", "\"My Father\"", "water", "more than 70", "Black pudding", "Animorphs", "Francis", "two Nobel Peace Prizes", "Masahiko Takehita", "Acatosaurus", "TD Garden", "the group focuses on homosexuality, gay sex, and the gay bear subculture.", "Sam Kinison", "Melbourne Storm", "Hawaii", "2007", "Texas", "Prudence Jane Goward", "Vince Guaraldi", "\"What's My Line?", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Mathew Sacks", "Charles II", "17 October 2006", "Memphis Minnie", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "The 2018 Unibet Premier League Darts", "first freshman", "Canada", "near temples", "the eurozone", "Jane Seymour", "Willie Nelson", "1984", "Argentine", "around 3.5 percent", "Ali Bongo", "Antietam National Battlefield", "your medical bills", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.515625, "QA-F1": 0.670703125}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.6, 0.4, 0.0, 0.0, 0.8, 1.0, 1.0, 0.5, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.125, 1.0, 1.0, 0.0, 0.4, 0.0, 0.8, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-5328", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1237", "mrqa_hotpotqa-validation-372", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_hotpotqa-validation-294", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-2586", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.515625, "CSR": 0.537130376344086, "EFR": 0.9354838709677419, "Overall": 0.7033509744623656}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "Bill Cosby", "Edward R. Murrow", "Liesl", "Stage Stores", "\"Sabotage\" (2014)", "1998", "World Famous Gold & Silver Pawn Shop", "1972", "Argentina", "the Crab Orchard Mountains", "Target Corporation", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the IRA's South Armagh Brigade", "Tel Aviv", "Chevy", "the nature of human sexual response", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "PEN America", "Love Letter", "2013", "Jericho Union Free School District", "January 15, 1975", "Cartoon Network", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Arthur Rimbaud", "water sprite", "Hopeless Records", "August Heckscher", "Isabella Hedgeland", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow", "George Martin", "Timo Hildebrand", "Adam Dawes", "Enkare Nairobi", "Rockland", "2009", "Vietnam War", "Toto", "9 February 2018", "Cheap trick", "Gabriel Byrne and Kevin Spacey", "Funchal", "British", "Scudetto", "it would investigate the video and any group that tries to take justice into its own hands.\"", "money who want, or need, to \"move down\" from the new-car market", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6701388888888888}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-5586", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2965", "mrqa_searchqa-validation-16694"], "SR": 0.609375, "CSR": 0.5378989361702128, "EFR": 0.6, "Overall": 0.6364079122340425}, {"timecode": 94, "before_eval_results": {"predictions": ["he hears a different drummer", "Adolf Hitler", "Mrs. Miniver", "Simon Cowell", "Eagles", "a Packard car dealer", "lifejackets", "Ian Fleming", "the Shrew", "Anne Frank", "Bora Bora", "Earl", "Nassau", "a geisha", "former president of France", "the Barbary Corsairs", "CIA", "antimicrobial", "the iPhone", "the three Temptations of Jesus", "Phonetics", "Crosby, Stills & Nash", "Cheers", "the bottles filled with holy water", "a rocket", "the arbitral seat", "Yucatan", "\"Jeopardy\"", "Afghanistan", "Australia", "buffalo", "seoul", "The Mortimer D. Sackler", "the duck", "Pete Rose", "Esther", "South Africa", "Bacall", "GoldenEye", "agricultural", "Dumbo", "Edith Wharton", "Bonnie Raitt", "marsupials", "Italian", "The Crow", "Cal Ripken Jr.", "Orson Welles", "mongoose", "Richard Dreyfuss", "Ecuador", "Apokalypsis", "four", "elected or appointed by means of a commission ( letters patent ) to keep the peace", "Friends", "frankincense", "the solar system", "Ranulf de Gernon, 4th Earl of Chester", "Karolina Dean, a lesbian whom they were to marry", "Pieter van Musschenbroek", "Seoul", "\" Fortunately, I've been feeling better every single day since surgery and this weekend my doctors gave me the green light to get back to work.\"", "methylene", "The Krankies"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6024553571428571}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2367", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-1024", "mrqa_searchqa-validation-4594", "mrqa_searchqa-validation-11084", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-11593", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-11623", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-12196", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-804", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-1101", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4503", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.546875, "CSR": 0.5379934210526316, "EFR": 0.7586206896551724, "Overall": 0.6681509471415608}, {"timecode": 95, "before_eval_results": {"predictions": ["Bork", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "the Mallow", "Antnio Guterres", "Latin", "King Henry VIII", "San Francisco", "The Memory Keepers daughter", "Neptune", "Harry Potter and the Chamber of Secrets", "Brutus", "the wild-goose", "Joseph Haydn", "Willa Cather", "Dow Jones industrial average", "Aunt Jemima", "the fowls", "dynasties", "Homer", "Amanda Bynes", "Danson", "O. Henry", "Osteosarcoma", "B.B. King", "Kennedy Onassis", "Donovan", "plankton", "Candlestick Park", "spokeshaves", "just compensation", "Vodka", "pickled", "Adam", "Protestantism", "Ivy Dickens", "dizzy", "thunder", "Ham", "wounds", "Sicily", "Lord Nelson", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Norma's brother, Caleb", "1957", "Jurchen Aisin Gioro clan", "Wharton's club", "Little arrows", "Rotary", "Craig William Macneill", "William Adelin", "twenty", "Newark's Liberty International Airport,", "more than 4,000", "Lifeway Christian Stores", "Pakistan"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6357886904761905}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.28571428571428575, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1854", "mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-13003", "mrqa_searchqa-validation-12114", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-503", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-12050", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-15970", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.5625, "CSR": 0.5382486979166667, "EFR": 0.8214285714285714, "Overall": 0.6807635788690476}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "Luca di Paolo", "Unbreakable", "Holy Week", "Rosarito", "Wizard", "gigabit", "Planned Parenthood", "Jamie Lee Curtis", "Jeopardy", "saray", "Alexander Graham Bell", "the Northern Mountain covered region of India", "baffle plate", "Corpulent", "The Cartoonists", "Erin Go Bragh", "Queen Victoria", "giant slalom", "Medusa", "zoology", "\"Lucia di Lammermoor.\"", "the largest lakes and rivers", "cricket", "Hawking", "St. Francis of Assisi", "luminous intensity", "The Scarlet Letter", "2016", "Drug Rehab & Treatment Center", "pastries", "Hundred Years' War", "the Onassis Cultural Center", "milk and honey", "3", "Stenosis", "The Beatles", "Manhattan", "a disaccharides", "King Kong", "Cubism", "Umbria", "cheese curd", "M. C. Escher", "Oahu", "the kidney", "F. Scott Fitzgerald", "aria", "a Harbor chick", "Marquette University", "the monk", "Fall 1998", "infection, irritation, or allergies", "Bart Howard", "Portugal", "Marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "we seek a new way forward, based on mutual interest and mutual respect.\"", "amateur singer TV show.", "acid", "number five"], "metric_results": {"EM": 0.5, "QA-F1": 0.6031249999999999}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, true, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-14869", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16364", "mrqa_searchqa-validation-4803", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-12798", "mrqa_searchqa-validation-11397", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-10594", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-14498", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-1885", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_naturalquestions-validation-2666", "mrqa_triviaqa-validation-3952", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741", "mrqa_newsqa-validation-1645"], "SR": 0.5, "CSR": 0.537854381443299, "EFR": 0.71875, "Overall": 0.6601490012886597}, {"timecode": 97, "before_eval_results": {"predictions": ["4", "a gift given by \"my true love\"", "Gaston Leroux", "Concorde", "gold", "European Monetary System", "cities of Canterbury and Lancaster", "Vietnam", "Florence", "Wanderers", "Emilia Fox", "Amnesty International", "(1596)", "Shaft", "gal", "Ramadan", "Bizet", "Count Basie Orchestra", "Pegida", "plutonium", "sheree Murphy", "Edward Hopper", "Einstein", "Faversham", "Justin Trudeau", "Julia Roberts", "Time Team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "Bolivia", "Christian Wulff", "marinated dried fruits", "usk", "spider", "Malcolm Turnbull", "Daily Herald", "East Africa", "Alan Turing", "bone", "right atrium", "Puck", "the Cassini Division", "Dubonnet", "Persuasion", "Rocky Graziano", "sweater", "Today", "Today", "Gene Vincent", "Midgard", "a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus", "USS Chesapeake", "Ben Faulks", "a Taylor series", "the right bank of the Gomti River", "Art of Dying", "2nd Lt. John Auer,", "Apple's new iOS5 operating system,", "Christopher Savoie", "Plouton", "Ingenue", "World War I", "Joseph"], "metric_results": {"EM": 0.625, "QA-F1": 0.6419642857142858}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true, false, false, true, false, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-2947", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-4806", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-6279", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947"], "SR": 0.625, "CSR": 0.5387436224489797, "EFR": 0.875, "Overall": 0.6915768494897959}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "belfast", "hippopotamus", "mares' tails", "procol harum", "ottune", "clifden", "tintagel", "Uganda", "st Pancras", "lactic acid", "villefranche", "Robinson Crusoe", "newsbooks", "my Favorite Martian", "whist", "fear of snakes", "Madagascar", "Wyatt", "July", "One Direction", "The West Wing", "Prince Harry", "1994", "titanium", "leicestershire", "Pegasus", "alaskan", "Tom Sawyer", "Brazil", "horseradish", "carpentula", "eyes", "karst", "bowie knife", "Nile", "a rat", "Independence Day", "Tinie Tempah", "Portugal", "Greek", "collapsible", "beard", "angel", "cliffes", "Sunday Post", "bobby darin", "emirate", "Nick Griffin", "mansfield park", "South Africa", "Cam Clarke", "drivers who meet more exclusive criteria", "Florida", "twenty-three", "Mexican War on Drugs", "relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsis", "The Tempest", "Naples", "David", "heart"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5021577380952381}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, false, true, false, true, false, false, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.5, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-2636", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-4266", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-487", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-4987", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_searchqa-validation-6488", "mrqa_hotpotqa-validation-3713"], "SR": 0.4375, "CSR": 0.5377209595959596, "EFR": 0.75, "Overall": 0.6663723169191919}, {"timecode": 99, "UKR": 0.767578125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.720703125, "KG": 0.496875, "before_eval_results": {"predictions": ["stoned to death by an angry mob.", "28", "dismissed all charges", "U.S. Defense Department", "11,", "inmates", "Kenyan and Somali", "prostate cancer,", "Philip Markoff", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her; girls banned from school, their books burned, as the hard-core Islamic militants spread their reign of terror across parts of Pakistan.", "Red Lines", "Kirchners", "Sonia Sotomayor", "Arsene Wenger", "Arnold Drummond", "Carrousel du Louvre,", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "his business dealings", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "Alejandro Peralta", "Kerstin Fritzl,", "prisoners' rights and better conditions for inmates, like Amnesty International.", "The Tinkler", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "overthrow the socialist government of Salvador Allende in Chile,", "a lump in Henry's nether regions", "reached an agreement late Thursday", "Snow, which continued to fall", "\"Steamboat Bill, Jr.\"", "dogs who walk on ice in Alaska.", "five days a week.", "school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "as he tried to throw a petrol bomb", "al-Moayad", "\"I wanted to push it up that black a--.\"", "Three thousand", "The Palestinian Islamic Army,", "homicide by undetermined means,", "Peruvian Supreme Court", "2,000", "Nirvana frontman, 27,", "Cirque du Soleil", "9", "for the rest of the year", "94", "Bobby Darin", "foreign investors", "back of the neck", "wrigley's", "CBS", "round five of the 2017 season", "North Dakota", "To Know Him Is to Love Him", "Charlie and the Chocolate Factory", "Death of a Salesman", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5521902142995894}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, true, false, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, true, false, true, false, true, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.33333333333333337, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.875, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-530", "mrqa_newsqa-validation-807", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3457", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4326", "mrqa_triviaqa-validation-7478", "mrqa_triviaqa-validation-3949", "mrqa_hotpotqa-validation-2793", "mrqa_hotpotqa-validation-34"], "SR": 0.453125, "CSR": 0.536875, "EFR": 0.7714285714285715, "Overall": 0.6586919642857143}]}