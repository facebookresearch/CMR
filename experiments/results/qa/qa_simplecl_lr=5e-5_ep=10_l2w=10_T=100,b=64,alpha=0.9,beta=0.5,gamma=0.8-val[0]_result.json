{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4130, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "the Los Angeles Times", "the Broncos", "anticlines and synclines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "Rhenus", "Atlantic", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia terrorist groups", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "the infected corpses", "the United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "Luther states that everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "a shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "an algorithm for multiplying two integers can be used to square an integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "Swedishex GmbH & Co KG", "More than 1 million", "2011", "by the market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Buddhism", "Matthew 16:18", "U.S.-flagged Maersk Alabama", "Rwanda", "revelry", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7736301892551893}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-4289", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-2520", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-4274", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_squad-validation-8014", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.71875, "CSR": 0.7734375, "EFR": 0.9444444444444444, "Overall": 0.8589409722222222}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "a multi-party system", "allows those tainted by sin to nevertheless make a truly free choice to accept or reject God's salvation in Christ", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "Arizona Cardinals", "1991", "Chaffee", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "more integral", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "Ronnie Wood and Brandon Block", "Documents", "the company's factory in Waterford City, Ireland", "nitrogen", "Christopher Nolan", "The Florida current feeds the Gulf Stream that flows east of Cape Hatteras;  (3) the looping motion in Buoy ID 30688", "six", "It always begins with the music", "conductor", "Illinois", "Rafael Palmeiro", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.765625, "QA-F1": 0.8017423876798877}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.16216216216216214, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.19999999999999998, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-803", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-8316", "mrqa_squad-validation-9805", "mrqa_squad-validation-235", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-3629"], "SR": 0.765625, "CSR": 0.7708333333333334, "EFR": 1.0, "Overall": 0.8854166666666667}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "stout man with a \"double chin, strong mouth, piercing deep-set eyes, fleshy face, and squat neck.\"", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "charleston", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "The Commission's President (currently an ex-Luxembourg Prime Minister, Jean-Claude Juncker)", "2000", "oxygen", "increase", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "the Edict of Nantes", "reserved to, and dealt with at, Westminster (and where Ministerial functions usually lie with UK Government ministers)", "multiple revisions", "philanthropic initiative", "integer factorization problem", "inequality", "Isel", "adapted quickly and often married outside their immediate French communities", "John Hancock, John Adams, John Quincy Adams, Rutherford B. Hayes, Theodore Roosevelt, Franklin D. Roosevelt", "Charles-Fer Ferdinand University", "that he had drowned in the Mur River", "yellow fever outbreaks", "Jim Nantz and Phil Simms", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "the late 19th century", "Channel Islands", "charleston", "charleston", "charleston", "charleston", "charleston", "charleston", "charleston", "charleston", "gulfina", "study insects and their relationship to humans, other organisms, and the environment", "charleston", "travis", "charleston", "ireland", "charleston", "24 hours a day and 7 days a week", "Sponsorgate", "charleston"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5206801470588236}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.8235294117647058, 1.0, 0.20000000000000004, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-801", "mrqa_squad-validation-9286", "mrqa_squad-validation-4293", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-7321", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-1150", "mrqa_squad-validation-597", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-6700", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-1024", "mrqa_triviaqa-validation-6556", "mrqa_triviaqa-validation-1581", "mrqa_hotpotqa-validation-437", "mrqa_hotpotqa-validation-3821"], "SR": 0.484375, "CSR": 0.69921875, "EFR": 0.8787878787878788, "Overall": 0.7890033143939394}, {"timecode": 4, "before_eval_results": {"predictions": ["in plants that contain them", "Parliament of Victoria", "Zaha Hadid", "the Marquis de Vaudreuil", "Science and Discovery", "Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "a number of stages", "The Skirmish of the Brick Church", "port city of Kaffa in the Crimea", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "miners", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "1985", "1606", "mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "Sabina Guzzanti", "22", "terror groups that they say were planning numerous suicide attacks, including in the country's largest city of Karachi.", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "a way of getting into that Lexus, Lincoln, Infiniti ororsche you always wanted, without laying out $70,000 or $80,000 for something you're not actually going to live in.", "Muslim", "this will be the first time any version of the Magna Carta has ever gone up for auction", "Monday night where it left off in September with what Sedgwick called \"a fantastic five episodes.\"", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "Julissa Brisman", "one", "Isabella, Emma, Olivia, Sophia, Ava, Emily, Madison, Abigail, Chloe and Mia", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "colombia"], "metric_results": {"EM": 0.671875, "QA-F1": 0.6923655939648586}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3, 0.15999999999999998, 1.0, 0.11428571428571428, 0.0, 0.32, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-4773", "mrqa_squad-validation-2961", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_squad-validation-166", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2965", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.671875, "CSR": 0.69375, "EFR": 0.9047619047619048, "Overall": 0.7992559523809524}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a high-level marketing manager, was given the job of turning the business around.", "500,000", "Ofcom", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence.", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "part of a rule connected with civil disobedience", "June 1978", "Milton Latham", "1914", "Philippines", "the Broncos", "1950s to 2011", "the spoils of the war", "German Te Deum.", "1795", "Bermuda 419", "evaporated to cool oxygen gas", "Infinity Broadcasting Corporation", "\"semi-legal\" and was the only opposition group in Egypt able to field candidates during elections.", "1972", "rudimentary", "1957", "mother-of-pearl made between 500 AD and 2000", "Gene Barry", "the Secretary of State and ambassadors are appointed by the President, with the advice and consent of the Senate", "It is mainly for the purpose of changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings.", "from an Ohio newspaper on 8 February 1925", "Herbert Hoover, has made at least one State of the Union report as a speech delivered before a joint session of Congress", "angular rotation", "Panning", "Justin Timberlake", "the following 15 countries or regions have reached an economy of at least US $2 trillion by GDP in nominal or PPP terms", "police, troops, and military experts. European nations contribute nearly 6,000 units to this total", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's has 62 locations in Canada", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "the seven ages of man : infant, schoolboy, lover, soldier, justice, Pantalone and old age", "most episodes feature a storyline taking place in the present ( 2016 -- 2018, contemporaneous with airing )", "Morgan Freeman reprising his role as detective Alex Cross.", "David Gahan ( / \u0261\u0251\u02d0n / ; born David Callcott ; 9 May 1962 ) is an English singer - songwriter", "it includes a restaurant, spa, and bed - and - breakfast and provides guided tours which feature the history and alleged paranormal activity of the site", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "people prepare for the long Lenten fast", "Jaipur", "Jonas Olsson,", "a relatively small and fast naval ship designed to carry torpedoes into battle.", "Newport"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6622156005544163}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 0.2666666666666667, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.25, 1.0, 0.7200000000000001, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.0, 1.0, 0.0, 0.2857142857142857, 0.3157894736842105, 1.0, 0.0, 0.0, 0.3636363636363636, 0.631578947368421, 0.0, 0.5833333333333334, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-4836", "mrqa_squad-validation-9552", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-7488", "mrqa_squad-validation-9908", "mrqa_squad-validation-3473", "mrqa_squad-validation-9635", "mrqa_squad-validation-5451", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.546875, "CSR": 0.6692708333333333, "EFR": 0.9655172413793104, "Overall": 0.8173940373563218}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "\"social and political action,\" declared that \"To perform its mission in the society, a university must sustain an extraordinary environment of freedom of inquiry and maintain an independence from political fashions, passions, and pressures.\"", "1936", "the New Birth", "gold", "a deficit", "Costiff collection of 178 Vivienne Westwood costumes", "reciprocating Diesel engines, and gas turbines,", "disease", "\"TFIF\"", "Confucian propriety and ancestor veneration", "\"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "a chain or screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "teachers in publicly funded schools must be members in good standing with the college, and private schools may also require their teachers to be college peoples.", "end of the season", "10", "Michael, Alexander, William, Joshua, Daniel, Jayden, Noah and Anthony.", "African-Americans", "will not support the Stop Online Piracy Act", "David Duchovny, playing what the tabloidoids would have you believe is an autobiographical role, has managed to hang onto his Bukowski-phase well into his forties.", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer, can put users in a dazed stupor for about two hours,", "New York apartment in 1980", "Stuttgart on Sunday.", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "North Korea's reclusive leader Kim Jong- Il", "first five Potter films", "know what's important in life", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "a \"stressed and tired force\" made vulnerable by multiple deployments", "James Whitehouse, has been quoted as saying she has terminal brain cancer, according to a blog called Manson Family Today.", "we want to ensure we have all the capacity that may be needed over the course of the coming days.", "a series of monthly meals for people with food allergies.", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "Mike Gatting", "Colgate University", "Church of Christ, Scientist", "a fat or fatty acid in which there is at least one double bond within the fatty acid chain", "New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16, and Acts 1 : 13 ) indicate that all the apostles were men"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6519581194948842}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.28571428571428575, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 0.16, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.45454545454545453, 0.2857142857142857]}}, "before_error_ids": ["mrqa_squad-validation-7950", "mrqa_squad-validation-5441", "mrqa_squad-validation-3370", "mrqa_squad-validation-6001", "mrqa_squad-validation-486", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.578125, "CSR": 0.65625, "EFR": 0.9629629629629629, "Overall": 0.8096064814814814}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism in the Small Catechism", "Jim Gray", "P = PSPACE", "July 1969", "German citizens when Hitler's secret police demanded to know if they were hiding a Jew in their house.", "yellow chlorophyll precursor", "spontaneous", "the courts of member states", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "\u00a320,427", "21 October 1512", "James O. McKinsey", "dance Your Ass Off", "their \"Freshman Year\" experience", "India", "Zulfikar Ali Bhutto, former president and prime minister of Pakistan", "at the country's third-largest oil refinery", "April 24 through May 2", "Krishna Rajaram,", "early detection", "250,000", "Timothy Masters", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "William S. Cohen", "\"Dance Your Ass Off\"", "interrogations that have been obtained from detainees through interrogation and cruel treatment, such as waterboarding, will no longer be admitted as evidence before the commissions", "Gary Brooker", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian.", "a \"stressed and tired force\" made vulnerable by multiple deployments", "Japanese officials", "patrolling the pavement", "\"Empire of the Sun,\"", "Norman given name Robert", "Olympics", "Matt Winer", "Henry Fonda", "opposite R\u00fcgen island", "Mustique, St. Vincent & the Grenadines, West Indies", "green"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6935687576312577}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true, true, true, true, false, true, false, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4615384615384615, 0.5, 1.0, 1.0, 1.0, 0.0, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.4, 0.0, 0.0, 0.2857142857142857, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-2448", "mrqa_squad-validation-1796", "mrqa_squad-validation-3938", "mrqa_squad-validation-1556", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-417", "mrqa_naturalquestions-validation-6514", "mrqa_hotpotqa-validation-4367", "mrqa_searchqa-validation-7977", "mrqa_triviaqa-validation-2858", "mrqa_triviaqa-validation-4305"], "SR": 0.609375, "CSR": 0.650390625, "EFR": 0.84, "Overall": 0.7451953124999999}, {"timecode": 8, "before_eval_results": {"predictions": ["2009", "The British provided medical treatment for the sick and wounded French soldiers and French regular troops were returned to France aboard British ships with an agreement that they were not to serve again in the present war.", "Roman Catholic", "a renegade Time Lord who desires to rule the universe", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday", "\"Journey's End\"", "immediate", "Levi's Stadium", "Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan", "Galileo Galilei and Sir Isaac Newton", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington Railway", "autonomy", "Islamic", "$24.1 million", "Fernando Gonzalez", "Graeme Smith", "a strong work ethic is the reason for his longevity in the movie", "finance", "terminal brain cancer.", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "Employee Free Choice act", "separated", "Animal Planet", "crashing his private plane into a Florida swamp.", "there were no radar outages and said it had not lost contact with any planes during the computer glitches.", "54 bodies", "early detection and helping other women cope with the disease.", "Diversity", "$250,000", "make sure water continues flow through the river channel and not spread out over land.", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president was declared the winner of the country's presidential elections on Thursday,", "2050", "Alfredo Astiz, a former Navy captain whose boyish looks and deceitful ways", "Abdullah Gul,", "Carl Froch", "The Everglades, known as the River of Grass,", "when the cell is undergoing the metaphase of cell division", "Gibraltar", "New Orleans Pelicans", "large sums were still demanded for the bulbs of a very few rare and... a Haarlem connoisseur named Aert Huybertsz. paid 850 guilders for a single bulb", "MIBs", "They", "Hockey has to be the most difficult sport to be a play-by-play announcer."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6751858278174068}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.13333333333333333, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 0.7368421052631579, 0.0, 1.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 0.3076923076923077, 1.0, 0.0, 0.2857142857142857, 0.2222222222222222, 1.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-10341", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-1542", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3910", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.59375, "CSR": 0.6440972222222222, "EFR": 0.8461538461538461, "Overall": 0.7451255341880342}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "His wife Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "hoos", "30%\u201350% O2", "very badly disposed towards the French, and are entirely devoted to the English.", "the top 15 most populous", "CRISPR sequences", "six", "300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "the substance of the statement", "Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "engaging with the Taliban in Pakistan and Afghanistan.", "25", "a treadmill", "couple's surrogate lost the pregnancy.", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "at least two and a half hours", "Elin Nordegren", "American and European consumers", "6,000", "cortisone", "President Clinton", "delivered three machine guns and two silencers to the hip-hop star,", "Morgan Tsvangirai.", "policing the world and Africa", "future relations between the Middle East and Washington", "canyon in the path of the blaze", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school", "strife in Somalia", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia, Illinois", "violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "they did not know how many people were onboard.", "London", "after Shawn's kidnapping", "immediate physical and social setting in which people live or in which something happens or develops.", "William Tell", "Andr\u00e9 3000", "Groundhog Day", "Cleopatra,", "fairground"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6653195154873544}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.17391304347826086, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.8333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.4, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-3687", "mrqa_squad-validation-2429", "mrqa_squad-validation-9194", "mrqa_squad-validation-9484", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-11812"], "SR": 0.59375, "CSR": 0.6390625, "EFR": 0.8076923076923077, "Overall": 0.7233774038461538}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction", "The Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "fractured pelvis and sacrum -- the triangular bone within the pelvis.", "issued his first military orders as leader of North Korea", "light snow or flurries", "Willem Dafoe", "\"Maude\"", "Phillip A. Myers", "Korea", "The University of California San Diego has suspended a student who admitted to hanging a noose in a campus library,", "58", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Lance Cpl. Maria Lauterbach", "Dangjin", "\"novel that you would embarrassed to buy,\"", "Chinese President Hu Jintao", "magazine, GospelToday,", "Mikey", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next.", "President Bush", "Jeffrey Jamaleldine", "2,800", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "kabinett -", "Lionsgate", "James David Lofton", "Sanskrit", "hair-like structures that help paramecium move around."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6658617424242425}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_squad-validation-1299", "mrqa_squad-validation-8655", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-13", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.578125, "CSR": 0.6335227272727273, "EFR": 0.9259259259259259, "Overall": 0.7797243265993266}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "hermaphroditism and early reproduction", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company under the Office of Alien Property (OAP) seal.", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching.", "Elway", "Philo of Byzantium", "36 acres", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "David Copperfield", "pink mouse type creatures", "antelope", "nipples", "Precambrian period", "cooperative", "Anastasia Dobromyslova", "Lady Gaga", "9", "The Live Read of Space Jam 2", "European radishes", "Robert Ludlum", "magical", "(.mov)", "The Donington Grand Prix Collection is, quite simply, the largest showcase of Grand Prix racing cars in the world", "It\u2019s Only Rock and Roll", "Hebrew alephbet", "London Underground Piccadilly Line", "Wisconsin", "orangutan", "Manet", "The Magic Finger", "Oberlin College in Ohio,", "2005", "1969", "DodgeDodge", "dolt", "Venice", "a peplos.", "Enrico Caruso", "Elizabeth Arden", "lightweight baby buggy with a collapsible support assembly", "Sir Hardy Amies", "Antigua and Barbuda", "patronymic surname", "Can't Get You Out of My Head ''", "Cody Miller", "Bloomingdale Firehouse", "Israel's vice prime minister compared Iran to Nazi Germany", "Golden Gate Yacht Club of San Francisco", "Antonio Canova", "\"No woman, no cry\"", "Buddhism"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6182562625728676}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, false, true], "QA-F1": [0.5, 1.0, 1.0, 0.2608695652173913, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 0.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-2092", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-3759", "mrqa_triviaqa-validation-5743", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-2331", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983", "mrqa_searchqa-validation-13120"], "SR": 0.515625, "CSR": 0.6236979166666667, "EFR": 0.967741935483871, "Overall": 0.7957199260752689}, {"timecode": 12, "before_eval_results": {"predictions": ["the Southern Border Region", "70-50's", "Panini", "new laws or amendments to existing laws as a bill", "anti-colonial movements", "Rhine Valley", "Streptococcus", "experience", "Zhongshu Sheng", "legitimate medical purpose", "cases of an express wish of the people to withdraw from the EU", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "because the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "Ness Point", "lachey", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "Nick Boles", "he was not a British soldier and did not have amnesia.", "Vladivostok", "Sheryl Crow", "tESLAR", "Camellia sinensis", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "astronomy", "gin", "George Clooney", "Eric Coates", "James Chadwick", "\"No one was saved\"", "Monopoly", "champagne", "a pluvial was an extended period of abundant rainfall lasting many thousands of years.", "the U.S.", "Brigit Forsyth", "salt", "state of Japan", "\"problem play\"", "Thomas Edward Lawrence", "Kent", "Renoir\u00b4s", "Vanguard", "white", "Switzerland", "gin", "people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Derek Mears", "bremen", "The Goat Amalthea", "Buster Keaton"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6068222402597403}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.2857142857142857, 0.0909090909090909, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9600000000000001, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9452", "mrqa_squad-validation-6655", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_squad-validation-4590", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-3032", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-2446", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_searchqa-validation-8450", "mrqa_searchqa-validation-9647", "mrqa_newsqa-validation-3860"], "SR": 0.578125, "CSR": 0.6201923076923077, "EFR": 0.9629629629629629, "Overall": 0.7915776353276354}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "the Black Death", "their own militia", "days, weeks and months", "Over 61", "quality of a country's institutions", "cilia", "friction", "Sky Digital", "2005", "force", "mustelids", "John Connally", "saffron", "HYMENAEUS", "gods", "albinism", "The Straits of Tiran", "Brigit Forsyth", "Call My Bluff", "March 10, 1997", "crazed Holiday", "The Battle of the Three Emperors", "Velazquez", "Ashe", "lizards", "strong, cold south-westerly wind", "table tennis", "medical literature", "penhaligon", "Gandalf", "c. Auguste Dupin", "Jinnah International", "Monday", "capital of Venezuela", "beads", "soap", "liquor", "Avro", "Genesis", "Charlie Brooker", "linden", "Harrods", "2007", "cher", "Scarface", "pale yellow", "dior glazing", "bubba", "June 12, 2018", "Filipino American", "London", "Lambic", "Nook", "Steven Green", "c", "fortune", "a sovereign principality located along the Mediterranean Sea in the...", "Synchronicity"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6166666666666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-6933", "mrqa_squad-validation-2920", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-3807", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-372", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-6628"], "SR": 0.546875, "CSR": 0.6149553571428572, "EFR": 0.9310344827586207, "Overall": 0.7729949199507389}, {"timecode": 14, "before_eval_results": {"predictions": ["seven months", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "it is separated from the body", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "a declining state of mind", "1898", "The Deadly Assassin and Mawdryn", "radioisotope thermoelectric generator", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat in the hat", "2020", "1974", "332", "1997", "Authority", "senior enlisted sailor", "Spanish moss", "Chinese cooking for over 400 years", "Vienna", "World Trade Center Transportation Hub", "Kevin Spacey", "All Hallows'Day", "78", "main type of cell found in lymph", "Bangladesh -- India border", "President", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "January 12, 2017", "the United States", "claims adjuster", "The neck", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column ( spine)", "three", "perennial", "boudin", "kew Gardens", "Nikita Khrushchev", "$500,000", "young self-styled anarchists", "reaper", "NYPD Shield", "BBC building in Glasgow, Scotland", "a thick stack of paper"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7071746056630568}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false, false], "QA-F1": [0.8, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.37499999999999994, 1.0, 0.28571428571428575, 0.6666666666666666, 0.25, 0.3333333333333333, 1.0, 0.5, 0.2857142857142857, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-653", "mrqa_squad-validation-125", "mrqa_squad-validation-2339", "mrqa_squad-validation-7670", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.5625, "CSR": 0.6114583333333333, "EFR": 0.9285714285714286, "Overall": 0.770014880952381}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "The Late Show with Stephen Colbert", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "CBS", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "60", "Seattle, Washington", "Battle of Antietam", "Dimitar Berbatov and Carlos Tevez", "In Time", "early 3rd century", "Glenn Close", "three", "Agostino Bassi", "five", "Malibu, California", "the church at Philippi", "Dutch navy captain Jurriaen Aernoutsz", "September 2017", "Professor Kantorek", "1546", "Jane Fonda", "Bhupendranath Dutt", "Grey Wardens", "Dr. Lexie Grey ( Chyler Leigh )", "Majandra Delfino", "September 1972", "Uruguay", "Alex Skuby", "Thomas Middleditch", "The National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "Director of National Intelligence", "D.A.D. a.", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal. The Man", "John Coffey", "Rachel Kelly Tucker", "Bohemia", "conanous wings", "Code 02PrettyPretty", "musician", "the parliament within 15 days.", "abduction of minors", "new Mexico, Colorado, Wyoming and Montana,", "Pablo Neruda", "Stage Stores, Inc.", "1881"], "metric_results": {"EM": 0.484375, "QA-F1": 0.591587449009324}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.5454545454545454, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.0, 1.0, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_squad-validation-551", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_newsqa-validation-2674", "mrqa_searchqa-validation-13473", "mrqa_searchqa-validation-5103", "mrqa_hotpotqa-validation-1852"], "SR": 0.484375, "CSR": 0.603515625, "EFR": 0.8787878787878788, "Overall": 0.7411517518939394}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "the Arizona Cardinals", "Bert Bolin", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Khitan", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Vancouver", "Microsoft Office", "SAVE", "SAS Fr\u00f6sundavik Office Building in Solna Municipality, Sweden", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award Best Actor", "Jello Biafra drew on Nardwuar's face with a marker pen", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson, David Michener, and the team of John Musker and Ron Clements", "Sir William McMahon", "North Sea", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "CAC FC-1 \"Xiaolong\"", "Delacorte Press.", "Neighbourhood is generally defined spatially as a specific geographic area and functionally as a set of social networks.", "Secretariat", "Wake Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth", "\"Southern Living\"", "Thomas Harold Amer", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Alticor", "Parlophone Records", "South Africa", "Surrey", "\"My Sassy Girl\"", "Charles Russell", "Boyd Gaming", "Anthony Davis of the New Orleans Pelicans", "1968", "Glenn Close", "Florence Glenda Ballard", "Neighbours", "Ewan McGregor", "2011", "Alice Lloyd College", "an enslaved African American", "power-sharing talks", "Brown-Waite"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6596947017443342}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.3636363636363636, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 0.5, 0.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2409", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.578125, "CSR": 0.6020220588235294, "EFR": 0.8888888888888888, "Overall": 0.7454554738562091}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter status", "1830", "nonfunctional pseudogenes", "inner chloroplast membrane", "Charlie Harper", "Stevie Wonder", "beaver", "La Boh\u00e8me", "formic acid", "Toledo", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Xenophon", "London Pride", "Fresh Water Load Line", "Nick Hornby", "\"The Two Gentlemen of Verona\"", "Charles V", "King of Mann", "Lagertha", "weight plates", "\"big house\"", "Hadrian", "California", "murine typhus", "Moonee Ponds, a suburb in Melbourne, Victoria", "Essen", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "Manchester United", "Prokofiev", "Jessica Simpson", "Boy George", "Finland", "3000m", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "It was a Confederate victory", "New Jewel Movement", "sub-Saharan Africa", "U.S. 93", "Anjuna beach in Goa", "Lev Ivanov", "Oshkosh", "\"Papa's Got a Brand New Bag\"", "Jesse James", "\"The Sunday Thing\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6505580357142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.28571428571428575, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.7499999999999999, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7089", "mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_naturalquestions-validation-767", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.5625, "CSR": 0.5998263888888888, "EFR": 0.9642857142857143, "Overall": 0.7820560515873016}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "1994", "Coppolas and, technically, the Farrow / Previn / Allens", "Allison Janney", "Isthmus of Corinth", "Aphasia is an inability to comprehend and formulate language because of damage to specific brain regions", "Splodgenessabounds", "Tyrion", "electron donors", "Alison", "1985", "19 state rooms", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Alice", "2 September 1990", "Coton in the Elms", "pass grades 1 ( threshold 85 %, a distinction )", "Zoe Badwi", "in 1995", "Definition of the problems and / or goals", "16 August 1975", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "`` Killer Within ''", "Western Australia", "arterioles", "July 21, 1861", "Dr. Addison Montgomery", "capital and financial markets", "An optional message body", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "universal significance", "September 2017", "moral", "Rising Sun Blues", "Part 2", "dumbo", "the duke of Monmouth\u2019s rebellion", "Christian", "Robert L. Stone", "2008", "Yemen", "jegna", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6498854366307927}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, false, true, false, false, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 1.0, 0.2857142857142857, 1.0, 0.0, 0.4210526315789474, 1.0, 0.19999999999999998, 1.0, 0.0, 0.6666666666666666, 0.4, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.2, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6242", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-8908", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9836", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-7111", "mrqa_hotpotqa-validation-4735"], "SR": 0.5625, "CSR": 0.5978618421052632, "EFR": 0.9642857142857143, "Overall": 0.7810737781954887}, {"timecode": 19, "before_eval_results": {"predictions": ["Luther reviews and reaffirms, on the one hand, what has been called the \"second use of the law,\"", "black", "Illinois Country", "Jaime Weston", "1978", "high art and folk music", "warming", "the mid-sixties", "270,000", "Long troop deployments", "Joe Pantoliano", "a Florida girl who disappeared in February", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "32 percent", "Falkland Islands to carry a government permit.", "Tuesday", "forgery and flying without a valid license", "Anil Kapoor", "55", "President Obama", "unwanted baggage from the 80s", "The Louvre", "snowstorm", "exotic sports cars", "11 healthy eggs", "Mutassim", "two Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18,", "\"GoldenEye\"", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic,", "alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone", "\u00a341.1 million", "Kingman Regional Medical Center", "CNN", "Manmohan Singh", "Michael Jackson", "be silent", "40 militants and six Pakistan soldiers dead", "Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Louisiana", "the Southeast", "jenkins", "Carol Browner", "\"A Mother For All Seasons.\"", "a tracheotomy, a surgical procedure in which an opening is made into the airway through an incision in the neck to allow for suction of fluid out of the lungs.", "back at work", "Georgia Aquarium", "27", "Corbin Bleu and Karina Smirnoff", "John Adams", "ciorb", "Zager and Evans", "Bob Hurley", "fourth term", "obscenity", "cavalry", "Lapland", "2000", "Emad Hashim"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5996247964997965}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, false, true, false, false, false, true, false, true, true, false, false, false, true], "QA-F1": [0.14814814814814814, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.13333333333333336, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.923076923076923, 0.6666666666666666, 0.8333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_hotpotqa-validation-4760", "mrqa_searchqa-validation-8011", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-5120"], "SR": 0.484375, "CSR": 0.5921875, "EFR": 0.8181818181818182, "Overall": 0.7051846590909091}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "Rhenus", "1331", "Death wish Coffee", "L", "Cameroon", "1994", "ballots", "clothes that are consistent and accessible", "three empty vodka bottles,", "training Afghan police and troops, before trading his uniform for a diplomat's business suit.", "Bobby Darin,", "Nico Rosberg", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "composer of \"Phantom of the Opera\" and \"Cats\"", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony, 2,", "Amanda Knox's aunt", "half Moon Bay (some weighing well over 1,000 pounds)", "Iran's development of a nuclear weapon", "12 shades of violet, including a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, relaxing near-black on red-eyes when it's time to sleep.", "allegedly faking a doctor's note and was restricted from leaving his house in Tokyo,", "ceo Herbert Hainer", "Brett Cummins,", "a nearby day care center whose children are predominantly African-American.", "inmates", "Col. Elspeth Cameron-Ritchie,", "E! News", "Six members of Zoe's Ark", "jobs", "saying Tuesday the reality he has seen is \"terrifying.\"", "waterboarding at least 266 times on two top al Qaeda suspects,", "Mexico's attorney general's office responded with a statement saying that it would investigate the video and any group that tries to take justice into its own hands.", "Republicans", "\"They left without me,'", "Alexandros Grigoropoulos,", "deciding the duties of the new prime minister has been a sticking point in the negotiations.", "a 57-year old male deep in a mid-life crisis is proven.", "North Korea intends to launch a long-range missile in the near future,", "Angola", "Matthew Fisher,", "\"outlaws\"", "boogeyman Jason Voorhees", "This was not any one particular act; this was just a combination of things that had a medical impact on him, that hurt his health.", "Sea World in San Antonio", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "the WSSRC had received about 50 formal applications for speed attempts during 2008.", "the Ku Klux Klan", "MGM prohibited the release until The Wizard of Oz ( 1939 ) had opened and audiences heard Judy Garland perform it", "Yale University", "Bury, Oldham, Rochdale, Stockport, Tameside, Trafford, Wigan, and the cities of Manchester and Salford.", "stamens", "Malayalam movies", "August 17, 2017", "a jacket, gloves or a briefcase", "mice followed, in the '80s | clone. right: Dave.", "Hodel", "the benefits of the US privacy Act to Europeans and gives them access to US courts", "Coldplay"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5020393866610973}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false, false, true, false, true, false, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.10526315789473684, 0.0, 0.0, 1.0, 0.9523809523809523, 0.0, 0.25, 0.23076923076923078, 0.8, 1.0, 0.6153846153846153, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.14814814814814814, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 0.0, 0.19047619047619047, 0.15384615384615385, 1.0, 0.1111111111111111, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.5263157894736842, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-10284", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-3783"], "SR": 0.40625, "CSR": 0.5833333333333333, "EFR": 0.9473684210526315, "Overall": 0.7653508771929824}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "\u201cUnder The Sea\u2019 From \u201cThe Little Mermaid\u2019 Is The Best Way To Start Your Weekend\u201d", "Nicola Adams", "copper and zinc", "eagle", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "undersirts", "Madonna's", "Glasgow", "road map", "Australia", "Gastronomy", "Pearson PLC.", "Irish Setter", "American Civil War", "Loch Awe", "rochner", "Tasmania", "medium-sized", "Taiwan (or Republic of China)", "Harrisburg", "mink mink,", "glockenspiel", "Dr John Sentamu", "rochoon", "Cruella de Vil", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "Charlemagne", "the A's west to Oakland,", "Russell Crowe", "Theodore Roosevelt", "roch", "Robin Goodfellow", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "Atlantic", "Albert Square", "Newbury", "the Old Testament", "estimated 70 million people", "Target Corporation", "Sister, Sister (1982 film)", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "International NGO", "John Jackson Dickison", "better conditions for inmates, like Amnesty International.", "talk show queen Oprah Winfrey.", "his mother."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6111111111111112}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-3498", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-4805", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2484", "mrqa_searchqa-validation-11802", "mrqa_searchqa-validation-1273", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.546875, "CSR": 0.5816761363636364, "EFR": 0.896551724137931, "Overall": 0.7391139302507836}, {"timecode": 22, "before_eval_results": {"predictions": ["coughing and sneezing", "1765", "along the frontiers between New France and the British colonies", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "hydrocodone", "ireland", "Robert Peary", "pearls", "Utah", "Carrie Underwood", "whisky", "he made his horse a consul, his palace a brothel, and his...", "Google", "Langston Hughes", "Pain tolerance", "blacking", "Tito Puente", "riata", "unFINISHED OPERAS", "USS LST 325", "black and Tan Coonhound", "David Beckham", "Arturo Toscanini", "economics", "Andes flight disaster", "the triumphal arch", "Montenegro", "discus", "kouign", "basidiomycota", "James Gandolfini", "Georgia Thomas", "president of the Democratic Republic of the Congo", "blacksmith", "a tangible and visible entity", "black", "Plutarch", "Rudy Giuliani", "masa", "40 seconds", "the Vikings.", "fairfield Street", "champs Elysees", "typhoid fever", "fjord", "baviere-quebec.org", "Williamsburg", "Jul 13, 2010", "tualatin", "hydrogen peroxide & yeast creates foam, steam & notably causes heat to be given off in this type of 10-letter chemical reaction", "John Knox", "the internal reproductive anatomy", "$612.4 million", "risk factors for disease and targets for preventive healthcare", "jape", "Tesco", "A4", "Graham Hill", "Battelle Energy Alliance.", "IT", "debris", "$10 billion", "Bailey, Colorado,"], "metric_results": {"EM": 0.34375, "QA-F1": 0.40585847975553857}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, true, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.09090909090909091, 1.0, 0.5, 0.0, 0.14285714285714285, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10104", "mrqa_squad-validation-6429", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-12564", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-2327", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-1118", "mrqa_hotpotqa-validation-68", "mrqa_newsqa-validation-1997"], "SR": 0.34375, "CSR": 0.5713315217391304, "EFR": 0.9523809523809523, "Overall": 0.7618562370600414}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "the Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "the Gulf of Mexico", "domestic cat in America", "sister", "Basel, Switzerland", "The Argonauts", "prometheus", "Altamont Speedway Free Festival", "John F. Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a multi-user real-time virtual world described entirely in text.", "Italy", "Khaki", "magma", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "the Mendip Hills", "President George W. Bush", "the Earth", "Nafea Faa Ipoipo?", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "New Netherland", "Justin Trudeau", "aircraft, ships, spacecraft, guided missiles, motor vehicles, weather formations", "Denis Law", "Love Is All Around", "William Golding", "Sally Ride", "Earthquake", "Fife", "Money Saving", "Adidas", "The Hunting of the Snark", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "the unoccupied square or one occupied by an opponent's piece, which is captured and removed from play.", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "The Wall Street Journal Europe", "fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7294730392156863}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-3164", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848"], "SR": 0.671875, "CSR": 0.5755208333333333, "EFR": 1.0, "Overall": 0.7877604166666666}, {"timecode": 24, "before_eval_results": {"predictions": ["illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins", "the chosen machine model", "20th Century Fox, Lionsgate, Paramount Pictures, Universal Studios and Walt Disney Studios", "1997", "a suite of network protocols created by Digital Equipment Corporation", "his son, Isaac, and daughter, Rebecca.", "15", "the first home series defeat on Australia in almost 16 years", "between Pyongyang and Seoul", "fatally shooting a limo driver on February 14, 2002.", "11", "change course", "Alwin Landry's supply vessel Damon Bankston", "Chaffetz is a conservative Republican married father of three who is sleeping on a cot in his congressional office to save money.", "money or other discreet aid for the effort", "Sarah", "illegal crossings into U.S. waters.", "environmental", "Costa Rica", "Afghan security", "Saturday", "38", "70,000 or so", "the single European Sky initiative", "E! News", "national coach", "Steve Williams", "McDonald's", "crafts poems telling of the pain and suffering of children just like her; girls banned from school, their books burned,", "pastor Paula White", "at the end of the year it's been very hectic.", "Diego Maradona", "Dog patch Labs", "club-themed", "two", "Itawamba County School District", "the former Massachusetts governor", "EU naval force", "Plymouth Rock", "Liza Murphy", "the nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "police", "former U.S. secretary of state", "At least 33", "Samir Kuntar", "get better skin, burn fat and boost her energy.", "the black market of prison life", "the most powerful form of prevention is believing that students can help stop crime from happening.", "Alwin Landry's", "karthik Rajaram", "Sunday,", "killing", "an Irish feminine name", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "Northern Ireland", "radio waves", "art", "the 16th season for the Minnesota Timberwolves in the National Basketball Association.", "23", "South America", "freestyle", "the Nightingale", "the Kingdom of the Crystal Skull"], "metric_results": {"EM": 0.359375, "QA-F1": 0.5270772316647943}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 1.0, 0.09090909090909091, 0.8333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7741935483870968, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 0.5, 0.0, 0.15384615384615383, 0.0, 0.19354838709677422, 1.0, 0.5, 0.25, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.7272727272727273]}}, "before_error_ids": ["mrqa_squad-validation-6846", "mrqa_squad-validation-610", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3169", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-1405", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-1545", "mrqa_searchqa-validation-3826"], "SR": 0.359375, "CSR": 0.566875, "EFR": 0.926829268292683, "Overall": 0.7468521341463414}, {"timecode": 25, "before_eval_results": {"predictions": ["its 50th anniversary special", "Thomas Savery", "Vicodin, generically known as hydrocodone", "Eastern crops such as carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago", "a violent separatist campaign", "Eleven people died and 36 were wounded", "269,000", "The three men entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "38 feet", "Eintracht Frankfurt", "150", "a man had been stoned to death by an angry mob.", "Russian bombers", "41,", "Los Alamitos Joint Forces Training Base", "the company has not yet managed to sell the concept to a buyer.", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "Quebradillas.", "the Russian air force,", "34", "the eventual closure of Guant Bay prison and CIA \"black site\" prisons, and placed interrogation in all American facilities by all U.S. personnel under the guidelines of the Army Field Manual.", "carbon neutral airline.", "Amanda Knox's aunt", "\"They don't go that you could cut off all the commands out to the control surfaces,\"", "ensuring that all prescription drugs on the market are FDA approved", "customers", "Tom Baer.", "Pakistan", "The oceans are kind of the last frontier for use and development,\"", "a two-piece bathing suit", "Brian Mabry", "iTunes,", "Sunday.", "60 euros -- $89 --", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment,", "The tower will be built in the Saudi town of Jeddah and will be part of a larger project that will cost $26.7 billion, (100 billion Saudi riyals)", "his wife's name", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "2006", "San Diego", "five", "Bergdahl, 23, was captured June 30 from Paktika province in southeastern Afghanistan,", "@", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "National Police", "heart", "Hyderabad", "between the Mediterranean Sea to the north and the Red Sea", "to stay, abide", "Las Vegas", "Jackson Pollock,", "Wye", "McComb, Mississippi", "October 4, 1970", "King Duncan", "Brasstown Bald", "Monopoly", "taking a walk"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5292503571397412}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, true, false, true, false], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.8750000000000001, 1.0, 0.8, 0.25, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.29411764705882354, 0.0, 1.0, 0.0, 0.07407407407407408, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.1111111111111111, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.2608695652173913, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1695", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-1982", "mrqa_searchqa-validation-9476"], "SR": 0.4375, "CSR": 0.5618990384615384, "EFR": 0.8888888888888888, "Overall": 0.7253939636752136}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "pro-democracy activists clashed Friday with Egyptian security forces", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot", "Hong Kong's Victoria Harbor", "2002", "six prostitutes and a runaway involved in the drug trade.", "the legitimacy of that race.", "think are the best.", "three", "Monday", "Scarlett Keeling", "two years,", "nearly 28 years", "regulators in the agency's Colorado office", "military trials for some Guantanamo Bay detainees.", "July", "Akshay Kumar", "Alan Graham", "the Indians were gathering information about the rebels to give to the Colombian military.", "\"disagreements\" with the Port Authority of New York and New Jersey,", "September,", "Michelle Rounds", "James Newell Osterberg", "death of Prince George's County police Cpl. Richard Findley,", "Phil Spector", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "Izzat Ibrahim al-Douri, the highest ranking former member of Saddam Hussein's regime still at large,", "dependable Camry", "sexual assault", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "a Yemeni cleric and his personal assistant,", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "same-sex civil unions,", "military veterans", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units", "6 - 6 with one win against a team from the lower Football Championship Subdivision ( FCS )", "Bongos", "Jack Frost", "the innermost digit of the forelimb", "1974", "25 million", "Peoria, Illinois", "Honolulu", "water", "King", "Ottoman Empire"], "metric_results": {"EM": 0.5625, "QA-F1": 0.649428777921425}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, true, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.10256410256410256, 0.6666666666666666, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-9563", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_hotpotqa-validation-5856", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.5625, "CSR": 0.5619212962962963, "EFR": 0.8928571428571429, "Overall": 0.7273892195767195}, {"timecode": 27, "before_eval_results": {"predictions": ["in the early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "bank robber John Dillinger,", "what caused the collapse of the building", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen,", "a government-run health facility that provides her with free drug treatment.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Los Angeles Angels", "eight Indian army troopers, including one officer, and 17 militants,", "\"There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "in a Starbucks", "BADBUL", "98", "2008", "near the Somali coast", "chairman of the House Budget Committee,", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "between government soldiers and Taliban militants", "South Dakota State Penitentiary", "Iran", "last month's Mumbai terror attacks", "people have chosen their rides based on what their cars say about them.", "in July", "Sudanese nor orphans,", "Four Americans", "his father, Josef Fritzl,", "Glasgow, Scotland", "At least 38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "in the city center,", "broken pelvis", "Wednesday", "the abduction of minors.", "gun", "Jennifer Aniston, Marta Kauffman, co-creator of the series \"Friends\" and Kristin Hahn,", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "Missouri", "largest city", "beta blockers"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7352511459129106}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, false, true, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5333333333333333, 0.3636363636363636, 0.4444444444444445, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 1.0, 1.0, 0.23529411764705885, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4094", "mrqa_newsqa-validation-4138", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-2656", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2906", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-436", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-14535"], "SR": 0.59375, "CSR": 0.5630580357142857, "EFR": 1.0, "Overall": 0.7815290178571428}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author", "rule", "1981,", "forgery and flying without a valid license,", "a racially-tinged remark made by his former caddy,", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul", "Genocide Prevention Task Force.", "shoot down the satellite that North Korean officials said they plan to launch.", "semiconductors", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "seven", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has,\"", "Anil Kapoor.", "eradication of the Zetas cartel from the state of Veracruz, Mexico,", "The Rosie Show,\"", "Form Design Center.", "the guerrillas detained and \"executed\" eight people on February 6 in the town of Rio Bravo because the Indians were gathering information about the rebels to give to the Colombian military.", "Christianity and Judaism,", "the Dalai Lama's current \"middle way approach,\"", "Russia", "around 8 p.m. local time Thursday", "Passers-by", "one day, Nicole noticed a UPS delivery box where it shouldn't be.", "executive director of the Americas Division of Human Rights Watch,", "750", "300", "Matthew Fisher", "The Ski Train", "Big Brother.", "Ozzy Osbourne", "AbdulMutallab,", "U.S. senators", "inconclusive", "about 5:20 p.m. at Terminal C", "environmental and political events.", "$250,000", "byproducts emitted during the process of burning and melting raw materials.", "School-age girls", "5,600", "a million", "Specter", "Deutschneudorf,", "would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "a deceased organ donor,", "he discussed foreplay, sexual conquests and how he picks up women,", "vertebral column ( spine )", "December 11, 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "the Sidgwick Avenue arts faculty buildings", "Douglas Hofstadter", "\"The Dark Tower\"", "American", "Marmee takes care of her 4 girls while her husband is away serving as an army chaplain in the Civil War.", "Castle Rock", "flat bread"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7059028452692641}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 0.6, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.1111111111111111, 0.0, 1.0, 0.4, 0.9565217391304348, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.631578947368421, 1.0, 0.25, 1.0, 1.0, 1.0, 0.8421052631578948, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.972972972972973, 1.0, 0.08333333333333334, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8616", "mrqa_squad-validation-9810", "mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_searchqa-validation-7309", "mrqa_searchqa-validation-9830"], "SR": 0.578125, "CSR": 0.5635775862068966, "EFR": 0.9629629629629629, "Overall": 0.7632702745849298}, {"timecode": 29, "before_eval_results": {"predictions": ["downward pressure", "El Tem\u00fcr", "estimated 438,000 species", "Marty Ingels", "coaxial", "Pakistan A", "Everbank Field", "7", "Battle of Dresden", "John Churchill,", "1965", "Paris", "fifth", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Province of Syracuse", "1963", "non-alcoholic", "puzzle", "Knoxville, Tennessee", "Washington, D.C.", "Oryzomyini", "Tom Kartsotis,", "2017", "Wayman Tisdale", "Mexico", "Kolkata", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Adventures of Huckleberry Finn", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Major Charles White Whittlesey.", "Floridians", "Virginia", "1996 NBA Slam Dunk Contest", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes", "IB Primary Years Program", "Richard Parker", "South American mainland", "Cecil B. De Mille", "allergic reaction", "Peter Townsend,", "3,000 kilometers (1,900 miles)", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "Swiss art heist", "Russia", "shrimp", "Australia"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6756944444444445}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4444444444444444, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_squad-validation-4347", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-4074", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-8450", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585"], "SR": 0.609375, "CSR": 0.5651041666666667, "EFR": 1.0, "Overall": 0.7825520833333334}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "effects of deforestation", "Prussian army general, adjutant to Frederick William IV of Prussia", "London", "Dave Thomas", "a farmers' co-op", "Danish", "1903", "attack on Pearl Harbor.", "other individuals, teams, or entire organizations.", "ten years of probation", "In Pursuit", "Bolton", "Monty Python's Flying Circus", "Kansas City crime family", "Dirk Werner Nowitzki", "Cecil B. DeMille Award honoree", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E.", "New Jersey", "Norse mythology", "86,112", "Celtic", "Ouse and Foss", "the United States and Canada", "British comedian", "Apatosaurus", "1885", "American", "Frank Thomas' Big Hurt", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "New York City", "The Seduction of Hillary Rodham", "2005", "Lambic", "Tom Clancy's The Division", "Argentina", "Larry Alphonso Johnson Jr.", "Mike Mills", "veto power", "Joseph E. Grosberg", "Chelsea Lately", "276,170 inhabitants", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "Seattle", "discus thrower", "Villa Park", "2005", "228 people", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7005303030303031}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, false, false, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4446", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-6491", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-672", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.578125, "CSR": 0.5655241935483871, "EFR": 0.9629629629629629, "Overall": 0.764243578255675}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "Silent Snow, Secret Snow", "Riptide", "Iowa Demonstration Construction Grant Program", "Disability", "Nassau", "mollusc", "HIV", "Martin Van Buren", "yellow front panels", "Rigoletto", "aardwolf", "Beijing", "Sir Roger Gilbert Bannister", "Inuk", "San Jose", "Yves Saint Laurent", "antlers are true bone", "King Fortinbras", "the War of 1812", "Anna Mary Robertson Moses", "Sailor Moon", "Nevilles Superette", "Dan Brown", "Spectacled bear", "a flurry", "George Harrison.", "Monty Python and the Holy Grail", "topaz 3d", "Milton Berle", "george herbert walker bush", "Congolese", "lunar module", "Almagro", "Dan Marino", "Mars", "clownfish", "E = mc2", "Guru Pitka", "Las Vegas", "soy", "Butterflies", "King Arthur's", "orangutan", "Sonora", "death of Caesar", "Prime Minister of Israel Yitzhak Rabin", "Saul", "Gettysburg National Military Park", "Jack Gleeson", "Plank", "Buddhism", "Carl Johan", "Portugal", "Graham Bond", "Johnson & Johnson", "acidic", "20 March to 1 May 2003", "operates 52 nuclear, hydroelectric and fossil-fuel facilities in the southeastern United States.", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "12.3 million"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5877232142857143}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.28571428571428575, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.42857142857142855, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-6655", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-7151", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-4905", "mrqa_searchqa-validation-13033", "mrqa_triviaqa-validation-4765", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587"], "SR": 0.515625, "CSR": 0.56396484375, "EFR": 0.967741935483871, "Overall": 0.7658533896169355}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62 acres", "Henry Addington", "40", "Libya, on the south by the Central African Republic,", "Shania Twain", "Hillsborough", "insulin and glucagon", "The New York Yankees", "rapid eye movement", "green, red, white", "Stanley", "Ba'ath Party", "French", "Jim Branning", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New", "Sarah Ferguson", "Mercury", "a power factor of one means that the real power is equivalent to the apparent power.", "Peter Butterworth", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "Rio de Janeiro", "his faith that \"something will turn up\"", "aged 75 or older", "Jennifer Lopez", "1664", "Eurythmics", "Fred Perry", "Downton Abbey", "Martina Hingis", "painter", "cyclops", "Toonhound", "Michael Miles.", "Sheryl Crow", "Gulliver's Travels", "Salford", "Milan", "The Streets", "E North America", "a rent-a-car", "a branch of mathematics", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "Campbell Soup Company", "Kirkcudbright", "the soldiers", "the banned substance cortisone.", "is one of the few -- possibly the only -- NATO member that has deep religious, cultural and historic knowledge of both Afghanistan and Pakistan.", "Juno", "a humanist Sans-serif", "a network of blood"], "metric_results": {"EM": 0.5, "QA-F1": 0.5753348214285714}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.33333333333333337, 0.5, 0.17142857142857143, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-778", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.5, "CSR": 0.5620265151515151, "EFR": 1.0, "Overall": 0.7810132575757576}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "Knutsford", "insulin", "a Caesar salad", "Hudson Bay", "florida", "allergens like molds, pollen and animals.", "Sarah Churchill", "Getafix", "Brighton", "Belfast", "wind", "fire", "Robin Hood's A Holy Grail", "West Point", "Andy Warhol", "Spain", "John Cable", "rykjavik", "the solar system.", "tomato", "Moldova", "Mitsubishi A6M Zero Fighter", "Dartford Warblers", "Franz Liszt", "Estimate", "baroudeur", "cadmus", "Pet Sounds", "Madness", "Buxton", "Discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "the Philippines", "beaver", "mel Blanc", "a dog", "riggs", "Ellen Morgan", "rochdale", "5000 meters", "racing", "casein", "Newfoundland and Labrador", "crow", "Yellowstone", "St. Thomas", "Cebu", "Hugh Laurie", "Buddhism", "Guy Berryman", "Ohio", "Port Melbourne", "\u00c6thelred I", "Scarface", "forgery and flying without a valid license,", "It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory over FK Ventspils.", "Liza Murphy,", "Spock", "Kazakhstan", "Andorra, Belgium, Germany, Italy, Luxembourg"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5713541666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, true, true, true, false, false, false, false, true, true, false, false, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-2126", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-1395", "mrqa_triviaqa-validation-6154", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-1620", "mrqa_triviaqa-validation-4987", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-11382"], "SR": 0.53125, "CSR": 0.5611213235294117, "EFR": 0.9666666666666667, "Overall": 0.7638939950980392}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business districts", "prairies", "Bologna, Italy", "George Santayana", "marsupials", "Alice Cooper", "heart disease", "trumpet", "mrs woolin", "a person", "shildon", "appalachian mountain range", "mrs Herald of Free Enterprise", "ballet", "quake", "black Eyed Peas", "lizard", "Blackburn Lancashire", "Frankie Laine", "The Mystery of Edwin Drood", "pommel horse", "bird", "Dick Van Dyke", "Egremont", "numb3rs", "Francisco de Goya", "phrixus", "Basil Feldman, Baron Feldman.", "Canada", "ink", "Pears soap", "Some Like It Hot", "mull", "Ireland", "Mike Meyers", "a sea horse", "pellet of plutonium", "magma", "Passepartout", "Thank you", "Iceland", "Denmark", "shrek", "26 miles", "Cleveland Brown", "Heston Blumenthal", "One Direction", "tall John silver", "Uranus", "george mccain", "Charles Lindbergh", "November 1999", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "stoneware", "Pittsburgh", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "tchaikovsky", "Howard Carter"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6659722222222222}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, false, false, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-1369", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-5109", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-5976", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-78"], "SR": 0.59375, "CSR": 0.5620535714285715, "EFR": 0.9615384615384616, "Overall": 0.7617960164835165}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "Leonardo da Vinci", "Matlock", "American Civil War", "Ethiopia", "beetles", "Arafura Sea", "daedalus", "Tigris", "Bavarian", "furrow", "Spain", "Carousel", "bullfight", "Mike Brady,", "countertenor", "alpo", "flore", "Guys and Dolls", "Julian Fellowes", "Denmark", "Another Day in paradise", "The Last King of Scotland", "ghanians", "pembrokeshire", "G. Ramon", "jane fonda", "rachmaninoff", "Finland", "stars", "Mille Miglia", "caves", "Billaley & His comets", "50p", "Muriel Spark", "happy birthday to You", "seven", "opossums", "Pickwick", "presliced bread", "Saga Noren", "raven", "Jordan", "bPA", "elondon", "Etruscan", "Ken Burns", "jane", "team GB", "Pyotr Ilich Tchaikovsky", "Mujib", "libras", "Donna", "season four", "sinoatrial node", "Yubin, Yeeun", "tomato", "2002", "problems with the way Britain implements European Union employment directives.", "L'Aquila earthquake", "March 24,", "peter", "equinox", "Pocahontas"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5776041666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.53125, "CSR": 0.5611979166666667, "EFR": 1.0, "Overall": 0.7805989583333334}, {"timecode": 36, "before_eval_results": {"predictions": ["Americans", "kim", "city of acacias", "branson", "Gordon Ramsay", "maurice law", "Robert Kennedy", "sulfur dioxide and nitrogen oxides", "Margot", "maurice airport", "Portuguese", "travelocity", "Avengers", "roosevelt", "Batman", "comets", "a ghost", "canola", "tina Turner", "Sweeney Todd", "maurice", "Bolivia", "John Donne", "Uranus", "Rio Grande river", "Percheron", "louis dregs", "national", "joan foyle", "king James I", "One Foot in the Grave", "Bronx Mowgli", "maurice deller", "George Santayana", "stalls", "baltale", "Krankies", "comets de torquemada", "louis farenboim", "Canada", "rum", "houseboat", "ghee", "George III", "comets", "hyperbole", "a cigarette", "June", "David Graham", "Ceylon", "screwdrivers", "the Kansas City Chiefs", "G minor", "A Christmas Story", "2004", "Nightmares", "Amberley", "lack of a cause of death and the absence of any soft tissue on the toddler's skeletal remains", "Canadian Prime Minister Stephen Harper", "louisabeth", "cixi", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5203125}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-6678", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_naturalquestions-validation-4108", "mrqa_hotpotqa-validation-2330", "mrqa_hotpotqa-validation-5545", "mrqa_hotpotqa-validation-4454", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-12", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120"], "SR": 0.46875, "CSR": 0.5586993243243243, "EFR": 0.9411764705882353, "Overall": 0.7499378974562798}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "generally carved in decorative patterns", "Charlotte", "Sakshi Malik", "Columbia River Gorge", "secretion of catecholamines, especially norepinephrine and epinephrine", "49 cents", "1876", "geologist Charles Lyell", "Dakar", "joy of living", "420", "George Strait", "to describe the six nations that have had sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "London, England", "Los Angeles", "September 28, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "1770 BC", "Niveditha, Diwakar, Shruti", "two parties", "Jane Lynch", "cell nucleus", "Anakin and Obi - Wan", "Travis Tritt and Marty Stuart", "1976", "Barry and Robin Gibb", "Matt Czuchry", "Pradyumna", "1853", "A line joining Isle Vierge", "Psychomachia", "the New Jersey Devils", "two", "7.6 mm", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Gloria", "Hudson Bay", "Maginot Line", "pussia", "dumbo", "purple rain", "Charles Guiteau", "Gettysburg Address", "iTunes, iTunes Radio, and iTunes Music", "$273 million", "India", "Jeddah, Saudi Arabia", "Desperate Housewives", "captain chaos", "chihuahua", "Tuesday"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6276416167023289}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, false, false, false, false, true, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.5714285714285714, 0.0, 1.0, 1.0, 0.6363636363636364, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.14035087719298245, 0.25, 0.5454545454545454, 1.0, 0.0, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-9191", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2334", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-5119", "mrqa_searchqa-validation-3257", "mrqa_searchqa-validation-2335"], "SR": 0.53125, "CSR": 0.5579769736842105, "EFR": 0.9666666666666667, "Overall": 0.7623218201754386}, {"timecode": 38, "before_eval_results": {"predictions": ["Isaac Newton", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in positions Arg15 - Ile16", "Charles Crozat Converse", "Lady Gaga", "the Chicago metropolitan area", "The president", "Domhnall Gleeson", "eusebeia", "horticulture", "Notts County", "f\u0254n", "Stephen A. Douglas", "1984", "`` man ''", "Pakistan", "21 February", "El Filibusterismo", "Bryan Cranston", "thylakoid membranes", "depression", "Alan Eustace", "Franklin", "January 1923", "18 Divisional Round", "602", "the average energy of 251 keV", "between $10,000 and $30,000", "September 1980", "1931", "the University of Oxford", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "The statesmen who led the secession movement", "Randy", "the Pearl Harbor attack", "Joseph Stalin", "into the intermembrane space", "a divergent tectonic plate boundary", "Idaho", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "Baroness Thatcher", "Roddy Doyle", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below", "Henry Ford", "David McCullough", "Rendezvous with Rama", "CERN", "saudade"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5836983543417368}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 0.09523809523809525, 0.0, 1.0, 0.5, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.32, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2512", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4929", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-448", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.53125, "CSR": 0.5572916666666667, "EFR": 0.9666666666666667, "Overall": 0.7619791666666667}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "Diary of a Wimpy Kid : The Long Haul", "Jenny Slate", "Active absorption", "Philippe Petit", "September 1980", "January 2004", "southwest and along the Yangtze", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "rock music subgenres", "March 12, 2013", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "XXXX", "Gestalt", "83 volumes", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Rachael Harris", "Richard Crispin Armitage", "Brooks & Dunn", "Dirk Benedict", "Bonnie Aarons", "either late 2018 or early 2019", "diffuse nebulae", "effectively overturned the Plessy v. Ferguson decision of 1896, which allowed state - sponsored segregation, insofar as it applied to public education", "McKim Marriott", "John F. Kelly,", "Charles Sherrington", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "related to the Common Germanic word guma ( Old English guma `` man '', Middle English gome )", "1960s", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Ariel Winter", "Mark Jackson", "Michael Buffer", "there is one body and one Spirit just as you were called to the one hope that belongs to your call one Lord, one faith, one baptism, one God and Father of all, who is over all and through all", "on location", "the federal government", "New England", "Cody Fern", "the nature of Abraham Lincoln's war goals", "prophets and beloved religious leaders", "in an area with fluoridated water", "Juan Manuel de Ayala", "Joseph Smith, Jr.", "funny Folks", "1909", "John Duigan", "179", "Princess Diana", "Mikkel Kessler", "curfew", "me and Bobby McGee", "shark", "Fast Food Nation: The Dark Side of the All-American Meal", "ABBA"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6118663964711758}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, true, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3076923076923077, 0.17142857142857143, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 0.6666666666666666, 0.47058823529411764, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 0.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5454545454545454, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-302", "mrqa_searchqa-validation-10341", "mrqa_searchqa-validation-4731"], "SR": 0.46875, "CSR": 0.555078125, "EFR": 0.9705882352941176, "Overall": 0.7628331801470588}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants", "Joan Rivers", "\"You're The One That I Want\"", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "Zimbabwe President Robert Mugabe", "2004", "coalition troops", "Switzerland", "Monday", "second time since the 1990s", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany", "he wants to spend $10 billion on childhood education, $150 billion over 10 years on developing alternative energy", "T.I.", "Oaxaca, Mexico", "Robert Barnett,", "a class A traffic violation that can command a fine of $627, Hastings said.", "41", "Nick Adenhart", "a strict interpretation of the law,", "Derek Mears", "Sylt", "about 30 miles southwest of Nashville", "Tuesday afternoon", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "Section 60", "Ali Bongo", "The Transportation Security Administration", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Two pages -- usually high school juniors who serve Congress as messengers", "A Brazilian supreme court judge", "Derek Mears", "Operation Pipeline Express.", "help rebuild the nation's highways, bridges and other public-use facilities.", "a residential area in East Java", "St. Louis, Missouri.", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2007", "P.V. Sindhu", "on location in Mexico, where both the village and the U.S. border town were built for the film", "snickers bar", "narwhal", "ivy", "Anaheim, California", "his uncle Juan Nepomuceno Guerra", "Bergen", "embalming", "torino", "a graphical user", "UK Kennel Clubs"], "metric_results": {"EM": 0.4375, "QA-F1": 0.6420818952678368}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.25, 0.4444444444444444, 0.05405405405405406, 0.0, 0.25, 1.0, 0.16666666666666669, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.5714285714285715, 1.0, 1.0, 0.9523809523809523, 0.3076923076923077, 0.4, 1.0, 0.3333333333333333, 0.9411764705882353, 0.5714285714285715, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.08695652173913045, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.33333333333333337, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3472", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-239", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.4375, "CSR": 0.5522103658536586, "EFR": 1.0, "Overall": 0.7761051829268293}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1998", "displacement", "based on sovereign states", "Megan Park", "the formal currency of the European Union", "Kate Walsh", "September 14, 2008", "American country music artist Trace Adkins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "international aid as one of the largest financial inflows to developing countries", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "1902", "the Dutch figure of Sinterklaas", "Yuzuru Hanyu", "to provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo as Anatole", "collect menstrual flow", "pigs", "General George Washington", "Spanish", "Coalhouse Walker Jr.", "an integral membrane protein that builds up a proton gradient across a biological membrane", "the atrioventricular node", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six 50 minute ( one - hour with advertisements )", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Intertropical Convergence Zone ( ITCZ )", "Missouri River", "the right to vote", "frontal lobe", "10 June 1940", "Tandi", "alberich", "ear", "brazil", "The Dressmaker", "$10.5 million (USD 8 million)", "Tim Whelan", "on the project, which is designed to promote private sector investment in a variety of gas-related industries,", "Denver, Colorado.", "the Sadr City and Adhamiya districts of Baghdad City,\"", "President Logan", "King Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6733059730302378}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 0.0, 1.0, 0.07692307692307693, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.23529411764705882, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_hotpotqa-validation-157", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518"], "SR": 0.53125, "CSR": 0.5517113095238095, "EFR": 0.9, "Overall": 0.7258556547619048}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization of water", "Middlesex County, Province of Massachusetts Bay", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "its population", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "victory", "Paul von Hindenburg", "Ceramic", "the Soviet Union", "Covington, Kentucky", "New Mexico", "reduces the back pressure", "December 15, 2017", "Paradise, Nevada", "L.K. Advani", "lowered the river's base level ( its lowest point )", "Glenn Close", "the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "The Puerto Rico Electric Power Authority ( PREPA )", "Tsetse fold their wings completely when they are resting so that one wing rests directly on top of the other over their abdomens", "Norman Greenbaum", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "118", "compasses", "Charlotte Thornton", "the Northeast Monsoon", "March 16, 2018", "President Lyndon Johnson", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "asexually", "1926", "Durban, South Africa", "starting in 1560s", "Frankie Muniz", "Lou Rawls", "between 1765 and 1783", "Alfheim", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "won two awards.", "prostate cancer,", "wyvern", "Lord Fauntleroy", "a key", "yellow"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6201848932989922}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.4799999999999999, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 0.9, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.14814814814814814, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.9767441860465117, 1.0, 0.7878787878787877, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.46875, "CSR": 0.549781976744186, "EFR": 0.8823529411764706, "Overall": 0.7160674589603283}, {"timecode": 43, "before_eval_results": {"predictions": ["1985", "February 27, 2007", "pick yourself up and dust yourself off and keep going ', female - empowerment song", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan )", "2013", "the arms of the king of Ireland", "Miami Heat", "1982", "After World War I", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Brutus", "Pierre Carrier - Belleuse", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home three days earlier,", "Edward Kenway ( Matt Ryan ), a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus", "rootlets", "Alex Ryan", "a habitat", "2018", "Advanced Systems Format ( ASF )", "100", "Toledo", "embryo", "the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "Dominic West, Walton Goggins, Daniel Wu, and Kristin Scott Thomas", "annually in late January or early February", "Kalinga Ashoka ( son of Bindusara )", "the name of a work gang", "Robert Andrews Millikan,", "Puerto Rico Electric Power Authority", "Bumblebee", "into the Christian biblical canon", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "armored fighting vehicle", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011,", "2008", "Florida", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "the southwestern part of the island", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "winter", "Pangaea", "Newcastle Brown Ale", "Western Australia", "V\u00e1clav Havel,", "Mary Bon auto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"It was perfect work, ready to go for the stimulus package,\"", "\"peregruzka\"", "Michigan", "North Atlantic Treaty Organization", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6249336680608282}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.8387096774193548, 1.0, 0.4, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 0.888888888888889, 1.0, 0.9387755102040816, 1.0, 0.4444444444444444, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.9189189189189189, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 0.09523809523809525, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-151", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-946", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977", "mrqa_searchqa-validation-13337"], "SR": 0.46875, "CSR": 0.5479403409090908, "EFR": 0.9705882352941176, "Overall": 0.7592642881016043}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "aluminum foil", "Laurel, Mississippi", "about the outdoors, especially mountain-climbing", "Sunflower County", "insurance", "DuSable", "1992", "Goddess of Pop", "Alabama", "Jim Harrison", "Montreal", "Tomorrowland", "fennec fox", "the United States Army", "stop motion animation", "Jean Acker", "4,530", "Leucippus", "Caesars Entertainment Corporation", "Terrence \"Uncle Terry\" Richardson", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "Northrop F-15 Reporter", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Grammy", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "OutKast", "Richard Street", "Zaire", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer", "South America", "in 2006", "perjury", "Operation Overlord", "Mary Elizabeth Hartman", "over 9,000 employees", "Rosalind Bailey", "potential of hydrogen", "Alamodome in San Antonio, Texas", "Carrie", "arrows", "Kent", "almost 9 million", "Kenya", "2008", "terrorism", "Moses", "Chapter 78", "Jeff Barry and Andy Kim"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6658424908424908}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, false, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-4762", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_triviaqa-validation-6953", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.5625, "CSR": 0.5482638888888889, "EFR": 0.9285714285714286, "Overall": 0.7384176587301587}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "1903", "navigation by river", "Naomi Wallace", "Jenson button", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih", "King James II of England", "God Save the Queen", "526", "Scotland", "\"rock and roll\"", "GmbH", "Mick Jackson", "Lalit", "performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Sullenberger III", "Manhattan Project", "Asia-Pacific War", "Romantic", "Hugh Dowding", "AMC Theatres", "New York Islanders", "fennec fox", "1978", "six different constructors taking the first six positions", "Canadian", "Pacific Place", "The Australian women's national soccer team", "is a song by American singer-songwriter Taylor Swift, from her fifth studio album \"1989\"", "Rudebox", "about 5320 km", "Andrea Maffei", "Chief Minister of Tamil Nadu", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Faysal Qureshi", "the British Army", "Elections", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Judy Garland", "Switzerland", "Model A", "NATO's International Security Assistance Force", "2,000", "Cyprus", "is an American singer-songwriter, multi-instrumentalist, and actor.", "jeddah", "Geraldine A. Ferraro", "two"], "metric_results": {"EM": 0.59375, "QA-F1": 0.65859375}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.13333333333333336, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-4934", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_triviaqa-validation-3592", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-8327"], "SR": 0.59375, "CSR": 0.5492527173913043, "EFR": 1.0, "Overall": 0.7746263586956521}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican", "1996", "5", "Greenland shark", "The Word", "President Abraham Lincoln's", "St Jude Thaddeus", "Anthoonij van Diemenslandt", "death penalty", "xerophyte", "Jackie Robinson", "Manhattan", "Dian Fossey", "MI5", "Harrow", "creme anglaise", "(ah-la-lee-on-glaz)", "pork", "curling", "Victoria Coren Mitchell", "Gettysburg", "Chile", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara", "Uranus", "Venus", "Barack Obama", "Canada's Liberal Party", "mortadella", "Castro and the Cuban Revolution", "David Bowie", "Stephen King", "Hinduism", "caryatid", "feet", "Florida", "Mary Poppins", "Glyn Jones", "Port Moresby", "Connecticut", "Quentin Blake", "whooping cough", "The Sun", "(1939\u20131945)", "animal (such as pork)", "beginning in 2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1987", "umpire Louise Engzell.", "Jeddah, Saudi Arabia", "death", "Beatrix Potter", "Dan Eggen and Elizabeth Williamson", "How to Keep Young Mentally", "(GNT)"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5744791666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-1718", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-1584", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_hotpotqa-validation-252", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.53125, "CSR": 0.5488696808510638, "EFR": 1.0, "Overall": 0.7744348404255319}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "allergic reaction", "bobby Charlton", "inverness", "Runic", "Spain", "cricketer", "geheimrat Dr. Max", "rotherham United", "heat exchange", "Misery", "Styal", "stately", "Blind Beggar", "Brainwash", "asafa Powell", "parlophone", "Wild Atlantic Way", "John  Denver", "unseen Academicals", "noddy", "Lackawanna 6", "Brazil", "scrabble", "muezzin", "a window", "a ship", "realist", "Apollo 11", "Cellophane", "Nikola Tesla", "jockey", "Evita", "albino sperm whale", "a fighter named Ray Robinson", "east fife", "st Pancras International Station", "social environment", "presliced bread", "Dilbert", "casterbridge", "nunc dimittis", "French", "medea", "Burgundy", "cribbage", "The Beatles", "Johannesburg", "French", "The Muffin Man", "Seoul", "The Province", "prejudice in favour of or against one thing, person, or group compared with another", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Galveston, Texas,", "airlines around the world shut down every year.", "Robert Frost", "King Henry VIII", "pillsbury", "Mitsubishi Eclipse"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6177827380952381}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, true, true, false, true, false, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-1189", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-2610", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.53125, "CSR": 0.5485026041666667, "EFR": 1.0, "Overall": 0.7742513020833334}, {"timecode": 48, "before_eval_results": {"predictions": ["Route 66", "sesame Street", "marcella Hazan,", "cabbage", "south", "Quincy Magoo", "fleece", "Ash tree", "opossum", "New Zealand", "jug band", "60", "goldfinger", "1983", "pike", "mongols", "1875", "tax collector", "penny", "maria maria", "Wars of the Roses", "Bagram Collection Point", "maggie Gilkeson", "Chrysler", "fur hat", "dandy", "law", "united nation of people from many different backgrounds and beliefs", "Brazil", "tientsin", "shooting", "mercury", "Charlie Chan", "Vienna", "white", "jaws", "Paul Rudd", "rabbit", "Scotland", "penelope Keith", "Orson Welles", "Hindu Wisdom", "menorah", "Impressionist", "Texas", "Super Bowl Sunday", "quant pole", "Little Tommy Stout", "the British pop band Go West", "Rhododendron", "England", "Chuck Noland", "Colony of Virginia", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park", "2010", "Greece,", "10 below", "Nearly all", "silver", "the American Kennel Club", "Omaha", "jedoublen/jeopardy"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5394345238095237}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, false, true, false, false, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-7507", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-2446", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-263", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-6306", "mrqa_triviaqa-validation-2158", "mrqa_naturalquestions-validation-4803", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-16460", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.4375, "CSR": 0.5462372448979591, "EFR": 0.9722222222222222, "Overall": 0.7592297335600906}, {"timecode": 49, "before_eval_results": {"predictions": ["donald farfrae", "dharm", "alcohol", "france", "dutch Francis", "daniel Boone", "stables of the Star Inn", "Theodore Roosevelt", "satyrs", "crabs", "la Boh\u00e8me", "MITS", "wishbone", "garrick club", "Lackawanna 6", "master humphrey", "britten", "American Civil War", "dark", "jennifer leachman", "Jimmy Robertson", "tuscany", "tsar Ivan IV", "veruca salt", "severn", "south", "south", "bunch grasses", "guinea", "Clement Attlee", "duke of Suffolk", "chemnitz", "dutch", "trout", "ap\u00e9ro", "kennon", "belmopan", "dutchwork", "hair loss", "omnium", "Charlie Drake", "robin hood", "Chris Martin", "wilma Flintstone", "(Lee Ingleby)", "rugby", "honda", "steely Dan", "11", "tobacco", "heifer", "free floating", "Tom Selleck", "New Orleans", "superhuman abilities", "Texas Tech University Health Sciences Center", "Loughborough Technical Institute", "sharon Bialek", "the United States", "helicopters and unmanned aerial vehicles", "George Babbitt", "dutch", "(1970)", "four"], "metric_results": {"EM": 0.34375, "QA-F1": 0.40654761904761905}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, false, false, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-2309", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-3092", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-6060", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-115", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-12598", "mrqa_searchqa-validation-3615"], "SR": 0.34375, "CSR": 0.5421875, "EFR": 1.0, "Overall": 0.77109375}, {"timecode": 50, "UKR": 0.775390625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.76171875, "KG": 0.4796875, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "University of Kansas", "\"Barracuda Frank\"", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland, California", "37", "Tufts University", "Owsley Stanley", "\"The Late Late Show\"", "Kongo", "Harold Lipshitz", "Spanish", "Ted", "1945", "69.7 million litres", "Neneh Cherry", "Sunyani", "antelopes", "Comodoro Arturo Merino Ben\u00edtez International Airport, Santiago, Chile", "Scotty Grainger Jr.", "9", "balta ballade", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1898", "Nicolas Winding Refn", "devotional", "Fortunino Francesco Verdi", "Laban Movement Analysis", "Cecily Legler Strong", "J. Robert Oppenheimer", "invoicing", "seasonal television specials, particularly its work in stop motion animation", "4 km", "1853", "Vogue", "Supremes", "census", "Vincent Landay", "Edward James Olmos", "playback singer", "1901", "Pope John X", "Best Art Direction", "VAQ-135", "Alex Skuby", "Nitty Gritty Dirt Band", "English", "'Q'", "FBI", "a jug", "EMI,", "UNICEF", "9 a.m.", "george golden", "Van Helsing", "kufic", "a long-range missile"], "metric_results": {"EM": 0.5, "QA-F1": 0.6404761904761905}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, false, false, false, true, false, true, false, false, false, false, true, false, true, true, false, false, false, false, true, true, false, true, true, true, true, false, true, false, false], "QA-F1": [0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.8, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5030", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1652", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-4616", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-5779", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-7487", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.5, "CSR": 0.5413602941176471, "EFR": 1.0, "Overall": 0.7116314338235294}, {"timecode": 51, "before_eval_results": {"predictions": ["Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143,007", "a historic house museum", "Realty Bites", "24", "Razor Ramon", "psychoanalysis", "Forbes", "St. George, Maine", "Kiss", "Lithuania", "International Boxing Federation", "15", "Conservatorio Verdi", "Lester Ben \"Benny\" Binion", "Smoothie King Center", "International Conference on LGBT Human Rights", "microbrewery", "Umberto II", "Presbyterian Church", "neuro-orthopaedic", "Hookend Recording Studios in Checkendon, Oxfordshire", "North Sea", "2006", "67,575", "Oxford", "OSRIC", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "English", "Eric Whitacre", "Mission Revival Style", "180", "George Adamski", "Vision of the Future", "Switzerland", "McKenna's Fort", "Scunthorpe", "Canadian comedian", "Captain Cook's Landing Place", "Summer Olympic Games", "1936", "1970", "The Kennedy Center", "Budget Rent a Car", "Japan", "lion", "1959", "Donna Mills", "Tell me why I can't be there where you are", "735 feet", "Maine", "Blanche", "maxillae", "Microsoft", "4.6 million", "the International Press Institute", "tea rose", "John J. Pershing", "black Russian", "Rear Window"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6160511363636363}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true, true, true, true, false, false, true, true, true, true, false, true, false, false, true, false, false, true, true, false, true, false, true, true], "QA-F1": [0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 0.8, 0.0, 0.0, 0.5, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1568", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-84", "mrqa_triviaqa-validation-4184", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653"], "SR": 0.515625, "CSR": 0.5408653846153846, "EFR": 1.0, "Overall": 0.7115324519230769}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "non-voters", "3", "up to 100,000 write / erase cycles", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel", "Orlando", "Advanced Systems Format ( ASF )", "the Ramones", "Albert Finney", "American comedy web television series", "Gospel of Matthew", "30 years after Return of the Wars", "a leonine contract, a take - it - or - leave - it contract, or a boilerplate contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1960", "British", "1972", "U.S. states of Oregon and Washington", "coercivity", "1998", "malicious software", "Cyndi Grecco", "differs in ingredients", "1900", "dorsally on the forearm", "species of animal", "Terry Kath", "clay", "one person", "The Parlement de Bretagne", "password recovery tool for Microsoft Windows", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "1986", "typically closes for two and half weeks in late summer", "currency option", "1623", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas, developed by Rockstar North", "the medulla oblongata", "1998", "Gibraltar", "Howard Caine", "May 3, 2005", "Andy Cole", "Harry patch", "comedy playhouse", "Paul Maskey", "Child actor", "Saoirse Ronan", "Happy Madison Productions", "The Kirchners", "north London rivals Tottenham", "Gordon Brown", "crawford", "yellow fever", "winter", "Netflix"], "metric_results": {"EM": 0.5, "QA-F1": 0.5773984593837536}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333334, 0.3137254901960785, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.058823529411764705, 1.0, 0.0, 0.13333333333333333, 0.2857142857142857, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2179", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-10706", "mrqa_naturalquestions-validation-1203", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-9142", "mrqa_naturalquestions-validation-9099", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-2688", "mrqa_newsqa-validation-318", "mrqa_searchqa-validation-1310", "mrqa_searchqa-validation-4527"], "SR": 0.5, "CSR": 0.5400943396226415, "EFR": 0.9375, "Overall": 0.6988782429245283}, {"timecode": 53, "before_eval_results": {"predictions": ["Al Lenhardt", "Big Bang Theory of Creation", "James Bennett II", "Green Acres", "Cooking", "Peter Paul Candies", "the Doppler shift", "lobster", "HarperCollins Children's Books", "American Airlines", "her coronation", "Vermont", "Windsor County Vermont", "vintage rock", "salmon", "Adam", "Osaka", "the tapir", "France", "Spam", "Stephen Dedalus", "Braxton-Hicks", "Camembert", "Friday", "Dragon", "centaur", "Mentor", "General Emile Lahoud", "Manifest Destiny", "William Jennings Bryan", "disabilities", "Singapore", "Hidden City Philadelphia", "Cyprus", "Glucosamine", "Madagascar", "articles", "a celebration, stunt, spectacle", "afur hat", "The Undeclared War Against American Women", "Dr. Dre", "Al Lang Stadium", "Fidel Castro", "fudge", "kanga", "Service Employees International Union", "goldfish", "hormone", "a dive", "yellowtail", "Nitrides of boron & silicon are used to make crucibles", "between the Mediterranean Sea to the north and the Red Sea in the south", "Beijing", "Zeus", "Van Morrison", "antelopes", "manufacturer, distributor, and marketer of non-alcoholic beverage concentrates", "Rocky Mountain Institute", "21", "a cobblestone-size (10x10 cm ) concrete cube bearing a brass plate inscribed with the name and life dates of victims of Nazi extermination or persecution", "Three thousand", "insurgent small arms fire", "3,000 kilometers (1,900 miles)", "Lambic"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5692708333333334}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, false, true, true, false, true, false, true, true], "QA-F1": [0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.9, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7290", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-7425", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-14085", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-7952", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-13258", "mrqa_searchqa-validation-9470", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-6093", "mrqa_searchqa-validation-379", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-7747", "mrqa_hotpotqa-validation-3325", "mrqa_newsqa-validation-1792"], "SR": 0.53125, "CSR": 0.5399305555555556, "EFR": 0.9, "Overall": 0.6913454861111111}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "state legislators of Assam", "a travelling circus", "in the stems and roots of certain vascular plants", "Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas ''", "1987", "John F. Kennedy", "in elocution teaching", "Isle of FERNANDO 'S??, a fictional location based in Puerto de la Cruz, Tenerife", "seven", "1999", "Rashida Jones", "Hook", "Bush", "tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai, the most famous Pukhtun religious leader of the time was requested by Nawab Sir Sahibzada Abdul Qayyum", "45 %", "Motorola", "the Earth's axial tilt, which fluctuates within a margin of 2 \u00b0 over a 40,000 - year period, due to tidal forces resulting from the orbit of the Moon", "1998", "Guy Berryman", "Ming dynasty", "the red - bed country of its watershed", "Thomas Jefferson, John Adams and Thomas Paine", "The Intolerable Acts", "National Industrial Recovery Act ( NIRA ), 1933", "semi-autonomous organisational units within the National Health Service in England", "Jeff Gillen", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg of Mainz, Germany", "1885", "1964 Republican National Convention in San Francisco, California", "the Finch family's African - American housekeeper", "the muscles of the limbs, abdominal, and intercostal muscles", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms, while the Resident Commissioner serves for four years", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "Philippines", "driving Miss Daisy", "Goddess of Revenge", "Marine Corps Air Station Kaneohe Bay", "PlayStation 4", "2015 Orange Bowl", "Seminole", "Defense of Marriage Act", "BMW Oracle", "Eiffel tower", "barnacles", "Puppy", "Gary Chapman"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6244253822289876}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, true, false, false, true, true, false, false, false, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.2, 0.0, 1.0, 0.0, 0.4615384615384615, 0.5555555555555556, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5882352941176471, 1.0, 0.888888888888889, 0.1904761904761905, 1.0, 0.0, 0.12903225806451613, 0.0, 0.0, 1.0, 0.923076923076923, 0.06451612903225806, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.8571428571428571, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-7214", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-6901", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-4645", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.46875, "CSR": 0.5386363636363636, "EFR": 1.0, "Overall": 0.7110866477272727}, {"timecode": 55, "before_eval_results": {"predictions": ["King Edward III", "golf", "purple", "aeoline", "Ascot", "Litas", "Loretta Lynn", "Survivor Series", "steppenwolf", "chop suey", "Ross MacManus", "Coronation Street", "drama", "Yuvraj Singh", "Saddam Hussein", "New Zealand", "Tyrrhenian", "baltimore", "Mauritania", "Hans Lippershey", "Bolivia", "Bob Giraldi", "Mozambique Channel", "ash", "Edward VII", "Thomas Cranmer", "testicles", "Guatemala", "bacall", "Caroline Aherne", "James", "S\u00e8vres", "Mau Mau", "Kipps: The Story of a Simple Soul", "frankincense", "Serena Williams", "Lome", "Pegida", "Alberich", "Utrecht", "1709", "Mitford sisters", "Kansas", "Miles Morales", "a pest of commercial grapevines", "Skylab", "ostrich", "Hugh Quarshie", "a ship\u2019s thrust", "Batman", "Beijing", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jack", "Linux Format", "Stage Stores", "26", "ordered the immediate release", "Shanghai", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6202651515151515}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-1051", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-3596", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-597", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-4261"], "SR": 0.609375, "CSR": 0.5398995535714286, "EFR": 0.88, "Overall": 0.6873392857142857}, {"timecode": 56, "before_eval_results": {"predictions": ["argina", "Bolivia", "The Telegraph", "liver", "portugal", "Drunk", "Galway", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "george elis", "north-west corner of the central business district", "minced", "Benazir Bhutto", "cricketer", "Sam Mendes", "alex steed", "scorcese", "eighth", "business", "godsgifu", "scorcese", "Mexico", "river Towy", "two", "1984", "new York", "half a dozen", "Shintoism", "ireland", "george iv", "Mickey Mouse", "oxygen", "Prince Albert", "toro", "Are you going to come quietly, or do I have to use earplugs", "Dar es Salaam", "creep", "ANDREW", "loch of 310m", "pyrenees", "South Korea", "gelatine", "Papua New Guinea", "the Suez Canal", "Yorkshire", "aces de Gaulle", "sankt Moritz", "the French Revolution", "a square mile", "one of the Vikings nine realms", "a salt formed by the combination of acetic acid with an alkaline, earthy, or metallic base", "iron", "a President since creation of the office in 1789", "Christopher Whitelaw Pine", "Yorgos Lanthimos", "Tottenham ( ) or Spurs", "unseeded", "off east  Africa", "Shanghai", "cicada", "John Pershing", "governess", "a large portion of rural Maine, published six days per week in Bangor, Maine"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5049632352941176}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.8, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.11764705882352941]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-4296", "mrqa_triviaqa-validation-4984", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-1331", "mrqa_triviaqa-validation-5070", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-1010", "mrqa_triviaqa-validation-1012", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-501", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4370", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_searchqa-validation-10653", "mrqa_hotpotqa-validation-4052"], "SR": 0.421875, "CSR": 0.537828947368421, "EFR": 1.0, "Overall": 0.7109251644736843}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "godson holborn", "coagulation", "river lee", "Rudolf nureyev", "Jessica", "placebo", "weather", "lake placid", "a sovereign state", "contractions", "William Boyd", "Saint Cecilia", "Caroline Garcia", "morecambe and Wise", "maggie Gilkeson", "butcher", "cowpox", "fox hunting", "Stockholm", "france", "Brothers in Arms", "smell disorders", "celestial surveyor probe", "Chemnitz", "herbygrass", "yellow", "marinus raven", "capital of Venezuela", "ennio morricone", "British", "Spain", "timesigns", "Turandot", "tokyo", "highest mountains", "eat porridge", "Howard Keel", "valhalla", "boutros Ghali", "Germany", "Sinclair Lewis", "southern", "garden of Gethsemane", "Decision Tree template", "Decimals", "Sunday Times", "France", "kentiania", "kirin", "selenium", "vehicle which drives on all four wheels, but may not be designed for off - road use", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "Michael Jackson's comeback concerts in London have been postponed until next year because producers can't be ready in time for the July debut,", "Shiza Shahid,", "Perseid meteor shower", "accordions", "bones", "Mark wahlberg"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6088541666666667}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-883", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-6704", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-4990", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-4857", "mrqa_triviaqa-validation-1334", "mrqa_naturalquestions-validation-10066", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-6518"], "SR": 0.5625, "CSR": 0.5382543103448276, "EFR": 1.0, "Overall": 0.7110102370689655}, {"timecode": 58, "before_eval_results": {"predictions": ["rubbing", "Jonah", "Hughe", "Constantinople", "Jacqueline Susann", "Bangladesh", "Hudson River", "spinal column", "New Year's Day", "the Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "ruby", "get absorbed into your hand, and then rub in", "Siberia", "William Pitt the Younger", "five", "CAKES", "manchester", "godfather", "skin cancer", "Nostradamus", "jihad", "harpoons", "every Breath you take", "finance", "Conrad Hilton Jr.", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "the Battle of Trafalgar", "bald eagle", "menudo", "Panax", "hurricanes", "home Improvement", "Kashmir", "airport", "nu", "Bourbon French Parfums", "statistic", "little mermaid", "brother", "lethal", "Pell grants", "beryl", "colour glass", "19 July 1990", "Incudomalleolar joint", "Louis XV", "Zimbabwe", "Mansion House", "senior", "London", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Auckland", "fear of money"], "metric_results": {"EM": 0.546875, "QA-F1": 0.59375}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-3868", "mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-12684", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-3807", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225", "mrqa_triviaqa-validation-2596"], "SR": 0.546875, "CSR": 0.5384004237288136, "EFR": 0.9310344827586207, "Overall": 0.6972463562974868}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "Shylock", "distillation", "Leonard Bernstein", "calcium", "vatican", "Danube", "the albatross", "Seinfeld", "The Smashing Pumpkins", "a sentence", "Ohio State", "Sherman", "Pakistan", "Theology of God", "Leinster", "Sally Field", "Barbara Cartland", "Rum", "a Pringles can", "Paul Hamm", "a type of classical male singing voice", "East Siberia", "a skipping rhyme", "Tom Hanks", "Clue", "two inseparable black magpies", "#5367", "alternating current", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "Marshall", "General Motors", "the trade winds", "ambassador to South Vietnam", "silk", "W", "a Unicorn", "Scrabble", "the ulnar nerve", "Saturday Night Fever", "Petruchio", "Philippines", "mushrooms", "Che Guevara", "Yale University", "Oscar Wilde", "Aphrodite", "Dian Fossey", "a map", "an iron -- nickel alloy", "ABC", "a legal case in certain legal systems", "pear", "Melbourne", "jape", "Ringo Starr", "D.O.", "Hanna, Alberta", "an acid attack by a spurned suitor.", "National Intelligence Service, and Defense Minister Kim Kwan Jim", "\"We take this issue seriously,\"", "Sinon"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6297619047619047}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5714285714285715, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-12007", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-116", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-10144", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-16156", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-10544", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-15230", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-1635", "mrqa_hotpotqa-validation-249", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_triviaqa-validation-6487"], "SR": 0.546875, "CSR": 0.5385416666666667, "EFR": 1.0, "Overall": 0.7110677083333333}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "close to 50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Carlos Almeida da Cunha", "four", "Sippin' on Some Syrup", "Jared Snyder", "M\u00f8ller Centre for Continuing Education", "Terrina Chrishell Stause", "Karl-Anthony Towns", "five", "Charlie Wilson", "Sim Theme Park", "a facelifted 850 saloon", "its riverside location", "1858", "Julie Taymor", "actress", "James Edward Kelly", "Spanish", "Indiana University", "lower Manhattan", "Homeland", "2016", "Virgin Atlantic", "green and yellow", "Champion Jockey", "March 2012", "Tom Courtenay", "Erinsborough", "2015", "Vladimir Valentinovich Menshov", "The Birds", "Londonderry", "York County", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "1949", "Savannah River Site", "\u00c6thelred I", "God and the just cause", "Swiss", "emperor Claudius", "World War I", "October 4, 1970", "Marktown", "five", "Rodney Crowell", "Mendel", "Manhattan", "scales", "Frankfurt", "Apollo", "Anil Kapoor", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "Arthur E. Morgan III,", "quarantina", "the Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6923549107142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.125, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3314", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-6034", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.609375, "CSR": 0.539702868852459, "EFR": 0.92, "Overall": 0.6952999487704917}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaelic", "Chicago Bears", "girls", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Adult Swim", "1983", "Rio Ferdinand", "247,597", "2,664", "841", "first and second", "Australian Broadcasting Corporation (ABC)", "MG Car Company Limited", "Walt Disney and Ub Iwerks", "1979", "15", "January 23, 1898", "Tom Werner", "Bolton", "Argentinian", "Them", "575 acres (2.08 km\u00b2)", "John Snow", "New York and New Jersey", "2013\u201314", "Melbourne Storm", "University of Nevada", "21", "Armenia", "Friday", "Oklahoma Sooners", "2002\u201303", "7pm", "1866", "Gaahl", "Serie B", "1887", "Isabella", "RAF Tangmere, West Sussex", "North Holland", "Burt Reynolds", "Golden Calf", "Forza Horizon 3", "The final of 2011 AFC Asian Cup", "Agatha Christie's Marple", "Mercer", "1951", "35,124", "154 days", "2018", "Jimmy Flynn", "the Soviet Union and its satellite states", "his finger", "Ronald Reagan", "One Thousand and One", "perceived stigma associated with seeking help", "from dealers to assembly workers and parts markers", "forcibly drugging", "James Watt", "T.S. Eliot", "ANastasia", "Games"], "metric_results": {"EM": 0.5, "QA-F1": 0.6319128787878787}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.33333333333333337, 0.4, 0.5, 0.6666666666666666, 1.0, 1.0, 0.5, 0.09523809523809525, 0.25, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-1187", "mrqa_hotpotqa-validation-3573", "mrqa_hotpotqa-validation-5870", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-4939", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-1453", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-826", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-5180", "mrqa_triviaqa-validation-7611", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129"], "SR": 0.5, "CSR": 0.5390625, "EFR": 0.9375, "Overall": 0.6986718749999999}, {"timecode": 62, "before_eval_results": {"predictions": ["the \"Acad\u00e9mie royale d'architecture\" (1671\u20131793)", "13 October 1958", "Walt Disney and Ub Iwerks", "pressure-sensitive film", "Babylon", "a card (or cards) during a card game", "a water sprite", "Sean Yseult", "law", "October 5, 1937", "Hillsborough County", "Charles Eug\u00e8ne Jules Marie Nungesser", "Burning Man", "Love Streams", "King George VI", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "Somerset County, Pennsylvania", "Simon Bolivar Buckner", "German", "Gareth Jones", "consulting services", "April", "1978", "actor, producer, and director", "Melanie Owen", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "American jewelry designer", "Guns N' Roses", "Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "the German princely Battenberg family", "dice", "Kal Ho Naa Ho", "Dungeness", "Pendlebury, Lancashire", "25 October 1921", "Canadian comedian", "Martin O'Neill", "Stratfor", "Reginald Engelbach", "American", "Black Friday", "Minneapolis", "Jean Erdman", "5.7 million", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard Seddon", "the heart", "New York City", "to launch a group that will serve as an alternative to the Organization of American States.", "has been a Parkinson's Disease sufferer", "Bob Bogle", "circumference", "The Hague", "a stationwagon", "2001"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6340603237342368}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, true, false, true, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.7272727272727272, 1.0, 1.0, 0.0, 0.8, 0.34782608695652173, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-4046", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-4838", "mrqa_hotpotqa-validation-5074", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-2535", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-197", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-2224", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-12404"], "SR": 0.515625, "CSR": 0.5386904761904762, "EFR": 0.9354838709677419, "Overall": 0.6981942444316436}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "two weevils", "The Pound of flesh", "from the data set", "the beluga", "Nicholas II", "tuna", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "salir", "Thor", "Orange", "astride", "Borneo", "Versailles", "a mushroom", "new york", "whipped cream", "Yellowfin", "Macbeth", "Jean-Michel Basquiat", "Led Zeppelin", "War & Peace", "The Morning", "The Talk of Tv", "the outskirts of a small Southern town", "Peter Falk", "John Tyler", "Milwaukee", "tranfgrel", "Wall Street", "sake", "Notre Dame", "Portland", "Charles-Franois de Broglie", "The Indianapolis 500", "Toy Story", "improv", "Charles Askegardshe", "Eustachys", "Nikolai Gogol", "Oscar Wilde", "Fletcher Christian", "weaving", "Karol Wojtyla", "Greenland", "John", "The Marx Brothers", "the watermelon", "Phillip Schofield and Christine Bleakley", "the duodenum", "Reverend J. Long", "violin", "sexual imagination", "Mount Godwin Austen", "Garrett Morris", "1966", "12 mi east-southeast of Bridgeport", "Susan Atkins", "almost 9 million", "three thousand", "Nouri al-Maliki"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6365699404761904}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, false, true, true, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_searchqa-validation-513", "mrqa_searchqa-validation-4522", "mrqa_searchqa-validation-6512", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-15074", "mrqa_searchqa-validation-4458", "mrqa_searchqa-validation-14769", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-16930", "mrqa_searchqa-validation-8527", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.5625, "CSR": 0.5390625, "EFR": 0.9285714285714286, "Overall": 0.6968861607142858}, {"timecode": 64, "before_eval_results": {"predictions": ["the most gigantic pumpkins in the world", "Seminole", "billions of dollars in Chinese products", "\"green-card warriors\"", "228", "love and loss", "2005", "contaminated groundwater, hundreds of buildings used for plutonium enrichment that need to be torn down, and underground tanks that are full of radioactive sludge.", "consumer confidence", "Fernando Verdasco", "in the southern port city of Karachi,", "Dan Parris, 25, and Rob Lehr, 26,", "Jason Chaffetz", "computer", "Russia", "Barack Obama", "Sunday", "the Islamic militant group Abu Sayyaf,", "France", "41,280 pounds", "be silent", "iTunes", "Kenyan and Somali governments", "\"gotten the balance right\"", "a dozen", "10", "Quiet Nights", "his death cast a shadow over festivities", "Iran", "123 pounds of cocaine and 4.5 pounds of heroin", "an engineering and construction company", "took her own life.", "fractured pelvis and sacrum", "five", "to step up", "first-degree murder", "Nizhny Novgorod", "Mashhad", "summer", "one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda,", "Garth Brooks", "Oxbow,", "Ameneh Bahrami", "different women coping with breast cancer", "Michael Schumacher", "Luiz Valente", "the release of the four men", "2006", "12.9 - kilometre ( 8 mi )", "Mike Brignardello", "Theodosius I", "David Heath", "Estonia", "learning", "Princess Anne", "Sergeant", "Champion Jockey", "Frederic Remington", "Ptolemy", "the German use of submarine warfare", "the word mark"], "metric_results": {"EM": 0.46875, "QA-F1": 0.629074050949051}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, true, false, false, false, false, false, false, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.9090909090909091, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-1314", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1367", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1825", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-3682", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-10081", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_hotpotqa-validation-4585", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-11117", "mrqa_searchqa-validation-709"], "SR": 0.46875, "CSR": 0.5379807692307692, "EFR": 0.9411764705882353, "Overall": 0.6991908229638009}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "he was always courteous even as he tried to meet his target of robbing banks in under two minutes.", "North Korea", "February 12", "Mandi Hamlin", "United Nations", "\"falling space debris,\"", "Arkansas", "voluntary genocide", "after a head injury,", "Chris Robinson", "Grease", "Cipro", "34", "E. coli bacteria", "More than 15,000", "\"A good vegan cupcake has the power to transform everything for the better,\"", "The Sopranos", "government", "during childbirth", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "Graeme Smith", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano,", "against using injectable vitamin supplements because the quantities are not regulated.", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "400 years ago", "Gulf of Aden,", "Obama", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee Anthony,", "the immorality of these deviant young men does not provide solutions that prevent gang rape from happening.", "in five days.", "managing his time.", "it does not grant full health-care coverage, which would require an act of Congress,", "\"We need a president who understands the world today, the future we seek and the change we need. We need Barack Obama as the next president of the United States.\"", "us to step up.\"", "he acted in self defense in punching businessman Marcus McGhee.", "education about rainforests.", "13 and 15", "Vicente Carrillo Leyva,", "Texas Department of Criminal Justice,", "Trevor Rees,", "eight women and 15 children.", "the leader of a drug cartel", "Ed McMahon,", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "Genocide Prevention Task Force.", "243 days", "Kirstjen Nielsen", "August 5, 1937", "20", "Wisconsin", "\"Mr Loophole\"", "Arlo Looking Cloud", "Queenston", "1694", "the Golden Fleece", "Gustav", "Amish", "6teen"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5999766132989818}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, false, false, false, true, false, true, true, true, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.2727272727272727, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.10526315789473685, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-431", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-3555", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-9728", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4692"], "SR": 0.53125, "CSR": 0.5378787878787878, "EFR": 1.0, "Overall": 0.7109351325757576}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "sonar", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Spain", "about a mile north of the village of Dunvegan", "the 114.5 metre sculpture", "\"lodges\"", "Stilwell", "Tallinn", "the solar system", "coelacanth", "Belgium", "Dennis Potter", "Calcium", "Eric Coates", "Geoffrey Cox", "Mel Brooks", "The California condor", "Ohio", "wind turbines", "Hattie Jacques", "The Bill", "6", "Hamlet", "Johannesburg", "Crackerjack pencil", "duke", "czech and Hammerstein", "Spain", "minder", "special sauce", "Les Dennis", "Kauffman", "Hard Times", "Tuscany", "18 meters", "Singapore", "Archie", "Pakistan International Airlines", "gold", "France", "Tomorrow Never Dies", "Jack Kennedy", "Hong Kong", "Chuck Yeager", "lisping Violet- Elizabeth Bott", "northern France", "horse", "Moby Dick", "east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "a sociological perspective", "21 July 2015", "Bern", "28 June 1945", "not", "25", "Afghanistan", "Yves Saint Laurent", "Rush", "Topix", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6328373015873017}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.6666666666666666, 0.0, 1.0, 0.1111111111111111, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-5468", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-7476", "mrqa_triviaqa-validation-7211", "mrqa_triviaqa-validation-6089", "mrqa_triviaqa-validation-6792", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-613", "mrqa_triviaqa-validation-7014", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-7017", "mrqa_searchqa-validation-11790", "mrqa_newsqa-validation-2682"], "SR": 0.546875, "CSR": 0.5380130597014925, "EFR": 1.0, "Overall": 0.7109619869402984}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "the federal government", "Robert Duncan McNeill", "August 9, 1945", "after obtaining the consent of the United Kingdom", "product's", "Olivia Olson", "Helsinki", "Pyeongchang County, South Korea", "602", "March 11, 2018", "5.7 million customer accounts", "Wembley Stadium", "the President", "David Joseph Madden", "The Fixx", "at night", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "Royal Air Force", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US Privacy Act", "around the time when ARPANET was interlinked with NSFNET", "in the 18th century", "Mariah Carey", "Spektor", "H CO", "seven", "September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "Chernobyl Nuclear Power Plant", "435", "sport utility vehicles", "Elk and Kanawha Rivers", "The Bellamy Brothers", "University of Oxford", "Massachusetts", "the plane crash", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand to New Guinea", "Frank Oz", "1954", "2010", "Missouri River", "alchemist", "lute", "france", "John Churchill", "Gregg Popovich", "Asiana Town building", "Jaime Andrade", "Eleven", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi", "emphasis or heightened effect"], "metric_results": {"EM": 0.5, "QA-F1": 0.6278877340409847}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true, false, true, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 0.8421052631578948, 0.8, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 0.5, 0.11764705882352941, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-5363", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-2886", "mrqa_searchqa-validation-12184", "mrqa_triviaqa-validation-4040"], "SR": 0.5, "CSR": 0.5374540441176471, "EFR": 0.96875, "Overall": 0.7046001838235294}, {"timecode": 68, "before_eval_results": {"predictions": ["dusseldorf", "Roberta Flack", "sesame seed", "infanta", "Sunday", "barnaby rudge", "Buddha", "Ethiopia", "1963", "discus", "tabloid", "festival of Britain on London's South Bank", "chester racecourse,", "Washington State", "Jews", "Romanian", "saint Basil's", "Peru", "keel", "Evander Holyfield", "\"The Creator's Game.\"", "dharmarajika-Taxila", "New Orleans", "soda", "fat like oil or lard", "Graham Henry", "brash", "ken Burns", "paddy doherty", "Barry Howard and Yvonne", "phi", "Hungary", "So Solid Crew", "blues-rock", "Pennsylvania", "caucausus", "Scottish Parliament", "morningtown Ride", "Jupiter", "watch with Mother", "child", "8", "Queens Park Rangers", "wiziwig", "bulphemus", "flannel", "b\u00e9la Bart\u00f3k", "Hugh Dowding's", "Montpelier", "month", "Arthur, Prince of Wales", "annual income of US $11,770", "318", "Chris Rea", "Tomasz Adamek", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine", "March 30, 2025", "Knox's parents, Curt Knox and Edda Mellas,", "Dubai", "a rabbit hole,", "deep-rooted", "UTC+11:00 (Srednekolymsk Time)", "heavy-metal", "tumaczenie"], "metric_results": {"EM": 0.5, "QA-F1": 0.5797867063492064}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.4, 0.5714285714285715, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7645", "mrqa_triviaqa-validation-6027", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-3417", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-10485", "mrqa_searchqa-validation-7826"], "SR": 0.5, "CSR": 0.536911231884058, "EFR": 1.0, "Overall": 0.7107416213768116}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey Archer", "Chicago", "California Chrome", "Dar es Salaam", "Sarah Keays", "Miss Marple", "Elkie Brooks", "UPS", "Novak Djokovic", "piano", "Cambridge", "Fitzwilliam", "spice girls", "glycerol", "Addams Family", "Doubting Castle", "arthropoda", "argentia", "england", "Harry Shearer", "9-13 years", "pirate day", "penny", "spice girls", "barboria cop", "AFC Wimbledon", "germany", "Tombstone", "Friedrich Nietzsche", "Cambridge", "South Africa", "Bagram Theater Internment Facility", "pygmalion", "bajan", "champagne", "Dieppe raid", "Dengue fever", "The Left Book Club", "triathletes", "Gabriel Byrne and Kevin Spacey", "dividing of cells into additional cell bodies", "strictly Come Dancing", "sound and light", "how", "fox terrier", "Alberta", "raclette", "kilimanjaro", "The Magic Circle", "The Potsdam Conference", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Kent and Edgar", "London Luton Airport", "Thocmentony", "wild boar, and red, fallow and roe deer", "Chaudhary's death was warning to management.", "they don't feelMisty Cummings has told them everything she knows.", "he spent the first night in his car.\"The next morning, he exited his vehicle and observed another vehicle adjacent to his own with a deceased male driver behind the wheel,\" the report said.", "Vanilla Ice", "William Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6136004314313138}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, true, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, false, false, true, false, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 0.5, 0.5, 1.0, 0.11764705882352941, 0.0, 0.7, 0.10256410256410257, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-2042", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-1346", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627"], "SR": 0.53125, "CSR": 0.5368303571428572, "EFR": 1.0, "Overall": 0.7107254464285714}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew - Somerville", "compound sentence", "Australia", "Ashrita Furman", "the American girl group No Secrets", "1994", "April 2010", "12 November 2010", "1 October 2006", "1977", "2018", "Missouri", "Swedien and Jones", "in 1902", "Edgar Lungu", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "1999", "the Maryland Senate", "Latitude", "anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Steve Lukather", "$100", "the referee", "Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W", "`` If These Dolls Could Talk ''", "around 2011", "New Jersey Devils of the National Hockey League", "ulnar nerve", "2018", "31 October 1851", "many forested parts of the world", "Western Australia", "Carol Worthington", "1830", "chemicals", "thanksgiving for a good harvest", "( born November 28, 1973 )", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "birth centenary of Pandit Jawaharlal Nehru", "Anthony Hopkins", "Jesus", "1996", "holography", "Spanish", "far from the Madding crowd", "Gillian Leigh Anderson", "direct scattering and inverse scattering", "45th Infantry Division", "\"it should stay that way.\"", "2010", "an open window", "Dutchman", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.5, "QA-F1": 0.6811340161064425}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 0.823529411764706, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.7142857142857143, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 0.0, 0.8333333333333333, 0.5714285714285715, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.8, 0.8333333333333333, 1.0, 0.7499999999999999, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-5300", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9867", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-2577", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-5562", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-706", "mrqa_newsqa-validation-2658", "mrqa_newsqa-validation-1139", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.5, "CSR": 0.5363116197183099, "EFR": 0.90625, "Overall": 0.691871698943662}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "the inner core and growing bud of certain palm trees", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "Total Drama World Tour", "in Armenia", "red", "off the rez", "either in front or on top of the brainstem", "On March 14, 1942", "Aegisthus", "Epithelium", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Vincent Price", "Pakistan", "Tessa Peake - Jones", "an expected or free or continuously changing behaviour and may have a given individual social status or social position", "United Nations Peacekeeping Operations", "part of the normal flora of the human colon", "Noahic Covenant", "Shirley Mae Jones", "Heat transfer by thermal radiation", "Luke 6 : 12 -- 16, and Acts 1 : 13", "on August 19, 2016", "Sets heart in mediastinum and limits its motion", "scrolls", "Terrell Suggs", "Cecil Lockhart", "August 22, 1980", "retinal ganglion cell axons and glial cells", "letter series", "on August 21, Clash of Champions on September 25 and the following night on Raw", "in the Blue Ridge Mountains of Virginia", "the Confederacy", "in 1955", "electron donors", "2", "Montreal Canadiens", "in 2002", "On 1 September 1939", "three", "creating a so called minimum viable product that addresses and solves a problem or need that exists", "Wyatt `` Dusty '' Chandler ( George Strait )", "last book accepted into the Christian biblical canon", "In the 1920s", "ice giants", "on what became known to locals as `` Black Monday '', and continued into the mid-1980s", "Camellia sinensis", "European Economic Community (EEC)", "Mumbai", "Frank Fertitta, Jr.", "Coronation Street", "Michael Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry", "complicated and deeply flawed", "a house party in Crandon, Wisconsin,", "Butterflies", "Rocky Mountain spotted fever", "10 years", "Afghan"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6179870699583354}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.35294117647058826, 0.75, 1.0, 1.0, 1.0, 0.12121212121212122, 0.0, 0.4444444444444445, 1.0, 1.0, 0.7692307692307693, 0.6666666666666666, 0.8571428571428571, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.10526315789473684, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.5714285714285715, 0.4444444444444445, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-9154", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-2682", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.46875, "CSR": 0.5353732638888888, "EFR": 1.0, "Overall": 0.7104340277777778}, {"timecode": 72, "before_eval_results": {"predictions": ["Earth Day", "Afghanistan", "a potato", "suffrage", "(Greenleaf)", "Christopher Darden", "gourmet", "a type of light we cannot see.", "Philip Berrigan", "wheat", "Carole King", "spain", "The Pro-Jig Clamp Set", "Christo Vladimirov Javacheff", "Wichita", "US Department of Agriculture", "Gilligan's Island", "Penelope", "(Tom) Harkin", "Channel Islands", "Krackel", "Penelope", "Pronouns", "Bonobo", "Harry's", "Veep", "alex", "lullaby", "Burma Ruby stone", "Pan's Labyrinth", "(Peter Pan)", "John Irving", "singular", "The Who", "the Aegean Sea, the Dardanelles-Sea of Marmora-Bosporus", "Xerox", "extra virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "war on drugs", "Beijing", "Lee Harvey Oswald", "George Armstrong Custer", "Newton's Second Law", "mask", "Stockholm", "Alaska", "a puff", "Mausoleum at Halicarnassus", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew 2:11", "Genesis", "Saint Cecilia the Patron Saint of Musicians", "Germany", "1989 until 1994", "Suzuki YZF-R6", "the nose, cheeks, upper jaw and facial tissue", "Donald Trump and Joan Rivers", "two", "Kim Bauer"], "metric_results": {"EM": 0.453125, "QA-F1": 0.570889136904762}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, true, false, false, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.8571428571428571, 0.0, 0.8750000000000001, 0.5714285714285715, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-15033", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-16212", "mrqa_searchqa-validation-14147", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-305", "mrqa_triviaqa-validation-6286", "mrqa_triviaqa-validation-4653", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-1535"], "SR": 0.453125, "CSR": 0.5342465753424658, "EFR": 0.9714285714285714, "Overall": 0.7044944043542074}, {"timecode": 73, "before_eval_results": {"predictions": ["Baltimore", "Happy Days", "Rita Mae Brown", "Bolivia and Paraguay", "Kansas", "a grasshopper", "the commander", "Sure", "1876", "brood", "a spectator", "Humphrey Bogart", "Maryland", "Lion", "the pen", "Herod", "Tonto", "Malaysia", "Georgetown University", "Barry Goldwater", "Goofy", "Walter Payton", "Mount Everest", "Winston Rodney", "Crossword", "the Bufflehead", "the Tom Thumb", "Prince Edward Island", "the Mad Hatter", "sluggishness", "Cincinnati", "Reed VIII", "a Steinway piano", "ketchup", "peanut butter", "soccer", "Tom Petty", "Tuscany", "Tunisia", "Rosa Parks", "inch", "Paris", "William Henry Harrison", "Corinthian", "a gram", "Bern", "Prada", "Chicago", "the umbilical cord", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "2015", "Tipping Point", "Scotland", "the dogger Bank", "James Harden", "eworldly wave", "Ronald Lyle \" Ron\" Goldman", "mad men", "U.S. program to assassinate terrorists in Iraq.", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7052083333333333}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14786", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-12562", "mrqa_searchqa-validation-13507", "mrqa_searchqa-validation-16552", "mrqa_searchqa-validation-12504", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-403", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15975", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-2410", "mrqa_newsqa-validation-510"], "SR": 0.65625, "CSR": 0.5358952702702703, "EFR": 1.0, "Overall": 0.710538429054054}, {"timecode": 74, "before_eval_results": {"predictions": ["Urban Outfitters", "The Tyger", "'The River'", "The Last Supper", "Baccarat", "Rook", "Harlem", "Hertogenbosch", "hull", "Drug Rehab & Treatment Center", "cricket", "India", "Children of Men", "Skagway", "a petition", "Hippolyta", "a species", "John Galt", "spinach", "milk", "last", "imaginative", "World War I", "student loan", "the Gateway Arch", "Itzhak Perlman", "Wolfgang Johannes Puck", "dachshund", "the Monitor", "Cyprus", "Milwaukee", "Coffee", "Kevin Costner and Tim Robbins", "Hot Lips", "Isadora Duncan", "Pig Latin", "Little Debbie", "Gerald Ford", "Speed Racer", "The Beach Boys", "Aristotle", "ER", "the Eagles", "An American Tail", "a Starline Tour", "Argyle", "Honda", "a Wallaby", "a leather feather", "Mark Twain", "Greg Montgomery", "30 October 1918", "Mel Tillis", "Michael Moriarty", "James Christopher Bolam", "eight pawns", "India", "House of Habsburg-Lorraine", "highest commissioned SS rank", "Kansas\u2013Nebraska Act", "Orbiting Carbon Observatory", "South Africa", "Tuesday.", "two"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7177083333333334}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-8228", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-4180", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-1047", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-9788", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_triviaqa-validation-3359", "mrqa_hotpotqa-validation-686"], "SR": 0.65625, "CSR": 0.5375, "EFR": 1.0, "Overall": 0.710859375}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "2017 season", "state", "1900", "at specific locations, or origins of replication, in the genome", "Yuzuru Hanyu", "Michael Crawford", "USA", "Hold On", "Gustav Bauer", "November 2016", "Empiricism", "Evaluation of alternative plans / policies", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "continent", "Johnson", "Song of Songs", "Taron Egerton", "it failed to enforce its rule", "an abbreviation from the initial components in a phrase or a word, usually individual letters ( as in NATO or laser ) and sometimes syllables", "Sheev Palpatine", "Divyanka Tripathi", "the following day", "Lex Luger and Rick Rude", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "homicidal thoughts of a troubled youth", "John C. Reilly", "Daniel A. Dailey", "Mickey Mantle", "U + 002A * Asterisk", "December 15, 2016", "Kid Creole and the Coconuts", "before the start of the era", "2010", "a microfilament", "1983", "Edward Douglass White, Charles Evans Hughes, Harlan Fiske Stone, and William Rehnquist", "the President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Podujana Peramuna, led by former president Mahinda Rajapaksa", "1773", "Buddhism", "introverted Sensing ( Si ), Extroverted Thinking ( Te )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "McKim Marriott", "peacock", "york", "t.S. Eliot", "Russell Humphreys", "Lieutenant Colonel Horace Meek Hickam", "Rihanna", "comments had been taken out of context.", "fractured pelvis and sacrum", "2001", "to recoup any of his principal", "Blackbird", "Sara Ramirez", "September 25, 2017"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6214468964880149}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, false, true, true, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.10526315789473684, 0.0, 0.7142857142857143, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.13333333333333333, 0.0, 0.4444444444444445, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-10448", "mrqa_naturalquestions-validation-4308", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-8004", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-6706", "mrqa_naturalquestions-validation-9410", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.5625, "CSR": 0.537828947368421, "EFR": 0.9642857142857143, "Overall": 0.703782307330827}, {"timecode": 76, "before_eval_results": {"predictions": ["works in a bridal shop", "Walter Mondale", "system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "1942", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "28", "Donald Trump", "24 hours", "Universal Pictures and Focus Features", "multiple", "restarting play after a minor infringement", "A footling breech", "Mockingjay -- Part 1 ( 2014 )", "the President of India", "to signify cunnilingus", "28 %", "Elvis Presley", "N\u0289m\u0289n\u0289", "Jack Scanlon", "2013", "Elijah Wood", "head - up", "Doug Pruzan", "1976", "Donna Reed", "inside the cell nucleus", "pathology", "1986", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "19 - year - old Jourdan Miller", "Panzerkampfwagen VIII Maus", "exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "New England Patriots ( 5 - 4 )", "40 %", "Janie Crawford", "in the east coast of Queensland", "April 2, 2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "Boston Bruins", "around 1872", "Snake River Valley", "starch", "carbon", "on the first Monday in September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery F.C.", "Ken Howard", "one", "Government Accountability Office report", "ethnic Somalis by rebels and Ethiopian troops are rampant.", "a jacket having wide overlapping front flaps and two, parallel columns of buttons", "Heroes Reborn", "to get back the ability to speak", "since 1983."], "metric_results": {"EM": 0.4375, "QA-F1": 0.5861843018093018}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, false, true, false, true, true, false, true, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false], "QA-F1": [0.7272727272727273, 0.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.4615384615384615, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.5, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-1427", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-2782", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-3373", "mrqa_searchqa-validation-1664", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.4375, "CSR": 0.536525974025974, "EFR": 0.9444444444444444, "Overall": 0.6995534586940837}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes virus, (Another name for shingles is herpes zoster.)", "Zork", "Roddy Doyle", "Jaggers' novel", "Prussia", "Rudyard Kipling", "Spongebob Squarepants", "Exile", "an enclave which is entirely enclosed", "South Dakota", "Brian Close", "cabbage worm", "Leeds", "Edinburgh", "meter maid", "cricketer", "france", "Neptune", "Vimto", "phobia", "Leicestershire", "carry On", "Egypt", "sense of taste", "snare drum", "geochronology", "sesame seed", "hurdling", "Centaur", "tallest building in the world", "football", "Paula Wagner", "Beatrix Potter", "Giglio Island", "czech republic", "The Haight-Ashbury district", "Geoffrey Rush", "Harry patch", "funny Folks", "Sight & Sound", "Inigo Jones", "sonar", "Nelson Mandela", "Today", "trousseau", "bootleggers", "Bridget Jones", "dragon", "supercontinent", "Salyut 1", "Dominican Republic", "DJ Khaled's music producer, who takes a liking to Beca", "62", "Matthew Gregory Wise", "1861", "voice actress", "Limbo", "12.3 million", "in July", "U.S. Vice President Dick Cheney", "New Hampshire", "Miniskirt", "fathom", "$163 million (180 million Swiss francs)"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6332859848484848}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true, false], "QA-F1": [0.3636363636363636, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-5462", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-5507", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-7059", "mrqa_triviaqa-validation-479", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-57", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-4029"], "SR": 0.546875, "CSR": 0.5366586538461539, "EFR": 1.0, "Overall": 0.7106911057692307}, {"timecode": 78, "before_eval_results": {"predictions": ["three", "he believed he was about to be attacked himself.", "1960", "\"he was there before Tiger Woods, before Michael Jordan, even before Barack Obama... I hope people remember him for the work he did.\"", "\"momentous discovery\"", "al-Aqsa mosque", "Sri Lanka back on top again in the final session with a 74 stand", "as soon as 2050,", "sylt", "Middle East and North Africa", "city of Najaf.", "Barack Obama", "Arnoldo Rueda Medina.", "left his indelible fingerprints on the entertainment industry.", "ketamine.", "Brian David Mitchell", "Defense of Marriage", "Jacob", "Ronaldinho", "the Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "\"brain hacking\"", "at the age of 23", "start a dialogue of peace", "al Qaeda", "Manmohan Singh's", "help the convicts find calmness in a prison culture fertile with violence and chaos.", "J. Crew", "\"My gut started feeling like something just wasn't right,\"", "10,000", "Meira Kumar", "antihistamine and an epinephrine", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's", "Arthur E. Morgan III", "million dollars", "bribing other wrestlers to lose bouts", "people", "not feel Misty Cummings has told them everything she knows.", "10 below", "Steven Gerrard", "$55.7 million", "Karl Eikenberry", "\"The Closer.\"", "Carol Browner", "conviction of Peru's ex-president is a warning to those who deny human rights.", "Brazil", "10 percent", "the return of a fallen U.S. service member", "modeling", "Val Avery", "early Christians of Mesopotamia", "16 seasons", "caveat", "well", "China", "Capture of the Five Boroughs", "I Should Have Known Better", "pornographicstar", "the burning bush", "summer", "Fannie Farmer", "liberty as its main idea, promoting free expression, freedom of choice, other social freedoms, and \"laissez-faire\" capitalism"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6252591338259441}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.06896551724137931, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.19047619047619047]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-1390", "mrqa_triviaqa-validation-7665", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-15636", "mrqa_hotpotqa-validation-3140"], "SR": 0.53125, "CSR": 0.5365901898734178, "EFR": 1.0, "Overall": 0.7106774129746836}, {"timecode": 79, "before_eval_results": {"predictions": ["Togus", "Ulysses S. Grant", "Yangtze River", "Benjamin", "Queen Anne", "the New York Times", "Swansea", "Oklahoma", "the Communist Party of China", "1950s", "Humphry Davy", "head", "24 hours", "smallpox", "Dead Sea", "the fairway", "Hill Street Blues", "elevation", "Mao Zedong", "Harriet Fitzhugh", "Mickey Mouse", "Xerox", "linebacker", "Jamaica", "G gossip", "an exothermic reaction", "canabalism", "Morocco", "Surf's Up", "Yao Ming", "IRS", "Clothes Off Our Back", "Marvell", "vegetables", "Bollywood", "Love Theme from \"Titanic\"", "Take Me Out To the Ballgame", "parapet", "the first name of dramatist Orton", "chocolate", "Coffee", "Nike", "Margaret Thatcher", "gas masks", "Suriname", "Pearl", "Pirates of the Burning Sea", "Switzerland", "Vestal Virgins", "The Lord of the Rings", "Fidel", "H CO ( equivalently OC ( OH ) )", "During his epic battle with Frieza", "W. Edwards Deming", "Clara Wieck", "Douglas Trendle", "Ricky Gervais and Stephen Merchant", "Ricky Marco", "edith Cavell", "Forbes", "45 minutes, five days a week.", "22", "Demjanjuk", "1,776 steps"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6556344696969697}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, true, true, false, true, false, true, false, true, true, true, false, false, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 0.7272727272727272, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8, 0.4, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13653", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-11663", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-7549", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-807", "mrqa_searchqa-validation-468", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-9998", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-8650", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-2118", "mrqa_naturalquestions-validation-3561"], "SR": 0.515625, "CSR": 0.536328125, "EFR": 0.9354838709677419, "Overall": 0.6977217741935483}, {"timecode": 80, "before_eval_results": {"predictions": ["homebrewer", "the German Empire", "Tim Whelan", "Waimea", "Virgin", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "nine", "Greek: \u1fec\u03ad\u03b1,?]", "Azeroth", "1,467", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "Sinatra: London", "the Manor of the More", "England, Scotland, and Ireland", "the Workers' Party", "his own opinions", "his exploration and settlement of what is now Kentucky,", "six", "Mauthausen-Gusen", "Adrian Peter McLaren", "Distillery", "Ted Nugent", "New York", "Viscount Cranborne", "The Princess and the Frog", "the Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Akinwunmi Martins", "Boulder, Colorado", "Dutch", "November of that year", "Boston, Massachusetts", "The 2011 Teen Choice Awards", "Brendan O'Brien", "Delphine Software International", "Sullivan University College of Pharmacy", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31 - member Senate and a 150 - member House of Representatives", "September 15, 2012", "Chris Evert", "Vienna", "Malaysia", "I, the chief executive officer, the one on the very top", "Iran's nuclear program.", "alternative-energy vehicles", "Bix", "having two heads", "judge", "M&M's"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6930803571428571}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.5, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.4, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.19999999999999998, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-237", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-3760", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-870", "mrqa_searchqa-validation-15999"], "SR": 0.5625, "CSR": 0.5366512345679013, "EFR": 1.0, "Overall": 0.7106896219135802}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "the Entente or Allied powers", "The group's seminal 12-minute track \"Acid Tracks\" (1987)", "Esteban Ocon", "Sophie Lara Winkleman", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham, Alabama", "Nobel Prize in Physics", "Adam Karpel", "blues", "1968", "Windermere", "Sir Frank P. Lowy", "Hermione Baddeley", "Metrolink", "South Australia", "1698", "Greenwood", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "McLaren-Honda", "Ambroise Thomas", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Dar es Salaam", "The English Electric Canberra", "1 September 1864", "Washington, D.C.", "Chechen Republic", "H. R. Haldeman", "Cartoon Cartoon Fridays", "Roman \u00e0 clef", "number 5", "Duchess Eleanor of Aquitaine", "Latium", "April 1, 1949", "English", "Ericsson", "interstate commerce", "1935", "Michael Redgrave", "Tyrann Devine Mathieu", "1933", "British Columbia, Canada", "The Great Gatsby", "willow", "the grinder", "Kim Clijsters", "Africa.", "died Thursday after a suicide bombing at a political rally", "Elementary", "Peter Martins", "voltage", "Willa Cather"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5454861111111111}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, true, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-2729", "mrqa_hotpotqa-validation-3028", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-3513", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-2137", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_triviaqa-validation-873", "mrqa_triviaqa-validation-388", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.453125, "CSR": 0.5356326219512195, "EFR": 0.9714285714285714, "Overall": 0.7047716136759582}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Helen Mirren", "Algernod Lanier Washington", "Conservative Party", "four", "October 29, 1895", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "2006", "Norwegian", "\"The Late Late Show\"", "Ry\u016bky\u016b minzoku", "Commanding General", "\"50 best cities to live in.\"", "Mike Mills", "Parlophone", "January 15, 2016", "IATA: VNO, ICAO: EYVI", "George Clooney", "The Worm", "Herman's Hermits", "Ustad Vilayat Khan", "810", "German", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Richard Price", "Novel", "Gabriel Jesus Iglesias", "3,384,569", "Gambaga", "2 March 1972", "Appalachian Mountains", "La Scala, Milan", "every aspect of public and private life wherever feasible", "Gary Ross", "Washington", "Commissioner", "Sam Tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "born 2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epithelium", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "Ringo Starr", "1882", "off the coast of Dubai", "Sunday's security breach", "not doing more since taking office.", "ibm-l-lpic1104-pdf-devices- filesystems", "polio", "the treble", "gun charges"], "metric_results": {"EM": 0.625, "QA-F1": 0.7278545673076924}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3076923076923077, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8750000000000001, 1.0, 0.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-2244", "mrqa_hotpotqa-validation-438", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-904", "mrqa_hotpotqa-validation-1559", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732", "mrqa_searchqa-validation-5174"], "SR": 0.625, "CSR": 0.5367093373493976, "EFR": 1.0, "Overall": 0.7107012424698794}, {"timecode": 83, "before_eval_results": {"predictions": ["83 Beals Street", "Philip", "Chicago", "Leon Trotsky", "a dough", "a family tree", "the New York Times", "Martin Van Buren", "Ugly Betty", "Winnie the Pooh", "Rigoletto", "Alexander Graham Bell", "(Vijay) Singh", "fog", "a modem", "China", "the Boston Red Sox", "Jon Stewart", "Hitler", "Epistle I", "Jane's", "Christo", "a psychiatrist", "Ichiro Suzuki", "Frank Sinatra", "the Sahel", "the banjo", "Ulysses S. Grant", "Belle Watling", "Mozart", "Chicago, Illinois", "Nellie Bly", "Lord Byron", "meningitis", "Douglas MacArthur", "3M", "the Rolling Stones", "Edie Falco", "The U.S.A.", "Oneonta College", "1936", "the CN Tower", "The farthest from the sun from 1979 to 1999", "inheritance", "Maryland", "the cardinal", "Japan", "spongiform encephalopathy", "Prince Edward Island", "Hindu", "the pronghorn", "January 2, 1971", "in San Francisco", "Moscazzano", "cliff thorburn", "730,000 people", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul John Manafort", "1959", "Ali Bongo", "the United States", "in mid November"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6630580357142857}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-11538", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8713", "mrqa_searchqa-validation-4619", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-15564", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_naturalquestions-validation-10030", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_naturalquestions-validation-8884"], "SR": 0.578125, "CSR": 0.5372023809523809, "EFR": 0.9259259259259259, "Overall": 0.6959850363756613}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "Peter Pan", "Jabez Stone", "Taft", "olive", "buffalo", "Olivia Newton-John", "Oahu", "Joseph Smith", "arthropoda", "Roosevelt", "Capricorn", "Diane Arbus", "Chiles Rellenos", "Thomas Jefferson", "legislation", "tofu", "Old School", "the DEW Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "Variety", "Robert Bruce", "Zinc", "oxygen", "Gargantua", "the Coppertone suntan lotion", "hoof", "Robin Williams", "Philadelphia", "Ivory soap", "Giuseppe Garibaldi", "The Five People You Meet in Heaven", "Anglerfish", "the Jaguar S-Type R", "Thomas Jefferson", "Gandhi", "Brazil", "Jim Thorpe", "Michael", "Jack Crabb", "King Lear", "descend toward the ground", "the National Symphony", "the Haunted Mansion", "Rembrandt", "Gilligan's Island", "a stride", "buffalo Bill", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Tom Robinson", "Andy Serkis", "South Africa", "a horizontal desire", "Charlie Drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun descent", "Dolgorsuren Dagvadorj", "because of what they had done to Muslims in the past,\"", "former U.S. secretary of state", "Newcastle Falcons"], "metric_results": {"EM": 0.609375, "QA-F1": 0.656076388888889}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.26666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-16755", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16785", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-5050", "mrqa_naturalquestions-validation-6465", "mrqa_hotpotqa-validation-660", "mrqa_newsqa-validation-3293"], "SR": 0.609375, "CSR": 0.5380514705882353, "EFR": 0.96, "Overall": 0.702969669117647}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "Postcards from the Edge", "birds", "Virginia", "hot chocolate", "elementary", "Ramadan", "Hamlet", "The Carol Burnett Show", "Wee", "Gertrude Stein", "Pope John XXIII", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tippi Hedren", "object oriented programming", "Nova Scotia", "cocoa", "tuna", "Absinthe", "Macragge", "marsupials", "quid", "Lincoln", "Anthony Newley", "Swimmer's Ear", "Henry", "gigahertz", "Cyrillic", "Jeff Probst", "Hopelessly", "Nasser", "The Moment of Truth", "Laura", "Ethiopia", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "Austin", "the Black Sea", "May 12, 1907", "Uncle Sam", "Young Frankenstein", "Shout", "to form a higher alkane", "comprehend and formulate language", "eusebeia", "Venezuela", "The Shootist", "Sega Dreamcast", "National Society of Daughters of the American Revolution", "Johnny Galecki", "44,300", "it has not", "At least 88", "drowning death,", "murder"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6635416666666666}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.5, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-13276", "mrqa_searchqa-validation-5292", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-15430", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-16963", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-2819", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-13742", "mrqa_searchqa-validation-2063", "mrqa_naturalquestions-validation-4881", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.59375, "CSR": 0.5386991279069768, "EFR": 1.0, "Overall": 0.7110992005813953}, {"timecode": 86, "before_eval_results": {"predictions": ["John Ridgely as Jim Merchant", "at a given temperature", "season ten", "October 28, 2007", "seven units of measure", "permanently absorbed the superhuman powers and the psyche of Carol Danvers, the original Ms. Marvel", "Port Said to the southern terminus of Port Tewfik at the city of Suez", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "5 : 7 -- 8", "between the stomach and the large intestine", "Gupta Empire", "Vicente Fox", "armored fighting vehicle", "Egypt", "the base of the right ventricle", "St. Pauli Girl Special Dark", "U.S. Bank Stadium", "Solange Knowles & Destiny's Child", "statistical", "Cliff's father", "Husrev Pasha", "Anna Maria Demara", "The Osmonds", "735 feet ( 224 m )", "It is a homodimer of 37 - kDa subunits", "chili con carne", "September 8, 2017", "SURFACE AREA OF ROOTS", "Iowa ( 36.6 % )", "Matt Flinders", "1 October 2006", "Natya Shastra", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Hebrew", "nasal septum", "Session Initiation Protocol", "January 1, 1976", "parthenogenesis", "Evaluation of alternative plans / policies", "Ludacris", "Jack Scanlon", "a crown cutting of the fruit", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "the retina", "Donna Mills", "Donna", "Annette Crosbie", "Bobby Kennedy", "Minder", "leopard", "Tim Burton", "Association of Commonwealth Universities", "Symbionese Liberation Army", "102", "two", "Like a Rock", "cat", "King George III", "Norway"], "metric_results": {"EM": 0.53125, "QA-F1": 0.630064472260196}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, false, false, false, true, true, false, true, false, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true], "QA-F1": [0.5714285714285715, 0.5454545454545454, 0.0, 1.0, 0.4, 0.9600000000000001, 0.28571428571428575, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.0, 0.28571428571428575, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-10526", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-4369", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-613", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-3582", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-1808"], "SR": 0.53125, "CSR": 0.5386135057471264, "EFR": 0.9333333333333333, "Overall": 0.6977487428160919}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol.  2", "Arlo Looking Cloud", "Jyothika Sadanah", "the War of 1870", "Hirsch", "Cody Miller", "1951", "Teenitans Go!", "The Ramna Stacks", "Book of Judges", "new, small and fast vessels such as torpedo boats and later submarines", "9 February 1971", "San Francisco, California", "Three's Company", "9,984", "Diondre Cole", "Marktown", "the Rose Theatre", "1 million", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "615 square kilometers or 237 square miles", "Shakespeare's reputation", "Balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden", "Noel", "Michael Rispoli", "U2 360\u00b0 Tour", "Daniel Richard \" Danny\" Green, Jr.", "Scarface", "the Austro-Hungarian Army", "St. George, Maine", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "his son's death", "Helsinki, Finland", "Urijah Faber", "four", "3 May 1958", "The Thomas Crown Affair", "Bharat Ratna", "November 11, 1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "the Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "the person compelled to pay for reformist programs", "the 1920s", "Blue laws", "James Hargreaves", "puff", "Hindi", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "flooding", "composer", "Fontdeck", "Bath", "Winnipeg", "a greeting which is used by some on birthdays, and by others in response to `` Merry Christmas '' and `` Happy New Year ''"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7150263798701298}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 0.25, 0.0, 0.5, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.8571428571428571, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.12121212121212123]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-929", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-4831", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-5179", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-2044", "mrqa_searchqa-validation-15272", "mrqa_naturalquestions-validation-9361"], "SR": 0.59375, "CSR": 0.5392400568181819, "EFR": 1.0, "Overall": 0.7112073863636363}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus", "as many as 250,000", "Ameneh Bahrami", "40", "state senators", "2005", "by text messaging", "Hawaii", "Haiti", "Brazil", "her most important work is her charity, the Happy Hearts Fund.", "ways to speed up screening of service members and, to the extent possible, their families, when the service members are in uniform and traveling on orders.", "Her husband and attorney, James Whitehouse,", "helping to plan the September 11, 2001, terror attacks,", "\"Empire of the Sun,\"", "the burning World Trade Center", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Washington Redskins fan and loved to travel,", "time", "the devastating January 12 earthquake", "Jason Chaffetz", "summer", "southern port city of Karachi,", "allegedly involved in forged credit cards and identity theft", "that anything could have stopped Robert Hawkins from going on a murderous rampage at an Omaha, Nebraska, shopping mall", "Ricardo Valles de la Rosa", "Islamabad", "Toffelmakaren", "3 p.m. Wednesday", "Microsoft", "1995", "Jaime Andrade", "Casalesi Camorra", "Nigeria", "201-262-2800", "South Africa", "sustain future exploration of the moon and beyond.", "France", "President Obama", "late Tuesday night", "to reach car owners who haven't complied fully with recalls.", "Mashhad", "Plymouth Rock", "Alina Cho", "Roger Federer", "last week", "to ensure he had access to cardio equipment at all times without limiting himself to going to the gym or facing days of bad weather.", "AbdulMutallab", "10 years", "second", "Central Germany", "Rust", "gastrocnemius", "Granada", "axe", "Portugal", "June 17, 2007", "England", "Black Elk", "spinach", "Kwanzaa", "\"Sorry, boss,\"", "leopard"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7062824784864258}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.10526315789473685, 0.7368421052631579, 1.0, 0.8571428571428571, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-368", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-929", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1201", "mrqa_newsqa-validation-3264", "mrqa_naturalquestions-validation-7608", "mrqa_triviaqa-validation-6987", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749", "mrqa_hotpotqa-validation-855"], "SR": 0.59375, "CSR": 0.5398525280898876, "EFR": 0.8846153846153846, "Overall": 0.6882529575410544}, {"timecode": 89, "before_eval_results": {"predictions": ["Salt Lake City, Utah,", "(3 degrees Fahrenheit),", "Michael Schibbye and Persson", "killing rampage.", "Eintracht Frankfurt", "they did not receive a fair trial.", "federal officers' bodies", "American Bill Haas", "Larry Ellison", "The supplemental spending bill provides nearly $162 billion in war funding without the restrictions congressional Democrats vowed to put into place since they took control of Congress", "disposable income", "Joan Rivers", "backed Romney in his bid for the Republican presidential nomination", "Phoenix, Arizona,", "KBR's", "Coptic Christians and Muslims", "Alicia Keys", "two years", "the body of the aircraft", "the United States, Japan, Russia, South Korea and China,", "will not support the Stop Online Piracy Act,", "pattern matching.\"", "Teen Patti", "almost 9 million", "U.S. senators", "U.S.-Turkish relations", "London and Buenos Aires", "she returned to Pakistan", "Hitler did to the Jewish people just 65 years ago,\"", "President Obama", "a bank", "two", "believed to be illegal immigrants", "At least 38", "India", "The BBC", "\"wipe out\" the United States if provoked.", "after they ambushed a convoy carrying supplies for NATO forces in southern Afghanistan,", "is a city of romance, of incredible architecture and history.", "top designers, such as Stella McCartney,", "clogs", "debris", "Alicia Keys", "ALS6", "The EU naval force", "well over 1,000 pounds", "Iran's Green Movement of protesters", "helped make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "provides nearly $162 billion in war funding", "Vonn", "three", "the optic chiasm", "Hugo Weaving", "aragonite", "arson", "Olympia", "Bruce R. Cook", "Los Angeles", "86,112", "Tweedledee", "a soap opera", "the Gross Domestic Product Deflator", "zanfairpwllgwyngyll"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6254757395382395}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, true, true, false, false, false, true, false, true, true, false, false, false, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false], "QA-F1": [0.7272727272727273, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.07692307692307693, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8571428571428571, 1.0, 0.2222222222222222, 1.0, 0.923076923076923, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-906", "mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-2900", "mrqa_newsqa-validation-3267", "mrqa_newsqa-validation-436", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-3909", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.515625, "CSR": 0.5395833333333333, "EFR": 1.0, "Overall": 0.7112760416666666}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "Anthrax", "Venus", "larynx", "the Surgeon General", "Ebony", "Cook County", "Sartre", "Wordsworth", "St. Louis", "James K. Polk", "Harpy", "lacrosse", "Naples", "a Dormouse", "the Galatians", "cow pie", "Paradise Lost", "beautiful", "the White Sea", "Doctor Dolittle", "Graceland", "Mitch Albom", "for a few reasons", "earthquakes", "Donovan", "Best Supporting Actor", "The Bionic Woman", "5000", "a tan", "Narnia", "comet Tempel 1", "Cedar of Lebanon", "Kamehameha", "(Elbert) Gary", "sensory experience of sound a marker of corporality", "crowded", "'Duke'", "Orlans", "\"Another Brick in the Wall\"", "Pulp Fiction", "Hester Prynne", "pyjama", "China Airlines", "bagpipe", "a stork", "BOWLING", "Henry David Thoreau", "Encephalitis", "The Americas", "Sydney", "Hudson Bay", "Ellen is restored to life", "The long - hair gene is recessive", "the canaries", "Another Day in Paradise", "The Danelaw", "Donald Wayne Johnson", "Robert Allen Iger", "Manchester Airport", "Iowa,", "16", "they could shoot down the object whether it is a missile or a satellite.", "financial gain,"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7192708333333333}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.4, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-14528", "mrqa_searchqa-validation-10975", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-793", "mrqa_hotpotqa-validation-4724", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-1662"], "SR": 0.671875, "CSR": 0.5410370879120879, "EFR": 1.0, "Overall": 0.7115667925824176}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff", "keirin", "welterweight", "Christopher Nolan", "Arthur Schopenhauer", "a highball", "Conan Doyle", "Godfigu", "brain", "six", "Bashir", "dog sport", "The Double", "arsenic", "omega", "Mickey Mouse", "gallons", "The Welcome Stranger", "the recorder", "Oman", "Genesis", "Ladysmith", "californium", "Robert Guerrero", "the Arizona Diamondbacks", "george Orwell", "Goldie Myerson", "Marc", "all'aglio e olio", "William Shakespeare", "1960's", "Some Like It Hot", "Beaujolais", "injecting a 7 percent solution intravenously three times a day", "The National Council for the Unmarried Mother and her Child", "Sarajevo", "Richard of Montgomery", "St. Thomas \u00e0 Becket", "bullfighting", "leicestershire", "cycling", "Crimean Tatar", "a pea", "Switzerland", "Shanghai", "Duke Orsino", "Gordon Low's birthday", "the Swordfish", "France", "Australia", "France", "17 - year - old Augustus Waters", "1898", "December 1922", "South Asian Games", "Rana Daggubati", "four", "1,500", "a group of teenagers.\"", "38 feet", "the Marquis de Lafayette", "turquoise", "birds", "2010"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5974702380952381}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.7142857142857143, 0.5, 0.0, 0.8571428571428571, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-4071", "mrqa_hotpotqa-validation-369", "mrqa_hotpotqa-validation-3814", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-6259", "mrqa_searchqa-validation-11134"], "SR": 0.53125, "CSR": 0.5409307065217391, "EFR": 0.9, "Overall": 0.6915455163043478}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,438", "Roger the Dodger", "1979 to 2013", "two", "2001", "Meghan Markle", "2006", "alcoholic drinks", "Seoul, South Korea", "Dutch", "41st President of the United States from 1989 to 1993", "political correctness", "Russell Humphreys", "Wisconsin and the Upper Peninsula of Michigan to the south", "January 24, 2012", "over 3 million", "Mazda", "Jack Kilby", "\"My Father\"", "water", "more than 70", "Black pudding", "animorphs", "Francis", "two Nobel Peace Prizes", "Masahiko tofuhita", "\"Apatosaurus\"", "TD Garden", "gay sex, and the gay bear subculture", "Sam Kinison", "Melbourne Storm", "Hawaiian language, \"k\u0101ne \u02bb ohe\" means \"bamboo man\"", "2007", "Washington", "Prudence Jane Goward", "Vince Guaraldi", "\"Famous Ghost Stories,\"", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Mathew Sacks", "Charles VI, Holy Roman Emperor", "17 October 2006", "Memphis Minnie", "29,000 people", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "2018 Unibet Premier League Darts", "first freshman to finish as the runner-up", "Canada", "defense against rain rather than sun", "euro", "Jane Seymour", "Willie Nelson", "1984", "Argentina", "around 3.5 percent", "Ali Bongo", "Antietam", "your premium", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7173692626817627}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.22222222222222224, 0.5, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 0.8, 0.5454545454545454, 0.4, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 0.0, 0.4, 1.0, 0.8, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-310", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1237", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-4468", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_hotpotqa-validation-5757", "mrqa_naturalquestions-validation-7425", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.578125, "CSR": 0.5413306451612903, "EFR": 1.0, "Overall": 0.711625504032258}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "Bill Cosby", "Edward R. Murrow College of Communication", "Liesl, the eldest Von Trapp daughter", "Stage Stores", "Theicide Squad", "1998", "World Famous Gold & Silver Pawn Shop in Las Vegas", "1972", "Argentina", "High Knob", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the IRA's South Armagh Brigade", "Tel Aviv", "Chevy", "tissues of the outer third of the vagina", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "PEN America: A Journal for Writers and Readers", "Love Letter", "1977", "the Commack School District", "January 15, 1975", "Cartoon Network", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Scottish novelist and poet", "Pennsylvania's 18th congressional district, the 43rd District of the Pennsylvania State Senate", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow", "George Martin", "Manchester United", "Adam Dawes", "Enkare Nairobi\"", "Rockland, Maine", "2009", "Vietnam War", "Toto", "9 February 2018", "Todd Griffin", "Gabriel Byrne, Kevin Spacey, Benicio Del Toro, Kevin Pollak, and Stephen Baldwin", "funchal", "the British", "Chievo", "it would", "a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7091653138528138}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.888888888888889, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.1818181818181818, 0.6666666666666666, 0.2857142857142857, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.28571428571428575, 0.5714285714285715, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2095", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-4194", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-5279", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-4397", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-960", "mrqa_hotpotqa-validation-961", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_searchqa-validation-16694"], "SR": 0.578125, "CSR": 0.5417220744680851, "EFR": 1.0, "Overall": 0.7117037898936169}, {"timecode": 94, "before_eval_results": {"predictions": ["he hears a different drummer", "Hitler", "Mrs. Miniver", "Simon Cowell", "the Eagles", "Packard", "lifejackets", "Ian Fleming", "The Taming of the Shrew", "A Young Girl", "Tahiti", "My Name Is Earl", "Nassau", "a geisha", "France", "Barbarossa", "the CIA", "yeast", "the BlackBerry", "Matthew", "Phonetics", "4 Way Street", "Frasier", "the bottles filled with holy water", "a cannonball", "the Court of Cassation", "Chiapas", "Jeopardy", "Afghanistan", "Australia", "buffalo", "seoul", "the College of Physicians and Surgeons", "pitch", "Pete Rose", "Esther", "South Africa", "Bacall", "GoldenEye", "The Business of Marriage", "Dumbo", "Edith Wharton", "Bonnie Raitt", "marsupials", "Italian", "The Crow", "Lou Gehrig", "Orson Welles", "snakes", "Russell Crowe", "Ecuador", "only apocalyptic document", "four", "elected or appointed by means of a commission", "Friends", "frankincense", "the solar system", "Ranulf de Gernon", "Karolina Dean", "Pieter van Musschenbroek", "Seoul", "I've been feeling better every single day since surgery", "the secrets of the Ku Klux Klan", "The Krankies"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6338541666666666}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2367", "mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-13172", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-804", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_searchqa-validation-16657", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4503", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.59375, "CSR": 0.5422697368421052, "EFR": 1.0, "Overall": 0.711813322368421}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "the Vic-Wells", "Antnio Guterres", "Latin", "King Henry VIII", "San Francisco", "The Memory Keepers daughter", "Nereid", "the Chamber of Secrets", "Brutus", "the wild-goose", "Joseph Haydn", "Willa Cather", "the Dow Jones Industrial Average", "Aunt Jemima", "the fowls", "dynasties", "Homer", "Amanda Bynes", "Ted Danson", "O. Henry", "Osteosarcoma", "B.B. King", "JFK", "Donovan", "plankton", "Candlestick Park", "a plane", "compensation", "vodka", "corned beef", "Adam", "heresy", "Ivy Dickens", "woozy", "Thor", "Ham", "a mild astringent", "Sicily", "Nelson's Column", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Norman's half - brother", "1 October 1939", "Ming general Wu Sangui", "wilt", "Little arrows", "Rotary", "Craig William Macneill", "William Adelin", "the 617th episode", "Newark's Liberty International Airport,", "more than 4,000", "Lifeway Christian Stores", "Pakistan"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6651785714285714}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.28571428571428575, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-5291", "mrqa_searchqa-validation-9089", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-12114", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-1558", "mrqa_searchqa-validation-503", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.609375, "CSR": 0.54296875, "EFR": 0.92, "Overall": 0.695953125}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "Sarto", "Unbreakable", "Holy Week", "Tijuana", "Wizard", "byte", "Planned Parenthood", "Jamie Lee Curtis", "King of the Hill", "Abduction", "Alexander Graham Bell", "north-east", "baffle", "corpulent", "Herman", "Erin Go Bragh", "Queen Victoria", "giant", "Medusa", "zoology", "Lucia di Lammermoor", "the largest lakes and rivers", "cricket", "Stephen Hawking", "St. Francis of Assisi", "lumens", "The Scarlet Letter", "2016", "Drug Rehab & Treatment Center", "pastries", "the Hundred Years' War", "the Met", "milk and honey", "Three", "stenosis", "The Beatles", "Bronx", "saccharides", "King Kong", "Cubism", "Umbria", "hoop cheese", "Escher", "Oahu", "the ureter", "F. Scott Fitzgerald", "aria", "Ghostbusters II", "Marquette University", "Rothschild", "Fall 1998", "infection", "Bart Howard", "the Netherlands", "marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"To the Muslim world, we seek a new way forward, based on mutual interest and mutual respect.\"", "2008", "acid", "number five"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7442708333333333}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-1885", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-9309", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-333", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-1645"], "SR": 0.65625, "CSR": 0.5441365979381443, "EFR": 1.0, "Overall": 0.7121866945876288}, {"timecode": 97, "before_eval_results": {"predictions": ["4", "four gold rings", "Gaston Leroux", "Concorde", "gold", "European Economic Community", "Canterbury and Lancaster", "Vietnam", "Florentius", "Wanderers", "Emilia Fox", "WWF", "stare Miasto", "Shaft", "gal", "Ramadan", "Girard", "Count Basie Orchestra", "Pegida", "plutonium", "Eva Strong", "Edward Hopper", "Einstein", "Faversham", "Justin Trudeau", "Michael Jackson", "time team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "Bolivia", "Christian Wulff", "ginger", "usk", "spider", "Malcolm Turnbull", "Daily Herald", "Nairobi", "Alan Turing", "bone", "in the sinoatrial node", "Puck", "Saturn's Hula-Hoops", "an ap\u00e9ritif", "Lady Susan, and the Watsons", "Rocky Graziano", "cashmere", "Today", "Today", "Gene Vincent", "Midgard", "an aberrant, ligand - independent, non-regulated growth stimulus", "the Chesapeake", "Ben Faulks", "Taylor series", "the right bank of the Gomti River", "Art of Dying", "John Auer,", "a handful of tweaks", "Christopher Savoie", "Plouton", "Ingenue", "World War I", "Joseph"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5895833333333333}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, true], "QA-F1": [0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-2947", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-4006", "mrqa_triviaqa-validation-4806", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4376", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-2098", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947"], "SR": 0.546875, "CSR": 0.5441645408163265, "EFR": 0.9655172413793104, "Overall": 0.7052957314391273}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "belfast", "Jerry Mouse", "cirrus uncinus", "Procol Harum", "river Alt", "belfast", "cracow", "Uganda", "st pancras", "lactic acid", "\u00f2se", "Robinson Crusoe", "aller f\u00fcrnemmen und gedenckw\u00fcrdigen Historien", "\u201cMy Favorite Martian,\u201d", "whist", "a fear of snakes", "Madagascar", "Wyatt Earp", "July", "One Direction", "The West Wing", "Prince Harry", "1994", "titanium", "a meadows", "Pegasus", "Alaska", "robin huckleberry Finn", "Brazil", "horseradish", "carol thatcher", "eyes", "czech republic", "bowie knife", "Nile", "a rat", "Independence Day", "Tinie Tempah", "porto", "cracow", "lightweight baby buggy", "beard", "Amy Dorrit", "oldham", "The Sunday Post", "bobby darin", "emirate", "robin williams", "mansfield park", "South Africa", "Cam Clarke", "Daytona 500 pole winners", "Florida", "twenty-three", "Mexican War on Drugs", "relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi ethnic minority and Hutu majority", "Tempest", "Naples", "Solomon", "If the citizen's heart was heavier than a feather"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5925854527417027}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, false, true, true, true, false, false, true, true, false, false, true, false, true, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.75, 1.0, 0.4, 1.0, 0.5, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.18181818181818182]}}, "before_error_ids": ["mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-4266", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-487", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-4125", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-4987", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_hotpotqa-validation-3713"], "SR": 0.484375, "CSR": 0.5435606060606061, "EFR": 0.8787878787878788, "Overall": 0.6878290719696969}, {"timecode": 99, "UKR": 0.751953125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.78125, "KG": 0.503125, "before_eval_results": {"predictions": ["people kill him with the blocks,", "37th", "dismissed all charges", "U.S. Defense Department", "11", "inmates", "Kenyan and Somali governments", "prostate cancer,", "Philip Markoff,", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her.", "Red Lines", "Kirchners", "an African-American woman", "Arsene Wenger", "Gary Coleman", "Carrousel du Louvre", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "Marcus Schrenker,", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "June 25.", "\"El Viceroy,\"", "Kerstin", "Amnesty International.", "The Tinkler", "\"Let it Roll:", "to do the dirty work,\"", "a lump in Henry's nether regions", "It's a done deal", "snow,", "\"Stagecoach\"", "dogs who walk on ice in Alaska.", "cardio", "school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "in Thessaloniki", "al-Moayad", "\"I wanted to shove it up that black a--.\"", "3 thousand", "burning of a church.", "cause of the child's death will be listed as homicide by undetermined means,", "separately on multiple corruption charges.", "2,000", "Nirvana frontman,", "Cirque du Soleil", "9", "for the rest of the year", "hydrogen", "Bobby Darin", "foreign investors", "the back of the neck", "wrigley's", "CBS", "Anzac Day (25 April)", "on the upper Missouri River", "Phil Spector", "Charlie and the Chocolate Factory", "Arthur Miller", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6200253739316239}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.25, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-807", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-1992", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4326", "mrqa_triviaqa-validation-7478", "mrqa_triviaqa-validation-3949", "mrqa_hotpotqa-validation-2793", "mrqa_hotpotqa-validation-3174", "mrqa_searchqa-validation-6438"], "SR": 0.5625, "CSR": 0.54375, "EFR": 1.0, "Overall": 0.716015625}]}