{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=1e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=1e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=1e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4010, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "isomorphic", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Stanford University Professor of Comparative Literature Richard Rorty", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8181801079682272}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.9333333333333333, "Overall": 0.8494791666666667}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "P", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "September 1969", "Mansfeld", "Warsaw Stock Exchange", "390 billion individual trees divided into 16,000 species", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "13 May 1899", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification that occurs following sequential proteolytic activation of complement molecules", "Lituya Bay in Alaska", "120 m ( 390 ft ) at its widest part", "the eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books have been released, plus one do - it - yourself book and two movie diaries", "Hal David and Burt Bacharach", "five points", "The Monitor and Merrimac", "the Atlantic Ocean, the Gulf of Mexico and the Straits of Florida"], "metric_results": {"EM": 0.671875, "QA-F1": 0.774634455779654}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 0.3076923076923077, 1.0, 0.6153846153846154, 0.4444444444444445, 1.0, 0.4, 1.0, 0.5853658536585366, 1.0, 0.0, 0.5, 0.5, 0.16666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1759", "mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-5788", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1454", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.671875, "CSR": 0.734375, "EFR": 0.9047619047619048, "Overall": 0.8195684523809523}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "Abercrombie was recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "John Elway", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Bud '' Bergstein", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "the surly librarian who looks after his alcoholic sister Mary Elizabeth ( Margaret Hoard )", "In December 1971, the `` Smithsonian Agreement '' was reached. In this agreement, the dollar was devalued from $35 per troy ounce of gold to $38", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7768601190476191}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.5, 0.0, 0.13333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.6875, "CSR": 0.72265625, "EFR": 1.0, "Overall": 0.861328125}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Presque Isle", "wireless", "Coldplay", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "1960s", "that narcotic drugs were controlled in all member states, and so this differed from other cases where prostitution or other quasi-legal activity was subject to restriction", "Napoleon", "Immunology", "geophysical surveys", "topographic gradients", "130 million cubic foot", "50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "NDS, a Cisco Systems company", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "their parent thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "evading it", "the kettle and the Cricket", "Gandhi", "The first written mention of this capital's name was in a 1459 document of Vlad the Impaler", "\"Take us the foxes, the little... Alexandra - first cousins - as a means of getting Horace's money", "the 1982 Sony SL-2000 portable", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "8/4 x 365 = 730 days", "1994", "1867 to 1877", "Marshal Dillon", "\"Wannabe\" and \"Say You'll Be There\"", "The Best Hotels on Bali", "The new nightspot Teddy's made this presidential Hollywood hotel a happening", "LASER abbreviation", "Incomprehensible", "Juno", "Hundreds of species of peat mosses are found in bogs throughout Canada", "why", "Daya", "fear of meat", "American", "Mexican military"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6366284756909757}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.2666666666666667, 0.0, 0.3076923076923077, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.1818181818181818, 0.0, 0.0, 0.0, 0.15384615384615385, 0.0, 0.33333333333333337, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-10204", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-2804", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.53125, "CSR": 0.684375, "EFR": 0.9666666666666667, "Overall": 0.8255208333333333}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau", "Levi's Stadium", "ten million", "the Lippe", "Video On Demand content", "time and storage", "semester", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "League of the Three Emperors", "science", "143,007", "Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "from 1972", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Br'er Rabbit", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.75, "QA-F1": 0.807832532051282}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-4919", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-6676", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.75, "CSR": 0.6953125, "EFR": 0.875, "Overall": 0.78515625}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the courts of member states", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "A vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "the means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "Spanish", "Structural geologists", "president and CEO of ABC", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Burwell Johnston, Jr.", "a large green dinosaur", "Taylor Swift", "Eric Edward Whitacre", "Joint Chiefs of Staff", "Linux Format", "Jasenovac concentration camp", "Rabat", "between 11 or 13 and 18", "Heather Langenkamp", "Henry Gwyn Jeffreys Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "It is based in Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "English former international footballer", "the Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Ashanti", "79", "Algeria", "a novel", "the Eastern part", "Polar Bebe", "Atlantic City"], "metric_results": {"EM": 0.65625, "QA-F1": 0.793686537114846}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 0.6666666666666666, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.5, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7983", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971"], "SR": 0.65625, "CSR": 0.6897321428571428, "EFR": 0.9090909090909091, "Overall": 0.799411525974026}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "the working fluid", "a suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "output", "those who already hold wealth", "center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "canalized section", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "along the entire length of the lake", "computer programs", "General Conference", "1996", "dreams", "The Judiciary", "deterministic", "Bart Starr", "oxygen that is damaging to lung tissue", "Karluk Kara-Khanid", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "A. E. Housman", "capital of the Socialist Republic of Vietnam", "Sevens", "fennec fox", "Bart Conner", "fantasy", "Martin \"Marty\" McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Cody Miller", "140 to 219", "the \"Father of Liberalism\"", "Christophe Lourdelet", "Pablo Escobar", "African", "Mexico City", "Sleeping Beauty", "2005", "1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Ali Bongo", "Wheat Chex", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7217013888888889}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-1771", "mrqa_squad-validation-9287", "mrqa_squad-validation-1819", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.671875, "CSR": 0.6875, "EFR": 0.9047619047619048, "Overall": 0.7961309523809523}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Non-revolutionary", "higher efficiency", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "5th Avenue laboratory fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "General Conference in Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "tailless", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Harvard University", "Fulham", "A55", "Maud of Gloucester", "\u00c6thelstan", "Special economic zone", "44", "NCAA's Division I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "A diastema ( plural diastemata )", "Shirley", "Israel", "Bigfoot", "Papua New Guinea", "Edgar Degas", "Manchester"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7539434523809524}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 0.6666666666666666, 0.0, 0.3636363636363636, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-3391", "mrqa_squad-validation-1501", "mrqa_squad-validation-9859", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_triviaqa-validation-3170", "mrqa_newsqa-validation-1268", "mrqa_triviaqa-validation-1423"], "SR": 0.6875, "CSR": 0.6875, "EFR": 0.75, "Overall": 0.71875}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules", "French", "Museum of the Moving Image in London", "acted increasingly aggressively to force the Huguenots to convert", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "pivotal event", "one of the youngest publicly documented people to be identified as transgender, and for being the youngest person to become a national transgender figure", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia, the Disneyland Monorail, and the Motor Boat Cruise", "Yasir Hussain", "USC Marshall School of Business", "Stephen Ireland", "Marko Tapani", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "4145 ft above mean sea level", "Central Park", "Robert John Day", "Tifinagh", "James Tinling", "Italy", "the 79th Masters Tournament", "Kristoffer Rygg", "University of Kentucky College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "a North African dish of small steamed balls of semolina, usually served with a stew spooned on top", "more than 22 million", "morphine sulfate oral solution 20 mg/ml", "The Firm (1993 film)", "freshwater"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6275569529498016}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-5477", "mrqa_hotpotqa-validation-1267", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.546875, "CSR": 0.6734375, "EFR": 0.9310344827586207, "Overall": 0.8022359913793103}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "Timucuan", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Panthers", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "not covered in any newspapers", "arrows, swords, and leather shields", "Cybermen", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "Standard Model", "Tolui", "the Rhine-Ruhr region", "pedagogy", "Prevenient grace", "Kansas Jayhawks", "the Queensland Heritage Register", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The The The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "the RATE project's results", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany", "New Jersey", "Massachusetts", "Ector County", "Jim Davis", "Buck Owens", "World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the Halle Orchestra", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "The Londoner"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7002300933078549}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7269", "mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-6927", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.609375, "CSR": 0.6676136363636364, "EFR": 0.92, "Overall": 0.7938068181818182}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "Spanish", "Only 100\u2013150 species", "Philo of Byzantium", "cooler", "marine waters worldwide", "$60,000", "his mother's genetics and influence", "shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "new element", "building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "It's helping consumers move beyond these hard times and has reignited a whole industry", "planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "deciding the duties of the new prime minister has been a sticking point in the negotiations", "lack of a cause of death and the absence of any soft tissue", "200", "The drug is legal for medical use, but it is trafficked into Hong Kong from other parts of Asia, such as India and mainland China, and sold on the streets illegally", "opposition party members", "Missouri", "\"Racism and racist conversations have no place today in America.\"", "executive director of the Americas Division of Human Rights Watch", "Dominican Republic", "90", "KARK", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "her home", "Employee Free Choice act", "Bush administration", "more than 200", "This is not a project for commercial gain. It is done with the parents' full consent", "best-of-three series", "Kaka", "Japanese ex-wife", "Dan Parris, 25, and Rob Lehr, 26", "apartment near Fort Bragg in North Carolina", "two", "The federal government has set aside nearly $2 billion in stimulus funds to clean up Washington State's decommissioned Hanford nuclear site", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "Winehouse", "Ark of the Covenant ( the Aron Habrit in Hebrew )", "Jean F Kernel ( 1497 -- 1558 ), a French physician", "Thomas Hardy\u2019s novel", "Richmondshire Museum", "1994", "The Conjuring", "The Gallipoli Campaign", "Georgian Bay", "Nowhere Boy"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6102020790200138}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.25, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8666666666666666, 0.4444444444444445, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.38095238095238093, 0.0, 1.0, 0.0, 0.4444444444444445, 0.8333333333333333, 1.0, 0.2608695652173913, 1.0, 1.0, 0.4, 0.0, 0.6, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4611", "mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-1283", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-733", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-6176", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.484375, "CSR": 0.65234375, "EFR": 0.8484848484848485, "Overall": 0.7504142992424243}, {"timecode": 12, "before_eval_results": {"predictions": ["C\u00e9loron threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "every good work designed to attract God's favor is a sin.", "Napoleon", "mass production", "James O. McKinsey", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states.", "1227", "lower lake", "three", "Elders", "587,000", "A further type of committee", "Bruno Mars", "the Catechism", "beneath the university's Stagg Field", "Ian Botham", "Pyotr Tchaikovsky", "Vincent Motorcycle Company", "\"Frenchie\"", "Salvador Allende", "Marie Antoinette", "Hawaii", "Erik Thorvaldson", "Apollo", "the 1940 Rodgers and Hart musical Pal Joey.", "Mary Seacole", "green", "Indonesia", "Moses", "Antonio", "European Economic Community", "Christine Keeler", "Jesus", "Jack Nicholson", "four", "Netherlands", "\"Sugar Baby Love\"", "Coretta Scott King", "Sean", "Bill and Taffy Danoff", "early", "Travis", "Blue Peter", "Robert Kennedy", "Q", "a lightweight, folding version that, with added waterproofing materials, could protect users from rain and snow.", "Hobbies", "barber", "Harry Hopman", "Murrah Federal Office Building", "Evita", "an old, unsavoury, and oily black clay pipe, which was \u201cto him as a counsellor\u201d and \u201ccompanion of his deepest meditations.\u201d", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley", "\"It is very easy for comments to be taken out of context and create unnecessary drama", "a delegation of American Muslim and Christian leaders", "Royal Wives", "the Greek Village", "Juan Martin Del Potro."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6111369460978836}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, true, false, true, false, true, false, false, true], "QA-F1": [0.962962962962963, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 0.07142857142857142, 1.0, 0.8571428571428571, 1.0, 0.0625, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10141", "mrqa_squad-validation-2262", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_triviaqa-validation-712", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_searchqa-validation-5929"], "SR": 0.546875, "CSR": 0.6442307692307692, "EFR": 0.7931034482758621, "Overall": 0.7186671087533156}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "in order to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "julph", "moles", "d\u0113mokritos", "kajalein Atoll", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "jazz tenor saxophonist", "one", "komando Pasukan Khusus", "Carlisle", "liquid", "clannicothe and Zanesville", "Lucas McCain", "p\u00f4le antarctique", "mercury gilding", "aniridia", "stearns Eliot", "the Firth of Forth", "woe", "NOW Magazine", "j Jesse James", "Italy", "Canada", "typhoid fever", "juliano Pavarotti", "action figure", "walt Kowalski-Gran Torino", "2010", "einasto's law", "Venezuela", "stooge", "turbulence", "40", "the Sch\u00e4dellehre", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Christopher James \" Chris\" Weidman", "Athletics Stadium", "one", "Virgin America", "julie o'Reily", "sae", "Iran's parliament speaker", "In Group D, Bundesliga Hertha Berlin beat Sporting Lisbon of Portugal 1-0 through Gojko Kacar's second half strike.It meant Dutch side Heerenveen were eliminated despite a 5-0 home victory"], "metric_results": {"EM": 0.5, "QA-F1": 0.5421875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, false, false, true, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-2463", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.5, "CSR": 0.6339285714285714, "EFR": 0.71875, "Overall": 0.6763392857142857}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary civil disobedience", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow", "public official", "the most cost efficient bidder", "acorn", "continental United States", "thighbone", "Olympia", "Ukraine", "shrews", "Lois & Clark", "roan krakauer's Into the Wild", "amber", "stanley Basmati", "The executioner's Song", "180 degree", "almaty", "anamosa", "grouchy", "The Comedy of Errors", "asylum", "film", "rope", "germania", "Cologne", "Henley", "an ingot", "Kosovo", "James Jeffords", "Prague", "tennis", "silk", "cowboys", "Sir Winston Churchill", "Key deer", "Japan", "burt Reynolds", "Thant", "boys", "accordion", "Monsieur", "George S. Klein", "Augusta", "counter clockwise", "2013", "Nick Hornby", "parachutes", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama", "mother's memories of his mother", "Israel"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.453125, "CSR": 0.621875, "EFR": 0.9142857142857143, "Overall": 0.7680803571428572}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "Rhenus", "1996", "wine", "German", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "a violinist", "Paula Abdul", "Strongsville, Ohio", "Flemish", "Mastercard", "Roger B. Smith", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "a tan or brown macule", "a casino", "Toronto Maple", "Zsa Zsa Gabor", "Vladimir Nemirovich-Danchenko", "Utah", "sugarcane", "updike", "Johann Strauss II", "joey", "pro bono", "Siena", "The Fun Factory", "a ale", "Manfred von Richthofen", "Nacho Libre", "copper", "fictional narratives set in actual places such as cities", "the hemlock", "Dr. Jeffrey Wigand", "poetry", "The Runza Way", "a meager allowance", "1942", "blimps", "the Bunsen burner", "a geisha", "Bigfoot", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a tin star", "dark", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6213541666666667}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, false, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-9248", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-14698", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.546875, "CSR": 0.6171875, "EFR": 0.9655172413793104, "Overall": 0.7913523706896552}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Weser", "(Evita) Peron", "(Nguyn) Thnh", "circumference", "the Inuit", "Detroit", "the Toronto Blue Jays", "President Lincoln", "(Ray) Bradbury", "crimes committed out of hatred for someone's race", "Madagascar", "( Nicolas) Sarkozy", "Rubicon", "(Sanjaya)", "17", "Jo March", "Modeling Compound", "Aphrodite", "(Thomas) Gabriel", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Rodham Clinton", "(Errol Lincoln) Uys", "(Bellerophon)", "Balaam", "the University of Pennsylvania", "The Caine Mutiny", "(The Allman Brothers Band)", "(founded 1932)", "(John) Coltrane", "the peace sign", "oxygen", "Sphinx", "Huss", "USA Network's The Sing-Off", "Mavericks", "Onegin", "Macy's Christmas Parade", "a spinning jenny", "(H0H 0H0)", "(Denzel Washington)", "negligence", "the courts", "attached to another chromosome", "Broughton", "Australia", "The Jefferson Memorial", "aged between 11 or 13 and 18", "Michoacan Family", "prisoners", "his salary", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan."], "metric_results": {"EM": 0.484375, "QA-F1": 0.6214514652014652}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true, false, true, true, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.8, 0.5, 1.0, 0.2, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.23076923076923078]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8100", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-9150", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-14660", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13667", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_hotpotqa-validation-3410", "mrqa_newsqa-validation-1759"], "SR": 0.484375, "CSR": 0.609375, "EFR": 0.9393939393939394, "Overall": 0.7743844696969697}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Robert Lane and Benjamin Vail", "a telephone ring", "the Party of National Unity", "22", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "Jesse Jackson", "Puerto Rico", "Mausolus", "Million Dollar Baby", "Switzerland", "Belgian World Airlines", "The Old Man and the Sea", "French", "Joe Louis", "lion", "d'Artagnan", "the Bayeux Tapestry", "Front Porch", "China", "Shia", "notes placed at the bottom of a page", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "Blanche DuBois", "a binding technique", "FRAM", "the House of Representatives", "a beer company founded by John Kinder Labatt", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "Don Juan", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Ronald Reagan", "Fiddler", "Ethiopian", "six", "1992", "a base", "Bromley-By- Bowen", "the Ruul", "Cartoon Network", "Caylee Anthony", "know what's important in life", "the bomber claimed to be a Taliban member who had come for the talks about peace and reconciliation, and detonated the explosives as he entered the home.", "nuclear", "The drama of the action in-and-around the golf course has enraptured fans of the game through the generations and around the world."], "metric_results": {"EM": 0.640625, "QA-F1": 0.6677442528735632}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, false, false, true, false, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.06896551724137931, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-15593", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-2709", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-14873", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-12814", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-4110"], "SR": 0.640625, "CSR": 0.6111111111111112, "EFR": 0.9565217391304348, "Overall": 0.783816425120773}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXXIII", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity", "same-gender marriages", "2006", "mid-18th century", "hollandaise", "A Raisin in the Sun", "Sistine Chapel", "Belarus", "a tight end", "a trowel", "Big Bang", "Sex Pistols", "endodontist", "Saturn", "The 10 Most Beautiful Towns in Denmark", "Genoa", "Galt", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Seattle", "polyantha", "The Hampton Inn", "21", "the Civil War", "Copeina arnoldi", "Paul McCartney", "omega-6", "paoletas", "Bachman Turner Overdrive", "Halloween", "caddy Shack", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "bears", "a quake", "a sign", "elephants", "Mazur", "Denmark", "covert", "Our Country", "May 2010", "in the majority of the markets the company has entered", "Guanabara Bay", "Thailand", "gender queer", "Minister for Social Protection", "Berga", "Mount Vernon Estate & Gardens", "McFerrin, Robin Williams, and Bill Irwin", "ase", "the upper peninsula of Michigan, south to northern Louisiana, west to Colorado, and east to Massachusetts"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5331981169871794}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.15384615384615383, 0.0, 1.0, 0.0, 1.0, 0.5, 0.4, 0.5, 1.0, 0.9375]}}, "before_error_ids": ["mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_newsqa-validation-3343", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.421875, "CSR": 0.6011513157894737, "EFR": 0.8918918918918919, "Overall": 0.7465216038406828}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "transplastomic", "Earth", "53,000", "one", "poet", "two points", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "arousal recognition", "Charlene Holt", "Bill", "1991", "electron shells", "Cornett family", "acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Rick Rude", "Ohio", "a form of business network", "a cylinder of glass or plastic", "James Hutton", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Necator americanus", "February 29", "the Lykan", "disagreements involving slavery and states'rights", "oxygen", "Cecil Lockhart", "Mara Jenna", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "a man called Lysander", "Jupiter", "east", "15", "John Robert Cocker", "Silvan Shalom", "a simple puzzle video game", "a palace", "the olfactory nerve", "Eucalyptus", "a dolphin", "oxygen"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6618489583333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.625, 1.0, 0.2, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-8339", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_triviaqa-validation-2227"], "SR": 0.5625, "CSR": 0.59921875, "EFR": 0.9285714285714286, "Overall": 0.7638950892857144}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "His Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape", "illegal crossings", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "well over 1,000 pounds", "peace with Israel", "Mutassim", "from Texas and Oklahoma to points east", "Polo", "\"The Jacksons: A Family Dynasty\"", "in Amstetten", "computer problems", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus", "prisoners", "September, 2004", "consumer confidence", "about 5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Lula Bell Houston Laundry", "Swat Valley", "Friday", "1979", "the United States", "behind the counter", "chief executive officer", "\"There's no chance of it being open on time.", "file papers shortly with an appeals court seeking an emergency stay of the order in its tracks", "Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "Michael Schumacher", "Hurricane Gustav", "gun", "Henrik Stenson", "the children that a French charity attempted to take to France from Chad for adoption are neither Sudanese nor orphans", "40", "Jason Voorhees", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter solstice", "Pentecost Sunday", "Aberdeen", "Dumb and Dumber", "Nokia Sugar Bowl", "Minton", "converging", "passing of the year", "season five", "Revenge of the Wars ( 2005)"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6527620816683316}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, true, false, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.4, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.5, 0.0, 1.0, 0.18181818181818182, 0.5, 1.0, 0.2857142857142857, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.3636363636363636, 0.8666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.7499999999999999, 0.3333333333333333, 0.22222222222222224]}}, "before_error_ids": ["mrqa_squad-validation-2466", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-3477", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-3209", "mrqa_newsqa-validation-1549", "mrqa_triviaqa-validation-3457", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.484375, "CSR": 0.59375, "EFR": 0.8484848484848485, "Overall": 0.7211174242424243}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress", "Southern Border Region", "chief electrician", "Newton", "static friction", "the assassination of US President John F. Kennedy", "the Kenyan forces crossing of the joint border as \"an affront to Somalia's territorial sovereignty.\"", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "in a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offset,", "Wednesday.", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday.", "Kim Clijsters", "Mashhad", "Amanda Knox's aunt", "great jazz", "$17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "a nurse who tried to treat Jackson's insomnia with natural remedies", "Sarah", "jumped full time into his company, Ripken Baseball, without taking any break, lessening the emotional jolt of retirement.", "1981", "17 Again", "Nigeria", "$81,88010", "Republicans", "EU naval force", "Chris Robinson", "Bongo", "The Delta Queen steamboat, a floating National Historic Landmark, departed Cincinnati, Ohio, on its final scheduled voyage this week.", "Hyundai Steel", "a bone-growth disorder that causes dwarfism", "London Heathrow's Terminal 5.", "\"It was never our intention to offend anyone,\"", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "The White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\" (2012)", "Northumbrian", "\"get thee to a nunnery\"", "Elena Ceausescu", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Eduard Leopold, Prince of Bismarck, Duke of Lauenburg"], "metric_results": {"EM": 0.5, "QA-F1": 0.611567449793069}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 1.0, 0.11764705882352941, 0.5454545454545454, 0.0, 0.0, 0.9, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.21052631578947367, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.36363636363636365]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-7642", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107", "mrqa_hotpotqa-validation-1056"], "SR": 0.5, "CSR": 0.5894886363636364, "EFR": 0.84375, "Overall": 0.7166193181818181}, {"timecode": 22, "before_eval_results": {"predictions": ["X-ray imaging", "WMO Executive Council and UNEP Governing Council", "Germans", "New York and Virginia, especially.", "two", "glowed even when turned off.", "a number of celebrities and ministers, ranging from Yolanda Adams to Bishop T.D. Jakes to Kirk Franklin.", "resources that could sustain future exploration of the moon and beyond.", "sovereignty over them.", "April 6, 1994", "Prague", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "a federal judge in Mississippi", "the department has been severely affected by the earthquake, with thousands of officers injured, killed or unaccounted for.", "$22 million", "severe flooding", "music video on his land.", "Lindsey oil refinery in eastern England.", "\"Watchmen\"", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Rany Freeman,", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain", "women.", "longest domestic relay in Olympic history,", "Zimbabwe's dire economic situation.", "No. 1", "nine", "Four bodies", "Friday", "The tower will be built in the Saudi town of Jeddah and will be part of a larger project that will cost $26.7 billion, (100 billion Saudi riyals)", "Rima Fakih", "Tuesday night", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "researchers have developed technology that makes it possible to use thoughts to operate a computer, maneuver a wheelchair or even use Twitter", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning", "84-year-old", "Robert Park", "Fakih", "Isthmus of Corinth", "Nalini Negi", "( 2017 - 12 - 10 )", "Runcorn", "collarbone", "horiz\u014dn kyklos", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "the Quiz"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6390772493208994}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.20000000000000004, 1.0, 1.0, 0.11764705882352941, 0.8235294117647058, 1.0, 0.5, 0.19999999999999998, 0.967741935483871, 1.0, 0.6086956521739131, 1.0, 1.0, 0.5714285714285715, 0.4444444444444444, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.484375, "CSR": 0.5849184782608696, "EFR": 0.9090909090909091, "Overall": 0.7470046936758894}, {"timecode": 23, "before_eval_results": {"predictions": ["help red algae catch more sunlight in deep water", "scientific data, tools, photographs, valued at $50,000\u2014was lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma.", "56", "Yemen", "2005", "Karen Floyd", "Four Americans", "the two bodies out of the plant, which makes Slim Jim food products.", "Haiti", "Susan Boyle", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy", "Hyundai", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over.", "threatening messages", "if she would try to travel to Japan for summer vacation.", "citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "\"in the interest of justice.\"", "martial arts, which he taught upon his return to India before becoming a male model.", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "then-Sen. Obama", "Congress", "curfew", "Anne Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "the queen's \"official\" birthday.", "The alleged surviving attacker from last month's Mumbai terror attacks is seeking help from Pakistani officials, India", "Zuma", "haute, bandeau-style little numbers", "five", "Iraq", "September 11, 2001", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed", "Desmond Tutu", "$530 million", "Apple", "$81,88010", "provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "a transformiation, change of mind, repentance, and atonement", "Jason Lee", "stage of sleep during which dreams occur,", "nouns which can occur with articles and attributive adjectives and can function as the head of a noun phrase.", "Kent", "beer and soft drinks", "five", "Cherokee River", "Snowball", "a former NASA astronaut and a retired captain in the United States Navy,", "Florida"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5574382307369831}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 0.72, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.625, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.56, 0.08333333333333333, 0.5, 0.0, 0.25, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.0, 0.058823529411764705, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.9787234042553191, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_squad-validation-1506", "mrqa_squad-validation-10100", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-1876", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.453125, "CSR": 0.5794270833333333, "EFR": 0.9428571428571428, "Overall": 0.761142113095238}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "American Lindsey Vonn", "one of the shocks of the year on Sunday by defeating favorite Venus Williams in straight sets to win the final of the Madrid Open.", "him to step down as majority leader.", "EU naval force", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offset,", "The Louvre", "club", "cars are older than the industry average, with 88 percent born before 1946, according to Auto Pacific data.", "1979", "Heshmat Tehran Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies,", "Bangladesh", "technology experts Michael Arrington, founder and former editor of Tech Crunch, and Vivek Wadhwa,", "one out of every 17 children under 3 years old in America", "President Sheikh Sharif Sheikh Ahmed", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent.", "military personnel", "behind the counter.", "11 healthy eggs and, this week, all 11 of them hatched", "one Iraqi soldier,", "Michael Partain,", "her fianc\u00e9,", "racial intolerance.", "all animal products.", "Vicente Carrillo Leyva, a leader of the Carrillo Fuentes drug cartel,", "Symbionese Liberation Army", "$8.8 million", "work together to stabilize Somalia and cooperate in security and military operations.", "compromise the public broadcaster's appearance of unbiasedity.", "black is beautiful", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "Kabul forces in destroying drug labs, markets and convoys,\"", "provides nearly $162 billion in war funding without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "along the Red Line just before 5 p.m. Monday on an above-ground track in the District of Columbia near Takoma Park, Maryland.", "27 Awa", "Mark Obama Ndesandjo", "\"Dance Your Ass Off.\"", "famous faces like NHL hockey star Alexander Ovechkin, Russian Vogue editor in chief Alinda Doletskaya, acclaimed conductor Valery Gergiev, the \"Russian Madonna\" singer Valeriya, and London-based", "\"The Screening Room\"", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "Vienna", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Walt Disney World Resort in Lake Buena Vista, Florida", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5612215730552128}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.5, 0.0, 1.0, 0.4, 1.0, 0.8, 1.0, 0.25, 0.23529411764705882, 0.33333333333333337, 0.05555555555555555, 1.0, 0.0, 0.8, 0.16666666666666669, 0.5, 1.0, 0.0, 1.0, 0.8, 0.5, 1.0, 1.0, 0.15384615384615385, 0.0, 1.0, 0.0, 1.0, 0.09999999999999999, 0.375, 1.0, 0.0, 0.0, 0.4, 0.5, 0.4, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1728", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3304", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.40625, "CSR": 0.5725, "EFR": 0.9210526315789473, "Overall": 0.7467763157894737}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "1752 Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "beetle", "Arthropods", "Ub Iwerks", "England Cathedrals", "holography", "Pelias", "Sarah Collins", "Northumbria", "Harvard", "cricketer", "Seymour Hersh,", "quant pole", "copper and zinc", "Tigris", "Cordelia", "pamphlets, posters, ballads", "pityriasis capitis", "50", "a Rh\u00f4ne Grape Varietal Grown at Tablas Creek Vineyard", "Joseph Smith,", "Huntington Beach, California", "palladium", "moon", "13", "petticoat", "The Virgin Spring", "Canada", "Winston Churchill", "Stockholm", "Peter Parker", "Goldie Myerson,", "Irena Prikryl", "bullfight", "Sparks", "Ginger Rogers", "Plymouth Rock", "Comedy Playhouse", "citric", "Charles Darwin", "John", "Mrs. Boddy", "Marie Van Brittan Brown", "Southern California Timing Association ( SCTA )", "1995", "Bourbon", "Taylor Swift", "\"Home\"", "\"The three gunshot wounds to the head included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "The Detroit, Michigan, radio station promotion held three years ago was like a class to help women \" learn how to dance and feel sexy,\"", "Amy Bishop", "calathus", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5726516468656427}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, false, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.0, 0.1764705882352941, 0.4827586206896552, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-7521", "mrqa_naturalquestions-validation-1399", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.46875, "CSR": 0.5685096153846154, "EFR": 0.8235294117647058, "Overall": 0.6960195135746606}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Space Museum\"", "number eight", "affordable housing", "Mao Zedong", "Verona", "New York studio", "elephant", "a charcoal powered grill, stove or hot plate", "Frank McCourt", "Harry Burton", "j Judy Cassab", "Margo Leadbetter", "Schengen Area", "A", "city of Sheffield, England", "Famous Players-Lasky Corporation", "the Monkees", "Gerald Durrell", "Jezebel", "County Cork", "jason", "Arabian", "Halifax", "Noises Off", "jason stanley", "Frank Wilson", "Carlos the Jackal", "Edwina Currie", "julian julia Lipnitskaya", "Robert Maxwell", "1917", "For Gallantry", "Tuesday", "Caucasus", "Cahaba", "The Good Life", "Tahrir Square", "uranium", "Count de La F\u00e8re", "27", "Jack Ruby", "tintoretto", "Eric Coates", "Saudi Arabia", "Lester", "Thailand", "Sydney", "a dove", "Tunisia", "Prince Philip", "Apsley House", "Tokyo", "Edgar Lungu", "49 cents", "heart rate that exceeds the normal resting rate", "672", "\"Linda McCartney's Life in Photography\",", "The Frost Place Advanced Seminar", "keystroke", "Juan Martin Del Potro.", "27", "Edgar Allan Poe", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.484375, "QA-F1": 0.528125}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8026", "mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-2797", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-208", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.484375, "CSR": 0.5653935185185186, "EFR": 0.9393939393939394, "Overall": 0.752393728956229}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "70", "forced Tesla out leaving him penniless.", "Benazir Bhutto", "Iran's nuclear program.", "at least 27 Awa Indians", "(l-r)", "FBI Special Agent Daniel Cain", "acid attack", "Wally", "2008", "after Wood went missing off Catalina Island, near the California coast,", "Rima Fakih", "Afghanistan", "The Everglades, known as the River of Grass,", "made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27-year-old", "Alexandros Grigoropoulos,", "$163 million (180 million Swiss francs)", "baggage from the 80s and has grown beyond a resort town into something more substantial.", "around 3.5 percent of global greenhouse emissions.", "Ensenada, Mexico", "Orbiting Carbon Observatory", "Switzerland", "Kenneth Cole", "Janet and La Toya", "more than 22 million people in sub-Saharan Africa", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "he's burned badly on the backs of his knees and every time he moves his knee, it pulls, and it cracks,", "al-Shabaab", "posting a $1,725 bail,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "Opryland complex.", "Number Ones", "only normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "Obama", "\"gotten the balance right\"", "oceans", "stomized him with a broomstick, a pair of scissors and a wooden dowel", "doctors", "off the coast of Dubai", "Bill Haas", "Oona Castilla Chaplin", "1932", "1925", "Gilda", "jeremy dryden", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Disraeli", "a rising sun"], "metric_results": {"EM": 0.5, "QA-F1": 0.6104104662698413}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, true, true, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.4, 0.8, 0.25, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.125, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.6, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-15354"], "SR": 0.5, "CSR": 0.5630580357142857, "EFR": 0.90625, "Overall": 0.7346540178571428}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai", "Monday night", "Bailey, Colorado", "hopes the journalists and the flight crew will be freed,", "40", "Illuminati", "in a public housing project,", "toxic smoke from burn pits", "Lucky Dube,", "two Israeli soldiers,", "space shuttle Discovery", "Gavin de Becker", "building a nuclear weapon", "in Japan", "Arizona", "between South America and Africa.", "Tetris", "outside influences in next month's run-off election,", "aid to Gaza,", "flipped and landed on its right side,", "suppress the memories and to live as normal a life as possible;", "Tuesday in Los Angeles.", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "the area was sealed off, so they did not know casualty figures.", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "Cash for Clunkers program", "\"project work\"", "\"Oprah: A Biography,\"", "80 percent", "London's 20,000-capacity O2 Arena.", "try to make life a little easier for these families by organizing the distribution of wheelchair, donated and paid for by his charity, Wheelchair for Iraqi Kids.", "Ozzy Osbourne", "$50", "Australian officials", "Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "At least 38", "Argentina", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "17 Again", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off, so they did not know casualty figures.", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "ocular choruses", "Fifth", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6229308556625368}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.42857142857142855, 0.8571428571428571, 0.0, 1.0, 0.5714285714285715, 0.0, 0.20689655172413793, 1.0, 1.0, 1.0, 0.9090909090909091, 0.4444444444444445, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-725", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.46875, "CSR": 0.5598060344827587, "EFR": 0.8529411764705882, "Overall": 0.7063736054766734}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "sex organs", "the Russian army", "diffuse nebulae", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "Iran", "maintenance utility", "July 4, 1776", "pick yourself up and dust yourself off and keep going '", "John Garfield as Al Schmid", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "Cadillac", "Brenda", "ranking used in combat sports, such as boxing or mixed martial arts, of who the better fighters are relative to their weight", "Husrev Pasha", "Stephanie Judith Tanner", "ulnar collateral ligament of elbow joint", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii et Spiritus Sancti", "al - Khulaf\u0101\u02beu ar - R\u0101shid\u016bn", "Lake Powell", "ornament", "September 6, 2019", "population", "substitute good", "Marries", "74", "1987", "cunnilingus", "October 2000", "New York City", "Mamata Banerjee", "economy", "in sequence with each heartbeat", "Hermann Ebbinghaus", "Marvin Gaye", "used their knowledge of Native American languages as a basis to transmit coded messages", "Donny Osmond", "Rome and Carthage", "George", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "the two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Russia", "\"Harold & Kumar Go to White Castle\""], "metric_results": {"EM": 0.390625, "QA-F1": 0.5369218993410804}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, false, true, false, true, false, true, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3076923076923077, 0.5, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.7142857142857143, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.25, 0.5, 0.5, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.20689655172413793, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.2857142857142857]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-5753"], "SR": 0.390625, "CSR": 0.5541666666666667, "EFR": 0.7948717948717948, "Overall": 0.6745192307692307}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "pioneers.", "Hutter", "shoes.", "nine", "Rashid Akmaev,", "acetylene", "\"being obscure\" may mean going through your daily life without calling... Don't dress, behave or speak in ways that aren't considered \"ordinary\"", "fiber.", "red deer", "a rose", "Winston Rodney", "sand", "Nanjing", "Montana", "John Cleese", "the Sun", "GILBERT & SullIVAN", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon.", "fibreboard", "tin", "Tordis and Toralv Maurstad", "Frida Kahlo", "son of John and Abigail Adams, served as the sixth President of the United States from 1825 to 1829.", "\"Y\" 2 \"K\": An Eskimo", "Fat man", "Hair", "William Randolph Hearst", "pumice", "a brown", "Hominidae", "dingy", "a song performed by English pop punk band Busted", "Luther", "\"The New Colossus\"", "yelped", "Richard Wagner", "Princess Beatrice of York", "Braddock", "the middleweight champion,", "bronchodilators", "Forty", "Argon Glow Lamps", "Red", "in a Chenard... their way to victory, covering almost 1373 miles, for an average of 57.21 mph.", "Earl Long", "Neil Patrick Harris", "Wyatt and Dylan Walters", "1999", "vitamin D", "five", "Alberto juantorena", "Boyz II Men", "Awake", "Doctor of Philosophy", "Pakistan", "in Seoul.", "Sonia Sotomayor"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4385416666666667}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_triviaqa-validation-7493", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.421875, "CSR": 0.5498991935483871, "EFR": 0.972972972972973, "Overall": 0.7614360832606801}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the macula", "the volume", "a crossword puzzle clue", "Breakfast at Tiffany's", "Diners' Club Card", "Christian Dior", "The Pittsburgh Cycle", "Juliet", "Notre Dame", "Table Mountain", "Tate", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "a sandwich", "a deck", "kozo", "Tenzing Norgay", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Kate Middleton", "Ugly Betty", "R", "Zechariah", "New Jersey", "Lake Ontario", "Matt LeBlanc", "Baltimore", "John Ford", "kismet", "the Chocolate Factory", "artillery", "aluminum", "General McClellan", "Ned Kelly", "an assemblage", "gravitational force", "Isis", "a quiver", "Heroes", "on the two tablets", "organ transplant of a kidney into a patient with end - stage renal disease", "seven units", "Dr. A.G. Ekstrand,", "Duke Ellington", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "February 20, 1978", "two years", "Arsene Wenger", "as time goes on, it kind of becomes more and more of a phenomenon.\""], "metric_results": {"EM": 0.5, "QA-F1": 0.5802083333333332}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16496", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-8269", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-1379", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-10526", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-114", "mrqa_newsqa-validation-2123"], "SR": 0.5, "CSR": 0.54833984375, "EFR": 0.9375, "Overall": 0.742919921875}, {"timecode": 32, "before_eval_results": {"predictions": ["the same as the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "the Black Death", "Kenneth Dwight", "John Stuart Mill", "Herman Melville", "CIA", "piano", "Rickey Henderson", "Indira Priyadarshini Gandhi", "Daucus", "John Grunsfeld", "Llados", "1976", "Galileo Descartes", "a baryon", "The Thomas Berryman Number", "Rudy Giuliani,", "the Free Speech Clause", "Virginia", "Sif", "New Jersey", "The Omega Man", "a walk-in pantry", "a flatheads", "the 1984 Summer Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Ashley Davenport", "Los Angeles", "Zephyrus", "King Edward", "the policies", "pen", "Croatia", "Douglas Adams", "Celso Santebanes", "Hawaii", "Stephen Crane", "Prussia", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "Alice", "Part 2", "Coconut Cove", "a piano-like keyboard", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "ZZ Top", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.53125, "QA-F1": 0.608358134920635}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, false, true, false, true, false, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-9313", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767"], "SR": 0.53125, "CSR": 0.5478219696969697, "EFR": 0.9333333333333333, "Overall": 0.7405776515151515}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "pathogens, an allograft", "a large concrete block is next to his shoulder, with shattered pieces of it around him. Blood trickles down the road.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "\"I think she's wacko.\"", "the annual White House Correspondents' Association dinner", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "Hundreds of women protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license,", "Arkansas", "Cash for Clunkers", "environmental", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers,", "different women coping with breast cancer in", "a missile", "Police", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space, allowing for such features as a full garden and pool, a tennis court, or several heli-pads.", "CNN", "no chance", "SSM Cardinal Glennon Children's Medical Center", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "The portrait of William Shakespeare", "Symbionese Liberation Army", "he acted in self defense in punching businessman Marcus McGhee.", "two tickets to Italy on Expedia.", "Colombia", "in-cabin lighting system", "unwanted horses", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1,", "Appathurai", "$40 and a bread.", "Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15", "November 5, 2013", "Javier Bardem", "Scotland", "in a family of Portuguese descent", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "Spokescandy", "The Star-Spangled Banner"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7009104304600628}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 0.5, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.888888888888889, 1.0, 1.0, 0.4, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 0.7499999999999999, 0.4444444444444445, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.59375, "CSR": 0.5491727941176471, "EFR": 0.9230769230769231, "Overall": 0.736124858597285}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "union members; Philadelphia is a union city,\"", "nuclear site,", "Yemen", "creditors going out of business for one reason or another,", "nearly $2 billion in stimulus funds", "a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spaniard Carlos Moya", "Bahrain", "children of street cleaners and firefighters.", "Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers,", "Honduras", "Brazil", "environmental", "strife in Somalia,", "Roy", "WBO welterweight title", "relatives of the five suspects,", "Meredith Kercher.", "former U.S. soldier Steven Green exhibited clear symptoms of acute stress disorder in Iraq and that a military psychiatric nurse-practitioner failed to diagnose the troubled infantryman and pull him out of combat.", "Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "cancerous tumor.", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "model of sustainability.", "glamour and hedonism", "a $158 green skirt and $298 bead and rhinestone cardigan", "Department of Homeland Security Secretary Janet Napolitano", "543", "The patient, who prefers to be anonymous,", "Robert Gates", "Israel", "on 112 acres about 30 miles southwest of Nashville,", "in critical condition", "Seoul,", "Nicole", "holding the Olympic medal she and her mom always wanted,", "next week.", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "Her husband and attorney, James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1754", "Black Elk", "The Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6118473800505051}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, false, false, true, false, true, true, false, false, false, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.5, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.5, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.16, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_searchqa-validation-7879"], "SR": 0.515625, "CSR": 0.5482142857142858, "EFR": 0.7096774193548387, "Overall": 0.6289458525345623}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position.", "Canada", "Malibu", "Sisyphus", "measure of sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Caliban", "pizzazz", "the Aegean Sea", "the Battle of the Little Bighorn", "Shakers", "a bellwether", "Time and Free Will", "chips", "Boxer", "The Spooderwick Chronicles", "Florence Mabel Harding", "Las Vegas", "the process of choosing actors & assigning parts", "the Rose Bowl", "Norman Rockwell", "short cropped", "light tunais", "Napa", "Italy", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Sadat", "a sundae", "Grace Evans", "50 million cells per litre (quart)", "Volitan Lionfish", "Charlie Sheen", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "a pop ballad", "Seth", "Lou Gehrig", "meaning and origin.", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.484375, "QA-F1": 0.6088541666666667}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-1389", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-13067", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.484375, "CSR": 0.5464409722222222, "EFR": 0.9696969696969697, "Overall": 0.758068970959596}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "a scallop", "nothing gained", "silver", "Supernanny", "the Atlantic", "Cincinnati", "a mosque", "Henry Hudson", "the Peashooter", "dry ice", "Elihu Root", "Entourage", "eels", "Philadelphia", "The Museum of Modern Art", "the unicorns", "(John C.) Fremont", "Russia", "(Barbara) STREISAND", "Hermann Hesse", "the Taj Mittal", "English Monarchs", "the Toreador Song", "Margaret Mitchell", "Frollo", "Sultans of Swing", "Pandarus", "(a gloomy landscape)", "Burt Reynolds", "the Sphinx", "Louis Armstrong", "Saudi Arabia", "American new wave band", "Arby's", "coffee", "The Lgion", "Robert Burns", "The Incredible Hulk", "Winnipeg", "the Memphis Belle", "Burkina Faso", "the Central Pacific", "Attorney General", "Icelandic", "a bison", "The Interruption", "Piaf", "Ivan III", "a prologue", "clay", "investor couple", "Jack Gleeson", "Phil Hurtt", "animals", "Massachusetts", "Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "17 Again"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6573660714285714}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-14520", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-1409", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_hotpotqa-validation-2162", "mrqa_newsqa-validation-3951"], "SR": 0.59375, "CSR": 0.5477195945945945, "EFR": 0.8846153846153846, "Overall": 0.7161674896049895}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "impressionist", "John Y. Brown Jr.", "oats", "Romney", "Ivan the Terrible", "Mary", "1927", "Egypt", "pi", "tin", "Lake Maurapas", "Clark Griswold", "w", "Marriott International", "France", "Canada", "The Secret", "gold", "collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Gulf of Mexico", "Austin", "Euclid", "Eva Peron", "Cain", "Ed Asner", "X-Men", "the Louvre", "coho salmon", "Prison Break", "Mars", "Maine", "a sheep's milk cheese", "Meg", "Modersohn-Becker", "deuce", "Hans Christian Andersen", "Peter Bogdanovich", "Billy Joel", "Jesus Christ Superstar", "BOAT PROPULSION", "the Quaternary Period", "nolo contendere", "Jr. Walker", "Czech Republic", "Chicken of the Sea", "NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"The Disaster Artist\"", "Australian", "the sins of the members of the church,", "$22 million", "\"State of Play\"", "Nelson"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7145833333333333}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5244", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-12168", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_newsqa-validation-1527", "mrqa_hotpotqa-validation-5774"], "SR": 0.640625, "CSR": 0.5501644736842105, "EFR": 0.8695652173913043, "Overall": 0.7098648455377574}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospira", "recession", "a mermaid", "Jay Silverheels", "Singapore", "a tank", "marimba", "a canoe", "Forting Sarah Marshall", "Witness", "Jack the Ripper", "3900", "Alan Shore", "taxonomy", "Spain", "the brain", "Francesco Schettino", "Macbeth", "comedy", "Mary Poppins", "Casowasco", "Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "a second marriage", "Livin' On A Prayer", "Sherlock Holmes", "a licorice", "Marie Antoinette", "Ford", "Marie Curie", "Roger Brooke Taney", "a slope", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "The Queen of Spades", "nickel", "forests", "Olympia", "Waylon Jennings", "Lawrence", "Brazil", "British Columbia", "Platoon", "a scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "the different levels of importance of human psychological and physical needs", "one", "Norfolk Island", "Wright brothers", "sexual activity", "Sam tick", "Sandro Bondi refused to attend", "voluntary homicide", "\"deep sorrow\" at the death of two women killed in a stampede at one of his events in Angola", "Pygmalion"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6417467948717949}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.1, 0.5, 0.8717948717948718, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-4043", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.5625, "CSR": 0.5504807692307692, "EFR": 0.9285714285714286, "Overall": 0.7395260989010989}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "Wikis", "the Fall of Constantinople", "Independence", "Jefferson", "Ford", "the Orinoco River", "a q-tip", "California", "Dixie", "The RAND Corporation", "Warren Harding", "engrave", "Costar", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "conformation dog shows", "Ratatouille", "circadian rhythms", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "26", "Prince", "a bird's foot", "chess", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Tara", "March 15, 1945", "Charles Darwin", "Old Trafford", "Spider-Man", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer", "Bob Dole", "a pair of Mathematics geniuses.", "managing his time"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6227678571428572}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-15434", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.546875, "CSR": 0.550390625, "EFR": 0.9310344827586207, "Overall": 0.7407125538793103}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "South Korean horror film", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "Yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133,", "The Andy Williams Christmas Album", "Tsavo East National Park", "New York Islanders", "Algirdas", "nearly 80 years", "Jean Acker", "the Premier League", "The Gettysburg Address", "most awarded female act of all-time.", "Premier League club Manchester United and the England national team.", "The Rite of Spring", "1", "26,000", "Kristin Scott Thomas", "Mayor Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "a prototype of the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard ( born 7 March 1963 ), known by her pen name E.L. James,", "Mase Dinehart", "Tevye", "Sir Tom Finney", "Cameroon", "obtaining and proper handling of human blood.", "exposure by military personnel to hazardous materials in the United States, Japan and Iraq, including toxic smoke from burn pits in Iraq and contaminated water.", "two", "Iggy Pop invented punk rock.", "a riddle", "a man", "Leonardo DiCaprio", "a pathological ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6871527777777778}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.22222222222222224, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_naturalquestions-validation-6326"], "SR": 0.59375, "CSR": 0.5514481707317074, "EFR": 1.0, "Overall": 0.7757240853658537}, {"timecode": 41, "before_eval_results": {"predictions": ["a interception", "10", "did not identify any of the dead.", "Les Bleus", "2005", "more than 4,000", "the club's board", "an angry mob.", "normal maritime", "Sri Lanka", "her fetus were found beneath in a fire pit January 11 in Marine Cpl. Cesar Laurean's backyard.", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as", "piano", "$250,000", "a \"prostitute\"", "the skull", "tax", "Los Ticos", "acute stress disorder", "Russia", "Facebook and Google,", "through a facility in Salt Lake City, Utah", "Manmohan Singh", "Haiti", "Tuesday afternoon", "Pakistan", "23 years.", "a head injury.", "Tim Cahill", "an open window", "Leo Frank", "Paul McCartney", "off Haiti's coast", "President Robert Mugabe", "don't have to visit laundromats", "three", "Diversity", "on-loan David Beckham claimed his first goal in Italian football.", "his son is fighting an unjust war for an America that went too far when it invaded Iraq", "Twilight", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died,", "Fayetteville, North Carolina,", "the plane had a crew of 14 people and was carrying an additional 98 passengers,", "the Taliban", "Secretary of State Hillary Clinton", "Rihanna", "angular rotation", "from the right side of the heart to the lungs", "54 Mbit / s", "Gloucestershire", "the B-24 Liberator", "cereal", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "Department of Transportation"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6866595643939394}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 0.7272727272727273, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.625, 1.0, 1.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.8571428571428571, 0.21428571428571427, 1.0, 0.5714285714285715, 1.0, 1.0, 0.7272727272727273, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376"], "SR": 0.5625, "CSR": 0.5517113095238095, "EFR": 0.8214285714285714, "Overall": 0.6865699404761905}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Chinese", "Zimbabwe", "Italian Serie A title", "Darrel Mohler", "dancing against a stripper's pole.", "Michoacan Family,", "WTA Tour titles", "Morgan Tsvangirai.", "42", "takes on the swords of the Taliban.", "some great travel spots to be altered or ruined by global climate change.", "80 percent of a woman's face", "1979", "\"Follow the Sun,\"", "Elena Kagan", "CBS, CNN, Fox and The Associated Press.", "an auxiliary lock", "1-1", "AbdulMutallab", "Myanmar", "Collier County Sheriff Kevin Rambosk", "Marcus Schrenker,", "Abu Sayyaf,", "poems", "the program was made with the parents' full consent.", "Senator. Barack Obama", "The Red Cross, UNHCR and UNICEF", "Russia", "debris", "Steven Gerrard was cleared by a court in Liverpool of affray.", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award", "state senators", "31 meters (102 feet)", "its nude beaches.", "how preachy and awkward cancer movies can get.", "a Florida girl who disappeared in February,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill.", "\"theoretically\"", "1940's", "March 22,", "celebrity pontificating about the plight of the environment", "at a depth of about 1,300 meters in the Mediterranean Sea.", "Antichrist", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Rigel", "brown", "Selfie", "2002", "South Australia", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.609375, "QA-F1": 0.701187193627451}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.11764705882352941, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5333333333333333, 0.4, 0.4, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.12500000000000003, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_triviaqa-validation-1492", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.609375, "CSR": 0.5530523255813953, "EFR": 0.84, "Overall": 0.6965261627906976}, {"timecode": 43, "before_eval_results": {"predictions": ["north,", "legitimacy of that race.", "88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "\"The U.S. subcontributed out an assassination program against al Qaeda... in early 2006.\"", "hardship for terminally ill patients and their caregivers,", "Araceli Valencia,", "Zac Efron", "finance", "nearly $2 billion", "The National Infrastructure Program,", "After the war,", "The station", "Krishna Rajaram,", "The Arkansas weatherman", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Afghanistan's Helmand province,", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "could be secretly working on a nuclear weapon", "the fact that the teens were charged as adults.", "death squad killings carried out during his rule in the 1990s,", "Elena Kagan", "Dangjin", "100 percent", "Saturday", "Afghanistan,", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole", "a Muslim with Lebanese heritage,", "South Africa,", "Barack Obama", "helicopters and unmanned aerial vehicles", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "a receptionist with a gunshot wound in her stomach", "$50 less", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960 Summer Olympics in Rome", "Aston Villa", "peasants, small and medium-size farmers, landless people, women farmers, indigenous people, migrants and agricultural workers", "pool", "1822", "The Dressmaker", "Trilochanapala", "rubiks", "a buffalo", "ruby slippers", "the sulcus"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6521585468426501}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.08695652173913043, 1.0, 0.9523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 0.33333333333333337, 0.5, 0.125, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-5351", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.5625, "CSR": 0.5532670454545454, "EFR": 0.8928571428571429, "Overall": 0.7230620941558441}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Christopher Livingstone \" Chris\" Eubank Jr.", "Duval County", "Benj Pasek and Justin Paul,", "Andes", "1952", "Soyo  Soyo (formerly known as Santo Ant\u00f3nio do Zaire)", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Atlanta Athletic Club", "Franconia, New Hampshire,", "Operation Watchtower", "Dan Crow", "War & Peace", "Amberley Village", "What Are Little Boys Made Of?", "Berea College", "the Chicago Bears", "Luca Guadagnino", "Liesl", "Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown", "jus sanguinis", "Radcliffe College", "Charles Guiteau", "Ford Motor Company", "If the citizen's heart was heavier than a feather they would face torment in a lake of fire.", "India", "Lutheranism", "armed", "25 million", "The Snowman", "Ella Fitzgerald", "X-Men: God Loves, Man Kills", "Rain Man", "Interscope Records", "Robert Grosvenor", "4,000", "Henry Luce", "I'm Shipping Up to Boston", "American", "British singer and \"Britain's Got Talent\" winner Jai McDowall", "central", "Australia's capital is Canberra, and its largest urban area is Sydney", "beginning of the American colonies", "Nicola Adams", "\"Boesmansrivier\" (Afrikaans for Bushman's river)", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "in a hotel,", "Chaucer", "rattlesnakes", "Riddles in the Dark", "healthy, wealthy, and wise"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6168265716374269}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2105263157894737, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.10526315789473684, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-2355", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986"], "SR": 0.5625, "CSR": 0.5534722222222221, "EFR": 0.7857142857142857, "Overall": 0.6695932539682539}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "the Gulf of Aden.", "30", "crocodile eggs", "Colorado prosecutor", "Jason Chaffetz", "the annual White House Correspondents' Association dinner", "in Haiti", "in July for A Country Christmas, and the festivities run from mid-November until the holidays end.", "to slip phones into the prison and hide them.", "the shoreline of the city of Quebradillas.", "Herman Cain", "\"17 Again,\"", "does not believe North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie", "Heshmatollah Attarzadeh", "the ireport form", "the government", "Nine out of 10 children", "Phoenix, Arizona, police", "Sen. Joe Lieberman, I-Connecticut,", "the jaws of a crocodile", "a bronze medal in the women's figure skating final,", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families, when the service members are in uniform and traveling on orders.", "Phillip A. Myers.", "Obama's", "King Birendra,", "the cause of the child's death will be listed as homicide by undetermined means,", "Casey Anthony,", "officers at a Texas  airport", "10 municipal police officers", "UNICEF", "the couple's surrogate", "228", "Kerstin and two of her brothers, ages 18 and 5,", "the first near-total face transplant in the United States,", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Arsene Wenger", "slavery", "Kat ( Jesse Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ), and grandmother Mo ( Laila Morse )", "Latin liberalia studia", "Enid Blyton", "Johnny Mathis", "Eddie Murphy's", "Champion Jockey", "Luca Guadagnino", "Freddie Jackson", "unknown", "timing shapes and supports brain function", "a shotglass", "a Bristol Box Kite"], "metric_results": {"EM": 0.5, "QA-F1": 0.617523229495841}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.14285714285714288, 0.16666666666666666, 0.0, 1.0, 1.0, 0.8695652173913044, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-691", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.5, "CSR": 0.5523097826086957, "EFR": 0.9375, "Overall": 0.7449048913043479}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "can vote online, via phone calls or by text messaging, and those votes comprise 50 percent of each couple's score.", "the Orange County District Attorney's Office.", "12.3 million", "Mexico", "Argentine", "Vivek Wadhwa,", "Brett", "eight Indian army troopers, including one officer, and 17 militants,", "Saturday", "Nicole", "legitimacy of that race.", "Adidas,", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "promise to improve health and beauty.", "Chinese", "Newcastle", "Nothing But Love", "allegedly involved in forged credit cards and identity theft", "June 6, 1944,", "[Middle East and North Africa]", "twice", "October 19,", "\"I sincerely apologize to Tiger and anyone else I have offended.\"", "Seoul,", "promotes fuel economy and safety while boosts the economy.", "ALS6", "eight", "Siri", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback Forestry in Medford, Oregon,", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "students", "two Israeli soldiers,", "the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "a turtle", "Japan", "fox hunting", "New York", "travel", "16,116", "smoke", "sugar", "a bumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.640625, "QA-F1": 0.698034821081696}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.8, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.12500000000000003, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615388, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3956", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_triviaqa-validation-1729", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573"], "SR": 0.640625, "CSR": 0.554188829787234, "EFR": 0.8695652173913043, "Overall": 0.7118770235892692}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "\"Parachutes\"", "5", "Chicago", "The One Who Walk Away from Omelas", "child actor", "Dennis H. Kux", "drawing the name out of a hat.", "Brett Ryan Eldredge", "I-League", "two or three", "Badfinger", "Lady Frederick Windsor", "point-coloration pattern", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1946 and 1947", "5,112", "1992", "many artists' lofts and art galleries, but is now better known for its variety of shops ranging from upscale upscale boutiques to national and international chain store outlets.", "143,372", "6'5\" and 190 pounds", "Mickey Gilley's", "Switzerland\u2013European Union relations", "a puppy", "Mexican", "December 24, 1973", "1933", "the backside", "Ulver and the Troms\u00f8 Chamber Orchestra", "1730", "London", "the Salzburg Festival", "Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "Messiah Part II", "Boston", "lion", "Royal", "World War II", "Knoxville, Tennessee", "\"Three's Company\"", "P.O.S,", "Labour", "\"Linda McCartney's Life in Photography\", \"Some Like It Hot\", \"Kubrick's Napoleon: The Greatest Movie Never Made\", \"Saturday Night Live: The Book\",", "English", "September 14, 2008", "79", "Buffalo Bill", "Romania", "Zephyr, Billy Cobham, Alphonse Mouzon, the James Gang, Deep Purple, and Moxy.", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces at the site.", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "halls", "Bank of England"], "metric_results": {"EM": 0.546875, "QA-F1": 0.688426243894994}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, false, true, false, true, true, false, false, false], "QA-F1": [0.8, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.13333333333333333, 1.0, 0.4, 0.5, 0.4444444444444444, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4166666666666667, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3076923076923077, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5349", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-5531", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.546875, "CSR": 0.5540364583333333, "EFR": 0.8275862068965517, "Overall": 0.6908113326149425}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "ryegrass", "offensive", "Vulcan", "the Pilgrims", "Fawn Hall", "waive", "Shakespearean Heroines", "Barnum & Bailey Circus", "Johnny Weissmuller", "cathode", "Torque Wrench", "the California gold rush", "Marlon Brando", "Middle Dutch", "\"Impressionists\"", "the University of Kentucky", "the ruddy", "Brussels", "Macbeth", "General Thomas J. \"Stonewall\" Jackson", "piracy", "Fyodor Dostoevsky", "Martin Luther", "Clue", "Poe", "Norway", "Andrew Johnson", "7", "Mike Connors", "JUNGLE JIM", "Jim Inhofe", "sancire", "Corpus Christi", "Nigeria", "an ostrich", "the United States", "8-hours per day", "mug", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "a frigate", "the Grail", "West Virginia", "James Madison", "movie house", "Renold", "critic", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambidevous", "chariots", "Humberside Airport", "265 million", "100 million", "help rebuild the nation's highways, bridges and other public-use facilities.", "a head injury.", "Pope Benedict XVI refused Wednesday to soften the Vatican's ban on condom use", "Charles II"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5844975490196078}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-11080", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-2811", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.53125, "CSR": 0.5535714285714286, "EFR": 0.9333333333333333, "Overall": 0.743452380952381}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Colorado", "Pammerie Anderson", "carnaval", "Treasure Island", "Pocahontas", "\"Whose Line Is Itchy?\"", "(Whizzer) White", "an octave", "an an inert gas or other activating agent", "Great American Novel", "(Frederick) Emmerich", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "a Clydesdale horse", "(Ernest) Lawrence", "a rodeo", "a fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "the Tudor", "Department of Homeland Security", "the Black Sea", "a leotard", "Bulworth", "a melon", "the mouth", "Cuba", "a pickle", "1975", "scalpels", "Manhattan", "Feb 2, 2016", "Leontyne Price", "a composting material", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "Sarah Jessica Parker", "a spring", "Suriname", "a burnoose", "Philadelphia", "peanut butter", "Invisible Women", "cork", "Alexander \"Lex\" Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "\"Meadowbank II The Sequel", "St Moritz", "October", "Drifting", "Ellesmere Port, United Kingdom", "Sunday evening", "three out of four", "poems telling of the pain and suffering of children just like her", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.421875, "QA-F1": 0.5090277777777779}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-3349", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-15005", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-5787", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-12067", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073"], "SR": 0.421875, "CSR": 0.5509375000000001, "EFR": 0.918918918918919, "Overall": 0.7349282094594596}, {"timecode": 50, "UKR": 0.798828125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.849609375, "KG": 0.5234375, "before_eval_results": {"predictions": ["Fatih Ozmen", "Volvo 850", "Skyscraper", "a Chevy Stingray", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hawaii County", "Robert Downey, Jr.", "Continental AG", "band director", "Germanic", "Anaheim", "Reinhard Heydrich", "the Big Ben clockface", "Standard Oil", "The Longest Yard", "Chiwetel Umeadi Ejiofor", "president of Guggenheim Partners", "19th-century", "Hillary Scott", "WikiLeaks", "the 43rd Vice President of the United States", "Tottenham Hotspur", "October 2016", "Vixen", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine.", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Santa Fe", "propaganda channel", "Adelaide Lightning", "Landing Barge", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "north-northeast of Bologna,", "created the American Land-Grant universities and colleges", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "American", "hamburgers", "Liverpool", "little hairs", "Luigi Segre", "United States House of Representatives", "February 9, 2018", "1980", "Nacio Herb Brown", "Geoff Hurst", "Precambrian", "Mull", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final", "\"The three gunshot wounds included two nonfatal rounds with entry points below the chin, and one fatal shot that entered Peterson through the right side of the head,\"", "an opening is made into the airway through an incision in the neck to allow for suction of fluid out of the lungs.", "Paul Newman", "Puccini", "Steve Martin", "milk and honey"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5465277777777777}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.4, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.1111111111111111, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.13333333333333333, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-712", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2137", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-355", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-13015"], "SR": 0.453125, "CSR": 0.5490196078431373, "EFR": 0.9428571428571428, "Overall": 0.7327503501400561}, {"timecode": 51, "before_eval_results": {"predictions": ["1979", "an Indian", "Chiltern Shakespeare Company", "1898", "Stacey Kent", "1970s", "Arthur Freed", "Elizabeth Kekaikuihala Keka\u02bbaniauokalani Kalaninuiohilaukapu La\u02bbanui Pratt", "Gothic Revival", "Buffalo", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "its air-cushioned sole", "The White Knights of the Ku Klux Klan", "WikiLeaks", "Nine-card Brag", "Montana State University", "Tool", "Wikimedia Foundation", "Flashback: The Quest for Identity", "ARY Films", "1987", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale", "Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "United States", "Sargent Shriver", "35", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Richard Price", "Archie Andrews", "George Lawrence Mikan, Jr.", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "Celtic Sea", "a string of obscure words", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "October 29 and November 5.", "The Baldwin Project", "hunter sauce", "The Quest of Erebor", "carbon"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7347419507575758}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.375, 0.5, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.6875, "CSR": 0.5516826923076923, "EFR": 0.85, "Overall": 0.7147115384615385}, {"timecode": 52, "before_eval_results": {"predictions": ["My ntonia", "King Henry VIII", "lead", "the Rose Bowl", "VC-25", "amber", "Denmark", "terriers", "Katrina & the Waves", "Galilee", "freestyle", "DOG'S", "pornography", "Stargate", "Lou Reed", "Stonewall Jackson", "Fennoscandia", "Emma Peel", "canvas", "petticoat", "The X-Files", "Frankie Muniz", "the undersea world", "Hudson Bay", "Coupvray, France", "kinetic", "Santera", "Starsky and Hutch", "a torch", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "the San Antonio River", "cornucopia", "All That Jazz", "Ankara", "condensation", "be", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Como agua para chocolate", "Niger-Congo", "TGI Fridays", "John Tyler", "Daniel Craig", "humility", "programming", "Isle of Sheppey in England", "A footling breech", "concentration of a compound exceeds its solubility", "Doctor Zhivago", "Bristol", "John Baptiste Le Roy", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1961", "between South America and Africa.", "The clothes we make for the runway", "fake his own death by crashing his private plane into a Florida swamp.", "the Stockton & Darlington Railway"], "metric_results": {"EM": 0.625, "QA-F1": 0.6716889880952381}, "metric_results_detailed": {"EM": [false, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, true, false], "QA-F1": [0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7142857142857143, 0.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-7160", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-9100", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-15002", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-3189", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.625, "CSR": 0.5530660377358491, "EFR": 0.6666666666666666, "Overall": 0.6783215408805031}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen and illustrated by Helen Oxenbury", "Neil Young", "After Shawn's kidnapping", "manage the characteristics of the beer's head", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "birch", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Nicolas Anelka", "season two", "in the sequence of pieces of DNA called genes", "global crowdfunding platform focused on creativity and merchandising", "Most days are sunny throughout the year", "David Motl", "The Portuguese", "Madison, Wisconsin, United States", "September 1972", "2017", "Gustav Bauer", "detritus", "the motion of the continents is linked to seafloor spreading by the theory of plate tectonics", "126", "Brooke Wexler", "John Barry", "1961", "111", "Brazil, Turkey and Uzbekistan", "an even - toed ungulate in the genus Camelus", "13", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "compound sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophia Monk and Eddie Perfect", "Coriolis force", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Daya Jethalal Gada", "over 74", "the words `` speed limit '' omitted and an additional panel stating the type of hazard ahead", "various submucosal membrane sites of the body", "noble gas", "Department of Health and Human Services", "four distinct levels", "Janie Crawford", "Justin Timberlake", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Paul Gauguin", "USA Today serving as its megaphone.", "creeks,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "United Arab Emirates", "the Northwest Territories", "Chayka", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6548768130711534}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, true, false, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true], "QA-F1": [0.4444444444444445, 1.0, 0.0, 0.6666666666666666, 0.8, 0.6666666666666666, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.5, 0.4615384615384615, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.08695652173913043, 0.41379310344827586, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3076923076923077, 0.4444444444444445, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4748", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.515625, "CSR": 0.5523726851851851, "EFR": 0.6774193548387096, "Overall": 0.6803334080047789}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "cumin, introduced by Spanish immigrants to Texas from the Canary Islands and used in Berber cuisine", "Paul McCartney", "Kanawha Rivers", "1803", "heads of federal executive departments who form the Cabinet of the United States", "3000 BC", "a password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "Balthazar changes history in the sixth season episode `` My Heart Will Go On ''", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "elected from the citizens of the jurisdiction in which they serve", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "on May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "The management team", "1999", "supervillains who pose catastrophic challenges to the world", "the courts", "Malvolio", "Beyonc\u00e9", "Arkansas", "the birth centenary of Pandit Jawaharlal Nehru", "Edward Seton", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "Joe Pizzulo", "Secretary of Homeland Security", "cylinder of glass or plastic that runs along the fiber's length", "Transvaginal ultrasonography", "741 weeks", "Zimbabwe", "London", "Hillary Clinton's", "Tampa", "Battle of Prome", "itty Hawk", "John Lennon and George Harrison,", "the ship of violating Chinese and international laws during its patrols,", "a city of romance, of incredible architecture and history.", "Tater Tots", "Yemen", "quod erat demonstrandum", "the Dalton Gang"], "metric_results": {"EM": 0.5, "QA-F1": 0.6231172146889059}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.56, 0.1, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.8, 0.4, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 0.060606060606060615, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5714285714285715, 0.0, 0.8571428571428572, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-3311", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-3099", "mrqa_hotpotqa-validation-2751", "mrqa_newsqa-validation-3310", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-8575"], "SR": 0.5, "CSR": 0.5514204545454545, "EFR": 0.84375, "Overall": 0.7134090909090909}, {"timecode": 55, "before_eval_results": {"predictions": ["the spoiled, bedridden daughter of wealthy businessman James Cotterell ( Ed Begley )", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "In 1967, Celtic became the first British team to win the competition", "the U.S. states of Oregon and Washington", "the Northeast Monsoon", "2013", "American country music group The Nitty Gritty Dirt Band", "land, fresh water, air, rare earth metals and heavy metals including ores such as gold, iron, copper, silver", "an annual income of US $11,770 ; the threshold for a family group of four, including two children, was US $24,250", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "minimum viable product that addresses and solves a problem or need that exists", "London", "Marty J. Walsh", "Hem Chandra Bose", "Ernest Rutherford", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "the sacroiliac joint", "HTTP / 1.1", "Brooklyn, New York", "1 mile ( 1.6 km )", "a pop ballad", "8 December 1985", "during meiosis", "the law was introduced to the New Zealand Parliament as a private members bill by Green Party Member of Parliament Sue Bradford in 2005", "Arnold Schoenberg", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "in the books of Exodus and Deuteronomy", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outside ( skin ) and the inside cavities and lumina of bodies", "2007", "her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "10,605", "Steve Bacic", "Sebastian Vettel", "San Antonio", "Meg Optimus", "Eukarya", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Joe Anne Worley", "Celebrity Big Brother", "Joseph V. Micallef", "James Garner", "Boston, Massachusetts", "Robert Jenrick", "Bob Hurley", "improve the military's suicide-prevention programs.", "five", "\"a fantastic five episodes.\"", "Charles the Bald", "Madonna", "Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6097491118394854}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, true, false, true, true, true, false, false, true, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.21052631578947367, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.08695652173913042, 1.0, 0.7878787878787877, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.0, 0.1290322580645161, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.09523809523809522, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-6540", "mrqa_hotpotqa-validation-4760", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.515625, "CSR": 0.55078125, "EFR": 0.7741935483870968, "Overall": 0.6993699596774194}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "World War II began with its invasion by Nazi Germany on 10 May 1940", "Harishchandra", "16 episodes", "1787", "1999", "Old Trafford", "Tami Lynn", "U + 2234 \u2234 therefore ( HTML & # 8756 ; &there4 ; )", "United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "Dutch", "4 September 1936", "hydrogen and oxygen", "1940", "Authority", "April 1st", "Brobee", "the claims process starts at noon Eastern Time and ends 24 hours later", "Francisco Pizarro", "habitat", "Ben Faulks", "Lady Gaga", "can negatively affect a person's personal, work, or school life, as well as sleeping, eating habits, and general health", "1989", "Liam Cunningham", "Eddie Deezen", "Walter Pauk", "After Margaret Thatcher became Prime Minister in May 1979", "the septum", "Daoism", "the forex market", "`` Singing the Blues '' by Guy Mitchell in 1957", "Sir Ernest Rutherford", "Nigel Lythgoe", "December 2, 2013", "gastrocnemius", "Art Carney", "Thomas Hobbes in his Leviathan", "March 26, 1973", "1986", "on location", "President Lyndon Johnson", "prenatal development of the human heart", "a Christmas Tree", "1840", "2007", "Branson", "first baseman", "Tumi Holdings", "River Shiel", "Ozzy Osbourne", "Polo", "the music label that owns them said Sunday, after days of speculation that they were.", "ego", "Nova Scotia", "Sir Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7028361344537815}, "metric_results_detailed": {"EM": [true, false, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 0.35294117647058826, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.19047619047619047, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4303", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7486", "mrqa_hotpotqa-validation-3278", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-10569"], "SR": 0.609375, "CSR": 0.5518092105263157, "EFR": 0.88, "Overall": 0.7207368421052631}, {"timecode": 57, "before_eval_results": {"predictions": ["Norman occupational surname ( meaning tailor ) in France", "Manchester - by - the - Sea, Massachusetts", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "Casino promotions such as complimentary matchplay vouchers or 2 : 1 blackjack payouts allow the player to acquire an advantage without deviating from basic strategy", "the Infamy Speech of US President Franklin D. Roosevelt", "the coffee shop Monk's", "Fred E. Ahlert", "the original game release", "Ozzie Smith", "Mark Jackson", "2017", "two - year terms", "January 2018", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "September 30", "the ancestral virus, of avian origin, crossed the species boundaries and infected humans as human H1N1", "Gerald Ford", "September 8, 2017", "1998", "political ideology", "Spektor", "an object", "Cell nuclei", "1973", "on Thursdays at 8 : 00 pm ( ET )", "Ren\u00e9 Verdon", "preserves the intervallic relationships of the original scale", "the contestant", "to refer to a god of the Ammonites, as well as Tyrian Melqart and others", "P.V. Sindhu", "Carpenter", "Asuka", "126", "Scorpions", "Brazil", "UNESCO / ILO Recommendation concerning the Status of Teachers", "upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "on an inward spiral where it would eventually cross the event horizon", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "prenatal development", "skeletal muscle and the brain", "American country music duo Brooks & Dunn", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "Irish Chekhov", "Gust Avrakotos", "Jenny Sanford,", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6153396037736552}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false], "QA-F1": [0.0, 1.0, 0.7499999999999999, 0.14285714285714288, 0.07692307692307693, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.21052631578947367, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.06451612903225806, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.9142857142857143, 0.0, 0.9600000000000001, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3, 0.8181818181818181, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-5291", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.515625, "CSR": 0.5511853448275862, "EFR": 0.7741935483870968, "Overall": 0.6994507786429366}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "Idaho", "October 14, 2017", "Exodus and Deuteronomy", "digestion of proteins, by activating digestive enzymes, and making ingested proteins unravel so that digestive enzymes break down the long chains of amino acids", "1979 -- 80 season", "separately in England and Wales", "iron", "the Reverse - Flash", "Los Angeles, California", "the British Empire", "Jaffa Cakes are biscuit - sized cakes introduced by McVitie and Price in the UK in 1927", "the name of a work gang", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "between 1923 and 1925", "the brain and spinal cord", "Seattle, Washington", "in serial format in Collier's Weekly magazine ( 27 January -- 16 April 1898 )", "Yosemite National Park", "Ewan McGregor", "LED illuminated display", "turkey", "1917", "January 2004", "Anna Faris", "smen", "Mount Sinai", "Macon Blair", "the genome", "by each state'sDM, which is required to drive", "France's Legislative Assembly", "four", "divergent tectonic", "Steve Russell", "peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "The 2017 -- 18 UEFA Champions League knockout phase began on 13 February and will end on 26 May 2018", "291", "the early 1960s", "Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "2003", "Zuzu & Zaza Zebra", "dysmenorrhea", "1960", "Justin Trudeau,", "2006", "Walldorf", "superhero roles as the Marvel Comics characters Steve Rogers / Captain America in the Marvel Cinematic Universe and Johnny Storm / Human Torch in \"Fantastic Four\" and.", "crude oil", "Peppermint oil, soluble fiber, and antispasmodic drugs", "the FBI", "a ferry", "Leland Stanford", "Mexico", "Nepal"], "metric_results": {"EM": 0.5, "QA-F1": 0.6597579637423387}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.92, 1.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.125, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.3076923076923077, 0.15384615384615385, 0.0, 0.0, 0.2857142857142857, 0.5, 0.5, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.5945945945945945, 1.0, 0.0, 1.0, 0.19999999999999998, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3571428571428571, 0.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-10561", "mrqa_triviaqa-validation-3434", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98"], "SR": 0.5, "CSR": 0.5503177966101696, "EFR": 0.75, "Overall": 0.6944385593220339}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic -- Biotic resources are obtained from the biosphere ( living and organic material ), such as forests and animals, and the materials that can be obtained from them", "IIII", "`` the ultimate exercise for the bored and lazy ''", "quarterback", "July 2012", "Audrey II", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "by January 2018", "George Strait", "Antarctica's lowest air temperature record was set on 21 July 1983, with \u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F ) at Vostok Station", "Herman Hollerith", "94 by 50 feet", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds, and also in the differential", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "October 1, 2014", "The Miracles", "provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Marie Fredriksson", "Long Island", "1988", "Germany", "Rococo - era France", "Michael Crawford", "Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 3, 1945", "the 1950s", "Maximilien Robespierre", "XXXX", "by the early - to - mid fourth century", "Made a decision to turn our will and our lives over to the care of God as we understood Him", "Leon Battista Alberti", "January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "A diastema ( plural diastemata )", "July 21, 1861", "the Brewster family, descended from the Mayflower, but now composed of insane homicidal madnesss", "Efren Manalang Reyes", "Joker Wild,", "Chicago", "Dijon", "Lucas Stephen Grabeel", "15,024", "model", "the test results by the medical examiner's office, Garavaglia said.", "15-year-old's", "Thursday,", "Vietnam", "a double bass", "Richard", "Son of Sam"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7062312334842576}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, false, false, false, true, false, false, false, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07999999999999999, 0.0, 0.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5161290322580645, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 0.0, 1.0, 0.6153846153846153, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.9090909090909091, 0.2580645161290323, 0.5454545454545454, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-9195", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-3750", "mrqa_naturalquestions-validation-7165", "mrqa_triviaqa-validation-34", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_searchqa-validation-8465"], "SR": 0.609375, "CSR": 0.5513020833333333, "EFR": 0.84, "Overall": 0.7126354166666666}, {"timecode": 60, "before_eval_results": {"predictions": ["a recognized group of people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "1996", "used their knowledge of Native American languages as a basis to transmit coded messages", "Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "writ of certiorari", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "macadamia nuts", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Lorenzo Lamas", "Mahatma Gandhi", "people of the United States", "eighth", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "1990", "James `` Jamie '' Dornan", "the left coronary artery", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Clare Torry", "ummat al - Islamiyah", "Brazil", "Parashara", "Domhnall Gleeson", "Brazil and Paraguay", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "`` Mirror Image ''", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1966", "the alluvial plain", "\"The closest approach to the original sound\"", "Peter Sellers", "Colonel Tom Parker", "Atlantic Ocean", "mistress of the Robes", "Australian Electoral Division", "Conway", "Kurt Cobain's", "\"Empire of the Sun,\"", "Stephen Dedalus", "The Killing Fields", "Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.609375, "QA-F1": 0.7056923024891775}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, false, false, true, true, false, true, true, false], "QA-F1": [0.625, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.5, 1.0, 1.0, 1.0, 0.08000000000000002, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_searchqa-validation-1451", "mrqa_newsqa-validation-1282"], "SR": 0.609375, "CSR": 0.5522540983606558, "EFR": 0.64, "Overall": 0.6728258196721312}, {"timecode": 61, "before_eval_results": {"predictions": ["May 26, 2017", "to form a higher alkane", "Andy Cole and Shearer", "Jason Marsden", "New Mexico", "In 1889", "Poems : Series 1", "William the Conqueror", "March 2, 2016", "July 20, 2017", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "John Donne", "1980s", "David Gahan", "Emma Watson", "legislation ( i.e., `` statutes '' or `` statutory law '' ) consists exclusively of Acts passed by the Congress of the United States and its predecessor, the Continental Congress", "2018", "every year from 6 -- 14 July", "2010", "4.25 inches ( 108 mm )", "Judi Dench", "Japan by Crunchyroll", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "1836", "Thomas Jefferson's", "Elijah Wood", "cat in the hat", "Brad Dourif", "counter clockwise direction", "Joanne Wheatley", "vice president, Speaker of the House of Representatives, President pro tempore of the Senate, and then the heads of federal executive departments who form the Cabinet of the United States", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "the 1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the efferent nerves that directly innervate muscles", "1773", "The First Battle of Bull Run ( the name used by Union forces )", "Kix Brooks", "kippis", "South America", "The Pilgrim's Progress", "Bourbon County", "Argentina, whose president Bartolom\u00e9 Mitre provided him with supplies, Argentine volunteers and river transport for troops.", "Hungary", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6448040182531072}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, false, false, true, false, false, false, true, false, true, true, false, true, true, true, false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, true, false, true, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.24000000000000002, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.17391304347826084, 1.0, 0.6666666666666666, 0.0, 0.7272727272727273, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5714285714285715, 0.0, 1.0, 0.8, 1.0, 0.14814814814814814, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.25, 0.0, 1.0, 0.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-1856", "mrqa_naturalquestions-validation-7147", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-6789", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-2842", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-1887", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.515625, "CSR": 0.5516633064516129, "EFR": 0.8064516129032258, "Overall": 0.7059979838709677}, {"timecode": 62, "before_eval_results": {"predictions": ["1952 in the television series, The Lone Ranger for one season from 1952 until 1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Javier Fern\u00e1ndez", "Tim Russert", "Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples", "toys or doorbell installations", "a microfilament", "in positions Arg15 - Ile16 and produces \u03c0 - Chymotrypsin", "the center of the Northern Hemisphere", "a new mysterious entity arises and begins using Emojis to communicate but later baptizes themselves as `` A.D. ''", "Eduardo", "1868 war veterans, such as Polish internationalist General Carlos Roloff and Seraf\u00edn S\u00e1nchez in Las Villas", "1971", "Leo Arnaud ( / \u02c8le\u026a. o\u028a \u0251\u02d0r \u02c8no\u028a / ; July 24, 1904 -- April 26, 1991", "Emmanuelle Chriqui", "Carlos Alan Autry Jr. ( also known for a period of time as Carlos Brown ; born July 31, 1952 )", "16 March 2018", "Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 ) is an American soul and gospel singer and an actress", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "judges", "1936", "Eric Clapton", "Djokovic", "Abraham Gottlob Werner ( 1749 -- 1817 ) proposed Neptunism, where strata represented deposits from shrinking seas precipitated onto primordial rocks such as granite", "January 1923", "2017", "a scythe", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "Leonard Bernstein", "Toronto, Ontario, Canada", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the fourth season", "Phillip Paley", "1981", "Jakkur, Bangalore, India", "New Orleans going north through Chicago and to New York", "Mesoamerica", "the tax rate paid by a small business", "ecological regions", "White House Executive chef", "the International Border ( IB )", "Bart Millard", "an informal term for mother 1, wife 1", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "heavy metal drummer", "Selden", "Muslims as Americans.", "the day before.", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Chastity", "Mali", "Chief Oshkosh", "River Welland"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5662003437738732}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [0.47058823529411764, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.38095238095238093, 1.0, 0.7272727272727273, 0.25, 0.16666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.3333333333333333, 0.28571428571428575, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-6435", "mrqa_naturalquestions-validation-7744", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-6970", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-9494", "mrqa_triviaqa-validation-7273", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.46875, "CSR": 0.5503472222222222, "EFR": 0.9411764705882353, "Overall": 0.7326797385620915}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "the end of the 2015 season", "the closing of the atrioventricular valves and semilunar valves", "the Coppolas", "SI joint", "the problems", "Mexico", "development of electronic computers", "the Internal Revenue Service", "Balaam ( Numbers 22 : 28 )", "Bhupendranath Dutt", "George III's German - born wife, Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "at luncheon", "Andrew McCarthy as Blane McDonough", "Jakkur, Bangalore, India", "Five years later", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "an active supporter of the League of Nations", "Kennedy Space Center ( KSC ) in Florida", "supported modern programming practices and enabled business applications to be developed with Flash", "Forbes Burnham", "on Saturday and then broadcast `` as live '' on the Sunday", "Isekai wa Sum\u0101tofon", "the tsar's Moscow residence", "the court from its members for a three - year term", "Alicia Vikander", "over 300,000", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "eight", "Lori Rom", "from a Czech word, robota, meaning `` forced labor ''", "Arthur `` The President '' Flanders", "Cameron Fraser ( who disappeared with \u00a3 60,000 of her savings )", "Austin and Pflugerville", "the history of the Philadelphia Eagles begins in 1933", "using His name to commit evil", "four", "Geothermal gradient", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "American singer and songwriter Lana Del Rey", "The Matterhorn", "Trinidadian Calypso", "Jiles Perry Richardson", "The Pentagon", "Croatan, Nantahala, and Uwharrie", "Johnnie Ray", "President Robert Mugabe", "Capitol Hill,", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionists", "Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.3125, "QA-F1": 0.48715247426184927}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.9333333333333333, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.6153846153846153, 0.3333333333333333, 0.4, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.19999999999999998, 0.6666666666666666, 0.5714285714285715, 0.2222222222222222, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.13333333333333333, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.125, 0.6, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-5515", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-7492", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_naturalquestions-validation-7669", "mrqa_triviaqa-validation-6825", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-4240", "mrqa_newsqa-validation-3392", "mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-8333"], "SR": 0.3125, "CSR": 0.546630859375, "EFR": 0.8636363636363636, "Overall": 0.7164284446022727}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan,", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Foxborough, Massachusetts", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Temple Sanchez", "Vanessa Hudgens", "Liga MX", "Amber Laura Heard", "Peter Seamus O'Toole", "March 8, 1942", "Michael Stipe", "January 30, 1930", "Doctor", "Government of Ireland", "James Weldon Johnson (June 17, 1871June 26, 1938)", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes o' Bowhether\"", "Westminster system", "Ionolyce", "For Love alone", "October 4, 1970", "King of the Polish-Lithuanian Commonwealth", "Julius Robert Oppenheimer", "Transporter 3", "March 14, 2000", "Gauteng province, South Africa", "Vietnam War", "Bill Walton", "Darling River", "Brian Keith Bosworth", "140 million", "American", "Teri Garr", "the employer", "the 1965 -- 66 season ( including a record 27 straight NCAA Tournament appearances )", "Wyoming", "Wee Jimmy Krankie and his father,", "people or society", "announced it would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "The clothing must be black, red or white, and women in the impoverished city are concerned that they will not be able to purchase clothing that conforms to the order,", "trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "Billy Corgan", "Ellicott City", "a sprint", "Southport, North Carolina"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6037405303030303}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 0.5454545454545454, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.25, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.0, 0.06060606060606061, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2569", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-9071"], "SR": 0.484375, "CSR": 0.5456730769230769, "EFR": 0.7878787878787878, "Overall": 0.701085372960373}, {"timecode": 65, "before_eval_results": {"predictions": ["Tsung-Dao Lee", "American animated television series \"Archer\"", "Albert", "September 30, 2017", "339,520", "New York Giants", "the Swiss tourism boom", "Eliot Cutler", "The MGM Grand fire", "Odense Boldklub", "A disputed succession and victory at the Battle of Hastings led to the conquest of England by William of Normandy", "Scott Eastwood", "Gweilo", "Tufts College", "Prince Amedeo", "1942", "The Wu-Tang Clan", "\"Hey Dad\"", "a midtempo hip hop ballad with a pop refrain, sung by Rihanna,", "melodic hard rock", "G\u00e9rard Depardieu", "rural", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse University", "Kings Point, New York", "Robert Paul \"Robbie\" Gould III", "\"The Gang\"", "Baldwin", "Port Clinton", "November 20, 1942", "Wayne Conley", "Armidale, New South Wales", "Faith", "Marge agrees to stay with her old prom date, Artie Ziff, for one weekend (on the grounds that he try not to grope her like he did in \"The Way We Was\")", "the Cleveland Celtics", "\"Supernatural\"", "CHO", "eight", "the regime of Emperor Napoleon III", "Sippin' on Some Syrup", "Jim Harrison", "the third Viscount", "John Churchill", "Lester Ben \"Benny\" Binion", "two Grammy awards", "S7", "2017", "Qutab Ud - Din - Aibak", "September 2000", "Thomas Jefferson", "Luxembourg", "Golda Meir", "Muffin Man", "President George Bush", "250,000", "former boxing champion Vernon Forrest,", "cake", "blown", "ghosts", "Dan Aykroyd"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5977718790218791}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.1, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.16216216216216217, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.5, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2978", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-30", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.515625, "CSR": 0.545217803030303, "EFR": 0.9032258064516129, "Overall": 0.7240637218963831}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Sheffield Wednesday", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambidextrous", "Louis Daguerre", "Stephen Hawking", "paleogeography", "an international award given each year to a living architect who, in the opinion of select Pritzker Prize jury, has made profound achievements in the world of architecture.", "Guy", "a man holding up a lighted match", "Port Moresby", "orange", "Kursk nuclear submarine", "pyrotechnic", "badminton", "Eurythmics", "a goose", "Olympics", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "Thomas Jefferson", "Ellice Islands", "Meta", "the 'Flower of Scotland'", "about a mile north of the village of Dunvegan", "a double-reed instrument", "Spice Girls", "Mr Loophole", "Istanbul", "drinking song", "Texas", "Pablo Picasso", "Yalta Conference", "Rajasthan", "African violet", "Bali", "Glee", "Cardigan", "notorious Welsh pirate Edward Kenway, grandfather and father of Assassin's Creed III protagonist and antagonist Ratonhnhak\u00e9 : ton and Haytham Kenway respectively", "Djokovic", "1912", "fennec", "1950", "Prince Nikolai Sergeyevich Trubetzkoy", "Vernon Forrest,", "Linda Hogan", "development of two courses on the Black Sea coast in Bulgaria.", "N.C. Wyeth", "viruses", "Stephen Alan Weinberg", "substitute good"], "metric_results": {"EM": 0.625, "QA-F1": 0.6736458333333333}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, false, true, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.07999999999999999, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-4090", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391", "mrqa_searchqa-validation-7189"], "SR": 0.625, "CSR": 0.5464085820895522, "EFR": 0.7916666666666666, "Overall": 0.7019900497512438}, {"timecode": 67, "before_eval_results": {"predictions": ["$199", "Thailand", "France", "tranquil beaches, the tiny northern island of Sylt is the country's best-kept summer secret.", "took on water", "Werder Bremen", "Secretary of State", "Obama", "nearly three out of four Americans are scared about the way things are going in the country today.", "Fernando Caceres", "an Italian and six Africans dead.", "no evidence", "America's Cup", "the 11th century Preah Vihear temple", "Bahrain", "voluntary manslaughter", "Jenny Sanford,", "Isabella, Emma, Olivia, Sophia, Ava, Emily, Madison, Abigail, Chloe and Mia.", "Miami Beach, Florida,", "\"Percy Jackson & The Olympians,\"", "cell phones.", "two contestants.", "Fiona MacKeown", "the Southern Baptist Convention", "South Africa", "former U.S. secretary of state.", "tried to fake his own death by crashing his private plane into a Florida swamp.", "54-year-old", "from Thursday and Friday to the end of her tour on June 17 and 18,", "helicopters and boats, as well as vessels from other agencies,", "terrorize is a crime,", "two tickets to Italy", "Oxbow, a town of about 238 people,", "\"a potential hazard may occur due to re-entry of satellite debris into the earth's atmosphere.\"", "21-year-old", "Jacob Zuma", "Toffelmakaren", "former Procol Harum bandmate Gary Brooker", "a civil disturbance call", "Pew Research Center", "can also taste a hamburger and pizza, and drink coffee from a cup, the \"things we take for granted every day,\"", "Kenyan and Somali governments", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "Hold On", "a central place in Christian eschatology", "Phil Mickelson", "Dumbo", "Yardbirds", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "julie taymor", "Perkins", "director", "batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6787176840856276}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, false, false, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, true, false, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.4, 0.2, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.2857142857142857, 0.07692307692307693, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.1935483870967742, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3315", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_naturalquestions-validation-833", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.609375, "CSR": 0.5473345588235294, "EFR": 0.92, "Overall": 0.7278419117647059}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura this year.", "their homes in Bhola for the Muslim festival of Eid al-Adha.", "off east  Africa", "Flint, Michigan.", "AS Roma", "President Barack Obama,", "the Southern Baptist Convention", "in body bags on the roadway near the bus,", "Tuesday", "an American who entered the country illegally from China on Christmas Eve.", "2000", "at least 300", "Thursday,", "volatile and dangerous.", "Israeli", "The drama of the action in-and-around the golf course", "2008", "root out terrorists within its borders.", "25 years", "a key find by paleontologists at Los Angeles' George C. Page Museum.", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford,", "a remote part of northwestern Montana", "genocide", "identity theft", "Bailey, Colorado,", "John Demjanjuk,", "Venus Williams", "Black History Month", "How I Met Your Mother", "British", "six", "he was released Friday and taken to the Australian embassy in Bangkok, where he stayed until leaving for Australia at about midnight.", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "stand down", "his past and his future", "Mombasa, Kenya,", "related to the Common Germanic word guma ( Old English guma `` man ) / gomo ( High Old German gomo `` man '', Middle High German gome ) related to Latin homo `` man", "Taron Egerton", "Italy", "Hard Times", "purple coneflower", "MELBA, Nellie Melba", "The King of Hollywood", "1959", "the backside", "Sweden", "garcinia cambogia", "Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6410219988344987}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.8, 0.18181818181818182, 0.3333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.07692307692307693, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_triviaqa-validation-1456", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337"], "SR": 0.5625, "CSR": 0.5475543478260869, "EFR": 0.9285714285714286, "Overall": 0.7296001552795032}, {"timecode": 69, "before_eval_results": {"predictions": ["the cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Kevin Sumlin", "Paradise, Nevada", "Professor Eobard Thawne", "Hathi Jr", "LED illuminated display", "Spektor", "The Star Spangled Banner", "Bill Russell", "a judge who lacks compassion is repeatedly approached by a poor widow, seeking justice", "by October 1986", "a protocol ( http ), a hostname ( www.example.com ), and a file name ( index. HTML )", "1,484 m / s in water ( 4.3 times as fast as in air )", "1997", "Carol Worthington", "September 6, 2019", "1972", "1853", "SURFACE HEREA of ROOTS", "back", "Battle of Antietam", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Andrew Garfield", "under normal conditions", "the 1980s", "Pasek & Paul", "in a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "The White House Executive chef", "place of trade", "25 years after the release of their first record", "the bank", "One Night in the Tropics", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation", "Eucalyptus", "inflation", "Christies Foxhunters", "John M. Dowd", "December 17, 1974", "The Northrop F-15 Reporter", "26", "The woman", "as soon as 2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7047643180295834}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.8, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.5714285714285715, 0.0, 0.4, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.75, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9411764705882353, 0.17391304347826084, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.09523809523809525, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_hotpotqa-validation-993"], "SR": 0.59375, "CSR": 0.5482142857142858, "EFR": 0.7692307692307693, "Overall": 0.697864010989011}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison's", "Brevet Colonel Robert E. Lee", "instructions", "January 2, 1971", "minced meat", "Oakland Athletics", "Bonhomme Carnaval", "1792", "Longliners", "Sebastian Vettel", "Niles", "China", "2017", "Upstate New York", "Carol Ann Susi", "a bar", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "investment bank Friedman Billings Ramsey", "the NFL", "N 17 \u00b0 26 \u2032 48 ''", "1 January 1904", "a password recovery tool for Microsoft Windows", "from 35 to 40 hours per week", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer", "The UN General Assembly", "benzodiazepines", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "St. Theodosius Russian Orthodox Cathedral", "Ray Charles", "a jazz funeral without a body", "2004", "May 31, 2012", "John De Vito", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "Beorn", "South Dakota", "Ronald Reagan", "100,000 writes", "1967", "Rajasthan", "Sodor", "eyes", "44,300", "the 2008 presidential election", "Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "Humpty Dumpty", "Thailand", "500-room"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6577705654911536}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.4615384615384615, 0.35294117647058826, 0.058823529411764705, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333333, 1.0, 0.0, 1.0, 0.15384615384615385, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6307", "mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-5392", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-7551"], "SR": 0.578125, "CSR": 0.5486355633802817, "EFR": 0.7777777777777778, "Overall": 0.6996576682316119}, {"timecode": 71, "before_eval_results": {"predictions": ["David O. Dykes", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Helvellyn Lower Man", "photographer", "clown", "the Titanic", "Campania", "Hadrian", "Madagascar", "The Barbizon school", "Michel Denance", "Manet", "lYNDHURST", "shuttle Columbia", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "'Hansel and Gretel' cottage", "jap\u00f3n", "Greenock", "ABBA", "Sonja Henie", "six", "Lord Snooty", "Greyfriars Bobby, Skye terrier", "Rudolf Hess", "Fonds de la Recherche Scientifique, National Fund for Scientific Research", "Stieg Larsson", "Music Stories", "1957", "le menech", "steel", "Rotherham United", "Joseph Priestley", "a German greyhound, gazelle hound or tazi", "international", "Periodic Table", "CameroonCameroon", "mesopotamia (khora) (the land) between two rivers", "Timothy Carroll", "Cuba", "ab initio", "Patience", "Chubby Checker", "Tim Roth", "establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "Augusta National Golf Club", "San Francisco", "90s", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "January", "Jet Republic", "hiring veterans as well as job training for all service members leaving the military.", "40 lash after he was convicted of drinking alcohol in Sudan where he plays for first division side Al-Merreikh of Omdurman.", "the American Civil War", "subject to unexpected and prolonged contractions as they have in Japan over the past decade", "peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6271859015345269}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3529411764705882, 0.08695652173913042, 0.8, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-127", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-1065", "mrqa_triviaqa-validation-5241", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5039", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196"], "SR": 0.5625, "CSR": 0.548828125, "EFR": 0.7142857142857143, "Overall": 0.6869977678571428}, {"timecode": 72, "before_eval_results": {"predictions": ["Bobby Darin", "Thames", "Altamont Speedway in Livermore, California.", "The Jetsons", "26.22", "tibia", "ocellaris", "Samson", "Connecticut", "Daedalus", "a critically burned English accented Hungarian man, his Canadian nurse, a Canadian-Italian thief, and an Indian sapper in the British Army as they live out the end of World War II in an Italian villa.", "Pandemonium", "a goad", "Miles Morales", "up to 14", "radars", "Queen Elizabeth II", "Tonto", "hippocampus", "gunga Din", "tennis", "Orwell", "Atlantic Ocean", "New Zealand History", "Chatsworth House", "dirk bikembergs", "Budapest", "on your dog's eyelid", "Husqvarna", "baker Street Irregulars", "aug. 24, 1572", "taurine cattle", "Augustus", "Venezuela", "Southwest Airlines", "Sunset Boulevard", "hopper", "Derwent", "sesame", "Laos", "Allardyce", "Petain", "Ryan O\u2019 Neal", "Miami", "Bill Haley & His comets", "sparrow corkscrew", "1917", "Joan Rivers", "Ethiopia", "William Refrigerator Perry", "Ghana", "as an extension to this procedure", "magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "U.S. Holocaust Memorial Museum", "Robert Barnett,", "Diego Milito", "dont wanna leave", "Dumbo the Flying elephant", "\" Lost colony\" of 1580s North Carolina", "pythons"], "metric_results": {"EM": 0.40625, "QA-F1": 0.49007056451612907}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, false, false, true, false, true, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06451612903225806, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-5614", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-1380", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-208", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.40625, "CSR": 0.546875, "EFR": 0.868421052631579, "Overall": 0.7174342105263157}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "Mercer Bears", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Washington", "Helen Mirren", "horse breeder", "Schutzstaffel", "Edward Albert Heimberger", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis", "sitters", "Premier League", "Sleepy Hollow", "Jane Mayer", "Obafemi Martins", "Knowlton School", "143,007", "Philadelphia", "33-member", "American television personality and film actress", "1957", "mathematician", "King Duncan", "St Andrews Agreement", "Royal College of Music", "4145 ft above mean sea level", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "main east-west road", "schoolteacher", "People v. Turner", "Bill Ponsford", "Aamina Sheikh, Hasan Ahmed, Neelam Muneer, Zaheen Tahira, Ismat Zaidi, Sami Khan and Faisal Qureshi", "one", "Mortal Kombat", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "parashah", "paramitas", "1881", "marketing", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Jobs", "Christianity and Judaism", "blintz", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.625, "QA-F1": 0.7082923695400718}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0625, 0.6, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 1.0, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8918918918918919, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5010", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621"], "SR": 0.625, "CSR": 0.5479307432432432, "EFR": 0.7083333333333334, "Overall": 0.6856278153153152}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ribonucleic acid (RNA)", "ketchup", "igloo", "compound eyes", "timbaland", "Former Texas governor and two-time Republican presidential candidate", "republic", "Latvia", "spleen", "auf wiedersehen", "rely", "Ramesses II", "wine", "the esophagus", "Super Bowl VI", "the Bible", "twist", "Marie Tussaud", "Biscay", "Ziz", "March", "Ferdinand Magellan", "Kevin Spacey", "a brothel", "an oblate spheroid", "The Aviator", "Gioachino Rossini", "Veracruz", "tail", "Tennessee", "hanging garden", "a robot", "Billy Crystal", "skin cancer", "de la Motte Cadillac", "Qubec", "pontificio", "The Drew Carey Show", "Onagraceae", "Moonlighting", "Corpus Christi", "Mentor", "Ruth Bader Ginsburg", "Edward R. Murrow", "beryl, rubies, sapphires, topazes, and garnet", "in vitro fertilization", "Diogenes of Sinope", "pastries", "jedoublen/jeopardy", "the Electric Company", "September 24, 2012", "Roger Dean Stadium", "March 31, 2013", "Helen Reddy", "Celsius", "Jeremy Irons", "monthly", "Jennifer Grey", "Donald Wayne Johnson", "demolishing American third seed Venus Williams in the final of the Sony Ericsson Open in Miami on Saturday.", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.5, "QA-F1": 0.5982638888888889}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-7401", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-3193", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-9143", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-976", "mrqa_naturalquestions-validation-5096", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-801"], "SR": 0.5, "CSR": 0.5472916666666667, "EFR": 0.96875, "Overall": 0.7375833333333334}, {"timecode": 75, "before_eval_results": {"predictions": ["only eleven", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "The nucleus provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "2004 -- 2005", "1963", "The Satavahanas", "the Central Board of Artisans", "it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK", "28 July 1914", "Lager", "908 mbar", "North Atlantic Ocean", "February 7, 2018", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "on a sound stage in front of a live audience in Burbank, California", "Valens and Richardson", "American singer - songwriter - actress Debbie Gibson", "Lula", "31 January 1934", "Austin", "the southeastern United States", "the gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "synthesizing vitamin B and vitamin K as well as metabolizing bile acids", "Kyla Coleman", "Bill Patriots", "December 19, 1971", "Tim Passmore", "Garbi\u00f1e Muguruza", "Spanish / Basque origin", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Partridge", "Bell Labs", "Saint Etienne", "a marked ( `` - s '' ) or unmarked plural", "Chuck Noland", "many forested parts of the world", "arithmetic", "Finger Tips", "Red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie meals", "0-0 draw", "Hapsburg", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.5, "QA-F1": 0.6589781746031746}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666667, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9428571428571428, 1.0, 1.0, 0.6, 1.0, 0.28571428571428575, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.888888888888889, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-2402", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-5481", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-1646"], "SR": 0.5, "CSR": 0.5466694078947368, "EFR": 0.78125, "Overall": 0.6999588815789474}, {"timecode": 76, "before_eval_results": {"predictions": ["$689.4 million in North America and $1.528 billion in other countries, for a worldwide total of $2.187 billion", "Total Drama Action", "Christopher Lloyd", "senators", "rape", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "sovereignty", "Authority", "Archie Andrews", "American rock band Los Lonely Boys", "ecosystems", "cakes", "Kiss", "England", "Julie Adams", "During World War II", "Anthony Quinn as Craig Belden", "January 2004", "The Vamps, McGregor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "William T. Deutschendorf", "Derrick Henry", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins, and the lyrics to most of the suite's sections consist of his thoughts about her and their imminent breakup", "southern Turkey, dividing the Mediterranean coastal region of southern Turkey from the central Anatolian Plateau", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Brady Lee Richmond as Hank, a regular Maggie's patron", "an anembryonic gestation", "It is a homodimer of 37 - kDa subunits and is classified as a glycosyl Transferase", "Matt Monro", "a Nativity scene", "they are easily confused with III and VIII ), and are generally replaced with IV ( one less than 5 ) and IX", "first No. 1 seed to lose to a No. 16 seed since the field expanded to 64 teams in 1985", "Saphira hatches from the stone, which was really an egg", "September 2017", "an Irish feminine name", "Ace", "Spike", "regulatory site", "After releasing Willow from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Aegisthus", "InterContinental Hotels Group", "peninsulas", "Jason Flemyng", "peninsular mainland jutting out into the Mediterranean Sea at the southernmost tip of the Balkans, and two smaller peninsulas projecting from it : the Chalkidice and the Peloponnese", "Norman Mailer", "a Bristol Box Kite", "Pye", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million", "San Diego,", "CNN.com", "a jazz funeral", "hedgehog", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6498991894846086}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, false, true, true], "QA-F1": [0.21052631578947367, 0.5714285714285715, 1.0, 1.0, 0.0, 0.8181818181818181, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.33333333333333337, 1.0, 0.0, 0.375, 0.962962962962963, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.09090909090909093, 1.0, 1.0, 0.09523809523809523, 0.0, 0.2222222222222222, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.07407407407407408, 1.0, 1.0, 0.0, 1.0, 0.08695652173913045, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170", "mrqa_searchqa-validation-9852"], "SR": 0.5625, "CSR": 0.546875, "EFR": 0.75, "Overall": 0.69375}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Giuliano Bugiardini", "palladium", "pulsar", "Seth", "Honda", "John & Yoko and The Plastic Ono Band with the Harlem Community Choir - \" Happy Christmas (War Is Over)\"", "Adolf Hitler", "Hamlet", "the 2010 FIFA World Cup", "Elizabeth I", "June", "Italy", "1960", "Mel Brooks", "Belgium", "chlorophyll", "Paul Dukas", "Iceland", "Uranus", "rum", "apples", "Aberlemno", "Roddy Doyle", "the U.S Olympic Trials", "Separate Tables", "telephone call over telegraph wires between two towns in Ontario, Canada", "Beatrix Potter", "Magpie", "comets", "swimming", "Kansas City", "Ra\u00fal Castro", "Space Oddity", "Scotland", "an egg", "Illinois", "red", "Splash", "South Africa", "menorah", "Good Will Hunting", "gollum", "otters", "John McCarthy", "John Mortimer", "Cheerios", "line code", "native to Asia", "Liam Cunningham", "Brobee", "Fuenlabrada", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "E22", "security breach", "at checkposts and military camps in the Mohmand agency, part of the lawless Federally Administered Tribal Areas where U.S. and Pakistani officials have reported a presence of militants.", "Mashhad, Iran.", "St Bernard", "France", "Barnard College", "the equator, powered entirely by the sun."], "metric_results": {"EM": 0.578125, "QA-F1": 0.6302083333333334}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-4389", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-307", "mrqa_triviaqa-validation-6105", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-5040", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.578125, "CSR": 0.547275641025641, "EFR": 0.8518518518518519, "Overall": 0.7142004985754985}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Verdi", "the month of May", "Michael Corleone", "vVD Savarkar", "by increasing the number of arcs", "Mr. Golding", "a nerve cell cluster  or a group of nerve cell bodies located in the autonomic nervous system", "vitamin B3", "Director General of the Security Service", "Hell Upside Down", "Funchal", "bachelor", "spaghetti harvest", "Northern Ireland", "passport", "Marcel Duchamp", "Quatermass Experiment", "Mumbai", "the Labyrinth", "1875", "raven", "hound", "sue", "Estimate", "$x^2", "Narendra Modi", "Richard Wagner", "quentin tarantino", "Argentina", "an acronym", "Kitzb\u00fchel", "Tunisia", "Crystal Gayle", "steppes steppe", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "the 11th Century Church", "Darrin Stephens", "springtime for Hitler", "the Holy Land", "Eva Herzigov\u00e1", "David Hockney", "Ireland", "rigbit", "Carrie", "Colombia", "the island of Ireland", "1 - 2 spinal nerve segments above the point of entry", "magnetic stripe `` anomalies '' on the ocean floor", "Samaria", "Tudor music and English folk-song", "Martin O'Malley", "1992", "sculptures", "when people gathered outside as the conference in the building ended.", "al-Shabaab", "the Old Man and the Sea", "Edward I", "the Cranberries", "there were no radar outages and said it had not lost contact with any planes during the computer glitch."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6207056781045752}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.5, 0.35294117647058826, 0.6666666666666666, 0.25, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.9, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-7072", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_naturalquestions-validation-7920", "mrqa_newsqa-validation-2485", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.53125, "CSR": 0.5470727848101266, "EFR": 0.7333333333333333, "Overall": 0.690456223628692}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "French", "HMS Amethyst", "Libya", "tomato", "Kyoto Protocol", "Fancy Dress Shop", "Bull Moose Party", "hippo", "Jake La Motta", "resistance of an unknown resistor", "lillian Randolph", "South Africa", "indigestion", "discretion", "Beijing", "The Apprentice", "George Washington", "Corinth Canal", "human rights lawyer", "Iceland", "Ascot", "peaches", "Bruce Jenner", "gangsters", "bitches", "Duncan", "UK Independence Party", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "Rambo", "julian WikiLeaks", "IT Crowd", "ilie nastase", "local police officer Rip Nix", "gretos", "Richard Curtis", "terms of endearment", "China", "lothbrok", "1790", "argyle", "ladywort", "driving Miss Daisy", "orchid", "Hilary Swank", "Aberdeen", "latitude 90 \u00b0 North", "18th century", "eight hours ( UTC \u2212 08 : 00 )", "just 18 minutes", "England", "Sri Lanka Freedom Party", "\"Steamboat Bill, Jr.\"", "Afghanistan's Helmand province,", "Rodong Sinmun", "theology", "Fred Astaire", "sanctions", "February"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6373958333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16, 0.6, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-889", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-7034", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-1857", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-2116"], "SR": 0.578125, "CSR": 0.5474609375, "EFR": 0.7037037037037037, "Overall": 0.6846079282407407}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Eleanor Roosevelt", "senators", "2 total", "dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Jason Momoa", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "the Hudson Bay", "H CO ( equivalently OC (OH ) )", "Miami Heat", "2018", "four of the 50 states of the United States in their full official state names : Kentucky ( the law creating Kentucky names it the `` State of Kentucky ''", "manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas", "usually, the significance level is set to 0.05 ( 5 % ), implying that it is acceptable to have a 5 % probability of incorrectly rejecting the null hypothesis", "Australian reality television talent show which premiered on 18 February 2007 on the Seven Network", "A thin film is a layer of material ranging from fractions of a nanometer ( monolayer ) to several micrometers in thickness", "Tulsa, Oklahoma", "Kristy Swanson", "Corey Taylor", "Charles R Ranch, County Road 24, Las Vegas, New Mexico, USA", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation from the Great Plains whose historic territory, known as Comancheria, consisted of present - day eastern New Mexico, southeastern Colorado, southwestern Kansas, western Oklahoma", "United Nations", "as of October 1, 2015, when the green class A was retired", "2026", "318", "the Director of National Intelligence", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "The fourteenth season of the American television medical drama Grey's Anatomy was ordered on February 10, 2017, by American Broadcasting Company ( ABC ), and premiered on September 28, 2017 with a special two - hour premiere", "Staci Keanan", "Brooklyn, New York", "1837", "Lagaan", "1996", "American rock band Los Lonely Boys", "G -- Games ( AKA `` appearances '' ) : number of times a pitcher pitches in a season", "the foreign exchange market (FX )", "Coppolas and, technically, the Farrow / Previn / Allens", "Sunday Post", "Karl Pilkington", "peking", "1860", "\"Back to December\"", "Ringo Starr", "\"Up\" mixes allegory with adventure and dumb imaginative exuberance.", "\"Empire of the Sun,\"", "off Somalia's coast.", "modificre", "molly ringwald", "faerie", "blue, ridged glass"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7033957748278452}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, false, true, true, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.08695652173913045, 0.6666666666666666, 1.0, 1.0, 1.0, 0.08695652173913045, 0.0, 0.9032258064516129, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3870967741935484, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.17647058823529413, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.16666666666666669, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.09090909090909093, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-10421", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-8711", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-5915", "mrqa_triviaqa-validation-7286", "mrqa_hotpotqa-validation-5254", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.640625, "CSR": 0.5486111111111112, "EFR": 0.9130434782608695, "Overall": 0.7267059178743962}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "shaport", "Berenice II", "nuclear warheads", "capitals", "a pizza roll", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "fauvism", "Auguste Deter", "Marcia Clark", "a hand-powered multiple spinning machine", "gestation", "ravens", "J.R. Tolkien", "James Franco", "Blue Ridge Mountain range", "Georgia", "a mixture of iron oxide and aluminum oxide", "buddha's toe", "Apple", "the leader of the late insurrection in Southampton, Virginia,", "a catfish", "A Chorus Line", "parma", "Robbie Turner", "a feeling of sadness about something that you did or did not do", "Olivia Newton-John", "Virginia", "the College of William", "small", "Louisiana", "Vassar", "Japan", "silverware", "The Police", "Air France", "Scarlatti", "Heracles", "trudge", "Violent Femmes", "Albert Camus", "Volvo", "Rhode Island", "yodeling", "Indian Ocean", "a syringe", "Charlotte Corday", "a nanosecond", "bat", "Mason Alan Dinehart", "plays a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "a great deal on location", "2010", "a drum kit", "Madagascar", "Tom Hiddleston", "Estadio Victoria", "Borough of Allerdale", "Mugabe's opponents", "70,000 or so", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.53125, "QA-F1": 0.65390625}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-2110", "mrqa_naturalquestions-validation-5526", "mrqa_triviaqa-validation-7122", "mrqa_hotpotqa-validation-868", "mrqa_newsqa-validation-1720"], "SR": 0.53125, "CSR": 0.5483993902439024, "EFR": 0.9333333333333333, "Overall": 0.7307215447154471}, {"timecode": 82, "before_eval_results": {"predictions": ["submarine", "Hopi", "Vatican City", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Parthenon", "Michael", "Marilyn Monroe", "souvlaki", "Richard III", "the bald eagle", "the Louvre", "4,047 m2", "the Baha de Darwin, Spanish for \"Darwin Bay\"", "Frans Hals", "the Black Sox Scandal", "lynx", "Grenadine", "Constantine", "Aleutian", "alchemy", "art nouveau", "autobahn", "Anglo-Saxon", "California quail", "curtsy", "Lacrosse", "Toronto", "acute accent", "King David", "B1", "tassels", "Indiana Jones", "Michigan", "French Revolutionary ideals", "freelance", "Philadelphia", "Goodyear", "The hobbit", "the Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "laces", "Lee Marvin", "Prince Edward Island", "Westminster Abbey", "Superbad", "the Granite State", "1885", "$2.187 billion", "Isle Vierge ( 48 \u00b0 38 \u2032 23 '' N 4 \u00b0 34 \u2032 13 '' W", "France", "acai", "the Benedictine Order", "Pansexuality", "authorship of \"Titus Andronicus\"", "getaway driver", "Drew Kesse,", "the pregnancy.", "eight-week", "1999"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6773631840796019}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, false, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.41791044776119407, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-1956", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-4646", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.59375, "CSR": 0.5489457831325302, "EFR": 0.8846153846153846, "Overall": 0.7210872335495829}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "vulture", "Nantucket", "Ebony", "the University of Cambridge", "Algeria", "Joseph Haydn", "Dick Cheney", "the black market", "a number", "The Bodyguard", "China", "pizza al taglio", "a turtle", "the Empire State Building", "white blood cor`puscle", "a trifle", "dogwood", "Qubec", "Larry McMurtry", "Kellogg's", "Helen of Troy", "sweats sweats sweats sweater", "W=Fd", "Napoleon", "gold", "the Arctic", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "Ba", "Pancho Gonzales", "the Aleutians", "Latter-day Saints", "Jane Grey", "Tommy Tutone", "the crescent moon", "the Hijaz", "an old grasshopper", "Nicolaus Copernicus", "an Anaheim chiles", "Craig", "the Santa Maria delle Grazie, Milan", "London", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "Casablanca", "Theodore Roosevelt Mason", "Parlophone", "9:20 p.m. ET Wednesday.", "Daryeel Bulasho Guud", "1995", "four"], "metric_results": {"EM": 0.5, "QA-F1": 0.5828125}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-5531", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1070", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1916", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-502", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-537"], "SR": 0.5, "CSR": 0.5483630952380952, "EFR": 0.96875, "Overall": 0.7377976190476191}, {"timecode": 84, "before_eval_results": {"predictions": ["Syria", "Catherine of Aragon", "Judas Iscariot", "Windsor, Ontario", "Stephen Douglas", "Comrade", "the Great Gatsby", "a fox", "Sexuality", "Salaries", "(Solomon)", "John McEnroe", "a bicycle", "Johnson County", "Jericho", "push", "Alexander Solzhenitsyn", "tomfoolery", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "Daughters of the American Revolution", "Manila", "St Mark", "Eragon", "\"Strawberry Fields Forever\"", "Louisiana", "Mexico", "jolly Roger", "engrave", "Daisy Miller", "the French Legion of Honour", "X", "a ship", "Kamehameha I", "a raccoon", "Virginia", "Jerry Maguire", "the north magnetic pole", "Oyster Bar", "orangutan", "Candlestick Park", "Zimbabwe", "a bowstring", "Patty Duke", "Pronouns", "Hoffmann", "a calico cat", "Frankie Muniz", "in season two", "A complex sentence", "40", "Neptune", "Nowhere Boy", "August 1973", "a simple iron boar crest adorns the top of this helmet associating it with the Benty Grange helmet and the Guilden Morden boar", "Richa Sharma", "Haiti", "financial gain,", "a Nazi concentration camp,", "Golfer Tiger Woods"], "metric_results": {"EM": 0.625, "QA-F1": 0.7279050207039338}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, false, true, true, true, false, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.34782608695652173, 1.0, 1.0, 1.0, 0.4, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-5876", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-6178", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-11433", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-10841", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_searchqa-validation-9898", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-9404", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.625, "CSR": 0.549264705882353, "EFR": 0.9583333333333334, "Overall": 0.7358946078431373}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Kanga", "Italian", "Eggs Benedict", "the Taj Mahal", "Ayn Rand", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Latifah", "F.O. J. Smith", "The Beatles", "The Hague", "Geena Davis", "pharmacy", "Amos", "the NFL", "Doolittle", "air", "Shakespeare in Love", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "the money changers", "The X-Files", "Babar the elephant", "Mensa", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "a Booster seat", "the Church of Jesus Christ of Latter-day Saints", "Italy", "a watermelon", "the Warsaw Pact", "Sparta", "the Sunday New York Times", "anode", "boldly go where no man has gone before", "the National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "hair", "the Texas Rangers", "Fluoxetine", "the only acid excreted as a gas by the lungs", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "Yodel It!", "ketamine.", "has to move out of her rental house because it is facing foreclosure", "Why he's more American than a German,", "Santiago Ram\u00f3n y Cajal"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6375000000000001}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14387", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_naturalquestions-validation-9220", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-1212", "mrqa_newsqa-validation-2692", "mrqa_naturalquestions-validation-4103"], "SR": 0.578125, "CSR": 0.5496002906976745, "EFR": 0.8518518518518519, "Overall": 0.7146654285099052}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy feet", "a short distance", "a real animal", "Joseph", "Chicago", "Aeneas", "Cannery Row", "Palatine", "California", "Mississippi", "Alpha", "Quebec", "a pearl", "Texas Chainsaw Massacre III", "a building", "a Medal of Honor", "Manet", "Plutarch", "Milan", "Corin", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "(John) Wells", "Vasco da Gama", "Millard", "a wool", "Finnegans Wake", "alaykum", "the black market", "professor of higher education", "S-waves", "Maastricht", "Delilah", "synapses", "croissants", "Rocky Down Mexico Way", "lungs", "fuchsia", "metacarpals", "grade & grave", "Warsaw", "a trowel", "Mercury", "Taiwan", "Gettysburg", "Ibtihaj Muhammad", "trout", "a slow Boat", "1959", "season two", "$75,000", "Malawi", "15", "Stonemason's Yard", "Agent Carter", "Orson Welles", "Manhattan", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6654761904761906}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-6251", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.59375, "CSR": 0.5501077586206897, "EFR": 0.7692307692307693, "Overall": 0.6982427055702918}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists and the Carlists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770 guaranies", "Geoffrey Zakarian", "$72", "Mary Elizabeth ( Margaret Hoard )", "Scott Schwartz", "Paris", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Francis Ford Coppola", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "slavery", "The Osmonds", "a political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "the Federated States of Micronesia and the Indonesia ( which consists of thousands of islands )", "Anakin", "Alexander Salkind", "one", "Portia de Rossi", "Jesse Triplett", "Kevin Garnett", "a star", "Brazil", "Selena Gomez", "Washington", "the 2nd century", "drive", "the first novel in the Harry Potter series and Rowling's debut novel, first published in 1997 by Bloomsbury", "shared", "foreign investors", "Napoleon", "marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool ( USMT )", "Robber baron", "December 20, 1951", "Watson", "Mount Aconcagua", "Bake Off", "1924", "Noah Levenstein", "zona glomerulosa of the adrenal cortex", "Fionnula Flanagan", "last summer.", "social issues like homelessness and AIDS.", "three-time road race world champion, as well as a double winner of the women's Tour de France, and the clear favorite for gold in Seoul.", "banker", "eyelid", "the Cubs", "pickpocket"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6026542834291266}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.782608695652174, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.7741935483870968, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.8, 0.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5714285714285715, 0.0, 1.0, 0.05714285714285715, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-1656", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-5041", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-995", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.484375, "CSR": 0.5493607954545454, "EFR": 0.9090909090909091, "Overall": 0.7260653409090909}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff,", "a bag", "Federer", "from Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "\"The harder they squeeze and squish that breast, the less tissue the X-rays have to go through and the more likely they are to find something.\"", "militants were plotting to attack two Shiite mosques, police stations, and a Norwegian telecommunications company in Punjab, according to district police officer Usman Anwar.", "Salt Lake City, Utah,", "normal maritime traffic", "Saluhallen, the covered market on Lilla Torg", "to make space for two ocean wind farms -- taking up 2 percent of the state's waters -- without angering fishing industries, killing whales or harming ecosystems.", "Rocky Ford brand cantaloupes", "\"Ocean advocates say these planning processes are urgently needed and have been a long time in coming.", "arrested three men with suicide vests who were plotting to carry out the attacks,", "\"We are going to systematically go through each and every one of them,\"", "club managers,", "Long Island", "90", "FBI", "Reggae legend Lucky Dube,", "the Kurdish militant group in Turkey", "14", "\"It was difficult for him to talk about. Difficult for us to listen to,\"", "Kerstin Fritzl,", "Justice Department motion filed last week in support of the Defense of Marriage Act -- which effectively bars the federal government from recognizing same-sex unions.", "Europe", "\"I believe it's discriminatory. I think it interferes with state's rights, and we will work with Congress to overturn it,\"", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Greeley, Colorado,", "Festival Foods", "\"It all started when the military arrested one man, and then an hour later he emerged from building barely able to walk from the beating,\"", "drugs", "Daniel Radcliffe", "1.2 million", "\"I wanted to push it up that black a--.\"", "12.3 million people worldwide", "Krishna Rajaram,", "North Korea", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Taher Nunu", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "Turkey can play an important role in Afghanistan as a reliable NATO ally.", "the Yemeni port city of Aden", "federal officers", "\"Beverly Hills Chihuahua\"", "the Chao Phraya River and its many canals.", "journalists and the flight crew will be freed,", "writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "The Hague Conventions", "Chris Hemsworth", "Viscount Cranborne", "England", "beef", "Sleyman", "the rainforest", "Ramadan"], "metric_results": {"EM": 0.5, "QA-F1": 0.6177637359758332}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 0.12903225806451613, 1.0, 0.8, 0.0, 0.07407407407407407, 1.0, 0.47619047619047616, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.23255813953488377, 0.6666666666666666, 0.24000000000000002, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.875, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.17391304347826086, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-3441", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-3575", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4144", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763"], "SR": 0.5, "CSR": 0.5488061797752809, "EFR": 0.78125, "Overall": 0.7003862359550561}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron", "Sun Woong", "president", "Comedy Film Nerds", "9\u201310 March 1945,", "2011", "John D Rockefeller's", "early 1970s", "Asiana Town building", "American R&B singer, guitarist, songwriter and music producer", "Rockland County", "Manitowoc County, Wisconsin", "34.9 kilometres", "1967", "alcoholic drinks", "Fabbrica Italiana Automobili Torino", "Chrysler", "Australian", "chimpanzee", "Eyes Wide Shut", "The Royal Navy", "Robert Digges Wimberly Connor", "Yitzhak Edward Asner", "the Beatles", "Baden-W\u00fcrttemberg", "2001 NBA All-Star Game", "rated R", "95 AD", "1614", "Italian", "\"The Manhunter from Mars\"", "Mondays", "Michael Jordan", "Snowball II is killed off,", "bank of China Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "The Home Rule League", "Anne Fletcher", "1822", "Mulberry", "Suspiria", "BBC Focus", "Kansas\u2013Nebraska Act of 1854", "Scandinavian design", "Buck Owens", "Big Machine Records", "UPS, Parcelforce, DHL, Hermes, Royal Mail", "Flaw", "June 5, 2017", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "forearm", "Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "Piers Morgan Tonight", "misdemeanor assault charges after a fight at his Texas high school", "Florida", "The Partridge Family", "Mickey Spillane", "for housing, business and infrastructure repairs, federal authorities said."], "metric_results": {"EM": 0.703125, "QA-F1": 0.7472052253302254}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5567", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3253", "mrqa_newsqa-validation-3369"], "SR": 0.703125, "CSR": 0.5505208333333333, "EFR": 0.8947368421052632, "Overall": 0.7234265350877193}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2009", "actress and singer", "Pakistan", "1754", "\"Confessions of a Teenage Drama Queen\"", "Bundesliga club VfL Wolfsburg", "d\u00edsabl\u00f3t", "David Villa", "Adrian Peter McLaren", "2013", "an early colonist of South Australia, remembered as a schoolmaster at J. L. Young's Adelaide Educational Institution and at Saint Peter's College.", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Diamond White", "25 November 2015,", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "Gatwick Airport", "Riot Act", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Goitsebeng Maphiri Khama, GCB, KBE", "Scandinavian design", "Mike Pence", "Barack Obama", "Flex-fuel vehicle", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian", "138,535", "Ry\u016bky\u016b", "1972", "Stern-Plaza", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravitation", "ensure consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "South Africa", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailing", "Robert Barnett,", "Sally Ride doll", "Diane Cilento", "CO2", "Shout"], "metric_results": {"EM": 0.625, "QA-F1": 0.7084856455440696}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.787878787878788, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.30434782608695654, 1.0, 1.0, 1.0, 0.2564102564102564, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-4050", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-2030", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743"], "SR": 0.625, "CSR": 0.5513392857142857, "EFR": 0.6666666666666666, "Overall": 0.6779761904761905}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "Apple", "Jaguar", "Tony's", "Friday", "Sabino Canyon", "Orlando Bloom", "Babe Ruth", "Polk County", "Arkansas", "Cus D'Amato", "Virgo", "Contemporary", "Coyote", "bcolicus", "Tito Puente", "Hydrogen", "Ben Jonson", "Hodgkin's lymphoma", "Margaret, Countess of Snowdon", "Las Vegas", "San Francisco", "Norman Mailer", "Mary Baker Eddy", "Bank One Corp.", "the College of William & Mary", "The Wright Brothers", "Badminton", "John Deere", "depth and height", "Chrysler", "Reptiles", "Georgia", "Key lime pie", "Lettuce", "Arabian Nights", "bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "Mesopotamia", "Jean-Paul Marat", "Cetshwayo", "Bay of Montevideo", "the bank, rather than the purchaser, is responsible for paying the amount", "a spirit-lifting jingle", "Bobby Brown,", "Bath", "1.5 million households", "Macomb County", "Kristoffer Rygg", "Veracruz", "Monday night.", "eight", "minister and biographer"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6692708333333333}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_hotpotqa-validation-4539"], "SR": 0.5625, "CSR": 0.5514605978260869, "EFR": 0.75, "Overall": 0.6946671195652174}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico, Virginia", "the East", "William Shakespeare", "William Shakespeare", "abscesses", "Colorado", "Sputnik 1", "Richmond", "Sturm und Drang", "Java", "baritone", "Blanche DuBois", "the Flag", "Room-temperature vulcanization", "Wuthering Heights", "Muhammad", "September 20, 1934", "The Curse of the Black Pearl", "Frederick Forsyth", "Chesterfield", "a wolf", "Marie-Joseph-Rose de Tascher de la Pagerie", "salt", "a warrant", "Rossini", "Oman", "Lapland", "Tom Canty", "Roman Polanski", "Joan Didion", "a frigate", "Baltimore", "the Bay of Bengal", "buttonedoublen", "Clinton", "Terrific", "geology", "six sides", "Olympia", "Ship of Fools", "Haunted", "tendang", "fluid", "Margaret Mitchell", "Frances", "Vin Diesel", "cremation", "the French & Indian War", "a manic episode", "the Hudson Bay", "lighter", "a scuffle with the Beast Folk", "Tanner", "Germany", "Tan-y-Bwlch Station,", "Dar es Salaam", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20.", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5590277777777777}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.4444444444444445, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-10078", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-12499", "mrqa_searchqa-validation-4155", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_searchqa-validation-4465", "mrqa_naturalquestions-validation-6707", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6984", "mrqa_triviaqa-validation-6867", "mrqa_hotpotqa-validation-3557"], "SR": 0.46875, "CSR": 0.5505712365591398, "EFR": 0.8823529411764706, "Overall": 0.7209598355471221}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Lulu", "Telma Hopkins", "Mel Gibson", "2017", "drivers who were 2016 Pole Award winners ; former Clash race winners, former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "November 1975", "Pacific Grove", "while in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form, he made the hair more `` wild '' and covered Goku's body in red fur", "Audrey II", "January 2017 patch", "NIRA", "1922", "Jacqueline Bouvier", "Justin Timberlake", "The Chainsmokers", "13 May 1787", "Prince James, Duke of York and of Albany ( later King James II & VII )", "his brother", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3 of the United States Constitution", "McFerrin", "Napoleon", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "Jupiter", "hyperinflation", "1939", "Richard Masur", "Kyla Pratt", "Spanish", "Sauron", "Lana Del Rey", "a `` house edge '', a statistical advantage for the casino that is built into the game", "159", "The Third Five - year Plan", "The chant was first adopted by the university's science club in 1886", "works in a bridal shop", "activates a relay which will handle the higher current load", "limited period of time", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood's A Holy Grail", "nide", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz and Jared Polis", "Da Vinci Code", "contact us.", "Khrushchev", "Julie Andrews", "Headless Horseman", "Leo Frank,"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6703819617882119}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, false, true, false, false, false, true, false, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.8571428571428572, 0.0, 0.7499999999999999, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.7272727272727273, 0.0, 0.30769230769230765, 1.0, 0.2, 0.0909090909090909, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-2862", "mrqa_naturalquestions-validation-857", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3374"], "SR": 0.5625, "CSR": 0.5506981382978724, "EFR": 0.7857142857142857, "Overall": 0.7016574848024316}, {"timecode": 94, "before_eval_results": {"predictions": ["direct scattering and inverse scattering", "ThonMaker", "Battle of Chester", "youngest TV director ever", "1864", "on the shore, associated with \"the Waters of Death\" that Gilgamesh had to cross to reach Utnapishtim, the far-away", "playback singer, director, writer and producer", "Austral L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado", "Revengers Tragedy", "Japan", "rural areas", "number 6", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "August 28, 1774", "Pantone Matching System (PMS)", "Las Vegas Boulevard", "The Bridge Between Science and Theology", "Anthony Herrera", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevy Corvette Stingrays", "Field of Dreams", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Tom Tykwer", "the Nazi Occupation of the Netherlands", "mastered recordings for many well known musicians, including David Bowie, The Subways, Foo Fighters, Lou Reed, Paul McCartney, Sin\u00e9ad O'Connor, Natalie Merchant, Marianne Faithfull, and Madonna.", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "the Food and Agriculture Organization", "dance partner", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "Holinshed's Chronicles", "June 26, 2018", "University Grants Commission", "1 April 1985", "Australia", "Bonkyll Castle", "February 5, 2015", "Zeffirelli", "giant planet", "alveolar", "Duisburg", "Hugh Quarshie", "King George V of the United Kingdom", "Tokyo", "Utah Valley Regional Medical Center,", "Madonna", "Fareed Zakaria", "Easter Island", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.5625, "QA-F1": 0.7076954539125592}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true], "QA-F1": [0.8333333333333333, 0.0, 1.0, 1.0, 0.5, 0.3157894736842105, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.47619047619047616, 0.0, 0.0, 0.14814814814814814, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-706", "mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-3258", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-854", "mrqa_hotpotqa-validation-5042", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-1297", "mrqa_naturalquestions-validation-5155", "mrqa_naturalquestions-validation-3989", "mrqa_triviaqa-validation-514", "mrqa_searchqa-validation-2056"], "SR": 0.5625, "CSR": 0.5508223684210527, "EFR": 0.8928571428571429, "Overall": 0.7231109022556391}, {"timecode": 95, "before_eval_results": {"predictions": ["more than 250 million copies worldwide", "Ben Ainslie", "1978", "Spoorloos", "Scott Mosier", "1950", "Roy Warren Spencer", "1964", "Shawnee Mission Parkway", "VH1", "March", "Russian", "Jack Ryan", "July 25 to August 4", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer, songwriter, actress, and radio and television presenting", "Northern Lights", "coca wine", "Mach number", "Terrina Chrishell Stause", "Maine", "Encore Las Vegas", "Baa, Baa", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1935", "President John F. Kennedy", "paracyclist", "Taiwanese", "Kevin Spacey", "Deputy Vice-Chancellor", "Song Il-gon", "Teenitans Go!", "Mickey Mouser", "three", "right-hand", "Sheen Michaels Entertainment", "Sela", "whale lice", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers", "Metro-Goldwyn-Mayer", "P.O.S", "My Backyard", "Sun Woong", "American professional boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "March 1st.", "Da Vinci Code", "Dogpatch Labs", "iceberg", "a fuel cell", "Queen Victoria", "Venus Williams"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6813368055555555}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, false, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true], "QA-F1": [0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.5, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-1895", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-5568", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-1151", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5665", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-3773", "mrqa_newsqa-validation-3838", "mrqa_searchqa-validation-14503"], "SR": 0.578125, "CSR": 0.5511067708333333, "EFR": 0.8148148148148148, "Overall": 0.7075593171296296}, {"timecode": 96, "before_eval_results": {"predictions": ["The Concubine", "1927", "16,116", "the 2012 Summer Olympics", "at the end of the 18th century", "1942", "Willie Nelson and Kris Kristofferson", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "The Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "The Winter Olympic Games", "Oldham County, Kentucky", "1896", "Oracle Corporation", "143,007", "SARS", "5.3 million", "chocolate-colored", "Norman Graham Hill", "1908", "Neneh Mariann Karlsson", "American rapper Eminem", "Love Streams", "In a Better World", "Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker and Matt Stone", "\"Pimp My Ride\"", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "wooden Indian", "John Francis Kelly", "early Romantic period", "$700 million", "the Sun", "Bhushan Patel", "1692", "interstate commerce", "The Wu-Tang Clan", "Kids", "Mortal Kombat", "Kew Gardens", "third season", "May 2016", "Kristy Swanson", "colonel", "Conan Doyle", "scalene", "put a lid on the marking of Ashura", "Pakistan", "homicide", "bread pudding", "leather", "cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8318339646464648}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3971", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-447", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-2482", "mrqa_triviaqa-validation-2789", "mrqa_newsqa-validation-1218"], "SR": 0.734375, "CSR": 0.5529961340206185, "EFR": 0.8235294117647058, "Overall": 0.7096801091570649}, {"timecode": 97, "before_eval_results": {"predictions": ["Eddie Redmayne", "the Caucasus range", "David Bowie", "Steve Davis", "Granada", "Treaty of Brest-Litovsk", "Karl Marx", "Procol Harum", "Marilyn Monroe", "fish", "1957", "1876", "transsexual", "Fred Astaire", "Edinburgh", "Scotland Yard detective", "The island", "loving and giving", "innie Mae", "Rudyard Kipling", "1921", "Trainspotting", "Emilia", "avocate", "Frans Hals", "New Democracy", "Ford", "soybean", "Cole Porter", "1826", "William WymarkJacobs", "the Parthenon", "Paddy Doherty", "Thomas Aquinas", "Dubonnet Rouge Aperitif", "an elephant", "Tigran Petrosyan", "asthma", "Westminster Abbey", "Canada", "Seal", "Edward VII", "Tombstone", "Sardinia", "Timbuctoo series of 25 books, John Mouse and the Roundy and Squarey books", "Worcester Cathedral", "Mercury", "December 7, 1941", "the stapes", "Nadia Comaneci", "Neil Armstrong", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "Electronic Attack Squadron 135", "95 AD", "more than 170", "\"The Frisky\"", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "1922 to 1991"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6375}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, true, true, true, false, false, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, true, true, true, true, true, false, true, false, false, true, false, false, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-6617", "mrqa_triviaqa-validation-3031", "mrqa_triviaqa-validation-5738", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-329", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3100", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.5625, "CSR": 0.5530931122448979, "EFR": 0.6428571428571429, "Overall": 0.6735650510204081}, {"timecode": 98, "before_eval_results": {"predictions": ["sent an e-mail to reporters Wednesday with the subject line \"Vice presidential...\"", "Afghanistan's", "deutschneudorf", "suspects allegedly involved in forged credit cards and identity theft led authorities to a $13 million global crime ring,", "his health and about a comeback.", "poems", "then-Sen. Obama", "a woman", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Former Mobile County Circuit Judge Herman Thomas", "celebrities and ministers, ranging from Yolanda Adams to Bishop T.D. Jakes to Kirk Franklin.", "Iraq's autonomous region of Kurdish.", "Phillip A. Myers.", "I stopped at a small station on First Street, WAHR. The guy in charge liked my voice. \"We get a lot of people coming and going,\"", "share personal information.", "London and Buenos Aires", "in his 60s,", "Iraqi Prime Minister Nouri al-Maliki", "Egypt", "He was incredible. We've had so much rain, and yet today it was beautiful. The rain held off wherever Muhammad Ali went,\" Frankie Neylon, the town's mayor said.", "Jennifer Arnold and husband Bill Klein,", "Pacquiao returned home to a hero's welcome in his native Philippines on Friday after wresting the WBO welterweight title from Miguel Cotto on a 12th round technical knockout in Las Vegas.'", "Austin, Texas,", "15-month investigation, at least a part of which was conducted undercover.\"", "him to be included in the family allowance.", "Manmohan Singh's", "the war of words", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "Bill Haas", "Consumer Reports magazine", "28", "step up.\"", "42 years old", "since 1983.", "improve health and beauty.", "almost 100", "Espinoza", "Derek Mears", "\"By working together, we will set wise and effective policies.\"", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "18th", "Haeftling", "on the table or, more formally, may be kept on a side table", "Asuka", "Bart Millard", "Nissan", "stone arch bridges", "Jane Austen", "Marx Brothers film", "Indian", "early 20th-century Europe", "a hostage", "Shakespeare in Love", "w. Somerset maugham", "leicestershire"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6204629360428834}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.23728813559322035, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.38095238095238093, 0.8333333333333333, 0.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 0.0, 0.923076923076923, 0.19354838709677416, 1.0, 0.18181818181818182, 0.15384615384615383, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.5, 1.0, 0.13333333333333333, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-3008", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-2549", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-2967", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2745", "mrqa_newsqa-validation-2541", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-14191"], "SR": 0.484375, "CSR": 0.5523989898989898, "EFR": 0.7878787878787878, "Overall": 0.7024305555555556}, {"timecode": 99, "UKR": 0.765625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.8203125, "KG": 0.5453125, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "Mach number", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota, United States", "most performed song of all time", "Oregon State Beavers", "Arkansas", "2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "Grandmasters", "Broadcasting House in London", "London Tipton", "Barney Miller", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "The Heirs", "Saturday Night Live", "strongly associated with Gaia and Cybele,", "Tumi Holdings, Inc.", "Black Ravens", "commercial", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Nelson County", "Kang", "25 million", "Athenion", "James G. Kiernan", "Fred &quot", "James City County", "Tunisian", "Linda Ronstadt", "the United Kingdom", "August 19, 2013", "the Americas and the entire South American temperate zone", "Sister, Sister", "five", "Alex Turner, Bill Bailey, Pete Shelley, Paul Farley, Steve Coogan, Mark Radcliffe, Craig Charles, Plan B, Kate Nash, Miranda Sawyer and Paul Morley", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "The term was first used in tennis, and is based on the idea of laying out a tournament ladder by arranging slips of paper with the names of players on them the way seeds or seedlings are arranged in a garden", "Zappa", "1991 model year", "apples", "Fred Trueman", "Scotland", "Chesley", "Fernando Torres", "Friday,", "Lifeboat", "a kilobytes", "stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6858067024886878}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.3333333333333333, 0.25, 0.0, 0.0, 0.07692307692307691, 1.0, 1.0, 0.6666666666666666, 0.7647058823529412, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-1798", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-2863", "mrqa_naturalquestions-validation-934", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2083", "mrqa_searchqa-validation-572"], "SR": 0.5625, "CSR": 0.5525, "EFR": 0.9285714285714286, "Overall": 0.7224642857142858}]}