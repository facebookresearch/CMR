{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=20_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=100.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=20_l2w=100_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8300, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.9333333333333333, "Overall": 0.8494791666666667}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "isomorphic", "Daniel Burke", "the highest terrace", "major national and international patient information projects and health system interoperability goals", "three", "net force", "12 January", "1976\u201377", "E. W. Scripps Company", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "coordinating lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "main hall", "the Teaching Council", "One could wish that Luther had died before ever [On the Jews and Their Lies] was written", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM", "optimisation", "2014", "late 1970s", "30% less", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "teachers in publicly funded schools", "Stanford University Professor of Comparative Literature Richard Rorty", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "appellate courts are also called appeals courts, courts of appeals, superior courts, or supreme courts", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8206106635237826}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09090909090909091, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-3352", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.765625, "CSR": 0.765625, "EFR": 0.8666666666666667, "Overall": 0.8161458333333333}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "P", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "reverse direction", "7 West 66th Street", "patent archives", "Any member", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "second use of the law", "free", "1973", "1971", "Mansfeld", "Warsaw Stock Exchange", "390 billion individual trees divided into 16,000 species", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "13 May 1899", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification that occurs following sequential proteolytic activation of complement molecules", "Lituya Bay in Alaska", "120 m ( 390 ft )", "the eighth season will have only six episodes", "100 members", "photoelectric", "Welch, West Virginia", "Independence ( Purna Swaraj ) was proclaimed by the Indian National Congress", "twelve Wimpy Kid books have been released, plus one do - it - yourself book and two movie diaries", "Hal David and Burt Bacharach", "five points", "The Monitor and Merrimac", "Spain"], "metric_results": {"EM": 0.6875, "QA-F1": 0.779767101045884}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 0.3076923076923077, 1.0, 0.888888888888889, 0.4444444444444445, 1.0, 0.4, 1.0, 0.4736842105263158, 1.0, 0.0, 0.5, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1759", "mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1454", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_squad-validation-6645", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.6875, "CSR": 0.7395833333333333, "EFR": 0.85, "Overall": 0.7947916666666666}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "the principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "Abercrombie was recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "spy network and Yam route systems", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "Calvin cycle", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw)", "cloud storage", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Bud '' Bergstein", "Janie Crawford", "it extends from the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "Inney Hull ( James Frain ), the surly librarian who looks after his alcoholic sister Mary Elizabeth ( Margaret Hoard )", "In October 1973, the price was raised to $42.22", "the land itself, while blessed, did not cause mortals to live forever", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7627976190476191}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.16666666666666669, 0.0, 1.0, 0.4, 0.2, 0.13333333333333333, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.671875, "CSR": 0.72265625, "EFR": 0.9047619047619048, "Overall": 0.8137090773809523}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Presque Isle", "wireless", "Coldplay", "the Yuan dynasty", "same-gender marriages with resolutions", "red algae red", "after their second year", "1960s", "that narcotic drugs were controlled in all member states, and so this differed from other cases where prostitution or other quasi-legal activity was subject to restriction", "Napoleon", "Immunology", "geophysical surveys", "topographic", "130 million cubic foot (3.7 million cubic meter)", "50 fund", "Conflicts between the colonies, accomplished through raiding parties that included Indian allies, had taken place for decades, leading to a brisk trade in European colonial captives from either side.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "struggle, famine, and bitterness among the populace", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "Cisco Systems", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "a thylakoid", "University College London", "to protect their tribal lands from commercial interests", "religious beliefs", "the spirit of protest should be maintained all the way, whether it is done by remaining in jail, or by evading it", "the kettle and the Cricket", "Gandhi", "The first written mention of this capital's name was in a 1459 document of Vlad the Impaler", "\"Take us the foxes, the little... Alexandra - first cousins - as a means of getting Horace's money", "The first US-market Betamax video recorder, the 1982 Sony SL-2000 portable", "Vincent van Gogh, in which Nimoy played Van Gogh's brother Theo.", "16/3, 18/3", "the Story of Tiger Woods' 1996 U.S. Amateur Win - Golf.com  Aug 16, 2012", "It was Arizona's territorial capital from 1867 to 1877, and a university was founded there in 1885.", "the title \"Marshal Dillon\"", "They come from our heartJi, from our...   14 - American Radio History  Mar 14, 1997", "The Best Hotels on Bali", "The new nightspot Teddy's made this presidential Hollywood hotel a happening", "Light Amplification by Stimulated Emission by radiation", "Jean Dapra", "Saturn", "Hundreds of species of peat mosses are found in bogs throughout Canada", "Why", "Daya", "Amaxophobia- Fear of riding in a car.", "American", "Mexican military"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6516118838269573}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.17647058823529413, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 1.0, 0.0, 0.2666666666666667, 0.19999999999999998, 0.3076923076923077, 0.0, 0.2857142857142857, 0.0, 0.0, 0.0, 0.4, 0.1818181818181818, 0.25, 0.0, 0.0, 0.15384615384615385, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-10204", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-5214", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-9448", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073"], "SR": 0.53125, "CSR": 0.684375, "EFR": 0.8, "Overall": 0.7421875}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "fell from his horse while hunting", "the member state cannot enforce conflicting laws", "Graham Twigg", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely", "Europe", "he was illiterate in Czech", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center in San Jose", "Variable lymphocytes receptors (VLRs)", "Edict of Fontainebleau", "Levi's Stadium", "ten million", "the Lippe", "Video On Demand content", "time and storage", "semester", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence", "League of the Three Emperors", "the field of science awarded by universities in many countries", "143,007", "Bill Clinton", "Waltham Abbey", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.", "Thomas Christopher Ince", "American Chopper", "drawn the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Br'er Rabbit", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.71875, "QA-F1": 0.8009128891941392}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3846153846153846, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.8000000000000002, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-6218", "mrqa_squad-validation-4919", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-4573", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.71875, "CSR": 0.6901041666666667, "EFR": 0.9444444444444444, "Overall": 0.8172743055555556}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the Court of Justice of the European Union", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "overthrow a government", "entertainment", "A vote clerk", "high growth rates", "vicious and destructive", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools on the South Side of Chicago", "the means to invest in new sources of creating wealth", "Spanish", "Structural geologists", "president and CEO", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Ben Johnston", "Sinclair Oil Corporation", "Taylor Swift", "Eric Edward Whitacre", "Joint Chiefs of Staff", "Linux Format", "Jasenovac", "Rabat", "aged between 11 or 13 and 18", "Heather Langenkamp", "Henry Moseley", "paracyclist", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk, England", "Charmed", "Lily Hampton", "Liverpool and England international player", "Philadelphia Eagles", "Rickie Lee Skaggs", "48,982", "Ashanti", "73", "Algeria", "a novel", "the Eastern part", "Polar Bears", "Atlantic City"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7619414592760181}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.2, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 0.923076923076923, 1.0, 1.0, 1.0, 0.8, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3939", "mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-7983", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_naturalquestions-validation-2159", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-5279", "mrqa_searchqa-validation-1971"], "SR": 0.65625, "CSR": 0.6852678571428572, "EFR": 0.9545454545454546, "Overall": 0.8199066558441559}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "the working fluid", "a suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "the solution", "those who already hold wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "canalized section", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "northern (German) shore of the lake", "computer programs", "The General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "single-tape", "Bart Starr", "lung tissue", "the Karluk Kara-Khanid ruler", "Perth, Western Australia", "Ian Rush", "John Hume", "New Orleans Saints", "2016", "four operas", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "A. E. Housman", "capital of the Socialist Republic of Vietnam", "Sevens", "fennec fox", "Bart Conner", "fantasy", "Martin \"Marty\" McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Ray Looze", "140 to 219 passengers", "the \"Father of Liberalism\"", "Garth Jennings", "Pablo Escobar", "African", "Mexico City", "Sleeping Beauty", "PeopleMover", "1985", "Doddi in Iceland, Purzelknirps in Germany and Hilitos in Spain", "Ali Bongo", "Walmart.com", "Ray Harroun", "Drew Barrymore", "David Tennant"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7319444444444444}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-9287", "mrqa_squad-validation-3496", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_newsqa-validation-3925", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.703125, "CSR": 0.6875, "EFR": 0.9473684210526315, "Overall": 0.8174342105263157}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "Revolutionary", "lower heat addition temperature", "Lunar Excursion Module", "Zwickau prophets", "six years", "700", "the 5th Avenue laboratory fire", "arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "the constituting General Conference in Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "jet-powered tailless delta wing", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Ulli Lommel", "Ai-Ling Lee", "Miss Universe 2010", "Adam Amin", "boxer", "Boston University", "Fulham", "A55", "Ranulf de Gernon", "\u00c6thelstan", "Special economic zone", "44", "NCAA's Division I", "Harriet Tubman", "Manchester United", "Hong Kong", "Greek-American", "diastema", "Shirley Horn", "Israel", "Bigfoot", "Papua New Guinea", "Renoir", "Manchester"], "metric_results": {"EM": 0.625, "QA-F1": 0.699113906926407}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 0.6666666666666666, 0.0, 0.3636363636363636, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3391", "mrqa_squad-validation-1501", "mrqa_squad-validation-7643", "mrqa_squad-validation-5972", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-524", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_hotpotqa-validation-1198", "mrqa_naturalquestions-validation-3553", "mrqa_triviaqa-validation-3170", "mrqa_newsqa-validation-1268"], "SR": 0.625, "CSR": 0.6805555555555556, "EFR": 0.75, "Overall": 0.7152777777777778}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "centrifugal governor", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "unpaired electrons", "French", "Museum of the Moving Image in London", "he sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "civil disobedients", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "pivotal event", "an American YouTube personality, spokesmodel, television personality, and LGBT rights activist", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "actor, singer and a DJ", "Prince Amedeo, 5th Duke of Aosta", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia, the Disneyland Monorail, and the Motor Boat Cruise", "Yasir Hussain", "USC Marshall School of Business", "Stephen Ireland", "Marco Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "2500 ft", "Central Park", "Robert John Day", "The Berber languages", "James Tinling", "Italy", "2015 Masters Tournament", "Ulver and the Troms\u00f8 Chamber Orchestra", "Sullivan University College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "a North African dish of small steamed balls of semolina, usually served with a stew spooned on top", "more than 22 million people in sub-Saharan Africa", "morphine sulfate oral solution 20 mg/ml", "The Firm (1993 film)", "a freshwater, airbreathing catfish"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6564213177516665}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-4147", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-1037", "mrqa_hotpotqa-validation-5477", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_hotpotqa-validation-4960", "mrqa_naturalquestions-validation-10208", "mrqa_triviaqa-validation-2522", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-3622"], "SR": 0.5625, "CSR": 0.66875, "EFR": 0.8571428571428571, "Overall": 0.7629464285714285}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "consumes ATP and oxygen, releases CO2, and produces no sugar", "Panthers", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "not covered in any newspapers", "arrows, swords, and leather shields", "Cybermen", "to attend school at the Higher Real Gymnasium", "Standard Model", "\u00d6gedei", "Rhine-Ruhr region", "lesson plan", "Prevenient grace", "Kansas State", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "World War II", "NCAA Division I", "The The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "Russell Humphreys", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germany and other parts of Central Europe", "New Jersey", "Bath, Maine", "Ector County", "Jim Davis", "Buck Owens", "World Health Organization", "Emmanuel Ofosu Yeboah", "Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the Halle Orchestra", "Sir Giles Gilbert Scott", "the first sign of trouble was when drilling \"mud\" -- a mixture used to pressurize and lubricate the drills", "Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "One Hundred Dollars a Month"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7813198368975985}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 0.9090909090909091, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 0.0, 0.0, 1.0, 0.23255813953488372, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-6927", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.671875, "CSR": 0.6690340909090908, "EFR": 0.9523809523809523, "Overall": 0.8107075216450216}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "Spanish", "100\u2013150", "Philo of Byzantium", "cooler", "marine waters worldwide", "$60,000 in cash and stock", "his mother's genetics and influence", "shock", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "a new element to the standard Christian suspicion of Judaism", "the building is ready to occupy", "boom-and-bust cycles", "Edinburgh", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "a 10 mile-per-gallon guzzler when gas jumps back to $4 a gallon", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations", "body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "Paul McCartney and Ringo Starr", "deciding the duties of the new prime minister has been a sticking point in the negotiations", "a great deal of circumstantial evidence, and this is a physical evidence case", "200", "a few reasons why the number of students getting into drugs is bigger and also getting younger and younger", "opposition party members", "Missouri", "\"Racism and racist conversations have no place today in America.\"", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "The station", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "in her home", "the Employee Free Choice act", "Bush administration", "more than 200", "This is not a project for commercial gain", "best-of-three series", "Kaka", "his Japanese ex-wife", "Dan Parris, 25, and Rob Lehr, 26", "apartment near Fort Bragg in North Carolina", "two", "The federal government has set aside nearly $2 billion in stimulus funds to clean up Washington State's decommissioned Hanford nuclear site", "Jacob", "Molotov cocktails, rocks and glass", "250,000", "Winehouse", "the Ark of the Covenant ( the Aron Habrit in Hebrew )", "Jean F Kernel ( 1497 -- 1558 )", "The truth was, that as she now stood excited, wild, and honest as the day, her alluring beauty bore out so fully the epithets he had bestowed upon it", "Richmond", "1994", "The Conjuring", "the Anzac Day", "a surface area of 23,000 square miles", "Nowhere Boy"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6579460884827733}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4, 1.0, 0.33333333333333337, 1.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.8333333333333333, 1.0, 0.2608695652173913, 1.0, 1.0, 0.0, 0.0, 0.6, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1313", "mrqa_squad-validation-1257", "mrqa_squad-validation-2493", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.5625, "CSR": 0.66015625, "EFR": 0.8214285714285714, "Overall": 0.7407924107142857}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British", "wealth", "God's grace (which cannot be earned) alone can make them just.", "Napoleon", "mass production", "James O. McKinsey", "private actors", "Bell Northern Research", "a body of treaties and legislation, such as Regulations and Directives, which have direct effect or indirect effect on the laws of European Union member states.", "1227", "lower lake", "three", "Elders", "227,000", "Private Bill Committees", "Bruno Mars", "the Catechism", "Stagg Field", "Ian Botham", "Pyotr Tchaikovsky", "Kawasaki", "Srenchie", "Salvador Allende", "Marie Antoinette", "Redmond, United States", "Erik Thorvaldson", "Apollo", "the 1940 Rodgers and Hart musical Pal Joey", "Mary Jane Grant", "Green", "Indonesia", "Moses", "Antonio", "European Economic Community (EEC)", "Christine Keeler", "Yehoshua", "Jack Nicholson", "four", "Netherlands", "\"Sugar Baby Love\"", "Rosa Parks", "Sean", "Bill and Taffy Danoff", "beginning at Stage 1 when a sperm fertilizes an oocyte and together they form a zygote", "Travis", "The Show", "Robert Kennedy", "Q", "umbrella", "Hobbies", "barber", "Rod Laver", "Murrah Federal Office Building", "Evita", "tobacco", "fortified complex at the heart of Moscow, overlooking the Moskva River to the south, Saint Basil's Cathedral and Red Square to the east, and the Alexander Garden to the west", "bohrium", "Duchess Eleanor of Aquitaine", "Mickey Gilley", "get four successful women together on a movie set and you'd think it's all claws, all the time.", "a delegation of American Muslim and Christian leaders", "Royal Wives", "Columbia", "Kim Clijsters"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6182167658730159}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.12500000000000003, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.4, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 1.0, 0.125, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-4257", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6696", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_naturalquestions-validation-4905", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_searchqa-validation-5929", "mrqa_newsqa-validation-1150"], "SR": 0.578125, "CSR": 0.6538461538461539, "EFR": 0.7037037037037037, "Overall": 0.6787749287749287}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Bo'orchu", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "in order to counteract the constant flooding and strong sedimentation in the western Rhine Delta", "Wesleyan Holiness Consortium", "Maxwell", "in whole by charging their students tuition fees", "Dublin, Cork, Youghal and Waterford", "Tangled", "jure", "moles", "leucippus", "muri (The Full Wiki)", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "jazz tenor saxophonist", "one/6", "komando Pasukan Khusus", "Carlisle", "liquid carbon dioxide", "Chillicothe and Zanesville", "Lucas McCain", "Antarctica", "mercury gilding", "aniridia", "stearns Eliot", "River Forth", "woe", "NOW Magazine", "j Jesse James", "Italy", "Canada", "typhoid fever", "Pavarotti", "action figure", "Joe Willie Kirk", "2010", "einasto's law", "Venezuela", "altinge Burlesque Theater in New York City in 1935", "temperature inversion", "40", "f J Gall and J K Spurzheim", "San Francisco", "Fall 1998", "Marcus Atilius Regulus", "Chris Weidman", "Athletics Stadium", "one", "Virgin America", "Nate O'Reily", "handouts", "Iran's parliament speaker", "English Premier League Fulham produced a superb performance in Switzerland on Wednesday to eliminate opponents Basel from the Europa League with a 3-2 victory."], "metric_results": {"EM": 0.46875, "QA-F1": 0.5149621212121211}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, false, false, true, false, false, true, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0909090909090909]}}, "before_error_ids": ["mrqa_squad-validation-6078", "mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-1142", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-3093", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-1733", "mrqa_naturalquestions-validation-5675", "mrqa_hotpotqa-validation-1390", "mrqa_hotpotqa-validation-2463", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.46875, "CSR": 0.640625, "EFR": 0.7647058823529411, "Overall": 0.7026654411764706}, {"timecode": 14, "before_eval_results": {"predictions": ["in an adult plant's apical meristems", "Tugh Temur", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically", "Aristotle", "St. George's Church", "Missy", "Strathclyde Regional Council debating chamber in Glasgow", "public official", "the most cost efficient bidder", "acorn", "continental time zone", "femur", "Olympia", "Ukraine", "shrew", "Teri Hatcher", "a hopeful miner", "amber", "Princeton University", "The executioner's Song", "galaxy", "almaty", "anamosa", "grouchy", "The Comedy of Errors", "Camelot--Camelot", "television", "knife", "glinding light", "Cologne", "Leadership Academy for Girls", "an ingot", "Kosovo", "James Jeffords", "Prague", "tennis", "silk", "cowboys", "Winston Churchill", "Key deer", "Japan", "King of the Hill", "thant", "NASCAR", "windjammer", "columbus", "stanoma State University", "Augusta", "counter clockwise", "2013", "Nick Hornby", "Coldplay", "December 24, 1973", "David Weissman", "bikinis", "the Dalai Lama", "memories of his mother", "Israel"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5354166666666667}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, true, false, true, true, false, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2105", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-10459", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_naturalquestions-validation-325", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-3084"], "SR": 0.46875, "CSR": 0.6291666666666667, "EFR": 0.7941176470588235, "Overall": 0.7116421568627451}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling back his initial losses and returning the balance to his family", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "Rhenus", "1996", "wine", "German-Swiss", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "a violinist", "Cuba Gooding Jr.", "Strongsville, Ohio", "flemish", "Mastercard Worldwide", "Roger B. Smith", "Nashville", "cranial nerve", "Ivan the Terrible", "Nancy Astor", "lentigo senilis", "a casino", "Toronto Maple Leaf", "a marvelous housekeeper", "the Moscow Art Theatre", "Delaware", "sugarcane", "(Harry) Angstrom", "Johann Strauss II", "joey", "pro bono", "the Universit degli Studi di Siena", "The Fun Factory", "a pale ale", "Anthony Fokker", "Nacho Libre", "copper", "black magic or of dealings with the devil", "cucumbers", "Dr. Jeffrey Wigand", "poetry", "a sesame seed bun", "a meager allowance", "1942", "blimps", "Robert Bunsen", "a geisha", "Bigfoot", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "ThonMaker", "a tin star", "\"black\"", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6005208333333333}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.5, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1325", "mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-14722", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-12372", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-13453", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-7531", "mrqa_searchqa-validation-5375", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-12150", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-14698", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_newsqa-validation-2036"], "SR": 0.484375, "CSR": 0.6201171875, "EFR": 0.7575757575757576, "Overall": 0.6888464725378788}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "the late 1920s", "\u00a31.3bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Weser River", "in an open casket", "Ho Chi Minh", "circumference", "the Inuit", "Detroit", "the Toronto Blue Jays", "Lincoln", "Ray Bradbury", "crimes committed out of hatred for someone's race", "King Julien", "Nicolas Sarkozy", "Rubicon", "Sanjaya", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "Jesus Christ", "The Prince and the Pauper", "Crystal Pepsi", "Hillary Clinton", "(Errol Lincoln)", "Bellerophon", "Balaam", "business", "The Caine Mutiny", "Rolling Stone", "(founded 1932)", "(John) Coltrane", "peace sign", "oxygen", "Sphinx", "Jan Hus", "USA Network's original grassroots talent search", "Sugar", "Eugene Onegin", "Macy's Christmas Parade", "cotton-spinning machine", "(H0H 0H0)", "( Julius Caesar)", "negligence", "judges", "attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "between 11 or 13 and 18", "Michoacan Family", "prisoners", "his salary", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan."], "metric_results": {"EM": 0.53125, "QA-F1": 0.601820054945055}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, true, true, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.2, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.23076923076923078]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-11817", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-9150", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-858", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13667", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_newsqa-validation-1759"], "SR": 0.53125, "CSR": 0.6148897058823529, "EFR": 0.8, "Overall": 0.7074448529411765}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Robert Lane and Benjamin Vail", "ring", "Party of National Unity", "22", "Dauphin", "Phillip Marlowe", "piracy", "Roger Clemens", "Jesse Jackson", "the Philippines", "The Mausoleum", "The World Through More Than One lens", "Switzerland", "Deutsche Lufthansa", "The Old Man and the Sea", "French", "Joe Louis", "lion", "d'Artagnan", "the Bayeux Tapestry", "a covered shelter", "China", "Sunni", "notes placed at the bottom of a page", "Stephen Hawking", "Cicero", "Memphis", "Mountain Dew", "Blanche DuBois", "Quilt Crazy", "FRAM", "House of Representatives", "Labatt Brewing Company", "Michael Moore", "Oman", "Chevy", "Ingenue", "Pennsylvania", "Don Juan", "Ian Fleming", "Headless Horseman", "London", "Yellowstone National Park", "Ronald Reagan", "Fiddler on The Roof", "Ethiopian", "six", "1992", "pH", "Bromley-By- Bowen", "Kree", "John R. Dilworth", "Caylee Anthony", "know what's important in life", "\"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "nuclear", "The Stooges"], "metric_results": {"EM": 0.625, "QA-F1": 0.671875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1295", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-7710", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-5228", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-14873", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-9270", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_hotpotqa-validation-3692", "mrqa_hotpotqa-validation-3449", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-4110"], "SR": 0.625, "CSR": 0.6154513888888888, "EFR": 0.9166666666666666, "Overall": 0.7660590277777777}, {"timecode": 18, "before_eval_results": {"predictions": ["Super Bowl XXXIII", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "complexity", "same-gender marriages", "2006", "the mid-18th century", "hollandaise", "A Raisin in the Sun", "Sistine Chapel", "Belarus", "a spread formation", "a trowel", "Big Bang", "Sex Pistols", "endodontist", "Saturn", "the Cliffs of Dover", "Genoa", "Fanchette", "Jersey Boys", "the door of the Castle Church in Wittenberg", "Indiana", "Ozone", "a rose", "pho- a popular Vietnamese dish", "21", "the Civil War", "alevin", "Paul McCartney", "omega-3", "a lion", "Bachman Turner Overdrive", "VOD", "Outta nowhere", "Tokyo", "Panama", "Wynonna Ellen", "Narnia", "Finnegans Wake", "Wordsworth", "Norway", "the bear", "a quake", "betraying the Son of Man", "elephants", "Mazur", "Denmark", "covert operations", "Our Country", "May 2010", "the International Space Station", "Sugarloaf Mountain", "Thailand", "gender queer", "Minister for Social Protection", "Berga", "the estate", "McFerrin, Robin Williams, and Bill Irwin", "ase", "Michigan and surrounding states and provinces"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5501132246376812}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.1739130434782609]}}, "before_error_ids": ["mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-5208", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-3298", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.453125, "CSR": 0.606907894736842, "EFR": 0.8285714285714286, "Overall": 0.7177396616541354}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "plants that are biologically contained", "Earth", "53,000", "one", "poet", "two points", "20,000", "the kip", "skeletal muscle and the brain", "2014", "peptide bonds", "Montreal", "Sunday evenings", "egg", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "Arousal regulation", "Charlene Holt", "Buffalo Bill", "1991", "electron shells", "The Cornett family", "acid rain", "October 22, 2017", "inefficient", "he cheated on Miley", "2001", "flawed democracy", "735 feet", "1871", "Rick Rude", "Ohio", "a form of business network", "a cylinder of glass or plastic that runs along the fiber's length", "James Hutton", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Necator americanus and Ancy lostoma duodenale", "March 1", "The Lykan Hypersport", "the American Civil War", "oxidized by a series of respiratory integral membrane proteins with sequentially increasing reduction potentials with the final electron acceptor being oxygen", "Cecil Lockhart", "Mara Jenna", "British and French Canadian fur traders", "semi-autonomous organisational units", "Lou Rawls", "Hermia", "Jupiter", "east", "15", "John Robert Cocker", "Israel", "puzzle video game", "a palace", "nervus olfactorius", "Eucalyptus", "an elephant", "oxygen"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6385044642857143}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.8571428571428572, 1.0, 0.2, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-8339", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-2379", "mrqa_searchqa-validation-12372", "mrqa_triviaqa-validation-2227"], "SR": 0.546875, "CSR": 0.60390625, "EFR": 0.8620689655172413, "Overall": 0.7329876077586206}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "more than 70", "death of a heretic", "His Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer in five vignettes", "well over 1,000 pounds", "Egyptian security", "Mutassim", "Oklahoma", "Polo", "Joe Jackson", "Amstetten", "computer problems", "Silvan Shalom", "Climatecare", "Steve Wozniak", "12-hour-plus shifts", "Brad Blauser", "September", "consumer confidence", "5:20 p.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian", "India", "1964", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "all of Lifeway's 100-plus stores nationwide", "chief executive officer", "there's no chance of it being open on time", "urbina scheduled an October 16 hearing for immigration officials and other government agencies to discuss conditions for the 17 men.", "Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "Michael Schumacher", "Gustav", "gun", "Henrik Stenson", "asylum", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military", "two years", "1966", "winter", "Whitsunday", "Aberdeen", "\"Dumb and Dumber\"", "Nokia Sugar Bowl", "Earl Warren", "converging lens", "autu", "season five", "The Force ( 2015 )"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5968164061224723}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, true, false, true, true, false, true, true, false, true, true, false, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.4, 1.0, 0.8750000000000001, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.18181818181818182, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.058823529411764705, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2466", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2368", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-2301", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_naturalquestions-validation-7266", "mrqa_triviaqa-validation-3457", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.484375, "CSR": 0.5982142857142857, "EFR": 0.7272727272727273, "Overall": 0.6627435064935066}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers", "El Centro", "chief electrician", "Newton", "static friction", "the assassination of US President John F. Kennedy", "Kenya's territorial sovereignty.", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Kenneth Cole", "a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "\"no more than an official of the most tyrannical dictatorial state in the world.", "\"Maude\"", "Climatecare, one of Europe's most experienced providers of carbon offset,", "Wednesday", "Cash for Clunkers", "Bobby Jindal", "9:20 p.m. ET Wednesday", "Venus Williams", "Mashhad", "Amanda Knox's aunt", "great jazz", "$17,000", "Barney Stinson", "Luiz Inacio Lula da Silva", "his father's parenting skills", "two", "Bill", "J.G. Ballard", "Dr. Conrad Murray", "Sarah Brown", "planning for life after baseball", "1981", "17 Again", "Nigeria", "$81,88010", "Republicans", "EU naval force", "Chris Robinson", "Bongo", "steam-driven, paddlewheeled overnight passenger boat", "Hyundai Steel", "a single gene for their type of skeletal dysplasia,", "London Heathrow's Terminal 5", "canceled the swimming privileges", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military strike", "The White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"The Expendables 2\" (2008)", "The Kingdom of Northumbria", "Ophelia", "an iron fist", "Argentinian", "Mercedes-Benz Superdome", "Eduard Leopold"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6004541031884782}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 1.0, 0.125, 0.5454545454545454, 0.0, 0.0, 0.9, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-2036", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3926", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-251", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-1056"], "SR": 0.484375, "CSR": 0.5930397727272727, "EFR": 0.8484848484848485, "Overall": 0.7207623106060606}, {"timecode": 22, "before_eval_results": {"predictions": ["X-rays", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia, especially.", "two", "glowed even when turned off", "five female pastors", "resources", "sovereignty over them.", "April 6, 1994", "Prague", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "a federal judge in Mississippi", "the department has been severely affected by the earthquake, with thousands of officers injured, killed or unaccounted for.", "22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery in eastern England.", "\"Slumdog Millionaire\" (No. 4)", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide", "a president who understands the world today, the future we seek and the change we need.", "the commissions", "Kase Ng", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain", "male veterans struggling with homelessness and addiction.", "ancient rituals in Olympia,", "Harare", "No. 1 slot", "nine", "ash and rubble", "Friday", "The tower will be built in the Saudi town of Jeddah and will be part of a larger project that will cost $26.7 billion", "a Muslim with Lebanese heritage,", "two contestants.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Alwin Landry's supply vessel Damon Bankston", "researchers", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning -- the FDA's strongest -- to alert patients of possible tendon ruptures and tendonitis.", "84-year-old", "Robert Park", "Rima Fakih", "the Isthmus of Corinth", "Nalini Negi", "2017 ( 2017 - 12 - 10 )", "Runcorn", "collarbone", "the geographic horizon", "UFC 50  UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "Ibiblio"], "metric_results": {"EM": 0.390625, "QA-F1": 0.540737552865394}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, false, false, false, false, false, false, true, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.20000000000000004, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.19999999999999998, 0.967741935483871, 1.0, 0.6086956521739131, 1.0, 1.0, 0.5714285714285715, 0.4, 0.4444444444444445, 1.0, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-2760", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1418", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.390625, "CSR": 0.5842391304347826, "EFR": 0.6410256410256411, "Overall": 0.6126323857302118}, {"timecode": 23, "before_eval_results": {"predictions": ["phycobilin phycoerytherin", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma", "56", "Yemen", "2005", "Karen Floyd", "Four Americans", "those missing", "Haiti", "Susan Boyle", "Saturday just hours before he was scheduled to perform at the BET Hip Hop Awards.", "Spain", "Jared Polis", "Janet and La Toya, and brother Randy Jackson", "Dangjin", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding was so fast that the thing flipped over", "threatening messages", "Noriko Savoie", "Citizens are picking members of the lower house of parliament, which will be tasked with drafting a new constitution after three decades of Mubarak's rule.", "fake his own death", "\"in the interest of justice.\"", "martial arts", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "then-Sen. Obama", "Congress", "curfew", "Anne Frank, whose account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "once on New Year's Day and once in June, to mark the queen's \"official\" birthday.", "The alleged surviving attacker from last month's Mumbai terror attacks is seeking help from Pakistani officials, India", "Zuma", "haute, bandeau-style little numbers", "nine", "al-Maliki", "September 11, 2001", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed", "Desmond Tutu", "$17,000", "Jobs", "$81,88010", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "a transformiation, change of mind, repentance, and atonement", "Jason Lee", "phase of sleep", "substantive", "Kent", "beer and soft drinks", "five aerial victories.", "Cherokee River", "Snowball", "NASA", "Florida"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6149320144724557}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, false, true, false, true, true, true, true, true, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.13333333333333333, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.08333333333333333, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.058823529411764705, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10100", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2067", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3039", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-4199", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458", "mrqa_searchqa-validation-10787"], "SR": 0.546875, "CSR": 0.5826822916666667, "EFR": 0.7241379310344828, "Overall": 0.6534101113505748}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "The Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "Lindsey Vonn", "WTA Tour titles at Strasbourg and Bali prior to Madrid", "him to step down as majority leader.", "The EU naval force", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offset,", "The Louvre", "his club", "will be at the front of the line, self-righteously driving under the speed limit on his or her way to save the world.", "1979", "Heshmat Tehran Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector", "Bangladesh's southern Bhola district.", "Michael Arrington, founder and former editor of Tech Crunch, and Vivek Wadhwa,", "one out of every 17 children under 3 years old in America", "President Sheikh Sharif Sheikh Ahmed", "Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent", "military personnel", "behind the counter.", "11 healthy eggs", "one Iraqi soldier,", "Michael Partain,", "her fianc\u00e9,", "racial intolerance.", "animal products.", "El General", "Symbionese Liberation Army", "8.8 million", "work together to stabilize Somalia and cooperate in security and military operations.", "compromise the public broadcaster's appearance of unbiasedity.", "black is beautiful", "1905, in May 2004.", "Picasso's muse and mistress, Marie-Therese Walter.", "NATO to provide alternative work for poor Afghan farmers to encourage them to give up opium production.", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "off the coast of Dubai", "fallen comrades lost in the heat of battle.", "District of Columbia near Takoma Park, Maryland.", "27 Awa", "Mark Obama Ndesandjo", "The premier of \"Dance\" rated highly for Oxygen, with more than 1 million viewers tuning in.", "Russian residents and worldwide viewers, in English or in Russian, what they think about Russia's role in the international community.", "Buster Keaton", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "the division of Italy into independent states, the restoration of the Bourbon kings of Spain, and the enlargement of the Netherlands to include what in 1830 became modern Belgium", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1 Team", "Viscount Cranborne", "Disneyland theme park in Anaheim, California", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5578390707395207}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.4, 0.06896551724137931, 1.0, 0.4, 1.0, 1.0, 0.0, 0.2857142857142857, 0.23529411764705882, 0.33333333333333337, 0.06666666666666667, 1.0, 0.0, 0.8, 0.5, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 0.0, 1.0, 0.0, 1.0, 0.14285714285714285, 0.1142857142857143, 1.0, 0.0, 0.0, 0.4, 0.5, 0.125, 0.0, 0.0, 0.6666666666666666, 0.0, 0.07999999999999999, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-240", "mrqa_newsqa-validation-3304", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.4375, "CSR": 0.576875, "EFR": 0.6944444444444444, "Overall": 0.6356597222222222}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "The grant required that it settle 100 families in the territory, and construct a fort for their protection.", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale approach", "Anthony Hopkins", "New Zealand", "Tamar", "rhododendron", "35", "specialist", "spider", "Arthropods", "Ub Iwerks.", "Westminster Abbey", "holography", "Pelias", "Barry White", "Northumbria", "Harvard", "cricketer", "Ron Ridenhour,", "A long pole", "copper and zinc", "Tigris", "Cordelia", "there were many kinds of publications that told both news and rumours.", "dermatitis", "33", "spicy", "Joseph Smith,", "Huntington Beach, California", "palladium", "the moon", "13", "a palla", "The Apartment", "Canada", "Churchill", "Stockholm", "Peter Parker", "Goldie Myerson,", "Lesa Ukman", "bullfight", "Sparks", "Ginger Rogers", "Rock of Gibraltar.", "Comedy Playhouse", "citric", "Charles Darwin", "John", "Mr. Boddy", "Marie Van Brittan Brown", "Southern California Timing Association ( SCTA )", "In 1995, California was the first state to enact a statewide smoking ban ; throughout the early to mid-2000s", "Bourbon", "Taylor Swift.", "Rihanna", "Tyler Peterson, a sheriff's deputy who killed six young people at a house party in Crandon, Wisconsin,", "The Detroit, Michigan, radio station promotion held three years ago was like a class to help women \" learn how to dance and feel sexy,\"", "Amy Bishop,", "cactus", "the Louvre", "an American private, not-for-profit, coeducational research university affiliated with the Churches of Christ."], "metric_results": {"EM": 0.40625, "QA-F1": 0.49872694790997363}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, false, false, false, true, true, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.8, 0.9523809523809523, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5714285714285715, 0.125, 0.6666666666666666, 1.0, 0.0, 0.08695652173913045, 0.4827586206896552, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10227", "mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-82", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-7521", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-8908", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.40625, "CSR": 0.5703125, "EFR": 0.7631578947368421, "Overall": 0.666735197368421}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Space Museum\"", "eight", "affordable housing", "Mao Zedong", "Verona", "Pontiac", "elephants", "cooking device, with a definition confined to a charcoal brazier covered by a grill in Japan, or with an expanded definition of any charcoal-powered stove or hot plate in North America.", "Frank McCourt", "jules Verne", "j Judy Cassab", "margo Leadbetter", "Schengen Area", "\u201cA\u201d", "city of Sheffield, England", "Famous Players-Lasky Corporation", "the Monkees", "Gerald Durrell", "jzebel", "Cork", "jason", "Arabian", "Halifax", "Noises Off", "jessica Smith", "Frank Wilson", "Carlos the Jackal", "Edwina Currie", "st Moritz Winter Olympics in 1928, Gillis Grafstr\u00f6m", "Robert Maxwell", "1768", "For gallantry", "Tuesday", "south Ossetia", "Montgomery", "Ever decreaseasing Circles", "Tahrir Square", "uranium", "d'Artagnan", "27", "Jack Ruby", "Jacopo tintoretto", "Eric Coates", "Saudi Arabia", "Lester", "Thailand", "Sydney", "dove", "Tunisia", "Prince Philip", "grosvenor Crescent", "Tokyo", "Edgar Lungu", "49 cents", "heart rate that exceeds the normal resting rate", "672", "Linda McCartney's Sixties: Portrait of an Era", "The Frost Place Advanced Seminar", "@", "Juan Martin Del Potro.", "27", "england", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5974228896103896}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.07142857142857142, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3959", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-4910", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-733", "mrqa_searchqa-validation-12829"], "SR": 0.53125, "CSR": 0.5688657407407407, "EFR": 0.8666666666666667, "Overall": 0.7177662037037037}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "more than 70", "forced Tesla out leaving him penniless. He even lost control of the patents he had generated since he had assigned them to the company in lieu of stock.", "Benazir Bhutto", "Iran's nuclear program.", "27 Awa Indians", "Larry King", "Daniel Cain", "acid", "Wally", "2008", "after Wood went missing off Catalina Island, near the California coast,", "Behar", "Pakistan", "The Everglades, known as the River of Grass,", "Dilshan made 109 as Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "1950s", "64", "Iran's parliament speaker", "27", "young self-styled anarchists", "$163 million (180 million Swiss francs)", "unwanted baggage from the 80s", "around 3.5 percent of global greenhouse emissions.", "ensenada, Mexico", "Orbiting Carbon Observatory", "Switzerland", "jon Stewart", "Janet and La Toya", "more than 22 million people in sub-Saharan Africa", "hours", "returning combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "he's burned badly on the backs of his knees and every time he moves his knee, it pulls, and it cracks,", "al-Shabaab", "posting a $1,725 bail", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "Opry Mills,", "Number Ones", "normal maritime traffic", "he was diagnosed with skin cancer.", "al Qaeda", "Obama", "\"gotten the balance right\" on Myanmar, the military junta-ruled Asian nation formerly known as Burma, by starting a dialogue while maintaining sanctions,", "The oceans", "beat their victims' fingers with bricks, snip their backs open with wire cutters, carve them up with knives or simply shoot them.", "doctors", "off the coast of Dubai", "Bill Haas", "Talisa Maegyr", "1932", "between 1923 and 1925", "Gilda", "Nahum Tate (1652-1715)", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Benjamin Disraeli", "sun"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5907650434455392}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.375, 0.4, 0.8, 0.3333333333333333, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.06896551724137931, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 0.8, 0.8, 1.0, 0.5, 0.0, 1.0, 0.06896551724137931, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1302", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-1119", "mrqa_newsqa-validation-1668", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-14496"], "SR": 0.453125, "CSR": 0.5647321428571428, "EFR": 0.7428571428571429, "Overall": 0.6537946428571428}, {"timecode": 28, "before_eval_results": {"predictions": ["Bermuda 419 turf", "25-foot", "symbols", "Hyundai Steel", "Monday night", "Bailey, Colorado", "kidnapping the children and concealing their identities.", "40", "that the Illuminati was this secret society which was brutalized by the Catholic Church in the 1600s.", "in a public housing project,", "toxic smoke", "Lucky Dube,", "two Israeli soldiers, Ehud \"Udi\" Goldwasser and Eldad Regev.", "space shuttle Discovery", "Gavin de Becker", "a nuclear weapon", "IV cafe.", "Arizona", "between South America and Africa.", "Tetris", "outside influences", "the ad would compromise the public broadcaster's appearance of unbiasedity.", "flipped and landed on its right side,", "suppress the memories and to live as normal a life as possible;", "Tuesday", "file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "the area was sealed off, so they did not know casualty figures.", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "Cash for Clunkers", "project work", "Oprah: A Biography", "80 percent", "London's 20,000-capacity O2 Arena.", "to try to make life a little easier for these families by organizing the distribution of wheelchair, donated and paid for by his charity, Wheelchair for Iraqi Kids.", "Ozzy Osbourne", "$50", "Australian officials", "the Walk of Fame.", "Bill Klein,", "gun", "38", "Argentina", "mayor of Seoul from 2002 to 2004,", "Somalia's piracy problem was fueled by environmental and political events.", "17 Again", "Kabul", "22", "Steven Gerrard", "12.3 million people worldwide", "the area was sealed off, so they did not know casualty figures.", "Rima Fakih", "Old Trafford", "help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "mozart's finales", "The Fifth", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Nehru", "Transpiration", "hypomanic"], "metric_results": {"EM": 0.5, "QA-F1": 0.5884882478632478}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true, false, false, false, false, true, false, false, false, true, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.19999999999999998, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-3326", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-3651", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-2847", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-3575", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-919", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.5, "CSR": 0.5625, "EFR": 0.75, "Overall": 0.65625}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "100% oxygen", "Betty Meggers", "ancient cult activity as far back as 7th century BCE", "US - grown fruit ( grown by its cooperative members primarily in Polk County, Florida )", "sex organs", "Russian army", "diffuse nebulae", "August 6 and 9, 1945", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "Iran", "maintenance utility", "July 4, 1776", "pick yourself up and dust yourself off and keep going", "John Garfield as Al Schmid   Eleanor Parker as Ruth Hartley   Dane Clark as Lee Diamond   John Ridgely as Jim Merchant", "enabled European empire expansion into the Americas and trade routes to become established across the Atlantic and Pacific oceans", "1979", "Lorazepam", "the 2013 non-fiction book of the same name by David Finkel", "salami cutting", "Brenda", "who the better fighters are relative to their weight ( i.e., adjusted to compensate for weight class )", "Husrev Pasha", "Stephanie Judith Tanner", "ulnar collateral ligament of elbow joint", "McFerrin, Robin Williams, and Bill Irwin", "Watson and Crick", "Gorakhpur", "Patris et Filii et Spiritus Sancti", "the first four caliphs ( successors )", "Lake Powell", "ornament", "September 6, 2019", "population", "substitute good", "Marries", "74", "1987", "cunnilingus", "1999", "New York City", "Prafulla Chandra Ghosh", "United States economy first went into an economic recession", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "used obscure languages as a means of secret communication during wartime", "Donny Osmond", "Rome and Carthage", "43rd", "gmbH", "7.63\u00d725mm Mauser", "seven", "Muslim", "the two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Lake Baikal", "adventure park"], "metric_results": {"EM": 0.34375, "QA-F1": 0.5128358620546121}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, false, true, false, true, false, true, false, false, false, false, false, true, false, false, false, true, true, false, true, true, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.5555555555555556, 0.0, 1.0, 0.3076923076923077, 0.9090909090909091, 0.0, 0.5, 0.4, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.7142857142857143, 0.18181818181818182, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.4444444444444444, 1.0, 0.0, 0.25, 0.5, 0.5, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6, 0.4, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9447", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-10469", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-9421", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.34375, "CSR": 0.5552083333333333, "EFR": 0.6904761904761905, "Overall": 0.6228422619047619}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "Indiana", "The Last of the Mohicans", "shoes", "novem", "Rashid Akmaev,", "acetylene", "'Archer' Jokes", "fiber", "gray wolf", "Whats", "Winston Rodney", "sand", "Nanjing", "Custer", "walking Camelot Knight #4 / French Taunter / Tim the Enchanter", "Louis XIV of France", "GILBERT & SullIVAN.", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "The Song of Norway", "Frida Kahlo", "son of John and Abigail Adams, served as the sixth President of the United States from 1825 to 1829.", "Jeopary Questions page 831", "Fat man", "Hair", "William Randolph Hearst", "basalt", "an ale", "primate", "dogs", "\"Year 3000\"", "Luther", "The New Colossus", "yelped", "Richard Wagner", "Sarah, Duchess of York", "getting married tomorrow", "the middleweight champion,", "bronchodilator", "Forty", "fluorescent lights.", "Red Lake Indian Reservation", "in a Chenard", "Earl Long,", "Neil Patrick Harris", "Wyatt and Dylan Walters", "1999", "vitamin D", "three", "Alberto juantorena", "R&B vocal group", "Awake", "Doctor of Philosophy", "Pakistan", "in Sydney in 2000 at the age of 41, this time claiming bronze in the time trial -- and event in which she had also won silver in 1996.", "Sonia Sotomayor"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4508928571428571}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, false, false, true, false, true, true, false, false, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.5, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-13153", "mrqa_searchqa-validation-12259", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_triviaqa-validation-7493", "mrqa_triviaqa-validation-282", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.40625, "CSR": 0.5504032258064516, "EFR": 0.7105263157894737, "Overall": 0.6304647707979627}, {"timecode": 31, "before_eval_results": {"predictions": ["traditional Mongol shamans", "Prospect Park", "the eye", "a cone", "a squint", "Breakfast at Tiffany's", "Diners' Club Card", "Christian Dior", "August Wilson", "Juliet", "Notre Dame", "Table Mountain", "Tate", "Lt. Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "monosodium glutamate", "cards", "kozo", "Tenzing Norgay", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Kate Middleton", "America Ferrera", "R", "a horse with a reddish-brown horse", "New Jersey", "Lake Ontario", "Matthew Perry", "Marissa Jaret Winokur", "John Ford", "kismet", "the Chocolate Factory", "artillery", "aluminum", "General McClellan", "Ned Kelly", "a piles of papers", "gravitational force", "Isis", "quiveir", "Heroes", "on the two tablets", "organ transplant of a kidney into a patient with end - stage renal disease", "seven units", "Dr. A.G. Ekstrand,", "Rocky Marciano", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "February 20, 1978", "two years", "Arsene Wenger", "in an interview Tuesday on CNN's \"Larry King Live.\""], "metric_results": {"EM": 0.5, "QA-F1": 0.5807291666666667}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2]}}, "before_error_ids": ["mrqa_squad-validation-8204", "mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-16314", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-12766", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-9411", "mrqa_searchqa-validation-10370", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-7472", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-10042", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_naturalquestions-validation-10526", "mrqa_triviaqa-validation-2878", "mrqa_newsqa-validation-2123"], "SR": 0.5, "CSR": 0.548828125, "EFR": 0.78125, "Overall": 0.6650390625}, {"timecode": 32, "before_eval_results": {"predictions": ["the same as the weight of the air that rushed back in", "Fresno Street and Thorne Ave", "the Black Death", "Kenneth", "John Stuart Mill", "Joshua Abraham Norton", "CIA", "mezzo piano", "Rickey Henderson", "Jawaharlal Bhutto", "D. carota ssp. maritimus", "John Grunsfeld", "Llados and Llanmad", "1976", "Galileo Descartes", "a quark", "Dust", "Rudy Giuliani,", "the Free Speech Clause", "Virginia", "Sif", "New Jersey", "The Omega Man", "a walk-in pantry", "a barrel", "the Olympic Eagle", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Michael Collins", "Linda Davenport", "Flushing, New York", "the East Wind", "Richard III", "the policies", "The pen", "Croatia", "Douglas Adams", "Celso Santebanes", "Hawaii", "Stephen Crane", "Prussia", "Sophocles", "Mark Cuban", "the Thought Police", "a bust", "Central Park", "Alice", "Part 2", "Coconut Cove", "aeoline", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "ZZ Top, Lynyrd Skynyrd", "Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5984623015873016}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_searchqa-validation-4870", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-5449", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-6555", "mrqa_searchqa-validation-13862", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-12615", "mrqa_searchqa-validation-16637", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-7855", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767"], "SR": 0.53125, "CSR": 0.5482954545454546, "EFR": 0.9, "Overall": 0.7241477272727272}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC", "pathogens, an allograft", "a large concrete block is next to his shoulder, with shattered pieces of it around him. Blood trickles down the road.", "hours", "28", "back at work", "Oxbow,", "201-262-2800", "opium", "he regret describing her as \"wacko.\"", "the annual White House Correspondents' Association dinner Saturday,", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar", "The station", "Hundreds of women protest child trafficking and shout anti-French slogans", "forgery and flying without a valid license,", "Arkansas", "Cash for Clunkers", "environmental videos", "North Korea intends to launch a long-range missile in the near future,", "terrorism", "hardship for terminally ill patients and their caregivers", "different women coping with breast cancer in five vignettes.", "a long-range missile", "Samson D'Souza,", "a cancer-causing toxic chemical.", "Roger Federer", "Miami Beach, Florida", "over 1000 square meters", "CNN", "no chance", "SSM Cardinal Glennon Children's Medical Center", "one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago", "two", "a portrait", "Symbionese Liberation Army", "he acted in self defense in punching businessman Marcus McGhee.", "two tickets to Italy", "Colombia", "in-cabin lighting", "unwanted horses", "1981", "Los Angeles", "16", "Pope Benedict XVI", "Sri Lanka, seeking a win to level the series at 1-1, closed on 366 for eight wickets on the opening day.", "Antonio Maria Costa,", "a bread", "Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15", "1925", "Javier Bardem", "Scotland", "Erika Girardi", "Terry the Tomboy", "Harriet Tubman", "Mrs. Potts", "M&M'S Pe peanut Chocolate Candies", "The Star-Spangled Banner"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6963468720821662}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, false, true, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.7058823529411765, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.0, 0.33333333333333337, 0.4444444444444445, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-533", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_newsqa-validation-1379", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-1622", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.578125, "CSR": 0.5491727941176471, "EFR": 0.8148148148148148, "Overall": 0.6819938044662309}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "anti- strikers", "Washington State's decommissioned Hanford nuclear site,", "Yemen", "bankruptcy", "nearly $2 billion in stimulus funds", "a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Spanish Davis Cup hero Fernando Verdasco,", "Bahrain", "children of street cleaners and firefighters.", "Joan Rivers", "$3 billion,", "hardship for terminally ill patients and their caregivers", "Honduras", "Brazil", "eco", "strife in Somalia,", "Roy", "the WBO welterweight title from Miguel Cotto on a 12th round technical knockout in Las Vegas.", "relatives of the five suspects,", "Meredith Kercher.", "lawyers trying to save their client from the death penalty", "Alicia Keys", "military action in self-defense against its largely lawless neighbor.", "Friday,", "a lump in Henry's nether regions", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "a model of sustainability.", "glamour and hedonism", "a $158 green skirt and $298 bead and rhinestone cardigan", "Department of Homeland Security Secretary Janet Napolitano", "543", "The patient, who prefers to be anonymous,", "Robert Gates", "Israel", "on 112 acres about 30 miles southwest of Nashville", "in critical condition", "Seoul", "Nicole", "assess a school test score of 98 with a \"What about those other two points?\"", "next week", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "James Whitehouse,", "hopes the journalists and the flight crew will be freed,", "gentry Buddhism", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "Noreg", "Beer", "Revengers Tragedy", "1972", "Black Elk Speaks", "the Hogan Family", "the hippopotamus", "Peter"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5526820963821788}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, false, false, true, true, true, true, false, false, false, false, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.5, 0.19999999999999998, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.06896551724137931, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_hotpotqa-validation-4378", "mrqa_searchqa-validation-7879"], "SR": 0.453125, "CSR": 0.5464285714285715, "EFR": 0.6857142857142857, "Overall": 0.6160714285714286}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position.", "on the maple tree", "Malibu", "Sisyphus", "sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Caliban", "\"mau fern\"", "the Aegean Sea", "the Little Bighorn", "Shakers", "bellwether", "The Information Philosopher", "chips", "Boxer", "The Spiderwick Chronicles", "Mabel Harding", "Las Vegas", "Case", "the Rose Bowl", "Norman Rockwell", "short cropped hairstyles", "light tunais", "Napa Valley", "Eurail France", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "The Bodyguard", "12 men", "Jeff Merkley", "Editorial Reviews.", "Jupiter", "Anwar Sadat", "sundae", "Grace Evans", "50 million cells per litre (quart)", "ravenio marino", "HIV", "Fyodorovich", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Master of thunder,", "Lou Gehrig", "meaning and origin.", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.5, "QA-F1": 0.5671875}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, true, false, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-1389", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12977", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.5, "CSR": 0.5451388888888888, "EFR": 0.875, "Overall": 0.7100694444444444}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "a scallop", "nothing gained", "numismatic", "Supernanny", "Atlantic", "Cincinnati", "a mosque", "Henry Hudson", "a gun blast tubes", "Dry ice", "Taft", "Entourage", "eels", "Mariel", "The Museum of Modern Art", "the unicorns", "(John C.) Fremont", "Russia", "\"People, people who need\" Peabodys", "Hermann Hesse", "the Taj Mittal", "English Monarchs", "the Toreador Song", "Margaret Mitchell", "Quasimodo", "Money for Nothing", "Pandarus", "(Languid)", "Burt Reynolds", "the Sphinx", "Louis Satchmo Armstrong", "Saudi Arabia", "a new wave band", "Arby's", "coffee", "a chivalry", "Burns", "Hulk", "Winnipeg", "Memphis Belle", "Burkina Faso", "the Central Pacific", "Attorney General", "Icelandic", "a buffalo", "Sunday", "Edith Piaf", "Ivan I", "a prologue", "birch", "investor couple", "Jack Gleeson", "Phil Hurtt", "animals", "Massachusetts", "Starachowice", "Fredric March", "2009", "Democratic", "meteorologist", "$104,327,006", "\"State of Play\""], "metric_results": {"EM": 0.578125, "QA-F1": 0.6438244047619048}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, false, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, false, false, false, true, true, true, true, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-15899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-6076", "mrqa_searchqa-validation-8275", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-14520", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-15286", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-9274", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_hotpotqa-validation-2162", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-1525"], "SR": 0.578125, "CSR": 0.5460304054054055, "EFR": 0.7407407407407407, "Overall": 0.6433855730730731}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "Impressionist", "John Y. Brown Jr.", "oats", "Romney", "Ivan the Terrible", "Sally Field", "2012", "Egypt", "pi", "tin", "Lake Maurapas", "a tuxedo", "w", "Marriott International", "Monaco", "Canada", "The Secret", "gold", "collagen", "China", "a compound", "the crane", "a claw", "Alzheimer", "the Gulf of Mexico", "Stephen F. Austin", "Euclid's Elements", "Eva Peron", "Cain", "Edward Asner", "X-Men: The Last Stand", "the Louvre", "coho salmon", "Prison Break", "Mars", "Maine", "cheese made from unpasteurised sheep milk with no more than 20% goats milk mixed in.", "Meg", "Sonnet to Orpheus", "deuce", "Hans", "Peter Bogdanovich", "a #3 hit song", "Jesus Christ Superstar", "\"Britain redeemed and Canada preserved [microform]\"", "the Huronian Ice Age", "nolo contendere", "Junior Walker", "the Czech Republic", "a tuna", "the NIRA", "John Ernest Crawford", "beta decay", "France", "Priam", "Mariette", "Charles Quinton Murphy", "\"The Little Prince\" (2015)", "Australian", "sins of the members of the church", "$22 million", "\"17 Again,\"", "Nelson"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7036458333333333}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-6628", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-3594", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-10648", "mrqa_searchqa-validation-6998", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-8068", "mrqa_triviaqa-validation-6008", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-5774"], "SR": 0.59375, "CSR": 0.5472861842105263, "EFR": 0.9230769230769231, "Overall": 0.7351815536437247}, {"timecode": 38, "before_eval_results": {"predictions": ["in whole by charging their students tuition fees", "Holden Caulfield", "Bill Hickok", "Leptospira", "a recession", "a mermaid", "Jay Silverheels", "Singapore", "tanks", "a small bell", "a horse", "Spider-Man", "Witness", "Martha Tabram", "3800", "Alan Shore", "taxonomy", "Spain", "spinal cord", "William McMaster Murdoch", "Macbeth William Shakespeare", "comedy", "Mary Poppins", "Casowasco", "Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "marriage", "Livin' On A Prayer", "Sherlock Holmes", "cherry", "Marie Antoinette", "Ford", "Curie", "Roger Brooke Taney", "g", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "Harry Potter and the Philosopher Stone", "nickel", "forests", "Olympia", "Waylon Jennings", "The Bridge on the River Kwai", "Brazil", "British Columbia", "Oliver Stone", "scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "helps managers understand employees' needs in order to further employees' motivation.", "one", "Norfolk Island", "Wright brothers", "sexual activity", "Sam tick", "the L'Aquila earthquake,", "voluntary homicide", "\"deep sorrow\" at the death of two women killed in a stampede at one of his events in Angola on Saturday,", "Pygmalion"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5327108739837398}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true], "QA-F1": [0.4, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.9268292682926829, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6983", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-7370", "mrqa_searchqa-validation-5541", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-7477", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-9146", "mrqa_searchqa-validation-4043", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.4375, "CSR": 0.5444711538461539, "EFR": 0.8333333333333334, "Overall": 0.6889022435897436}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Bugle Boy", "Europe", "Jack Nicholson", "a wigs", "Sweeney Todd", "The Bridge on the Kwai", "the Byzantine Empire", "a feminist wedding", "Jefferson", "Ford Madox Ford", "The Orinoco River", "a ready-to-use cotton swab", "California", "Dixie", "RAND Corporation", "Warren Harding", "engrave", "Shue", "Francis Crick", "Jay and Silent Bob", "Heath", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "Westies, Scotties, schnauzers", "Ratatouille", "neurons", "Calvin Coolidge", "Mark Cuban", "Rudy Giuliani", "eyes", "Tony Dungy", "the Danube", "a Pocketknife Damascus Steel Blade", "26.2", "Prince", "a flowering plant", "chess", "GIGO", "Johannes Brahms", "Charleston Southern", "Italian", "The Grapes of Wrath", "a bicentennial exposition", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Tara", "March 15, 1945", "Charles Darwin", "Old Trafford", "Miles Morales", "Honey Irani", "global peace", "Kalahari Desert", "a Christian farmer", "Bob Dole", "Amitabh Bachchan", "managing his time"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5502232142857142}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, false, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_triviaqa-validation-6323", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.46875, "CSR": 0.542578125, "EFR": 0.8529411764705882, "Overall": 0.6977596507352941}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "horror", "Oakdale", "Missouri", "the FAI Junior Cup", "Flaw", "alt-right", "The Drudge Report", "15,000 people", "Yellow fever", "a cappella singing group", "1934", "a record of 13\u20133", "We Need a Little Christmas", "Tsavo East National Park", "New York Islanders", "1377", "nearly 80 years", "Jean Acker", "the second tier of the English football league system,", "The Gettysburg Address", "Whitney Houston", "Mbapp\u00e9", "The Rite of Spring", "1", "26,000", "Kristin Scott Thomas, Anne Bancroft, James Fox, Derek Jacobi, and Sean Penn.", "Ed Lee", "1958", "1993", "burlesque", "Afro-Russian", "Loretta Lynn", "England", "a B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Kansas City", "1999", "Pinellas County", "beer", "London", "a prototype of the B-17 Flying Fortress bomber", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mase Dinehart", "Tevye", "Sir Tom Finney", "Cameroon", "obtaining and proper handling of human blood.", "toxic smoke from burn pits in Iraq", "two", "Iggy Pop invented punk rock.", "a riddle", "a man", "DiCaprio", "a pathological ex-lover who did the protagonist wrong"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6483098447712419}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 0.35294117647058826, 0.4, 0.0, 1.0, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_searchqa-validation-13997", "mrqa_naturalquestions-validation-6326"], "SR": 0.546875, "CSR": 0.5426829268292683, "EFR": 0.8620689655172413, "Overall": 0.7023759461732548}, {"timecode": 41, "before_eval_results": {"predictions": ["a interception", "10", "did not identify any of the dead.", "Les Bleus", "2005", "more than 4,000", "Arlen Specter", "an angry mob.", "normal maritime traffic", "Sri Lanka", "death", "average of 25 percent", "fatally shooting a limo driver", "The Al Nisr Al Saudi", "as many as 50,000", "piano", "$250,000", "a \"prostitute\"", "the mammoth's skull", "tax", "Brazil", "acute stress disorder", "Russia", "Facebook and Google", "through a facility in Salt Lake City, Utah", "Manmohan Singh", "Haiti", "Tuesday afternoon", "Pakistan", "23 years", "a head injury", "Bahrain", "an open window", "Leo Frank", "Paul McCartney", "it has witnessed only normal maritime traffic around Haiti,", "President Robert Mugabe", "don't have to visit laundromats", "as adults", "United Kingdom Dance Championships.", "on-loan David Beckham claimed his first goal in Italian football.", "his son is fighting an unjust war for an America that went too far when it invaded Iraq", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died", "Cesar Laurean", "Suwardi, the village leader of Karas in East Java.", "al Qaeda", "Secretary of State Hillary Clinton", "Rihanna", "angular rotation", "heart", "54 Mbit / s", "Gloucestershire", "the Consolidated B-24 Liberator", "cereal", "Oakdale", "Melbourne", "Guillermo del Toro", "stocks", "Monty Python and the Holy Grail", "Sweden", "U.S. Department of Transportation"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6531977137445888}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, false, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.8, 1.0, 1.0, 0.4, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.5, 1.0, 0.7272727272727273, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.19999999999999998, 1.0, 0.625, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.16666666666666666, 0.0, 0.5714285714285715, 1.0, 1.0, 0.4, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_squad-validation-48", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-2129", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-3544", "mrqa_newsqa-validation-2414", "mrqa_newsqa-validation-1659", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-10945"], "SR": 0.515625, "CSR": 0.5420386904761905, "EFR": 0.7741935483870968, "Overall": 0.6581161194316436}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Chinese", "Zimbabwe", "Italian Serie A title", "Darrel Mohler", "dancing against a stripper's pole.", "Michoacan Family", "WTA Tour titles at Strasbourg and Bali prior to Madrid", "Welshman Ncube,", "42", "takes on the swords of the Taliban.", "If huge hunks of ice -- such as parts of Greenland and the western shelf of Antarctica -- melt, then the rise is expected to be more dramatic.", "80 percent of a woman's face", "1979", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Sonia Sotomayor", "Campbell Brown", "an auxiliary lock", "Mario Balotelli and James Milner ended Everton's run of victories in their last four visits to Eastlands.", "AbdulMutallab,", "Myanmar", "Collier County Sheriff Kevin Rambosk", "Marcus Schrenker,", "Philippine National Police.", "poems", "the program was made with the parents' full consent.", "(the Democratic VP candidate delivers a big speech next Wednesday)", "The Red Cross, UNHCR and UNICEF", "Nizhny Novgorod", "debris", "not guilty of affray by a court in his home city on Friday.", "capital murder and three counts of attempted murder", "Basel", "17", "Daytime Emmy Lifetime Achievement Award", "state senators", "31 meters (102 feet) long and 15 meters (49 feet) wide", "its nude beaches.", "how preachy and awkward cancer movies can get.", "her father", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying", "Capitol Hill,", "\"theoretically\" Iran could develop a nuclear weapon", "1940's", "March 22,", "its own environmental videos", "at a depth of about 1,300 meters in the Mediterranean Sea.", "Antichrist", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Orion", "brown", "Selfie", "2002", "South Australia", "Manhattan Project", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7034406693184266}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.0, 0.5, 0.11764705882352941, 0.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.2857142857142857, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4, 0.4, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.4, 1.0, 1.0, 0.12500000000000003, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-720", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_naturalquestions-validation-1799", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834"], "SR": 0.609375, "CSR": 0.5436046511627908, "EFR": 0.76, "Overall": 0.6518023255813954}, {"timecode": 43, "before_eval_results": {"predictions": ["north,", "legitimacy of that race.", "At least 88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "\"Well, about time.\"", "hardship", "Araceli Valencia,", "Zac Efron", "finance", "nearly $2 billion", "The National Infrastructure Program,", "1941", "The station", "Krishna Rajaram,", "dead, naked body", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Afghanistan's restive provinces", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "Iran could be secretly working on a nuclear weapon", "that the teens were charged as adults.", "death squad killings carried out during his rule in the 1990s.", "Sonia Sotomayor", "Hyundai", "100 percent", "Saturday", "Afghanistan,", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole", "Rima Fakih", "South Africa", "Obama", "helicopters and unmanned aerial vehicles from the White House to patrol the border region with Mexico.", "Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second", "Jund Ansar Allah", "1,500", "most of those who managed to survive the incident hid in a boiler room and storage closets", "$50 less", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960 Summer Olympics in Rome", "Villa Park", "peasants, small-holder farmer", "pool", "1822", "The Dressmaker", "Trilochanapala", "crote", "buffalo", "ruby slippers", "the frontal lobe"], "metric_results": {"EM": 0.5, "QA-F1": 0.6226963643082064}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.08333333333333333, 0.923076923076923, 0.9523809523809523, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5263157894736842, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 0.33333333333333337, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-1063", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-3451", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-2713", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.5, "CSR": 0.5426136363636364, "EFR": 0.90625, "Overall": 0.7244318181818181}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf.", "Los Angeles", "Chris Eubank Jr.", "Duval", "Benj Pasek and Justin Paul,", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Thomas Staubach", "1944", "Atlanta Athletic Club", "Franconia, New Hampshire,", "Operation Watchtower", "Dan Crow", "\"War & Peace\"", "Amberley Village", "What Are Little Boys Made Of?", "Berea College", "Chicago Bears", "Luca Guadagnino", "Liesl", "native to Germany and other parts of Central Europe,", "New York Islanders", "Todd Phillips", "26,788", "the Troubles", "1967", "Marktown, Clayton Mark's planned worker community in Northwest Indiana", "nationality law", "Radcliffe College", "Charles Guiteau", "Ford Motor Company", "If the citizen's heart was heavier than a feather they would face torment in a lake of fire.", "India", "German", "armed", "25 million", "The Snowman", "Ella Fitzgerald", "Chris Claremont", "Rain Man", "Interscope Records", "Robert Grosvenor", "3,672", "\"the most influential private citizen in the America of his day\"", "I'm Shipping Up to Boston", "American", "Believe", "the dynasty", "sixth - largest country by total area", "beginning of the American colonies", "Nicola Adams", "troopship", "Russia", "dependable Camry", "Steven Green", "in a hotel,", "Chaucer", "rattlesnakes", "Riddles", "healthy, wealthy, and wise"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6573259320175439}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, false, false, false, true, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8750000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.8, 1.0, 1.0, 1.0, 0.2105263157894737, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986"], "SR": 0.5625, "CSR": 0.5430555555555556, "EFR": 0.7857142857142857, "Overall": 0.6643849206349206}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder in the beating death of a company boss who fired them.", "the Indian Ocean waters", "30", "crocodile eggs", "Larry Abrahamson", "Jared Polis", "in recent days, recent weeks, recent months", "Carrefour", "in July for A Country Christmas, and the festivities run from mid-November until the holidays end.", "trail the illegal traffic.", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Herman Cain", "\"17 Again,\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie meals", "Heshmatollah Attarzadeh", "the ireport form", "the government", "Nine out of 10 children", "police", "Sen. Joe Lieberman, I-Connecticut, during the re-nomination hearing of ICE chief Julie Myers.", "the jaws of a crocodile", "a bronze medal in the women's figure skating final, just four days after Therese Rochette died of a heart attack.", "killed at least 63 people and wounded more than 200.", "Congress", "Susan Boyle", "a law signed Tuesday by President Obama.", "Phillip A. Myers.", "Obama's", "King Gyanendra", "homicide by undetermined means,", "Casey Anthony, 22,", "officers at a Texas  airport", "10 municipal police officers", "UNICEF", "surrogate", "228", "Kerstin and two of her brothers, ages 18 and 5,", "2004", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma", "Oaxaca, Mexico", "Arsene Wenger", "slavery", "Kat ( Jesse Wallace ), Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ), and grandmother Mo ( Laila Morse )", "enkuklios paideia or `` education in a circle ''", "Enid Blyton", "Johnny Mathis", "The son of a Brooklyn policeman who died when he was eight,", "Champion Jockey", "Luca Guadagnino", "Ms. Jackson", "the caged bird", "timing shapes and supports brain function", "a shaker", "a modified First World War Vickers Vimy"], "metric_results": {"EM": 0.5, "QA-F1": 0.6065542963980464}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, false, false, true, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.14285714285714288, 0.0, 0.47619047619047616, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5833333333333334, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.7499999999999999, 1.0, 0.5, 1.0, 0.25, 0.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-691", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-3221", "mrqa_newsqa-validation-1612", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-994", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-1388", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.5, "CSR": 0.5421195652173914, "EFR": 0.78125, "Overall": 0.6616847826086957}, {"timecode": 46, "before_eval_results": {"predictions": ["acular", "bipartisan", "Nirvana", "via phone calls or by text messaging", "without bail and will be arraigned June 25,", "12.3 million", "Mexico", "Real Madrid", "Michael Arrington,", "Brett", "eight Indian army troopers, including one officer, and 17 militants,", "Saturday", "Nicole", "legitimacy of that race.", "Adidas", "Dennis Davern, the captain of yacht owned by Wood and her then-husband, actor Robert Wagner.", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "improve health and beauty.", "Chinese", "Newcastle", "Nothing But Love", "allegedly involved in forged credit cards and identity theft", "June 6, 1944", "[Middle East and North Africa]", "twice", "October 19", "\"I sincerely apologize to Tiger and anyone else I have offended.\"", "Seoul,", "promotes fuel economy and safety while boosted the economy.", "ALS6", "eight", "Siri", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "VBS.TV", "children of street cleaners and firefighters.", "North Korea intends to launch a long-range missile in the near future,", "the area was sealed off, so they did not know casualty figures.", "attempting illegal crossings", "The American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "38", "Her husband and attorney, James Whitehouse,", "whites", "two", "half Moon Bay", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel ( 1497 -- 1558 )", "Discworld", "Japan", "fox hunting", "New York", "travel diary", "16,116", "the Jinx", "sukkar", "dumblebee", "Rowan Blanchard"], "metric_results": {"EM": 0.640625, "QA-F1": 0.689441071081696}, "metric_results_detailed": {"EM": [false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5333333333333333, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.12500000000000003, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615388, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-89", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-946", "mrqa_newsqa-validation-1260", "mrqa_newsqa-validation-3956", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3968", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_naturalquestions-validation-5769", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573", "mrqa_searchqa-validation-917"], "SR": 0.640625, "CSR": 0.5442154255319149, "EFR": 0.8260869565217391, "Overall": 0.6851511910268271}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "\"Parachutes\"", "5", "Chicago", "The Ones Who Walk Away from Omelas", "child actor", "Democratic", "drawing the name out of a hat", "Ryan Eldredge", "Indian Super League", "two or three", "Badfinger", "Lady Frederick Windsor", "Point", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue", "1946 and 1947", "5,112", "1992", "many artists' lofts and art galleries, but is now better known for its variety of shops ranging from stylish upscale boutiques to national and international chain store outlets.", "14,372", "6'5\" and 190 pounds", "Mickey Gilley's", "Swiss federal popular initiative \"against mass immigration\"", "puppy", "Mexican", "December 24, 1973", "1933", "the backside", "Kristoffer Rygg", "1730", "London Luton Airport", "the Salzburg Festival", "Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "Part II", "Bunker Hill", "lion", "Royal", "World War II", "Knoxville, Tennessee", "Three's Company", "P.O.S,", "Labour", "Linda McCartney's Sixties: Portrait of an Era", "English", "September 14, 2008", "79", "Frank Theodore `` Ted '' Levine", "Romania", "Zephyr, Billy Cobham, Alphonse Mouzon, the James Gang, Deep Purple, and Moxy.", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces at the site.", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "cloakroom", "Lehman Bros International"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6770073676323677}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, true, false], "QA-F1": [0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.13333333333333333, 0.0, 0.4, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-4043", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_triviaqa-validation-2701"], "SR": 0.546875, "CSR": 0.5442708333333333, "EFR": 0.8620689655172413, "Overall": 0.7031698994252873}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "ryegrass", "offensive", "Vulcan", "the hexameters", "Fawn Hall", "gesture", "Shakespearean Heroines", "Barnum", "Peter John", "topaz 3d", "torque wrench", "gold", "Marlon Brando", "low German", "\"Impressionists\"", "University of Kentucky", "reddish", "Brussels", "Macbeth", "General Lee", "piracy", "the death vestments (long white smocks)", "Martin Luther", "Clue", "Edgar Allan Poe", "Norway", "Andrew Johnson", "15", "Mike Connors", "\"JUNGLE JIM\"", "Jim Inhofe", "sancire", "Corpus Christi", "Africa", "an ostrich", "a \"rigid\" constitution", "night shift", "mug", "Desperate Housewives", "Galileo Galilei", "Canada", "Anne Hathaway", "spare", "the Grail", "West Virginia", "James Monroe", "movie house", "seaworld", "kritikos", "Ulbricht", "1904", "young girl", "Jimmy Robertson", "ambidextrous", "chariots", "Humberside", "more than 265 million", "100 million", "help rebuild the nation's highways, bridges and other public-use facilities.", "a head injury.", "Pope Benedict XVI refused", "Charles II"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5428308823529412}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, false, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.9411764705882353, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-15329", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-5735", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-12071", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_searchqa-validation-15062", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-2171", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.453125, "CSR": 0.5424107142857143, "EFR": 0.8571428571428571, "Overall": 0.6997767857142857}, {"timecode": 49, "before_eval_results": {"predictions": ["National Security Agency", "Heisman Trophy", "Brandi Chastain", "Colorado", "C.J. Parker", "carioca", "Treasure Island", "Pocahontas", "improvisation", "(Whizzer) White", "(E)", "an inert gas or other activating agent", "Great American Novel", "Ferris B Mueller", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "draft", "Ernest Lawrence", "rodeo", "fresco", "Nevil Shute", "(Ulysses) Grant", "Jesse Jackson", "Tudor", "Department of Homeland Security", "the Black Sea", "leotard", "Bulworth", "a shovelfuls", "the mouthpiece", "Key West", "the Fellowship of the Ring", "\" Please Mr. Please\"", "deep Woods", "Manhattan", "Feb 1, 2012", "Leontyne Price", "compost", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "Sarah Jessica Parker", "The Pierian spring", "Trinidad and Tobago", "a thawb robe", "Philadelphia", "peanut butter", "(I)", "leather", "Lex Luthor", "food and clothing", "Schwarzenegger", "Master Christopher Jones", "Hebrew", "\"Meadowbank II The Sequel - Scotland Mad  Scotland Mad", "St Moritz in Switzerland", "October", "Drifting", "Ellesmere Port, United Kingdom", "Sunday evening", "three out of four", "poems telling of the pain and suffering of children just like her", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.53125, "QA-F1": 0.5876736111111112}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, false, false, true, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 0.16666666666666669, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-1368", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2904", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301", "mrqa_newsqa-validation-3073"], "SR": 0.53125, "CSR": 0.5421875, "EFR": 0.7666666666666667, "Overall": 0.6544270833333334}, {"timecode": 50, "UKR": 0.796875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.76953125, "KG": 0.515625, "before_eval_results": {"predictions": ["Fatih Ozmen", "850 saloon", "Skyscraper", "Cadillac Stingrays", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hilo", "Robert Downey, Jr.", "Continental AG", "band director", "Visigothic", "Anaheim", "Reinhard Heydrich", "Big Ben", "Standard Oil", "\"The Longest Yard\"", "Chiwetel Ejiofor", "president of Guggenheim Partners", "19th-century", "Lady Antebellum", "WikiLeaks", "Vice President", "Tottenham Hotspur", "2010", "Vixen", "Forbidden Quest", "Rymill Park", "balloon Street, Manchester", "May 1, 2011", "Santa Fe", "political commentator", "Adelaide Lightning", "Landing Barge", "Lancia-Abarth", "Lonely", "254th", "Diamond White", "50 km north-northeast of Bologna,", "created the American Land-Grant universities and colleges", "Indooroopilly Shoppingtown", "2006", "Matt Flynn", "Indian", "hamburgers", "Liverpool", "little hairs", "Luigi Segre", "United States House of Representatives", "February 9, 2018", "1980", "Nacio Herb Brown ( music ) and Arthur Freed ( lyrics )", "Geoff Hurst", "Precambrian", "Mull", "Dube's death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "had a relationship with another person.", "progressive neurological disease", "Paul Newman", "Puccini", "Steve Martin", "milk and honey"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5266203703703705}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, true, false, false, true, false, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true, false, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 0.5, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.2, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.13333333333333333, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.37037037037037035, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-712", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2838", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2137", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-13015"], "SR": 0.453125, "CSR": 0.5404411764705883, "EFR": 0.8285714285714286, "Overall": 0.6902087710084034}, {"timecode": 51, "before_eval_results": {"predictions": ["1979", "an Indian", "Chiltern Shakespeare Company", "1961", "Stacey Kent", "1970s", "Arthur Freed", "Kalokuokamaile", "Gothic Revival", "Buffalo", "Sam Waterston", "Johan Leysen", "January 4, 1976", "237", "11,163", "an album", "its air-cushioned sole", "The White Knights of the Ku Klux Klan", "WikiLeaks", "Three card brag", "Montana State University", "Tool", "Wikimedia Foundation", "Flashback: The Quest for Identity", "ARY Films", "1987", "dementia", "two Grammy awards", "Port of Boston", "Denmark", "Las Vegas", "1961", "Rochdale", "Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward", "2012", "United States", "Sargent Shriver", "35", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Richard Price", "Archie Andrews", "George Mikan", "June 11, 1986", "2018\u201319 UEFA Europa League", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force ( RAF )", "Separate Tables", "Celtic Sea", "random", "near the Somali coast", "Daytime Emmy Lifetime Achievement Award", "October 29 and November 5", "Poe", "hunter sauce", "\"The Quest of Erebor\"", "carbon"], "metric_results": {"EM": 0.703125, "QA-F1": 0.752734375}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.5, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1731", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-1418", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4222", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-2803", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.703125, "CSR": 0.5435697115384616, "EFR": 0.6842105263157895, "Overall": 0.6619622975708502}, {"timecode": 52, "before_eval_results": {"predictions": ["To Carrie and Irene Miner", "King Henry VIII", "lead", "the Rose Bowl", "747", "amber", "Denmark", "terriers, Scotties, schnauzers and many other breeds", "The Waves", "Galilee", "freestyle", "dou Douglas", "pornography", "Stargate", "Lou Reed", "Jackson", "Fennoscandia", "Brunettes", "canvas", "potted plants", "The X-Files", "Frankie Muniz", "North American Mammals", "Hudson Bay", "January 4, 1809", "kinetic", "Santera", "Starsky and Hutch", "Statue of Liberty", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Red Lake", "Gatun Lake", "Cornucopia", "self-aware stage drama about a death obsessed", "Ankara", "water changing from a vapor to a liquid", "be", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Like Water for Chocolate", "NigerCongo", "Applebee's", "John Tyler", "Daniel Craig", "humility", "programming", "the Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "concentration of a compound exceeds its solubility", "Doctor Zhivago", "Bristol", "PETY BYNARD KEYNES", "Pan Am Railways", "Heinrich K\u00e4mpfert", "1961", "Atlantic Ocean", "consistent and accessible", "fake his own death by crashing his private plane into a Florida swamp.", "the S&DR"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6178385416666666}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, false, true, true, true, false, false, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.625, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7579", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-13812", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-15252", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-15500", "mrqa_searchqa-validation-3189", "mrqa_naturalquestions-validation-3230", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.59375, "CSR": 0.5445165094339622, "EFR": 0.8076923076923077, "Overall": 0.6868480134252539}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Saint Etienne", "After Shawn's kidnapping", "manage the characteristics of the beer's head", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "clay", "on the microscope's stage by slide clips, slide clamps or a cross-table", "Gary Player", "Nicolas Anelka", "season two", "The information carried by DNA is held in the sequence of pieces of DNA called genes", "help bring creative projects to life", "Most days are sunny throughout the year", "David Motl", "The Portuguese", "Madison, Wisconsin", "September 1972", "2017", "Gustav Bauer", "detritus", "the magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "Alice Cooper", "1961", "111", "Brazil, Turkey and Uzbekistan", "the dromedary", "13", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "complex sentence", "Kelly Osbourne, Ian `` Dicko '' Dickson, Sophia Monk and Eddie Perfect", "Coriolis effect", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "James Rodr\u00edguez", "Kristy Swanson", "James Madison", "the NFL", "Daya Jethalal Gada", "74", "omitted", "various submucosal membrane sites", "noble gas", "Office of Inspector General", "four distinct levels", "Janie Crawford", "Justin Timberlake", "1966", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Detective", "Paul Gauguin", "extreme", "creeks,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "off the coast", "the Northwest Territories", "Chekhov", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6022916591850416}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.6666666666666666, 0.8, 0.9, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.11764705882352941, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.29629629629629634, 1.0, 0.2, 0.5, 1.0, 1.0, 0.5, 0.3076923076923077, 0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-10653", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-4225", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-6745", "mrqa_triviaqa-validation-4748", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.46875, "CSR": 0.5431134259259259, "EFR": 0.7352941176470589, "Overall": 0.672087758714597}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "Tex - Mex cuisine is characterized by its heavy use of shredded cheese, meat ( particularly beef and pork ), beans, peppers and spices, in addition to flour tortillas", "Paul McCartney", "Kanawha Rivers", "1803", "President pro tempore of the Senate", "c. 3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "Balthazar changes history in the sixth season episode `` My Heart Will Go On ''", "California, Utah and Arizona", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "1773", "John J. Flanagan", "the earliest known official or large - scale celebration of Pi Day was organized by Larry Shaw at the San Francisco Exploratorium", "a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "December 1, 1969", "on May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m ( 41.5 ft )", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Coldplay", "Arkansas", "Pandit Jawaharlal Nehru", "the other guests'diaries", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "S\u00e9rgio Mendes", "Secretary of Homeland Security", "cylinder of glass or plastic that runs along the fiber's length", "embryo", "741 weeks", "Malawi", "London", "Hillary Clinton's", "Tampa", "Battle of Prome", "\"Kitty Hawk\"", "John Lennon and George Harrison", "the ship of violating Chinese and international laws during its patrols,", "beautiful", "Tater Tots", "Yemen", "a proof", "the Dalton Gang"], "metric_results": {"EM": 0.421875, "QA-F1": 0.555979317863509}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.56, 0.0, 0.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.8, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.8, 0.4, 0.5, 1.0, 1.0, 0.0, 0.0, 0.060606060606060615, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428572, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-3311", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-902", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-3032", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4428", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-3099", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-8575"], "SR": 0.421875, "CSR": 0.5409090909090909, "EFR": 0.7837837837837838, "Overall": 0.681344824938575}, {"timecode": 55, "before_eval_results": {"predictions": ["She calls the telephone company and the police, but with few concrete details, they can don'thing", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "In 1967, Celtic became the first British team to win the competition", "U.S. states of Oregon and Washington", "the Northeast Monsoon or Retreating Monsoon", "2013", "Hold On", "land, fresh water, air, rare earth metals and heavy metals including ores such as gold, iron, copper, silver", "annual income of US $11,770", "Neil Young", "the closing of the atrioventricular valves and semilunar valves", "minimum viable product that addresses and solves a problem or need that exists", "London", "Incumbent Democratic mayor Marty J. Walsh", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "Ernest Rutherford", "The sinus rhythm is any cardiac rhythm where depolarization of the cardiac muscle begins at the sinus node", "SI joint", "HTTP / 1.1", "Brooklyn, New York", "1 mile ( 1.6 km )", "pop ballad", "8 December 1985", "prophase I of meiosis", "The law was introduced to the New Zealand Parliament as a private members bill by Green Party Member of Parliament Sue Bradford in 2005", "Arnold Schoenberg", "notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "Orographic lift", "in the books of Exodus and Deuteronomy", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outermost layer of human skin", "2007", "Vanessa received an SMS which reveals that Dan was `` G gossip Girl ''", "10,605", "Niall Matter", "Sebastian Vettel", "San Antonio", "Meg Optimus", "biological taxonomy", "depending on the gender of the reigning monarch", "pathology", "Tevin Campbell", "My Big Fat Gypsy Wedding", "Joseph V. Micallef", "Mariette Hartley", "Boston, Massachusetts", "Colonel Patrick John Mercer, OBE", "Bob Hurley", "urging more help for military members, especially for those returning from war.", "five Lebanese prisoners", "Deputy Chief Brenda Johnson", "pope III", "Sean Penn", "Eiffel Tower", "Teddy Riley"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5756240646785723}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, false, false, true, false, false, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.9333333333333333, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.09523809523809522, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.08695652173913042, 1.0, 0.7878787878787877, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25000000000000006, 0.0, 0.9, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 0.0, 0.25, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-10218", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-1449", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-4482", "mrqa_hotpotqa-validation-2296", "mrqa_hotpotqa-validation-4760", "mrqa_newsqa-validation-1887", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-104", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-14136"], "SR": 0.4375, "CSR": 0.5390625, "EFR": 0.8333333333333334, "Overall": 0.6908854166666667}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "10 May 1940", "raghuwanshi dynasty", "six 50 minute ( one - hour with advertisements ) episodes", "1840", "1999", "Old Trafford", "Tami Lynn", "the symbol consists of three dots placed in an upright triangle and is read therefore", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "Dutch navy captain Jurriaen Aernoutsz", "4 September 1936", "hydrogen and oxygen", "1940", "Authority", "April 1st", "DJ Lance Rock", "24 hours", "Francisco Pizarro", "habitat", "Ben Faulks", "Lady Gaga", "mental disorder characterized by at least two weeks of low mood that is present across most situations", "1989", "Liam Cunningham", "Michael Biehn", "Walter Pauk", "After Margaret Thatcher became Prime Minister in May 1979", "septum", "Gentry Buddhism", "forex market", "`` Despacito '' by Luis Fonsi and Daddy Yankee featuring Justin Bieber in 2017", "Sir Ernest Rutherford", "Nigel Lythgoe, Mia Michaels, and Adam Shankman", "late - night programming block Adult Swim", "gastrocnemius", "Al Pacino", "Thomas Hobbes in his Leviathan", "March 26, 1973", "1986", "a forest", "President Lyndon Johnson", "prenatal development of the human heart", "farofa stuffing, assortments of fruit, fried cod, and roast turkey with a dessert called `` rabanada ''", "1840", "2007", "Branson, Missouri", "first baseman", "Tumi Holdings, Inc.", "River Shiel", "Ozzy Osbourne", "Polo", "is \"very interested\" in buying the studios,", "ego", "Nova Scotia", "Isaac Newton", "Love Letter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7039434523809524}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, false, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.22222222222222224, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.3333333333333333, 0.0, 1.0, 0.4444444444444445, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4000000000000001, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-7852", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-4571", "mrqa_triviaqa-validation-7674", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096"], "SR": 0.609375, "CSR": 0.540296052631579, "EFR": 0.84, "Overall": 0.6924654605263159}, {"timecode": 57, "before_eval_results": {"predictions": ["France", "the namesake town of Manchester - by - the - Sea, Massachusetts", "the one - mile - wide ( 1.6 km ) strait connecting San Francisco Bay and the Pacific Ocean", "potential of hydrogen", "an advantage without deviating from basic strategy", "the Infamy Speech of US President Franklin D. Roosevelt", "the coffee shop Monk's", "Fats Waller", "January 2017 patch", "Ozzie Smith", "Mark Jackson", "2017", "House to expel a member with a two - thirds vote", "January 2018", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "September 30", "pigs", "Gerald Ford", "September 8, 2017", "1998", "political ideology", "Spektor", "an object", "the nucleus", "1974", "on Thursdays at 8 : 00 pm ( ET )", "Ren\u00e9 Verdon", "transposition raises or lowers the overall pitch range, but preserves the intervallic relationships of the original scale", "the contestant", "a dysphemic vocalisation in the Second Temple period of a theonym based on the root litresk `` king ''", "P.V. Sindhu", "Carpenter", "Asuka", "126", "Scorpions", "Brazil, Turkey and Uzbekistan", "UNESCO / ILO Recommendation concerning the Status of Teachers", "upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "on an inward spiral where it would eventually cross the event horizon", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "prenatal development", "skeletal muscle and the brain", "American country music duo Brooks & Dunn", "Ireland", "Felicity Huffman", "1908", "Sir Henry Cole", "Long Island", "Eukarya", "commemorating fealty and filial piety", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "Irish Chekhov", "Gust Avrakotos", "\"Mosteller's brother-in-law\"", "Lance Cpl. Maria Lauterbach", "step up", "Prohibition", "Joe Louis", "Richard Cory", "ancient Mayan settlement"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6094146693330957}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false], "QA-F1": [0.0, 0.7272727272727273, 0.375, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.21052631578947367, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06451612903225806, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.4444444444444445, 0.9142857142857143, 0.0, 0.9600000000000001, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-5435", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_hotpotqa-validation-572", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-5291", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.515625, "CSR": 0.5398706896551724, "EFR": 0.8064516129032258, "Overall": 0.6856707105116796}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "Idaho", "July 18, 2013", "Deuteronomy", "enzymes break down the long chains of amino acids", "1979", "England and Wales", "iron", "Detective Eddie Thawne", "Los Angeles, California", "British Empire", "Jaffa cakes", "\"Lady Arbuthnot's Chamber ''", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "between 1923 and 1925", "the brain and spinal cord", "Seattle, Washington", "( 27 January -- 16 April 1898 )", "the slopes of Mt. Hood in Oregon", "Gugu Mbatha - Raw", "LED illuminated display", "turkey", "1917", "January 2004", "Anna Faris", "smen", "Mount Sinai", "Macon Blair", "non-coding sequences", "by each state's DMV, which is required to drive", "France's Legislative Assembly", "four", "divergent tectonic", "Steve Russell", "peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "the Northeast Monsoon", "on 13 February", "291", "early 1960s", "Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "2003", "Zoe Zebra", "dysmenorrhea", "1960", "Justin Trudeau", "2006", "Walldorf", "his superhero roles as the Marvel Comics characters Steve Rogers / Captain America in the Marvel Cinematic Universe and Johnny Storm / Human Torch in \"Fantastic Four\" and.", "crude oil", "peppermint oil, a drug for chronic constipation, food modification, acupuncture, and laxatives", "the FBI", "a leech", "Leland Stanford", "de Jurez", "Southeast Asia"], "metric_results": {"EM": 0.390625, "QA-F1": 0.5929608662636681}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, true, false, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.45714285714285713, 0.5, 0.6666666666666666, 0.0, 0.3333333333333333, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.3076923076923077, 0.33333333333333337, 0.8, 0.0, 0.2857142857142857, 0.5, 0.5, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 0.19999999999999998, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.5945945945945945, 1.0, 0.0, 0.5714285714285715, 0.8, 1.0, 0.4, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3448275862068966, 0.0, 0.41666666666666663, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-567", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-7968", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-4072", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-9332", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-3485", "mrqa_naturalquestions-validation-10561", "mrqa_triviaqa-validation-3434", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-10231", "mrqa_triviaqa-validation-1216"], "SR": 0.390625, "CSR": 0.5373411016949152, "EFR": 0.8205128205128205, "Overall": 0.6879770344415471}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Justin Timberlake", "Biotic -- Biotic resources are obtained from the biosphere ( living and organic material ), such as forests and animals, and the materials that can be obtained from them", "IIII", "useless, time - wasting activity", "quarterback", "July 2012", "`` Audrey II ''", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "January 2018", "John Prine and Roger Cook", "\u2212 89.2 \u00b0 C ( \u2212 128.6 \u00b0 F ) at Vostok Station", "Herman Hollerith", "94 by 50 feet", "transmission, which contains a number of different sets of gears that can be changed to allow a wide range of vehicle speeds", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "October 1, 2014", "Marvin Gaye", "required many hospitals, nursing homes, home health agencies, hospice providers, health maintenance organizations ( HMOs ), and other health care institutions to provide information about advance health care directives to adult patients", "Roxette", "Long Island", "1988", "Germany", "Rococo - era France", "Michael Crawford", "Devastator", "the five - year time jump for her brother's wedding to Serena van der Woodsen", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 3, 1945", "1969", "Napoleon Bonaparte", "Morty", "by the early - to - mid fourth century the Western Christian Church had placed Christmas on December 25, a date that was later adopted in the East", "Made a decision to turn our will and our lives over to the care of God as we understood Him", "Leon Battista Alberti", "January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York,", "Efren Manalang Reyes", "Joker Wild,", "Chicago", "dijon", "Lucas Stephen Grabeel", "15,024", "model", "the test results by the medical examiner's office, Garavaglia said.", "15-year-old", "Sunday", "Vietnam", "a double bass", "Richard", "Ken Garito"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6762462645137199}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, false, false, false, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07999999999999999, 0.0, 0.8, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8421052631578948, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 0.0, 0.0, 0.9090909090909091, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.37037037037037035, 0.2580645161290323, 0.5454545454545454, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-10459", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-3750", "mrqa_triviaqa-validation-34", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_newsqa-validation-3928", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-7581"], "SR": 0.578125, "CSR": 0.5380208333333334, "EFR": 0.8518518518518519, "Overall": 0.6943807870370371}, {"timecode": 60, "before_eval_results": {"predictions": ["a recognized group of people who jointly oversee the activities of an organization, which can be either a for - profit business, nonprofit organization, or a government agency", "1996", "used their knowledge of Native American languages as a basis to transmit coded messages", "Gilbert building", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "writ of certiorari", "southern USA", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "honey", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Lorenzo Lamas", "Mahatma Gandhi", "people of France to the people of the United States", "eighth and final season", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "1990", "James `` Jamie '' Dornan", "left coronary artery", "Jane Fonda", "Brazilian state of Mato Grosso to its confluence with the Paran\u00e1 River north of Corrientes and Resistencia", "Nicklaus", "1957", "Clare Torry", "ummat al - Islamiyah", "Brazil", "Parashara", "Domhnall Gleeson", "Brazil and Paraguay", "agriculture", "St. John's, Newfoundland and Labrador", "Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman ''", "plant anatomy", "the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "an episode typically ends as a cliffhanger showing the first few moments of Sam's next leap ( along with him again uttering `` Oh, boy! '' on discovering his situation ),", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1966", "alluvial plain", "possible radio broadcasting, including community and hospital stations that can't fit on DAB", "Peter Sellers", "Colonel Tom Parker", "Atlantic", "mistress of the Robes", "Australian Electoral Division", "Conway", "Kurt Cobain's", "\"Empire of the Sun,\"", "Stephen Dedalus", "The Killing Fields", "Endeavour", "News of the World tabloid."], "metric_results": {"EM": 0.53125, "QA-F1": 0.6610395247113997}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, false], "QA-F1": [0.625, 0.0, 0.06666666666666667, 1.0, 0.0, 1.0, 0.9142857142857143, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.5, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 0.6363636363636364, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.05714285714285715]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-2900", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_searchqa-validation-1451", "mrqa_newsqa-validation-1282"], "SR": 0.53125, "CSR": 0.5379098360655737, "EFR": 0.8, "Overall": 0.6839882172131148}, {"timecode": 61, "before_eval_results": {"predictions": ["May 26, 2017", "to form a higher alkane", "Dimitar Berbatov and Carlos Tevez", "Jason Marsden", "New Mexico", "In 1889, following the Local Government Act 1888, using those same boundaries, Sussex was divided into two administrative counties, East Sussex and West Sussex together with three self - governing county boroughs, Brighton, Eastbourne and Hastings", "Poems : Series 1", "William the Conqueror", "February 16, 2016", "July 20, 2017", "five", "December 19, 1971", "James Rodr\u00edguez", "Oceania", "The Vamps, McGregor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "Mickey Rourke", "John Donne", "the 1980s", "David Gahan", "Emma Watson", "Continental Congress", "2018", "The first bull running is on 7 July, followed by one on each of the following mornings of the festival, beginning every day at 8 am", "the 2009 model year", "no more than 4.25 inches ( 108 mm )", "Judi Dench", "November 27, 2017", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "1836", "Thomas Jefferson", "Elijah Wood", "cat in the hat knows a lot about space movie", "Brad Dourif", "counter clockwise direction", "Joanne Wheatley", "President pro tempore of the Senate", "the rise of literacy, technological advances in printing, and improved economics of distribution", "Kristina Wagner", "1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "the lower motor neurons, the efferent nerves that directly innervate muscles", "1773", "Each side had about 18,000 poorly trained and poorly led troops in their first battle", "Don Cook", "kippis", "Australia", "The Pilgrim's Progress", "Bourbon County", "Venancio Flores", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's sons", "(Jack) London", "Arthur C. Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5648288170163169}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, false, false, false, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, true, false, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.05714285714285715, 0.24000000000000002, 1.0, 0.3333333333333333, 0.0, 0.5, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.07692307692307691, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.18181818181818182, 1.0, 0.8, 1.0, 0.28571428571428575, 0.5, 0.0, 0.8, 1.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-1916", "mrqa_naturalquestions-validation-10285", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-4647", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-2842", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-1887", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_triviaqa-validation-4519"], "SR": 0.46875, "CSR": 0.5367943548387097, "EFR": 0.7352941176470589, "Overall": 0.6708239444971538}, {"timecode": 62, "before_eval_results": {"predictions": ["December 13, 1917 -- September 20, 2009", "beneath the liver", "Rudy Clark", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "Byzantine Greek culture and Eastern Christianity became founding influences in the Arab / Muslim world and among the Eastern and Southern Slavic peoples", "toys or doorbell installations", "microfilament", "in the pancreas by protein biosynthesis as a precursor called chymotrypsinogen that is enzymatically inactive", "the center of the Northern Hemisphere", "`` A.D. ''", "Eduardo", "M\u00e1ximo Gomez and Antonio Maceo", "1971", "Leo Arnaud", "the raconteur ( Austin Winkler ) and his former lover ( Emmanuelle Chriqui )", "Carlos Alan Autry Jr.", "16 March 2018", "the Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "the courts", "1936", "Eric Clapton", "Djokovic", "Abraham Gottlob Werner", "1922", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Toronto City Airport", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco", "2013", "Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the fourth season", "Phillip Paley", "1981", "the birth centenary of Pandit Jawaharlal Nehru", "New Orleans going north through Chicago and to New York", "the port of Nueva Espa\u00f1a to the Spanish coast", "10.5 %", "ecological regions", "White House Executive chef", "Bangladesh -- India border", "Christian rock band MercyMe", "the Bank of England", "Thabo Mbeki", "Midnight Cowboy", "Austrian", "heavy metal drummer", "Selden", "Muslims", "five minutes before commandos descended from ropes that dangled from helicopters,", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Chastity", "the Entente Council", "Oshkosh", "River Welland"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6072208318302068}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, false, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.5454545454545454, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.625, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-3482", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6970", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-7484", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-10077", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_hotpotqa-validation-1201"], "SR": 0.53125, "CSR": 0.5367063492063492, "EFR": 0.9333333333333333, "Overall": 0.7104141865079365}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "1998", "the closing of the atrioventricular valves and semilunar valves, respectively", "the Coppolas", "SI joint", "Identification of alternative plans / policies", "Mexico", "development of electronic computers in the 1950s", "Employers", "Numbers 22 : 28", "Bhupendranath Dutt", "Charlotte of Mecklenburg - Strelitz", "March 23, 2018", "at luncheon", "Andrew Dice Clay", "Jakkur, Bangalore, India", "Five years later", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "Incudomalleolar joint", "Terry Reid", "long - standing policy of neutrality was tested on many occasions during the 1930s", "Kennedy Space Center ( KSC ) in Florida", "targeted the enterprise application development market", "Forbes Burnham", "Saturday", "Isekai wa Sum\u0101tofon to Tomo ni", "the tsar's Moscow residence", "the court from its members", "Alicia Vikander", "over 300,000", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "eight", "Lori Rom", "a Czech word, robota, meaning `` forced labor ''", "Arlen `` The Chief '' Bitterbuck", "Cameron Fraser", "Austin and Pflugerville", "1933", "Exodus 20 : 7", "four", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "Utah, Arizona, Wyoming, and Oroville, California", "Dan Enright", "Hugo Weaving", "from the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "Belle Del Rey", "The Matterhorn", "calypso", "Jape", "The Pentagon", "Pisgah National Forest (Croatan, Nantahala, and Uwharrie)", "Johnnie Ray", "Robert Mugabe", "Capitol Hill", "discussed water shortages in the major Tigris and Euphrates rivers, which run through all three countries.", "impressionist", "Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.40625, "QA-F1": 0.540592452890247}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, false, true, true, true, true, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, false, true, false, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.5882352941176471, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.4, 0.5714285714285715, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.14285714285714288, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.9523809523809523, 0.5, 0.0, 1.0, 0.11764705882352941, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.7272727272727273, 0.0, 1.0, 1.0, 0.16, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-2940", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-8341", "mrqa_naturalquestions-validation-3801", "mrqa_naturalquestions-validation-7669", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-3339", "mrqa_hotpotqa-validation-4240", "mrqa_newsqa-validation-198", "mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-8333"], "SR": 0.40625, "CSR": 0.53466796875, "EFR": 0.7631578947368421, "Overall": 0.6759714226973684}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League group stage", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Foxborough, Massachusetts", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Temple Sanchez", "Vanessa Hudgens", "Liga MX", "Amber Laura Heard", "Peter Seamus O'Toole", "March 8, 1942", "\"Electron Blue\"", "January 30, 1930", "Doctor of Philosophy", "The Government of Ireland (Irish: \"Rialtas na h\u00c9ireann\"", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "the third", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes o' Bowhether\"", "Westminster system", "Ionolyce", "For Love alone", "October 4, 1970", "King of the Polish-Lithuanian Commonwealth", "Sam Waterston", "Transporter 3", "March 14, 2000", "Gauteng province", "Vietnam War", "William Theodore Walton III", "the Darling River", "Brian Keith Bosworth", "over 140 million", "American", "Teri Garr", "the employer", "the 1965 -- 66 season", "Wyoming", "Wee Jimmy Krankie and his father,", "anger or of becoming angry", "ordered the immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guant Bay, Cuba.", "The clothing must be black, red or white,", "trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "American alternative rock band", "Ellicott City", "a short distance", "Southport, North Carolina"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6014745670995671}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, true, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.8, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.8, 0.5, 0.0, 1.0, 0.5, 0.14285714285714285, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.48484848484848486, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1263", "mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-5297", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2569", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-3275", "mrqa_hotpotqa-validation-2442", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9071", "mrqa_searchqa-validation-16474"], "SR": 0.46875, "CSR": 0.5336538461538461, "EFR": 0.7941176470588235, "Overall": 0.681960548642534}, {"timecode": 65, "before_eval_results": {"predictions": ["Stephen Lee", "Archer", "Albert", "September 30, 2017", "339,520", "New York Giants", "the Swiss tourism boom", "Eliot Cutler", "the 1946 Winecoff Hotel fire", "Odense Boldklub", "Stephen of Blois", "Scott Eastwood", "Gweilo", "Tufts College", "Prince Amedeo", "1936", "The Wu-Tang Clan", "\"For Love alone\" (1986)", "a song recorded by the American rapper Eminem,", "melodic hard rock", "G\u00e9rard Depardieu", "rural", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Philadelphia", "Kings Point, New York", "Robert Paul \"Robbie\" Gould III", "\"The Gang\"", "Baldwin", "Port Clinton", "November 20, 1942", "Wayne Conley", "on the Australian coast", "Faith", "turns out to be a terrible date", "the Cleveland Celtics", "Everybody Hates Chris", "fructose", "eight", "the regime of Emperor Napoleon III", "Sippin' on Some Syrup", "James Harrison", "James II", "Arabella Churchill", "Lester Ben \"Benny\" Binion", "two Grammy awards", "S7", "2017", "Qutab Ud - Din - Aibak", "14 November 2001", "colonists of the Thirteen Colonies who rebelled against British control", "Luxembourg", "Margaret Thatcher", "The Muffin Man", "President George Bush", "as many as 250,000", "former boxing champion Vernon Forrest,", "a dessert", "blown", "mythical", "Jamie Lee Curtis"], "metric_results": {"EM": 0.5, "QA-F1": 0.6240990780053279}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, false], "QA-F1": [0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.25, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.0, 1.0, 0.3333333333333333, 0.8571428571428571, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1941", "mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4733", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-5245", "mrqa_hotpotqa-validation-5497", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2978", "mrqa_naturalquestions-validation-10202", "mrqa_triviaqa-validation-2994", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-30", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.5, "CSR": 0.5331439393939394, "EFR": 0.9375, "Overall": 0.7105350378787879}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Hillsborough", "Paraguay", "steam locomotives", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambilevous", "Louis Daguerre", "Richard Feynman", "strata", "an international award given each year to a living architect who, in the opinion of select Pritzker Prize jury, has made profound achievements in the world of architecture.", "Guy Fawkes Night", "a man holding up a lighted match", "Port Moresby", "orange", "Kursk nuclear submarine", "pyrotechnic", "badminton", "Annie Lennox", "a goose", "Olympics", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "Martin Van Buren", "Ellice Islands", "Meta", "the Oil Capital of Europe", "about a mile north of the village of Dunvegan", "a double basses", "The Spice Girls", "\"Mr Loophole\"", "Istanbul", "drinking song", "Texas", "Pablo Picasso", "Yalta Conference", "Rajasthan", "African violet", "bali", "MetroLyrics", "Cardigan", "notorious Welsh pirate Edward Kenway, grandfather and father of Assassin's Creed III protagonist and antagonist Ratonhnhak\u00e9 : ton and Haytham Kenway respectively", "Djokovic", "1912", "fennec fox", "1950", "Prince Nikolai Sergeyevich Trubetzkoy", "Vernon Forrest,", "Linda Hogan,", "since the Berlin Wall has fallen there has been a renaissance of the game in the region.", "N.C. Wyeth", "viruses", "Stephen Alan \" Steve\" Wynn", "substitute good"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6607382246376812}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, true, false, true, true, true, false, false, true, false, false, true, true, false, true], "QA-F1": [0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07999999999999999, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.17391304347826086, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-2811", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-2232", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-4090", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391", "mrqa_newsqa-validation-491", "mrqa_searchqa-validation-7189"], "SR": 0.59375, "CSR": 0.5340485074626866, "EFR": 0.8076923076923077, "Overall": 0.6847544130309988}, {"timecode": 67, "before_eval_results": {"predictions": ["$249", "Thailand", "Ireland", "nude beaches.", "flooding", "Werder Bremen", "Secretary of State", "Obama", "21 percent", "Fernando Caceres", "an Italian and six Africans", "an accident", "best-of-three series.", "the 11th century Preah Vihear temple", "Uzbekistan", "voluntary manslaughter", "Jenny Sanford", "celebrity-inspired names", "Miami Beach, Florida", "\"Dear John,\"", "cell phones.", "two contestants.", "Fiona MacKeown", "juror Larry Flynt.", "Graeme Smith", "former U.S. secretary of state.", "timothy Darlington, manager of Anderson Municipal Airport, told CNN the plane was in fine condition at takeoff, and said Schrenker is \"an accomplished pilot\" who owns \"a couple of airplanes\" and flies regularly.", "54-year-old", "from Thursday and Friday to the end of her tour on June 17 and 18,", "helicopters and boats, as well as vessels from other agencies,", "terrorize", "tickets to Italy", "Oxbow,", "FAA received no reports from pilots in the air of any sightings but the agency recieved \"n numerous\" calls from people on the ground from Dallas, Texas, south to Austin, Texas.", "21-year-old", "Jacob Zuma", "traffelmakaren", "Gary Brooker", "a civil disturbance call", "Pew Research Center", "take immunosuppression drugs for life so that the body does not reject the donated tissue,", "Kenyan and Somali governments", "30,000", "1983", "discusses his roots as he castigates U.S. policies and deplores Israel's offensive in Gaza that started in late December 2008 and continued into January.", "North Korea", "Steve Jobs", "Garth Brooks", "40-year-old", "Twitter", "1983", "Carolyn Sue Jones", "The Nitty Gritty Dirt Band", "in Christian eschatology", "Phil Mickelson", "Dumbo", "blues", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "Julie Taymor", "Marilyn Monroe", "director", "help batterers work to change their attitudes and personal behavior so they would learn to be nonviolent in any relationship"], "metric_results": {"EM": 0.484375, "QA-F1": 0.575773908510189}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, false, true, false, true, false, false, true, false, true, true, false, false, true, true, false, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.0, 1.0, 0.5, 0.8571428571428571, 1.0, 0.24390243902439027, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.14285714285714288, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2271", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2149", "mrqa_newsqa-validation-1093", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-293", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-190", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.484375, "CSR": 0.5333180147058824, "EFR": 0.7878787878787878, "Overall": 0.6806456105169341}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura this year.", "from the capital, Dhaka, to their homes in Bhola for the Muslim festival of Eid al-Adha.", "off Somalia's coast.", "Flint, Michigan.", "AS Roma beat Lecce 3-2", "President Barack Obama,", "Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday in Los Angeles.", "an American who entered the country illegally", "2000", "at least 300", "Thursday,", "volatile and dangerous.", "passengers on the Miva Marmara", "the same drama that pulls in the crowds", "2008", "root out terrorists within its borders.", "25 years", "finding of \"a whole new treasure loot of fossils\"", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford,", "northwestern Montana", "genocide", "stealing the personal credit information of thousands of unsuspecting American and European consumers,", "out in the woods", "German authorities", "Venus Williams", "Black History Month", "How I Met Your Mother", "London and Buenos Aires", "Six", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "stand down", "his past and his future", "Mombasa, Kenya", "a loanword of the Visigothic word guma `` man", "Taron Egerton", "Treaty of Chaumont", "Hard Times", "purpurea", "Nellie Melba", "\"The King of Hollywood\"", "1958", "the backside", "Sweden", "spotted hyena", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6388155395136779}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.8, 0.13333333333333333, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.16666666666666666, 1.0, 1.0, 0.6666666666666666, 0.7142857142857143, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.21276595744680848, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.3, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-1280", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3677", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-4367", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.515625, "CSR": 0.5330615942028986, "EFR": 0.7741935483870968, "Overall": 0.677857278517999}, {"timecode": 69, "before_eval_results": {"predictions": ["the cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Texas A&M University", "Paradise, Nevada", "Detective Eddie Thawne", "Hathi Jr", "LED illuminated display", "Spektor", "The Star Spangled Banner", "Bill Russell", "a judge who lacks compassion is repeatedly approached by a poor widow, seeking justice", "by October 1986", "http://www.example.com/index.HTML", "solids", "1997", "Carol Worthington", "September 6, 2019", "1973", "1902", "SURFACE NOWA of ROOTS", "back", "Battle of Antietam", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Andrew Garfield", "normal conditions", "the 1980s", "Pasek & Paul", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "prospective studies", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "White House Executive chef", "place of trade, entertainment, and education", "25 years after the release of their first record", "the bank", "One Night in the Tropics", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation", "eucalyptus", "inflation", "Christies Foxhunters", "John M. Dowd", "December 17, 1974", "Northrop P-61 Black widow", "26", "The woman", "as soon as 2050,", "America's Story from America's Library", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7188616071428571}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.8, 0.3333333333333333, 1.0, 0.2857142857142857, 1.0, 0.0, 0.5714285714285715, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.75, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.09523809523809525, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-710", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_searchqa-validation-10785"], "SR": 0.640625, "CSR": 0.5345982142857143, "EFR": 0.8260869565217391, "Overall": 0.6885432841614907}, {"timecode": 70, "before_eval_results": {"predictions": ["President", "Walter Pauk", "Madison", "Brevet Colonel Robert E. Lee", "a specific task", "January 2, 1971", "minced meat ( commonly beef when named cottage pie or lamb when named shepherd's pie )", "St. Louis Cardinals", "the Carnaval de Qu\u00e9bec", "1792", "Longliners", "Sebastian Vettel", "Niles", "China", "2017", "Upstate New York", "Carol Ann Susi", "a stem", "Nala", "Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "investment bank Friedman Billings Ramsey", "the NFL", "on the world map", "1 January 1904", "a password recovery tool for Microsoft Windows", "from 35 to 40 hours per week", "by week 4 of development", "contemporary Earth", "somatic cell nuclear transfer", "UN General Assembly", "benzodiazepines", "two degrees of freedom", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "in the North Cascades range of, Washington", "Ray Charles", "a jazz funeral without a body", "2004", "May 31, 2012", "John De Vito", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "Beorn", "South Dakota", "Donald Trump", "100,000", "1967", "Rajasthan", "Sodor", "eyes", "44,300", "2008", "Anglo-Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "LEWIS CARROLL", "Thailand", "500-room"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6204989308757691}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, false, false, false, true, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.35294117647058826, 0.058823529411764705, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.5185185185185185, 0.8, 0.6, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333333, 1.0, 0.0, 0.0, 0.07999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-10625", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2577", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8673", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.53125, "CSR": 0.5345510563380282, "EFR": 0.8, "Overall": 0.6833164612676057}, {"timecode": 71, "before_eval_results": {"predictions": ["Mae West", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Striding Edge", "photographer", "a clown", "the Titanic", "Brundisium", "Hadrian", "Madagascar", "French school of landscape painters", "Nick Weall", "Manet", "Gary Sparrow", "Challenger", "Edinburgh City F.C.", "Lacock Abbey", "Clive Cussler", "Canada", "Gatcombe Park", "japonesa", "Glasgow", "ABBA", "Sonja Henie", "six", "Lord Snooty", "Greyfriars Bobby, Skye terrier", "Rudolf Hess,", "Royal Australasian College of Surgeons", "Stieg Larsson", "Facebook Music Stories", "1957", "a giant menhir stands, known as the giant manius", "steel", "Rotherham United", "Joseph Priestley", "a dog", "tennis", "Periodic Table", "CameroonCameroon", "region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Cuba", "From outside", "Patience", "Chubby Checker", "Tim Roth", "to establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three 12th hole", "San Francisco", "in the United States of America", "Brooke Wexler", "2004 Nokia Sugar Bowl", "aging issues", "January", "one of Europe's most experienced providers of carbon offset, where each project is rigorously audited and monitored for quality.", "businesses hiring veterans as well as job training for all service members leaving the military.", "40 lash after he was convicted of drinking alcohol in Sudan where he plays for first division side Al-Merreikh of Omdurman.", "6 counties in Ulster", "How do we know when irrational exuberance has unduly escalated asset values, which then become subject to unexpected and prolonged contractions as they have in Japan over the past decade?", "gun blast tubes", "UFC Fight Pass"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6167043130658061}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, true, true, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.08695652173913042, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-5039", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-8965", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-15899"], "SR": 0.578125, "CSR": 0.53515625, "EFR": 0.7037037037037037, "Overall": 0.6641782407407407}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby Darin", "Thames", "Altamont Speedway in Livermore, California.", "The Jetsons", "26.22", "tibia", "ocellaris", "Samson", "Connecticut", "Daedalus", "L\u00e1szl\u00f3 de Alm\u00e1sy", "Pandemonium", "a goad", "Miles Morales", "up to 14", "radars", "Queen Elizabeth II", "Tonto", "hippocampus", "Frank Miller", "tennis", "George Orwell", "Atlantic Ocean", "The discovery and colonisation of New Zealand by Polynesians.", "Chatsworth House", "dirk bikembergs", "London", "on the meibomian gland", "Husqvarna", "augusta", "Aug. 24, 1572", "fatty hump on their shoulders, drooping ears and a large dewlap", "Julius Caesar", "Venezuela", "Southwest Airlines", "SUNSET BOULEVARD", "hopper", "Derwill", "tahini", "Laos", "Allardyce", "General Henri-Philippe Petain", "Ryan O\u2019 Neal", "Miami", "Bill Haley & His comets", "bOW TIE PASTA", "1768", "Joan Rivers", "Athens", "William Refrigerator Perry", "Ghana", "the Near East", "observing the magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "U.S. Holocaust Memorial Museum", "Robert Barnett,", "Diego Milito's", "Rembrandt Harmenszoon van Rijn", "Dumbo the Flying elephant", "Casey at the Bat", "reticulated pythons"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5117715617715618}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, true, true, true, false, true, true, false, false, false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18181818181818182, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-5614", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7364", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5164", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-8205", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2030", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706", "mrqa_searchqa-validation-4802"], "SR": 0.421875, "CSR": 0.5336044520547945, "EFR": 0.7567567567567568, "Overall": 0.6744784917623102}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "Mercer University", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Washington", "Helen Mirren", "striker", "Nazi Party (NSDAP)", "Glenn Ford", "The Bye Bye Man", "Chevron Corporation", "ragby", "Indianapolis", "pastels and oil painting", "Premier League", "Sleepy Hollow", "Jane Mayer", "Obafemi Martins", "Knowlton School of Architecture", "143,007", "Philadelphia", "7", "model, actress and television host", "2 July 1903", "Carl David Tolm\u00e9 Runge", "King Duncan", "The St Andrews Agreement", "Royal College of Music", "4145 ft above mean sea level", "Japan Airlines Flight 123", "near North Chicago, in Lake County, Illinois", "HBO miniseries \"Empire Falls\"", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "main east-west road", "schoolteacher", "People v. Turner", "William Harold \"Bill\" Ponsford", "Aamina Sheikh", "one", "\"The Expendables 2\"", "Mike Holmgren", "Gauteng province", "Herman Hollerith", "6 -- 14 July", "weekly", "paramitas", "July 2, 1881", "writing", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Disney", "Christianity and Judaism", "blintz", "Texas Chainsaw Massacre III", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.5, "QA-F1": 0.6008212560946936}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, false, false, false, true, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0625, 0.6, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.8918918918918919, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-5790", "mrqa_hotpotqa-validation-5164", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-3069", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5795", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-4514", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-4105", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621", "mrqa_searchqa-validation-7139"], "SR": 0.5, "CSR": 0.5331503378378378, "EFR": 0.875, "Overall": 0.6980363175675676}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ribonucleic acid", "ketchup", "a house", "compound eyes", "Timberland", "former Texas governor", "Burma", "Latvia", "spleen", "auf wiedersehen", "rely", "Ramesses II", "wine", "esophagus", "Super Bowl VI MVP", "The King Jesus Gospel", "a twist", "Marie Tussaud", "Biscay", "Ziz", "March", "Ferdinand Magellan", "Kevin Spacey", "brothel", "an oblate spheroid", "The Aviator", "Gioachino Rossini", "Puebla", "a tail", "Tennessee", "Hanging Gardens of Babylon", "The Last Starfighter", "Billy Crystal", "skin cancer", "Henry Ford", "Qubec", "pontiff", "Mimi Bobeck", "Fiji", "Moonlighting", "Corpus Christi", "Homer's Mentor", "Ruth Bader Ginsburg", "Edward R. Murrow", "the Indian Ocean", "in vitro fertilization", "Diogenes Laertius", "pastries", "Whatchamacallit", "the Electric Company", "September 24, 2012", "Roger Dean Stadium", "March 31, 2013", "Helen Reddy", "Celsius", "Jeremy Irons", "monthly", "Jennifer Grey", "Donald Wayne Johnson", "giving birth to baby daughter Jada, who was watching her mum from the stands again on Saturday.", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6039855072463767}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, false, true, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, false, false, false, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5217391304347825, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9777", "mrqa_searchqa-validation-6585", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-6725", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-4454", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-9143", "mrqa_searchqa-validation-9557", "mrqa_naturalquestions-validation-5096", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-801"], "SR": 0.46875, "CSR": 0.5322916666666666, "EFR": 0.7647058823529411, "Overall": 0.6758057598039215}, {"timecode": 75, "before_eval_results": {"predictions": ["eleven", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "1765", "The Miracles", "1900", "provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm, allowing levels of gene regulation that are not available to prokaryotes", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "2006", "1976", "The Satavahanas", "Jos\u00e9 Mart\u00ed", "because they believed that it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK", "from 28 July 1914 to 11 November 1918", "Lager", "908 mbar", "North Atlantic Ocean", "February 7, 2018", "October 2000", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "on a sound stage in front of a live audience in Burbank, California", "Allsup", "American singer - songwriter - actress Debbie Gibson", "Atticus Finch's children", "31 January 1934", "Austin, Texas", "the southeastern United States", "gastrocnemius", "Daniel A. Dailey", "the commemoration of Jesus'birth", "President Yahya Khan", "Ramanaa", "function like an endocrine organ", "Kyla Coleman", "Bill Patriots", "September 1972", "Dennis Locorriere", "Garbi\u00f1e Muguruza", "Spanish / Basque origin", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Mae Jones", "Bell Labs", "Neil Young", "a marked ( `` - s '' ) or unmarked plural", "Chuck Noland", "indigenous to many forested parts of the world", "arithmetic", "Finger Tab", "Red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "President Felipe Calderon", "exercise", "0-0 draw", "Hapsburg", "Mexico", "coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.625, "QA-F1": 0.756203939909297}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, false, false, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.9795918367346939, 0.9523809523809523, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 0.28571428571428575, 0.05714285714285714, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.888888888888889, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-5304", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-4147", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-1646"], "SR": 0.625, "CSR": 0.5335115131578947, "EFR": 0.875, "Overall": 0.6981085526315789}, {"timecode": 76, "before_eval_results": {"predictions": ["$657.4 million in North America and $1.528 billion in other countries", "Total Drama Action", "Christopher Lloyd", "senators", "rape", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "layered systems of sovereignty", "Authority", "Archie Andrews", "American rock band Los Lonely Boys", "ecosystems", "cakes", "Kiss", "from 18 September to 31 October", "Julie Adams", "During World War II", "Anthony Quinn as Craig Belden", "January 2004", "The Vamps", "William T. Deutschendorf", "Tennessee Titan", "Stephen Stills'former girlfriend, singer / songwriter Judy Collins", "Turkish : Toros Da\u011flar\u0131, Ancient Greek : \u1f4c\u03c1\u03b7 \u03a4\u03b1\u03cd\u03c1\u03bf\u03c5 ) are a mountain complex in southern Turkey", "in various submucosal membrane sites of the body, such as the gastrointestinal tract, oral passage, nasopharyngeal tract, thyroid, breast, lung, salivary glands, eye, and skin", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1945", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2014 -- 15", "October 28, 2007", "Barry Corbin", "an anembryonic gestation", "a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "Christmas Tree", "IIII", "Virginia", "Saphira", "September 2017", "an Irish feminine name", "Ace", "Spike", "regulatory site", "When the others arrive", "Aegisthus", "InterContinental Hotels Group", "the Isthmus of Corinth", "Jason Flemyng", "the Isthmus of Corinth", "Norman Mailer", "a Bristol Box Kite", "Pye", "Part II", "17 October 2006", "biochemist and academic Dr. Alberto Taquini", "$1.5 million", "San Diego", "CNN.com", "jazz funeral", "echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6815847529663319}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, true, true, false, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, false, true, false, false, false, true, false, true, true, false, true, true, true, true], "QA-F1": [0.15384615384615385, 0.5714285714285715, 1.0, 1.0, 0.0, 0.8181818181818181, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 0.7999999999999999, 0.22222222222222224, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.0, 1.0, 0.6363636363636364, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-7461", "mrqa_triviaqa-validation-6055", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1166", "mrqa_newsqa-validation-3170"], "SR": 0.578125, "CSR": 0.5340909090909092, "EFR": 0.7777777777777778, "Overall": 0.6787799873737373}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 11", "Live and Let Die", "Giuliano Bugiardini", "electrons", "pulsar", "Seth", "Honda", "\"There's No-one Quite Like Grandma.\"", "Ozzy Van Halen", "Merchant of Venice", "FIFA World Cup 2010", "Elizabeth I", "June", "Italy", "1960s", "Mel Brooks", "Belgians", "chlorophyll", "Paul Dukas", "San Marino", "Uranus", "rum", "apples", "barber", "Roddy Doyle", "discus thrower", "Separate Tables", "sound of the human voice could be reproduced, which confirmed his theory that speech patterns can be made to change the intensity of an electrical current.", "Beatrix Potter", "Magpie", "Bill Haley & His comets", "volleyball (indoors and beach) and bobsleigh (includes skeleton)", "Kansas City", "Ra\u00fal Castro", "Space Oddity", "Scotland", "Butterflies", "Illinois", "green", "Splash", "South Africa", "menorah", "Finding Forrester", "gollum", "otters", "John McCarthy", "John Mortimer", "Cheerios", "line code", "Asia", "Liam Cunningham", "Brobee", "Fuenlabrada", "Ottawa Renegades", "E22", "security breach", "at checkposts and military camps in the Mohmand agency, part of the lawless Federally Administered Tribal Areas where U.S. and Pakistani officials have reported a presence of militants.", "Mashhad, Iran.", "St Bernard", "France", "Barnard College", "one day we will have no more oil and we'll have to find another way to live."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6138888888888889}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.4, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-4389", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-3824", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-693", "mrqa_triviaqa-validation-3464", "mrqa_triviaqa-validation-6105", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-3681", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-3964", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.546875, "CSR": 0.5342548076923077, "EFR": 0.9310344827586207, "Overall": 0.7094641080901857}, {"timecode": 78, "before_eval_results": {"predictions": ["japan", "Granada", "Daniel Fran\u00e7ois Esprit Auber", "April", "Al Pacino", "vVD Savarkar", "by increasing the number of arcs", "Mr. Golding", "a group of nuclei interconnected with the cerebral cortex, thalamus and brainstem, associated with a variety of functions: motor control, cognition, emotions, and learning.", "vitamin B3", "Director General of the Security Service", "quake", "Funchal", "hardwood", "spaghetti harvest", "enniskillen", "passport", "Marcel Duchamp", "quatermass experiment", "Mumbai", "daedalus", "1875", "raven", "hound", "Ernie", "Estimate", "$x", "Narendra Modi", "Wagner", "arpad \u2018Arki\u2019 Busson", "Argentina", "hard", "in Kitzb\u00fchel : Skiing in Tyrol", "Tunisia", "gail webb", "steppes steppe", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "Casino at Loews a full lock left hand 2nd gear 20mph bend, before the sharp right at Portier.", "darrin Stephens", "springtime for Hitler", "Holocaust memorial", "Eva Herzigov\u00e1", "David Hockney", "island of Ireland", "gambit", "horror fiction", "Colombia", "rolling hillsides", "1 - 2 spinal nerve segments above the point of entry", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "Tudor music and English folk-song", "Martin O'Malley", "1992", "sculptures", "Sunday's strike", "al-Shabaab", "The Old Man and the Sea", "Edward of Carnarvon, Prince of Wales", "vH1", "there were no radar outages and said it had not lost contact with any planes during the computer glitches."], "metric_results": {"EM": 0.4375, "QA-F1": 0.5132965686274509}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.25, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.11764705882352941, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.9, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1306", "mrqa_triviaqa-validation-5620", "mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1956", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-518", "mrqa_triviaqa-validation-3345", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_newsqa-validation-2485", "mrqa_searchqa-validation-7161", "mrqa_searchqa-validation-6534", "mrqa_newsqa-validation-904"], "SR": 0.4375, "CSR": 0.5330300632911392, "EFR": 0.8055555555555556, "Overall": 0.684123373769339}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "French", "HMS amethyst", "Libya", "tomato", "Kyoto Protocol", "costume", "bull moose", "headpan", "Jake La Motta", "resistance", "vetie McDaniel", "South Africa", "indigestion", "discretion", "evan shiwen", "The Apprentice", "George Washington", "Corinth Canal", "human rights lawyer", "Iceland", "ascot", "pear", "Bruce Jenner", "gangsters", "doe", "Duncan", "UKIP", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "franny", "julian WikiLeaks", "The IT Crowd", "\u00ef\u00bf\u00bd", "local police officer Rip Nix", "johnson barberdeau", "Richard Curtis", "Terms of Endearment", "China", "lagertha", "1790", "greenock", "chamomile", "driving Miss Daisy", "orchid", "Hilary Swank", "Aberdeen", "geodetic latitude 90 \u00b0 North, as well as the direction of true north", "18th century", "nine hours", "just 18 minutes", "England", "Sri Lanka Freedom Party", "goldenEye", "north Carolina", "Rodong Sinmun", "theology", "Cyd Charisse", "sanctions", "February"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6998958333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.16, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-374", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-959", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_newsqa-validation-1857", "mrqa_searchqa-validation-2116"], "SR": 0.640625, "CSR": 0.534375, "EFR": 0.8260869565217391, "Overall": 0.6884986413043478}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Eleanor Roosevelt", "senators", "2", "dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Jason Momoa", "1969", "Tim Passmore", "2002 -- 2003", "5 : 7 -- 8", "the Hudson Bay", "H CO ( equivalently OC (OH ) )", "Miami Heat", "scheduled to end on September 30", "four", "manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas", "0.05 ( 5 % )", "Australian reality television talent show which premiered on 18 February 2007 on the Seven Network", "a multilayer", "Tulsa, Oklahoma", "Kristy Swanson", "Joanna Moskawa", "Bonanza Creek Ranch", "Tbilisi", "genome", "North Atlantic Ocean", "Native American nation", "United Nations", "as of October 1, 2015, when the green class A was retired", "2026", "318", "Director of National Intelligence", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "September 28, 2017", "Staci Keanan", "the Mayflower", "1837", "Lagaan", "1996", "American rock band Los Lonely Boys", "appearances", "foreign exchange market (FX )", "the Coppolas", "Sunday Post", "Karl Pilkington", "peking", "1860", "Back to December", "Buck Owens", "to get there, he launches his house into the sky thanks to thousands of balloons.", "\"Empire of the Sun,\"", "off east  Africa", "modify", "Anne Juergens", "faerie", "skull and crossbones"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7424189814814814}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.14814814814814817, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8444", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-2967", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-7286", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-10600", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-691"], "SR": 0.671875, "CSR": 0.5360725308641976, "EFR": 0.8571428571428571, "Overall": 0.6950493276014109}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "shanghai", "Berenice III", "nuclear tests", "capitals", "pepperoni minis", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Auguste Deter", "The O.J. Simpson trial", "a spinning jenny", "gestation", "ravens", "J.R. R. Tolkien", "James Franco", "Blue Ridge Mountain Range", "Georgia", "a bathrobe", "buddha", "Apple", "a slave insurrection in Southampton, Virginia,", "a catfish", "A Chorus Line", "Frommer", "Robbie Turner", "a feeling of sorrow, guilt or... regret A courteous expression of regret, especially at having to decline an invitation", "de Havilland", "Virginia", "College of William and Mary", "small", "Louisiana", "Matthew Vassar", "Japan", "cutlery", "The Police", "Air France", "Fnelon", "drove the hero mad, making him kill his wife Megara and his children.", "to trudge", "Violent", "Albert Camus", "Volvo", "Rhode Island", "falsetto", "Indian Ocean", "a syringe", "Charlotte Corday", "a nanosecond", "bats", "Mason Alan Dinehart", "chain elongation", "on location", "2010", "cymbal", "Madagascar", "Thomas William Hiddleston", "Estadio Victoria", "Allerdale", "Mugabe's opponents", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6445684523809523}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-9895", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-13394", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-506", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-868"], "SR": 0.546875, "CSR": 0.5362042682926829, "EFR": 0.8275862068965517, "Overall": 0.6891643450378468}, {"timecode": 82, "before_eval_results": {"predictions": ["Nautilus", "Hopi", "Vatican City", "Pope John Paul II", "the Yangtze River", "Gnarls Barkley", "the Parthenon", "Jack Canfield", "Marilyn Monroe", "kebab", "Richard III", "the bald eagle", "the National Gallery of Art", "155", "Baha de Darwin, Spanish for \"Darwin Bay.\"", "(Dutch) Frank Cavendish", "the Chicago White Sox", "an Abyssinian", "Monin Pomegranate Syrup", "Constantine", "Aleutian", "alchemy", "art nouveau", "the Autobahn", "Anglo-Saxon", "California quail", "curtsy", "lacrosse", "Toronto", "acute accent", "King David", "Riboflavin", "plumes", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "The Hobbit", "the Red Sox", "William Claude Dukenfield", "Yale University", "Graceland", "the Caspian Sea", "point", "James E. and Anne Collier Rehill", "Prince Edward Island", "Westminster Abbey", "Superbad", "the Granite State", "1885", "$2.187 billion", "Isle Vierge ( 48 \u00b0 38 \u2032 23 '' N 4 \u00b0 34 \u2032 13 '' W \ufeff 48.63972 \u00b0 N 4.57028 \u00b0 W", "Austria", "maqui berry", "the Benedictine Order", "Pansexuality", "authorship of Titus Andronicus", "getaway driver", "Drew Kesse,", "the pregnancy.", "eight-week", "1999"], "metric_results": {"EM": 0.5, "QA-F1": 0.5885557432432432}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.5675675675675675, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-12135", "mrqa_searchqa-validation-16250", "mrqa_searchqa-validation-13920", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-12190", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-2505", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-9427", "mrqa_searchqa-validation-5031", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_newsqa-validation-3331", "mrqa_hotpotqa-validation-943"], "SR": 0.5, "CSR": 0.5357680722891567, "EFR": 0.9375, "Overall": 0.7110598644578314}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "a typical male face", "penguins", "vrai", "Napoleon", "A.J. Foyt", "vulture", "Nantucket", "Ebony", "Trinity College", "Algeria", "Joseph Haydn", "Dick Cheney", "Jeopardy", "a number", "Saturday Night Fever", "Japan", "a focaccia", "a turtle", "the Empire State Building", "white", "a picayune", "dogwood", "Qubec", "Larry McMurtry", "Kellogg's", "Helen of Troy", "the sweatshirt", "Fd", "Napoleon", "wood", "Spmi", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "Ba", "Pancho Gonzales", "the Aleutians", "Latter-day Saints", "Lady Jane Grey", "Tommy Tutone", "the crescent moon", "Iraq", "a silk worm", "Nicolaus Copernicus", "Stuffed Poblano Chiles", "Craig", "the Dominican monastery of this Church", "to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "Casablanca", "Theodore Roosevelt Mason", "Parlophone", "Wednesday.", "Daryeel Bulasho Guud", "1995", "four"], "metric_results": {"EM": 0.5, "QA-F1": 0.5817708333333333}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true], "QA-F1": [0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-9848", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-12923", "mrqa_searchqa-validation-16443", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-5531", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-546", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-12014", "mrqa_searchqa-validation-5412", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1916", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-502", "mrqa_hotpotqa-validation-3182", "mrqa_newsqa-validation-1339", "mrqa_newsqa-validation-537"], "SR": 0.5, "CSR": 0.5353422619047619, "EFR": 0.96875, "Overall": 0.7172247023809524}, {"timecode": 84, "before_eval_results": {"predictions": ["the Czech Republic", "Henry VIII", "Judas Iscariot", "Windsor, Ontario", "Stephen Douglas", "comrade", "Paradise", "a fox", "Sexuality", "Salaries", "Solomon", "John McEnroe", "a bicycle", "Johnson County", "La Fea", "push", "Alexander Solzhenitsyn", "farce", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "Daughters of the American Revolution", "Manila", "St Mark", "Eragon", "The Beatles", "Louisiana", "Mexico", "a pirate", "engrave", "Daisy Miller", "The Stag", "Y", "a ship", "Kamehameha I", "a deer", "Jamestown", "Wikiquote", "the north magnetic pole", "Oyster Bar", "an Italian-American", "Candlestick Park", "Zimbabwe", "0.49 m", "Patty Duke", "Pronouns", "Hoffmann", "a calico cat", "Frankie Muniz", "season two", "a complex sentence", "40", "Neptune", "Nowhere Boy", "August 1973", "an Anglo-Saxon tumulus (or \"barrow\")", "Richa Sharma", "Carrefour", "financial gain", "a Nazi concentration camp,", "\"Tiger Woods will \"apologize for his behavior\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.6638020833333333}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, false, true, true, true, true, true, true, false, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-6178", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-10285", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-11433", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-8044", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_searchqa-validation-9898", "mrqa_naturalquestions-validation-9752", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.59375, "CSR": 0.5360294117647059, "EFR": 0.8076923076923077, "Overall": 0.6851505938914026}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "Ayn Rand", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Ezra Cornell", "\"Strawberry Fields Forever\"", "The Hague", "Geena Davis", "pharmacy", "(HALF)", "the NFL", "Doolittle", "air", "Shakespeare", "Floyd Mayweather Jr", "ABBA", "the League of Nations", "Marlee Matlin", "the NIV", "The X-Files", "Babar the elephant", "Mensa International", "Edward Hopper", "oratorios", "steak", "a voodoo sorcerer", "Booster", "the Church of Jesus Christ of Latter-day Saints", "Italy", "a watermelon", "the Warsaw Pact", "Sparta", "the Sunday New York Times", "anode", "Star Trek", "The National Teachers Hall of Fame", "the Bicentennial", "the Cherokee", "hair", "the Texas Rangers", "Fluoxetine", "H CO ( equivalently OC (OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College", "Leeds", "Bexar", "Dwight D. Eisenhower", "Battleship", "\"Shake It Off\"", "ketamine.", "has to move out of her rental house because it is facing foreclosure", "Why he's more American than a German,", "Charles Sherrington"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6609375}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-6109", "mrqa_searchqa-validation-15693", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-12611", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_newsqa-validation-2692"], "SR": 0.59375, "CSR": 0.5367005813953488, "EFR": 0.7307692307692307, "Overall": 0.6699002124329159}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy Feet", "a sprint", "a Himalayan Yeti", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "Palatine", "Death Valley", "Mississippi", "Alpha", "Quebec City", "nacre", "Texas Chainsaw Massacre", "the oculus", "a Medal of Honor", "Manet", "Plutarch", "Mediolanum", "Corin", "Shropshire", "a kidney", "Afghanistan", "satin", "Lady Godiva", "Job", "Vasco da Gama", "The Little Puffer", "a cordovan", "Finnegans Wake", "aleikum", "the black market", "professor of higher education", "S-waves", "Maastricht", "Delilah", "synapses", "croissant", "Rocky Down Mexico Way", "lungs", "fuchsia", "metacarpal", "a pool", "Warsaw", "a trowel", "Mercury", "Taiwan", "Gettysburg", "the United States", "trout", "slow", "1959", "season two", "$75,000", "Malawi", "15", "doge's Palace", "Agent Carter", "Orson Welles", "Manhattan", "56", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6052083333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-6341", "mrqa_searchqa-validation-18", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-6251", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-4065", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-15786", "mrqa_searchqa-validation-12181", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-2509", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.546875, "CSR": 0.5368175287356323, "EFR": 0.7931034482758621, "Overall": 0.6823904454022989}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the Alfonsists and the Carlists", "Michael Crawford", "Sonu Nigam", "Pat McCormick", "Louis Mountbatten", "David Ben - Gurion", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770 guaranies", "Geoffrey Zakarian", "$72", "Mary Elizabeth ( Margaret Hoard )", "Jeff Gillen", "Milan, Italy", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Harry Kane", "Robert Duvall", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "slavery", "Donny Osmond", "political pamphlet written by the Russian revolutionary Vladimir Lenin in 1901 and published in 1902", "island countries", "an unmasked and redeemed Anakin Skywalker", "Alexander Salkind", "one", "Mary Elizabeth Ellis", "Jesse Triplett", "Kevin Garnett", "a star", "Brazil", "Instagram's own account", "Washington", "by the early 3rd century", "offensive player", "in his first year at the Hogwarts School of Witchcraft and Wizardry", "Dimitar Berbatov and Carlos Tevez", "foreign investors", "Napoleon", "the inverted - drop - shaped icon that marks locations in Google Maps", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "User State Migration Tool", "Robber baron", "December 20, 1951", "Crick", "Aconcagua", "Bake Off", "2002", "Eugene Levy", "Aldosterone", "Nicole Kidman", "last summer", "to get involved in service and volunteerism in their communities.", "fourth", "banker", "eyelid", "the Cubs", "thief"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5637281360470969}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.782608695652174, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7741935483870968, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.10256410256410257, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-2524", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-5696", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-3658", "mrqa_naturalquestions-validation-5989", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-1027", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-5041", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-397", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.46875, "CSR": 0.5360440340909092, "EFR": 0.8823529411764706, "Overall": 0.7000856450534759}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany", "A 22-year-old college student in Boston, Massachusetts,", "a bag", "Roger Federer", "Veracruz, Mexico,", "Diego Milito", "Because their age, race or medical history, the female patients probably shared a similar experience during the 20-minute procedure.", "Lashkar-e-Jhangvi, was planning to conduct attacks in Karachi,", "Salt Lake City, Utah,", "normal maritime traffic", "Toffelmakaren", "to protect ocean ecology, address climate change and promote sustainable ocean economies.", "Rocky Ford brand cantaloupes", "\"The oceans are growing crowded, and governments are increasingly trying to plan their use.", "Two suspects are in custody.", "\"We want to reset our relationship and so we will do it together.'\"", "club managers", "Long Island", "90", "the FBI.", "Reggae legend Lucky Dube,", "the Kurdish militant group in Turkey", "At least 14", "\"It hurts my heart to see him in pain, but it enlightenedens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin Fritzl,", "Justice Department motion filed last week in support of the Defense of Marriage Act -- which effectively bars the federal government from recognizing same-sex unions.", "Europe", "\"I believe it's discriminatory. I think it interferes with state's rights, and we will work with Congress to overturn it,\"", "immediate release", "Greeley, Colorado", "Festival Foods", "Molotov cocktails, rocks and glass.", "drugs", "Daniel Radcliffe", "1.2 million", "\"I wanted to push it up that black a--.\"", "12.3 million", "Krishna Rajaram", "North Korea", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Hamas", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "This was the first time a U.S. president visited Turkey at the start of his term, sending a clear signal that this administration recognizes the importance of Turkey and wants to engage with it from the start.", "Yemen", "federal officers", "dogs", "central business district of Bangkok", "would legally be able to intervene in the case if it is transferred from a judge in the eastern city of Abeche, where the children were taken, to a judge", "writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "Hague", "Robert Downey, Jr.", "Viscount Cranborne", "England", "beef", "Sleyman", "arboreal lichen", "Ramadan"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5925091352615222}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.0, 0.13333333333333333, 1.0, 0.1111111111111111, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 0.9655172413793104, 0.6666666666666666, 0.24000000000000002, 0.0, 0.0, 1.0, 1.0, 0.0, 0.07407407407407407, 1.0, 1.0, 1.0, 0.875, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.09302325581395349, 1.0, 0.8, 0.0, 0.33333333333333337, 0.0625, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.125, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-2755", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-3441", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-2733", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-2819", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_newsqa-validation-928", "mrqa_triviaqa-validation-2863", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763", "mrqa_searchqa-validation-6846"], "SR": 0.46875, "CSR": 0.5352879213483146, "EFR": 0.7352941176470589, "Overall": 0.6705226577990746}, {"timecode": 89, "before_eval_results": {"predictions": ["133d Air Refueling Squadron", "Sun Woong", "president of Guggenheim Partners", "Comedy Film Nerds", "9\u201310 March 1945,", "2011", "John D Rockefeller's Standard Oil Company", "the early 1970s", "Asiana Town building", "American R&B singer, guitarist, songwriter and music producer who played a key role in the transition from the blues to rock and roll,", "Rockland County", "Manitowoc County, Wisconsin", "34.9 kilometres", "1967", "alcoholic drinks", "FCA", "Chrysler", "Australian", "bonobo", "\"Traumnovelle\" (\"Dream Story\")", "The Royal Navy", "Robert Digges Wimberly Connor", "Rage Against the Machine", "the Beatles and the Rolling Stones", "Baden-W\u00fcrttemberg", "2001 NBA All-Star Game", "rated R", "95 AD", "1614", "French", "\"Grimjack\" (from First Comics) and \"Firestorm\", \"The Spectre\", and \"Martian Manhunter\"", "Mondays", "Michael Jordan", "I, (Annoyed Grunt)-bot", "HSBC Main Building", "1987", "Kalokuokamaile", "17 October 2006", "melodic hard rock", "Home Rule League", "Anne Fletcher", "1822", "Mulberry", "Suspiria", "Immediate Media Company", "Kansas\u2013Nebraska Act of 1854 (10 Stat.  277 ) created the territories of Kansas and Nebraska and was drafted by Democratic Senator Stephen A. Douglas of Illinois and President Franklin Pierce.", "Scandinavian design", "Buck Owens", "Big Machine Records", "UK Mail, UPS, Parcelforce, DHL, Hermes, Royal Mail", "Flaw", "June 5, 2017", "1972", "the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Daniel Boone", "forearm", "Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "Piers Morgan Tonight", "misdemeanor assault charges after a fight at his Texas high school", "Florida", "\"I Woke Up In Love\"", "Mickey Spillane", "for flooding from Hurricane Irene that pummeled the East Coast last August and for damages from Tropical Storm Lee in Schoharie, Tioga, Broome, Greene, and Orange counties."], "metric_results": {"EM": 0.59375, "QA-F1": 0.6545390279905835}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, false, true, true, true, true, true, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13793103448275862, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.4615384615384615, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5567", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-3752", "mrqa_hotpotqa-validation-2403", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-5440", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-9812", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-702", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3253", "mrqa_searchqa-validation-16394", "mrqa_newsqa-validation-3369"], "SR": 0.59375, "CSR": 0.5359375, "EFR": 0.8461538461538461, "Overall": 0.6928245192307692}, {"timecode": 90, "before_eval_results": {"predictions": ["Sharon Sheeley", "Ardeth Bay", "2009", "singer", "Pakistan", "1754", "\"To Save a Life\"", "VfL Wolfsburg", "d\u00eds", "David Villa S\u00e1nchez", "Adrian Peter McLaren", "2013", "an early colonist of South Australia, remembered as a schoolmaster at J. L. Young's Adelaide Educational Institution and at Saint Peter's College.", "The Birds", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Kim Yoon-seok and Ha Jung-woo", "Diamond White", "25 November 2015", "Craig William Macneill", "January 14, 2010", "2,664", "Tamil", "Objectivism", "Chicago", "London Heathrow", "Riot Act", "The Gold Coast", "January 30, 1930", "Soma", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Khama", "Scandinavian design", "Mike Pence", "Barack Obama", "Flexible-fuel", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian", "138,535", "Lewchewan or Uchinaanchu (\u6c96\u7e04\u4eba, Japanese: \"Okinawa jin\")", "1972", "Stern-Plaza in Potsdam", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravitation", "ensures consistency within a document and across multiple documents and enforces best practice in usage and in language composition, visual composition, orthography and typography", "South Africa", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailor", "Robert Barnett,", "Barbbie Miss Astronaut", "the Agony", "CO2", "Shout"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6541453677662917}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.787878787878788, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.0, 0.30434782608695654, 1.0, 1.0, 1.0, 0.2564102564102564, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-2035", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-5335", "mrqa_hotpotqa-validation-1457", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-4050", "mrqa_newsqa-validation-386", "mrqa_newsqa-validation-1446", "mrqa_newsqa-validation-2030", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743"], "SR": 0.546875, "CSR": 0.5360576923076923, "EFR": 0.7586206896551724, "Overall": 0.675341926392573}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "Apple", "Jaguar S-Type R", "chef Louis Q. Taste", "Friday", "Sabino Canyon", "Depp", "Babe Ruth", "Knots Landing", "Arkansas", "Alberto Gonzales", "Virgo", "contemporary and modern art", "Steppenwolf", "bcolicus", "Tito Puente", "Hydrogen", "Ben Jonson", "Hodgkin's lymphoma", "Margaret, Countess of Snowdon", "Salt Lake City", "San Francisco", "Norman Mailer", "Mary Baker Eddy", "Bank One Corp.", "College of William and Mary", "the Wright Brothers", "Badminton", "John Deere", "Elizabeth Barrett Browning", "Chrysler", "reptiles", "Georgia Bulldogs", "Key lime pie", "Lettuce", "Haroun", "bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro's tomb", "Assyria", "Jean-Paul Marat", "Cetshwayo", "Bay of Montevideo", "the bank, rather than the purchaser, is responsible for paying the amount", "a spirit-lifting jingle", "Bobby Brown,", "bath", "1.5 million households", "Macomb County", "Kristoffer Rygg", "boats are expected to arrive in Veracruz on Wednesday and Thursday.", "Monday night.", "eight", "minister and biographer"], "metric_results": {"EM": 0.5, "QA-F1": 0.6188244047619048}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, true, false, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.8, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.4, 0.0, 0.6666666666666666, 1.0, 1.0, 0.19999999999999998, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-13516", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-5927", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-10498", "mrqa_searchqa-validation-11001", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-3331", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-16068", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-6896", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_hotpotqa-validation-4539"], "SR": 0.5, "CSR": 0.5356657608695652, "EFR": 0.875, "Overall": 0.6985394021739131}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "brancusi", "Quantico, Virginia", "the East", "William Shakespeare", "William Shakespeare", "abscesses, ulcers and mucous membranes", "Alaska", "Sputnik I", "Richmond", "Revolvy", "Java", "(Bach)", "Blanche DuBois", "inseparable", "Room-temperature vulcanization", "Wuthering Heights", "Muhammad", "September 20, 1934", "Pirates of the Caribbean: The Curse of the Black Pearl", "Charles de Gaulle", "Chesterfield", "a chipmunk", "Josphine de Beauharnais", "salt", "a disorderly Conduct", "Gioachino Rossini", "Oman", "Lapland", "Tudor", "Roman Polanski", "Joan Didion", "the frigate", "Baltimore", "the Bay of Bengal", "John Hart", "Hillary Clinton", "Terrific", "the geology of Mars", "six sides", "Olympia", "the Ship of Fools", "Haunted", "tendang", "the fluid", "World War II", "Frances", "Vin Diesel", "Cremation", "the French & Indian War", "a manic episode", "the Hudson Bay", "lighter fluid", "a scuffle with the Beast Folk", "Judi Dench", "Germany", "Caernarfon", "Dar es Salaam", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20", "Michael Krane,", "Virgin America", "AIDS and HIV"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5694444444444444}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, true], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.33333333333333337, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-10078", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-4155", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-10796", "mrqa_searchqa-validation-2418", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-20", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-4465", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6867", "mrqa_hotpotqa-validation-3557"], "SR": 0.484375, "CSR": 0.535114247311828, "EFR": 0.6363636363636364, "Overall": 0.6507018267350928}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Lulu", "Tony Orlando and Dawn", "Mel Gibson", "1947, 1956, 1975, 2015 and 2017", "drivers who were 2016 Pole Award winners, former Clash race winner, former Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "over the next seven years until the last coin, a gold sovereign, was struck in London in November 1975", "Pacific Grove", "while in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form, he made the hair more `` wild '' and covered Goku's body in red fur", "Audrey II", "January 2017 patch", "NIRA", "after the Irish War of Independence and the Anglo - Irish Treaty, most of Ireland seceded from the United Kingdom to become the independent Irish Free State, which after the 1937 constitution, began to call itself Ireland", "Jacqueline Bouvier", "Justin Timberlake", "The Chainsmoker", "13 May 1787", "Prince James, Duke of York and of Albany ( later King James II & VII )", "his brother", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3", "McFerrin", "Napoleon", "Hem Chandra Bose, Azizul Haque and Sir Edward Henry", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "Jupiter", "excessive growth", "1939", "Richard Masur", "Kyla Pratt", "Spanish", "Sauron", "Rick Nowels", "position in blackjack relative to the player", "159", "Third Five - year Plan", "The chant was first adopted by the university's science club in 1886", "makes Maria a dress to wear to the neighborhood dance", "activates a relay which will handle the higher current load", "limited period of time", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood Men in Tights", "Drey", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "\"The Da Vinci Code,\"", "humiliate herself by standing next to a story", "Nikita Khrushchev", "Julie Andrews", "Ichabod Crane", "Leo Frank,"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6237230255517527}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.9655172413793104, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8571428571428572, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.11764705882352942, 1.0, 1.0, 0.5, 0.13333333333333333, 0.0, 0.30769230769230765, 1.0, 0.2, 0.0909090909090909, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-5865", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-857", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-1722", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-2989", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374", "mrqa_searchqa-validation-11408", "mrqa_searchqa-validation-105"], "SR": 0.53125, "CSR": 0.5350731382978724, "EFR": 0.8, "Overall": 0.6834208776595745}, {"timecode": 94, "before_eval_results": {"predictions": ["the theory of direct scattering and inverse scattering", "ThonMaker", "Battle of Chester", "youngest TV director ever", "19 February 1927", "on the shore, associated with \"the Waters of Death\" that Gilgamesh had to cross to reach Utnapishtim, the far-away", "playback singer, director, writer and producer", "L\u00edneas A\u00e9reas", "English", "National Basketball Development League", "Neville Chamberlain,", "Boulder High School in Boulder, Colorado", "Revengers Tragedy", "Japan", "rural", "8", "Larry Alphonso Johnson Jr.", "Gabriel Iglesias", "August 28, 1774", "CMYKOG process", "Las Vegas Boulevard", "intelligent design: The Bridge Between Science and Theology", "Anthony Herrera", "Jack Elam", "Rymill Park", "Uzumaki", "Kansas", "nearly 80 years", "Chevy Corvette Stingrays", "Field of Dreams", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music.", "The Wachowskis", "the \"Pour le M\u00e9rite\"", "mastered recordings for many well known musicians, including David Bowie, The Subways, Foo Fighters, Lou Reed, Paul McCartney, Sin\u00e9ad O'Connor, Natalie Merchant, Marianne Faithfull, and Madonna.", "Drowning Pool", "typically found within a casino, ranging from card to slot machines.", "Food and Agriculture Organization", "dance partner", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "shorthand writing", "2018", "Commonwealth Universities", "25 October 1921", "Australian", "Bonkyll Castle", "February 5, 2015", "Zeffirelli", "giant", "alveolar process", "Duisburg", "Hugh Quarshie", "Olga", "Tokyo", "Utah Valley Regional Medical Center", "Madonna", "CNN", "Ingenta", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7109940650236704}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.3157894736842105, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.2, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 0.47619047619047616, 1.0, 1.0, 0.14814814814814814, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-429", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-3258", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5456", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-4047", "mrqa_triviaqa-validation-514", "mrqa_newsqa-validation-726", "mrqa_searchqa-validation-4530", "mrqa_searchqa-validation-2056"], "SR": 0.609375, "CSR": 0.5358552631578948, "EFR": 0.68, "Overall": 0.659577302631579}, {"timecode": 95, "before_eval_results": {"predictions": ["more than 250 million copies worldwide", "Ben Ainslie", "1978", "The Vanishing", "Scott Mosier", "1945", "Roy Spencer", "1964", "U.S. Route 71", "VH1", "London", "Russian", "Jack Ryan", "July 25 to August 4", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer, songwriter, actress", "Northern Lights", "non-alcoholic", "Mach number", "Days of our Lives", "Maine", "Encore Las Vegas", "\"Baa, Baa, Black sheep\"", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1935", "Sargent Shriver", "paracyclist", "Mandarin", "Kevin Spacey", "a pro-vice-chancellor", "Song Il-gon", "Teenitans", "Mickey Mouse cup", "Grammy Award", "right-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "whale lice", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers women's basketball", "Metro-Goldwyn-Mayer", "P.O.S", "My Backyard", "Kim So-hyun", "boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "La traviata", "March 1st.", "The Da Vinci Code", "Dogpatch Labs", "iceberg", "a fuel cell", "Victoria", "Venus Williams"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6619791666666667}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [0.5, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-5568", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-2388", "mrqa_newsqa-validation-3838", "mrqa_searchqa-validation-14503", "mrqa_searchqa-validation-9695"], "SR": 0.578125, "CSR": 0.5362955729166667, "EFR": 0.8518518518518519, "Overall": 0.6940357349537037}, {"timecode": 96, "before_eval_results": {"predictions": ["Prince Sung-won", "1927", "16,116", "the 2012 Summer Olympics", "the end of the 18th century", "1942", "Willie Nelson and Kris Kristofferson", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "The Bears", "Gillian Leigh Anderson", "the alternative rock band R.E.M.", "Ice Princess", "the 1900 Summer Olympics", "Oldham County", "1896", "Oracle Corporation", "143,007", "SARS", "5.3 million", "chocolate-colored", "Bruce McLaren", "1952", "Neneh Mariann Karlsson", "American rapper Eminem", "Love Streams", "In a Better World", "Shropshire Union Canal", "comedy-drama anthology series", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker and Matt Stone", "\"Pimp My Ride\"", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "a wooden Indian", "John Francis Kelly", "early Romantic period", "approximately $700 million", "the Sun", "Bhushan Patel", "1692", "federal authority over interstate commerce including navigation by river", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "colonel", "(Conan) Conan", "scalene", "to put a lid on the marking of Ashura", "Pakistan", "homicide", "dough bread", "leather", "cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.625, "QA-F1": 0.7495083041958042}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.3333333333333333, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 0.18181818181818182, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 0.923076923076923, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3971", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5292", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-1588", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-447", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-1887", "mrqa_triviaqa-validation-2789", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-13280"], "SR": 0.625, "CSR": 0.5372100515463918, "EFR": 0.9166666666666666, "Overall": 0.7071815936426117}, {"timecode": 97, "before_eval_results": {"predictions": ["The Theory of Everything", "the main Caucasus range", "David Bowie", "hace Lindrum", "Granada", "Treaty of Brest-Litovsk", "groan h Hess", "Procol Harum", "the Duke and Duchess of Windsor", "a Texas cichlid pair", "1957", "1912", "transvestite", "Fred Astaire", "south of England", "Scotland Yard detective", "Inverness-shire", "Friday's child that's born on the Sabbath day", "airplane", "Rudyard Kipling", "1921", "\u201cThe Full Monty\u201d (1997)", "Emilia", "avocados", "Frans Hals", "Syriza", "Ford", "garbanzo", "Cole Porter", "1826", "w w w rothevelt (1863-1943)", "the Parthenon", "Paddy Dooley", "Thomas Aquinas", "Dubonnet Rouge Aperitif", "elephant", "Bobby Fischer", "armadhmi", "Westminster Abbey", "Canada", "Sheidi Klum", "Edward VII", "Tombstone", "island of s\u00e3o Miguel", "Mr. Men and 33 Little Miss", "worcestercathedral.co.uk", "Mercury", "December 7, 1941", "the middle ear", "mary Lou Retton", "Buzz Aldrin", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "Electronic Attack Squadron 135", "95 AD", "more than 170", "gossip Girl", "Karen Floyd", "awe-inspiring", "the Caspian Sea", "(Christ Auxilio Chapel)", "1922 to 1991"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5069444444444444}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, false, false, true, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, false, false, true, false, false, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, false, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false], "QA-F1": [0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444444, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7127", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-3064", "mrqa_triviaqa-validation-3538", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-6617", "mrqa_triviaqa-validation-2651", "mrqa_triviaqa-validation-3031", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3878", "mrqa_triviaqa-validation-329", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-229", "mrqa_triviaqa-validation-174", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3100", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_searchqa-validation-16068", "mrqa_naturalquestions-validation-7080"], "SR": 0.421875, "CSR": 0.5360331632653061, "EFR": 0.8108108108108109, "Overall": 0.6857750448152233}, {"timecode": 98, "before_eval_results": {"predictions": ["he'll send a text message and e-mail to his supporters to let them know who his sidekick will be.", "Afghanistan", "deutschneudorf", "Several suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags", "his health and about a comeback.", "poems", "then-Sen. Obama", "woman", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "former Alabama judge is standing trial on charges he checked male inmates out of jail and forced them to engage in sexual activity such as paddling in exchange for leniency.", "celebrities and ministers, ranging from Yolanda Adams to Bishop T.D. Jakes to Kirk Franklin.", "Iraqi economy.", "Phillip A. Myers.", "You'll host The Larry King Show.\"Nine o'clock was approaching.", "to share personal information.", "Argentine", "Sheik Mohammed Ali", "Iraqi Prime Minister Nouri al-Maliki", "France", "\"It was incredible. We've had so much rain, and yet today it was beautiful. The rain held off wherever Muhammad Ali went,\" Frankie Neylon, the town's mayor said.", "\"We really want to be parents, and that is the goal here through surrogacy and adoption. We are not done trying yet.\"", "WBO welterweight title", "Austin, Texas,", "15-month", "monthly allowance,", "Manmohan Singh's Congress party", "the war of words in the Republican Party centered around Rush Limbaugh.", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "American Bill Haas", "Consumer Reports", "28", "step up.\"", "42 years old", "since 1983", "improve health and beauty.", "almost 100", "Espinoza Barron's", "I'll tell the producer's version because my version was I heard they were doing a new \"Friday the 13th,\" and I went, I really want to do this.", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.\"", "fastest circumnavigation of the globe in a powerboat", "nearly $106.5 million", "18th", "Haeftling", "the left of the dinner plate", "Asuka", "Bart Millard", "Nissan", "stone arch bridges", "jMW Turner", "the Marx Brothers film", "Indian", "early 20th-century Europe", "(\"No hostage will be released until all our demands are met,\"", "Shakespeare in Love", "w. Somerset Maugham", "leicestershire"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5635638575605681}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, false, true, true, false, false, false, true, true], "QA-F1": [0.14285714285714285, 0.0, 0.0, 0.9210526315789475, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.38095238095238093, 0.1142857142857143, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.07142857142857142, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.4, 0.0, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.16666666666666669, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1833", "mrqa_newsqa-validation-2182", "mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-2610", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-3208", "mrqa_newsqa-validation-2745", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-900", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-14191"], "SR": 0.4375, "CSR": 0.5350378787878788, "EFR": 0.7222222222222222, "Overall": 0.6678582702020203}, {"timecode": 99, "UKR": 0.76171875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.69140625, "KG": 0.49453125, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "Mach number", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "Minnesota", "most performed song of all time", "the University of Oregon", "Arkansas", "the 2011 Pulitzer Prize in General Nonfiction", "Golden Gate National Recreation Area", "Pain Language", "Broadcasting House in London", "London Tipton", "Barney Miller", "Lily Hampton", "43rd President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "The Heirs", "Saturday Night Live", "strongly associated with Gaia and Cybele", "Tumi Holdings, Inc.", "Black Ravens", "Lifestyle cities", "Suspiria", "Silvia Navarro", "22,500 acres", "Warsaw, Poland", "Nelson County", "Kang and Kodos", "25 million", "Athenion", "James G. Kiernan", "the MC5", "Naval Weapons Station Yorktown", "Tunisian", "Linda Ronstadt", "the United Kingdom", "August 19, 2013", "the Americas and the entire South American temperate zone", "Sister, Sister", "five", "Mark Radcliffe", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "The term was first used in tennis", "Frank Zappa", "1991", "apples", "Fred Trueman", "Scotland", "Chesley \"Sully\" Sullenberger", "Mario Balotelli", "Friday,", "Lifeboat", "a megabyte", "stock-broker", "Benazir Bhutto"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7024505876068377}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 0.3333333333333333, 0.25, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.05128205128205128, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-2946", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-2484", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-5753", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572"], "SR": 0.59375, "CSR": 0.535625, "EFR": 0.7307692307692307, "Overall": 0.6428100961538462}]}