{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=5e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=5e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=5e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[2]_result.json', stream_id=2, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4240, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Ed Asner", "arrows", "1st century BC", "Marburg Colloquy", "Brookhaven", "ca. 2 million", "the Hungarians", "Mercury", "19th Century", "Art Deco style in painting and art", "The ability to make probabilistic decisions", "impact process effects", "1999", "phagosome", "the mass of the attracting body", "the Association of American Universities", "three", "allowed government agencies and large companies (mostly banks and airlines) to build their own dedicated networks", "freight services", "up to four minutes", "the Little Horn", "Muslim and Chinese", "intracellular pathogenesis", "Santa Clara, California", "1784", "George Low", "Annual Conference Cabinet", "three", "Students", "Atlantic", "2001", "1887", "Chicago Bears", "John Harvard", "increase its bulk and decrease its density", "literacy and numeracy", "Christmas Eve", "the state", "Paris", "gender roles and customs", "outdated or only approproriate", "soy farmers", "United States", "Albert Einstein", "the number of social services that people can access wherever they move", "Tesco", "ABC Inc.", "1776", "wireless", "an electric current", "Warszowa", "the courts of member states", "supervisory church body", "the union of the Methodist Church (USA) and the Evangelical United Brethren Church", "Manakin Episcopal Church", "Des Moines College, Kalamazoo College, Butler University, and Stetson University", "Westminster", "Von Miller", "evidence in 2009 that both global inequality and inequality within countries prevent growth by limiting aggregate demand", "Khwarezmia", "Queen Elizabeth II", "CBS", "Pittsburgh Steelers", "The chloroplast peripheral reticulum"], "metric_results": {"EM": 0.875, "QA-F1": 0.8875363542546205}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.12121212121212122, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1826", "mrqa_squad-validation-4874", "mrqa_squad-validation-4283", "mrqa_squad-validation-1802", "mrqa_squad-validation-6210", "mrqa_squad-validation-3650", "mrqa_squad-validation-7430", "mrqa_squad-validation-6136"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 1, "before_eval_results": {"predictions": ["the Inland Empire", "New Zealand", "Jacksonville", "Newton's First Law", "the ability to pursue valued goals", "May 1888", "lecture theatre", "more than 28 days", "elliptical", "Boston", "Wednesdays", "Orange", "three", "Lampea", "San Jose State", "March 29, 1883", "between AD 0\u20131250", "Pleurobrachia", "eleven", "punts", "Solim\u00f5es Basin", "1474", "Arizona Cardinals", "Julia Butterfly Hill", "Orange", "Doctor in Bible", "left Graz", "waldzither", "over $40 million", "14th century", "6.7+", "end of the 19th century", "peace", "$40,000", "Cloth of St Gereon", "time and space", "7,000", "elementary particles", "indigenous", "3.5 billion", "New York City O&O WABC-TV and Philadelphia O&o WPVI-TV", "John Fox", "architectural", "Prime ideals", "Normant", "Leonardo da Vinci", "2003", "modern buildings", "Charles River", "KOA", "a disaster", "no contest", "Latin", "Manakin Town", "40,000", "After liberation", "\"winds up\" the debate", "10%", "The Daily Mail is mentioned in The Beatles\u2019 hit single Paperback Writer  The Yorkshire Post was the first British newspaper to report on The Abdication Crisis", "Uncle Tom's Cabin", "The liver", "No man", "Martina Hingis", "Ukraine borders with seven countries"], "metric_results": {"EM": 0.875, "QA-F1": 0.8942708333333333}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_squad-validation-4458", "mrqa_squad-validation-1775", "mrqa_squad-validation-1001", "mrqa_squad-validation-696", "mrqa_triviaqa-validation-5992", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-7750", "mrqa_naturalquestions-validation-646"], "SR": 0.875, "CSR": 0.875, "EFR": 1.0, "Overall": 0.9375}, {"timecode": 2, "before_eval_results": {"predictions": ["$155 million", "CBS", "San Jose State", "Half", "the evolution of the German language and literature", "Qur'an", "Brotherhood", "high wages", "Tolui", "legon, the current King of Thebes, who is trying to stop her from giving her brother Polynices a proper burial", "the object's weight", "over half", "1960s", "two months", "his friends Johannes Bugenhagen and Philipp Melanchthon", "1805", "Elders", "30\u201375%", "45,000 pounds", "self molecules", "Taishi", "1960", "Captain America: Civil War", "political divisions", "D loop mechanism", "Monterey", "The Book of Common Prayer", "14", "Charleston", "fear of their lives", "hot winds blowing from nearby semi-deserts", "intracellular pathogenesis", "Safari Rally", "10,006,721", "Philip Segal", "decision problem in Presburger arithmetic has been shown not to be in P, yet algorithms have been written that solve the problem in reasonable times in most cases", "1965", "quantum gravity", "German Te Deum", "Stanford Stadium", "Jin", "Trevathan", "Doctor Who", "1206", "clinical services", "CRISPR sequences", "Queen Elizabeth II", "zero", "1992", "food security", "plasmas", "their low ratio of organic matter to salt and water", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "guardian", "time goes", "guardian", "guardian", "black", "one mile above sea level"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6923261634199134}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9714285714285714, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.06666666666666667, 1.0, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.3636363636363636, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25]}}, "before_error_ids": ["mrqa_squad-validation-6099", "mrqa_squad-validation-6641", "mrqa_squad-validation-2547", "mrqa_squad-validation-8360", "mrqa_squad-validation-2577", "mrqa_squad-validation-8747", "mrqa_squad-validation-5893", "mrqa_squad-validation-2906", "mrqa_squad-validation-1860", "mrqa_squad-validation-10427", "mrqa_squad-validation-6178", "mrqa_squad-validation-6405", "mrqa_squad-validation-1435", "mrqa_searchqa-validation-12637", "mrqa_searchqa-validation-3982", "mrqa_searchqa-validation-11010", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11930", "mrqa_searchqa-validation-9010", "mrqa_searchqa-validation-16253", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-12889", "mrqa_triviaqa-validation-3333", "mrqa_triviaqa-validation-3857"], "SR": 0.609375, "CSR": 0.7864583333333334, "EFR": 1.0, "Overall": 0.8932291666666667}, {"timecode": 3, "before_eval_results": {"predictions": ["fewer than 10 employees", "1624", "Hangzhou", "committee", "the 19th century", "1962", "dealing with patients' prescriptions and patient safety issues", "a group that included priests, religious leaders, and case workers as well as teachers", "Vistula River", "1290", "21 October 1512", "140,079", "a double membrane", "August 1967", "German", "27-30%", "four", "the 50 fund", "Arizona Cardinals", "Peanuts", "comb rows", "calcitriol", "Warsaw", "time", "since at least the mid-14th century", "the mitochondrial double membrane", "Mike Figgis", "in an adult plant's apical meristems", "isopentenyl pyrophosphate synthesis", "Associating forces with vectors", "prime ideals", "The Three Doctors", "Von Miller", "four", "the Koori", "1910\u20131940", "pressure swing adsorption", "Luther", "English", "a lack of remorse", "the fundamental means by which forces are emitted and absorbed", "the A1 (Gateshead Newcastle Western Bypass)", "Sun Life Stadium", "the Duchy of Prussia, the Channel Islands, and Ireland", "John Houghton", "February 2015", "draftsman", "the Mollusca", "Orestes", "the Galapagos Islands", "the term \"act of terror\"", "denver", "the Forty-merchandising", "denver", "denver", "the Mycenaean civilization", "a biological process that displays an endogenous, entrainable", "the Belasco Theatre", "the Normandy Landings", "the Forty", "the fibula", "Il Trovatore", "the South Pole", "the Royal Border Bridge"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6195211038961039}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6345", "mrqa_squad-validation-2192", "mrqa_squad-validation-4724", "mrqa_squad-validation-3347", "mrqa_squad-validation-4730", "mrqa_squad-validation-1036", "mrqa_squad-validation-776", "mrqa_squad-validation-3673", "mrqa_squad-validation-2132", "mrqa_squad-validation-6737", "mrqa_squad-validation-10310", "mrqa_squad-validation-3019", "mrqa_searchqa-validation-5045", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-4118", "mrqa_searchqa-validation-5307", "mrqa_searchqa-validation-8509", "mrqa_searchqa-validation-8486", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-11449", "mrqa_searchqa-validation-879", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-10694", "mrqa_triviaqa-validation-2595", "mrqa_triviaqa-validation-7003"], "SR": 0.59375, "CSR": 0.73828125, "EFR": 0.9615384615384616, "Overall": 0.8499098557692308}, {"timecode": 4, "before_eval_results": {"predictions": ["Germany and Austria", "Centrum", "blue police box", "to spearhead the regeneration of the North-East", "Rhenus", "the Gramme dynamo", "under the wing of the secular powers", "in 1281 as the official calendar of the Yuan dynasty", "Zhongtong", "11.1%", "1538", "Deacons", "the New Testament", "experience, ideology, and weapons", "25", "May 2013", "K-9 and Company", "in capturing prey", "a four-carbon compound", "livestock pasture", "Ford", "1,300,000", "it has trouble distinguishing between carbon dioxide and oxygen", "two tumen (20,000 soldiers)", "eight", "algorithm", "WzzM and WOTV", "Orange", "tentilla", "gender roles and customs", "social unrest and violence", "Woodward Park", "1745", "the Battle of Olustee", "observer status", "the 50-yard line", "3D printing technology", "The Malkin Athletic Center", "24\u201310", "6.7+", "empires", "the domestic legislation of the Scottish Parliament", "the most effective of the three therapies", "Bloomberg", "the oceans are growing crowded, and governments are increasingly trying to plan their use", "a new generation of innovative, exciting skyscrapers", "a lump in Henry's nether regions", "the war years", "the computer processing unit (CPU) market", "Matt Kuchar and Bubba Watson", "the fastest circumnavigation of the globe in a powerboat", "a large concrete block", "the BBC's central London offices", "Buddhism", "Manchester City", "Noriko Savoie", "three", "change course", "Tsvangirai", "A Lion Among Men", "1971", "honey", "Chelsea Lately", "Luxembourg"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7150793650793651}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, false, true, false, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.4, 1.0, 1.0, 0.09523809523809525, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.6666666666666666, 0.0, 0.2, 0.0, 0.8333333333333333, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9250", "mrqa_squad-validation-1320", "mrqa_squad-validation-2288", "mrqa_squad-validation-8231", "mrqa_squad-validation-4947", "mrqa_squad-validation-4258", "mrqa_squad-validation-8832", "mrqa_squad-validation-6046", "mrqa_squad-validation-1643", "mrqa_squad-validation-4572", "mrqa_squad-validation-7094", "mrqa_newsqa-validation-96", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2859", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-2807", "mrqa_naturalquestions-validation-47", "mrqa_hotpotqa-validation-547"], "SR": 0.609375, "CSR": 0.7125, "EFR": 1.0, "Overall": 0.85625}, {"timecode": 5, "before_eval_results": {"predictions": ["with money from foreign Islamist banking systems, especially those linked with Saudi Arabia", "Anheuser-Busch InBev", "4000 years of glass making", "$37.6 billion", "Anglo-Saxons", "seven", "Golden Gate Bridge", "Southwest Fresno", "divergent boundaries", "chloroplasts are surrounded by a double membrane", "QuickBooks", "surface condensers", "clinical pharmacists", "seal", "Philip Howard", "Duke Richard II of Normandy", "capturing three traders", "three", "Spanish", "Golden Super Bowl", "the constitutional traditions common to the member states", "pharmacological effect", "Huguenots", "10\u20137", "Polish Academy of Sciences", "spherical and highly refractive bodies", "Nurses", "New England Patriots", "Time magazine", "Class II MHC molecules", "two plastid-dividing rings", "George Westinghouse", "by disrupting their plasma membrane", "internal combustion engines", "indirectly", "Religious and spiritual teachers", "B cells", "property damage", "human rights abuses against ethnic Somalis", "Goa", "How I Met Your Mother", "France's famous Louvre museum", "Leo Frank", "Greece", "Graziano Transmissioni", "opposition parties", "204,000", "United's", "the release of the four men", "how health care can affect families", "Ed McMahon", "at least $20 million to $30 million", "Evan Bayh", "Friday", "Ali Larijani", "paper ballots", "Sodra nongovernmental organization", "sodium dichromate", "promotes fuel economy and safety", "heart rate that exceeds the normal resting rate", "heavy breeds", "Denmark", "Cincinnati", "Donald Sutherland"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6536947070494865}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [0.7000000000000001, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.6, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4705882352941177, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.1111111111111111, 0.0, 0.0, 0.5, 1.0, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-9691", "mrqa_squad-validation-754", "mrqa_squad-validation-5750", "mrqa_squad-validation-8715", "mrqa_squad-validation-1090", "mrqa_squad-validation-10244", "mrqa_squad-validation-3610", "mrqa_squad-validation-3075", "mrqa_squad-validation-827", "mrqa_squad-validation-8826", "mrqa_squad-validation-8867", "mrqa_squad-validation-6644", "mrqa_squad-validation-10444", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-113", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-2467", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-2287", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-534", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-4043", "mrqa_naturalquestions-validation-10131", "mrqa_triviaqa-validation-4171", "mrqa_hotpotqa-validation-520", "mrqa_hotpotqa-validation-2465"], "SR": 0.53125, "CSR": 0.6822916666666667, "EFR": 1.0, "Overall": 0.8411458333333334}, {"timecode": 6, "before_eval_results": {"predictions": ["18 February 1546", "11", "neither conscientious nor of social benefit", "University of Chicago Press", "$2 million", "2015", "1762", "biased against Genghis Khan", "Warsaw Stock Exchange", "they are often branched and entangled with the endoplasmic reticulum", "computational resource", "to denote unknown or unexplored territory", "Nicholas Stone", "early Lutheran hymnals", "a straight line", "1991", "William Smith", "William Pitt", "geochemical component", "Theory of the Earth to the Royal Society of Edinburgh", "Japan", "Super Bowl Opening Night", "the Working Group chairs", "laws of physics", "Denver's Executive Vice President of Football Operations and General Manager", "noisiest", "independent of each other", "issues under their jurisdiction", "unsuccessful", "human", "if they are homebound", "eliminate all multiples of 1 (that is, all other numbers) and produce as output only the single number 1", "nerves", "1671", "the Reichstag", "aldehydes and ketones", "Howard Dean III", "heart, blood, and blood vessels", "Troggs", "six", "Slovakia", "Diana the Princess", "slave trade", "vena cava", "Virginia", "5 feet 8 Inches from the floor", "Tartarus", "a kind of backdrop that often represents the sky is known", "Nancy Reagan", "Persian Achaemenid Empire", "a piece of luxury", "Zeppelin", "San Francisco", "64", "Datson, H., Birch,... plus assorted small iron and slag particles.", "Dies at 65", "Judas", "a group of characters who have safely gotten off the Island", "a comic book series by Robert Kirkman, Tony Moore, and Charlie Adlard", "Love Is All Around", "Los Angeles Dance Theater", "Somalia", "nine companies to stop selling unapproved pain-relief drugs.", "18"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5973090277777777}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, false, true, false, false, true, true, false, true, false, true, false, false, false, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.11111111111111112, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 1.0, 1.0, 0.0, 0.08333333333333333, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6230", "mrqa_squad-validation-8765", "mrqa_squad-validation-5588", "mrqa_squad-validation-4005", "mrqa_squad-validation-5054", "mrqa_squad-validation-383", "mrqa_squad-validation-10398", "mrqa_squad-validation-6337", "mrqa_squad-validation-3113", "mrqa_searchqa-validation-10504", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-14366", "mrqa_searchqa-validation-8371", "mrqa_searchqa-validation-8993", "mrqa_searchqa-validation-15874", "mrqa_searchqa-validation-16503", "mrqa_searchqa-validation-2340", "mrqa_searchqa-validation-12614", "mrqa_searchqa-validation-5092", "mrqa_searchqa-validation-1637", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-16060", "mrqa_naturalquestions-validation-10057", "mrqa_newsqa-validation-2074", "mrqa_newsqa-validation-1064"], "SR": 0.546875, "CSR": 0.6629464285714286, "EFR": 1.0, "Overall": 0.8314732142857143}, {"timecode": 7, "before_eval_results": {"predictions": ["extinction", "oxygen", "reduce growth", "Torchwood", "9.1 million", "little", "individual countries", "cattle", "Mongol", "a maze of semantical problems and grammatical niceties", "five", "Wahhabism", "British", "Finsteraarhorn", "Abilene", "white", "Yosemite Freeway", "Thanksgiving", "874.3 square miles", "Two thirds", "the Privy Council", "well into the nineteenth century", "capability deprivation", "Daily Mail", "San Mateo", "Spanish", "around 300,000", "cryptomonads", "Swahili", "hymn-writer", "a site of starch accumulation in plants that contain them", "Bryant", "Jupiter", "a tornado", "Rodeo", "hog", "Barack Obama", "Kenny G", "a cup", "a peacock unitard", "Annapolis", "Spring", "klammeraffe", "female", "Allah", "bones", "Python", "Cecil B. DeMille", "Cold Mountain", "Faith Hill", "Ben Affleck", "the European", "V", "time", "a jazz saxophonist", "Sweden", "Indonesia", "hydrogen", "Alexandria", "Perfume", "the New Jersey Economic Development Authority's 20% tax credit", "Georgetown", "Essex Eagles", "Alzheimer's disease"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6444602272727273}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4198", "mrqa_squad-validation-7626", "mrqa_squad-validation-1938", "mrqa_squad-validation-6220", "mrqa_squad-validation-9588", "mrqa_squad-validation-4562", "mrqa_squad-validation-8189", "mrqa_squad-validation-8828", "mrqa_searchqa-validation-47", "mrqa_searchqa-validation-4753", "mrqa_searchqa-validation-943", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5290", "mrqa_searchqa-validation-4898", "mrqa_searchqa-validation-8990", "mrqa_searchqa-validation-4050", "mrqa_searchqa-validation-390", "mrqa_searchqa-validation-13480", "mrqa_searchqa-validation-6934", "mrqa_searchqa-validation-10190", "mrqa_searchqa-validation-10916", "mrqa_searchqa-validation-5178", "mrqa_searchqa-validation-4457", "mrqa_newsqa-validation-2608", "mrqa_triviaqa-validation-6485", "mrqa_triviaqa-validation-3468"], "SR": 0.59375, "CSR": 0.654296875, "EFR": 1.0, "Overall": 0.8271484375}, {"timecode": 8, "before_eval_results": {"predictions": ["shocked", "lymphocytes", "producers of the show", "BSkyB", "Kawann Short", "Daidu in the north", "silent film", "22", "the park", "1965", "tidal currents", "Concentrated O2", "Ma Jianlong", "Demaryius Thomas", "Lake Constance", "the Orange Democratic Movement", "Bannow Bay", "the Red Army", "20th century", "ITT", "1966", "masses", "Linebacker", "high art and folk music", "four", "with six series of theses", "the midseason forensic investigation drama Body of Proof", "seven-eighths", "the cardinal de Richelieu", "the Atlas Mountains", "Madrid", "the Danube", "an exclamation to Yahweh", "leather", "Lewis Pullman", "the plums", "the Messiah's birth", "Sappho", "Possession", "the tonka bean", "the divisor", "Hypnos", "Texas", "the IHOP family restaurant chain", "a black breed and a white breed mingled to produce this type of cow named for a German region", "the Bill of Rights", "the ACT", "Rio", "Henry David Thoreau", "Santa Ana", "Dick Cheney", "the Earth", "Gustave Eiffel", "Edward Hopper", "the CIA", "D'Artagnan", "the Venus figurines", "1985", "apple", "its air-cushioned sole", "13", "Fort Worth", "Agent 99", "private"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6390190972222223}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.375, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3478", "mrqa_squad-validation-1169", "mrqa_squad-validation-2474", "mrqa_squad-validation-5926", "mrqa_searchqa-validation-15994", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-15182", "mrqa_searchqa-validation-523", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-9386", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11971", "mrqa_searchqa-validation-10315", "mrqa_searchqa-validation-14478", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-5620", "mrqa_searchqa-validation-680", "mrqa_searchqa-validation-815", "mrqa_searchqa-validation-16872", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-9179", "mrqa_naturalquestions-validation-6242", "mrqa_triviaqa-validation-776", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4461"], "SR": 0.578125, "CSR": 0.6458333333333333, "EFR": 1.0, "Overall": 0.8229166666666666}, {"timecode": 9, "before_eval_results": {"predictions": ["\"Provisional Registration\"", "August 15, 1971", "Levi's Stadium", "the United Nations Framework Convention on Climate Change", "Inflammation", "Brown v. Board of Education", "15 May 1525", "The Walt Disney Company", "Dundee", "61", "During the Second World War", "the integer factorization problem", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence", "Exploration is still continuing to determine if there are more reserves", "prep schools", "Cultural imperialism", "a strong Islamist outlook", "lengthening rubbing surfaces of the valve", "$32 billion", "keyed Northumbrian smallpipes", "the Dutch Republic", "Alex Haley", "three", "the helmeted honeyeater", "4:51", "Khrushchev", "Hera", "cherries", "Elton John", "Cuba", "the Battle of Thermopylae", "Kievan Rus", "Kroc", "cricket", "white", "Washington State", "Preamillo", "Genoa", "3", "tarn", "972", "buffalo", "Ann Widdecombe", "Isosceles", "the Old Kent Road", "Tuesday", "stone", "Ab Fab", "Massachusetts", "Barrow", "California", "the Susquehanna River", "80\u2019s", "the maqui berry", "Singapore", "Wigan Warriors", "Davos", "eight", "playing a wide range of starring or supporting roles", "the Home Rule Party", "Janet Napolitano", "J. Crew", "Deval Patrick", "Grover"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6309027777777778}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2666666666666667, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.16666666666666669, 1.0, 0.0, 0.6666666666666666, 0.4444444444444445, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7060", "mrqa_squad-validation-9552", "mrqa_squad-validation-8273", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2480", "mrqa_triviaqa-validation-1981", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-5675", "mrqa_triviaqa-validation-7659", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2533", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-1203", "mrqa_triviaqa-validation-6848", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-1432", "mrqa_triviaqa-validation-3637", "mrqa_triviaqa-validation-4808", "mrqa_naturalquestions-validation-6564", "mrqa_hotpotqa-validation-2428", "mrqa_hotpotqa-validation-2672", "mrqa_newsqa-validation-4153", "mrqa_newsqa-validation-1553", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-7509"], "SR": 0.5625, "CSR": 0.6375, "EFR": 0.9642857142857143, "Overall": 0.8008928571428571}, {"timecode": 10, "before_eval_results": {"predictions": ["-s", "environmental determinism", "4 August 2010", "King George III", "radio", "Edsen Khoroo", "League of Augsburg", "Duarte Barbosa", "the People's Republic of China", "the Roman Catholic Church", "Amazonia: Man and Culture in a Counterfeit Paradise", "fundamental rights (see human rights), proportionality, legal certainty, equality before the law and subsidiarity", "Sydney", "five", "January 18, 1974", "Spanish", "NFL", "extremely difficult", "student populations", "Catholic", "Parliament of the United Kingdom", "296", "the Ghent-Terneuzen Canal", "mulberry", "a bacteria", "a roadside tree", "Ken Russell", "Dan Dare", "crimean", "Smiths", "Mike Tyson", "Turkey", "Pesach", "Brian Deane", "kaleidoscopes", "Uranus", "Apollon", "George Carlin", "Soviet Union", "Sydney", "Los Angeles", "Underground", "puck", "barbarian", "passion fruit", "Portugal", "cricket", "Serena Williams", "63 to 144 inches", "The Titanic", "William Tell", "Christian Dior", "a jack-in-the-box-like creature", "Mendip Hills", "Wichita", "eukharisti\u0101", "New Croton Reservoir in Westchester and Putnam counties", "andr\u00e9 3000", "Leucippus", "Stephen King", "Venus Williams", "firefighter", "Python and the Holy Grail", "barbarian"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6972222222222222}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, true, true, true, false, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.888888888888889, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6278", "mrqa_squad-validation-6263", "mrqa_squad-validation-6811", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-4730", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-7463", "mrqa_triviaqa-validation-648", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-1428", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-3850", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-7523", "mrqa_triviaqa-validation-7222", "mrqa_triviaqa-validation-2265", "mrqa_naturalquestions-validation-7138", "mrqa_newsqa-validation-2710", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-8589"], "SR": 0.65625, "CSR": 0.6392045454545454, "EFR": 0.9545454545454546, "Overall": 0.796875}, {"timecode": 11, "before_eval_results": {"predictions": ["the method by which the medications are requested and received", "salvation", "jugs and candlesticks", "they produce secretions (ink) that luminesce at much the same wavelengths as their bodies", "zaju", "administration", "Chivas USA", "Edinburgh", "The Pink Triangle", "the dot", "Magdalen Tower", "an international data communications network", "public service", "Guy de Lusignan", "tiger team", "a sub-group", "The European Commission", "completed (or local) fields", "a fundamental error", "Mongol and Turkic tribes", "hizbullah", "five", "Whist", "morocco", "morocco", "achromatopsia", "rod", "Pluto", "iron, morolybdenum, and titanium", "copper", "The Hague", "Vancouver Island", "Ironside", "morocco", "morocco", "brown trout", "Beyonce", "Wordsworth", "man V Food", "morocco", "Samuel Johnson", "Conrad Murray", "Mary Poppins", "Bennett Cerf", "morocco", "morocco", "morocco", "morocco", "Oslo", "horses", "Rhododendron", "morocco", "morocco", "Shanghai", "morocco", "underground railways with two connected railway cars on inclined tracks", "Snake River Valley", "17 October 2006", "beer", "Hoover Dam", "morocco", "morocco", "Edgar Allan Poe", "morocco"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5701121794871795}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.15384615384615383, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5460", "mrqa_squad-validation-6530", "mrqa_triviaqa-validation-7516", "mrqa_triviaqa-validation-3550", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-6740", "mrqa_triviaqa-validation-5702", "mrqa_triviaqa-validation-5474", "mrqa_triviaqa-validation-695", "mrqa_triviaqa-validation-1361", "mrqa_triviaqa-validation-4959", "mrqa_triviaqa-validation-3846", "mrqa_triviaqa-validation-7464", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-5108", "mrqa_triviaqa-validation-6189", "mrqa_triviaqa-validation-3023", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-890", "mrqa_naturalquestions-validation-2730", "mrqa_naturalquestions-validation-2782", "mrqa_hotpotqa-validation-3112", "mrqa_newsqa-validation-3032", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-16344", "mrqa_searchqa-validation-348", "mrqa_searchqa-validation-8473"], "SR": 0.546875, "CSR": 0.6315104166666667, "EFR": 1.0, "Overall": 0.8157552083333334}, {"timecode": 12, "before_eval_results": {"predictions": ["a gift from God", "Greenland", "1724 to 1725", "placing them on prophetic faith", "1.25 million", "720p high definition", "five", "Maria Goeppert-Mayer", "the International Association of Methodist-related Schools, Colleges, and Universities", "one", "an majority in Parliament, a minority in the Council, and a majority in the Commission", "President Mahmoud Ahmadinejad", "Newcastle Eagles", "cholera", "other senior pharmacy technicians", "relative units of force and mass", "AD 14", "orogenic wedges", "his exploration and settlement of what is now Kentucky, which was then part of Virginia but on the other side of the mountains from the settled areas.", "The Handmaid's Tale", "chimpanzee", "The Fault in Our Stars", "The Ballade", "puzzle video", "1898", "400 MW", "Total Nonstop Action Wrestling", "galt\u00fcr avalanche", "Archbishop of Canterbury", "1861", "Disneyland, California", "David Villa", "Red and Assiniboine Rivers", "Bergen County, New Jersey", "Continental Army", "Jack Kilby", "darryl", "andrew kadyrov", "July 16, 1971", "1933", "The Heirs", "a combination of colours and blocks, which is a representation of the Baudot code.", "1959", "1887", "Mark Dayton", "Marvel Comics", "Rihanna", "Nick Cassavetes", "Lamar Hunt", "Sarah Winnemucca", "Jean Baptiste Point du Sable", "England", "Paul W. S. Anderson", "a basilica", "1963", "Ricky Nelson", "Wakanda and the Savage Land", "mercury", "phobias", "drug trafficking is a transnational threat, and therefore national initiatives have their limitations, and it is in everyone's interest to stop this proliferation.", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "elizabeth pays", "dapple-grey", "pre-Columbian times"], "metric_results": {"EM": 0.609375, "QA-F1": 0.695987345987346}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.3076923076923077, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.0, 0.12121212121212123, 0.04761904761904762, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4958", "mrqa_squad-validation-5889", "mrqa_squad-validation-4079", "mrqa_squad-validation-10428", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-2904", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-1269", "mrqa_hotpotqa-validation-4479", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-2664", "mrqa_hotpotqa-validation-89", "mrqa_hotpotqa-validation-5658", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-3253", "mrqa_naturalquestions-validation-6015", "mrqa_triviaqa-validation-2685", "mrqa_newsqa-validation-2183", "mrqa_newsqa-validation-774", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-7025", "mrqa_naturalquestions-validation-8227"], "SR": 0.609375, "CSR": 0.6298076923076923, "EFR": 1.0, "Overall": 0.8149038461538461}, {"timecode": 13, "before_eval_results": {"predictions": ["\u00a341,004", "The Rocket", "Tolui", "lower lake", "Gospi\u0107, Austrian Empire", "since 2001", "impossible", "Southwest Fresno", "5,000", "Huguenot", "ABC News Now", "sold Wardenclyffe for $20,000 ($472,500 in today's dollars)", "\u00c9mile Girardeau", "Brownlee", "The Five Doctors", "The average fee is around \u20ac5,000 annually for most schools", "NCAA Division II", "Adrian Lyne", "his most brilliant student", "Las Vegas", "Hugh de Kevelioc", "2017", "Dallas", "Rudolf Schenker", "Shrek", "Lucille Ball", "\"Grimjack\" (from First Comics)", "16\u201321", "Vince Guaraldi", "Anthony Stephen Burke", "Michael Redgrave", "Minnesota's 8th congressional district", "Highlands Course", "Hawaii", "Liquidambar styraciflua", "Marquis de Lafayette", "Gujarat", "three", "Winter Haven", "four", "The Process", "Mindy Kaling", "Surrey", "Claudio Javier L\u00f3pez", "Kanye West", "FCI Danbury", "two", "US Naval Submarine Base New London submarine school", "Las Vegas", "Pope John X", "2013", "Arlo Looking Cloud", "Rwandan genocide", "Larnelle Harris", "Secretary of State", "in 2015, 2017", "1982", "rod", "Chris Robinson", "Gossip Girl", "fluid dynamics", "out", "the Egyptian Goddess of Creation", "Richie Unterberger"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6086004273504273}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, false, false, true, false, true, false, false, true, true, true, false, false, true, false, false, false, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.8, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.5, 1.0, 0.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3176", "mrqa_squad-validation-3287", "mrqa_squad-validation-1488", "mrqa_squad-validation-7792", "mrqa_squad-validation-7036", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1561", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2160", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-450", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-4174", "mrqa_hotpotqa-validation-1552", "mrqa_hotpotqa-validation-4947", "mrqa_hotpotqa-validation-4422", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-2949", "mrqa_triviaqa-validation-6585", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-3098", "mrqa_searchqa-validation-9546", "mrqa_searchqa-validation-16181", "mrqa_triviaqa-validation-5414", "mrqa_triviaqa-validation-469"], "SR": 0.53125, "CSR": 0.6227678571428572, "EFR": 1.0, "Overall": 0.8113839285714286}, {"timecode": 14, "before_eval_results": {"predictions": ["10,000", "perpendicular to the velocity vector", "Inherited wealth", "December 1963", "Only the series from 2009 onwards", "religious freedom in the Polish\u2013Lithuanian Commonwealth", "Spreading", "kilogram-force", "ten times their own weight", "Quaternary", "1887", "jellyfish and turtles", "a symbiotic relationship", "introducing mathematical models of computation to study these problems and quantifying the amount of resources needed to solve them", "Vistula River", "a handful of British military personnel operating in Iraq will be withdrawn to Kuwait after Iraq's parliament adjourned without passing a deal that would let them stay,\" the spokesman said.", "Apple CEO Tim Cook", "palesa and Alebohang", "March 8", "Mike Meehan", "the Catholic League", "1,000 pounds", "\"He is obviously very relieved and grateful that the pardon was granted,\"", "Friday", "Movahedi", "different women coping with breast cancer in five vignettes", "mud coming out of the top of the derrick", "a smile on her face", "$40 and a quarter of bread", "Lance Cpl. Maria Lauterbach", "Hyundai Steel", "London", "more than 4,000", "Val d'Isere, France", "the test results by the medical examiner's office, Garavaglia said.", "Four Americans", "$14.1 million", "1616", "Saturn", "Chile", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "Buddhism", "J.Crew", "U.N. officials", "\"I always kind of admired him, oddly.\"", "boyhood experience in a World War II internment camp", "suppress the memories and to live as normal a life as possible", "4 meters (13 feet) high", "the Irish capital", "Republican", "in the county jail in Spanishfork,", "Mandi Hamlin", "Islamabad", "9 a.m.", "March 26, 1973", "Indian Ocean", "argument form", "the toe-line", "Sevens", "England", "Yemen", "Domenikos Theotokopoulos", "peter", "mercury"], "metric_results": {"EM": 0.359375, "QA-F1": 0.48141966540404046}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, false, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3636363636363636, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.3, 1.0, 0.6666666666666666, 0.8750000000000001, 0.4, 0.0, 0.8000000000000002, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 0.4, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10400", "mrqa_squad-validation-7770", "mrqa_squad-validation-4856", "mrqa_squad-validation-10458", "mrqa_squad-validation-4607", "mrqa_squad-validation-1672", "mrqa_newsqa-validation-1255", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-1647", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-4179", "mrqa_newsqa-validation-1983", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-450", "mrqa_newsqa-validation-3525", "mrqa_newsqa-validation-1731", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-1528", "mrqa_newsqa-validation-1658", "mrqa_newsqa-validation-3279", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1214", "mrqa_newsqa-validation-187", "mrqa_newsqa-validation-2032", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-391", "mrqa_naturalquestions-validation-6733", "mrqa_triviaqa-validation-3004", "mrqa_triviaqa-validation-3302", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-4399", "mrqa_searchqa-validation-7587", "mrqa_searchqa-validation-12191", "mrqa_triviaqa-validation-3839"], "SR": 0.359375, "CSR": 0.6052083333333333, "EFR": 0.975609756097561, "Overall": 0.7904090447154472}, {"timecode": 15, "before_eval_results": {"predictions": ["Prospect Park", "Khanbaliq", "Quaternary", "1870", "water", "a prime number", "The committee created the 50 fund as its philanthropic initiative and focuses on providing grants to aid with youth development, community investment and sustainable environments.", "the Camisards", "$40 million", "GTE", "1,100", "caveat", "Oligocene", "Melodie Rydalch", "Charles Darwin", "Conway, Arkansas,", "March 24,", "the Beatles", "Robert Park", "Adriano", "Eleven people died and 36 were wounded in the Monday terror attack,", "2007", "opened considerably higher Tuesday and saw an unprecedented wave of buying amid the elections.", "\"She had a smile on her face, like she always does when she comes in here,\"", "56,", "Ben Roethlisberger", "The Lost Symbol", "Heshmatullah Attarzadeh", "In fashionable neighborhoods of Tokyo customers are lining up for vitamin injections that promise to improve health and beauty.", "18 federal agents and two soldiers", "Seoul.", "resources", "66, served as vice-chairman of Hussein's Revolutionary Command Council.", "he won two Emmys for work on the 'Columbo' series starring Peter Falk.", "\"I have a very, very good family that I love back home in America, and are 100 percent behind you, and we thank God every day that you have our back.\"", "\"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "Rwanda", "75.", "to kill members of the Zetas, a ruthless cartel whose area of influence includes the eastern state of Veracruz.", "closing these racial gaps.", "\"He was held in federal custody over the weekend.", "President Bush", "a hospital in Amstetten,", "African National Congress Deputy President Kgalema Motlanthe", "\"There is nothing for me there in our country any more. I had no job and I could not afford anything. Even when I was working life was tough,\"", "\"The Kirchners have been weakened by this latest economic crisis,\"", "President Kennedy came down to Hoboken in '61 and I was only 10 years old.", "a strict interpretation of the law,", "telling CNN his comments had been taken out of context.", "Iran", "20% tax credit", "July 23.", "70,000 or so are estimated to be there now.", "\" Unfortunately, this is not an anomaly in Naples and in that neighborhood.\"", "Robert Remak", "Tim McGraw", "Prussian 2nd Army", "cabbage", "a homebrew campaign setting", "Beno\u00eet Jacquot", "white, pale green, blue, gold, pink (rare), reddish-yellow or", "the Capitol", "The Left Book Club", "holography"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5714843897351519}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.16, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.5, 0.6428571428571429, 0.7499999999999999, 0.0, 1.0, 0.0, 0.0, 0.0975609756097561, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.5, 0.4444444444444445, 0.0, 0.09523809523809525, 0.0, 0.29629629629629634, 0.33333333333333337, 1.0, 1.0, 1.0, 0.6923076923076924, 0.2962962962962963, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9016", "mrqa_squad-validation-397", "mrqa_squad-validation-10449", "mrqa_newsqa-validation-1233", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2065", "mrqa_newsqa-validation-4183", "mrqa_newsqa-validation-2869", "mrqa_newsqa-validation-3641", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-3325", "mrqa_newsqa-validation-2817", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-2795", "mrqa_newsqa-validation-1245", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-2903", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2654", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-185", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-2727", "mrqa_naturalquestions-validation-7158", "mrqa_triviaqa-validation-6858", "mrqa_hotpotqa-validation-5305", "mrqa_searchqa-validation-11133", "mrqa_triviaqa-validation-6296"], "SR": 0.4375, "CSR": 0.5947265625, "EFR": 0.9722222222222222, "Overall": 0.7834743923611112}, {"timecode": 16, "before_eval_results": {"predictions": ["two thousand", "address information", "high risk of a conflict of interest and/or the avoidance of absolute powers.", "to look at both the possibilities of setting up a second university in Kenya as well as the reforming of the entire education system.", "Thames River", "Lt Col Paul von Lettow-Vorbeck", "several hundred thousand, some 30% of the city", "the Tower District", "Ted Ginn Jr.", "Catch Me Who Can", "John Fox", "the housing bubble", "137", "Adam Lambert and Kris Allen,", "Brian Smith", "\"Hillbilly Handfishin'\"", "Charles Lock", "voluntary negligence", "his enjoyment of sex and how he lost his virginity at age 14.", "his injuries,", "in 1979", "murder", "next year", "U.S. special envoy to Sudan,", "Christopher Savoie", "Anil Kapoor.", "Afghanistan and India", "Dr. Albert Reiter,", "\"The IAEA has inspected the known nuclear sites where they may be enriching uranium", "brutal choice", "Matthew Fisher", "cancer,", "Courtney Love,", "us to step up.\"", "\"Walk -- Don't Run\" and \"Hawaii Five-O\"", "your own environmental videos", "two women", "Queen Elizabeth's birthday", "Monday,", "First Stop Resource Center and Housing Program", "Yusuf Saad Kamel", "hand-painted Swedish wooden clogs", "11 healthy eggs", "don't believe the U.S. assertion that the system is needed to guard against imminent threats from Iran or North Korea.", "to fritter his cash away on fast cars, drink and celebrity parties.", "Fullerton, California,", "around the United States", "in the 1950s,", "U.S. troops", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "More than 120 groups across six continents are holding vegan bake sales from April 24 through May 2.", "\"The Rosie Show,\"", "Trevor Rees,", "Oxbow,", "gastrocnemius", "Ed Sheeran", "20", "National Museum of Australia", "first of three films that comprise the \"Three Colours\"", "2001", "vingtaines", "U.S.", "George Blake", "Bogota"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5789520375457875}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false], "QA-F1": [1.0, 0.16666666666666669, 1.0, 0.9743589743589743, 1.0, 0.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.27272727272727276, 0.22222222222222224, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.08333333333333333, 0.0, 1.0, 0.0, 0.6666666666666666, 0.14285714285714285, 0.05555555555555555, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.2222222222222222, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_squad-validation-8570", "mrqa_squad-validation-8339", "mrqa_squad-validation-914", "mrqa_newsqa-validation-3529", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-2201", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-2308", "mrqa_newsqa-validation-1", "mrqa_newsqa-validation-601", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-3790", "mrqa_newsqa-validation-1928", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-853", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-2789", "mrqa_newsqa-validation-3275", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3125", "mrqa_newsqa-validation-2957", "mrqa_triviaqa-validation-1217", "mrqa_triviaqa-validation-1251", "mrqa_hotpotqa-validation-4647", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-10239", "mrqa_triviaqa-validation-6739"], "SR": 0.46875, "CSR": 0.5873161764705883, "EFR": 1.0, "Overall": 0.7936580882352942}, {"timecode": 17, "before_eval_results": {"predictions": ["lower levels of inequality", "a pharmacy practice residency", "questions and answers", "wakes (sed vigilat) and experiences visions", "Captain Francis Fowke,", "12 January", "2 million", "Zagreus", "CBS", "17", "temperate", "Rod Blagojevich,", "\"Sesame Street's\"", "Windsor, Ontario,", "$50 less,", "Afghanistan's restive provinces", "400 scraped together his last salary, some money he made from trading sugar bought at a discount from the supermarket where he worked, and funds borrowed from friends to secure a place to sleep.", "collaborating with the Colombian government,", "Iran", "Russian concerns about the missile defense system.", "Sharon Bialek", "Matthew Fisher,", "unclear,", "in the north and west of the country,", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation", "introduce legislation Thursday, to improve the military's suicide-prevention programs.\"", "$250,000", "Sunday afternoon.", "Derek Mears", "a motor scooter", "Gary Player,", "nieb\u00fcll", "It's helping consumers move beyond these hard times and has reignited a whole industry.", "kite boards", "Virgin America", "International Polo Club Palm Beach in Florida.", "Daniel Wozniak,", "22-year-old", "Omar bin Laden,", "\"What she's doing is putting a personal and human face on the issue... there's nothing more crucial,\"", "400 Afghan farmers", "U.S. Food and Drug Administration", "Casa de Campo International Airport", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place, and we hope to be protected up to 40 feet.\"", "2002", "at checkposts and military camps in the Mohmand agency,", "Lashkar-e-Tayyiba (LeT), an Islamic militant group based in Pakistan.", "Friday,", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "crocodile eggs", "from Geraldine Ferraro to Bill Clinton.", "\"aceli Valencia, was mopping the kitchen in their family home on a typical warm spring morning in Phoenix, Arizona,", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "senators", "in the five - year time jump for her brother's wedding to Serena van der Woodsen", "Messenger orbiter", "Arlene Phillips", "23 July 1989", "Ry\u016bkyuan people", "surrealism", "C. S. Lewis", "7", "rice wine", "Halifax"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5468643935765499}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, false, false, false, true], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.125, 1.0, 0.23529411764705885, 1.0, 1.0, 0.0, 0.3529411764705882, 0.5217391304347826, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 0.15384615384615388, 0.2857142857142857, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.1, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 0.4, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7341", "mrqa_squad-validation-2408", "mrqa_squad-validation-10114", "mrqa_newsqa-validation-3631", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3317", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-855", "mrqa_newsqa-validation-94", "mrqa_newsqa-validation-2191", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1453", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-2020", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1173", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2027", "mrqa_newsqa-validation-2022", "mrqa_newsqa-validation-157", "mrqa_naturalquestions-validation-132", "mrqa_triviaqa-validation-1659", "mrqa_hotpotqa-validation-1867", "mrqa_searchqa-validation-16043", "mrqa_searchqa-validation-8695", "mrqa_searchqa-validation-6296"], "SR": 0.46875, "CSR": 0.5807291666666667, "EFR": 1.0, "Overall": 0.7903645833333334}, {"timecode": 18, "before_eval_results": {"predictions": ["melatonin", "constant factors and smaller terms", "Shi Bingzhi", "Baron Dieskau", "linear", "Advanced Steam", "Defensive ends", "the dot", "chastity", "European Court of Justice", "bronze medal in the women's figure skating final,", "\"trying to steal the election\" and \"intimidating the population and election officials as well.\"", "UK", "\"Gandhi,\"", "Argentina", "Congress", "28", "Frank Ricci,", "the project, which is designed to promote private sector investment in a variety of gas-related industries,", "\"terrifying.\"", "Bill & Melinda Gates Foundation", "$106,482,500", "people give the United States abysmal approval ratings.", "the FDA is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.\"", "\"political and religious\"", "$163 million (180 million Swiss francs)", "Afghan lawmakers", "North Korea", "a precaution and did not change the threat level, an administration official said.", "the mammoth's fossil was found along with 16 other deposits at the site that paleontologists \"tree-boxed\" along with the surrounding dirt,", "\"global security, prosperity and freedom.\"", "because the federal government is both dishonest and reckless.", "Molotov cocktails, rocks and glass.", "\"wildcat\" strikes, unsanctioned by national unions, at other sites across the country.", "Ben Roethlisberger", "Dr. Christina Romete,", "Ewan McGregor", "Brazil", "Meira Kumar", "next week.", "other parts of Asia, such as India and mainland China,", "Lindsey Vonn", "(l-r) Paul McCartney, Yoko Ono Lennon, Olivia Harrison and Ringo Starr", "organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "race", "Los Ticos", "the Formagruppen ( Engelbrektsgatan 8)", "trying to detonate an explosive device in his underwear aboard a Christmas 2009 flight to Detroit,", "two people", "40-year-old", "Pakistan's North West Frontier Province,", "Casey Anthony,", "the iconic Hollywood headquarters of Capitol Records,", "Emma Watson and Dan Stevens", "2002", "his finger.", "\"Sunny Afternoon\"", "Che Guevara", "Miller Brewing", "Elizabeth I", "John Fogerty", "Garonne", "giraffe", "cheese"], "metric_results": {"EM": 0.515625, "QA-F1": 0.600410969004719}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, true, false, false, false, true, true, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.125, 0.2857142857142857, 0.8571428571428571, 1.0, 0.0, 0.9714285714285714, 0.0, 0.5, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.625, 0.2666666666666667, 0.0, 0.0, 0.0, 0.16, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2702702702702703, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10247", "mrqa_newsqa-validation-3220", "mrqa_newsqa-validation-3943", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3834", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-4171", "mrqa_newsqa-validation-1444", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-3068", "mrqa_newsqa-validation-176", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-263", "mrqa_newsqa-validation-2122", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-686", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-1203", "mrqa_newsqa-validation-1603", "mrqa_naturalquestions-validation-10406", "mrqa_naturalquestions-validation-9104", "mrqa_triviaqa-validation-7611"], "SR": 0.515625, "CSR": 0.5773026315789473, "EFR": 0.967741935483871, "Overall": 0.7725222835314092}, {"timecode": 19, "before_eval_results": {"predictions": ["1876", "1507", "Danny Trevathan", "11", "that unless he were removed from the school, Tesla would be killed through overwork.", "Japanese", "Muqali, a trusted lieutenant,", "2011 and 2012,", "Pittsburgh Steelers", "apartment building", "Aung San Suu Kyi", "(The Frisky)", "3rd District of Utah.", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Stephen Tyrone Johns", "three", "procedures", "acid attack by a spurned suitor.", "most of those who managed to survive the incident hid in a boiler room and storage closets", "\"I can tell you, there are definitely going to be more ships in that area in the next 24 or 48 hours, because there are two more sailing to the coming days.\"", "appealed against the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Courtney Love,", "33-year-old", "cell phones", "a book.", "he was diagnosed with skin cancer.", "to leave once there is a solid political solution to the conflict.", "Ashley \"A.J. Jewell,", "at least 17", "from her father's home in Satsuma, Florida,", "to the southern city of Naples", "Hugo Chavez", "London's", "home in rural California,", "knocking the World Cup off the front pages for the first time in days.", "Old Trafford", "the area of the 11th century Preah Vihear temple", "steam-driven, paddlewheeled overnight passenger boat.", "individual pieces.", "Alaska or Hawaii.", "homicide", "The Ski Train", "Aniston, Demi Moore and Alicia Keys", "Lillo Brancato Jr.", "intends to follow up with ICE to ensure that detainees are not drugged unless there is a medical reason to do so.\"", "Blagojevich", "$60 billion on America's infrastructure.", "protective shoes", "public-sector labor", "U.S. President-elect Barack Obama", "Burhanuddin Rabbani, a former Afghan president who had been leading the Afghan peace council,", "was depressed over a recent breakup, grabbed the gun and  took her own life.", "often discard beer bottles on pebbled walkways.", "Sedimentary rock", "3.45 billion years ago ( 2.45 Ga ), during the Siderian period, at the beginning of the Proterozoic eon", "London", "Colorado", "Bangor International", "his 2005 collaboration with GZA, \"Grandmasters\", and his 2007 collaboration with Sick Jacken, \" Legend of the Mask and the Assassin\"", "Suffragist", "Canterbury", "Tunisia", "Silver", "Bonnie and Clyde"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6435170575171709}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, false, true, false, false, true, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.631578947368421, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.9523809523809523, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 0.10810810810810811, 0.07692307692307693, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 1.0, 0.8333333333333333, 0.888888888888889, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.5, 0.5714285714285715, 1.0, 0.0, 1.0, 0.2857142857142857, 0.4, 0.0, 1.0, 0.896551724137931, 0.0, 1.0, 0.28571428571428575, 0.10526315789473684, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1326", "mrqa_squad-validation-6143", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-1757", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-3182", "mrqa_newsqa-validation-3769", "mrqa_newsqa-validation-2646", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-312", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-2260", "mrqa_newsqa-validation-3347", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-1977", "mrqa_newsqa-validation-3930", "mrqa_newsqa-validation-287", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-413", "mrqa_naturalquestions-validation-8257", "mrqa_triviaqa-validation-6758", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2805"], "SR": 0.484375, "CSR": 0.57265625, "EFR": 0.9696969696969697, "Overall": 0.7711766098484849}, {"timecode": 20, "before_eval_results": {"predictions": ["the Hostmen", "Greg Brady", "Jacksonville,", "Hungarians", "De Materia Medica", "John D. Rockefeller", "four", "lack of remorse, an attempt to avoid responsibility for her actions, and even a likelihood of repeating her illegal actions", "Beijing, China", "Virgil Tibbs", "Thaddeus Rowe Luckinbill", "up to 100,000", "the United States, its NATO allies and others", "Virginia Dare", "JackScanlon", "Kylie Minogue", "94 by 50", "Lalo Schifrin", "MGM Resorts International", "16 August 1975", "seawater", "1962", "Buddhist", "1978", "1927, 1934, 1938, 1956", "1969", "New England Patriots", "Joseph Heller", "the north pole", "1,350", "Leonard Bernstein", "25 September 2007", "Howard Caine", "Branford College", "62", "the team", "November 2014", "Archduke Franz Ferdinand of Austria", "Koine Greek : apokalypsis", "October 1941", "to refer to either peace between two entities ( especially between man and God or between two countries )", "bageecha or bagicha", "Cee - Lo", "before they kill him", "lacks the additives common to a complete tomato sauce and does not have the thickness of paste", "Labour Party", "three times", "November 25, 2002,", "December 27, 2015", "Peter Greene", "31 March 1909", "Ed Sheeran", "two", "Alberto Salazar", "live animals", "American", "Hoosick", "CEO of an engineering and construction company with a vast personal fortune.", "1.2 million", "The Three Little Pigs", "Robert Louis Stevenson", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "Russia and China", "Hanford Nuclear Site,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5961061507936508}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 1.0, 0.1111111111111111, 0.0, 0.0, 0.0, 0.9333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3086", "mrqa_squad-validation-6314", "mrqa_squad-validation-8027", "mrqa_squad-validation-6737", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-5180", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-2291", "mrqa_naturalquestions-validation-1409", "mrqa_naturalquestions-validation-2265", "mrqa_naturalquestions-validation-5808", "mrqa_naturalquestions-validation-5966", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-6972", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-8596", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-5476", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-2945", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-8934", "mrqa_triviaqa-validation-3886", "mrqa_hotpotqa-validation-2298", "mrqa_newsqa-validation-3687", "mrqa_searchqa-validation-13486", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-2446"], "SR": 0.515625, "CSR": 0.5699404761904762, "EFR": 0.9354838709677419, "Overall": 0.752712173579109}, {"timecode": 21, "before_eval_results": {"predictions": ["about 515 million years ago", "Spanish", "an attack on New France's capital, Quebec", "the Fresno Traction Company", "Westminster", "the ancestors of chloroplasts", "24 of the 32 songs", "Sauron", "Washington metropolitan area", "pH 7 ( 25 \u00b0 C )", "the breast or lower chest of beef or veal", "the ruling city of the Northern Kingdom of Israel,", "in either Tagalog or English", "around 1600 BC", "1984", "Michael Phelps", "Rajendra Prasad", "Ren\u00e9 Georges Hermann - Paul", "Donna", "the New York Yankees", "Orangeville, Ontario, Canada", "the electric potential generated by muscle cells when these cells are electrically or neurologically activated", "Janie Crawford,", "the 2nd century", "in the pancreas", "the Elk and Kanawha Rivers", "1961", "the latest version", "in rocks and minerals", "Michael Schumacher", "currency option", "1957", "1775", "1995", "Field Marshal Paul von Hindenburg", "2018", "Ireland", "Kit Harington", "her boyfriend Lance", "embryo", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Baker, California, USA", "Raja Dhilu", "October 12, 1979", "Guy Berryman", "Canadian ice dancers", "Sophocles", "Tim Allen as Luther Krank", "thick skin", "a cake", "India", "Brazil, Turkey and Uzbekistan", "on Chesapeake Bay,", "batsman", "the Major General of the Navy", "Marktown", "approximately 14,000", "that Iran could be secretly working on a nuclear weapon", "Honduras", "Pardon of Richard Nixon", "Ellen DeGeneres", "1961", "punk rock", "Westfield Old Orchard"], "metric_results": {"EM": 0.375, "QA-F1": 0.5099226590403061}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false, true, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 0.9333333333333333, 0.0, 0.30769230769230765, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.35294117647058826, 1.0, 0.8, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3076923076923077, 0.8, 0.0, 0.4, 0.0, 0.5454545454545454, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.4, 0.0, 0.0, 1.0, 1.0, 0.08, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4472", "mrqa_squad-validation-8780", "mrqa_squad-validation-2387", "mrqa_naturalquestions-validation-10565", "mrqa_naturalquestions-validation-10205", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-7920", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-7848", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-2748", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-10684", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-6429", "mrqa_naturalquestions-validation-6678", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-6874", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6843", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-9163", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-3670", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-6851", "mrqa_triviaqa-validation-5168", "mrqa_triviaqa-validation-4641", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-3883", "mrqa_hotpotqa-validation-3984"], "SR": 0.375, "CSR": 0.5610795454545454, "EFR": 1.0, "Overall": 0.7805397727272727}, {"timecode": 22, "before_eval_results": {"predictions": ["present-day Pittsburgh, Pennsylvania", "Stanford University", "linebacker", "the Mongol and Turkic tribes", "between 1859 and 1865", "Danny Lane", "in the New Testament ( Mark 3 : 13 -- 19, Matthew 10 : 1 -- 4, Luke 6 : 12 -- 16, and Acts 1 : 13 )", "The Fixx", "President Andrew Johnson", "Hellenism", "Mark Jackson", "Manhattan Island", "The Chainsmoker and British rock band Coldplay", "an annual income of US $11,770", "modestly", "week 4", "L.K. Advani", "the President", "Zachary John Quinto", "A.R. Rahman", "Massachusetts", "a single particle", "Thomas Jefferson", "the head of Lituya Bay in Alaska", "Manhattan, the Bronx, Queens, Brooklyn, and Staten Island", "on a sound stage in front of a live audience in Burbank, California", "Grace Zabriskie", "2014", "Yuzuru Hanyu", "Glenn Close", "Elk", "flawed democracy", "China", "Kirk Douglas", "Jodie Foster", "2007 -- 08", "Neil Patrick Harris", "8ft", "Owen Vaccaro", "bacteria", "on the lateral side", "Lynda Carter", "erosion", "90 \u00b0 N 0 \u00b0 W \ufeff / \ufefc 90 \u00b0N - 0 \u00b0 E", "London to Canterbury", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "in 2005", "February 29", "1840s", "9.7 m ( 31.82 ft )", "Montgomery", "Juliet", "Hotel California", "Paul Revere", "beetle", "Pearl Jam", "2005", "Dan Tyminski", "The 19-year-old woman", "in the country's largest city of Karachi", "at least nine", "Bashar al-Assad", "the New Revised Standard Version", "biathlon"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6256702473754104}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, false, false, false, false, true, true], "QA-F1": [0.8, 1.0, 1.0, 1.0, 0.25, 1.0, 0.34782608695652173, 0.33333333333333337, 0.8, 1.0, 1.0, 0.5, 0.2857142857142857, 0.5714285714285715, 0.0, 0.5714285714285715, 0.14814814814814814, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.8, 0.4444444444444445, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8148148148148148, 0.5, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.3636363636363636, 0.5454545454545454, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-10228", "mrqa_squad-validation-5620", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-4410", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-2079", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-7881", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-1046", "mrqa_naturalquestions-validation-519", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-1798", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-10428", "mrqa_naturalquestions-validation-9457", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-2101", "mrqa_hotpotqa-validation-1238", "mrqa_newsqa-validation-2904", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-1295", "mrqa_searchqa-validation-15510"], "SR": 0.46875, "CSR": 0.5570652173913043, "EFR": 0.9411764705882353, "Overall": 0.7491208439897699}, {"timecode": 23, "before_eval_results": {"predictions": ["internal strife", "a new stage in the architectural history of the regions they subdued", "Fresno", "castles and vineyards", "below 0 \u00b0C (32 \u00b0F)", "Von Miller", "Kansas", "Thaddeus Rowe Luckinbill", "December 25", "2002", "the Mandate of Heaven", "Geoffrey Zakarian", "Christopher Allen Lloyd", "prenatal development", "Holly", "Vijay Prakash", "Article 1, Section 2", "the Constitution of India came into effect on 26 January 1950", "Thomas Marvolo Riddle", "Dick Rutan and Jeana Yeager", "in sequence with each heartbeat", "Ren\u00e9 Descartes", "James P. Flynn", "detritus", "September 27, 2017", "Johnny Logan", "1981", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Tony Orlando and Dawn", "February 10, 2017", "Alex Skuby", "the Colony of Virginia", "March 2016", "1922", "Richard Roxburgh", "Bacon", "an explosion", "Heather Stebbins", "Redenbacher family", "sometimes ambiguous designation of two classes of organic compounds", "`` 0 '' trunk code", "April 1, 2016", "Friedman Billings Ramsey", "New York City", "cutting surfaces", "Massachusetts Compromise", "Justin Timberlake", "Andrew Moray and William Wallace", "Alamodome and city of San Antonio", "asexually", "John Garfield", "In 1871", "eye", "The History Boys", "sturgeon", "the White Knights of the Ku Klux Klan", "five", "Darkthrone", "Kingman Regional Medical Center,", "Phillip A. Myers", "CAIRO, Egypt", "Antarctica", "axon", "shiitake"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5901289682539683}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 1.0, 0.3333333333333333, 0.0, 0.5, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333333, 0.2857142857142857, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1129", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-9707", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-1445", "mrqa_naturalquestions-validation-3592", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7490", "mrqa_naturalquestions-validation-6022", "mrqa_naturalquestions-validation-7415", "mrqa_naturalquestions-validation-3260", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6977", "mrqa_naturalquestions-validation-1214", "mrqa_naturalquestions-validation-405", "mrqa_naturalquestions-validation-6927", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-232", "mrqa_triviaqa-validation-1207", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-3651", "mrqa_hotpotqa-validation-395", "mrqa_newsqa-validation-505", "mrqa_searchqa-validation-7144", "mrqa_searchqa-validation-12624"], "SR": 0.46875, "CSR": 0.5533854166666667, "EFR": 0.9705882352941176, "Overall": 0.7619868259803921}, {"timecode": 24, "before_eval_results": {"predictions": ["research, exhibitions and other shows", "no damage", "Stadtholder William III of Orange", "1945", "faith alone, whether fiduciary or dogmatic, cannot justify man", "Jim Thorpe", "the first hole of a sudden-death playoff", "the onset and progression of Alzheimer's disease", "Disco", "the \"Cisleithanian\" half of Austria-Hungary", "the Indian School of Business", "New York City", "Charles Whitman", "C. H. Greenblatt", "\"The Curious Case of Benjamin Button\"", "A55", "Corendon Dutch Airlines", "86", "Minneapolis, Minnesota", "the sea loch", "Fatih Ozmen", "U.S.", "Pacific Place", "writing for \"The New York Times\" and \"Popular Mechanics\", and is a regular contributor to various CNBC shows such as \"On the Money\"", "the Donny & Marie Showroom", "City of Westminster, London", "2016", "Steve Cuden", "New York University School of Law", "Crips", "Harper's Bazaar", "dementia", "the Province of Ferrara", "Guadalcanal Campaign", "Bishop's Stortford", "Starvation Is Motivation", "Barbara Niven", "Black Friday", "Archbishop of Canterbury", "TD Garden", "Vic Chesnutt", "the Teutonic Knights", "Australian", "Julie Taymor", "Easy", "World War I", "79 AD", "musicologist", "Portland, OR", "Yoruba", "\"Lucky\"", "Charles Otto Puth Jr.", "2007 and 2008", "2001", "1966", "Jeremy Clarkson", "Jehan Mubarak", "Medellin", "Joe Jackson", "alternative-energy vehicles", "2004", "genes", "olive", "Tjejmilen"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6154141865079366}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, false, false, true, false, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.08333333333333334, 1.0, 0.0, 0.8571428571428571, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2153", "mrqa_hotpotqa-validation-1893", "mrqa_hotpotqa-validation-5485", "mrqa_hotpotqa-validation-4669", "mrqa_hotpotqa-validation-5110", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-5348", "mrqa_hotpotqa-validation-1730", "mrqa_hotpotqa-validation-2213", "mrqa_hotpotqa-validation-5211", "mrqa_hotpotqa-validation-4192", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-4112", "mrqa_hotpotqa-validation-4441", "mrqa_hotpotqa-validation-431", "mrqa_naturalquestions-validation-1206", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-7203", "mrqa_triviaqa-validation-2659", "mrqa_triviaqa-validation-3361", "mrqa_newsqa-validation-1955", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-5511"], "SR": 0.53125, "CSR": 0.5525, "EFR": 0.9333333333333333, "Overall": 0.7429166666666667}, {"timecode": 25, "before_eval_results": {"predictions": ["progressive tax", "Jacksonville", "monophyletic", "Orthogonal components", "Fox Network", "La clemenza di Tito", "Anna Clyne", "Terence Winter, based on the memoir of the same name by Jordan Belfort", "Jeff Tremaine, Shanna Zablow, Dimitry Elyashkevich, Lance Bangs, Nick Weidenfeld and Keith Crofford", "Formula E", "Eastern College Athletic Conference", "Kim Jong-hyun", "Peter Chelsom", "The Ninth Gate", "heavy metal", "Cinderella", "Los Angeles", "Sharyn McCrumb", "Acid house", "Austria, south Germany, German Switzerland, and Slovenia at the end of the 18th century", "\"Fimm Borginn\"", "Miranda Leigh Lambert", "Shenandoah National Park", "BBC Formula One coverage", "10 Years", "Haleiwa Ali'i Beach Park", "Armin Meiwes", "1886", "Rockhill Furnace, Pennsylvania", "northeastern", "coca wine", "Entrepreneur", "the lead roles", "PBS", "second largest", "acid", "in 1911", "Johnnie Ray", "The Five", "Walt Disney Feature Animation", "in 2018", "torpedo boats", "1972", "Geographical Indication tag", "Ringo Starr", "Celtics", "World Championship Wrestling", "1994", "TD Garden", "the Chechen Republic", "Chrysler", "Princeton University", "2005", "the emperor Cuauhtemoc and Tenochtitlan, the capital of the Aztec Empire", "Tax Reform Act of 1986", "Henry Louis", "Mexico", "ThunderCats", "\"he was preparing the country for war and death, and to hand power to Kim Jong Un,\"", "the Catholic League", "Krishna Rajaram,", "gorgicus", "to earn the nickname Super Eli", "green"], "metric_results": {"EM": 0.5625, "QA-F1": 0.642686212998713}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.8, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.5, 1.0, 1.0, 0.1081081081081081, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-2753", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-5674", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5750", "mrqa_hotpotqa-validation-2056", "mrqa_hotpotqa-validation-2473", "mrqa_hotpotqa-validation-4553", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-2901", "mrqa_hotpotqa-validation-4240", "mrqa_hotpotqa-validation-1136", "mrqa_hotpotqa-validation-1586", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5254", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-4298", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-9487", "mrqa_triviaqa-validation-7575", "mrqa_newsqa-validation-2772", "mrqa_searchqa-validation-10249", "mrqa_searchqa-validation-4240"], "SR": 0.5625, "CSR": 0.5528846153846154, "EFR": 0.9642857142857143, "Overall": 0.7585851648351649}, {"timecode": 26, "before_eval_results": {"predictions": ["bacteriophage T4", "1698", "Xingu", "The Ruhr", "Dar es Salaam", "Heinkel Flugzeugwerke", "Victor Garber", "Pope John X", "Stanmore, New South Wales", "aged between 11 or 13 and 18", "Sleeping Beauty", "Orchard Central", "Tom Holland", "late eighteenth century", "The Snowman", "1979", "Premier League club Liverpool and the England national team", "port city of Aden,", "British", "Prince Louis of Battenberg", "1948", "Archie Andrews", "before", "17 December 177026 March 1827", "Crystal Dynamics", "Cleveland Cavaliers", "goalkeeper", "Debbie Harry", "\"media for the 65.8 million,\"", "John Joseph Travolta", "Hall & Oates", "the port of Mazatl\u00e1n", "striker", "Las Vegas,", "1919", "Kevin Spacey", "\"Love Streams\"", "Michael Edwards", "The Rite of Spring", "Lake Wallace", "England", "1993", "Boston Celtics", "The Eisenhower Executive Office Building", "6,396", "Australian coast", "The Saturdays", "Attack the Block", "Leonarda Cianciulli", "Morse Field", "Tudor music", "CMYK process", "1600 BC ( possibly a fragmentary copy of a text from 2500 BC )", "The centuries - old Jedi Grand Master", "1963", "a palla", "gaiusan", "caspian", "15,000", "2,500", "\"It has never been the policy of this president or this administration to torture.\"", "Tarzan", "Japan", "potp0urri"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6111492673992673}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, false, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-2737", "mrqa_hotpotqa-validation-2153", "mrqa_hotpotqa-validation-3410", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-3523", "mrqa_hotpotqa-validation-788", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1352", "mrqa_hotpotqa-validation-3886", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-606", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-5619", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4558", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10188", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-6931", "mrqa_triviaqa-validation-1677", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-97", "mrqa_searchqa-validation-13669"], "SR": 0.53125, "CSR": 0.5520833333333333, "EFR": 1.0, "Overall": 0.7760416666666666}, {"timecode": 27, "before_eval_results": {"predictions": ["Merritt Island", "pedagogic diversity", "Catholic", "Extension", "Cinderella", "Dan Tyminski", "Guthred", "October 17, 2017", "Kolkata", "Dumb and Dumber", "Boeing EA-18G Growler", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment and services", "Paper", "Alistair Grant", "Whitney Houston", "pneumatic tyres pioneer John Boyd Dunlop", "Bonkyll Castle", "Cheick Tiot\u00e9", "Algernod Lanier Washington", "erotic romantic comedy", "leg injury", "Antonio Salieri", "American", "Europe", "Ant Apollonius and Silla", "Brooklyn, New York", "Thriller", "Jesper Myrfors", "The Supremes", "\"A Song of Ice and Fire\"", "Kalokuokamaile, the older brother of Kamehameha I, founder of the Kingdom of Hawaii", "his father", "Charlie B. Barkin", "2008", "Chief of the Operations Staff of the Armed Forces High Command", "Hong Kong Disneyland", "London", "I Should Have Known Better", "September 8, 2017", "FBI", "Christine MacIntyre", "1911", "Wildhorn, Bricusse and Cuden", "Hotch kiss M1914 machine gun", "James Brolin", "Prussian army general", "January 2004", "co-founder and lead guitarist", "ten", "seven species", "October 25, 1881", "Sam Waterston", "Pradyumna", "Mark Jackson", "Road / Track", "The Colossus of Rhodes", "Equatorial Guinea", "c3H8O3", "identity documents", "Chris Robinson and girlfriend Allison Bridges", "U.S.", "bromide", "septum", "light"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6504777568922306}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, false, true, true, true, false, true, false, false, false, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.4000000000000001, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1916", "mrqa_hotpotqa-validation-471", "mrqa_hotpotqa-validation-68", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5708", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-3252", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-4135", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-1054", "mrqa_hotpotqa-validation-2837", "mrqa_hotpotqa-validation-3400", "mrqa_hotpotqa-validation-1734", "mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-697", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-6398"], "SR": 0.59375, "CSR": 0.5535714285714286, "EFR": 1.0, "Overall": 0.7767857142857143}, {"timecode": 28, "before_eval_results": {"predictions": ["public (government) funding", "boarding schools and day schools", "a program of coordinated, evolving projects sponsored by the National Science Foundation", "Hanover", "Henry Mancini", "tenno", "Gordon Ramsay", "Gorbachev", "free-associative riffs", "the rose", "Charlton Heston", "Anna (Julia Roberts)", "binky", "orchid", "Paddy Doherty", "smallpox", "the Great Pyramid", "Libya", "Yeehaw", "F\u00fcr Elise", "Iran", "Who\u2019s Who", "\"These Names Make News: Statement of Policy\u201d", "Porthos", "April", "Eric Morley", "ADHD and hypertension", "the Garrick Club", "Belle", "Fabio Capello", "New York", "Stoppard", "The Greatest", "a singer and performer", "the college circuit", "pepper", "jazz", "Everett", "the Union Inn", "Cardiff", "Baton Rouge", "stromberg", "Tahrir Square", "Romanian", "bathtub curve", "Michael Caine", "Snooty", "Alexander Borodin", "Jesse James", "muzzles", "Greek", "passion fruit", "Thomas Lennon", "Haikou on the Hainan Island", "in his Leviathan", "Denmark and Norway", "1966", "North America", "Everglades", "the 1,500-seat Encore Theater", "glamorous, sexy and international.", "driving through a fast-food chain", "a set of steak knives", "Sebastian Stark"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5185391865079365}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, false, false, true, false, true, true, true, true, false, true, false, true, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, false, false, false, false, true, true, false, true, true, false, true, false, false, true, false, false, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.28571428571428575, 0.4285714285714285, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.888888888888889, 0.7499999999999999, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6891", "mrqa_squad-validation-6918", "mrqa_squad-validation-4846", "mrqa_triviaqa-validation-3753", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-6165", "mrqa_triviaqa-validation-7349", "mrqa_triviaqa-validation-2856", "mrqa_triviaqa-validation-6272", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-5069", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-2313", "mrqa_triviaqa-validation-614", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-7660", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-3909", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-5994", "mrqa_triviaqa-validation-2902", "mrqa_triviaqa-validation-6701", "mrqa_triviaqa-validation-3243", "mrqa_triviaqa-validation-1227", "mrqa_triviaqa-validation-7182", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-9024", "mrqa_hotpotqa-validation-2910", "mrqa_newsqa-validation-3911", "mrqa_newsqa-validation-3674", "mrqa_newsqa-validation-1004", "mrqa_searchqa-validation-8934", "mrqa_searchqa-validation-12186", "mrqa_searchqa-validation-15919"], "SR": 0.421875, "CSR": 0.5490301724137931, "EFR": 1.0, "Overall": 0.7745150862068966}, {"timecode": 29, "before_eval_results": {"predictions": ["Chicago Theological Seminary", "CBS", "$100,000", "Super Bowl LII", "starch", "Taylor Michel Momsen", "Kennedy Space Center ( KSC ) in Florida", "Kyrie Irving", "James W. Marshall", "in florida", "Randy VanWarmer", "negotiates treaties with foreign nations", "Emma Watson and Dan Stevens as the eponymous characters with Luke Evans, Kevin Kline, Josh Gad, Ewan McGregor, Stanley Tucci, Audra McDonald, Gugu Mbatha - Raw, Ian McKellen", "between 8.7 % and 9.1 %", "between January 21 and February 20", "if the occurrence of one does not affect the probability of occurrence of the other", "Jason Flemyng", "Chesapeake Bay, south of Annapolis in Maryland", "northern China", "T.J. Miller", "in Pyeongchang County, Gangwon Province, South Korea", "the status line", "innermost in the eye", "jimmy man", "Triple Alliance of Germany, Austria - Hungary, and Italy", "Andrew Lloyd Webber", "1955", "Charles Frederickson ( Nick Sager )", "Buffalo Lookout", "Humpty Dumpty", "Charlene Holt", "1 US dollar", "the original Star Trek television series", "1960", "Sam", "10.5 %", "beneath the liver", "Andy Serkis", "West Norse sailors", "High school senior Buffy Summers", "Anna Faris", "1995", "Fleetwood Mac", "technological advances in printing", "Illinois", "in the 1970s and'80s", "in the books of Exodus and Deuteronomy", "Dusty", "Psychomachia, '' an epic poem written in the fifth century", "January 2, 1971", "The Miracles", "taxonomy", "elbow", "jimmy adaman", "Charlie Sheen", "\"Twice in a Lifetime\"", "Nineteen Eighty-Four", "Bardot", "27", "Long Island convenience store", "Mitt Romney", "rock", "heart disease", "bronchitis"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6058417277167276}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, false, true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, false, true, false, true, true, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.14285714285714288, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5454545454545454, 0.45454545454545453, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5764", "mrqa_naturalquestions-validation-9726", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8068", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-188", "mrqa_naturalquestions-validation-5069", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-4193", "mrqa_naturalquestions-validation-6875", "mrqa_naturalquestions-validation-6711", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-7217", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-1941", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-3412", "mrqa_naturalquestions-validation-2907", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-6865", "mrqa_triviaqa-validation-6508", "mrqa_hotpotqa-validation-2047", "mrqa_newsqa-validation-1979", "mrqa_searchqa-validation-11741", "mrqa_searchqa-validation-7426", "mrqa_searchqa-validation-647"], "SR": 0.53125, "CSR": 0.5484375, "EFR": 1.0, "Overall": 0.77421875}, {"timecode": 30, "before_eval_results": {"predictions": ["San Jose", "quality rental units", "cultural tourism and sports tourism", "a circle", "( Sequoia sempervirens)", "The Fairly Odd Parents", "Spanish Republic", "taxicab", "(twin brother of the god Quetzacoatl)", "The Sun", "Harry Reid", "Ray", "Axis", "forge", "Kinetoscope", "(Why did he kill them?)", "flowers", "Blackbird", "Footprints", "Caliban", "The Royal Report", "Census Bureau", "Tommy Lee Jones", "(St.) Jose Maria Escriva", "The Memory Keeper's daughter", "George Eliot", "hubris", "Yahtzee", "Who's the Boss", "markup language", "(overlapping circles)", "74.3", "William Surrey Hart", "(Sahih al-Bukhari)", "Pride and Prejudice", "adjectives", "kosher wine", "Munich", "Michael Jordan", "(St.) Andrew's Day", "Prospero", "Hikaru Sulu", "parrots", "pastry", "(St.) Aso-san)", "pak thong", "Boston", "Fisher- Price", "Arctic Ocean", "the Italian flag", "Pumpkin soup", "Spain", "Thomas Chisholm", "May 2002", "1936", "Newfoundland and Labrador", "The Odd Couple", "Monty Python's Spamalot", "1911", "Bryan Kocis", "devised of and commentary on Isaac Newton's book \"Principia\"", "Israeli Prime Minister Ehud Olmert", "Adidas", "anti-trust laws."], "metric_results": {"EM": 0.4375, "QA-F1": 0.5307291666666667}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true], "QA-F1": [0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-315", "mrqa_squad-validation-2965", "mrqa_searchqa-validation-16168", "mrqa_searchqa-validation-8463", "mrqa_searchqa-validation-5623", "mrqa_searchqa-validation-3963", "mrqa_searchqa-validation-16017", "mrqa_searchqa-validation-2374", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-11167", "mrqa_searchqa-validation-5093", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-6519", "mrqa_searchqa-validation-6305", "mrqa_searchqa-validation-2523", "mrqa_searchqa-validation-12072", "mrqa_searchqa-validation-12415", "mrqa_searchqa-validation-4307", "mrqa_searchqa-validation-6767", "mrqa_searchqa-validation-13549", "mrqa_searchqa-validation-9773", "mrqa_searchqa-validation-4861", "mrqa_searchqa-validation-9379", "mrqa_searchqa-validation-13738", "mrqa_searchqa-validation-10080", "mrqa_searchqa-validation-16158", "mrqa_searchqa-validation-9820", "mrqa_searchqa-validation-6412", "mrqa_naturalquestions-validation-10656", "mrqa_triviaqa-validation-28", "mrqa_triviaqa-validation-3030", "mrqa_hotpotqa-validation-4718", "mrqa_hotpotqa-validation-391", "mrqa_newsqa-validation-1406"], "SR": 0.4375, "CSR": 0.544858870967742, "EFR": 0.9722222222222222, "Overall": 0.7585405465949822}, {"timecode": 31, "before_eval_results": {"predictions": ["Rev. Paul T. Stallsworth", "white", "Bill Cosby", "satirical erotic romantic comedy", "the Ferengi cocktails Quark", "the Social Democratic Party of Austria", "June 26, 1970", "Bloomingdale Firehouse", "elizabeth Stefanik", "Fleetwood Mac", "Odense Boldklub", "Supreme Court", "Bangkok, Thailand", "The Oklahoma Sooners", "Weare", "Charlie Wilson", "The Late Late Show", "Mark Anthony \"Baz\" Luhrmann", "two", "Indianapolis Motor Speedway", "Romagnol", "Anita Dobson", "a family member", "January 19, 1943", "The Worm", "Eliot Cutler", "Blackheart Records", "1970s and 1980s", "C. J. Cherryh", "Pablo Escobar", "16,116", "Nyack", "\"Slaughterhouse-Five\"", "Shohola Falls", "wineries", "Frank Sinatra", "Robert L. Stone", "goalkeeper", "Philadelphia", "New York", "Massapequa", "Sinngedichte", "Highwayman", "Madrid", "Kevin Spacey", "Arizona State University", "Blue Grass Airport", "Lawton Chiles", "1952", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "I'm Shipping Up to Boston", "the Royal Navy", "Lenny Jacobson", "Hathi Jr", "1935", "a serpent", "\"Slow\"", "The Miracles", "Winter Park", "the European Commission", "this year's Nobel Peace Prize", "Blu Cantrell", "Franklin D. Roosevelt", "Ukraine"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6524038461538462}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, true, true, false, false, false, false, true, true, false, false, true, false, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.5, 1.0, 1.0, 0.8, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-1143", "mrqa_hotpotqa-validation-3320", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-1745", "mrqa_hotpotqa-validation-3875", "mrqa_hotpotqa-validation-1430", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-2268", "mrqa_hotpotqa-validation-2989", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-1364", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-1356", "mrqa_hotpotqa-validation-2607", "mrqa_hotpotqa-validation-3538", "mrqa_hotpotqa-validation-844", "mrqa_naturalquestions-validation-1846", "mrqa_naturalquestions-validation-3066", "mrqa_triviaqa-validation-5034", "mrqa_triviaqa-validation-6414", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-3918", "mrqa_newsqa-validation-512", "mrqa_searchqa-validation-6898", "mrqa_searchqa-validation-6055"], "SR": 0.578125, "CSR": 0.5458984375, "EFR": 1.0, "Overall": 0.77294921875}, {"timecode": 32, "before_eval_results": {"predictions": ["Hugh L. Dryden", "2004", "Kenya", "The Rocky Horror Picture Show", "Trainspotting", "Argentina", "Apollo 11 mission", "jellyfish", "March", "a clog", "fauntleroy", "the International Monetary Fund", "Eat porridge", "Kofi Annan", "oxygen", "the right to print was strictly controlled in England", "Taggart", "i second that was something he had been looking forward to this for a long time.", "the Atlantic Ocean", "i second that emotion", "Sven Goran Eriksson", "the BBC motto", "Route 66", "Brussels", "Flora MacDonald", "John Poulson", "i second largest airport, Orly", "the euro", "i second that mullet", "Saskatchewan (Province)", "Ambroz Bajec-Lapajne", "the Solent", "vomiting", "Basketball", "Bristol Aeroplane Company", "lettuces", "Tony Meo", "i second that that\u2019s gonna happen.", "Gemini", "Surrey", "1971", "i second that emotion", "Boston", "Chile", "William Shakespeare", "sodium tetraborate decahydrate", "a type of electrified hybrid urban and suburban railway", "Jamaica", "Peter Nichols", "Jason David", "Kent", "Vickers-Armstrong", "Ray Charles", "Rigor mortis is very important in meat technology", "USCS or USC", "Miller Brewing", "Liguria", "Sydney", "The nation's foremost concert producer, Charles Jubert, died. So did members of four bands who were practicing inside a studio that collapsed.", "Alice Horton", "\"The train ride up there is spectacular. You see wonderful vistas as you leave Denver through the northern plains and into the mountains,\"", "Peter Bogdanovich", "a Mourning Dove", "the Federal Republic"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5643465909090909}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, true, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 0.4444444444444445, 0.12121212121212123, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-2282", "mrqa_triviaqa-validation-7489", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-6942", "mrqa_triviaqa-validation-7165", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-6327", "mrqa_triviaqa-validation-4986", "mrqa_triviaqa-validation-7244", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-4758", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-3628", "mrqa_triviaqa-validation-6949", "mrqa_triviaqa-validation-6989", "mrqa_triviaqa-validation-468", "mrqa_naturalquestions-validation-2680", "mrqa_naturalquestions-validation-5817", "mrqa_hotpotqa-validation-3368", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-1488", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-5611"], "SR": 0.515625, "CSR": 0.5449810606060606, "EFR": 1.0, "Overall": 0.7724905303030303}, {"timecode": 33, "before_eval_results": {"predictions": ["New York and Virginia", "1887", "Lana Del Rey", "1,228 km / h", "New England Patriots", "Doc '' Brown", "Antarctica", "Mitch Murray", "blue", "Ultra Hand", "God Save the King", "775 rooms", "piety", "dennis Larson", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "Longline fishing", "Jesus'birth", "a habitat", "Simone Vangsness", "Central Germany", "Andrew Johnson", "Etienne de Mestre", "Aegisthus", "electors", "Julia Ormond", "Sauron's assistance, the Elves - smiths forged the Rings of Power", "1961", "ste\u026and / STAYND", "2013", "March 1", "novelization", "a usually red oxide formed by the redox reaction", "Spain", "MacKenzie Mauzy", "Paul Lynde", "elevator pitch -- reflects the idea that it should be possible to deliver the summary in the time span of an elevator ride, or approximately thirty seconds to two minutes", "Jocelyn Flores", "fled to exile in the Netherlands", "most - visited paid monument in the world", "erosion", "March 2, 2016", "a large roasted turkey", "1996", "Ray Charles", "18", "Ramones", "1800", "Anglo - Norman French waleis", "Frank Theodore", "Los Angeles", "May 2010", "France", "Heath Ledger", "dorsalis", "a centaur", "a young getaway driver and music lover who must work for a kingpin", "cricket fighting", "Luis Resto", "drama that pulls in the crowds has also provided rich material", "a Nazi German death camp", "safer surroundings.", "Tunisia", "RAND", "AIDS"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5383348005586666}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, true, false, false, false, true, true, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, false, true, false, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 0.06451612903225806, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.7368421052631579, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7804878048780487, 0.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3076923076923077, 1.0, 0.0, 0.125, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3127", "mrqa_naturalquestions-validation-6061", "mrqa_naturalquestions-validation-10238", "mrqa_naturalquestions-validation-3784", "mrqa_naturalquestions-validation-7802", "mrqa_naturalquestions-validation-4844", "mrqa_naturalquestions-validation-9572", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-1226", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-5170", "mrqa_naturalquestions-validation-2499", "mrqa_naturalquestions-validation-2897", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-663", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-8695", "mrqa_naturalquestions-validation-4387", "mrqa_naturalquestions-validation-2092", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4561", "mrqa_triviaqa-validation-5607", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-1997", "mrqa_newsqa-validation-4113", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-2243", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-9333"], "SR": 0.4375, "CSR": 0.5418198529411764, "EFR": 1.0, "Overall": 0.7709099264705882}, {"timecode": 34, "before_eval_results": {"predictions": ["Venus", "Beyonc\u00e9 and Bruno Mars", "Cal", "7th century", "2018", "her abusive husband", "September 29, 2017", "interstellar space", "transmission and final drive", "Universal Pictures", "Vijay Prakash", "March 14, 1942", "Nick Sager", "London boroughs, Metropolitan Boroughs, unitary authorities, and district councils", "prophets", "state legislators", "Gastric acid, gastric juice or stomach acid, is a digestive fluid formed in the stomach and is composed of hydrochloric acid ( HCl ), potassium chloride ( KCl ) and sodium chloride ( NaCl )", "Renishaw Hall, Derbyshire, England", "accomplish the objectives of the organization", "pickup", "Isabella Palmieri", "temperature at which the phase transition occurs", "Mind your Ps and Qs", "Germany", "20 November 1989", "Spanish Dominican Tom\u00e1s de Torquemada", "Bob Gaudio", "1975", "Irene Bedard", "Procol Harum", "Erica Rivera", "zinc", "a four - page pamphlet in 1876", "2003", "Sebastian Lund", "Wednesday, 5 September 1666", "Pebble Beach", "The management team", "various submucosal membrane sites", "Flex SDK, a set of components that included charting, advanced UI, and data services ( Flex Data Services )", "Steveston Outdoor pool in Richmond, BC", "Phillip Schofield and Christine Bleakley", "adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Ukraine", "Jem", "1850", "when the car comes to a halt", "early Christians of Mesopotamia, and from there it spread into Russia and Siberia through the Orthodox Churches, and later into Europe through the Catholic and Protestant Churches", "Tennesseeitans", "lowest air temperature record", "a cliffhanger showing the first few moments of Sam's next leap", "engraved on a bronze plaque and mounted inside the pedestal's lower level", "a chocolate cereal", "wilson", "Brian Close", "recording debut of future AC/DC founders Angus Young and Malcolm Young", "Galleria Vittorio Emanuele II", "Totalitarianism", "reached an agreement late Thursday to form a government of national reconciliation.", "Olympic medal", "Henry Ford", "Toyota", "vice president", "a mass of cells that grows slowly in... be slow-growing and unlikely to spread"], "metric_results": {"EM": 0.375, "QA-F1": 0.48275873731153907}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, false, true, true, false, true, false, true, false, false, false, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.5, 1.0, 0.3636363636363636, 1.0, 0.5, 0.14814814814814814, 0.888888888888889, 1.0, 0.0, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.7499999999999999, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.26666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.29629629629629634, 0.06896551724137931, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.20000000000000004, 0.2758620689655173, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-8664", "mrqa_naturalquestions-validation-9272", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-6194", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-10408", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-1119", "mrqa_naturalquestions-validation-4109", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-10576", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-2239", "mrqa_naturalquestions-validation-5702", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-3022", "mrqa_naturalquestions-validation-7235", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4633", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-1562", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-904", "mrqa_newsqa-validation-3224", "mrqa_newsqa-validation-2419", "mrqa_searchqa-validation-4141", "mrqa_searchqa-validation-15641"], "SR": 0.375, "CSR": 0.5370535714285714, "EFR": 0.95, "Overall": 0.7435267857142857}, {"timecode": 35, "before_eval_results": {"predictions": ["domestic Islamists", "euphoric", "The Colossus of Rhodes", "Venezuela", "Croatia", "The Ring", "Wendy's Story", "d'Agnolo", "the Arctic Ocean", "air pressure", "dams", "Gilbert du Motier", "Elijah Muhammad", "depression or unhappy listlessness.", "the Village People", "Alexander Pushkin", "Australia", "Munich Crisis", "Puebla", "rotating shifts", "the papacy", "the Delta", "The AI Behind Watson", "Renoir", "de savoir", "gaiacomo Meyerbeer", "Innsbruck", "Lance Ito", "Microsoft", "a fern", "alberta", "hanjulfsson", "Atlantic City", "Blackwater USA", "elephants", "American Airlines", "alberta", "Odysseus", "Geronimo.", "the London Museum at Kensington Palace", "William Carver", "Breda", "Pocahontas", "the Lion, the Witch and the Wardrobe", "John Galt", "the amygdala", "the Chicago Mercantile Exchange", "Las Vegas", "danskin", "wheat", "Pablo Casals", "a tamed ostrich", "1943", "Payaya Indians", "beneath the liver", "James I", "penrhyn", "psychological horror", "John Morgan", "Hungarian Rhapsody No. 2", "Eleanor of Aquitaine", "Sen. Debbie Stabenow", "63", "\"We are resetting, and because we are resetted, the minister and I have an overload of work.\""], "metric_results": {"EM": 0.546875, "QA-F1": 0.59375}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, true, false, true, false, true, false, true, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, true, false, true, true, false, true, true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6404", "mrqa_searchqa-validation-5600", "mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-7214", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-1774", "mrqa_searchqa-validation-11675", "mrqa_searchqa-validation-1917", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-3746", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-3215", "mrqa_searchqa-validation-11376", "mrqa_searchqa-validation-5646", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-16363", "mrqa_searchqa-validation-9239", "mrqa_searchqa-validation-15775", "mrqa_searchqa-validation-5473", "mrqa_naturalquestions-validation-368", "mrqa_triviaqa-validation-3348", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-2352"], "SR": 0.546875, "CSR": 0.5373263888888888, "EFR": 1.0, "Overall": 0.7686631944444444}, {"timecode": 36, "before_eval_results": {"predictions": ["to be lit up by electric lighting", "James W. Marshall", "Terrell Suggs", "the Earth's axial tilt, which fluctuates within a margin of 2 \u00b0 over a 40,000 - year period, due to tidal forces resulting from the orbit of the Moon", "Lucknow", "in the eighth episode of Arrow's second season", "National Industrial Recovery Act ( NIRA )", "The User State Migration Tool", "the Battle of Antietam", "William DeVaughn", "the National September 11 Memorial plaza", "the Thames Estuary", "Santa Monica", "the modern state system", "Raza Jaffrey", "31 January 1934", "Filipino", "1773", "RAM", "2012", "April 1917", "Bart Cummings", "October 27, 1904", "Harishchandra", "Olivia Olson", "2017", "the Canadian rock band Nickelback", "Bill Pullman", "BC Jean", "2016", "James and Lukas Rodriguez", "The stratum lucidum", "60", "Hasmukh Adhia", "four", "retinal", "the 1980s", "in plants and other living organisms", "card verification value ( CVV )", "to oversee the local church", "bohrium", "Britain", "a Gram - negative, facultatively anaerobic, rod - shaped, coliform bacterium", "Gavrilo Princip", "June 1991", "2010", "he lost the support of the army, abdicated in November 1918, and fled to exile in the Netherlands", "in De Inventione by Marcus Tullius Cicero", "Mike Czerwien", "1.23 % of India's total surface area", "Vienna", "(Barbados)", "Mexico", "\u201cThe Pope? How many divisions does the Pope of Rome have?", "$10.5 million", "Al Horford", "Andrew Johnson", "$22 million", "the leftist Workers' Party", "his mother and his three children", "cotton", "Denzel Washington", "Quinn", "Towcester"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5804387480798772}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, true, true, false, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, true, false, false, false, true, true, false, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, false, false, true, true, true, true], "QA-F1": [0.4444444444444445, 1.0, 0.0, 0.12903225806451613, 1.0, 0.7142857142857143, 0.888888888888889, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.09523809523809523, 0.16666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5157", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-2833", "mrqa_naturalquestions-validation-1696", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-8005", "mrqa_naturalquestions-validation-2411", "mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-6264", "mrqa_naturalquestions-validation-2333", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-3316", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-6916", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-7142", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-1028", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-4195", "mrqa_hotpotqa-validation-4351", "mrqa_newsqa-validation-2544", "mrqa_newsqa-validation-1953"], "SR": 0.46875, "CSR": 0.535472972972973, "EFR": 0.9411764705882353, "Overall": 0.7383247217806042}, {"timecode": 37, "before_eval_results": {"predictions": ["Joseph Swan", "the United States", "South Africa", "minorities as a threat", "Scott Hicks", "a cappella", "albinism", "Peterloo", "aglet", "Saturday Night Live", "FC Bayern M\u00fcnchen", "winter", "Bonnie and Clyde", "english", "copper", "Dawn French", "joseph Bowie", "a name that was a nurse in British hospitals during the Crimean War and is usually considered the founder of modern nursing", "Doris Lessing", "Scooby-Doo", "Swaziland", "joseph st John's College, Cambridge", "Kent", "the Humber", "a points based scoring system", "stuttgart", "Kent", "Rodgers and Hammerstein", "Culture Club", "Galileo Galilei", "Zelle", "Lee Ingleby", "Marilyn Manson", "Medellin,", "The Tempest", "spark-ignition", "a Celts", "Boulder Dam", "high-term effects", "Saudi Arabia", "Belle de Jour", "Morecambe", "abba", "precipitation", "blue", "the American astronomer asaph Hall", "France", "Frederick Little", "Kunsky", "psychology", "Rosamund Pike", "the forces of Andrew Moray and William Wallace", "142,907", "mid November", "YouTube", "Theo Walcott", "Ben Ainslie", "the District of Columbia near Takoma Park, Maryland.", "lightning strike", "different women coping with breast cancer in five vignettes.", "the &quot", "a sunflower", "Madonna", "March 24,"], "metric_results": {"EM": 0.5, "QA-F1": 0.5511904761904762}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, false, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 0.8, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3929", "mrqa_triviaqa-validation-5175", "mrqa_triviaqa-validation-69", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-5902", "mrqa_triviaqa-validation-5803", "mrqa_triviaqa-validation-3445", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-4921", "mrqa_triviaqa-validation-2386", "mrqa_triviaqa-validation-1497", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7074", "mrqa_triviaqa-validation-7384", "mrqa_triviaqa-validation-7434", "mrqa_triviaqa-validation-2500", "mrqa_triviaqa-validation-3612", "mrqa_triviaqa-validation-3855", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-2982", "mrqa_triviaqa-validation-298", "mrqa_triviaqa-validation-330", "mrqa_triviaqa-validation-687", "mrqa_triviaqa-validation-3013", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-8884", "mrqa_hotpotqa-validation-869", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-442", "mrqa_searchqa-validation-15674", "mrqa_searchqa-validation-6291"], "SR": 0.5, "CSR": 0.5345394736842105, "EFR": 1.0, "Overall": 0.7672697368421053}, {"timecode": 38, "before_eval_results": {"predictions": ["the Rip", "tyne", "the liver", "40", "sodium", "Bears", "cuba", "lewis le", "Phil Redmond", "Stevie Wonder", "the head", "hound", "hanover", "the sun", "the Earl of Strafford", "workless households", "scales", "Dirty Dancing", "the Greek Goddess of Revenge", "diana Ross", "Montezuma", "a 1934 Austin seven box saloon", "Paul Anka", "henry lewis", "albion", "a Dagger", "Blade Runner", "Jay-Z", "leopons", "cymbals", "air Bud", "le Dame aux cam\u00e9lias", "davis taylor", "flore", "South Africa", "Christian Dior", "albion", "a toothed whale", "george taylor", "lewis d'\u00c9vreux", "berries", "pilgrimage", "Cyprus", "speed camera", "duke", "lewis", "Blue Streak", "frauds", "a sea monster", "even numbers", "Tony Blair", "quartz or feldspar", "54 Mbit / s, plus error correction code", "Manley", "Stacey Kent", "Eyes Wide Shut", "Anthony Ray Lynn", "cards", "paid tribute to pop legend Michael Jackson,", "former U.S. President Bill Clinton", "French Guiana", "albion", "heraldry", "Tiger Woods"], "metric_results": {"EM": 0.375, "QA-F1": 0.42924107142857143}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, true, true, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, true, true, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.6, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2224", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-7768", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-3767", "mrqa_triviaqa-validation-2132", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-892", "mrqa_triviaqa-validation-6438", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-6652", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-7662", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-1924", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-2584", "mrqa_triviaqa-validation-1499", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-2909", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3351", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6603", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5730", "mrqa_newsqa-validation-785", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-2594", "mrqa_searchqa-validation-9940", "mrqa_searchqa-validation-4817", "mrqa_newsqa-validation-3899"], "SR": 0.375, "CSR": 0.530448717948718, "EFR": 0.975, "Overall": 0.752724358974359}, {"timecode": 39, "before_eval_results": {"predictions": ["\"No, that's no good\"", "Aldi", "Midnight Cowboy", "watling", "seborrheic dermatitis", "Amanda Barrie", "a barge", "Niger", "central Stockholm", "Tangled", "dogs", "James \"Buster\" Douglas", "Bulls Eye", "Napoleon I", "Laurent Planchon", "Martin Clunes", "charles Darwin", "pembrokeshire Coast National Park", "Kevin macdonald", "peppers", "early cenozoic Era", "joseph Boyd", "isambard Kingdom Brunel", "georgia", "1957", "Devonport", "seine", "potatoes", "watling", "Ralph Vaughan Williams", "musical scale", "cats", "flannel", "E. T. A. Hoffmann", "Shanghai", "Spain", "farms", "Tuesday", "Guru Nanak", "bleak house", "Inigo Montoya", "phosphorus", "nursery rhymes", "Doha, Qatar", "norman humbert", "cuckoo bird", "argatha Christie", "Ford", "Alice Cooper", "mallorca", "transfusions", "Bengal tiger", "1.5 times the Schwarzschild radius", "Max", "television", "1999", "Sela Ann Ward", "The Cycle of Life", "forgery and flying without a valid license", "137", "a log cabin", "St. Patrick's Day", "blitz", "Sondheim"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5230406746031746}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, true, false, true, false, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.5, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-661", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-7408", "mrqa_triviaqa-validation-7495", "mrqa_triviaqa-validation-6923", "mrqa_triviaqa-validation-2221", "mrqa_triviaqa-validation-6876", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-4859", "mrqa_triviaqa-validation-2142", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-5688", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-7573", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2738", "mrqa_triviaqa-validation-510", "mrqa_triviaqa-validation-4297", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-4437", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-2711", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-5435", "mrqa_hotpotqa-validation-3492", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2100", "mrqa_searchqa-validation-7546", "mrqa_naturalquestions-validation-9755"], "SR": 0.4375, "CSR": 0.528125, "EFR": 1.0, "Overall": 0.7640625}, {"timecode": 40, "before_eval_results": {"predictions": ["19th Century", "Famous Players-Lasky Corporation", "norway", "Thomas De Quincey", "pestilential fever", "horse", "buffalo", "cuculidae", "devon", "Sarajevo", "the Bill of Rights", "end", "Neighbours", "bligh", "trumpet", "Westminster Abbey", "origami", "resistance", "Arabian Gulf", "secretary", "jane humbert", "suicide", "jack Nicholson", "cuculidae", "humbert humbert", "Tomorrow Never Dies", "indian", "a Great Dane", "norway", "indianapolis", "New Hampshire", "jimmy i", "jimmy humbert", "jimmy humbert", "purple rain", "My Sweet Lord", "cuculidae", "humbert humbert", "rome", "10", "Southwest Airlines", "humbert humbert", "jimmy douaver", "The Comedy of Errors", "charlie humbert", "Alex Turner", "humbert humbert", "cuculidae", "norway", "al-Qaeda", "The Armoury", "Humpty Dumpty", "1998", "Vijay Prakash", "ENnie Award", "the 100th anniversary of the first \"Tour de France\"", "Mach number (M or Ma)", "Janet", "more than 2.5 million", "neuroscience", "the Matrix", "cuculidae", "nibelung", "Inequality of opportunity was higher"], "metric_results": {"EM": 0.3125, "QA-F1": 0.3848958333333333}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, false, false, false, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.25, 0.0, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999]}}, "before_error_ids": ["mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-2275", "mrqa_triviaqa-validation-4512", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-496", "mrqa_triviaqa-validation-2862", "mrqa_triviaqa-validation-1411", "mrqa_triviaqa-validation-3539", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-4716", "mrqa_triviaqa-validation-1766", "mrqa_triviaqa-validation-1404", "mrqa_triviaqa-validation-3739", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-5262", "mrqa_triviaqa-validation-6355", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-863", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-4337", "mrqa_triviaqa-validation-4593", "mrqa_triviaqa-validation-129", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-4662", "mrqa_triviaqa-validation-2307", "mrqa_triviaqa-validation-4928", "mrqa_naturalquestions-validation-7516", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-4271", "mrqa_hotpotqa-validation-4102", "mrqa_newsqa-validation-2969", "mrqa_newsqa-validation-864", "mrqa_newsqa-validation-2372", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-15441", "mrqa_searchqa-validation-11519", "mrqa_naturalquestions-validation-3969"], "SR": 0.3125, "CSR": 0.5228658536585367, "EFR": 1.0, "Overall": 0.7614329268292683}, {"timecode": 41, "before_eval_results": {"predictions": ["1220", "philippines", "moon", "nippon Sangyo", "the Argonauts", "roddy douglas", "abacus", "Robin Hood", "sisyphus", "philazquez", "South Africa", "london", "philippines", "tchaikovsky", "henry vii", "angola", "not private Eye", "david Bowie", "Neil Armstrong", "Jean-Paul Sartre", "james", "Dick Turpin", "rust", "chicago", "pembroke", "tbilisi", "mel Gibson", "othello", "nine", "glenn close", "Lacock Abbey", "Alan B'Stard", "domestic cat", "Anita Brookner", "james", "Golda Meir", "Black Sea", "bagram Theater Internment Facility", "miss dent", "a power outage", "city of Vienna", "The Archers", "lincoln", "james sousa", "city of chicago", "james boyd", "bonanarama", "The Four Marx Brothers", "avon", "us", "Dry Ice", "Pat McCormick", "19 June 2018", "2001", "from 1993 to 1996", "Michael Rispoli", "September 29, 2017", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26", "June 6, 1944", "sniff out cell phones.", "bassoon", "o.K. Corral", "pumpkin", "phoenicia"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5701388888888889}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, false, false, true, false, false, true, false, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, true, false, false, false, true, true, true, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.5, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1364", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-5582", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6407", "mrqa_triviaqa-validation-6854", "mrqa_triviaqa-validation-1815", "mrqa_triviaqa-validation-4865", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-3306", "mrqa_triviaqa-validation-2352", "mrqa_triviaqa-validation-5773", "mrqa_triviaqa-validation-6097", "mrqa_triviaqa-validation-3527", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-3648", "mrqa_triviaqa-validation-2641", "mrqa_triviaqa-validation-7225", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-3866", "mrqa_newsqa-validation-1194", "mrqa_searchqa-validation-9161", "mrqa_searchqa-validation-233"], "SR": 0.484375, "CSR": 0.5219494047619048, "EFR": 1.0, "Overall": 0.7609747023809523}, {"timecode": 42, "before_eval_results": {"predictions": ["lack of reliable statistics from this period", "a shortfall in their pension fund", "eintracht Frankfurt", "Comoros Islands off Africa", "\"revolution of values\"", "Jeddah, Saudi Arabia", "40", "his chest", "\"Big change is hard,\"", "Manny Pacquiao", "$250,000", "Wednesday,", "British Prime Minister Gordon Brown", "executive director of the Americas Division of Human Rights Watch", "a facility in Salt Lake City, Utah", "dancy-Power Automotive Group", "the federal chamber of deputies", "64", "life in prison.", "fastest", "Department of Homeland Security Secretary Janet Napolitano", "iran's parliament speaker", "won the league title with River Plate in 1991 and the European Cup Winners Cup with Spanish side Real Zaragoza in 1995", "\"E! News\"", "South Florida", "Madeleine K. Albright", "a residential dike", "toxic smoke from burn pits in Iraq", "benazir Bhutto", "July as part of the State Department's Foreign Relations of the United States series.", "U.S. senators", "South Africa", "Larry Ellison", "farmer Alan Graham", "her fianc\u00e9,", "cal Ripken Jr.", "a relative's house,", "cancer", "acid attack", "Vernon Forrest", "urged NATO to take a more active role in countering the spread of the", "one", "comfort those in mourning, to offer healing and \"the blessing of your voice, your chaste touch.\"", "byproducts emitted during the process of burning and melting raw materials", "about 5:20 p.m. at Terminal C", "Herman Thomas", "\"A salute to the martyrs of the massacre, and our condolences to their families.\"", "a man's lifeless, naked body", "\"release\" civilians,", "Dodi Fayed", "we can use solar and renewable energy at home everyday.", "when a population temporarily exceeds the long term carrying capacity of its environment", "Real Madrid", "emperor Cuauhtemoc", "spain", "Misery", "lord Hemingway", "Italo Balbo", "Thorgan Ganael Francis Hazard", "River Clyde", "spain", "lord of the Apes", "Cy Young", "Reese Witherspoon"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5877279892987131}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.8000000000000002, 1.0, 0.923076923076923, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 0.16000000000000003, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.14285714285714285, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4210526315789474, 0.28571428571428575, 0.0, 0.8, 0.05714285714285715, 1.0, 1.0, 0.3636363636363636, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-2202", "mrqa_newsqa-validation-2558", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1962", "mrqa_newsqa-validation-3779", "mrqa_newsqa-validation-906", "mrqa_newsqa-validation-2533", "mrqa_newsqa-validation-2479", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-3047", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-2874", "mrqa_newsqa-validation-588", "mrqa_newsqa-validation-3089", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3594", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-2959", "mrqa_newsqa-validation-3979", "mrqa_triviaqa-validation-5930", "mrqa_triviaqa-validation-4313", "mrqa_hotpotqa-validation-5687", "mrqa_searchqa-validation-6881", "mrqa_searchqa-validation-5649"], "SR": 0.484375, "CSR": 0.5210755813953488, "EFR": 0.9696969696969697, "Overall": 0.7453862755461593}, {"timecode": 43, "before_eval_results": {"predictions": ["tenth-largest", "Borromeo", "Washington, D.C.,", "1943", "Volvo 850", "Mountain West Conference", "Dominique Wilkins", "Western Europe", "video games", "Continental AG", "English football", "1989 until 1994", "the Distinguished Service Cross,", "\"50 best cities to live in.\"", "Bridgetown,", "Lollywood and Pollywood", "Emmanuel Ofosu Yeboah", "Ant-Man", "Bhushan Patel", "1986", "1916", "Reginald Engelbach", "Vince Staples", "Archbishop of Canterbury", "Galway", "ZZ Top, Lynyrd Skynyrd, Cinderella, Queensr\u00ffche, Heart, Ted Nugent, Charley Pride, and Ricky Skaggs", "2008\u201309", "coaxial", "Philip Pullman's Trilogy \"His Dark Materials\"", "three different covers", "Malayalam cinema", "held in Kingdom of Dalmatia", "August 11, 1946", "Vincent Landay", "May 26, 2010", "Basauri, Biscay, in the autonomous community of Basque Country", "Brian A. Miller", "Christian Duguay", "1985", "Wonder Woman", "Meghan Markle", "a Boeing B-17 Flying Fortress", "Erika Girardi", "Joe Scarborough", "Crimean", "76,416", "Bonkyll Castle", "second cousin once removed", "the International Olympic Committee (IOC)", "Sony Computer Entertainment", "Brig Gen Augustine Warner Robins", "United Nations", "Lewis Carroll", "two", "by Ratcliff & Gretton Limited", "blue", "elbow", "Citizens of the lower house of parliament,", "the Employee Free Choice act", "the release of the four men", "a rake", "jack the Ripper", "a carriage", "teak"], "metric_results": {"EM": 0.53125, "QA-F1": 0.62395294168392}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, false, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true], "QA-F1": [0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.888888888888889, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 0.08695652173913042, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7278", "mrqa_hotpotqa-validation-3693", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-4767", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-2081", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4027", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-771", "mrqa_hotpotqa-validation-190", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-145", "mrqa_hotpotqa-validation-380", "mrqa_hotpotqa-validation-1464", "mrqa_hotpotqa-validation-1334", "mrqa_hotpotqa-validation-1776", "mrqa_naturalquestions-validation-4007", "mrqa_triviaqa-validation-2264", "mrqa_newsqa-validation-2070"], "SR": 0.53125, "CSR": 0.5213068181818181, "EFR": 1.0, "Overall": 0.7606534090909091}, {"timecode": 44, "before_eval_results": {"predictions": ["British Prime Minister Edward Heath", "former White Zombie bassist Sean Yseult", "Washington, D.C.", "5.3 million", "sexy Star", "Conservatorio Verdi in Milan", "President of the United States", "\"the backside.\"", "\"the Gentle Don\"", "\"The Future\"", "the Knight Company", "Andrew Joseph", "Denmark", "2015 Orange Bowl", "Margarine Unie", "death sentence", "Fort Valley, Georgia", "Bill Paxton", "Vladimir Valentinovich Menshov", "Kramer", "the Dominican Republic", "Humberside Airport", "June 12, 2017", "Douglas Jackson", "wooden roller", "Blackpool Football Club", "William Lyon Mackenzie King", "\"Ted\"", "The Creator", "Fiat Chrysler Automobile N.V.", "Bruce Grobbelaar", "Honda Ballade", "Ascona", "Boston Celtics", "Austrian", "Australian Electoral Division", "Socrates", "Caesars Entertainment Corporation", "Hindi", "Richard Masur", "\"Irish Chekhov\"", "Bad Religion", "\"Dr. Gr\u00e4sler, Badearzt\"", "Alexandre Dimitri Song Billong", "The Arizona Health Care Cost Containment System", "Mineola", "Gian Carlo Menotti", "bobsledder", "Mazda", "102,984", "Roscoe Lee Browne", "1972", "James P. `` Sulley '' Sullivan", "216", "The Spectator", "Easter Parade", "Elgar\u2019s", "last summer.", "almost 100", "into the Southeast,", "the jeffersons tv show", "Great Balls of Fire", "primary figure in Okeh Records' \"race series,\"", "One Direction"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6560639880952381}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, true, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, false, true, false, true, false, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, true, false, true], "QA-F1": [1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.33333333333333337, 0.3333333333333333, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.75, 1.0, 1.0, 0.4, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-125", "mrqa_hotpotqa-validation-5312", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-4645", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4354", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-2915", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-1409", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-830", "mrqa_hotpotqa-validation-4127", "mrqa_hotpotqa-validation-4873", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-3087", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-10536", "mrqa_naturalquestions-validation-10118", "mrqa_triviaqa-validation-4729", "mrqa_newsqa-validation-2080", "mrqa_newsqa-validation-1078", "mrqa_searchqa-validation-15766", "mrqa_searchqa-validation-12050"], "SR": 0.53125, "CSR": 0.5215277777777778, "EFR": 1.0, "Overall": 0.7607638888888889}, {"timecode": 45, "before_eval_results": {"predictions": ["the American Revolution", "quod erat demonstrandum", "gold", "Part Gaul is divided into three parts,", "Northern Exposure", "cocoa butter", "\"Don't Worry, Be Happy\"", "Esther", "Warren Harding", "Monty Hall", "mini-golf", "The Situation Room", "February 2, 1886", "pratislava", "yellow fever", "otters", "MMs", "\"submarine\" or \"sub\"", "rod", "Nixon", "dressage", "astronomers", "Mickey Mouse", "the stigma", "Associate Professor", "a \"piece of real fruit\"", "Medusa", "a staircase", "tabby", "the staff", "Voyager 1", "Farsi (Persian)", "glucose", "objects", "China", "Helen of Troy", "Vegetarianism", "peace sign", "An Old Man, a Young Man", "English Monarchs", "Rajasthan", "\"retired\" safecracker Gal", "Observatory.", "NFL", "a \"road above\"", "White bread and butter", "Part of office of, say, one-third of its members expires", "Wordsworth", "brushes", "a \"dwarf planet\"", "Arabian Nights", "Vincent Price", "Rugrats in Paris : The Movie", "Middle Eastern alchemy", "London", "Isle of Wight", "The Peppercorn Pioneer", "\"Queen In-hyun's Man\"", "Oneida Limited", "Daniel Richard \" Danny\" Green, Jr.", "Libreville,", "tickets", "Brett Cummins,", "Cahaba"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5348958333333333}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, true, false, false, false, false, true, false, true, false, true, false, true, false, true, true, false, false, true, false, true, true, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-6832", "mrqa_searchqa-validation-13022", "mrqa_searchqa-validation-8749", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-4671", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-3074", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-8467", "mrqa_searchqa-validation-2190", "mrqa_searchqa-validation-975", "mrqa_searchqa-validation-14312", "mrqa_searchqa-validation-11749", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-5006", "mrqa_searchqa-validation-11964", "mrqa_searchqa-validation-7833", "mrqa_searchqa-validation-362", "mrqa_searchqa-validation-3686", "mrqa_searchqa-validation-3322", "mrqa_triviaqa-validation-6557", "mrqa_hotpotqa-validation-2807", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3949", "mrqa_triviaqa-validation-888"], "SR": 0.484375, "CSR": 0.5207201086956521, "EFR": 1.0, "Overall": 0.760360054347826}, {"timecode": 46, "before_eval_results": {"predictions": ["the position of people within the four-class system was not an indication of their actual social power and wealth", "Jorge Lorenzo", "Frank McCourt", "Indiana Jones", "fungi", "Venus flytrap", "Abraham", "room the book store", "Faggot", "the grey geese", "a filly/mare", "Pluto", "Route 66", "the Taklamakan Desert", "the Arabian Sea", "Astronaut Lifevest Morph", "desert", "German state of North Rhine-Westphalia", "the British pop band Go West", "December 18, 1958", "Benjamin Franklin", "Portugal", "Operation Overlord", "Birmingham", "snakes", "Sedgefield", "Coral Sea", "Saddam Hussein", "Nadia Comaneci", "tank", "South Korea", "pigs", "X-Men Origins: Wolverine", "Carmen", "Kenya", "Stephen Potter", "Verona", "Anwar Sadat", "3", "the Potomac River", "the Republic of Costa Rica", "the antagonist", "Frankfurt", "Mickey", "Goldie Hawn", "pulsar", "Belgium", "shows the feelings and hardships of not just horses from long ago, but even horses now.", "honey", "Chelsea", "Sun Lust Pictures", "Games played", "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "somatic cell nuclear transfer", "early 7th century", "1 January 1788", "Radcliffe College", "11 healthy eggs", "\"Twilight\"", "the museum itself.", "Speed Racer", "H.G. Wells", "Queen Elizabeth", "Sir Walter Scott"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6554197994987468}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true], "QA-F1": [0.10526315789473684, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.7368421052631579, 1.0, 1.0, 0.8, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8093", "mrqa_triviaqa-validation-3691", "mrqa_triviaqa-validation-1409", "mrqa_triviaqa-validation-1003", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-3440", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7328", "mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-3072", "mrqa_triviaqa-validation-2179", "mrqa_triviaqa-validation-6054", "mrqa_triviaqa-validation-3474", "mrqa_triviaqa-validation-3553", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-4014", "mrqa_triviaqa-validation-1106", "mrqa_triviaqa-validation-1622", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-7773", "mrqa_naturalquestions-validation-5241", "mrqa_hotpotqa-validation-3234", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-2953", "mrqa_searchqa-validation-4652"], "SR": 0.578125, "CSR": 0.5219414893617021, "EFR": 1.0, "Overall": 0.7609707446808511}, {"timecode": 47, "before_eval_results": {"predictions": ["Arabah", "Palazzo delle Prigioni", "Sinclair Lewis", "the bear", "The World is Not Enough", "a binder", "Jonathan Demme", "Vaclav Havel", "Dick Van Dyke", "millais", "Tina Turner", "1789", "baseraine", "a lens", "perfumer", "duke orsino", "iron", "germany", "The Apprentice", "a reference mark", "Cubism for Kids", "sahara desert", "a \"Commonwealth Institute of Science and Industry\"", "eukharistos", "\"Miracles Do Happen\"", "zenyatta", "silks", "William Randolph Hearst", "Lorne Greene", "rowing", "andes", "call My Bluff", "a", "andes", "Frank McCourt", "toadstool", "Caroline Aherne", "Home Guard", "sahara", "soap", "Donna Summer", "a pole", "nottingham", "Poland", "the Welcome Stranger", "taggart", "April", "Chechnya", "a police janitor", "the A- Team", "football", "801,200", "CV Raman", "Sun Tzu", "bioelectromagnetics", "Foxborough", "Speedway World Championship", "a city of romance, of incredible architecture and history.", "people", "Michelle Obama", "kbenhavn", "the Proletariat", "sahara", "fluoroquinolone"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5236742424242424}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.5, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-5858", "mrqa_triviaqa-validation-92", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-2213", "mrqa_triviaqa-validation-1599", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-5096", "mrqa_triviaqa-validation-3052", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6002", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-7189", "mrqa_triviaqa-validation-6039", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-703", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6892", "mrqa_triviaqa-validation-1730", "mrqa_naturalquestions-validation-4953", "mrqa_naturalquestions-validation-5726", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-1851", "mrqa_newsqa-validation-2825", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-7020", "mrqa_searchqa-validation-15651", "mrqa_newsqa-validation-1804"], "SR": 0.484375, "CSR": 0.5211588541666667, "EFR": 1.0, "Overall": 0.7605794270833334}, {"timecode": 48, "before_eval_results": {"predictions": ["East Lothian", "Caesars Entertainment Corporation", "Supergirl", "\u00c6lfgifu", "\"Creature Comforts\"", "British Airways (BA)", "William McKinley", "1905", "Vanilla Air Inc.", "Mineola, New York", "dovzhenko", "Strange Interlude", "Julia Compton Moore", "Olivia Newton-John's", "1988", "early Romantic period", "The Gettysburg Address", "Harold Edward Holt", "Washington Street", "Mathew Sacks", "Babylon", "Ford Falcon", "Southern State Parkway", "The Company", "1827", "Kim Bauer", "United States Food and Drug Administration (FDA)", "Lieutenant Martin", "Bury St Edmunds, Suffolk, England", "Prussian", "O", "1909 Cuban-American Major League Clubs Series", "86 ft", "American", "January 2004", "sulfur mustard H or HD blister gas", "The 45th Infantry Division", "2009", "5 Grammy Award nominations", "Anita Dobson", "City of Westminster, London", "Boyd Gaming", "August 14, 1848", "Texas Tech University", "John McClane", "Larry Wayne Gatlin", "the 924", "Edward Michael \" Mike\"/\"Spanky\" Fincke", "North Carolina", "Selinsgrove,", "Augusta Ada King-Noel, Countess of Lovelace (\"n\u00e9e\" Byron; 10 December 1815 \u2013 27 November 1852)", "Harry Potter's first year at Hogwarts School of Witchcraft and Wizardry", "cake", "Salman Khan", "space shuttle", "basil", "Clio Awards", "The Rosie Show", "North Korea", "over 1,000 pounds", "Julius Caesar", "desert", "the Library of Congress", "the stroma"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6574485636645963}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, false], "QA-F1": [0.22222222222222224, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8695652173913043, 0.19999999999999998, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3203", "mrqa_hotpotqa-validation-3844", "mrqa_hotpotqa-validation-3680", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-3232", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2108", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-1115", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4676", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-5714", "mrqa_hotpotqa-validation-3737", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-6806", "mrqa_triviaqa-validation-6785", "mrqa_newsqa-validation-2595", "mrqa_newsqa-validation-1762", "mrqa_searchqa-validation-14129", "mrqa_searchqa-validation-1028", "mrqa_naturalquestions-validation-4685"], "SR": 0.59375, "CSR": 0.5226403061224489, "EFR": 0.9615384615384616, "Overall": 0.7420893838304552}, {"timecode": 49, "before_eval_results": {"predictions": ["a small, hard, leather-cased ball with a rounded end wooden, plastic or metal bat", "Jena Malone", "Washington, D.C.", "joined the utopian Ascona community", "John William Henry II", "Mos Def", "James Mitchum", "4 April 1963", "1995", "Tom Shadyac", "Wendell Berry", "Love Hina", "eastern", "novelty songs, comedy, and strange or unusual recordings", "OutKast", "five", "Alain Robbe-Grillet", "the Seasiders", "Musicology", "Dragon TV", "the Appalachian Mountains", "Bay Ridge, Brooklyn", "Jean- Marc Vall\u00e9e", "over 1.6 million", "1968", "November 20, 1942", "September 26, 2010", "North Greenwich Arena", "1614", "Lucy Maud Montgomery", "Royce da 5'9\" (Bad) and Eminem", "nausea, vomiting, diarrhea, jaundice, fever, and abdominal pain", "Saint Michael, Barbados", "Sleepy Hollow", "more than 26,000", "EN World web site", "Charles Russell", "KB", "Robert Jenrick", "Golden Globe Award", "The Molly Brown Summer House", "Port Clinton", "Art of Dying", "Dallas", "Harvard", "fennec", "the Netherlands", "Terry Malloy", "Golden Calf for Best Actor in 2013", "Kal Ho Naa Ho", "Thorgan Ganael Francis Hazard", "the closing scene of the final episode of the first season", "Everywhere", "JNCASR", "honda", "J. M. W. Turner", "the Republic of Upper Volta", "56", "Nkepile Mabuse", "Eintracht Frankfurt", "the fortress", "Hephaestus", "Amherst College", "two courses"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7455783799533799}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.26666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2683", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5091", "mrqa_hotpotqa-validation-5792", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-162", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-1526", "mrqa_hotpotqa-validation-2328", "mrqa_hotpotqa-validation-335", "mrqa_hotpotqa-validation-3589", "mrqa_hotpotqa-validation-5500", "mrqa_hotpotqa-validation-4321", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2701", "mrqa_hotpotqa-validation-3430", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6410", "mrqa_newsqa-validation-616", "mrqa_searchqa-validation-9636", "mrqa_searchqa-validation-14102", "mrqa_newsqa-validation-492"], "SR": 0.640625, "CSR": 0.525, "EFR": 1.0, "Overall": 0.7625}, {"timecode": 50, "UKR": 0.71484375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1029", "mrqa_hotpotqa-validation-1053", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1137", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-132", "mrqa_hotpotqa-validation-137", "mrqa_hotpotqa-validation-1441", "mrqa_hotpotqa-validation-1463", "mrqa_hotpotqa-validation-1528", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1667", "mrqa_hotpotqa-validation-1706", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1807", "mrqa_hotpotqa-validation-1872", "mrqa_hotpotqa-validation-1888", "mrqa_hotpotqa-validation-1896", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2083", "mrqa_hotpotqa-validation-2130", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-2456", "mrqa_hotpotqa-validation-2508", "mrqa_hotpotqa-validation-2554", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-274", "mrqa_hotpotqa-validation-2741", "mrqa_hotpotqa-validation-2782", "mrqa_hotpotqa-validation-2960", "mrqa_hotpotqa-validation-3016", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-3067", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3122", "mrqa_hotpotqa-validation-3138", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3372", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-3630", "mrqa_hotpotqa-validation-3737", "mrqa_hotpotqa-validation-395", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4095", "mrqa_hotpotqa-validation-4147", "mrqa_hotpotqa-validation-4283", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-4330", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4566", "mrqa_hotpotqa-validation-4581", "mrqa_hotpotqa-validation-4588", "mrqa_hotpotqa-validation-4589", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4619", "mrqa_hotpotqa-validation-4622", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4662", "mrqa_hotpotqa-validation-4668", "mrqa_hotpotqa-validation-4673", "mrqa_hotpotqa-validation-4693", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4803", "mrqa_hotpotqa-validation-4827", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4859", "mrqa_hotpotqa-validation-4897", "mrqa_hotpotqa-validation-4971", "mrqa_hotpotqa-validation-5004", "mrqa_hotpotqa-validation-5012", "mrqa_hotpotqa-validation-5085", "mrqa_hotpotqa-validation-5123", "mrqa_hotpotqa-validation-5139", "mrqa_hotpotqa-validation-5167", "mrqa_hotpotqa-validation-5180", "mrqa_hotpotqa-validation-5192", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5289", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-5361", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5583", "mrqa_hotpotqa-validation-564", "mrqa_hotpotqa-validation-5650", "mrqa_hotpotqa-validation-5660", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-5733", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-5772", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5858", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-682", "mrqa_hotpotqa-validation-684", "mrqa_hotpotqa-validation-687", "mrqa_hotpotqa-validation-697", "mrqa_hotpotqa-validation-756", "mrqa_hotpotqa-validation-826", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-874", "mrqa_hotpotqa-validation-897", "mrqa_hotpotqa-validation-96", "mrqa_hotpotqa-validation-978", "mrqa_hotpotqa-validation-990", "mrqa_naturalquestions-validation-10194", "mrqa_naturalquestions-validation-10614", "mrqa_naturalquestions-validation-1089", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1525", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-1818", "mrqa_naturalquestions-validation-1823", "mrqa_naturalquestions-validation-1887", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-2069", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-2245", "mrqa_naturalquestions-validation-2282", "mrqa_naturalquestions-validation-239", "mrqa_naturalquestions-validation-2653", "mrqa_naturalquestions-validation-2949", "mrqa_naturalquestions-validation-3010", "mrqa_naturalquestions-validation-3522", "mrqa_naturalquestions-validation-3568", "mrqa_naturalquestions-validation-3639", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-3899", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4423", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-4685", "mrqa_naturalquestions-validation-4794", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5188", "mrqa_naturalquestions-validation-5464", "mrqa_naturalquestions-validation-5585", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-590", "mrqa_naturalquestions-validation-5925", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-6035", "mrqa_naturalquestions-validation-6240", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-655", "mrqa_naturalquestions-validation-6771", "mrqa_naturalquestions-validation-6883", "mrqa_naturalquestions-validation-6926", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7172", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-7496", "mrqa_naturalquestions-validation-7517", "mrqa_naturalquestions-validation-7535", "mrqa_naturalquestions-validation-800", "mrqa_naturalquestions-validation-8238", "mrqa_naturalquestions-validation-8248", "mrqa_naturalquestions-validation-8412", "mrqa_naturalquestions-validation-8563", "mrqa_naturalquestions-validation-868", "mrqa_naturalquestions-validation-8753", "mrqa_naturalquestions-validation-8899", "mrqa_naturalquestions-validation-9004", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-9666", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9755", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-996", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-136", "mrqa_newsqa-validation-1423", "mrqa_newsqa-validation-1484", "mrqa_newsqa-validation-1486", "mrqa_newsqa-validation-1553", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-1608", "mrqa_newsqa-validation-1719", "mrqa_newsqa-validation-1809", "mrqa_newsqa-validation-1840", "mrqa_newsqa-validation-1853", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1991", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-202", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-2243", "mrqa_newsqa-validation-2253", "mrqa_newsqa-validation-2372", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2462", "mrqa_newsqa-validation-2601", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2722", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-2937", "mrqa_newsqa-validation-3054", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-3113", "mrqa_newsqa-validation-3151", "mrqa_newsqa-validation-3167", "mrqa_newsqa-validation-3245", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3402", "mrqa_newsqa-validation-3459", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-353", "mrqa_newsqa-validation-3560", "mrqa_newsqa-validation-3569", "mrqa_newsqa-validation-3637", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-3697", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3920", "mrqa_newsqa-validation-3934", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-4112", "mrqa_newsqa-validation-4143", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-486", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-549", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-62", "mrqa_newsqa-validation-663", "mrqa_newsqa-validation-72", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-736", "mrqa_newsqa-validation-759", "mrqa_newsqa-validation-779", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10480", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-10968", "mrqa_searchqa-validation-11178", "mrqa_searchqa-validation-11928", "mrqa_searchqa-validation-11990", "mrqa_searchqa-validation-12184", "mrqa_searchqa-validation-12651", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-13669", "mrqa_searchqa-validation-1374", "mrqa_searchqa-validation-13836", "mrqa_searchqa-validation-14284", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-15433", "mrqa_searchqa-validation-15510", "mrqa_searchqa-validation-15641", "mrqa_searchqa-validation-15976", "mrqa_searchqa-validation-16060", "mrqa_searchqa-validation-16122", "mrqa_searchqa-validation-1617", "mrqa_searchqa-validation-165", "mrqa_searchqa-validation-16539", "mrqa_searchqa-validation-16614", "mrqa_searchqa-validation-1801", "mrqa_searchqa-validation-1954", "mrqa_searchqa-validation-2083", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-4683", "mrqa_searchqa-validation-4937", "mrqa_searchqa-validation-5213", "mrqa_searchqa-validation-5568", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-6074", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6398", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-7084", "mrqa_searchqa-validation-7106", "mrqa_searchqa-validation-7134", "mrqa_searchqa-validation-7546", "mrqa_searchqa-validation-7633", "mrqa_searchqa-validation-8206", "mrqa_searchqa-validation-8410", "mrqa_searchqa-validation-8433", "mrqa_searchqa-validation-8608", "mrqa_searchqa-validation-9141", "mrqa_searchqa-validation-9299", "mrqa_searchqa-validation-9338", "mrqa_searchqa-validation-975", "mrqa_squad-validation-10069", "mrqa_squad-validation-10086", "mrqa_squad-validation-1019", "mrqa_squad-validation-10310", "mrqa_squad-validation-1036", "mrqa_squad-validation-10397", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1052", "mrqa_squad-validation-1129", "mrqa_squad-validation-1211", "mrqa_squad-validation-1265", "mrqa_squad-validation-1311", "mrqa_squad-validation-139", "mrqa_squad-validation-164", "mrqa_squad-validation-1672", "mrqa_squad-validation-1712", "mrqa_squad-validation-1916", "mrqa_squad-validation-2132", "mrqa_squad-validation-2155", "mrqa_squad-validation-2176", "mrqa_squad-validation-2326", "mrqa_squad-validation-2436", "mrqa_squad-validation-2467", "mrqa_squad-validation-264", "mrqa_squad-validation-2798", "mrqa_squad-validation-2824", "mrqa_squad-validation-283", "mrqa_squad-validation-2848", "mrqa_squad-validation-2906", "mrqa_squad-validation-2914", "mrqa_squad-validation-294", "mrqa_squad-validation-305", "mrqa_squad-validation-3337", "mrqa_squad-validation-3650", "mrqa_squad-validation-3742", "mrqa_squad-validation-3948", "mrqa_squad-validation-4025", "mrqa_squad-validation-4066", "mrqa_squad-validation-4135", "mrqa_squad-validation-4258", "mrqa_squad-validation-4338", "mrqa_squad-validation-4349", "mrqa_squad-validation-44", "mrqa_squad-validation-4472", "mrqa_squad-validation-4480", "mrqa_squad-validation-4605", "mrqa_squad-validation-4607", "mrqa_squad-validation-4686", "mrqa_squad-validation-4835", "mrqa_squad-validation-487", "mrqa_squad-validation-4897", "mrqa_squad-validation-4947", "mrqa_squad-validation-5088", "mrqa_squad-validation-5136", "mrqa_squad-validation-5238", "mrqa_squad-validation-5330", "mrqa_squad-validation-5672", "mrqa_squad-validation-594", "mrqa_squad-validation-6362", "mrqa_squad-validation-6562", "mrqa_squad-validation-6737", "mrqa_squad-validation-6737", "mrqa_squad-validation-6811", "mrqa_squad-validation-6918", "mrqa_squad-validation-696", "mrqa_squad-validation-703", "mrqa_squad-validation-7173", "mrqa_squad-validation-7435", "mrqa_squad-validation-754", "mrqa_squad-validation-7576", "mrqa_squad-validation-7598", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8285", "mrqa_squad-validation-8402", "mrqa_squad-validation-8406", "mrqa_squad-validation-8483", "mrqa_squad-validation-8607", "mrqa_squad-validation-8636", "mrqa_squad-validation-8715", "mrqa_squad-validation-8747", "mrqa_squad-validation-8760", "mrqa_squad-validation-879", "mrqa_squad-validation-8846", "mrqa_squad-validation-9015", "mrqa_squad-validation-9329", "mrqa_squad-validation-933", "mrqa_squad-validation-9368", "mrqa_squad-validation-9541", "mrqa_squad-validation-9691", "mrqa_squad-validation-9757", "mrqa_triviaqa-validation-1094", "mrqa_triviaqa-validation-1165", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1319", "mrqa_triviaqa-validation-133", "mrqa_triviaqa-validation-1553", "mrqa_triviaqa-validation-1621", "mrqa_triviaqa-validation-1626", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1913", "mrqa_triviaqa-validation-2068", "mrqa_triviaqa-validation-2201", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-236", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2481", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2613", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2915", "mrqa_triviaqa-validation-2970", "mrqa_triviaqa-validation-2994", "mrqa_triviaqa-validation-303", "mrqa_triviaqa-validation-306", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-3120", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3350", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-353", "mrqa_triviaqa-validation-3531", "mrqa_triviaqa-validation-3551", "mrqa_triviaqa-validation-3636", "mrqa_triviaqa-validation-3692", "mrqa_triviaqa-validation-3740", "mrqa_triviaqa-validation-3778", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3886", "mrqa_triviaqa-validation-3911", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-4103", "mrqa_triviaqa-validation-414", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-453", "mrqa_triviaqa-validation-4752", "mrqa_triviaqa-validation-4754", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-4798", "mrqa_triviaqa-validation-4828", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-4920", "mrqa_triviaqa-validation-5118", "mrqa_triviaqa-validation-5133", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-5316", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5413", "mrqa_triviaqa-validation-5505", "mrqa_triviaqa-validation-5607", "mrqa_triviaqa-validation-5636", "mrqa_triviaqa-validation-564", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5794", "mrqa_triviaqa-validation-5846", "mrqa_triviaqa-validation-594", "mrqa_triviaqa-validation-5944", "mrqa_triviaqa-validation-6036", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6262", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-6385", "mrqa_triviaqa-validation-6422", "mrqa_triviaqa-validation-6431", "mrqa_triviaqa-validation-6432", "mrqa_triviaqa-validation-6557", "mrqa_triviaqa-validation-6558", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-6718", "mrqa_triviaqa-validation-6807", "mrqa_triviaqa-validation-6890", "mrqa_triviaqa-validation-696", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-702", "mrqa_triviaqa-validation-7122", "mrqa_triviaqa-validation-7173", "mrqa_triviaqa-validation-7181", "mrqa_triviaqa-validation-7270", "mrqa_triviaqa-validation-731", "mrqa_triviaqa-validation-7444", "mrqa_triviaqa-validation-7643", "mrqa_triviaqa-validation-7779", "mrqa_triviaqa-validation-890"], "OKR": 0.818359375, "KG": 0.46171875, "before_eval_results": {"predictions": ["Disha Patani", "\u00c6thelthryth", "Fife", "26,000", "Spain, Mexico and France", "1981", "\"D&D\"", "February 26, 1948", "is considered the father of modern flight training", "Amway", "1945", "1754", "the demarcation line between the newly emerging states, the Second Polish Republic, and the Soviet Union", "Epic Records", "IFFHS World's Best Goalkeeper", "shortest player ever to play in the National Basketball Association", "Maud of Gloucester", "\"personal earnings\" (such as salary and wages), \"business income\" and \"capital gains\"", "May 5 to July 8, 2014", "June 11, 1973", "twenty-three", "Niger\u2013Congo", "Duncan Kenworthy", "June 4, 1931", "northern", "Picric acid", "Las Vegas", "ESPN's \" SportsCenter\"", "her debut cookbook, \"Mastering the Art of French Cooking\"", "fantasy role-playing", "feats of exploration", "Columbia Records", "Bergen County", "Matthieu Vaxivi\u00e8re", "F.C. Kossou Bib\u00f3", "1994", "the superhero Birdman", "Harrison County", "New York Yankees", "1903", "King Kal\u0101kaua", "Mark Brandon \"Chopper\" Read", "e sublime darkwave", "IATA: VNO, ICAO: EYVI", "The virus is zoonotic,", "122,067", "the High Court of Admiralty", "Mercer University", "Katherine Murray Millett", "Kohlberg K Travis Roberts", "Robbie Gould", "21 December 2017", "1800", "the Behavioral Analysis Unit", "syrupy", "an umbrella", "fat and blood", "is the most high-profile amalgamation of Indian and western talent yet,", "1.2 million people.", "84-year-old", "Genesis 45", "testimony of accomplices", "Matt Damon", "Mitch Murray"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5480492597680098}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, true, false, false, false, false, false, false, true, false, false, true, false, false, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.2222222222222222, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.25, 0.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.4, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.30769230769230765, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-532", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-4018", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1822", "mrqa_hotpotqa-validation-1274", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-3065", "mrqa_hotpotqa-validation-2721", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-4698", "mrqa_hotpotqa-validation-597", "mrqa_hotpotqa-validation-4696", "mrqa_hotpotqa-validation-3346", "mrqa_hotpotqa-validation-3039", "mrqa_hotpotqa-validation-876", "mrqa_hotpotqa-validation-5860", "mrqa_hotpotqa-validation-169", "mrqa_hotpotqa-validation-3891", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-4462", "mrqa_hotpotqa-validation-3975", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3123", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-1629", "mrqa_naturalquestions-validation-5647", "mrqa_naturalquestions-validation-4079", "mrqa_triviaqa-validation-2520", "mrqa_triviaqa-validation-1015", "mrqa_newsqa-validation-3013", "mrqa_newsqa-validation-3165", "mrqa_searchqa-validation-984", "mrqa_searchqa-validation-3770"], "SR": 0.40625, "CSR": 0.522671568627451, "EFR": 1.0, "Overall": 0.7035186887254902}, {"timecode": 51, "before_eval_results": {"predictions": ["Nassau County", "Prince Antoni Radziwi\u0142\u0142", "Buskerud", "Charles Perrault's", "Via Port Rotterdam", "First Balkan War", "Australia", "Daniel Espinosa", "1942", "water", "Bury St Edmunds, Suffolk, England", "1981", "What You Will", "Cartoon Network Too", "MG Car Company Limited", "Jack Elam", "Bill Paxton", "Fade Out: The Calamitous Final Days of MGM", "Argentinian", "General Edward Lawrence Logan International Airport", "Blackpool F.C.", "Marvel Comics", "100 million", "Joseph McCarthy", "the Volvo S60", "1978", "July 25 to August 4", "Ann", "'Tis the Fifteenth Season", "he flew solo to Scotland in an attempt to negotiate peace with the United Kingdom", "Oracle Corporation", "Pittsburgh", "John Andr\u00e9", "Nine-card Brag", "in 1942", "new buildings, structures, projects, or even designs", "Nikolai Morozov", "Aymara and Quechua speaking people of Bolivia", "Volksb\u00fchne", "two", "Outside", "Traumnovelle", "Chechen Republic", "Gwyneth Paltrow, Ewan McGregor, Olivia Munn, Paul Bettany and Jeff Goldblum", "1986 to 2013", "Andalusia", "Guangzhou, China", "British", "Jaguar Land Rover Limited", "Citgo Petroleum Corporation", "artist", "B.R. Ambedkar", "Presley Smith", "the hydrological cycle or the hydrologic cycle", "Mungo Park", "Joe Meek", "Melissa Duck", "Chembur,", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Tibetan capital of Lhasa.", "Popular Science", "a ton", "The Church of Jesus Christ of Latter-day Saints", "John and Elizabeth Calvert"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6198795995670996}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, false, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 1.0, 0.0, 0.0, 0.6666666666666666, 0.7499999999999999, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 0.1904761904761905, 1.0, 0.0, 1.0, 0.1818181818181818, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 0.0, 0.8571428571428571, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.25, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5464", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-5807", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-5889", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-2929", "mrqa_hotpotqa-validation-185", "mrqa_hotpotqa-validation-4206", "mrqa_hotpotqa-validation-1445", "mrqa_hotpotqa-validation-2663", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1169", "mrqa_hotpotqa-validation-3481", "mrqa_hotpotqa-validation-4234", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-3656", "mrqa_hotpotqa-validation-309", "mrqa_hotpotqa-validation-5692", "mrqa_hotpotqa-validation-5677", "mrqa_hotpotqa-validation-4721", "mrqa_hotpotqa-validation-4797", "mrqa_hotpotqa-validation-10", "mrqa_hotpotqa-validation-2447", "mrqa_hotpotqa-validation-5696", "mrqa_hotpotqa-validation-3348", "mrqa_hotpotqa-validation-5766", "mrqa_triviaqa-validation-5002", "mrqa_triviaqa-validation-7539", "mrqa_newsqa-validation-3518", "mrqa_newsqa-validation-481", "mrqa_searchqa-validation-11184", "mrqa_newsqa-validation-4208"], "SR": 0.46875, "CSR": 0.5216346153846154, "EFR": 1.0, "Overall": 0.7033112980769232}, {"timecode": 52, "before_eval_results": {"predictions": ["Neighbourhoods", "1928", "Physical", "the self-immolation of a 19-year-old student named Romas Kalanta", "128 pages", "novel", "the National Society of Daughters of the American Revolution", "Timmy Sanders", "Japan", "St Augustine's Abbey", "The Indianapolis Times", "Shusett", "Jay Hanna \"Dizzy\" Dean", "UHF channel 44", "North Kesteven,", "Spanish Empire", "The Beatles", "\"Menace II Society\"", "September 1901", "March 30, 2025", "Black nationalism", "Pinellas County", "Benjamin Burwell Johnston", "Imagine", "Easy", "CBS Corporation", "\"Brickyard\"", "2012", "Candice Swanepoel", "Benny Andersson", "Peter, Paul and Mary", "Kathleen O'Brien", "private equity, credit and hedge fund investment strategies", "the River North Esk in Midlothian, Scotland", "Paris", "Hard rock", "Yubin, Yeeun, Sunmi and Hyerim", "\"Complex\" magazine", "Muhammad Ali", "the University of Keele", "Operation Iceberg", "Telugu", "Ding Sheng", "Sissy Spacek", "\"The Omega Man\"", "David Dunn", "William Bradford", "FieldTurf", "My Beautiful Dark Twisted Fantasy", "Benj Pasek and Justin Paul", "a hand injury", "Freedom Day 27 April 2000", "U2", "The main pulmonary artery begins at the base of the right ventricle", "\u201cThe Pope? How many divisions does he have?", "France", "taekwondo", "The Tinkler.", "since 1983.", "the legitimacy of that race.", "the Dukes of Norfolk", "Italy", "chili pepper", "star"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6913837031024531}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false, true, true, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-5506", "mrqa_hotpotqa-validation-2358", "mrqa_hotpotqa-validation-4864", "mrqa_hotpotqa-validation-48", "mrqa_hotpotqa-validation-2209", "mrqa_hotpotqa-validation-4843", "mrqa_hotpotqa-validation-4307", "mrqa_hotpotqa-validation-1813", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-974", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-5131", "mrqa_hotpotqa-validation-563", "mrqa_hotpotqa-validation-1025", "mrqa_hotpotqa-validation-1540", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5683", "mrqa_hotpotqa-validation-3644", "mrqa_hotpotqa-validation-1058", "mrqa_naturalquestions-validation-9150", "mrqa_naturalquestions-validation-7953", "mrqa_naturalquestions-validation-5589", "mrqa_triviaqa-validation-4195", "mrqa_searchqa-validation-14326", "mrqa_searchqa-validation-5599", "mrqa_searchqa-validation-11081"], "SR": 0.546875, "CSR": 0.5221108490566038, "EFR": 1.0, "Overall": 0.7034065448113208}, {"timecode": 53, "before_eval_results": {"predictions": ["a moon", "Friedrich Nietzsche", "give up the ship", "Lord Carnarvon", "Ireland", "Glaciers", "bdellium", "Marie Antoinette", "Aunt Bee", "Great Smoky Mountains National Park", "the meadow", "Ohiopyle", "Nostradamus", "the malignant disease", "The Cannonball Run", "sugar cane", "Charles Howland Hammatt Billings", "The Crow", "the Marathon plain", "John Keats", "(Scott) Peterson", "a backpacking Route", "the Mayflower", "Bob Kerrey", "Curly Lambeau", "St. Erasmus", "Google", "Dostoevsky", "Mike Rowe", "Resident Evil", "a daughter", "Bastille Day", "the Trucial States", "Dramamine", "korbat", "Oktoberfest", "Dred Scott", "Josphine de Beauharnais", "President McKinley", "stAY TUNED", "Transformers", "a \" Crystal Light\"", "the American Civil War", "Trans Fatty Acids", "Oscar Wilde", "Christopher Columbus", "Doctor Dolittle", "William Randolph Hearst", "a skull", "Indira Gandhi", "a rotating radar dome", "the Director of National Intelligence", "a neurosurgical technique that joins two more vertebrae", "the next day", "Peter Paul Rubens", "weasel", "David Bowie", "1 December 1948", "Lester Ben \"Benny\" Binion", "three centuries", "forgery and flying without a valid license,", "Michoacan state,", "\"gotten the balance right\"", "Carpenter"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6829861111111111}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false, true, true, false, true, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.7777777777777778, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1145", "mrqa_searchqa-validation-12432", "mrqa_searchqa-validation-13330", "mrqa_searchqa-validation-14213", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-3470", "mrqa_searchqa-validation-13947", "mrqa_searchqa-validation-14941", "mrqa_searchqa-validation-15298", "mrqa_searchqa-validation-14236", "mrqa_searchqa-validation-4485", "mrqa_searchqa-validation-15504", "mrqa_searchqa-validation-10626", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-11962", "mrqa_searchqa-validation-14733", "mrqa_searchqa-validation-6540", "mrqa_searchqa-validation-16405", "mrqa_searchqa-validation-15822", "mrqa_searchqa-validation-8356", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-3767", "mrqa_triviaqa-validation-3380", "mrqa_hotpotqa-validation-1576", "mrqa_newsqa-validation-2821"], "SR": 0.59375, "CSR": 0.5234375, "EFR": 1.0, "Overall": 0.7036718750000001}, {"timecode": 54, "before_eval_results": {"predictions": ["Angus Deayton", "(SI 318/92 Vehicle Registration and Taxation Regulations 1992", "Gary Havelock", "Anthony Joshua", "Kansas", "purple", "Thabo Mbeki", "Denver", "George Blake", "Illinois", "a Soldier", "Adrian Cronauer", "copenhagen", "the Spice Girls", "indigo", "Heston Blumenthal", "Angola", "John le Carr\u00e9", "a googol", "Niagara Falls", "$SPX", "Mrs Merton", "jazz", "Compare car rent", "Brazil", "aperitivo", "George Williams", "Michael Faraday", "Prescott", "Montmorency", "haddock", "Terry & June", "Tim Peake", "Phil Redmond", "tamale", "Argentina", "St Moritz", "Good Neighbors", "Woody", "Penelope Keith", "Sinclair Lewis", "mouse", "brazil", "Barry White", "Burt Ward", "Parchman Farm", "Canada", "The Hague Conventions", "Portugal", "silver", "Moby Dick", "X&Y ( 2005 )", "`` Killer Within", "during prenatal development in the central part of each developing bone", "13\u20133", "My Beautiful Dark Twisted Fantasy", "\"The Worm\"", "\"Maude\" and the sardonic Dorothy on \"The Golden Girls,\"", "\"If you are going to work on developing a state-based response to this enormous problem -- the lack of a national immigration policy -- Arizona is the place to do it.\"", "his former caddy, telling reporters Steve Williams apologized and is not a racist.\"", "Easy Rawlins", "President Grover Cleveland", "Scripps National Spelling Bee", "Berlin"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6215277777777777}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, false, false, false, false, true, false, true, true, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.5, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-164", "mrqa_triviaqa-validation-2608", "mrqa_triviaqa-validation-2102", "mrqa_triviaqa-validation-312", "mrqa_triviaqa-validation-2567", "mrqa_triviaqa-validation-3140", "mrqa_triviaqa-validation-3993", "mrqa_triviaqa-validation-7705", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-1916", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-5010", "mrqa_triviaqa-validation-6318", "mrqa_triviaqa-validation-5211", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-979", "mrqa_triviaqa-validation-7414", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-6566", "mrqa_triviaqa-validation-3131", "mrqa_naturalquestions-validation-6206", "mrqa_naturalquestions-validation-2440", "mrqa_hotpotqa-validation-227", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3584", "mrqa_newsqa-validation-2811", "mrqa_searchqa-validation-1750", "mrqa_searchqa-validation-12187"], "SR": 0.5625, "CSR": 0.5241477272727273, "EFR": 1.0, "Overall": 0.7038139204545455}, {"timecode": 55, "before_eval_results": {"predictions": ["detainees are not drugged unless there is a medical reason to do so.", "the man was dead,", "Republican Gov. Bobbyindal", "Mexico", "women", "the United States", "South Dakota State Penitentiary", "Peshawar", "fake his own death", "the twins", "Matthew Chance", "poppy production was going on largely unchecked.", "Bright Automotive,", "NASCAR", "Clifford Harris,", "a Muslim with Lebanese heritage", "Coptic Christians", "a new television show which looks at how children as young as eight would cope without their parents for two weeks.", "is", "new voters", "it was important to provide alternative work for poor Afghan farmers to encourage them to give up opium production.", "1831", "the Ku Klux Klan", "the Supreme Court", "the beetles", "the lower house of parliament,", "Robert Barnett", "isreal's threat list", "Daniel Radcliffe", "the \"deeply intimate portrait will provide viewers with a raw and honest look inside a musical dynasty,\"", "Ronald Reagan UCLA Medical Center,", "her brother, Murtaza, was killed along with six others in a 1996 shootout with police at his home.", "six", "remains unknown,", "$89", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Charles Darwin", "an acid attack", "root out terrorists within its borders.", "July 8", "he was released Friday and taken to the Australian embassy, where he stayed until leaving for Australia at about midnight.", "is not a project for commercial gain.", "\"Gustav's top winds weakened to 110 mph,", "rwanda", "two", "Bob Johnson", "the immorality of these deviant young men", "\"Dancing With the Stars,\"", "his club", "Microsoft", "two years", "the Confederate States", "Sylvester Stallone", "1,228 km / h ( 763 mph )", "Thomas \"Thom\" Edward Yorke", "Charlie Sheen", "silversmith", "Francis Keogh Gleason", "the International Federation of Competitive eating", "Valley Falls", "the Provisional Irish Republican Army", "naszkpfw", "the Lone Ranger", "the South Pacific Ocean"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5541170634920634}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, true, false, true, false, false, true, false], "QA-F1": [0.6666666666666666, 0.4, 0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.06666666666666667, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.1, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5, 0.6428571428571429, 0.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.6, 1.0, 0.4, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-136", "mrqa_newsqa-validation-3678", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2792", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-877", "mrqa_newsqa-validation-2175", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3412", "mrqa_newsqa-validation-1877", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-2530", "mrqa_newsqa-validation-1637", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1948", "mrqa_newsqa-validation-1497", "mrqa_newsqa-validation-847", "mrqa_newsqa-validation-1541", "mrqa_newsqa-validation-471", "mrqa_newsqa-validation-3652", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2307", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-566", "mrqa_newsqa-validation-1461", "mrqa_naturalquestions-validation-6888", "mrqa_triviaqa-validation-1475", "mrqa_hotpotqa-validation-698", "mrqa_searchqa-validation-1388", "mrqa_searchqa-validation-12033", "mrqa_naturalquestions-validation-7750"], "SR": 0.421875, "CSR": 0.5223214285714286, "EFR": 0.972972972972973, "Overall": 0.6980432553088803}, {"timecode": 56, "before_eval_results": {"predictions": ["a jet-powered strategic bomber", "peso", "the nucleus", "corticosteroid", "Starship Troopers", "Stalin", "the aquifer", "sperm", "the pythons", "William Proxmire", "George Orwell", "an indigenous ethnic group", "wood", "Coach Carter", "pzkpfw", "a giant leap", "Psycho", "a believer", "Athens", "'Extreme' Vetting", "zoos", "\" Please Mr. Please\"", "Mickey Gilley", "Oral Roberts", "the staff", "pzkpfw", "tin", "Ganges", "Jules Verne", "Dave Brubeck Quartet", "a Yellow Ribbon", "Stevie Wonder", "Richmond, Virginia", "Jupiter", "arachnids", "Apple", "pzkpfw", "The Mausoleum", "'Act One", "a blue star sapphire", "Rhapsody", "the spectacle on Broadway", "liquor", "Ronald", "Mount Kilimanjaro", "militia", "Delaware", "Graceland", "a supersonic interceptor aircraft", "Don Michael Corleone", "the 'oral phase'", "John F. Kennedy", "Siddharth Arora / Vibhav Roy", "`` Business Trip ''", "Munich", "the Circle line", "1123", "Julie Kavner", "Benedict of Nursia", "a Boltzmann machine", "\"Abbey Road.\"", "Dubai", "At least 15", "taekwondo"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5359375}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, false, true, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, false, false, false, true, false, true, false, false, true, true, true, true, true, true, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2168", "mrqa_searchqa-validation-4764", "mrqa_searchqa-validation-15581", "mrqa_searchqa-validation-3211", "mrqa_searchqa-validation-7001", "mrqa_searchqa-validation-4802", "mrqa_searchqa-validation-1039", "mrqa_searchqa-validation-2648", "mrqa_searchqa-validation-6007", "mrqa_searchqa-validation-11485", "mrqa_searchqa-validation-12936", "mrqa_searchqa-validation-12018", "mrqa_searchqa-validation-6590", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-7749", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-13088", "mrqa_searchqa-validation-9015", "mrqa_searchqa-validation-5745", "mrqa_searchqa-validation-11106", "mrqa_searchqa-validation-2176", "mrqa_searchqa-validation-10721", "mrqa_searchqa-validation-11145", "mrqa_searchqa-validation-13454", "mrqa_searchqa-validation-15618", "mrqa_searchqa-validation-15585", "mrqa_searchqa-validation-16690", "mrqa_searchqa-validation-2837", "mrqa_searchqa-validation-4798", "mrqa_searchqa-validation-9883", "mrqa_naturalquestions-validation-3714", "mrqa_naturalquestions-validation-9903", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-5658"], "SR": 0.46875, "CSR": 0.5213815789473684, "EFR": 1.0, "Overall": 0.7032606907894736}, {"timecode": 57, "before_eval_results": {"predictions": ["Siberia", "bamboo", "Merlin", "graphic design", "Alien", "Think Big", "Mariachi", "Rebel Heart", "excruciating", "Kilimanjaro", "polarization", "Joseph Campbell", "pardon", "the pope", "Calais", "One billion", "Thomas Edison", "reptiles", "Thomas Paine", "Isaac Newton", "American Wedding", "Anthony Michael Hall", "Tears for Fears", "Jamestown", "the Rhine", "a blacksmith", "the Mohs scale", "Katharine McPhee", "Henry Ford", "the Purple Rain", "(Cnut)", "spiral", "George W. Bush", "trout", "(Vijay) Singh", "geometric", "Baton Rouge", "Daniel Boone", "Chariots of Fire", "(Diemictylus) viridescens", "Sweden", "pink", "eyelid", "Hong Kong", "The Addams Family", "a bacterium", "Sanders", "a fraud", "Churchill", "the fineness of detail", "Sweden", "Woodrow Wilson", "Robert Gillespie Adamson IV", "September 9, 2012", "Jupiter", "90%", "Michael Fassender and Mia Wasikowska", "the University of Oxford", "1,467", "\"Vision of Love\"", "allegedly grabbed a pupil by the throat and threw her against a wall,", "federal prosecutors in Tennessee.", "Alwin Landry", "Israel"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5703125}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, true, false, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13203", "mrqa_searchqa-validation-14488", "mrqa_searchqa-validation-9192", "mrqa_searchqa-validation-4662", "mrqa_searchqa-validation-14895", "mrqa_searchqa-validation-13859", "mrqa_searchqa-validation-11647", "mrqa_searchqa-validation-11099", "mrqa_searchqa-validation-2121", "mrqa_searchqa-validation-1930", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-6775", "mrqa_searchqa-validation-1107", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-11322", "mrqa_searchqa-validation-10635", "mrqa_searchqa-validation-16972", "mrqa_searchqa-validation-7090", "mrqa_searchqa-validation-717", "mrqa_searchqa-validation-15511", "mrqa_searchqa-validation-10747", "mrqa_searchqa-validation-10072", "mrqa_searchqa-validation-7507", "mrqa_searchqa-validation-5688", "mrqa_triviaqa-validation-7432", "mrqa_hotpotqa-validation-4289", "mrqa_hotpotqa-validation-4131", "mrqa_newsqa-validation-3803", "mrqa_newsqa-validation-3265", "mrqa_newsqa-validation-2207"], "SR": 0.515625, "CSR": 0.5212823275862069, "EFR": 1.0, "Overall": 0.7032408405172415}, {"timecode": 58, "before_eval_results": {"predictions": ["Derek Mears", "Newcastle", "super-yacht", "cooperating with Turkey", "tells stories of different women coping with breast cancer in five vignettes.", "housing, business and infrastructure repairs", "\"No one on our end was ever contemplating pulling the plug,\"", "improve health and beauty.", "school", "Asashoryu", "attacked Chaudhary with iron rods,", "China", "\"I never thought any of this was going to be easy,\"", "Akio Toyoda", "Olympic Torch,", "a man's lifeless, naked body", "North Korea may be trying to prevent attempted defections as the country goes through a tumultuous transition, the report said.", "military commissions", "183", "Nirvana", "Patrick McGoohan,", "55-year-old", "opponents of Mugabe and his Zanu-PF party.", "new Touch,", "the Cleveland Clinic.", "International Polo Club Palm Beach in Wellington, Florida,", "President Bush", "All three pleaded not guilty in an appearance last week in Broward County Circuit Court.", "ten square meters in forward deck space", "Turkey can play an important role in Afghanistan as a reliable NATO ally. The question is: How can Turkey best help", "Lauren made it look as easy as Fred Astaire dancing down a staircase.", "a building in the Kenyan capital of Nairobi", "cancer", "Hussein's Revolutionary Command Council.", "abuses against ethnic Somalis by rebels and Ethiopian troops are rampant.", "ten", "The Rev. Alberto Cutie", "Daryeel Bulasho Guud", "magazine", "FBI Special Agent Daniel Cain", "Rihanna", "February 12", "Oaxacan", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "strict interpretation of sharia forbids girls from attending school, requires veils for women and beards for men", "trading goods and services without exchanging money", "two", "11", "CNN", "51 percent of the U.S. public consider China a military threat, with 47 percent disagreeing.", "Ben Roethlisberger", "Taylor Michel Momsen", "Scott", "November 2016", "motorway", "Kinshasa, Zaire", "vinegar", "DreamWorks Animation", "Debbie Harry", "2004", "a cord", "Brian Slade", "Existentialism", "William Windom"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5687734962406015}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.21052631578947367, 1.0, 1.0, 0.06666666666666667, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.9333333333333333, 1.0, 0.4444444444444445, 0.0, 0.13333333333333333, 0.10526315789473685, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.2222222222222222, 0.0, 1.0, 0.0, 1.0, 0.0, 0.41666666666666663, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1699", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3562", "mrqa_newsqa-validation-1020", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-4207", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1091", "mrqa_newsqa-validation-4124", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-1701", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-1004", "mrqa_newsqa-validation-2297", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-535", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2891", "mrqa_newsqa-validation-18", "mrqa_newsqa-validation-1535", "mrqa_newsqa-validation-1421", "mrqa_newsqa-validation-1313", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-2384", "mrqa_triviaqa-validation-4398", "mrqa_triviaqa-validation-4217", "mrqa_triviaqa-validation-3727", "mrqa_hotpotqa-validation-2564", "mrqa_searchqa-validation-2941", "mrqa_searchqa-validation-14208"], "SR": 0.484375, "CSR": 0.5206567796610169, "EFR": 1.0, "Overall": 0.7031157309322034}, {"timecode": 59, "before_eval_results": {"predictions": ["white", "Pakistan", "IndyCar Series", "Vernon Kay", "Florida", "ten", "Tim Andrew", "Maxwell Atoms", "Scandinavian design", "Sandy Bentley", "Pasek and Paul", "Toxics Release Inventory", "Oregon", "\"Mrs. Eastwood & Company\"", "Blackpool Football Club", "Denver, Colorado", "Ted Kennedy", "Boeing EA-18G Growler", "News Corporation", "Pennsylvania's", "Danielle Steel", "1970s and 1980s", "Milwaukee Bucks", "Hazel Keech", "North Atlantic Treaty Organisation", "sometimes I. A. K. Pataudi", "extreme nationalist, and nativist", "AOL Inc.", "World War II", "the coca wine", "Barack Obama", "local South Australian and Australian produced content", "Matt Groening", "William Finn", "45%", "Christophe Lourdelet", "2002 Golden Globe for Best Supporting Actress", "New Jersey", "Ian Rush", "Erich Maria Remarque", "Australian", "youngest TV director ever", "Art Bell", "California Shipbuilding Corporation", "Delaware River", "Jean Acker", "Anheuser-Busch", "MG Car Company Limited", "Boston Celtics", "May 2008", "Hungarian Rhapsody No. 2", "24 hours later", "Brian Steele", "35 to 40 hours per week", "to shut down October 24", "the Dieppe Raid", "hanover", "the iconic Hollywood headquarters of Capitol Records,", "228", "The son of Gabon's former president", "stocks", "Thomas Edison", "Han solo", "Longo-Ciprelli"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6740584935897436}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, true, false, false, false, false, false, false, true, true, true, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.923076923076923, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.8, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-411", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-1145", "mrqa_hotpotqa-validation-1512", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5535", "mrqa_hotpotqa-validation-4104", "mrqa_hotpotqa-validation-5449", "mrqa_hotpotqa-validation-4852", "mrqa_hotpotqa-validation-2870", "mrqa_hotpotqa-validation-2131", "mrqa_hotpotqa-validation-4364", "mrqa_hotpotqa-validation-5286", "mrqa_hotpotqa-validation-5452", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-919", "mrqa_hotpotqa-validation-3725", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-23", "mrqa_hotpotqa-validation-2977", "mrqa_naturalquestions-validation-215", "mrqa_triviaqa-validation-1201", "mrqa_triviaqa-validation-5185", "mrqa_newsqa-validation-3923", "mrqa_searchqa-validation-10636"], "SR": 0.578125, "CSR": 0.5216145833333333, "EFR": 1.0, "Overall": 0.7033072916666667}, {"timecode": 60, "before_eval_results": {"predictions": ["three", "May 4", "NATO fighters followed the bombers on their 13-hour flight over the Arctic Ocean and the Atlantic.", "the plane was in fine condition at takeoff,", "Rivers", "Russia and the United States,", "Alison Sweeney", "Carrousel du Louvre,", "Steve Williams", "$1,500", "the 50-year-old King of Pop has agreed to a series of summer concerts at the O2.", "she sent a letter to Goa's chief minister asking for India's Central Bureau of Investigation to look into the case.", "The dogs' canine high jinks", "at least 25", "269,000", "flooding", "(The Frisky)", "he won two Emmys", "ambassadors", "NATO", "lifeless,", "hanged in 1979", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "sports cars", "U.S. Vice President Dick Cheney", "people", "'overcharged.'\"", "Michael Schumacher", "Ashley \"A.J.\" Jewell", "economic and political engagement", "The Best Picture winner \"Slumdog Millionaire\" (No. 4)", "Noida, located in the outskirts of the capital New Delhi.", "body bags on the roadway near the bus,", "Afghanistan,", "10 to 15 percent", "Spain has denied his request", "The Celebrity Apprentice", "an engineering and construction company", "the north coast of Puerto Rico.", "At least 15", "the fires", "navy dress with red lining", "pay him a monthly allowance,", "Too many glass shards left by beer drinkers in the city center,", "the legitimacy of that race.", "Nigeria", "Andrew Morris,", "the shipping industry -- responsible for 5% of global greenhouse gas emissions,", "Drottningtorget", "the driver", "the World Wide Village Guest House.", "his cousin D\u00e1in", "Jesse McCartney", "the American Civil War", "Becket", "white", "Australia and Ireland", "1975", "1970", "Copenhagen", "The Pacemakers", "Khartoum", "Stand by Me", "Italian"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5933729373696479}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.14285714285714288, 0.19047619047619047, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.631578947368421, 0.1212121212121212, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.04761904761904762, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8333333333333333, 0.0, 0.923076923076923, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3025", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2107", "mrqa_newsqa-validation-2955", "mrqa_newsqa-validation-444", "mrqa_newsqa-validation-2983", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-3101", "mrqa_newsqa-validation-2062", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-3563", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-1796", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1954", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-705", "mrqa_naturalquestions-validation-7957", "mrqa_triviaqa-validation-5146", "mrqa_triviaqa-validation-2599", "mrqa_searchqa-validation-6409"], "SR": 0.484375, "CSR": 0.5210040983606558, "EFR": 1.0, "Overall": 0.7031851946721311}, {"timecode": 61, "before_eval_results": {"predictions": ["allergies to peanuts, nuts, shellfish, peanuts, tree nuts, wheat and soy", "Flying a space shuttle is a little more challenging than what we did in the movie,", "Santaquin City, Utah,", "It has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "Johnny Carson", "Bob Bogle", "183", "Russia: Moving Forward", "Sunday", "Filippo Inzaghi", "Sunni Arab and Shiite tribal leaders", "2002", "another American icon's", "two", "Ford", "Lula da Silva", "\"It has never been the policy of this president or this administration to torture.\"", "the soldiers", "the body of the aircraft", "the final of the Sony Ericsson Open in Miami", "the college campus.", "The cervical cancer vaccine,", "Bright Automotive,", "the world's tallest building,", "Europe,", "$7.8 million in cash", "Polo because \"it was the sport of kings.", "The elections are slated for Saturday.", "United", "the surgical anesthetic propofol", "she was humiliated by last month's incident,", "CNN", "school,", "Hurricane Gustav", "The cervical cancer vaccine, approved in 2006,", "two", "outfit from designer", "to get the two bodies out of the plant,", "second-degree aggravated battery.", "the man facing up, with his arms out to the side.", "British Prime Minister Gordon Brown's", "the first of 1,500 Marines", "Thai", "Arsene Wenger", "The local Republican Party", "the Gulf", "Gary Brooker", "teenager", "The Tupolev Tu-160 strategic bombers landed at Venezuela's Libertador military airfield and \"will spend several days carrying out training flights over neutral waters, after which they will return to the base,\"", "the funds for housing, business and infrastructure repairs,", "travel in cars with tinted windows -- which protected me from identification by terrorists -- or travel with privately armed guards,\"", "short - circuit - proof extra-low voltage transformers for toys", "British citizens", "Pepsi", "Greece", "Brighton", "a double empire", "Umberto II", "\"The Longest Yard\"", "Lucille D\u00e9sir\u00e9e Ball", "Louis XIV", "the Bronx", "flamboyant", "South Africa"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6095467032967032}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, true, false, true, true, true, false, false, false, false, false, true, false, true, false, false, true, true, false, false, false, false, false, false, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, false, false, false, false, false, false, false, false, true, true, false, true, true, false, true, true, true, true], "QA-F1": [0.5000000000000001, 0.0, 0.8571428571428571, 0.15384615384615385, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.8, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 0.0, 1.0, 0.6, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333333, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.8333333333333333, 0.0, 0.2222222222222222, 0.4444444444444445, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3733", "mrqa_newsqa-validation-350", "mrqa_newsqa-validation-1712", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-4118", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-937", "mrqa_newsqa-validation-2457", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-804", "mrqa_newsqa-validation-2168", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-237", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-2471", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-1372", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-1861", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-2149", "mrqa_newsqa-validation-1958", "mrqa_newsqa-validation-3489", "mrqa_newsqa-validation-3365", "mrqa_newsqa-validation-851", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-3881", "mrqa_naturalquestions-validation-6620", "mrqa_triviaqa-validation-5178", "mrqa_hotpotqa-validation-2827"], "SR": 0.453125, "CSR": 0.5199092741935484, "EFR": 1.0, "Overall": 0.7029662298387097}, {"timecode": 62, "before_eval_results": {"predictions": ["1-0", "Shakespeare", "Al Gore.", "200", "T.I.", "censorship", "Friday,", "carving in the middle of our Mountain View, California, campus.", "a Texas ranch that's home to members of a polygamist sect,", "Iran could be at work on building a nuclear weapon.", "assassinated Tuesday,", "56,", "April 28,", "former Boca Juniors teammate and national coach", "Fernando Caceres", "the license plate \"BADBUL,\"", "Nirvana frontman,", "its best-kept summer secret.", "the mastermind behind the September 11, 2001,", "a residential area in East Java", "\"The Cycle of Life,\"", "diplomatic relations", "supermodel", "10 below", "1,073", "children were Sudanese orphans that it was trying to rescue from a war-torn nation.", "fled Zimbabwe", "girls around 11,000", "Israel", "food, music, culture and language of Latin America", "cancerous tumor.", "Tennessee.", "Bright Automotive,", "nuclear weapon", "the invention of iTunes,", "\"Up,\"", "104 feet", "her daughter and granddaughter attend Oprah Winfrey's school in South Africa considers the talk-show host heaven-sent,", "al Qaeda,", "jury", "Sharon Tate", "Charlotte Gainsbourg and Willem Dafoe", "the infant who became the center of an international end-of-life debate,", "Osama's", "Hu and other top Chinese officials", "United States", "tallest building,", "speaking out about a cause someone feels passionate about.", "25 years", "Anil Kapoor.", "President Obama and Britain's Prince Charles", "Wembley Stadium", "a modulator molecule ( allosteric regulator )", "up to 40.5 metres ( 133 ft )", "whooping cough", "Exile", "Richard Attenborough and wife Sheila Sim", "Bob Mould", "331 episodes", "2008", "Ruth Bader Ginsburg", "Chandler's", "Seth", "pacock"], "metric_results": {"EM": 0.3125, "QA-F1": 0.4560961174242424}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, false, true, false, false, true, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.25, 0.0, 1.0, 0.1818181818181818, 0.19999999999999998, 0.6250000000000001, 0.0, 1.0, 0.0, 0.6, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.5714285714285715, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.09523809523809522, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.26666666666666666, 1.0, 0.0, 0.8, 0.0, 1.0, 0.5, 0.4, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3229", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-1250", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1763", "mrqa_newsqa-validation-776", "mrqa_newsqa-validation-724", "mrqa_newsqa-validation-283", "mrqa_newsqa-validation-879", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-1956", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-2013", "mrqa_newsqa-validation-2591", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-1371", "mrqa_newsqa-validation-1296", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-2634", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3715", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-505", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-746", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-2374", "mrqa_newsqa-validation-2497", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-5001", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-6362", "mrqa_hotpotqa-validation-3409", "mrqa_hotpotqa-validation-2260", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-12746", "mrqa_triviaqa-validation-3869"], "SR": 0.3125, "CSR": 0.5166170634920635, "EFR": 1.0, "Overall": 0.7023077876984127}, {"timecode": 63, "before_eval_results": {"predictions": ["U.S. senators", "a paragraph about the king and crown prince that authorities deemed a violation of a law that makes it illegal to defame, insult the crown.", "closing these racial gaps.", "\"The Ethiopian army's answer to the rebels has been to viciously attack civilians in the Ogaden,\"", "the Dalai Lama", "about the shootings, handed over the AR-15 and two other rifles and left the cabin.", "to help women \"learn how to dance and feel sexy,\"", "the German Foreign Ministry,", "$89", "South African ministers and the deputy president", "militants in Afghanistan", "Japan", "urged NATO to take a more active role in countering the spread of the narcotics trade.", "poor.", "striker", "Sixteen", "poems telling of the pain and suffering of children just like her; girls banned from school, their books burned,", "The wind chill (3 degrees Fahrenheit),", "Technological Institute of Higher Learning of Monterrey,", "Orioles", "Golden Gate Yacht Club of San Francisco", "nearly 100", "a national telephone survey of more than 78,000 parents of children ages 3 to 17", "ballots", "and renewable energy at home everyday,\"", "Joe Pantoliano", "The prince, second in line to the throne, landed a Chinook helicopter -- normally used for transporting troops -- in a field next to the home of Kate Middleton,", "part of the proceeds", "The minister later apologized, telling CNN his comments had been taken out of context.", "highlight weekend for the $80 million former Liverpool player, who also netted in the 3-1 defeat at Manchester United before an extraordinary miss that saw him widely lampooned.", "eight-day", "Alexey Pajitnov", "three", "Ozzy Osbourne", "\"Dancing With the Stars\"", "civilians,", "March 3,", "peanuts, nuts, shellfish and fish tend to be lifelong,", "Asashoryu", "a bag", "at a depth of about 1,300 meters in the Mediterranean Sea.", "\"To be casually talking about military action because we're getting frustrated seems to me somewhat dangerous,\"", "Buddhism, a practice that originated in China, and meet weekly to focus their minds. Others practice Vipassana, a Buddhist practice founded in India,", "Casalesi Camorra clan", "May 4", "tranquil beaches,", "$1.5 million.", "Booches Billiard Hall,", "\"peregruzka\"", "since 1983.", "And I think we also have these walls around us, and when people disagree, we're inclined not to listen, but to a degree you can break through that wall often", "Total Drama World Tour", "Kimberlin Brown", "a turlough, turlach", "1934", "Kirk Douglas", "highlight to televise various events", "Vikram, Jyothika and Reemma Sen", "the Dutch Empire", "substantive rank of Commodore", "the Department of Homeland Security", "France", "The Addams Family", "Niveditha, Diwakar, Shruti"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6579583772458193}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, false, true, false, true, false, false, true, true, false, false, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 0.16666666666666669, 0.0, 0.2857142857142857, 0.8235294117647058, 1.0, 0.0, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.10526315789473684, 0.0, 1.0, 0.0, 1.0, 0.0, 0.35294117647058826, 1.0, 1.0, 0.0, 0.08, 1.0, 0.2666666666666667, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.08333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 0.7272727272727273, 0.6666666666666666, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_newsqa-validation-702", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-3418", "mrqa_newsqa-validation-2317", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-2193", "mrqa_newsqa-validation-3075", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-2872", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3191", "mrqa_newsqa-validation-181", "mrqa_newsqa-validation-1286", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-2470", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3692", "mrqa_newsqa-validation-2353", "mrqa_naturalquestions-validation-6346", "mrqa_triviaqa-validation-7047", "mrqa_triviaqa-validation-2986", "mrqa_hotpotqa-validation-2833", "mrqa_hotpotqa-validation-1416", "mrqa_searchqa-validation-1695", "mrqa_naturalquestions-validation-10396"], "SR": 0.546875, "CSR": 0.51708984375, "EFR": 1.0, "Overall": 0.70240234375}, {"timecode": 64, "before_eval_results": {"predictions": ["prisoners at the South Dakota State Penitentiary and ultimately delivered in Iraq by the U.S. military.", "sportswear", "teenage", "July 23.", "Landry", "a Korean-American missionary", "Chester Arthur Stiles,", "United States", "Pakistan's High Commission in India", "Wednesday.", "Wigan Athletic in northern England.", "Amir Zaki", "poems", "Drew Kesse", "A 22-year-old college student in Boston, Massachusetts,", "to sniff out cell phones.", "Longo-Ciprelli", "The Screening Room", "of helping to plan the September 11, 2001, terror attacks,", "June 6, 1944,", "\"I will not forget about New Orleans,\"", "heavy snow and ice", "more than 30", "his salary", "\"We tortured (Mohammed al+) Qahtani,\"", "free laundry service.", "rural California,", "Jesus Christ", "11th year in a row.", "100,000", "future relations with Washington", "school", "a plaque at the home of his great-grandfather and by making Ali the first honorary \"freeman\" of the town.", "genocide, crimes against humanity and serious war crimes", "a nuclear weapon", "Tina Constable,", "\"The missile defense system is not aimed at Russia,\"", "Grand Ronde, Oregon.", "Lindsey oil refinery in eastern England.", "Fred Bright,", "\"Empire of the Sun,\"", "trading goods and services without exchanging money", "more than two years,", "stuck to with remarkably little internal drama. He won it with unparalleled fundraising and an overwhelming ground game. And he won it after facing various challenges and turning them to his advantage.", "$3 billion,", "Crap E-mail", "Bobby Jindal", "he believed he was about to be attacked himself.", "more than 600 Argentinean and 255 British military personnel died.", "Sen. Barack Obama", "jobs", "angular rotation", "180th meridian in a 360 \u00b0 - system", "Darlene Cates", "Colette", "crows", "douglas", "2015", "11", "January 15, 2016", "piano", "King Abdullah", "Barnard", "Chiltern Hills"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6224602220695971}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true], "QA-F1": [0.6, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8, 1.0, 0.1111111111111111, 0.0, 1.0, 1.0, 0.1111111111111111, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.125, 0.0, 1.0, 0.0, 0.4, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 1.0, 0.9666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1143", "mrqa_newsqa-validation-2982", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-8", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-3332", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-1021", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3048", "mrqa_newsqa-validation-3239", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-3320", "mrqa_newsqa-validation-1988", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-854", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2227", "mrqa_newsqa-validation-1181", "mrqa_newsqa-validation-3887", "mrqa_newsqa-validation-4041", "mrqa_naturalquestions-validation-10347", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-401", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-3992", "mrqa_searchqa-validation-1516"], "SR": 0.546875, "CSR": 0.5175480769230769, "EFR": 1.0, "Overall": 0.7024939903846155}, {"timecode": 65, "before_eval_results": {"predictions": ["banned substance cortisone.", "Larry King Show", "The Ski Train", "housing, business and infrastructure repairs,", "Joe Harn", "Port-au-Prince harbor", "South Korea", "Israel", "Nigeria, Africa's largest", "in Mexico", "two Metro transit trains that crashed the day before,", "identity documents belonging to Miguel Mejia Munera", "Denver, Colorado.", "his son is fighting an unjust war for an America that went too far when it invaded Iraq", "the single-engine Cessna 206", "a strong work ethic", "meter reader", "could be secretly working on a nuclear weapon", "was arrested in a federal sting after his bodyguard-turned-informant delivered three machine guns and two silencers to the hip-hop star,", "Karen Floyd", "GOP Sens. Daniel Verdin, Shane Martin, Ronnie Cromer and Wes Hayes", "\"I hope people look at the content of the speech, not just the delivery. You know, for years, I've been told I speak too quickly.", "April 22.", "Manuel Mejia Munera", "outfit from designer", "five", "Ozzy Osbourne", "Sarah Brown", "Lisa Jackson, former head of New Jersey's environmental agency, to serve as his Environmental Protection Agency administrator,", "pro-democracy activists", "eight.", "Fullerton, California,", "Hawaii", "Bill Haas", "\"A Lion Among Men,\"", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Ricardo Valles de la Rosa,", "talked of an impromptu memorial for the late singer at the \"Stone Circle,\"", "Karl Kr\u00f8yer", "Gyanendra, 60,", "Arlington National Cemetery's", "Gadahn", "Turkey", "Polo because \"it was the sport of kings.", "Texas and Oklahoma", "\u00a320 million ($41.1 million)", "unwanted horses", "700,000", "New York", "The 19-year-old woman whose hospitalization exposed a shocking Austrian incest case", "it -- you know -- black is beautiful,\"", "Arnold Schoenberg", "N\u0289m\u0289n\u0289\u0289", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "Einstein", "Nova Scotia", "pyrotechnic", "Battelle Energy Alliance", "North Chicago, in Lake County, Illinois", "Eran Kolirin", "cryptobiosis", "Tigers", "Herod", "leopard"], "metric_results": {"EM": 0.375, "QA-F1": 0.5217845379258423}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, true, false, true, false, false, true, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, false], "QA-F1": [0.5, 0.8, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.08, 1.0, 0.0, 0.12121212121212123, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.5, 1.0, 0.0, 0.18181818181818182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.782608695652174, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-3369", "mrqa_newsqa-validation-4098", "mrqa_newsqa-validation-2855", "mrqa_newsqa-validation-3233", "mrqa_newsqa-validation-3429", "mrqa_newsqa-validation-2948", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-875", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-4055", "mrqa_newsqa-validation-2332", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-292", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-1797", "mrqa_newsqa-validation-3839", "mrqa_newsqa-validation-2526", "mrqa_newsqa-validation-2908", "mrqa_newsqa-validation-1552", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9400", "mrqa_triviaqa-validation-5643", "mrqa_hotpotqa-validation-3069", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-4048", "mrqa_searchqa-validation-14691", "mrqa_hotpotqa-validation-1504"], "SR": 0.375, "CSR": 0.5153882575757576, "EFR": 0.975, "Overall": 0.6970620265151515}, {"timecode": 66, "before_eval_results": {"predictions": ["French Open champion Moya.", "they would not be making any further comments,", "Iowa's critical presidential caucuses", "Iran's nuclear program.", "green-card warriors", "a space for aspiring entrepreneurs to brainstorm with like-minded people.", "Tillakaratne Dilshan", "Columbia, Missouri.", "The plane was headed to nearby Wilson Airport,", "Harris won two awards.", "Bowe Bergdahl", "many different", "President Bush", "$17,000", "Employee Free Choice Act", "Sadat's assassination was recently revisited by his daughter, Roqaya al-Sadat,", "Thomas", "The worst snowstorm to hit Britain", "Arnold Drummond", "Madonna", "\"I'm certainly not nearly as good of a speaker as he is.\"", "the commissions are OK,", "love and loss.", "Larry King", "as many as 250,000", "is not doing everything within its power to prevent more people from needlessly suffering disabling tendon ruptures.", "managing his time.", "The commerce graduate and his wife and two children share a meeting room with other families and have been at the shelter for four months.", "Omar", "Scotland", "Mugabe's opponents", "inferior,", "his business dealings for possible securities violations", "January", "The Great Barrier Reef -- which is composed of about 2,900 individual reefs and is off the northeast coast of Australia -- is seeing limited bleaching now,", "Millvina Dean,", "dental work", "Sovereign Wealth Funds", "fake his own death by crashing his private plane into a Florida swamp.", "\"I haven't seen any violence. I know [Wimunc's husband] was not living here anymore, but that's all I know,\"", "Ripken's latest project is a business principles book called \"Get in the Game: 8 Elements of Perseverance That Make the Difference,\"", "Apple Inc.", "38,", "terrorists operating within its borders.", "Henrik Stenson", "The elephants can roam freely, largely feed and shelter themselves and interact with others, often after years living alone in captivity.", "The Angels said the two dead at the scene were the female driver of the Mitsubishi and another male.", "a history of successful medical treatment should be able to fly \"within a few months,\"", "Anjuna beach in Goa", "Why he's more American than a German,", "not doing more since taking office.", "demonstrations are held", "military units from their parent countries of Great Britain and France, as well as by American Indian allies", "naturalization law", "el Cid of Castile", "blancmange", "apple", "Los Alamos National Laboratory", "\"Dr. Gr\u00e4sler, Badearzt\"", "cancer", "Joplin", "Italy", "I.M. Pei", "the angel did not kill Balaam"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5018625236428303}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, false, true, false, false, true, false, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, false, false, true, true, false, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666669, 1.0, 0.33333333333333337, 0.0, 1.0, 0.2105263157894737, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.0625, 0.0, 0.0, 1.0, 1.0, 0.06666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.23999999999999996, 0.11764705882352941, 0.4, 0.0, 0.0, 0.8571428571428571, 0.0909090909090909, 0.16666666666666669, 0.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1368", "mrqa_newsqa-validation-1397", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-3301", "mrqa_newsqa-validation-2298", "mrqa_newsqa-validation-1248", "mrqa_newsqa-validation-3189", "mrqa_newsqa-validation-915", "mrqa_newsqa-validation-1482", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2330", "mrqa_newsqa-validation-4201", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-2652", "mrqa_newsqa-validation-502", "mrqa_newsqa-validation-3661", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-1638", "mrqa_newsqa-validation-1591", "mrqa_newsqa-validation-225", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-1088", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-276", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-149", "mrqa_newsqa-validation-1427", "mrqa_naturalquestions-validation-4064", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-10009", "mrqa_triviaqa-validation-5289", "mrqa_hotpotqa-validation-920", "mrqa_hotpotqa-validation-4501", "mrqa_searchqa-validation-12119", "mrqa_naturalquestions-validation-230"], "SR": 0.40625, "CSR": 0.5137593283582089, "EFR": 1.0, "Overall": 0.7017362406716419}, {"timecode": 67, "before_eval_results": {"predictions": ["Edward VIII", "road-building", "candles in iron candelabra shed some light", "Jaipur", "tea", "Ordovices", "Martin Pipe", "Wordsworth", "Ginger Rogers", "palace of Culture of the Podshipnikov Zavod", "sodium tetraborate", "United States Dollar", "peregrines", "VI", "muscle tissue", "Track & Field", "Derby Stakes", "Easter Parade", "traditional Greek Home Management", "HMS Amethyst", "goat", "sargento", "traditional WWII whistling tune, the Colonel Bogey March", "Cyprus", "King George VI", "ankle joint", "Skye terrier", "honeycomb", "flea", "a white robe", "Big Bopper", "NBA", "Hartley", "Leander", "Ipswich and Liverpool", "entropy", "Wadsworth", "green", "elia Earhart", "James Hogg", "lacrimal", "Loki Laufeyiarson", "The Apartment", "adler von Lille", "God", "1879", "Los Angeles", "Loch Lomond", "isosceles", "black", "ballet", "the New York Yankees", "1967", "temperature", "Bolshoi Theatre", "My Boss, My Hero", "mermaid", "death squad killings", "South America and Africa.", "question people if there's reason to suspect they're in the United States illegally.", "St. Croix", "hiccups", "the bumblebee", "12 to 36 months old"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6114383012820512}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, false, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, false, true, false, true, false, true, false, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2305", "mrqa_triviaqa-validation-6180", "mrqa_triviaqa-validation-6937", "mrqa_triviaqa-validation-4575", "mrqa_triviaqa-validation-2483", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-7302", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-737", "mrqa_triviaqa-validation-7172", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-1682", "mrqa_triviaqa-validation-2123", "mrqa_triviaqa-validation-6442", "mrqa_triviaqa-validation-1541", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-3591", "mrqa_triviaqa-validation-543", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-497", "mrqa_triviaqa-validation-6429", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-6242", "mrqa_naturalquestions-validation-2037", "mrqa_naturalquestions-validation-9194", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2782", "mrqa_naturalquestions-validation-8352"], "SR": 0.515625, "CSR": 0.5137867647058824, "EFR": 1.0, "Overall": 0.7017417279411765}, {"timecode": 68, "before_eval_results": {"predictions": ["Hotel barge", "smen", "the southern borders of Ohio, Indiana and Illinois", "the Americans", "Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "2018", "California's Del Norte Coast", "zebra", "257,083", "the island of Puerto Rico", "Norman", "Allies", "Shawn", "if the concentration of a compound exceeds its solubility", "the Soviet Union", "1623", "the eye ( of ) round, bottom round, and top round", "from 1957", "360", "electron shells", "the gastrointestinal tract", "Lori McKenna", "Wisconsin", "Tbilisi", "the Latin centum", "1799", "Paul to the Philippians", "his last starring role was as Boston police detective Barry Frost on the TNT police drama series Rizzoli & Isles ( 2010 -- 14 )", "Elvis Presley", "2009", "Best Picture, Best Director for Fincher, Best Actor for Pitt and Best Supporting Actress for Taraji P. Henson", "most of Sweden's political energy in the international arena had been directed towards the preservation of the League of Nations", "291 episodes", "Cairo, Illinois", "No Secrets", "Steve Russell", "22", "from 4 January 2011", "New Guinea", "Boston Celtics center Bill Russell", "Seattle, Washington", "the pituitary gland", "2010", "Buddhism", "first composed in the 7th century at Rendlesham in East Anglia", "semi-autonomous organisational units", "Diego Tinoco", "Henry Selick", "substitute goods", "to provide school districts with federal funds", "1956", "April", "great", "huff & puff", "Brad Silberling", "1941", "Nickelodeon Studios", "July", "iCloud service", "Thursday", "bonobo", "right and left sides", "Hollywood Bowl", "Oprah Winfrey"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5954982181796697}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, true, false, false, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.3333333333333333, 1.0, 0.9166666666666666, 1.0, 0.25, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.16666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.09999999999999999, 0.0909090909090909, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 0.18181818181818182, 0.5714285714285715, 0.3076923076923077, 1.0, 1.0, 1.0, 0.4615384615384615, 0.5, 1.0, 1.0, 0.5, 0.45161290322580644, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3413", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-6596", "mrqa_naturalquestions-validation-8847", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-10604", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-2965", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-7212", "mrqa_naturalquestions-validation-3771", "mrqa_naturalquestions-validation-7728", "mrqa_naturalquestions-validation-6853", "mrqa_naturalquestions-validation-8095", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-3300", "mrqa_naturalquestions-validation-10389", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-10692", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-6584", "mrqa_naturalquestions-validation-10693", "mrqa_triviaqa-validation-3284", "mrqa_triviaqa-validation-7540", "mrqa_hotpotqa-validation-4171", "mrqa_searchqa-validation-12035"], "SR": 0.453125, "CSR": 0.5129076086956521, "EFR": 0.9428571428571428, "Overall": 0.690137325310559}, {"timecode": 69, "before_eval_results": {"predictions": ["whitechapel", "Uganda", "definitely maybe", "Brazil", "Artemis", "white and black sets", "Bristol", "Florida", "pink", "tin", "Anita Roddick", "e pluribus unum", "black Swan", "Cambridge", "deuteranomaly", "Cambodia", "Nazi Party", "Russia", "1925 novel", "cooperative", "180", "blue", "Tommy Burns", "lady macbeth in Macbeth", "Andre Agassi", "hawk", "The Times of London", "John le Carr\u00e9", "german", "Albania", "zoological", "mata hari", "pyramids", "polo match", "gulliver's Travels", "ratings", "Saturday Night Live", "Bayern Munchen", "Alexander Dubcek", "hydrogen", "Guinea", "ghee", "Julius Caesar", "lathe", "tsbourg Cathedral in Strasbourg, France", "Charles M. Schulz", "Corvidae", "The Hunting of the Snark", "Union of Post Office Workers", "Tokyo Metropolitan Assembly", "convict", "Walter Mondale", "a neutron source used for stable and reliable initiation of nuclear chain reaction", "the plane crash in 1959", "Scotty Grainger Jr.", "The Boy in the Striped Pyjamas", "3.9 mi", "$1.5 million.", "Christianity and Judaism,", "grabbed the gun and  took her own life.", "Space Shuttle", "Smithfield, Virginia", "Alexander Solzhenitsyn", "10 Years"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5244318181818182}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, false, false, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.26666666666666666, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6, 1.0, 0.6666666666666666, 0.5, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4559", "mrqa_triviaqa-validation-3359", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1613", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-5362", "mrqa_triviaqa-validation-6771", "mrqa_triviaqa-validation-1071", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-5998", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-3317", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-7664", "mrqa_triviaqa-validation-5408", "mrqa_triviaqa-validation-3825", "mrqa_triviaqa-validation-7348", "mrqa_triviaqa-validation-1809", "mrqa_triviaqa-validation-7390", "mrqa_triviaqa-validation-5535", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-3323", "mrqa_triviaqa-validation-1993", "mrqa_triviaqa-validation-6176", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-8653", "mrqa_naturalquestions-validation-5936", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-3541", "mrqa_newsqa-validation-3691", "mrqa_newsqa-validation-2197", "mrqa_searchqa-validation-4999", "mrqa_searchqa-validation-16464"], "SR": 0.453125, "CSR": 0.5120535714285714, "EFR": 1.0, "Overall": 0.7013950892857144}, {"timecode": 70, "before_eval_results": {"predictions": ["Tracy Caulkins", "three", "high jump", "Stephen Hawking", "Benjamin Britten", "watchmaking", "Edmund Cartwright", "grapevine", "teaching evolution in violation of a Tennessee state law.", "Thomas Hardy", "shropshire", "Kent", "fox", "Jack Brabham", "Peterborough United", "hanover", "sqrt", "b\u00e9al feirste", "Pete Sampras", "prussia", "Red sea", "zoophobia", "The French Connection", "George Orwell", "Moaning Myrtle", "Italy", "Dubai", "CeeLo Green", "photography", "Justin Bieber", "Greece", "mahjong", "scar", "Stars on 45 Medley", "Cheltenham & Gloucester", "woodknife", "Istanbul", "Margaret Thatcher", "Achille Lauro", "Ian Botham", "stop motion effects", "clemullet", "Ellis Island", "Melanesian", "rhombus", "Zeljko Petrovic", "John Huston", "George Best\u2019s", "Anthony Hopkins", "Martin Van Buren", "Moscow", "2005", "Jim Justice", "Spanish colonization", "Hall & Oates", "TD Garden", "M. Night Shyamalan", "Gary Coleman is in critical condition", "2010", "Uzbekistan.", "Jerry Rice", "leotard", "Ford", "Shakira"], "metric_results": {"EM": 0.609375, "QA-F1": 0.639535984848485}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, true, true, false, false, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, false, false, true, false, false, true, true, true, false, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.36363636363636365, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6483", "mrqa_triviaqa-validation-3065", "mrqa_triviaqa-validation-1196", "mrqa_triviaqa-validation-273", "mrqa_triviaqa-validation-3603", "mrqa_triviaqa-validation-1383", "mrqa_triviaqa-validation-841", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-830", "mrqa_triviaqa-validation-1791", "mrqa_triviaqa-validation-5775", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-820", "mrqa_triviaqa-validation-4680", "mrqa_triviaqa-validation-6651", "mrqa_triviaqa-validation-4089", "mrqa_triviaqa-validation-6706", "mrqa_triviaqa-validation-1672", "mrqa_triviaqa-validation-7032", "mrqa_triviaqa-validation-1928", "mrqa_naturalquestions-validation-4207", "mrqa_naturalquestions-validation-368", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-3232"], "SR": 0.609375, "CSR": 0.5134242957746479, "EFR": 1.0, "Overall": 0.7016692341549297}, {"timecode": 71, "before_eval_results": {"predictions": ["December 23, 1977", "\"The Dragon\"", "public", "University of Southern California", "1935", "James Worthy", "David Weissman", "Moon Shot: The Inside Story of America's Race to the Moon", "Kim Sung-su", "Burma", "French, English and Spanish", "Jimmy Ellis", "Gary Ross", "Randal Keith Orton", "\"Arrested Development\"", "L\u00edneas A\u00e9reas", "October 15, 2013", "Neha Sharma", "Netherlands", "Quentin Coldwater", "1853", "Kew", "\"Apprendi v. New Jersey\" (2000)", "loch moidart", "from 1993 to 1996", "the canton of Sierre", "University of Georgia", "Burning Man", "Arizona State University.", "Pan Am Railways", "Best Actress", "11", "tempo", "7 miles", "1942", "Pollywood", "Fred Derry", "from July 25 to August 4", "2015", "179", "drawings", "1", "The Rebirth", "Herman's Hermits", "Wu-Tang Clan", "soccer", "West Tambaram,", "\"First Blood\"", "Virginia", "O.T. Genasis", "Melbourne Storm", "Juan Francisco Ochoa", "2001", "the coast of Guant\u00e1namo Bay in Cuba", "France", "Wordsworth", "spain", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "to \"wipe out\" the United States if provoked.", "two years", "yacht", "Hinduism", "60 Minutes", "FM, DAB-T (Freeview), Freesat/Sky, cable and internet"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7423081779331779}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.888888888888889, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.72, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4606", "mrqa_hotpotqa-validation-3196", "mrqa_hotpotqa-validation-583", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-1032", "mrqa_hotpotqa-validation-3723", "mrqa_hotpotqa-validation-1886", "mrqa_hotpotqa-validation-1669", "mrqa_hotpotqa-validation-5421", "mrqa_hotpotqa-validation-2849", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1398", "mrqa_hotpotqa-validation-5447", "mrqa_hotpotqa-validation-421", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-5608", "mrqa_naturalquestions-validation-5036", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-213", "mrqa_searchqa-validation-16721", "mrqa_triviaqa-validation-4907"], "SR": 0.640625, "CSR": 0.5151909722222222, "EFR": 1.0, "Overall": 0.7020225694444445}, {"timecode": 72, "before_eval_results": {"predictions": ["the conclusion of a syllogism", "the defendant owed a duty to the deceased to take care", "100,000", "2004", "the NFL", "15th century", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "Tony Orlando and Dawn", "2014 Winter Olympics in Sochi, Russia", "Pir Panjal Range in Jammu and Kashmir", "more pronounced", "the much - decorated Adam Schumann ( Miles Teller ) returns home to Kansas", "1885", "the final episode of the series", "Wisconsin", "the motion of the continents", "the stems and roots of certain vascular plants", "Mahalangur Himal sub-range of the Himalayas", "Americans who served in the armed forces and as civilians", "an Islamic shrine located on the Temple Mount in the Old City of Jerusalem", "2015 World Series", "Massachusetts", "Mark Jackson", "Burt Hammersmith", "antimeridian", "`` Remember, man, that thou art dust, and to dust thou shalt return", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Kida", "Selena Gomez", "iron -- nickel alloy", "Christopher Allen Lloyd", "Procol Harum", "George David Weiss", "federal government", "2013", "Kingsholm Stadium and Sandy Park", "Manhattan Bridge in the Little Fuzhou neighborhood within Manhattan's Chinatown", "the metaphase of cell division", "79", "Yugoslavia", "metabolic phase", "1902", "the female egg", "seven", "Ben Savage", "No. 16 seed", "Chris Coppola", "Daya Jethalal Gada", "system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "Gunpei Yokoi", "the Alamodome and city of San Antonio", "Amy Johnson", "post-modernism", "Bermuda", "win world titles", "their unusual behavior, such as the number of men killed and the manner of the attacks", "Neymar", "22", "opium", "Roger Federer", "Parody", "a prostitute", "Ashlee Simpson", "chicago"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5699837710006638}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, false, true, false, true, false, false, false, true, true, false, false, true, false, false, false, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, true, false], "QA-F1": [0.35294117647058826, 1.0, 0.07999999999999999, 1.0, 1.0, 0.5, 0.3076923076923077, 1.0, 0.2857142857142857, 1.0, 0.0, 0.18181818181818182, 0.4, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.8181818181818181, 0.14285714285714288, 0.5, 1.0, 1.0, 0.0, 1.0, 0.13793103448275862, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666667, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.6, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-2146", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-4830", "mrqa_naturalquestions-validation-9101", "mrqa_naturalquestions-validation-7409", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8205", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-735", "mrqa_naturalquestions-validation-7657", "mrqa_naturalquestions-validation-5000", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-4556", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-8610", "mrqa_naturalquestions-validation-6949", "mrqa_naturalquestions-validation-8159", "mrqa_naturalquestions-validation-4818", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-1909", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-1479", "mrqa_triviaqa-validation-5754", "mrqa_triviaqa-validation-48", "mrqa_hotpotqa-validation-2034", "mrqa_hotpotqa-validation-3308", "mrqa_searchqa-validation-3407", "mrqa_triviaqa-validation-4962"], "SR": 0.46875, "CSR": 0.514554794520548, "EFR": 1.0, "Overall": 0.7018953339041096}, {"timecode": 73, "before_eval_results": {"predictions": ["The Inn at Newport Ranch, a resort and cattle ranch to the north of San Francisco", "one person, whose decisions are subject to neither external legal restraints nor regularized mechanisms of popular control", "Kirstjen Nielsen", "December 14, 2017", "Barbara Windsor", "ninth w\u0101", "British Ultra code - breaking intelligence", "Bart Millard", "Jesse Wesley Williams", "Spencer Treat Clark", "1910", "FIGG Bridge Engineers", "Lenin", "Joanne Wheatley", "`` Everywhere ''", "Watson and Crick", "September 29, 2017", "Lead and lead dioxide", "Indian Olympic Association", "Taylor Michel Momsen", "Magnavox Odyssey", "The Lightning thief", "2015", "2000", "Sara Gilbert", "1962", "fifth studio album", "John Smith", "Katharine Hepburn", "Arnold Schoenberg", "the Indian Civil Service", "203", "Sam went to Hell, and he reappears to Dean after saving him from Djinn poisoning", "Welch, West Virginia", "named after the Swedish astronomer Anders Celsius", "Himadri Station", "Travis Tritt and Marty Stuart", "Cecil B. DeMille", "1877", "to `` help bring creative projects to life ''", "Joan Baez", "Joseph Nye Welch", "flawed democracy", "General George Washington", "Rococo - era France", "4 January 2011", "1837", "Manchuria", "Sanchez Navarro", "Rick Marshall", "Neil Diamond", "Hummer", "wood", "little Reggie", "Tampa", "1874", "January 28, 2016", "Jaipur", "five", "in July", "taro", "You Bet Your Life", "dinosaurs", "Grey's Anatomy"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6821720494417863}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, false, true, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, true, true], "QA-F1": [0.8666666666666666, 0.21052631578947367, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2250", "mrqa_naturalquestions-validation-4646", "mrqa_naturalquestions-validation-9781", "mrqa_naturalquestions-validation-734", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-2630", "mrqa_naturalquestions-validation-4500", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-672", "mrqa_naturalquestions-validation-10250", "mrqa_naturalquestions-validation-9492", "mrqa_naturalquestions-validation-9719", "mrqa_naturalquestions-validation-7144", "mrqa_naturalquestions-validation-7457", "mrqa_naturalquestions-validation-7387", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-6094", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-7464", "mrqa_naturalquestions-validation-8297", "mrqa_triviaqa-validation-2998", "mrqa_triviaqa-validation-249", "mrqa_newsqa-validation-2749"], "SR": 0.640625, "CSR": 0.5162584459459459, "EFR": 0.9130434782608695, "Overall": 0.6848447598413632}, {"timecode": 74, "before_eval_results": {"predictions": ["Oakland", "Russell Stover", "hub", "franchiseise", "Maccabees", "Macbeth", "Ruben Studdard", "Scrabble", "Passover", "the masses", "China", "linebacker", "Talking Heads", "commune", "a ring", "Thames", "song", "hockey", "Hans Christian Andersen", "David", "The Color Purple", "whales", "Ellen Gates Starr", "Shakespeare", "Tanzania", "Biosphere", "an inch", "death", "Henry Wadsworth Longfellow", "Bill Clinton", "Geneva", "humility", "white", "Twelve Thirty", "Diatomaceous earth", "the debt ceiling", "Spider-Pig", "Lake Titicaca", "Existentialism", "ashes", "emperor", "Jack London", "Newton", "Charles I", "Kevin Costner", "Apocalypse Now", "clef", "uranium", "Louisiana", "happy madison", "composting", "2016", "April 2010", "four", "Spey", "Popeye", "Denmark", "Trappist beer", "4,530", "Tim Cluess", "between 1986 and 2007,", "Airbus A330-200", "Symbionese Liberation Army", "Manitowoc County, Wisconsin"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6953125}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13672", "mrqa_searchqa-validation-13469", "mrqa_searchqa-validation-5138", "mrqa_searchqa-validation-807", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-7751", "mrqa_searchqa-validation-7588", "mrqa_searchqa-validation-16632", "mrqa_searchqa-validation-378", "mrqa_searchqa-validation-13356", "mrqa_searchqa-validation-3988", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-7717", "mrqa_searchqa-validation-7708", "mrqa_searchqa-validation-3864", "mrqa_searchqa-validation-160", "mrqa_searchqa-validation-12518", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-7832", "mrqa_naturalquestions-validation-8909", "mrqa_newsqa-validation-1696"], "SR": 0.640625, "CSR": 0.5179166666666667, "EFR": 1.0, "Overall": 0.7025677083333334}, {"timecode": 75, "before_eval_results": {"predictions": ["September 19, 2017", "James Bolam", "the gated community of Pebble Beach", "a marketing term for a vehicle that is both four - wheel - drive and primarily a road car", "Turing", "B.F. Skinner", "hydrogen", "Spain", "William the Conqueror", "111", "1983", "Baker, California, USA", "a routing table", "Paul Hogan", "the 9th century", "Asuka", "Jason Momoa", "James Snyder", "the President", "Spanish missionaries", "Gustav Bauer", "art of the Persian Safavid dynasty from 1501 to 1722, in present - day Iran and Caucasia", "T cells", "2.45 billion years ago", "Yente", "March 31, 2017", "incudomalleolar joint", "Gina Tognoni", "the Gupta Empire", "a half - life of 10.756 years and a maximum decay energy of 687 keV", "a distinction", "the summer of 1979", "Charles Evans Hughes", "Spanish / Basque", "U.S. service members who have died without their remains being identified", "the winter of 1348 -- 49, but during the following winter it gave in, and by December 1349 conditions were returning to relative normalcy", "Glenn Close", "Schleiden and Schawnn", "the Detroit Tigers", "Joseph", "International System of Units", "Margaery Tyrell", "redox", "Bill Belichick", "Judi Dench", "Spanish moss", "Carol Ann Susi", "William DeVaughn", "Amybeth McNulty", "Staci Keanan", "United States", "green", "the underground organization of the Irish Republican Brotherhood", "Lakeland Fells", "1967", "Yubin, Yeeun", "The record now is 9.58 seconds", "sedative", "a missing sailor whose five Texas A&M University crew mates were hoisted out of the Gulf of Mexico earlier in the day after their sailboat capsized.", "'overcharged.'\"", "Dr. Hook & the Medicine Show", "Parkinson's Disease", "Patrick Henry", "Samuel Joel \"Zero\" Mostel"], "metric_results": {"EM": 0.5, "QA-F1": 0.5974039775616578}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, false, false, false, false, false, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.5, 0.4210526315789474, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 0.8, 1.0, 0.17391304347826084, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.08333333333333333, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9081", "mrqa_naturalquestions-validation-3363", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-438", "mrqa_naturalquestions-validation-919", "mrqa_naturalquestions-validation-9340", "mrqa_naturalquestions-validation-6634", "mrqa_naturalquestions-validation-3348", "mrqa_naturalquestions-validation-949", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-8257", "mrqa_naturalquestions-validation-3523", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6763", "mrqa_naturalquestions-validation-8004", "mrqa_naturalquestions-validation-7124", "mrqa_naturalquestions-validation-5634", "mrqa_naturalquestions-validation-3678", "mrqa_naturalquestions-validation-5605", "mrqa_naturalquestions-validation-7514", "mrqa_naturalquestions-validation-5820", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-6333", "mrqa_triviaqa-validation-2810", "mrqa_triviaqa-validation-4525", "mrqa_hotpotqa-validation-2232", "mrqa_newsqa-validation-3613", "mrqa_newsqa-validation-4008", "mrqa_newsqa-validation-2348", "mrqa_hotpotqa-validation-3909"], "SR": 0.5, "CSR": 0.5176809210526316, "EFR": 0.9375, "Overall": 0.6900205592105264}, {"timecode": 76, "before_eval_results": {"predictions": ["Tintoretto", "scotch", "repechage", "the Outer Hebrides", "Victoria Rowell", "Barcelona", "England", "chickens", "steerpike", "siegfried", "Bleak House", "four", "the Indus Valley", "photo-sharing website", "jaws", "cairoli", "The Hague", "Adidas", "Coldplay", "Jules Verne", "Switzerland", "basketball", "Elizabeth II", "conclave", "Patrick Kielty", "8 minutes", "jimmy lecroix", "Red Crescent", "Schumann", "Margaret Thatcher", "Only Fools and Horses", "Darius Danesh", "Andrew Lloyd Webber", "Bonn", "air marshal", "snakes", "the northeast coast of Australia's state of Queensland", "dernell DUNKELD", "Madonna", "a par-5 hole", "beer", "leg", "Ice Age: The meltdown", "Darwin", "Oliver Stone", "Bahrain", "jocky Wilson", "Emilia", "Hawley Harvey", "two", "1799", "1979", "1976", "The Gupta Empire", "a British actress and stunt performer", "2004", "Rwandan genocide", "Steve Williams", "winter storm", "a fight outside of an Atlanta strip club", "seasonal affective disorder", "a timing gun", "Vienna", "well over two decades."], "metric_results": {"EM": 0.5625, "QA-F1": 0.6388106684981685}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, true, true, false, true, false, false, true, false, false, false, false, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.30769230769230765, 1.0, 1.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_triviaqa-validation-6962", "mrqa_triviaqa-validation-371", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-6005", "mrqa_triviaqa-validation-1591", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-4124", "mrqa_triviaqa-validation-261", "mrqa_triviaqa-validation-1430", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6129", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-456", "mrqa_triviaqa-validation-1241", "mrqa_triviaqa-validation-6099", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-1839", "mrqa_triviaqa-validation-5015", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-509", "mrqa_triviaqa-validation-7666", "mrqa_triviaqa-validation-1278", "mrqa_triviaqa-validation-6645", "mrqa_triviaqa-validation-138", "mrqa_triviaqa-validation-3403", "mrqa_hotpotqa-validation-573", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-2116"], "SR": 0.5625, "CSR": 0.518262987012987, "EFR": 1.0, "Overall": 0.7026369724025974}, {"timecode": 77, "before_eval_results": {"predictions": ["end of the 18th century", "1801", "Captain Cook's Landing Place", "SG Wannabe, SeeYa,", "Helen Mirren", "ATX Television Festival", "Eldridge Industries, LLC", "Diamond Rio", "lola Dee", "Robert Moses", "UFC 50: The War of '04", "Barbara Ryan Coleman", "\"Places in the Heart\"", "24 hours a day and 7 days a week", "\"O\", \"La Nouba\", \"Myst\u00e8re\", \"Alegr\u00eda\", and \"Quidam\"", "Nobel Prize in Physics", "glee", "Paul Corbould", "his advocacy of young earth creationism and intelligent design", "2 November 1902", "December 1993", "orisha", "2006", "highest commissioned SS rank", "David Abelevich", "\"Loch Lomond\"", "National Football League", "brothers", "James Franco", "London", "Kelly Bundy", "British", "high Arctic tundra soil near Ny-\u00c5lesund in Norway", "followed his father into the Military Band of Hanover, before migrating to Great Britain in 1757 at the age of nineteen", "around 8000 BC", "2002\u201303", "Peter Seamus O'Toole", "The \"unofficial national anthem\"", "Leonarda Cianciulli", "baron Rawd Brewery", "Biola University", "drama", "response-oriented therapy", "the Lola team", "Park Seo-joon", "Mot\u00f6rhead", "Nassau County", "The New Grove Dictionary of Opera", "Arlo Looking Cloud", "Kristy Lee Cook", "Giacomo Puccini", "The programme was originally presented by Sue Perkins and Mel Giedroyc, with Mary Berry and Paul Hollywood the judges", "Mel Gibson", "1987", "San Francisco", "robert anderson", "Vancouver", "onto the college campus.", "$106,482,500", "15-year-old's", "cleopatra", "A&W", "the Strait of Hormuz", "tambourine"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5788621365047996}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, true, false, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.25, 0.6666666666666666, 1.0, 0.28571428571428575, 0.3636363636363636, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.34782608695652173, 1.0, 0.0, 0.8, 0.25, 1.0, 0.0, 1.0, 0.0, 0.5, 0.3333333333333333, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2100", "mrqa_hotpotqa-validation-5738", "mrqa_hotpotqa-validation-4484", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-1510", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2310", "mrqa_hotpotqa-validation-5712", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-3887", "mrqa_hotpotqa-validation-3469", "mrqa_hotpotqa-validation-984", "mrqa_hotpotqa-validation-5784", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3613", "mrqa_hotpotqa-validation-1901", "mrqa_hotpotqa-validation-2813", "mrqa_hotpotqa-validation-2744", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3299", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-2044", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-2784", "mrqa_hotpotqa-validation-650", "mrqa_naturalquestions-validation-8228", "mrqa_triviaqa-validation-6460", "mrqa_searchqa-validation-4417", "mrqa_searchqa-validation-5368", "mrqa_triviaqa-validation-6919"], "SR": 0.46875, "CSR": 0.5176282051282051, "EFR": 1.0, "Overall": 0.7025100160256411}, {"timecode": 78, "before_eval_results": {"predictions": ["the sidewalk between Division Street and East Broadway", "August 1991", "Nigel Lythgoe", "the presence of correctly oriented P waves on the electrocardiogram ( ECG )", "1956", "Atlanta, Georgia", "The management team", "Title XVIII", "1990", "Ali", "1979", "Pakistan", "Chesapeake Bay, south of Annapolis in Maryland", "the fascia surrounding skeletal muscle", "energy from light is absorbed by proteins called reaction centres that contain green chlorophyll pigments", "1947", "April 10, 2018", "external genitalia", "May 2017", "mid-1980s", "the S - stage of interphase", "1956", "between 8.7 % and 9.1 %", "minor key", "Divyanka Tripathi", "Newfoundland", "Germany", "31 December 1960", "The period of being junior doctor starts when they qualify as a medical practitioner following graduation with a Bachelor of Medicine, Bachelor of surgery degree and start the UK Foundation Programme", "pre-Christian festivals that were celebrated around the winter solstice", "1992", "George Strait", "All Hallows'Day", "November 1961", "midpiece", "2004", "$6.2 trillion", "7000301604928199000", "James Martin Lafferty", "near the city of Cairo, Illinois", "Sylvester Stallone", "pop ballad", "eusebeia", "Gene Barry", "Keith Thibodeaux", "March 16, 2018", "Roger Dean Stadium", "Dorothy Gale", "Alastair Cook", "military experts", "Andrew Lloyd Webber", "domestic cat", "Q", "peter Werritty", "twin-faced sheepskin with fleece on the inside", "5,922", "1866", "two", "2006", "nine", "Lake Superior", "River Thames", "Agnese Bonucci", "red"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6436118197278912}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.0, 0.5, 0.5714285714285715, 0.2222222222222222, 0.0, 1.0, 0.08163265306122448, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8998", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-916", "mrqa_naturalquestions-validation-6258", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-7009", "mrqa_naturalquestions-validation-2586", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-9774", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-9824", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-1538", "mrqa_naturalquestions-validation-9235", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-6577", "mrqa_naturalquestions-validation-2182", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-10495", "mrqa_triviaqa-validation-5102", "mrqa_hotpotqa-validation-1250", "mrqa_newsqa-validation-3297", "mrqa_searchqa-validation-3505", "mrqa_searchqa-validation-10079", "mrqa_searchqa-validation-1302"], "SR": 0.546875, "CSR": 0.517998417721519, "EFR": 1.0, "Overall": 0.7025840585443038}, {"timecode": 79, "before_eval_results": {"predictions": ["PEN America: A Journal for Writers and Readers", "Louisiana Superdome", "1858", "indie and metal", "Edison Koon-hei Chen", "1875", "The satirical News Network", "his most brilliant student", "Juilliard School", "2006 World Outgames", "1812", "Peach", "1885", "Oregon Ducks", "Victorian England", "The War of '04", "American", "superhuman abilities", "Alpine climate and landscapes, in particular for skiing and mountaineering", "Baudot code", "Rockhill Furnace, Pennsylvania", "Mark O'Connor", "Duval County, Florida", "42,972", "the Estadio Victoria", "Boston Celtics", "Aqua", "Sydney ( )", "NCAA Division I Football Bowl Subdivision", "motor ships", "Linux Format", "Shameless (U.S. TV series)", "between 1252 and 1259", "Father Dougal McGuire", "satirical erotic romantic comedy", "Armin Meiwes", "Curtis James Martin Jr.", "Julie 2", "Gambaga", "Northern Ireland", "comparable to the seven Wonders of the World", "1933", "1894", "London", "Bulgarian-Canadian", "James Mitchum", "Nick on Sunset", "Javed Miandad", "Swiss", "Trappist beer", "Abdul Razzak Yaqoob", "Cyanea capillata", "the Roman Empire", "Max", "smeagol", "Melbourne", "paddington Bear", "8,", "Muslim Eid-ul-Adha", "\"This is not something that anybody can reasonably anticipate,\"", "Richmond", "Venezuela", "the Stone Age", "\"I would ultimately be a better person and of more service in whatever doors God opened next in life if I stuck around to learn lessons rather than running and hiding down at the farm."], "metric_results": {"EM": 0.640625, "QA-F1": 0.7269797441672441}, "metric_results_detailed": {"EM": [false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false], "QA-F1": [0.4444444444444445, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.054054054054054064]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-1094", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-4352", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-3860", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-4981", "mrqa_hotpotqa-validation-2938", "mrqa_hotpotqa-validation-891", "mrqa_hotpotqa-validation-4430", "mrqa_hotpotqa-validation-3440", "mrqa_naturalquestions-validation-2794", "mrqa_triviaqa-validation-4753", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-983", "mrqa_newsqa-validation-4059"], "SR": 0.640625, "CSR": 0.51953125, "EFR": 1.0, "Overall": 0.702890625}, {"timecode": 80, "before_eval_results": {"predictions": ["a Roman official", "chardonnay", "'is business", "volleyball", "a 1982 hit rock song written and performed by American singer-songwriter John Mellencamp, then performing as \"John Cougar.\"", "hot springs", "the Philosopher's Stone", "Sony", "pro bono", "an American politician and businessman", "epitaphic", "Boq", "a dragon", "a Rattus rattus", "The Teaching and Education Division", "The Merry Wives of Windsor", "kowtow", "Mars", "Purple Finch", "Brazil", "Mars", "Jericho", "Jane Addams", "Dances with Wolves", "Punch", "Mountain Dew", "alchemy", "Lon Chaney", "passe", "a katzenjammer Kids", "Cuisinart", "travertine", "Bob Dole", "the Ross Ice Shelf", "director", "China", "a grizzly bear", "Pinocchio", "the Czech Republic", "The Phantom of the Opera", "aison", "Olympia", "Jodie Foster", "Cleopatra VII", "the Mummy", "White Fang", "a bollworm", "(Sir Thomas) Lipton", "Alfred Binet", "Islamabad", "Brett Favre", "June 3, 1937", "53", "comic", "Brazil", "Edinburgh", "gagra", "Watts", "University of California", "Saturday Night Live", "a Yemeni cleric and his personal assistant,", "tells stories of different women coping with breast cancer in five vignettes.", "autonomy", "Joanne Wheatley"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5829613095238095}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4389", "mrqa_searchqa-validation-4359", "mrqa_searchqa-validation-7913", "mrqa_searchqa-validation-1639", "mrqa_searchqa-validation-15638", "mrqa_searchqa-validation-750", "mrqa_searchqa-validation-2632", "mrqa_searchqa-validation-1684", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-8010", "mrqa_searchqa-validation-11547", "mrqa_searchqa-validation-12889", "mrqa_searchqa-validation-6924", "mrqa_searchqa-validation-10951", "mrqa_searchqa-validation-9625", "mrqa_searchqa-validation-910", "mrqa_searchqa-validation-15161", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8868", "mrqa_searchqa-validation-9116", "mrqa_searchqa-validation-9203", "mrqa_searchqa-validation-9622", "mrqa_searchqa-validation-5848", "mrqa_naturalquestions-validation-3476", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-4135", "mrqa_triviaqa-validation-1353", "mrqa_triviaqa-validation-4862", "mrqa_hotpotqa-validation-1868", "mrqa_newsqa-validation-813"], "SR": 0.53125, "CSR": 0.5196759259259259, "EFR": 1.0, "Overall": 0.7029195601851852}, {"timecode": 81, "before_eval_results": {"predictions": ["George Fox", "Tasmania", "Indonesia", "The Generation Game", "The Firm", "red hair", "fourteen", "Spanish", "georgia", "wren", "sows", "bread", "Turkey", "Anastasia Dobromyslova", "every ten years", "Matterhorn", "Lake Placid", "$50", "Liverpool", "the Count Basie Orchestra", "the 6th Borough", "an arch", "Knightsbridge", "Sharjah", "India", "Mallard", "bach", "apollo", "1963", "Bologna", "bear", "Coleraine", "georgia", "t Titus", "Addis Ababa", "speedway", "kidney", "Triumph", "chilis", "Mark Twain", "Doctor Who", "Yosemite", "Microsoft", "40", "the First World War", "passion fruit", "USS Thresher", "7", "Southampton", "about 1344", "Benedict XVI", "Jesse Triplett", "Orlando", "LED illuminated display", "41st", "Mel Blanc", "Mauthausen-Gusen", "entered the E.G. Buehrle Collection -- among the finest collections of Impressionist and post-Impressionist art in the world", "an antihistamine", "a Lion Among Men.", "Danny Elfman", "Bolivia", "a leap year", "Sam Elliott"], "metric_results": {"EM": 0.53125, "QA-F1": 0.5672400210084034}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, false, false, true, false, false, false, true, false, true, true, true, false, true, true, false, false, false, false, false, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, false, false, false, true, true, false, false, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 0.2857142857142857, 1.0, 1.0, 0.0, 0.11764705882352941, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3189", "mrqa_triviaqa-validation-5389", "mrqa_triviaqa-validation-6466", "mrqa_triviaqa-validation-7685", "mrqa_triviaqa-validation-524", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-4361", "mrqa_triviaqa-validation-2265", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-5449", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-277", "mrqa_triviaqa-validation-2492", "mrqa_triviaqa-validation-3421", "mrqa_triviaqa-validation-6166", "mrqa_triviaqa-validation-5322", "mrqa_triviaqa-validation-7054", "mrqa_triviaqa-validation-4212", "mrqa_triviaqa-validation-992", "mrqa_triviaqa-validation-1972", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-6078", "mrqa_naturalquestions-validation-754", "mrqa_hotpotqa-validation-2379", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-859", "mrqa_searchqa-validation-14665"], "SR": 0.53125, "CSR": 0.5198170731707317, "EFR": 0.9666666666666667, "Overall": 0.6962811229674797}, {"timecode": 82, "before_eval_results": {"predictions": ["Dissection", "1978", "2004 Paris Motor Show", "Grandmasters", "Virginia", "1,696", "Melville, NY", "Western Europe", "girls aged 11 to 18", "March 14, 2000", "Regional Rural Bank", "Tufts University", "Hammer", "Sir Christopher Wren PRS", "Isla de Xativa", "the gaoler's family", "Blue Origin", "Bruce R. Cook", "1953", "Ken Rutherford", "February 12, 2014", "Whoopi Goldberg", "5.3 million", "six", "a polypeptide chain", "Brady Haran", "Minette Walters", "Syracuse University", "three", "Florida Panthers", "2010", "Adelaide", "Juan Manuel Mata Garc\u00eda", "Malayalam", "Pittsburgh Steelers", "a species of artiodactyl mammal", "Vyd\u016bnas", "Free Range Films", "Orson Welles", "his role as a pedestrian", "the Kentucky Music Hall of Fame", "Taoiseach", "50th anniversary of the founding of the National Basketball Association (NBA)", "American", "the Corps of Discovery, with William Clark", "pubs, bars and restaurants", "Andrew Johnson", "Minnesota", "power directly or elect representatives from among themselves to form a governing body, such as a parliament", "illnesses", "T. J. Lavin", "the bank's own funds", "31 March 1909", "President Lyndon Johnson", "Celsius", "whooping cough", "Johannesburg", "North Korea's National Intelligence Service,", "Juri Kibuishi, 23, of Irvine,", "the sins of the members of the church,", "Superman", "eight", "90", "Edward VIII"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6187140065816537}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.35294117647058826, 0.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615385, 0.09090909090909091, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-1343", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-3388", "mrqa_hotpotqa-validation-1527", "mrqa_hotpotqa-validation-5187", "mrqa_hotpotqa-validation-2434", "mrqa_hotpotqa-validation-4647", "mrqa_hotpotqa-validation-4368", "mrqa_hotpotqa-validation-2678", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-4483", "mrqa_hotpotqa-validation-4366", "mrqa_hotpotqa-validation-4655", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-3625", "mrqa_hotpotqa-validation-2045", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-3084", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-4519", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-3591", "mrqa_searchqa-validation-5760"], "SR": 0.5625, "CSR": 0.5203313253012047, "EFR": 0.9642857142857143, "Overall": 0.6959077829173839}, {"timecode": 83, "before_eval_results": {"predictions": ["Graphite", "Riding in Cars with Boys", "Mantle & Maris", "Titanic", "a science", "John Edwards", "Graceland Mansion", "Cambodian Peak Mountain", "a dangerous speed", "Edward Murdstone", "Arnold Schwarzenegger", "\"Jabberwocky\"", "w", "a milk Archives", "\"Gump,\"", "The Ghost of Tom Joad", "Dracula", "Mauritania", "a blowpipe", "Fikkle Fame", "the chief monk of Tibetan Buddhism", "Italy", "Most Famous Political Convention Speeches", "animals", "Luther", "Coward", "Little Rock", "the Third Reich", "Dresden", "a flippant", "Arkansas", "Marcel Duchamp", "Siege Hero", "toilet paper", "Sesame seeds", "Iceland", "a nocturnal mammal", "a goat", "a honey bee", "Janet Reno", "a connecticut yankee in king arthur's court", "Gianlorenzo Bernini", "Essen", "Clover Hill", "Thailand", "knowledge of eternal life is a personal relationship", "a cereal industry", "Pamela Anderson", "Margaret Alexander Edwards", "Whitehorse", "Scott McClellan", "Edd Kimber", "six", "Jacqueline MacInnes Wood", "Twin sisters", "John", "Gargantua", "2017", "four", "Lester", "India", "1959", "two", "her abusive husband"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4828125}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15509", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-3958", "mrqa_searchqa-validation-1463", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-7313", "mrqa_searchqa-validation-7089", "mrqa_searchqa-validation-5021", "mrqa_searchqa-validation-13719", "mrqa_searchqa-validation-1133", "mrqa_searchqa-validation-14381", "mrqa_searchqa-validation-11361", "mrqa_searchqa-validation-252", "mrqa_searchqa-validation-6475", "mrqa_searchqa-validation-7801", "mrqa_searchqa-validation-1643", "mrqa_searchqa-validation-15669", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-9774", "mrqa_searchqa-validation-10171", "mrqa_searchqa-validation-15322", "mrqa_searchqa-validation-1585", "mrqa_searchqa-validation-285", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-11429", "mrqa_searchqa-validation-14643", "mrqa_searchqa-validation-14500", "mrqa_searchqa-validation-4806", "mrqa_searchqa-validation-13336", "mrqa_searchqa-validation-3314", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-11986", "mrqa_searchqa-validation-6866", "mrqa_naturalquestions-validation-8695", "mrqa_triviaqa-validation-430", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-3590"], "SR": 0.40625, "CSR": 0.5189732142857143, "EFR": 1.0, "Overall": 0.7027790178571429}, {"timecode": 84, "before_eval_results": {"predictions": ["St. Anthony", "a shed", "Cuisinart", "a lobule", "the Boston Massacre", "Honesty", "Simn Bolvar", "Little Red Riding Hood", "Abigail Adams", "Bank of America", "Cleopatra", "Colorado Springs", "a diamond", "Picasso", "Arlington House", "John Paul II", "the hood", "Ismene", "South Dakota", "natural selection", "Department of the Interior", "Cyrus the Younger", "the White King", "Schembechler", "Gucci", "Vermont", "a chimp", "an icon", "The Man in the Iron Mask", "New Zealand", "Vladivostok", "Phil of the Future", "Kenny G", "Uruguay", "The Island of Doctor Moreau", "an organ", "wheat", "tundra", "Peter Falk", "AARP", "Tiffany", "the flag", "grass", "the stiletto", "cheese", "Kentucky", "Bora Bora", "Titanic", "a physician", "the \"Fisherman\\'s ring\"", "RBI", "the forex market", "the Tin Woodman", "a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "British Airways", "Rome", "the ocean", "Disney California Adventure", "Acharacle", "New York City", "Now Zad in Helmand province, Afghanistan.", "Tuesday.", "fled Zimbabwe", "Azerbaijan"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7371365613553114}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, true, false, true, false, false, true, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.75, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.3333333333333333, 1.0, 0.9743589743589743, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14524", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-1570", "mrqa_searchqa-validation-4199", "mrqa_searchqa-validation-7727", "mrqa_searchqa-validation-5824", "mrqa_searchqa-validation-6954", "mrqa_searchqa-validation-2555", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-5039", "mrqa_searchqa-validation-15036", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2628", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-9464", "mrqa_searchqa-validation-16502", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-2876", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-2374", "mrqa_newsqa-validation-1793"], "SR": 0.65625, "CSR": 0.5205882352941176, "EFR": 1.0, "Overall": 0.7031020220588236}, {"timecode": 85, "before_eval_results": {"predictions": ["dogs", "The Little Old Lady", "Parahunt", "Samuel Langhorne Clemens", "Margaret Mitchell", "The Ultimate Cannes", "a hangover", "a endodontist", "a desktop microcomputer", "South Dakota", "Alex Cross", "Mabel Belle", "George B. McClellan", "Soundgarden", "Emperor Maximillian", "Superman", "Renee Graziano", "I.M. Pei", "Charlie", "states", "Norway", "Meriwether Lewis", "\"Where there is hatred, let me sow love... where there is despair, hope\"", "Steve McQueen", "The Firebird", "\"Sweet Home.... this song and the horn section(led by Rolling Stones sax-man Bobby Keys) help make", "Vietnam", "Hercules", "Mike Huckabee", "the Declaration of Independence", "Peter Sellers", "St Mark", "I'm Jon Stewart", "Howard Dean", "Pogo", "I Can't Help Myself", "Manitoba", "Madonna", "a turban", "Perseid", "Holstein", "sugar", "Plutarch", "dinosaurs", "Duncan", "Meyer Lansky", "Aqua Teen Hunger Force", "Winston Churchill", "Jayne Torvill and Christopher Dean", "a song", "\"I think, therefore I am\"", "the Kingdom of Serbia", "prophets and beloved religious leaders", "1987", "Toy Story", "Harriet Tubman", "The Great British Bake Off", "Hockey Club Davos", "Native American", "The Soloist", "Mildred,", "as he exercised in a park in a residential area of Mexico City,", "jobs", "Kristy Swanson"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6568520911654135}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, false, false, true, false, false, true, true, false, false, false, false, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.7499999999999999, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.8421052631578948, 0.125, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-295", "mrqa_searchqa-validation-9390", "mrqa_searchqa-validation-4518", "mrqa_searchqa-validation-8172", "mrqa_searchqa-validation-2328", "mrqa_searchqa-validation-2098", "mrqa_searchqa-validation-1382", "mrqa_searchqa-validation-6921", "mrqa_searchqa-validation-3006", "mrqa_searchqa-validation-9907", "mrqa_searchqa-validation-7163", "mrqa_searchqa-validation-1193", "mrqa_searchqa-validation-7365", "mrqa_searchqa-validation-645", "mrqa_searchqa-validation-3197", "mrqa_searchqa-validation-6557", "mrqa_searchqa-validation-15636", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-5829", "mrqa_searchqa-validation-43", "mrqa_searchqa-validation-12899", "mrqa_searchqa-validation-3999", "mrqa_searchqa-validation-2188", "mrqa_searchqa-validation-14158", "mrqa_naturalquestions-validation-2819", "mrqa_naturalquestions-validation-5105", "mrqa_hotpotqa-validation-3446", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-4042"], "SR": 0.53125, "CSR": 0.5207122093023255, "EFR": 1.0, "Overall": 0.7031268168604651}, {"timecode": 86, "before_eval_results": {"predictions": ["the cob", "Barbara Walters", "Europe and Asia", "hoover", "Robert Frost", "The Once and Future King", "coffee milk", "Frogs", "Knott\\'s Berry Farm", "Narnia", "Poland", "Frida Kahlo", "24", "Baroque", "the Constellations", "de Gaulle", "electrolyte", "Bernini", "Ovid", "Pablo Escobar", "Lincoln", "Anne Boleyn", "modificre", "Eyelids", "bank of America", "copper", "blackjack", "Kiss Me, Kate", "Corbett", "plutonium", "bismuthinite", "iron", "Amistad", "Robert Redford", "The Simpsons", "the Ladies Professional Golf Association (LPGA)", "Universal Studios Hollywood", "Russia", "Camembert", "Thetis took her little son to the river of Styx,", "red", "Sweden", "Shirley Jones", "Kashmir", "the Great Seal", "The Empire Strikes Back", "Nelson\\'s Column", "Billy Bob Thornton", "Clark", "lima beans", "Will & Grace", "the Octopus", "De Wayne Warren", "2017", "Venezuela", "The Coalminer's Daughter", "golf", "Dialogues des Carm\u00e9lites", "England", "66,900", "between June 20 and July 20.", "the syndicate, founded by software magnate", "FBI Special Agent Daniel Cain,", "Missouri River"], "metric_results": {"EM": 0.625, "QA-F1": 0.7131696428571428}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, true, false, true, true, false, false, true, true, false, true, false, true, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-1144", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-7115", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-813", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-15498", "mrqa_searchqa-validation-16059", "mrqa_searchqa-validation-14596", "mrqa_searchqa-validation-10482", "mrqa_searchqa-validation-14712", "mrqa_searchqa-validation-6484", "mrqa_searchqa-validation-13716", "mrqa_searchqa-validation-2081", "mrqa_searchqa-validation-5382", "mrqa_naturalquestions-validation-6903", "mrqa_naturalquestions-validation-9523", "mrqa_triviaqa-validation-7114", "mrqa_hotpotqa-validation-1763", "mrqa_hotpotqa-validation-38", "mrqa_newsqa-validation-2461"], "SR": 0.625, "CSR": 0.5219109195402298, "EFR": 1.0, "Overall": 0.703366558908046}, {"timecode": 87, "before_eval_results": {"predictions": ["Tufts University", "Ian Fleming", "the adrenal cortex", "the late 19th and early 20th centuries", "Tom Jones", "Park Sung-woong", "Bonnie Franklin", "Violet", "Exit 82", "\"Grimjack\" (from First Comics) and \"The Spectre\"", "\" Easy\"", "Dayton, Ohio", "Gareth Barry", "(n\u00e9e Munyiri)", "\"Bambi, a Life in the Woods\"", "1896", "The Apple iPod+HP", "2017", "The Timekeeper", "July 8, 2014", "Ben Ainslie", "torpedoes", "Dante", "Miami", "Boston Red Sox (Korean)", "Dutch", "Dallas/Fort Worth", "Tia Carrere", "four", "Jim Davis", "Kurt Vonnegut Jr.", "Labrador Retriever", "Gurgaon, Haryana", "1837", "Blackpool Football Club", "Diondre Cole", "DS Virgin Racing Formula E Team", "\"The Dangerous World of Butterflies\"", "1943", "Las Vegas", "Kim Yoon-seok and Ha Jung-woo", "August 11, 1946", "1885", "2015", "the Northrop F-15 Reporter (later RF-61)", "Gareth Barry", "Gambaga", "March 2012", "English", "\"Kingdom Hearts\"", "1978", "peroxidase", "a deboned chicken", "c. 3000 BC", "Robert Devereux", "Gary Oldman", "Alanis Morissette", "the Employee Free Choice Act", "\"peregruzka\"", "Port-au-Prince", "Wimbledon", "Brazil", "Rocky & Bullwinkle", "baseball"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6322916666666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, true, false, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.2, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-397", "mrqa_hotpotqa-validation-5109", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-1506", "mrqa_hotpotqa-validation-375", "mrqa_hotpotqa-validation-3046", "mrqa_hotpotqa-validation-5698", "mrqa_hotpotqa-validation-5149", "mrqa_hotpotqa-validation-3586", "mrqa_hotpotqa-validation-4023", "mrqa_hotpotqa-validation-4700", "mrqa_hotpotqa-validation-5879", "mrqa_hotpotqa-validation-4572", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-4259", "mrqa_hotpotqa-validation-993", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1900", "mrqa_hotpotqa-validation-983", "mrqa_naturalquestions-validation-5711", "mrqa_naturalquestions-validation-5058", "mrqa_naturalquestions-validation-902", "mrqa_triviaqa-validation-5805", "mrqa_triviaqa-validation-569", "mrqa_searchqa-validation-14393"], "SR": 0.5625, "CSR": 0.5223721590909092, "EFR": 1.0, "Overall": 0.7034588068181818}, {"timecode": 88, "before_eval_results": {"predictions": ["green and yellow", "the first to utilize Audio-Animatronics", "Continental Army", "1874", "Park Yong-gyu", "January 16, 2013", "James Taylor", "a multi-control USB mouse", "S Pictures' \"Veyyil\" (2006)", "Victoria", "Umina Beach", "from 1989 until 1994", "Adelaide Miethke", "Pensacola", "Consigliere", "\"Shadow of a Doubt\"", "7", "the Bologna Process", "Peoria, Illinois", "Indonesia", "Dick Ebersol", "Philip K. Dick", "University of Texas Longhorns football", "O", "\"An All-Colored Vaudeville Show\"", "the summer solstice", "German Shepherd", "The Vaudevillains", "Iftikhar Ali Khan", "Robert L. Stone", "Joseph E. Grosberg", "Bolton", "the Twist", "1,462", "Premier League", "Bob Zmuda", "Edward Albert Heimberger", "Wilmette", "Ford Island", "The Times Higher Education Guide", "Derry City", "Beverly Hills", "Boston", "two", "Black Mountain College", "47,818", "1970", "The International Imitation Hemingway Competition", "Coll\u00e8ge de France", "Norwegian", "Oklahoma State", "Akshay Kumar", "2015", "A diastema ( plural diastemata )", "Thames Street", "Tom Stoppard", "Brazil", "Dube attempted to escape but died almost instantly from his wounds.", "an average of 25 percent", "super-yacht designers", "a charcuterie", "Livin' On A Prayer", "the Electoral College", "josef kipling"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6517609126984127}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.16666666666666669, 0.4, 0.8, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5055", "mrqa_hotpotqa-validation-3637", "mrqa_hotpotqa-validation-3419", "mrqa_hotpotqa-validation-812", "mrqa_hotpotqa-validation-1711", "mrqa_hotpotqa-validation-714", "mrqa_hotpotqa-validation-2896", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5856", "mrqa_hotpotqa-validation-2212", "mrqa_hotpotqa-validation-3009", "mrqa_hotpotqa-validation-2390", "mrqa_hotpotqa-validation-2791", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-1874", "mrqa_hotpotqa-validation-1630", "mrqa_hotpotqa-validation-5450", "mrqa_hotpotqa-validation-5371", "mrqa_hotpotqa-validation-2606", "mrqa_hotpotqa-validation-4543", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-2211", "mrqa_triviaqa-validation-7063", "mrqa_newsqa-validation-592", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-1697", "mrqa_searchqa-validation-6483", "mrqa_triviaqa-validation-7531"], "SR": 0.53125, "CSR": 0.5224719101123596, "EFR": 1.0, "Overall": 0.703478757022472}, {"timecode": 89, "before_eval_results": {"predictions": ["Richard Masur", "bigfoot-like sightings", "World War II", "The United States presidential election of 2016", "Gilley's Club", "Levi Weeks", "Afghanistan", "Arvo P\u00e4rt", "The Simpsons", "First Street", "5249", "the Dutch Empire", "Black Swan", "Ready to Die", "October 20, 2017", "artiodactyl", "The Lord's Resistance Army", "1965", "1943", "National Collegiate Athletic Association (NCAA)", "1959", "1932", "Neighbourhoods", "Warsaw", "Ezeiza Partido", "Sesame Street", "Billund", "the University of Kentucky", "The Sun on Sunday", "The Good, the Bad, the Weird", "crafting and voting on legislation, helping to create a state budget, and legislative oversight over state agencies", "four-engine heavy bomber", "Australian", "Worcester County", "Polish", "Thored", "BBC Formula One", "11,163", "four", "Bernd Bertie", "Lismore", "EQT Plaza in Pittsburgh, Pennsylvania", "Panthera pardus", "Prudential Center", "ten", "Conservatorio Verdi", "north", "the State House in Augusta", "Anna Clyne", "1901", "1967", "UMBC", "May 3, 2005", "Barry Bonds", "josef truncale", "World War II", "George Santayana", "clearly label products that contain any of the most common allergens", "an annual road trip,", "102", "vinegar", "\"I didn't\" give up my intelligence\"", "saliva", "Venus Williams"], "metric_results": {"EM": 0.625, "QA-F1": 0.6531723484848484}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.45454545454545453, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3426", "mrqa_hotpotqa-validation-5509", "mrqa_hotpotqa-validation-729", "mrqa_hotpotqa-validation-330", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-484", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-757", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-675", "mrqa_hotpotqa-validation-4617", "mrqa_hotpotqa-validation-5773", "mrqa_hotpotqa-validation-2759", "mrqa_hotpotqa-validation-2947", "mrqa_hotpotqa-validation-2905", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-4336", "mrqa_triviaqa-validation-6118", "mrqa_newsqa-validation-3736", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-2161", "mrqa_searchqa-validation-12464", "mrqa_searchqa-validation-3153"], "SR": 0.625, "CSR": 0.5236111111111111, "EFR": 1.0, "Overall": 0.7037065972222223}, {"timecode": 90, "before_eval_results": {"predictions": ["endoskeletons", "Joaquin Phoenix", "rayon gold", "the scalp", "Harley-Davidson", "New Coke", "Abigail Adams", "staff", "University of Hawaii at Manoa", "the leg", "Cristina Yang", "The Omega Man", "vincent van Gogh", "an eruption", "Buffalo", "Alanis Morissette", "Paddington Bear", "bicentennial", "a skyscraper", "1953", "Edward R. Murrow", "Cheetah Rivera", "Casablanca", "seven", "Nike", "a buck", "Sweden", "Lamborghini", "1044a", "John Philip Sousa", "oregano", "New South Wales", "Amelia Moore Nation", "Ho Chi Minh", "Martha\\' Vineyard", "Wayne Gretzky", "apples", "Transformers: Earth Wars", "An American in Paris", "Taiwan", "Walt Disney Night", "Amma Air Group", "Donald Donald Scherzer", "Jim Corbett", "Michael Jackson", "Firebird", "Sicily", "Bill Frist", "a dollar", "apokrupha", "Hercule Poirot", "13 May 1787", "March 9, 2018", "Kristy Swanson", "2011", "poland", "Celebrity Big Brother", "Vishal Bhardwaj", "1990", "Big Machine Records", "a monthly allowance,", "Aung San Suu Kyi", "36", "achievement gaps between racial groups in the United States"], "metric_results": {"EM": 0.5, "QA-F1": 0.5625}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, false, false, true, true, true, true, true, false, true, true, true, true, false, false, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-10892", "mrqa_searchqa-validation-9836", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-12132", "mrqa_searchqa-validation-1326", "mrqa_searchqa-validation-9465", "mrqa_searchqa-validation-15381", "mrqa_searchqa-validation-10254", "mrqa_searchqa-validation-14230", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-3386", "mrqa_searchqa-validation-11867", "mrqa_searchqa-validation-1646", "mrqa_searchqa-validation-13193", "mrqa_searchqa-validation-5582", "mrqa_searchqa-validation-16070", "mrqa_searchqa-validation-9918", "mrqa_searchqa-validation-15715", "mrqa_searchqa-validation-6022", "mrqa_searchqa-validation-12002", "mrqa_searchqa-validation-11648", "mrqa_searchqa-validation-15877", "mrqa_searchqa-validation-3575", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-7354", "mrqa_searchqa-validation-12430", "mrqa_searchqa-validation-1958", "mrqa_naturalquestions-validation-9878", "mrqa_triviaqa-validation-4298", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-1938", "mrqa_newsqa-validation-1993"], "SR": 0.5, "CSR": 0.5233516483516483, "EFR": 1.0, "Overall": 0.7036547046703296}, {"timecode": 91, "before_eval_results": {"predictions": ["the Channel Tunnel", "Hawaii", "Crayola", "giant", "Sil silicone grease", "Jackson-Atkinson Candies", "Lake Ontario", "the word of the mind", "(A.)I.)L.D.)", "The Sound and the Fury", "Suez Canal", "Stephen Hawking", "Ecuador", "Palatine", "radio and television", "acetylene", "a scrapple", "Fred Thompson", "Ramayana", "Seth", "Benz", "Frottage", "Titanic", "Dr. Quinn", "slanting", "Cracker Jack", "Ford", "a high jump", "the phoenix", "Tuscany", "Alice", "Sid Vicious", "sand", "Monaco", "sausage", "Venison", "Florida", "a packer", "the Gifted", "the Andes", "Ovid", "1937", "Grendel", "CAVIAR", "ascomycota", "Dolley Madison", "James Fenimore Cooper", "Lost in America", "tentacles", "the sound barrier", "Cyprus", "traditional dance", "Nala", "Bart Cummings", "PDSA", "2.1", "kenjutsu", "Rawlings", "Adam Levine", "Syracuse", "Stuttgart", "The 36-year-old from Atlanta, Georgia, said he tried to convert his analog TV to digital", "legislation that would let prisons jam cell-phone signals within their walls.", "Bed and breakfast"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6018229166666667}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, true, false, false, true], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.25, 0.19999999999999998, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12065", "mrqa_searchqa-validation-11921", "mrqa_searchqa-validation-16089", "mrqa_searchqa-validation-10891", "mrqa_searchqa-validation-15688", "mrqa_searchqa-validation-12800", "mrqa_searchqa-validation-12390", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-8832", "mrqa_searchqa-validation-1687", "mrqa_searchqa-validation-15440", "mrqa_searchqa-validation-7773", "mrqa_searchqa-validation-15924", "mrqa_searchqa-validation-4787", "mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-1338", "mrqa_searchqa-validation-16575", "mrqa_searchqa-validation-3687", "mrqa_searchqa-validation-5164", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-854", "mrqa_naturalquestions-validation-9897", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-6932", "mrqa_hotpotqa-validation-1014", "mrqa_newsqa-validation-1425", "mrqa_newsqa-validation-692"], "SR": 0.5625, "CSR": 0.5237771739130435, "EFR": 1.0, "Overall": 0.7037398097826087}, {"timecode": 92, "before_eval_results": {"predictions": ["salivary glands", "Carrie Meeber", "the Sharia", "yente", "the jaw", "a referendum", "alfalfa", "Phaedra", "Franklin D. Roosevelt", "Kurt Vonnegut", "Alice Walker", "As I Lay Dying", "(Daniel)", "Australia", "Mozart", "air", "Abu Musab al-Zarqawi", "Phil of the Future", "the velocity", "The Secret", "an acre", "ancora", "Benjamin Harrison", "William Conrad", "(Harold) Ulrich", "the burning bush", "a gastropod", "Indian tribes", "Australia", "ER", "Le djeuner sur l'herbe", "Finding Nemo", "Frdric Chopin", "a calculator", "Donna Mills", "Amman", "Van Halen", "the Permanent Select Committee on Intelligence", "amyotrophic lateral sclerosis", "a coconut", "Nancy Lopez", "The Magic Mountain", "Hudson\\'s Bay", "Beguile", "Hoosier", "the house of prayer", "a loaf of bread", "a mead", "the Mossad", "a menagerie", "an aide", "Judiththia Aline Keppel", "two - stroke engines and chain drive", "Those Comanche people are federally recognized as the Comanche Nation, headquartered in Lawton, Oklahoma", "plutocracy", "de Goya", "Laughing my panicked *a* off", "Panther", "paracyclist", "The 2007 Summer Universiade", "Those have complained that his wins are too routine, and purists grouse that he does not poses the quality of \"hinkaku,\"", "The planned Kingdom City project", "to secure more funds from the region.", "six-time"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6006030701754386}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, false, true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, false, true, true, false, true, true, true, true, true, false, false, false, true, true, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.5714285714285715, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.10526315789473684, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.8571428571428571, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5474", "mrqa_searchqa-validation-9791", "mrqa_searchqa-validation-16477", "mrqa_searchqa-validation-8180", "mrqa_searchqa-validation-16574", "mrqa_searchqa-validation-7695", "mrqa_searchqa-validation-13136", "mrqa_searchqa-validation-12806", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-12924", "mrqa_searchqa-validation-9061", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-10532", "mrqa_searchqa-validation-1824", "mrqa_searchqa-validation-14833", "mrqa_searchqa-validation-5866", "mrqa_searchqa-validation-4268", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-15267", "mrqa_searchqa-validation-14917", "mrqa_searchqa-validation-9804", "mrqa_searchqa-validation-6365", "mrqa_searchqa-validation-9730", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-129", "mrqa_triviaqa-validation-6160", "mrqa_hotpotqa-validation-1786", "mrqa_newsqa-validation-1122", "mrqa_newsqa-validation-744", "mrqa_newsqa-validation-574"], "SR": 0.515625, "CSR": 0.5236895161290323, "EFR": 1.0, "Overall": 0.7037222782258065}, {"timecode": 93, "before_eval_results": {"predictions": ["the Department of Labor", "Standard Oil", "Lima", "English", "archbishop", "Clark", "India", "the Carpenters", "Wyoming", "Mary", "the Crimean War", "a passe de deux", "a thermostat", "Hasty", "a sapphire", "florida", "Wipers", "grace", "a LX", "the most recent Davis Cup Nations Ranking from Group III of its Zone", "Blackbeard", "William of Orange", "Emily Dickinson", "a parabola", "Simon Wiesenthal", "Mercury and Venus", "Conrad Hilton", "San Diego", "a quadrille", "We Own the Night", "spontaneous", "Charles Dickens", "All Hallows", "apples & oranges", "the Kuiper Belt", "Apple", "Scream", "The Goonies", "American Bandstand", "a Tacos", "Target", "curds and whey", "Mozambique", "Howie Mandel", "a bat", "Munich", "Lance Armstrong", "Jimmy Carter", "Barbara Cartland", "Sir Walter Scott", "the War of the Worlds", "January 17, 1899", "when a population temporarily exceeds the long term carrying capacity of its environment", "about 13,000 astronomical units ( 0.21 ly )", "Betty", "Whisky Galore", "Elizabeth Taylor", "Emad Hashim", "Marika Nicolette Green", "Anita Dobson", "NATO's Membership Action Plan,", "a cancerous tumor.", "in the Bundesliga,", "Quinton Murphy"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7523809523809524}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-10246", "mrqa_searchqa-validation-11499", "mrqa_searchqa-validation-1407", "mrqa_searchqa-validation-897", "mrqa_searchqa-validation-12423", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14358", "mrqa_searchqa-validation-8187", "mrqa_searchqa-validation-5301", "mrqa_searchqa-validation-15608", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-16697", "mrqa_searchqa-validation-3584", "mrqa_naturalquestions-validation-8832", "mrqa_triviaqa-validation-6109", "mrqa_newsqa-validation-852", "mrqa_newsqa-validation-3138", "mrqa_hotpotqa-validation-751"], "SR": 0.703125, "CSR": 0.5255984042553192, "EFR": 1.0, "Overall": 0.704104055851064}, {"timecode": 94, "before_eval_results": {"predictions": ["assassination", "fever", "dinosaurs", "Janet Reno", "Harvard University", "Don Quixote", "The Turn of the Screw", "David Lynch", "(shepherds)", "pine", "(Wild) Hickok", "2D", "nuclear", "vodka", "lava", "the anthrax", "Jamaica", "Sacher Torte", "Hillary Clinton", "a coyote", "CVS (pharmacy)", "Sulfur", "the slave", "(Jean) Marquette", "occola", "Hannibal Lecter", "nucleus", "Thomas Jefferson", "a millimeter", "Megan Fox", "Philip", "event", "the Battle of the Little Bighorn", "Marie Curie", "the Russian Blue", "The Graduate", "Nebraska", "\"E-T\"", "lemon", "John", "(SUN) SNIFFED", "a green substance", "a listing", "Toyota", "Scout (Scout) Finch", "Iran", "the Dark Knight", "Pulp Fiction", "Mao Zedong", "Neptune", "the Triassic", "seven", "the therefore sign ( \u2234 ) is generally used before a logical consequence, such as the conclusion of a syllogism", "Mike Leeson", "Sir Giles Gilbert Scott", "Andrew Jackson", "athletics", "HackThis Site", "\"Traumnovelle\"", "1985", "Manuel Mejia Munera", "seven", "Six", "for a generator to fall apart and grind to a halt after a computer attack on its control system."], "metric_results": {"EM": 0.484375, "QA-F1": 0.5726384575569359}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.42857142857142855, 1.0, 1.0, 0.08695652173913043]}}, "before_error_ids": ["mrqa_searchqa-validation-5870", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-13563", "mrqa_searchqa-validation-11698", "mrqa_searchqa-validation-16102", "mrqa_searchqa-validation-14178", "mrqa_searchqa-validation-1093", "mrqa_searchqa-validation-6591", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-4784", "mrqa_searchqa-validation-12902", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-4855", "mrqa_searchqa-validation-9813", "mrqa_searchqa-validation-9516", "mrqa_searchqa-validation-7318", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-7314", "mrqa_searchqa-validation-4989", "mrqa_searchqa-validation-15871", "mrqa_searchqa-validation-10162", "mrqa_searchqa-validation-9179", "mrqa_searchqa-validation-16419", "mrqa_searchqa-validation-7292", "mrqa_searchqa-validation-97", "mrqa_searchqa-validation-8685", "mrqa_searchqa-validation-4661", "mrqa_searchqa-validation-16305", "mrqa_searchqa-validation-11462", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-5124", "mrqa_newsqa-validation-873", "mrqa_newsqa-validation-3607"], "SR": 0.484375, "CSR": 0.5251644736842105, "EFR": 1.0, "Overall": 0.7040172697368421}, {"timecode": 95, "before_eval_results": {"predictions": ["Beethoven", "Eleanor Rigby", "a genie", "the cassowary", "Robbie Turner", "a palette", "ice cream", "Cherry", "Tajikistan", "Theology", "Forrest Gump", "a piles foundation", "a hot dog", "Anthony", "Dixie", "Alfred Nobel", "Karen Blixen", "Germantown", "Sinbad", "the ziggurat", "the toe", "private research university", "The War of the Worlds", "Achilles", "Steve Jobs", "David Box", "a manwich", "salinity", "Caesar", "Jane Grey", "Eugene V. Debs", "California (31)", "Troy", "Antoinette Perry", "The Crucible", "the rabbit", "Battlestar Galactica", "Rugby School", "Titan", "Francis", "Samuel", "Arthur Miller", "Billie Holiday", "Seal", "improv", "Scrabble", "1997", "a raccoon", "Jammu and Kashmir", "Barbary Coast", "baboons", "Bill Belichick", "a permanent, fast - drying painting medium", "Reverend J. Long", "bridge", "Sahara", "cheese, \u201cspecial sauce\u201d (a variant of Thousand Island dressing)", "BBC", "FIFA Women\\' World Cup", "Great Lakes and Midwestern", "St. Louis, Missouri,", "nearly three out of four", "2002", "\"bad taste\""], "metric_results": {"EM": 0.609375, "QA-F1": 0.6967013888888889}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.1, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.888888888888889, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-7411", "mrqa_searchqa-validation-16243", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-11075", "mrqa_searchqa-validation-15371", "mrqa_searchqa-validation-8500", "mrqa_searchqa-validation-2360", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-4748", "mrqa_searchqa-validation-7264", "mrqa_searchqa-validation-4660", "mrqa_searchqa-validation-11923", "mrqa_searchqa-validation-12185", "mrqa_searchqa-validation-15461", "mrqa_searchqa-validation-16710", "mrqa_searchqa-validation-1640", "mrqa_searchqa-validation-9029", "mrqa_searchqa-validation-5472", "mrqa_naturalquestions-validation-10403", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-7707", "mrqa_hotpotqa-validation-257", "mrqa_newsqa-validation-621", "mrqa_newsqa-validation-1297", "mrqa_newsqa-validation-2950"], "SR": 0.609375, "CSR": 0.5260416666666667, "EFR": 1.0, "Overall": 0.7041927083333335}, {"timecode": 96, "before_eval_results": {"predictions": ["February 7, 2018", "Donna Reed", "InterContinental Hotels & Resorts", "Kaley Christine Cuoco", "1877", "`` Everywhere ''", "T.S. Eliot", "based on sovereign states", "30 October 1918", "St. Augustine", "Meri", "Peggy Lipton", "Nicole Gale Anderson", "Tiffany Adams Coyne", "a region in Greek mythology", "Randy Watson", "2 September 1990", "Ben Savage", "Genoese merchant sailor Manuel Pessanha ( Pesagno )", "`` The Star Spangled Banner ''", "Thomas Stone", "meaning `` save, rescue, savior ''", "the Canadian Rockies", "March 11, 2018", "Khrushchev", "Addie Horton", "International Border ( IB )", "Acy lostoma duodenale", "the Scenic Highway between Gananoque and Brockville", "Wakanda", "a warrior, Mage, or rogue coming from an elven, human, or dwarfven background", "during a game in 1988", "the Continental tropical ( north easterlies )", "Confederate", "Majandra Delfino", "September 19, 2017", "a convergent plate boundary", "in ancient Mesopotamia", "the fictional Iron River Ranch in the fictitious small town of Garrison, Colorado", "13", "Matt Monro", "Bill Russell", "Krypton", "May 2017", "31 December 1960", "October 22, 2017", "Mahatma Gandhi", "1913", "1985", "long - distance two - way communications", "around 1940", "Sid Vicious", "Apocalypse Now", "Gower", "11,163", "Jaguar Land Rover", "was an Indian cricketer and former captain of the Indian cricket team", "propofol,", "Courtney Love,", "near his Seattle home.", "score", "East of Eden", "Andes", "1919"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6030495546120547}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, false, true, false, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, true, true, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.28571428571428575, 0.2857142857142857, 0.9090909090909091, 0.46153846153846156, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.07142857142857142, 1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-9866", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-4462", "mrqa_naturalquestions-validation-9939", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-5951", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-10615", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-1975", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-3066", "mrqa_hotpotqa-validation-4364", "mrqa_newsqa-validation-1961", "mrqa_searchqa-validation-13115", "mrqa_searchqa-validation-457", "mrqa_triviaqa-validation-6451"], "SR": 0.515625, "CSR": 0.5259342783505154, "EFR": 0.967741935483871, "Overall": 0.6977196177668773}, {"timecode": 97, "before_eval_results": {"predictions": ["Blue laws", "Dr. Sachchidananda Sinha", "2001 -- 2002", "New England", "2007", "two reservoirs in the eastern Catskill Mountains", "from the 1960s to the mid-1970s", "Bart Cummings", "Billie `` The Blue Bear ''", "Arnold Schoenberg", "1526", "mindfulness", "Panzerkampfwagen VIII Maus", "A status line which includes the status code and reason message ( e.g., HTTP / 1.1 200 OK, which indicates that the client's request succeeded )", "Ian Hart", "friends selected for Phone - a- friend are alerted when their contestant begins to play the main game, and are told to keep the phone free and to wait for three rings before answering", "in the 1898 Treaty of Paris", "Massachusetts", "Rocinante", "Paul Hogan", "360", "since 3, 1, and 4 are the first three significant digits of \u03c0", "a major fall in stock prices", "Patricia Field", "Human fertilization", "senators", "a man called Lysander", "a combination of Shakespearean actresses and car salespeople", "Procol Harum", "2018", "William Shakespeare", "James Rodr\u00edguez", "a nitrogenous base, a five - carbon sugar ( ribose or deoxyribose ), and at least one phosphate group", "Hathi Jr", "interstitial and intravascular compartments", "1980", "Instagram", "Revelation was the last book accepted into the Christian biblical canon", "in the pachytene stage of prophase I of meiosis during a process called synapsis", "Qutab Ud - Din - Aibak", "difficulties of the pulmonary circulation, such as pulmonary hypertension or pulmonic stenosis", "Robert Jordan", "Michael Phelps", "Don McMillan", "German decision was not made or approved by the civilian government in Berlin, the by the military commanders and the Kaiser", "Taylor Morshower", "April 29, 2009", "Laodicea", "Gibraltar", "red, white, and blue", "to a domestic cause, aiding victims of Hurricane Katrina", "Salt Lake City", "Schengen Area", "Arnold Palmer", "1 September 1864", "Tom Ince", "Katarina Witt", "At least 38", "\"The Da Vinci Code\"", "Diana Krall", "Brave New World", "a phobia", "cryogenics", "a anxiety disorder"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5734644337395696}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, true, false, false, true, false, true, false, false, false, true, true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true], "QA-F1": [1.0, 0.3333333333333333, 0.8, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.26666666666666666, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.0, 0.12500000000000003, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.36363636363636365, 0.0, 0.4, 0.3636363636363636, 0.9565217391304348, 1.0, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8326", "mrqa_naturalquestions-validation-9953", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-1791", "mrqa_naturalquestions-validation-6453", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-3808", "mrqa_naturalquestions-validation-644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-1799", "mrqa_naturalquestions-validation-8950", "mrqa_naturalquestions-validation-5804", "mrqa_naturalquestions-validation-839", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-3261", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-7502", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7035", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-5405", "mrqa_naturalquestions-validation-10182", "mrqa_naturalquestions-validation-6638", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-564", "mrqa_naturalquestions-validation-5611", "mrqa_naturalquestions-validation-4641", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-3568", "mrqa_hotpotqa-validation-4992", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-786"], "SR": 0.453125, "CSR": 0.5251913265306123, "EFR": 0.9142857142857143, "Overall": 0.6868797831632654}, {"timecode": 98, "before_eval_results": {"predictions": ["William Corcoran Eustis", "Hong Kong Disneyland", "American actress", "Gene Serdena", "Rockbridge County", "Mumbai, Maharashtra", "Savannah", "\"Perfect Strangers,\"", "public", "Nelson County", "video game", "\"boundary river\"", "John Lennon/Plastic Ono Band", "15,000 people for basketball matches and 15,500 for concerts (with standing public ramp)", "alcoholic drinks for consumption on the premises", "\"The Simpsons 138th Episode Spectacular\"", "Puente Hills Mall", "neo-Nazi", "Hugh Michael Horace Dancy", "Bisexuality", "Adam Dawes", "early 17th-century", "Steven Selling", "Chief of the Operations Staff of the Armed Forces High Command", "18 December 1975", "Target Corporation", "Sofia the First", "playback singer, director, writer and producer", "Australian", "1968", "Longford Town", "Dirk Werner Nowitzki", "the highland regions of Scotland", "Kansas Jayhawks football team", "London", "Timothy Dalton", "2000", "Valley Falls", "Klasky Csupo", "The Hungry", "Russian film industry", "2008", "the full 24 hours", "John R. Leonetti", "2009", "Anthony Lynn", "Samuel Beckett's \"Eleuth\u00e9ria\"", "Bay Ridge, Brooklyn", "Amii Anne J. Grove", "their unusual behavior", "1952", "to start fires, hunt, and bury their dead", "`` 200 ''", "Dmitri Mendeleev", "honda", "Utah", "Moby Dick", "the train in front had stopped behind another train undergoing service and awaited directions to stop,\"", "More than 22 million people in sub-Saharan Africa are infected with HIV,", "to host the Olympic Games in Rio de Janeiro.", "\"Free Bird\"", "Great Expectations", "Jason Bourne", "lizards"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6812161796536796}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, false, true, false, false, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 0.5, 0.0, 0.28571428571428575, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0, 0.0, 0.4, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-260", "mrqa_hotpotqa-validation-26", "mrqa_hotpotqa-validation-3620", "mrqa_hotpotqa-validation-3672", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-2436", "mrqa_hotpotqa-validation-745", "mrqa_hotpotqa-validation-1155", "mrqa_hotpotqa-validation-1283", "mrqa_hotpotqa-validation-4774", "mrqa_hotpotqa-validation-1127", "mrqa_hotpotqa-validation-4172", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-4863", "mrqa_hotpotqa-validation-3595", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-1703", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2375", "mrqa_hotpotqa-validation-961", "mrqa_hotpotqa-validation-1650", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-7733", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-1668"], "SR": 0.59375, "CSR": 0.5258838383838385, "EFR": 1.0, "Overall": 0.7041611426767677}, {"timecode": 99, "UKR": 0.646484375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1091", "mrqa_hotpotqa-validation-1120", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-1192", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-1211", "mrqa_hotpotqa-validation-1262", "mrqa_hotpotqa-validation-1306", "mrqa_hotpotqa-validation-1309", "mrqa_hotpotqa-validation-1316", "mrqa_hotpotqa-validation-1335", "mrqa_hotpotqa-validation-1344", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1450", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-1560", "mrqa_hotpotqa-validation-1563", "mrqa_hotpotqa-validation-1600", "mrqa_hotpotqa-validation-1631", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1696", "mrqa_hotpotqa-validation-1751", "mrqa_hotpotqa-validation-1771", "mrqa_hotpotqa-validation-1803", "mrqa_hotpotqa-validation-1817", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1858", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1899", "mrqa_hotpotqa-validation-1968", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1997", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-2298", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-2445", "mrqa_hotpotqa-validation-250", "mrqa_hotpotqa-validation-2518", "mrqa_hotpotqa-validation-2540", "mrqa_hotpotqa-validation-2631", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-2656", "mrqa_hotpotqa-validation-2658", "mrqa_hotpotqa-validation-2732", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-2855", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3003", "mrqa_hotpotqa-validation-3088", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-3114", "mrqa_hotpotqa-validation-3130", "mrqa_hotpotqa-validation-3131", "mrqa_hotpotqa-validation-3294", "mrqa_hotpotqa-validation-337", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3393", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3462", "mrqa_hotpotqa-validation-3474", "mrqa_hotpotqa-validation-3556", "mrqa_hotpotqa-validation-36", "mrqa_hotpotqa-validation-3716", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-38", "mrqa_hotpotqa-validation-381", "mrqa_hotpotqa-validation-383", "mrqa_hotpotqa-validation-3994", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4006", "mrqa_hotpotqa-validation-4153", "mrqa_hotpotqa-validation-4221", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-431", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-439", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-4446", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4504", "mrqa_hotpotqa-validation-451", "mrqa_hotpotqa-validation-4595", "mrqa_hotpotqa-validation-4651", "mrqa_hotpotqa-validation-4720", "mrqa_hotpotqa-validation-4758", "mrqa_hotpotqa-validation-4766", "mrqa_hotpotqa-validation-4786", "mrqa_hotpotqa-validation-482", "mrqa_hotpotqa-validation-4860", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-4901", "mrqa_hotpotqa-validation-4933", "mrqa_hotpotqa-validation-5237", "mrqa_hotpotqa-validation-5239", "mrqa_hotpotqa-validation-5253", "mrqa_hotpotqa-validation-5256", "mrqa_hotpotqa-validation-526", "mrqa_hotpotqa-validation-5265", "mrqa_hotpotqa-validation-5293", "mrqa_hotpotqa-validation-5315", "mrqa_hotpotqa-validation-5345", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-5460", "mrqa_hotpotqa-validation-5601", "mrqa_hotpotqa-validation-5610", "mrqa_hotpotqa-validation-5653", "mrqa_hotpotqa-validation-5699", "mrqa_hotpotqa-validation-5793", "mrqa_hotpotqa-validation-5880", "mrqa_hotpotqa-validation-5881", "mrqa_hotpotqa-validation-5898", "mrqa_hotpotqa-validation-698", "mrqa_hotpotqa-validation-774", "mrqa_hotpotqa-validation-861", "mrqa_naturalquestions-validation-10172", "mrqa_naturalquestions-validation-10490", "mrqa_naturalquestions-validation-114", "mrqa_naturalquestions-validation-1426", "mrqa_naturalquestions-validation-1435", "mrqa_naturalquestions-validation-1479", "mrqa_naturalquestions-validation-1649", "mrqa_naturalquestions-validation-1680", "mrqa_naturalquestions-validation-1925", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-2222", "mrqa_naturalquestions-validation-2688", "mrqa_naturalquestions-validation-2690", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-312", "mrqa_naturalquestions-validation-3143", "mrqa_naturalquestions-validation-3404", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3492", "mrqa_naturalquestions-validation-3538", "mrqa_naturalquestions-validation-3553", "mrqa_naturalquestions-validation-3729", "mrqa_naturalquestions-validation-3768", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-3961", "mrqa_naturalquestions-validation-4033", "mrqa_naturalquestions-validation-4079", "mrqa_naturalquestions-validation-4212", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-4435", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-47", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5022", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5288", "mrqa_naturalquestions-validation-5330", "mrqa_naturalquestions-validation-5454", "mrqa_naturalquestions-validation-5682", "mrqa_naturalquestions-validation-5722", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5983", "mrqa_naturalquestions-validation-6550", "mrqa_naturalquestions-validation-6821", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-7240", "mrqa_naturalquestions-validation-7333", "mrqa_naturalquestions-validation-7447", "mrqa_naturalquestions-validation-7486", "mrqa_naturalquestions-validation-7750", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7929", "mrqa_naturalquestions-validation-8006", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-835", "mrqa_naturalquestions-validation-8554", "mrqa_naturalquestions-validation-861", "mrqa_naturalquestions-validation-8657", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-9324", "mrqa_naturalquestions-validation-951", "mrqa_naturalquestions-validation-9523", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-11", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-129", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1306", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1352", "mrqa_newsqa-validation-1546", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1580", "mrqa_newsqa-validation-1600", "mrqa_newsqa-validation-1617", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1717", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-1843", "mrqa_newsqa-validation-1844", "mrqa_newsqa-validation-1867", "mrqa_newsqa-validation-1894", "mrqa_newsqa-validation-1993", "mrqa_newsqa-validation-2047", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-22", "mrqa_newsqa-validation-2327", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2459", "mrqa_newsqa-validation-2497", "mrqa_newsqa-validation-2538", "mrqa_newsqa-validation-2653", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2749", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-294", "mrqa_newsqa-validation-2981", "mrqa_newsqa-validation-3001", "mrqa_newsqa-validation-3175", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-3435", "mrqa_newsqa-validation-3439", "mrqa_newsqa-validation-3470", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-3554", "mrqa_newsqa-validation-3666", "mrqa_newsqa-validation-3731", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3802", "mrqa_newsqa-validation-3838", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3931", "mrqa_newsqa-validation-3946", "mrqa_newsqa-validation-3981", "mrqa_newsqa-validation-4006", "mrqa_newsqa-validation-4059", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-479", "mrqa_newsqa-validation-647", "mrqa_newsqa-validation-670", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-771", "mrqa_newsqa-validation-85", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-940", "mrqa_searchqa-validation-10092", "mrqa_searchqa-validation-10145", "mrqa_searchqa-validation-10167", "mrqa_searchqa-validation-1033", "mrqa_searchqa-validation-10377", "mrqa_searchqa-validation-10516", "mrqa_searchqa-validation-10672", "mrqa_searchqa-validation-11150", "mrqa_searchqa-validation-11184", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-11465", "mrqa_searchqa-validation-11467", "mrqa_searchqa-validation-11539", "mrqa_searchqa-validation-11691", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-11900", "mrqa_searchqa-validation-12079", "mrqa_searchqa-validation-12198", "mrqa_searchqa-validation-12220", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12322", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12408", "mrqa_searchqa-validation-12676", "mrqa_searchqa-validation-12770", "mrqa_searchqa-validation-13486", "mrqa_searchqa-validation-13550", "mrqa_searchqa-validation-1372", "mrqa_searchqa-validation-13751", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-13917", "mrqa_searchqa-validation-13945", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-14166", "mrqa_searchqa-validation-14208", "mrqa_searchqa-validation-14263", "mrqa_searchqa-validation-14414", "mrqa_searchqa-validation-1461", "mrqa_searchqa-validation-14692", "mrqa_searchqa-validation-14797", "mrqa_searchqa-validation-14810", "mrqa_searchqa-validation-1512", "mrqa_searchqa-validation-15162", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-15584", "mrqa_searchqa-validation-15776", "mrqa_searchqa-validation-15790", "mrqa_searchqa-validation-15983", "mrqa_searchqa-validation-16182", "mrqa_searchqa-validation-16464", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-16567", "mrqa_searchqa-validation-2092", "mrqa_searchqa-validation-211", "mrqa_searchqa-validation-2193", "mrqa_searchqa-validation-2362", "mrqa_searchqa-validation-2478", "mrqa_searchqa-validation-25", "mrqa_searchqa-validation-2593", "mrqa_searchqa-validation-2883", "mrqa_searchqa-validation-2903", "mrqa_searchqa-validation-2942", "mrqa_searchqa-validation-3027", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-3397", "mrqa_searchqa-validation-3605", "mrqa_searchqa-validation-3713", "mrqa_searchqa-validation-3796", "mrqa_searchqa-validation-3975", "mrqa_searchqa-validation-4033", "mrqa_searchqa-validation-4077", "mrqa_searchqa-validation-4134", "mrqa_searchqa-validation-4473", "mrqa_searchqa-validation-45", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-4758", "mrqa_searchqa-validation-4830", "mrqa_searchqa-validation-5069", "mrqa_searchqa-validation-5173", "mrqa_searchqa-validation-5174", "mrqa_searchqa-validation-5296", "mrqa_searchqa-validation-5444", "mrqa_searchqa-validation-5804", "mrqa_searchqa-validation-5828", "mrqa_searchqa-validation-5996", "mrqa_searchqa-validation-613", "mrqa_searchqa-validation-6177", "mrqa_searchqa-validation-6195", "mrqa_searchqa-validation-6452", "mrqa_searchqa-validation-6457", "mrqa_searchqa-validation-6514", "mrqa_searchqa-validation-6687", "mrqa_searchqa-validation-6746", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-6792", "mrqa_searchqa-validation-7002", "mrqa_searchqa-validation-7213", "mrqa_searchqa-validation-7869", "mrqa_searchqa-validation-7875", "mrqa_searchqa-validation-7937", "mrqa_searchqa-validation-8175", "mrqa_searchqa-validation-854", "mrqa_searchqa-validation-8589", "mrqa_searchqa-validation-8714", "mrqa_searchqa-validation-9213", "mrqa_searchqa-validation-960", "mrqa_squad-validation-10252", "mrqa_squad-validation-10444", "mrqa_squad-validation-10449", "mrqa_squad-validation-1311", "mrqa_squad-validation-1488", "mrqa_squad-validation-178", "mrqa_squad-validation-2", "mrqa_squad-validation-2125", "mrqa_squad-validation-2400", "mrqa_squad-validation-2460", "mrqa_squad-validation-2705", "mrqa_squad-validation-2773", "mrqa_squad-validation-2899", "mrqa_squad-validation-2949", "mrqa_squad-validation-3029", "mrqa_squad-validation-33", "mrqa_squad-validation-3955", "mrqa_squad-validation-4338", "mrqa_squad-validation-4686", "mrqa_squad-validation-500", "mrqa_squad-validation-500", "mrqa_squad-validation-5154", "mrqa_squad-validation-5643", "mrqa_squad-validation-5750", "mrqa_squad-validation-5767", "mrqa_squad-validation-6214", "mrqa_squad-validation-7036", "mrqa_squad-validation-7150", "mrqa_squad-validation-7638", "mrqa_squad-validation-7640", "mrqa_squad-validation-7717", "mrqa_squad-validation-7782", "mrqa_squad-validation-7814", "mrqa_squad-validation-8010", "mrqa_squad-validation-8027", "mrqa_squad-validation-8115", "mrqa_squad-validation-816", "mrqa_squad-validation-8236", "mrqa_squad-validation-8406", "mrqa_squad-validation-8480", "mrqa_squad-validation-8957", "mrqa_squad-validation-96", "mrqa_squad-validation-9779", "mrqa_squad-validation-9870", "mrqa_triviaqa-validation-1028", "mrqa_triviaqa-validation-1050", "mrqa_triviaqa-validation-1157", "mrqa_triviaqa-validation-1166", "mrqa_triviaqa-validation-117", "mrqa_triviaqa-validation-1240", "mrqa_triviaqa-validation-1284", "mrqa_triviaqa-validation-1297", "mrqa_triviaqa-validation-1445", "mrqa_triviaqa-validation-1659", "mrqa_triviaqa-validation-1692", "mrqa_triviaqa-validation-1814", "mrqa_triviaqa-validation-1842", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1969", "mrqa_triviaqa-validation-2010", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-2204", "mrqa_triviaqa-validation-2259", "mrqa_triviaqa-validation-2306", "mrqa_triviaqa-validation-2329", "mrqa_triviaqa-validation-2343", "mrqa_triviaqa-validation-2351", "mrqa_triviaqa-validation-243", "mrqa_triviaqa-validation-2470", "mrqa_triviaqa-validation-2476", "mrqa_triviaqa-validation-2572", "mrqa_triviaqa-validation-2582", "mrqa_triviaqa-validation-2647", "mrqa_triviaqa-validation-2711", "mrqa_triviaqa-validation-2787", "mrqa_triviaqa-validation-2825", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-2996", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-3180", "mrqa_triviaqa-validation-3256", "mrqa_triviaqa-validation-3281", "mrqa_triviaqa-validation-3403", "mrqa_triviaqa-validation-3480", "mrqa_triviaqa-validation-3525", "mrqa_triviaqa-validation-3880", "mrqa_triviaqa-validation-3907", "mrqa_triviaqa-validation-3966", "mrqa_triviaqa-validation-4096", "mrqa_triviaqa-validation-4122", "mrqa_triviaqa-validation-4169", "mrqa_triviaqa-validation-4443", "mrqa_triviaqa-validation-45", "mrqa_triviaqa-validation-4538", "mrqa_triviaqa-validation-4549", "mrqa_triviaqa-validation-4582", "mrqa_triviaqa-validation-469", "mrqa_triviaqa-validation-4699", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-4783", "mrqa_triviaqa-validation-48", "mrqa_triviaqa-validation-4832", "mrqa_triviaqa-validation-4901", "mrqa_triviaqa-validation-4904", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5091", "mrqa_triviaqa-validation-5129", "mrqa_triviaqa-validation-5148", "mrqa_triviaqa-validation-5236", "mrqa_triviaqa-validation-5289", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-5332", "mrqa_triviaqa-validation-5360", "mrqa_triviaqa-validation-576", "mrqa_triviaqa-validation-5837", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5874", "mrqa_triviaqa-validation-5918", "mrqa_triviaqa-validation-6015", "mrqa_triviaqa-validation-6087", "mrqa_triviaqa-validation-6092", "mrqa_triviaqa-validation-6093", "mrqa_triviaqa-validation-6225", "mrqa_triviaqa-validation-6371", "mrqa_triviaqa-validation-6511", "mrqa_triviaqa-validation-6585", "mrqa_triviaqa-validation-6642", "mrqa_triviaqa-validation-6741", "mrqa_triviaqa-validation-6811", "mrqa_triviaqa-validation-6951", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7230", "mrqa_triviaqa-validation-7237", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-7333", "mrqa_triviaqa-validation-7468", "mrqa_triviaqa-validation-757", "mrqa_triviaqa-validation-7665", "mrqa_triviaqa-validation-769", "mrqa_triviaqa-validation-770", "mrqa_triviaqa-validation-7707", "mrqa_triviaqa-validation-7750", "mrqa_triviaqa-validation-797", "mrqa_triviaqa-validation-819", "mrqa_triviaqa-validation-854"], "OKR": 0.78515625, "KG": 0.4609375, "before_eval_results": {"predictions": ["The 2007 Trail Appliances Autumn Gold Curling Classic", "The English Electric Canberra", "Alemannic", "November 13, 2007", "The 2012\u201313 Mercer Bears men's basketball team", "1979", "Salisbury", "KKR & Co", "526", "Annie Ida Jenny No\u00eb Haesendonck", "Cold Spring", "The Grandmaster", "satirical erotic romantic comedy", "\"The Process\"", "Vikram", "1949", "BAFTA TV Award", "Duke University", "second vice-captain", "Levi Weeks", "219 passengers", "Esteban Ocon", "S6", "Lamar Hunt", "Black Mountain College", "\"You Can Be a Star\"", "People v. Turner", "in 1853", "1948", "wineries", "1996 NBA Slam Dunk Contest", "two", "Ector County", "Kentucky River", "August 10, 1933", "R- Point", "Ludwig van Beethoven", "Rabat", "A Boltzmann machine", "Dusty Dvoracek", "Alexa", "The Lykan HyperSport", "Richard Arthur", "The magazine \"mental_floss\"", "May 4, 2004", "3 mi", "Field Marshal Lord Gort", "Neighbourhood", "Miracle on Ice", "1979", "John Alexander-Arnold", "seven", "2011", "current day", "Tennessee", "wish FM", "Christian Dior", "Mark Fields", "Arlington National Cemetery's Section 60,", "Seoul", "circumnavigate", "a dash", "ten", "a mollusca"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6185267857142857}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, false, true, false, false, true, false, true, true, false, true, true, true, true, false, false, false], "QA-F1": [0.25, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2867", "mrqa_hotpotqa-validation-838", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-2449", "mrqa_hotpotqa-validation-3324", "mrqa_hotpotqa-validation-3155", "mrqa_hotpotqa-validation-298", "mrqa_hotpotqa-validation-5675", "mrqa_hotpotqa-validation-1133", "mrqa_hotpotqa-validation-3889", "mrqa_hotpotqa-validation-5731", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-2978", "mrqa_hotpotqa-validation-4683", "mrqa_hotpotqa-validation-327", "mrqa_hotpotqa-validation-4305", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-2755", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2066", "mrqa_hotpotqa-validation-992", "mrqa_hotpotqa-validation-761", "mrqa_hotpotqa-validation-5242", "mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-5960", "mrqa_triviaqa-validation-5037", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-10055", "mrqa_searchqa-validation-5045"], "SR": 0.546875, "CSR": 0.52609375, "EFR": 1.0, "Overall": 0.683734375}]}