{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=10.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=20.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=20_l2w=10_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 8220, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "Los Angeles Times", "the Broncos", "anticlines and synclines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "Rhenus", "Pacific", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "the infected corpses", "United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "a shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "two integers", "a Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "by the market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Taoism", "Matthew 16:18", "U.S.-flagged Maersk Alabama", "Rwanda", "revelry", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.765625, "QA-F1": 0.8228365384615385}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-9655", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.765625, "CSR": 0.796875, "EFR": 1.0, "Overall": 0.8984375}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "the coast of Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "visitation of the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "presidential representative democratic republic", "the grace that \"goes before\" us", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "Arizona Cardinals", "1991", "Chaffee", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "to become more integral within the health care system", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "Ronnie Wood and Brandon Block", "NLP Stand For - Documents", "the company's factory in Waterford City, Ireland", "nitrogen", "Christopher Nolan", "Agulhas Current Flow Rates", "six", "It always begins with the music", "music director", "Illinois", "Rafael Palmeiro", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.796875, "QA-F1": 0.8357567065287653}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-235", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-3629"], "SR": 0.796875, "CSR": 0.796875, "EFR": 0.9230769230769231, "Overall": 0.8599759615384616}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "prefabricated housing projects", "Sakya", "monumental size", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "beautiful voice", "Upper Lake", "northern China", "giving her brother Polynices a proper burial", "political figures", "President", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "Edict of Nantes", "reserved to, and dealt with at, Westminster", "multiple revisions", "philanthropic initiative", "integer factorization problem", "economic inequality", "Isel", "adapted quickly and often married outside their immediate French communities", "U.S. Ambassador to the European Union", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "late 19th century", "Channel Islands", "honor the separate spheres of knowledge that each applies to", "Alberich", "9", "ireil Lagasse", "Churchill Downs", "Ghent-Terneuzen Canal", "tetrahedron", "ireland", "Brazil", "study insects and their relationship to humans, other organisms, and the environment", "limbic system", "Allan Border", "George Fox", "Virginia", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorship scandal", "\"Krabby Road\""], "metric_results": {"EM": 0.609375, "QA-F1": 0.6464409722222222}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.16666666666666669, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-874", "mrqa_squad-validation-2597", "mrqa_squad-validation-801", "mrqa_squad-validation-4293", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-7321", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-6556", "mrqa_hotpotqa-validation-3821"], "SR": 0.609375, "CSR": 0.75, "EFR": 0.88, "Overall": 0.815}, {"timecode": 4, "before_eval_results": {"predictions": ["in higher plants", "Parliament of Victoria", "Zaha Hadid", "the Marquis de Vaudreuil", "Science and Discovery", "the Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "Battle of Olustee", "Sicily and the south of Europe", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "British troops", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "1985", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "Italian government", "22", "terror groups that they say were planning numerous suicide attacks", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "a way of getting into that Lexus, Lincoln, Infiniti ororsche you always wanted", "Muslim", "will be the first time any version of the Magna Carta has ever gone up for auction", "Monday night where it left off in September with what Sedgwick called \"a fantastic five episodes.\"", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "a woman who may have been contacted through a Craigslist ad", "one", "celebrity-inspired names", "$1,500", "National Industrial Recovery Act", "Travis", "Humberside Airport", "gABRIEL ROSSETTI"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7121231280973928}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4615384615384615, 0.15999999999999998, 1.0, 0.1, 0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-7094", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_squad-validation-166", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-2965", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.6875, "CSR": 0.7375, "EFR": 0.95, "Overall": 0.84375}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a high-level marketing manager,", "roughly 500,000", "Ofcom", "Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "reminding their countrymen of injustice", "June 1978", "Milton Latham", "1914", "the Philippines", "the Broncos", "the 1970s", "the characteristics of the conquering peoples", "German Te Deum", "1795", "Bermuda 419 turf", "evaporated to cool oxygen gas", "Infinity Broadcasting Corporation", "\"semi-legal\"", "1972", "rudimentary", "1957", "mother-of-pearl", "Gene Barry", "negotiates treaties with foreign nations", "It is mainly for the purpose of changing display or audio settings quickly", "The term monkey's uncle, most notably seen in the idiom", "Woodrow Wilson", "radius R of the turntable", "Panning", "Justin Timberlake", "Brazil, China, France, Germany, India, Indonesia, Italy, Japan, South Korea, Mexico, Russia, Turkey, the United Kingdom", "military experts. European nations contribute nearly 6,000 units to this total. Pakistan, India, and Bangladesh are among the largest individual contributors", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's opened its first three stores in Canada", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "the seven ages of man : infant, schoolboy, lover, soldier, justice, Pantalone and old age", "most episodes feature a storyline taking place in the present ( 2016 -- 2018, contemporaneous with airing )", "Morgan Freeman", "David Gahan", "it includes a restaurant, spa, and bed - and - breakfast", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "the day before Ash Wednesday", "Jaipur", "Johan Persson and Martin Schibbye", "torpedo boats", "Newport"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7204456955690508}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.4000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.38888888888888895, 0.15384615384615385, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.5833333333333334, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-4836", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-436", "mrqa_squad-validation-3473", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.640625, "CSR": 0.7213541666666667, "EFR": 0.9565217391304348, "Overall": 0.8389379528985508}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "more expensive", "an antigen from a pathogen", "their disastrous financial situation", "a Serbian Orthodox priest", "receptions, gatherings or exhibition purposes", "New England Patriots", "Charly", "Henry Cole", "steam turbines", "social and political action", "1936", "the New Birth", "gold", "a deficit", "Vivienne Westwood", "reduction", "disease", "\"TFIF\"", "Confucian propriety and ancestor veneration", "the rediscovery of \"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "teachers in publicly funded schools must be members in good standing with the college, and private schools may also require their teachers to be college peoples.", "end of the season", "10", "Jacob", "African-Americans", "will not support the Stop Online Piracy Act", "Don Draper", "always hot and humid and it rains almost every day of the year", "an animal tranquilizer", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Stuttgart on Sunday.", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "more than 170", "North Korea", "first five Potter films", "you love the environment and hate using fuel", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "Her husband and attorney, James Whitehouse,", "we want to ensure we have all the capacity that may be needed over the course of the coming days.", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "James Lillywhite, Alfred Shaw and Arthur Shrewsbury", "Colgate University", "Church of Christ, Scientist", "unsaturated fats are comprised of lipids that contain?", "gospel does not present any elaboration of who these twelve actually were"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7193837412587413}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07692307692307693, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.2, 0.5, 1.0, 0.5, 0.25, 1.0, 0.0, 1.0, 0.16666666666666669, 0.2666666666666667, 1.0, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6001", "mrqa_squad-validation-486", "mrqa_squad-validation-3390", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.65625, "CSR": 0.7120535714285714, "EFR": 1.0, "Overall": 0.8560267857142857}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "return to his side", "increased trade with poor countries", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism", "Jim Gray", "unequal", "July 1969", "that Hitler's secret police demanded to know if they were hiding a Jew in their house.", "a yellow chlorophyll precursor", "spontaneous", "the courts of member states", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "ricks for Warsaw", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "\u00a320,427", "21 October 1512", "James O. McKinsey", "dance Your Ass Off", "their \"Freshman Year\" experience", "India", "Benazir Bhutto", "at the Lindsey oil refinery in eastern England", "April 24 through May 2", "Krishna Rajaram", "early detection", "250,000", "Timothy Masters", "homicide", "permitted under Spanish Football Federation (RFEF) rules", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jared Polis", "William S. Cohen", "\"Dance Your Ass Off.\"", "leniency", "Matthew Fisher", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian.", "a \"stressed and tired force\" made vulnerable by multiple deployments", "Japan", "condition", "\"Empire of the Sun,\"", "Norman given name Robert", "performance enhancing drugs", "Matt Winer", "Wyatt Earp", "opposite R\u00fcgen island", "royalty", "green"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6119090544871795}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false, false, false, false, true], "QA-F1": [1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8749999999999999, 1.0, 1.0, 0.5333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.4, 1.0, 1.0, 1.0, 0.0, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 0.4, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6115", "mrqa_squad-validation-7533", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-3938", "mrqa_squad-validation-872", "mrqa_squad-validation-1556", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-103", "mrqa_newsqa-validation-417", "mrqa_naturalquestions-validation-6514", "mrqa_triviaqa-validation-991", "mrqa_hotpotqa-validation-4367", "mrqa_searchqa-validation-7977", "mrqa_triviaqa-validation-2858", "mrqa_triviaqa-validation-4305"], "SR": 0.53125, "CSR": 0.689453125, "EFR": 0.9666666666666667, "Overall": 0.8280598958333334}, {"timecode": 8, "before_eval_results": {"predictions": ["7 February 2009", "The British provided medical treatment for the sick and wounded French soldiers and French regular troops were returned to France aboard British ships", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday", "Journey's End", "immediate", "Levi's Stadium", "Wesleyan", "art posters", "Elbegdorj", "Chinggis Khaan", "Einstein", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington Railway", "autonomy", "Islamic", "tweener love", "Fernando Gonzalez", "Graeme Smith", "strong work ethic", "finance", "terminal brain cancer.", "attracted some U.S. senators who couldn't resist taking the vehicles for a spin.", "Employee Free Choice act", "separated", "Animal Planet", "fake his own death", "there were no radar outages and said it had not lost contact with any planes", "54 bodies", "early detection and helping other women cope with the disease", "Diversity", "$250,000", "fill sandbags", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president", "2050", "Alfredo Astiz,", "Abdullah Gul,", "Carl Froch", "Everglades", "when the cell is undergoing the metaphase of cell division", "Gibraltar", "New Orleans, Louisiana", "Tulip mania", "MIBs", "olympics", "olympics"], "metric_results": {"EM": 0.640625, "QA-F1": 0.712732233044733}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.12121212121212123, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.13333333333333336, 1.0, 0.5, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1639", "mrqa_newsqa-validation-302", "mrqa_naturalquestions-validation-8159", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.640625, "CSR": 0.6840277777777778, "EFR": 0.9565217391304348, "Overall": 0.8202747584541064}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "Book of Discipline", "Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "General Sejm", "Derek Jacobi", "net force", "hoos", "30%\u201350% O2 by volume", "very badly disposed towards the French, and are entirely devoted to the English", "the top 15 most populous", "CRISPR sequences", "six", "300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "issues related to the substance of the statement", "Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "helping the United States frame the challenges", "25", "a treadmill", "the couple's surrogate lost the pregnancy.", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "at least two and a half hours.", "Elin Nordegren", "Europe, Asia, Africa and the Middle East.", "6,000", "cortisone", "President Clinton.", "delivered three machine guns and two silencers", "Morgan Tsvangirai.", "policing the world and Africa", "future relations between the Middle East and Washington", "in a canyon", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail", "school", "strife in Somalia", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia, Illinois", "violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "they did not know how many people were onboard.", "London", "after Shawn's kidnapping", "an individual", "William Tell", "OutKast", "Groundhog Day", "he really didn't mean t", "a singer"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6196180555555555}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, true, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-3687", "mrqa_squad-validation-2429", "mrqa_squad-validation-9194", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.578125, "CSR": 0.6734375, "EFR": 0.9259259259259259, "Overall": 0.799681712962963}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction", "Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "within the premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "pelvis and sacrum -- the triangular bone within the pelvis.", "issued his first military orders as leader of North Korea", "precipitation will briefly transition back to light snow or flurries", "Willem Dafoe", "Maude", "Phillip A. Myers.", "Korea", "two weeks after Black History Month", "58 people", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "Christopher Savoie", "Touma", "Dangjin", "e-mails", "Chinese President Hu Jintao", "magazine, GospelToday,", "it pulls the scab and it cracks, and it starts to bleed.\"", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next.", "President Bush", "Jeffrey Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "bankruptcy", "16 August 1975", "Bonnie Aarons", "one", "kabinett", "Lionsgate.", "James Lofton", "mystic", "short, hair-like structures"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6884469696969697}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, true, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5454545454545454, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_squad-validation-1299", "mrqa_squad-validation-8655", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-2270", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.59375, "CSR": 0.6661931818181819, "EFR": 0.9615384615384616, "Overall": 0.8138658216783217}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "hermaphroditism and early reproduction", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company under the Office of Alien Property (OAP) seal.", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks, later called packets, and delivery of these messages by store and forward switching.", "Elway", "Philo of Byzantium", "36 acres", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "Agnes Wickfield", "pink mice", "antelope", "nipples", "the Precambrian period", "'helpful'", "Anastasia Dobromyslova", "Lady Gaga", "9", "Space Jam 2", "radishes", "Robert Ludlum", "a magical creatures", "a Space vehicle", "the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live", "Hebrew", "London Underground Piccadilly Line", "Wisconsin", "orangutan", "Manet", "The Magic Finger", "Massachusetts", "2005", "1969", "DodgeDodge", "dolt", "Venice", "a peplos", "Enrico Caruso", "Elizabeth Arden", "lightweight baby buggy with a collapsible support assembly", "Sir Hardy Amies", "Liechtenstein", "the 14th most common surname in Wales and 21st most common in England", "Rob Davis", "Cody Miller", "Bloomingdale Firehouse", "acquire nuclear weapons", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "Jamaica", "Buddhism"], "metric_results": {"EM": 0.5625, "QA-F1": 0.651383551950157}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, false, false, false, true, false, false, true, false, true, true], "QA-F1": [0.5, 1.0, 1.0, 0.2608695652173913, 1.0, 0.8, 1.0, 0.7234042553191489, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6153846153846153, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.4444444444444444, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-4890", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-2092", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5216", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983"], "SR": 0.5625, "CSR": 0.6575520833333333, "EFR": 1.0, "Overall": 0.8287760416666666}, {"timecode": 12, "before_eval_results": {"predictions": ["Southern Border Region", "70-50's", "Panini", "Bills", "anti-colonial movements", "the Rhine Valley", "protein A", "to test everything himself by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "if the EU does not comply with its basic constitutional rights and principles (particularly democracy, the rule of law and the social state principles)", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "because the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "Ness Point", "John Mayer", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "Eric Pickles", "Sir Hugo Drax", "Vladivostok", "sheryl Crow", "Telstar", "Camellia sinensis", "AFC Wimbledon", "Charles Hawtrey", "Malaysia's capital Kuala Lumpur", "cosmology", "gin", "George Clooney", "Eric Coates", "James Chadwick", "\"No one was saved\"", "Monopoly", "champagne", "an extended period of abundant rainfall lasting many thousands of years", "United States", "Brigit Forsyth", "Lord Melbourne", "state of Japan", "The History of Troilus and Cressida", "Thomas Edward Lawrence,", "Kent", "Renoir\u00b4s", "Vanguard", "Dannebrog", "Switzerland", "gin", "people of France to the people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Derek Mears", "bremen", "David in the Bargello", "\"Stagecoach\" (John Ford, 1939)"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6410309750733139}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, true, false, true, false, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.8387096774193548, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9600000000000001, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-2078", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_squad-validation-4590", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-3957", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-1262", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_triviaqa-validation-609", "mrqa_naturalquestions-validation-594", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_searchqa-validation-8450", "mrqa_searchqa-validation-9647", "mrqa_newsqa-validation-3860"], "SR": 0.5625, "CSR": 0.6502403846153846, "EFR": 0.9642857142857143, "Overall": 0.8072630494505495}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "it would appear to be some form of the ordinary Eastern or bubonic plague", "had their own militia", "after the end of the Mexican War", "Over 61", "quality of a country's institutions", "cilia", "friction", "Sky Digital", "2005", "force", "mustelids", "John Connally", "saffron", "HYMENAEUS", "Zeus", "albinism", "Straits of Tiran", "Brigit Forsyth", "call My Bluff", "March 10, 1997", "cuddly new pet", "The Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "lizards", "strong cold southwest wind", "table tennis", "jAMA", "penhaligon", "reed", "Edgar Allen Poe", "Jinnah International Airport", "Monday", "Caracas", "a crucifix", "soap", "liquor", "Avro Lancaster", "gove wuthering", "covey Brooker", "camomile", "harrods", "2007", "Christina Ricci", "Scarface", "pale yellow", "reed melbourne farmer Ted Moult", "bubba", "June 12, 2018", "Filipino American History Month", "London's West End", "Lambic", "Nook", "Steven Green", "commas", "fortune", "renoir", "Synchronicity"], "metric_results": {"EM": 0.5, "QA-F1": 0.5826388888888888}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-2875", "mrqa_squad-validation-2920", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-6547", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-6708", "mrqa_triviaqa-validation-4981", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_hotpotqa-validation-5340", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-6628"], "SR": 0.5, "CSR": 0.6395089285714286, "EFR": 1.0, "Overall": 0.8197544642857143}, {"timecode": 14, "before_eval_results": {"predictions": ["seven", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "sleep after it is separated from the body", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "a declining state of mind", "1898", "The Deadly Assassin and Mawdryn undead", "for scientific observation", "Cody Fern", "Nicklaus", "Jim Gaffigan", "cat in the hat", "2020", "1974", "332", "1936", "Authority", "senior enlisted sailor", "Spanish moss", "Chinese cooking", "Vienna", "World Trade Center", "Kevin Spacey", "1 November", "78", "in lymph", "Bangladesh -- India border", "President", "minor key", "Coppolas and, technically, the Farrow / Previn / Allens", "Chandan Shetty", "metamorphic rock", "January 12, 2017", "the United States", "claims adjusters", "The neck", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection, irritation, or allergies", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column", "three", "spring", "long", "Kew Gardens", "Nikita Khrushchev", "$500,000", "young self-styled anarchists", "reaper", "a revolver", "BBC building in Glasgow, Scotland", "they would get tested to see if their kidney could be donated."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6652165203455964}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false], "QA-F1": [0.5, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 0.5, 0.2857142857142857, 0.8, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.14285714285714285]}}, "before_error_ids": ["mrqa_squad-validation-653", "mrqa_squad-validation-125", "mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-10656", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-2297", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-7309", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.515625, "CSR": 0.63125, "EFR": 0.967741935483871, "Overall": 0.7994959677419355}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "a special episode of The Late Show with Stephen Colbert", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "ESPN Deportes", "Jean Ribault", "Tetzel", "the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "note number 60", "Seattle, Washington", "Battle of Antietam", "Dimitar Berbatov and Carlos Tevez", "In Time", "the 2nd century", "Glenn Close", "four times", "Agostino Bassi", "five", "Malibu, California", "the church at Philippi", "the Netherlands", "September 2017", "Professor Kantorek", "1546", "Jane Fonda", "Bhupendranath Dutt", "a warrior", "Dr. Lexie Grey", "Majandra Delfino", "September 1972", "Uruguay", "Alex Skuby", "Matt Jones", "The National Legal Aid & Defender Association", "Monk's Caf\u00e9", "domesticated sheep", "1970s", "Director of National Intelligence", "D.A.D. a.", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr.", "Thespis", "Portugal", "John Coffey", "Rachel Kelly Tucker", "Bohemia", "a garage beetle", "Code 02PrettyPretty", "musician", "opposition group, also known as the \"red shirts,\"", "the abduction of minors", "$6.2 trillion", "Gabriel Garcia", "Stage Stores", "1881"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6324576465201466}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, true, false, true, true, false, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 0.42857142857142855, 0.3076923076923077, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-10586", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_searchqa-validation-13473", "mrqa_searchqa-validation-5103"], "SR": 0.53125, "CSR": 0.625, "EFR": 0.9333333333333333, "Overall": 0.7791666666666667}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "Arizona Cardinals", "Bert Bolin", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Western Xia", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland", "Microsoft Office", "SAVE", "Scandinavian Airlines System", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award Best Actor", "Jello Biafra drew on Nardwuar's face with a marker pen", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson, David Michener, and the team of John Musker and Ron Clements", "Sir William McMahon", "North Sea", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "the CAC/PAC JF-17 Thunder", "Delacorte Press", "Neighbourhoods", "Secretariat", "Wake Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of France", "\"Southern Living\" Reader's Choice Awards", "William Shakespeare", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Alticor", "Parlophone Records", "South Africa", "Surrey", "The Girl", "Charles Russell", "Boyd Gaming", "Anthony Davis of the New Orleans Pelicans", "1991, 1992, 1993, 1994, 1998, 2009, 2010", "Glenn Close", "Mary Welch", "Neighbours", "Ewan McGregor", "2011", "a priest's cowl", "a son of an African-born slave mother in Southampton, Virginia", "power-sharing talks", "Shelley Moore Capito"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6839353354978355}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.3636363636363636, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-3521"], "SR": 0.59375, "CSR": 0.6231617647058824, "EFR": 0.9615384615384616, "Overall": 0.792350113122172}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "the University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "the inner chloroplast membrane", "Charlie Harper", "steveland Hardaway Morris", "beaver", "La Boh\u00e8me Giacomo Puccini", "formic acid", "Puente del Arzobispo", "Zimbabwe", "Mr. Boddy", "Ted Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Xenophon", "Fuller's", "a reference mark", "Nick Hornby", "The Comedy of Errors", "Charles V", "England", "Lagertha", "weight plates", "\"big house\"", "Hadrian", "US", "human flea", "Moonee Ponds, a suburb in Melbourne, Victoria", "Hamburg", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "Leicester City", "Sergei Prokofiev", "Jessica Simpson", "British public", "Corsican Republic", "3000m", "Scotland", "Japan", "Travis Tritt and Marty Stuart", "Confederate", "New Jewel Movement", "sub-Saharan Africa", "U.S. 93", "Anjuna beach in Goa", "Lev Ivanov", "du'y van", "two", "jeopardy/1870_Qs.txt at master  jedoublen/jeopardy", "Nightlife in Mallorca"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6338541666666666}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-6315", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-2549", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-7007", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-3198", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.5625, "CSR": 0.6197916666666667, "EFR": 1.0, "Overall": 0.8098958333333334}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "extremely high", "Manakin Town", "northwest", "fewer than 10 employees", "Middle Miocene", "new magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "in a balance sheet as an asset", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "Coppolas and, technically, the Farrow / Previn / Allens", "Allison Janney", "the Isthmus of Corinth", "inability to comprehend and formulate language", "Splodgenessabounds", "ser Gregor Clegane", "electron donors", "Meredith Quill", "1993", "19 state rooms", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Lewis Carroll", "20 November 1989", "Coton in the Elms", "55 -- 69 %", "Zoe Badwi", "1995", "Identification of alternative plans / policies", "16 August 1975", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "`` Killer Within ''", "Western Australia", "the aorta", "July 21, 1861", "Dr. Addison Montgomery", "capital and financial markets", "An empty line", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "universal significance", "September 2017", "moral", "`` Rising Sun Blues ''", "Part 2", "Disney's 1941", "the duke of Monmouth\u2019s rebellion", "Christian", "Robert L. Stone", "2008", "Yemen", "mentor", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.625, "QA-F1": 0.7108110182478788}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 0.2857142857142857, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.28571428571428575, 1.0, 1.0, 0.08695652173913042, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-6242", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-1161", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-4227", "mrqa_hotpotqa-validation-4735"], "SR": 0.625, "CSR": 0.6200657894736843, "EFR": 0.9583333333333334, "Overall": 0.7891995614035088}, {"timecode": 19, "before_eval_results": {"predictions": ["the law as the Holy Spirit's tool to work sorrow over sin in man's heart, thus preparing him for Christ's fulfillment of the law offered in the gospel", "black", "Louisiana, Biloxi, Mississippi, Mobile, Alabama", "Jaime Weston", "1978", "high art and folk music", "warming", "the mid-sixties", "270,000", "Long troop deployments", "Joe Pantoliano", "the girl's stepmother", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "Nearly eight in 10", "natural resources around the islands should be protected, and Britain must accept international resolutions labeling the Falklands a disputed area", "Tuesday", "forgery and flying without a valid license", "Anil Kapoor", "55", "President Obama", "unwanted baggage from the 80s", "The Louvre", "snowstorm", "exotic sports cars", "hatchlings", "Mutassim", "Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18,", "\"Steamboat Bill, Jr.\"", "Russia", "Al alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone", "\u00a341.1 million", "Kingman Regional Medical Center", "charlie Moore", "Manmohan Singh", "Michael Jackson", "to go the White Palace and show him my poems, show him what is happening and ask him to come to Pakistan and control it because he is a super power", "40 militants and six Pakistan soldiers dead", "Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Lousiana", "the Southeast", "Misty Croslin", "Nancy Sutley", "\" Michael Phelps, who won a record eight gold medals in Beijing, is the author of a new memoir, \"A Mother For All Seasons.\"", "Moe and Sana Maraachli", "back at work", "necropsy", "27", "Derek Hough", "John Adams, a leader in pushing for independence, had persuaded the committee to select Thomas Jefferson to compose the original draft of the document, which Congress edited to produce the final version", "borsht", "Zager & Evans", "Robert Matthew Hurley", "At-large", "\" Adult Theatre - You must be 21 and able to prove it\"", "(Oliver) Cromwell", "Lapland", "2000", "Emad Hashim"], "metric_results": {"EM": 0.421875, "QA-F1": 0.54001574933687}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, false, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, true, false, false, false, false, true, false, true, false, false, false, false, true, false, false, true, false, false, true], "QA-F1": [0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.923076923076923, 0.6666666666666666, 0.8333333333333333, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.13793103448275862, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-4024", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-1760", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-3079", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_triviaqa-validation-7208", "mrqa_hotpotqa-validation-2013", "mrqa_searchqa-validation-328", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-5120"], "SR": 0.421875, "CSR": 0.61015625, "EFR": 0.972972972972973, "Overall": 0.7915646114864865}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "diphthong", "1331", "Death wish Coffee", "L", "Cameroon", "1994", "policing the world and Africa", "fabric", "three empty vodka bottles,", "deputy director for strategy, plans and policy on the Army staff.", "Bobby Darin,", "Nico Rosberg", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "acknowledged the procedures should be changed.", "the composer of \"Phantom of the Opera\" and \"Cats\"", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan.", "Caylee Anthony, 2,", "Amanda Knox's aunt", "Half Moon Bay", "Iran's nuclear program.", "through 12 shades of violet, including a welcoming, bright blue-purple during the day, a softer violet hue after dusk", "allegedly faking a doctor's note", "ceo Herbert Hainer", "Brett Cummins,", "a nearby day care center whose children are predominantly African-American.", "inmates", "Col. Elspeth Cameron-Ritchie,", "\"E! News\"", "three French journalists, a seven-member Spanish flight crew and one Belgian", "jobs up and down the auto supply chain", "saying Tuesday the reality he has seen is \"terrifying.\"", "The controversial technique that simulates drowning -- and which President Obama calls torture -- was used at least 83 times in August 2002 on suspected al Qaeda leader Abu Zubaydah,", "any group that tries to take justice into its own hands.", "Republicans", "start developing a youth ballpark in his hometown of Aberdeen, Maryland, financed in part by a $75,000 gift from the Major League Baseball Players Association.", "An undated photo of Alexandros Grigoropoulos,", "deciding the duties of the new prime minister has been a sticking point in the negotiations.", "a 57-year old male", "North Korea intends to launch a long-range missile in the near future,", "Angola", "Gary Brooker", "outlaws", "boogeyman Jason Voorhees", "The United States had been seeking the death penalty against al-Qahtani and five other men in connection with the 9/11 attacks.", "Sea World in San Antonio", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans,", "about 50", "the Ku Klux Klan", "The Wizard of Oz ( 1939 )", "Branford College", "bury", "stamens", "Malayalam", "August 17, 2017", "a jacket", "mouse followed, in the '80s?", "Hodel", "the benefits of the US privacy Act to Europeans and gives them access to US courts", "Coldplay"], "metric_results": {"EM": 0.359375, "QA-F1": 0.47486108190086884}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, false, false, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.125, 0.0, 0.0, 1.0, 0.9523809523809523, 0.0, 0.25, 0.23076923076923078, 0.8, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 0.8571428571428571, 0.0851063829787234, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.06451612903225808, 0.0, 0.19047619047619047, 0.6666666666666666, 1.0, 0.4, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.5263157894736842, 0.4]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-1759", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-1449", "mrqa_naturalquestions-validation-10284", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987", "mrqa_naturalquestions-validation-3783"], "SR": 0.359375, "CSR": 0.5982142857142857, "EFR": 0.8292682926829268, "Overall": 0.7137412891986062}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "Splash", "Nicola Adams", "copper and zinc", "eagle", "Peter Nichols", "Gulf of Aden", "Carlo Collodi", "Tony Blair,", "Illinois", "both shoulders", "Madonna's", "Glasgow", "satellites", "Australia", "bird's food,", "Pearson PLC.", "Irish Setter", "American Civil War,", "Loch Lomond", "rochner", "Brisbane", "medium", "largest city of the country", "Harrisburg", "mustela erminea,", "glockenspiel", "Dr John Sentamu", "rochoon", "Pongo", "Anne Boleyn", "EMI", "Freddie Mercury,", "Emma Chambers", "Charlemagne", "the community", "Russell Crowe", "Theodore Roosevelt", "rochian", "Robin Goodfellow", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "Model Ship Master", "Albert Square", "Newbury", "a book of the Old Testament", "70 million people, at that time 21 % of the world's entire population", "Target Corporation", "Sister, Sister (1982 film)", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "international NGO", "John Jackson Dickison", "better conditions for inmates, like Amnesty International.", "talk show queen Oprah Winfrey.", "his mother."], "metric_results": {"EM": 0.53125, "QA-F1": 0.5805765415140416}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, false, true, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.3076923076923077, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-3498", "mrqa_triviaqa-validation-6242", "mrqa_triviaqa-validation-6330", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6307", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-6908", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-4805", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-2484", "mrqa_searchqa-validation-11802", "mrqa_searchqa-validation-1273", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.53125, "CSR": 0.5951704545454546, "EFR": 1.0, "Overall": 0.7975852272727273}, {"timecode": 22, "before_eval_results": {"predictions": ["The flushing action of tears and urine", "1765", "primarily along the frontiers between New France and the British colonies,", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "Vicodin", "jesuit", "Robert Peary", "pearls", "jesuit", "Carrie Underwood", "liqueur liquor", "he made his horse a consul", "jesuit", "Langston Hughes", "Self-torture", "frantiek Drtikol", "mambo", "rope", "unFINISHED", "USS LST 325", "prey drive", "David Beckham", "Arturo Toscanini", "economics", "Miracle in the Andes", "triumphal arch", "Montenegro", "discus", "jedoublen", "basidiomycota", "james", "Courtney thorne-Smith", "Idi Amin", "Riding mower", "a body, or a personal item associated with a saint", "terracotta", "plutarch", "Rudy Giuliani", "masa", "50", "the Vikings.", "mulberry Street", "jesuit", "New York City", "fjord", "baviere-quebec.org", "jesuit", "telegraph", "University of tualatin", "a chemical reaction to speed up but is not used up", "jen Knox", "the internal reproductive anatomy", "$657.4 million in North America and $1.528 billion in other countries", "epidemiology", "jockey", "Tesco", "Mallard", "Graham Hill", "the Battelle Energy Alliance.", "IT products and services, including storage systems, servers, workstations and data/voice communications equipment", "debris", "$10 billion", "Bailey, Colorado,"], "metric_results": {"EM": 0.375, "QA-F1": 0.41427067621920566}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, false, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, false], "QA-F1": [0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.16666666666666669, 0.5, 0.5, 0.15384615384615385, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47058823529411764, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6437", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-5055", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-13026", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-10188", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-5091", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_searchqa-validation-16854", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-68", "mrqa_newsqa-validation-1997"], "SR": 0.375, "CSR": 0.5855978260869565, "EFR": 1.0, "Overall": 0.7927989130434783}, {"timecode": 23, "before_eval_results": {"predictions": ["New Year's Day 2007", "1493\u20131500", "the Pittsburgh Steelers", "an Australian public X.25 network operated by Telstra", "Hamas", "Nintendo", "the Gulf of Mexico", "domestic cat in America,", "the daughter of Tony Richardson and Vanessa Redgrave", "Europ\u00e9ennes", "the Argo", "prometheus", "The Altamont Speedway Free Festival", "John F Kennedy,", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a MUD (multi-user dungeon),", "Libya", "Khaki", "a sedimentary", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "the Mendip Hills", "Barack Obama,", "the Earth", "Nafea Faa Ipoipo?", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the colony of Suriname", "Justin Trudeau", "Air traffic control, Air-defense systems, and Antimissile systems", "Denis Law", "Love Is All Around", "William Golding", "Sally Ride", "Influenza", "Fife", "Money Saving", "Adidas", "the Snark", "Elizabeth Arden", "Buxton", "woe", "Octopussy", "all pieces capture opponent's pieces by moving to the square that the opponent's piece occupies.", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "The Wall Street Journal Europe", "the Arctic fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.625, "QA-F1": 0.6734834558823529}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.25, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7871", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-3164", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3049", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-4882", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-2570", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848", "mrqa_searchqa-validation-6736"], "SR": 0.625, "CSR": 0.5872395833333333, "EFR": 0.9583333333333334, "Overall": 0.7727864583333333}, {"timecode": 24, "before_eval_results": {"predictions": ["limited coercion", "the chosen machine model", "Fox", "1997", "a suite of network protocols", "Noriko Savoie", "15", "nine-wicket", "between Pyongyang and Seoul", "he was led away in handcuffs after being sentenced in a New Jersey court for fatally shooting a limo driver on February 14, 2002.", "11", "fly to Australia", "Alwin Landry's supply vessel Damon Bankston", "Chaffetz", "money or other discreet aid", "Sarah Brown", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "environmental", "switzerland", "coalition troops", "Saturday", "38", "70,000 or so", "Climatecare", "E! News", "former Boca Juniors teammate and national coach", "Steve Williams", "McDonald's", "poetry", "Pastor Paula White", "2008", "Diego Maradona", "Dog patch Labs", "The drama of the action in-and-around the golf course", "two", "Itawamba County School District", "Romney", "EU naval force", "Plymouth Rock", "Liza Murphy, 42,", "The nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "police", "former U.S. secretary of state", "At least 33", "five", "improve health and beauty.", "Texas", "students often know ahead of time when and where violence will flare up on campus.", "Damon Bankston", "Krishna Rajaram,", "Sunday,", "killing", "an Irish feminine name", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "Northern Ireland", "radar", "art", "the National Basketball Association", "23", "Guarani", "freestyle", "Florence Nightingale", "Belief"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5900543587044212}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.5, 1.0, 0.0, 0.8571428571428571, 0.3076923076923077, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.9655172413793104, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.967741935483871, 0.0, 1.0, 0.25, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4673", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3338", "mrqa_newsqa-validation-3169", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2207", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_hotpotqa-validation-2170", "mrqa_searchqa-validation-3826"], "SR": 0.40625, "CSR": 0.5800000000000001, "EFR": 0.9736842105263158, "Overall": 0.776842105263158}, {"timecode": 25, "before_eval_results": {"predictions": ["its 50th anniversary special", "Thomas Savery", "Vicodin", "Eastern crops such as carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago onward", "violent separatist campaign", "Eleven", "269,000", "theft in Switzerland of two paintings by Pablo Picasso, Bjoern Quellenberg,", "38 feet", "Eintracht Frankfurt", "150", "a man had been stoned to death by an angry mob.", "Russian bombers", "41", "Los Alamitos Joint Forces Training Base", "Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy", "the area where the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "the Russian air force", "34", "President Obama ordered the eventual closure of Guant Bay prison and CIA \"black site\" prisons,", "around 3.5 percent of global greenhouse emissions.", "Amanda Knox's aunt", "\"several pieces of aircraft equipment were at fault or had broken down.\"", "ensuring that all prescription drugs on the market are FDA approved", "patients hoping to keep their skin looking young.", "Tom Baer", "Pakistan", "The oceans are growing crowded, and governments are increasingly trying to plan their use.", "a two-piece bathing suit", "Brian Mabry", "iTunes", "Sunday.", "60 euros -- $89 --", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment,", "Some truly mind-blowing structures are being planned for the Middle East.", "a passenger's name", "he was one of 10 gunmen who attacked several targets in Mumbai", "2006", "San Diego", "Debora Harris, Joyce Mims, Tonya Miller, Quithreaun Stokes, Sheila Farrior.", "The Taliban has threatened to kill Bergdahl if foreign troops continue targeting civilians in the name of search operations in Ghazni and Paktika provinces,", "@", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "Haitian National Police (HNP)", "heart", "Hyderabad", "Sinai ( / \u02c8sa\u026ana\u026a / ; Arabic : \u0633\u064a\u0646\u0627\u0621\u200e S\u012bn\u0101\u02bc", "to stay, abide", "Las Vegas", "Jackson Pollock", "Lyrical", "Mississippi", "October 4, 1970", "King Duncan", "Georgia", "thimble", "a stride"], "metric_results": {"EM": 0.4375, "QA-F1": 0.534459560754791}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, false, true, false, false, false, true, true, false, false, true, true, false, false, false, true, true, false, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.8750000000000001, 0.8571428571428571, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.07407407407407408, 0.0, 0.0, 1.0, 0.2666666666666667, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.1111111111111111, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.1818181818181818, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_squad-validation-9432", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_triviaqa-validation-1677", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-11832"], "SR": 0.4375, "CSR": 0.5745192307692308, "EFR": 0.9444444444444444, "Overall": 0.7594818376068376}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "lost their phycobilisomes", "Off-Off Campus", "reckless", "pro-democracy activists clashed Friday with Egyptian security forces in central Cairo,", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot.", "Hong Kong's Victoria Harbor", "2002", "six", "legitimacy of that race.", "think about saving the rainforests", "three", "Monday", "Scarlett Keeling", "two years,", "nearly 28 years", "regulators in the agency's Colorado office", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify. Military commission judges also will be able to establish the jurisdiction of their own courts.", "in July", "Akshay Kumar", "Graham's wife", "\"against people who independent of their race, religion, ethnicity, social condition etc. accepted money and put themselves at the service of the army in an area that is the object of military operations.\"", "\"disagreements\" with the Port Authority of New York and New Jersey,", "June 2004", "Michelle Rounds", "James Newell Osterberg", "the death of Prince George's County police Cpl. Richard Findley,", "Lana Clarkson", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday,", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "Izzat Ibrahim al-Douri,", "dependable Camry", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March.", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "in his 60s,", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "\"Don't Ask, Don't Tell.\"", "military veterans", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units", "6 - 6", "Bongos", "Jack Frost", "the innermost digit of the forelimb", "1988", "25 million", "Peoria, Illinois", "Honolulu", "'hardheads", "incense", "Ottoman Empire"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6329594017094018}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, true, false, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false, true, false, true, false, false, true], "QA-F1": [1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.5, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-2195", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-9563", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_triviaqa-validation-4905", "mrqa_hotpotqa-validation-5856", "mrqa_searchqa-validation-11586", "mrqa_searchqa-validation-6839"], "SR": 0.578125, "CSR": 0.5746527777777778, "EFR": 1.0, "Overall": 0.7873263888888888}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "John Dillinger,", "what caused the collapse of the building which contained the city's historical archives,", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen,", "Brazil's response to the HIV/AIDS fight has been widely praised and adopted as a model around the world.", "Lashkar-e-Tayyiba (LeT), an Islamic militant group based in Pakistan.", "$1.5 million", "2006", "Rev. Alberto Cutie", "Angels", "Indian army", "\"There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "a Starbucks", "BADBUL", "98", "1993", "near the Somali coast", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "Swat Valley", "Iraq", "Iran", "last month", "\"Buying a Prius shows the world that you love the environment and hate using fuel,\"", "in July", "Sudanese nor orphans,", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "at Hansa (Malmborgsgatan 6) and Triangeln (Sodra Forstadsgatan 41)", "broken pelvis,", "Wednesday at the age of 95", "abduction of minors.", "gun", "Aniston, Demi Moore and Alicia Keys", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "barley", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "Missouri", "Burlington", "beta blockers"], "metric_results": {"EM": 0.640625, "QA-F1": 0.754044991167836}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, true, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.9655172413793104, 0.4, 1.0, 1.0, 1.0, 0.5, 0.5714285714285715, 0.3636363636363636, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.9090909090909091, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2108", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-14535"], "SR": 0.640625, "CSR": 0.5770089285714286, "EFR": 1.0, "Overall": 0.7885044642857143}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "technological superiority", "1981,", "forgery and flying without a valid license,", "a racially-tinged remark made by his former caddy,", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul", "Genocide Prevention Task Force.", "shoot down the satellite", "semiconductors", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need.", "Kurt Cobain", "seven", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has.", "Anil Kapoor.", "the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "The Rosie Show", "Form Design Center.", "collaborating with the Colombian government,", "Christianity and Judaism,", "the Dalai Lama's", "Russia", "8 p.m. local time Thursday", "Passers-by", "one day,", "executive director of the Americas Division of Human Rights Watch,", "750", "300", "Matthew Fisher", "The Ski Train", "Big Brother.", "Ozzy Osbourne", "AbdulMutallab,", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "inconclusive", "5:20 p.m. at Terminal C", "environmental and political events.", "$250,000", "byproducts emitted during the process of burning and melting raw materials.", "School-age girls", "5,600", "a million", "Sen. Arlen Specter", "Deutschneudorf,", "bill that would crack down on convicts caught with phones and allow prison systems to monitor and detect cell signals.", "a deceased organ donor,", "bragging about his sex life on television", "a vertebral column ( spine )", "January to May 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "the South Bank", "Douglas Hofstadter", "\"The Dark Tower\"", "American", "March Gate", "Castle Rock", "tomato, mozzarella, anchovy and oil"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7024479502230861}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.9565217391304348, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.125, 1.0, 0.5, 1.0, 0.9090909090909091, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9743589743589743, 1.0, 0.1, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_triviaqa-validation-5458", "mrqa_hotpotqa-validation-4809", "mrqa_searchqa-validation-7309", "mrqa_searchqa-validation-9830"], "SR": 0.59375, "CSR": 0.5775862068965517, "EFR": 0.9230769230769231, "Overall": 0.7503315649867375}, {"timecode": 29, "before_eval_results": {"predictions": ["downward pressure on wages", "El Tem\u00fcr", "438,000", "Marty Ingels", "coaxial", "Pakistan A", "Everbank Field", "7 members appointed by the chief executive", "the German Campaign of 1813", "Arabella Churchill,", "1965", "Paris", "fifth", "Culiac\u00e1n, Sinaloa", "seven", "Province of Syracuse", "1963", "non-alcoholic", "puzzle", "Knoxville, Tennessee", "Washington, D.C.", "Oryzomyini", "Tom Kartsotis", "2017", "Wayman Tisdale", "Mexico", "Srinagar", "Northern Ireland", "late 19th and early 20th centuries", "political thriller", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Shohola Falls", "small forward", "ARY Films", "Erinsborough", "Marine", "Robert A. Iger", "Major Charles White Whittlesey", "Floridians", "Virginia", "NBA Slam Dunk Contest", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "Somerset County, Pennsylvania", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes", "IB Diploma Program and the IB Career - related Program for students aged 15 to 18", "Richard Parker", "off the southernmost tip of the South American mainland", "Charlton Heston", "allergic reaction", "Peter Townsend,", "3,000 kilometers (1,900 miles)", "remains committed to British sovereignty and the UK maintains a military presence on the islands.", "Swiss art heist", "Russia", "peel and devein shrimp", "Australia"], "metric_results": {"EM": 0.578125, "QA-F1": 0.673982181013431}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true], "QA-F1": [0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.25, 1.0, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 0.6666666666666666, 1.0, 0.15384615384615383, 1.0, 0.0, 0.4, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-2228", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-1982", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-8450", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585", "mrqa_searchqa-validation-6793"], "SR": 0.578125, "CSR": 0.5776041666666667, "EFR": 0.9259259259259259, "Overall": 0.7517650462962964}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "deforestation", "Prussian army general, adjutant to Frederick William IV of Prussia", "London", "Dave Thomas", "a farmers' co-op", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations.", "ten years of probation", "John Joseph \" Jay\" Joyce", "Bolton", "Monty Python's Flying Circus", "Kansas City crime family", "Dirk Werner Nowitzki", "Cecil B. DeMille Award", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E.", "New Jersey", "Hl\u00edn", "86,112", "Celtic", "Ouse and Foss", "the United States and Canada", "comedian", "Apatosaurus", "1885", "American", "Frank Thomas' Big Hurt", "\"Gliding Dance of the Maidens\"", "Margarine Unie", "Winecoff Hotel fire", "New York City", "The Seduction of Hillary Rodham", "1919", "Lambic", "Massive Entertainment", "Argentina", "Larry Alphonso Johnson Jr.", "Michael Edward \" Mike\" Mills", "nuclear weapons", "Joseph E. Grosberg", "Chelsea Lately", "276,170", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "the Californian coast at The Inn at Newport Ranch", "New York", "discus", "Aston Lower Grounds", "2005", "228 people", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6892282196969697}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5, 0.6666666666666666, 0.6666666666666666, 0.8, 1.0, 1.0, 0.5833333333333334, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-670", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-363", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-2368", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-672", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.5625, "CSR": 0.577116935483871, "EFR": 0.9642857142857143, "Overall": 0.7707013248847927}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "a huge terrestrial globe", "log ride", "Iowa", "Take Me", "Nassau", "a gemstone formed by the nacreous inner shell", "Dr. Anthony Gallo", "Martin Van Buren", "a network of rail lines", "Rigoletto", "aardwolf", "Beijing", "Roger Bannister", "Rich Clune", "Death Valley", "Yves Saint Laurent", "reindeer", "some other country", "a schooner & 1 sloop", "Anna Mary Robertson", "Sailor Moon", "ceviche", "Harry Potter", "a giant panda bear", "a whirlwind", "John Fogerty", "John Cleese", "a 3-electrode photocathode gun and a flashlamp", "(Milton) Berle", "George Herbert Walker Bush", "Patrice Lumumba", "lunar module", "Pedro de Valdivia", "Dan Marino", "Mars", "a clownfish", "E = mc2", "Guru Pitka", "Las Vegas", "millet", "a butterfly", "Camelot", "orangutan", "Baja California", "soothsayer", "Yitzhak Rabin", "Saul", "Gettysburg", "Jack Gleeson", "Plank", "Buddhism", "Jean Baptiste Jules Bernadotte", "Portugal", "Tom Evans", "Johnson &amp", "acidic", "20 March to 1 May 2003", "\"has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\"", "knocking the World Cup off the front pages for the first time in days.", "12.3 million people worldwide"], "metric_results": {"EM": 0.53125, "QA-F1": 0.55859375}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, false, true, false, true, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.08333333333333333, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-1768", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-899", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-4308", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_triviaqa-validation-4765", "mrqa_hotpotqa-validation-1598", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-3574"], "SR": 0.53125, "CSR": 0.57568359375, "EFR": 1.0, "Overall": 0.787841796875}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62", "Herbert Henry Asquith", "40", "the Central African franc", "Shania Twain", "Hillsborough", "glucagon", "The New York Yankees", "rapid eye movement", "green", "Stanley", "Saddam Hussein", "French", "Jim Branning", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New Years Day", "Sarah Ferguson", "Mercury", "watt", "Peter Butterworth", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "Bras\u00edlia", "optimism", "aged 75", "Jennifer Lopez", "1664", "Morgan Choir", "Fred Perry", "Downton Abbey", "Martina Hingis", "septs", "Cyclops", "The Woodentops", "Michael Miles", "Sheryl Crow", "Gulliver's Travels", "Pomona", "Milan", "Mike Skinner", "Appalachian Trail", "a black Ferrari", "algebra", "grizzly bear", "Michael Moriarty", "June 1992", "24", "1952", "Campbell's", "Kirkcudbright", "the soldiers", "cortisone", "not only can and will continue to help provide safety and physical security, but also could further assist with the reconstruction projects", "Juno", "a typeface", "the lung"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6050595238095238}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, false, false, false, false, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 1.0, 0.057142857142857134, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3508", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-6378", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-3576", "mrqa_triviaqa-validation-2914", "mrqa_triviaqa-validation-6656", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.546875, "CSR": 0.5748106060606061, "EFR": 1.0, "Overall": 0.787405303030303}, {"timecode": 33, "before_eval_results": {"predictions": ["hymn-writer", "deadly explosives", "Knutsford", "insulin", "a Caesar salad", "Hudson Bay", "florida", "allergic rhinitis, or a combination of both.", "mary of Modena", "Asterix", "Brighton", "Belfast", "wind", "fire insurance", "Robin Hood Men in Tights", "West Point", "Andy Warhol", "La Mancha", "John T. Cable", "rykjavik", "the solar system", "potatoes", "Moldovan", "Mitsubishi A6M Zero Fighter", "warblers", "Franz Liszt", "Estimate", "baroudeur-rouleur", "cadmium", "pet Sounds", "Madness", "Buxton", "discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "the Philippines", "beaver", "Mel Blanc", "a dog", "Moffitt", "Ellen Morgan", "Phil Woolas", "5000 meters", "racing", "micelles", "Newfoundland and Labrador", "crow", "Yellowstone National Park", "St. Thomas", "luzon", "Hugh Laurie", "Buddhism", "Guy Berryman", "Ohio", "Port Melbourne", "\u00c6thelwald Moll", "The Schemer", "forgery and flying without a valid license,", "UEFA Cup finalists Werder Bremen beat Athletic Bilbao 3-0 to top Group L,", "Liza Murphy", "Spock", "Kazakhstan", "Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain and Switzerland"], "metric_results": {"EM": 0.546875, "QA-F1": 0.591220238095238}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, false, true, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, false, false, true, true, false, false, false, true, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.19999999999999998]}}, "before_error_ids": ["mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-2100", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-786", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-6083", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-6732", "mrqa_triviaqa-validation-6154", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-1620", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-6068", "mrqa_triviaqa-validation-5870", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5152", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-11382"], "SR": 0.546875, "CSR": 0.5739889705882353, "EFR": 1.0, "Overall": 0.7869944852941176}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business", "steppes steppe", "Bologna, Italy", "George Santayana", "marsupials", "Alice Cooper", "diastolic", "trumpet", "Peter Kay", "a person squeezinging their face, screaming in anguish alone on a dock.", "shildon", "appalachians", "roll-on roll-off", "ballet", "philippian Schell", "george george", "snakes", "manhattan", "Frankie Laine, 93", "The Mystery of Edwin Drood", "pommel horse", "a scarlet tanager", "Dick Van Dyke", "egremont", "manhunt", "Francisco de Goya", "Medea", "Basil Feldman, Baron Feldman", "Canada", "ink sac", "pears soap", "Some Like It Hot", "manhattan", "ireland", "Mike Meyers", "sea horse", "plutonium", "magma", "jules Verne", "How", "spain", "spain", "shrek", "26.22", "Cleveland Brown", "heston Blumenthal", "One Direction", "spain", "Uranus", "Mr. Stringer", "Charles Lindbergh", "September 2001", "Baaghi", "Lead and lead dioxide", "boxer", "Wiltshire", "stoneware", "Pittsburgh", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "Peter Tchaikovsky", "Howard Carter"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5395833333333333}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-5109", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-1724", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-570", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-3837", "mrqa_triviaqa-validation-535", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3623", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_newsqa-validation-78", "mrqa_searchqa-validation-4312"], "SR": 0.46875, "CSR": 0.5709821428571429, "EFR": 1.0, "Overall": 0.7854910714285714}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "Leonardo da Vinci", "Matlock", "American Civil War", "shoa", "ticks", "Arafura Sea", "daedalus", "Tigris", "iceland", "to make wrinkles", "Spain", "carousel", "bullfights", "Mike Brady,", "chimtenor", "cats", "flore", "Guys and Dolls", "Julian Fellowes", "Denmark", "Another Day in Paradise", "The Last King of Scotland", "Ghana", "pembrokeshire", "L. Pasteur", "jean feldsworth", "rachmaninoff", "Finland", "no larger than a city", "Mille Miglia", "caves", "Billaley & His comets", "spain", "Muriel Spark", "happy birthday to you", "seven", "opossums", "pickwick", "presliced bread", "Saga Noren", "raven", "wadi musa", "gMO", "delondon", "Etruscan", "Ken Burns", "grosvenor crescent", "black Army captain Heather Stanning", "Pyotr Ilich Tchaikovsky", "Mujib,", "Libra", "Donna", "season four", "the sinoatrial node", "Lee Sun-mi", "tomato", "2002", "problems with the way Britain implements European Union employment directives.", "L'Aquila earthquake", "March 24,", "Duke of Edinburgh", "Philadelphia", "Pocahontas"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5473958333333333}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, false, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4000000000000001, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-400", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-5215", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_hotpotqa-validation-5135", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.484375, "CSR": 0.5685763888888888, "EFR": 0.9393939393939394, "Overall": 0.7539851641414141}, {"timecode": 36, "before_eval_results": {"predictions": ["Americans", "Kim", "city of acacias", "branson", "Gordon Ramsay", "mansfield town", "Ethel Skakel", "sulfur dioxide and nitrogen oxides", "Margot Betti", "Manchester Airport", "Portuguese", "travelocity", "The Avengers", "at the gateway to the Yorkshire dales is the market town skipton", "comets", "Tom and Jerry", "a ghost", "canola", "Tina Turner", "Benjamin kinglsey", "Preston North End", "Bolivia", "John Donne", "Uranus", "Rio Grande", "spectators", "The Graduate", "Greek", "Ginger Rogers", "king James I", "One Foot in the Grave", "Bronx", "Bob Anderson", "George Santayana", "Shooting Glove", "baltenthwaite", "Wee Jimmy Krankie", "Tomas de torquemada", "Christopher Finzi", "Canada", "rum", "seattlepi.com", "ghee", "George III", "ciao, Milano", "hyperbole", "oldpatrick", "June", "Lady Penelope", "Ceylon", "screwdrivers", "the Kansas City Chiefs", "G minor", "My Summer Story", "2004", "The Outsiders", "Amberley Village", "lack of a cause of death and the absence of any soft tissue", "Canadian Prime Minister Stephen Harper", "her father, Josef Fritzl,", "cixi", "Brigham Young", "May", "chalk quarry"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5125}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, false, false, false, false, true, true, false, true, false, false, true, false, true, true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-6749", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-1971", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-2834", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-132", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_hotpotqa-validation-2330", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-12", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-2849"], "SR": 0.453125, "CSR": 0.5654560810810811, "EFR": 0.9714285714285714, "Overall": 0.7684423262548263}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "the roofs of the choir side - aisles", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "49 cents", "1876", "geologist James Hutton", "Dakar", "joy of living", "420", "George Strait", "sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "London, England", "San Francisco", "September 28, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "hieroglyphs", "Niveditha, Diwakar, Shruti", "freehold", "Tamora Jean Calhoun", "cell nucleus", "Anakin Kenobi", "Travis Tritt and Marty Stuart", "1983", "the Bee Gees", "Matt Czuchry", "Pradyumna", "1902", "A line joining Isle Vierge", "Psychomachia", "New Jersey Devils", "two", "0.30 in ( 7.6 mm )", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Los Angeles", "1978", "Nicki Minaj", "alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Lisa Stelly", "the Canadian Rockies continental divide", "The Maginot Line", "France", "dumbo", "purple", "Charles Guiteau", "Gettysburg Address", "iTunes", "$273 million", "India", "Jeddah, Saudi Arabia", "Desperate Housewives", "Cannonball Run", "morelos", "Tuesday"], "metric_results": {"EM": 0.546875, "QA-F1": 0.663491183801896}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, false, true, false, true, false, true, true, true, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 0.14285714285714285, 1.0, 1.0, 1.0, 0.9285714285714286, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.787878787878788, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.8, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.14035087719298245, 0.25, 0.5454545454545454, 1.0, 0.3333333333333333, 1.0, 0.782608695652174, 1.0, 1.0, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-8470", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-8514", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-7642", "mrqa_searchqa-validation-2335"], "SR": 0.546875, "CSR": 0.564967105263158, "EFR": 0.9310344827586207, "Overall": 0.7480007940108893}, {"timecode": 38, "before_eval_results": {"predictions": ["James Watt", "25 years after the release of their first record", "the Taft -- Katsura Agreement", "Kim Basinger", "fall of 2015", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in the pancreas", "Joseph M. Scriven", "Lady Gaga", "the Chicago metropolitan area", "the president", "Domhnall Gleeson", "eusebeia", "Pastoral farming", "Notts County", "nobiliary particle", "Stephen A. Douglas", "1984", "a loanword of the Visigothic word guma `` man ''", "Pakistan", "Gangneung Ice Arena", "Tagalog", "Bryan Cranston", "thylakoid membranes", "a mental disorder characterized by at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "it lies just north of the state capital, Raleigh", "By late 1922", "2017 / 18 Divisional Round", "602", "stable, non-radioactive rubidium", "Membership is believed to cost between $10,000 and $30,000", "the studies and developments department of the French firm R2E Micral", "1931", "the University of Oxford", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "The `` Southern Cause ''", "Randy", "the Infamy Speech of US President Franklin D. Roosevelt", "Soviet leader Joseph Stalin", "into the intermembrane space", "a divergent tectonic plate boundary", "Idaho", "Sara Gilbert", "Season 6", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "black", "mrs mrs roan Major", "Roddy doddy dine", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below", "General Motors", "David McCullough", "a science fiction novel", "CERN", "paulho"], "metric_results": {"EM": 0.5, "QA-F1": 0.605869620575503}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true, false], "QA-F1": [0.0, 0.09523809523809525, 0.5, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.761904761904762, 0.0, 0.6666666666666666, 1.0, 0.4, 0.4666666666666666, 0.3333333333333333, 1.0, 0.11764705882352941, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5569", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-2743", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-3734", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_triviaqa-validation-5582", "mrqa_newsqa-validation-3486", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.5, "CSR": 0.563301282051282, "EFR": 0.9375, "Overall": 0.750400641025641}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "ATP", "Philippe Petit", "September 1980", "January 2004", "provinces along the Yangtze River and in provinces in the south", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "heavy metal", "March 12, 2013", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "XXXX", "the Berlin School of experimental psychology", "53", "lying between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Skylar Astin", "John Porter", "Brooks & Dunn", "Faceman '' Peck", "Bonnie Aarons", "either late 2018 or early 2019", "clouds, or diffuse nebulae", "the Court declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "John F. Kelly", "Charles Sherrington", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "1960s", "a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Ariel Winter", "Mark Jackson", "Michael Buffer", "\u201c There is one body and one Spirit just as you were called to the one hope that belongs to your call one Lord, one faith, one baptism, one God and Father of all, who is over all and through all", "on location", "the federal government", "1958", "Cody Fern", "questions about the name of the war, the tariff", "prophets and beloved religious leaders", "4.5", "iphon", "Prophet Joseph Smith, Jr.", "doozy (1874 - 1894)", "1909", "John Duigan", "179", "Princess Diana", "Mikkel", "curfew", "Pearl", "shark", "Fast Food Nation", "Hep Stars"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6350711207343679}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.9333333333333333, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.5, 0.5333333333333333, 0.967741935483871, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.47058823529411764, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.10909090909090907, 1.0, 0.0, 1.0, 1.0, 0.2222222222222222, 0.7499999999999999, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-4112", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-5299", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-9093", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-6119", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_triviaqa-validation-3500"], "SR": 0.484375, "CSR": 0.561328125, "EFR": 0.9696969696969697, "Overall": 0.7655125473484848}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "two soldiers, a policeman and four militants", "Joan Rivers", "\"Summer Nights\"", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "attacks", "Zimbabwe", "two weeks ago", "NATO", "Switzerland", "after takeoff from Lebanon early Monday", "second", "\"Nazi Party members digging up American bodies at Berga.\"", "\"it is impossible to turn back the tide of globalization.\"", "Clifford Harris,", "Oaxaca, Mexico", "Robert Barnett", "a class A traffic violation", "41", "Nick Adenhart", "a strict interpretation of the law,", "Derek Mears", "nieb\u00fcll", "on 112 acres about 30 miles southwest of Nashville,", "Tuesday afternoon", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "Section 60", "Ali Bongo", "Allred,", "suggested returning combat veterans could be recruited by right-wing extremist groups.", "Two pages -- usually high school juniors who serve Congress as messengers", "A Brazilian supreme court judge", "Derek Mears", "Operation Crank Call", "help rebuild the nation's highways, bridges and other public-use facilities", "a residential area in East Java", "St. Louis, Missouri.", "NATO fighters", "Raymond Thomas", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls.", "2007", "P.V. Sindhu", "location in Mexico", "Snickers candy bars", "Monodon monoceros", "ivy", "Anaheim, California", "uncle", "Bergen", "embalming", "Cartagena", "a graphical user", "a two - layer coat"], "metric_results": {"EM": 0.4375, "QA-F1": 0.6242505188507026}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, true, true, false, false, false, true, false, true, false, false, true, false, false, true, false, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.30769230769230765, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 0.5, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 0.4, 1.0, 0.07142857142857142, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.29629629629629634, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.5714285714285715, 1.0, 0.0, 0.9523809523809523, 0.3076923076923077, 0.4, 1.0, 1.0, 0.9411764705882353, 0.5714285714285715, 0.3333333333333333, 1.0, 0.0, 1.0, 0.5384615384615384, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-793", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3472", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3433", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-391", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-3541", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.4375, "CSR": 0.5583079268292683, "EFR": 1.0, "Overall": 0.7791539634146342}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1998", "Directed distance is a positive, zero, or negative scalar quantity", "state system", "Megan Park", "the formal currency of the European Union", "Kate Walsh", "September 14, 2008", "American country music artist Trace Adkins", "Mars Hill", "1648 - 51", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "one of the largest financial inflows to developing countries", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "interspecific hybridization and parthenogenesis", "David Joseph Madden", "In England, births were initially registered with churches, who maintained registers of births", "the Dutch figure of Sinterklaas", "Yuzuru Hanyu", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "collect menstrual flow", "pigs", "General George Washington", "Spanish", "Howard Ellsworth Rollins Jr.", "an integral membrane protein that builds up a proton gradient across a biological membrane", "through the right atrium to the atrioventricular node", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Jos Plateau", "Missouri River", "the right to vote", "frontal lobe", "10 June 1940", "Tandi", "Alberich", "ear", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "the project, which is designed to promote private sector investment in a variety of gas-related industries, on September 21.", "Denver, Colorado.", "the Sadr City and Adhamiya districts of Baghdad City,\"", "President Charles Logan", "King Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6627512792397661}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.21052631578947367, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-3651", "mrqa_naturalquestions-validation-5368", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518"], "SR": 0.5625, "CSR": 0.5584077380952381, "EFR": 0.9285714285714286, "Overall": 0.7434895833333334}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization of water", "Middlesex County, Province of Massachusetts Bay", "caused by chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "its population", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "to bring", "Hermann M\u00fcller", "art pottery", "the Soviet Union", "Covington, Kentucky", "New Mexico", "reduces the back pressure, which in turn reduces the steam consumption, and thus the fuel consumption", "December 15, 2017", "located on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive", "L.K. Advani", "differential erosion", "Glenn Close", "the long form in the Gospel of Matthew in the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "electricity generation, power distribution, and power transmission on the island", "by two easily observed features", "Norman Greenbaum", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "compasses", "Charlotte Thornton", "the Northeast Monsoon or Retreating Monsoon", "March 16, 2018", "President Lyndon Johnson", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "asexually", "1926", "East Asia", "starting in 1560s", "Frankie Muniz", "Lou Rawls", "between 1765 and 1783", "Alfheim", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Wood", "96,867", "recall notices", "won two", "prostate cancer,", "wyvern", "Lord Fauntleroy", "a hurrying White Rabbit in a waistcoat", "yellow"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6106918401143944}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, true, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 0.0, 0.4799999999999999, 0.2222222222222222, 1.0, 1.0, 0.0, 1.0, 0.7272727272727272, 1.0, 0.9, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.09090909090909093, 1.0, 0.782608695652174, 0.14814814814814814, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.14285714285714285, 0.08333333333333333, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-3848", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-8157", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.484375, "CSR": 0.5566860465116279, "EFR": 0.8181818181818182, "Overall": 0.6874339323467231}, {"timecode": 43, "before_eval_results": {"predictions": ["2003", "2007", "\" pick yourself up and dust yourself off and keep going ', female - empowerment song ''", "to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "le Roi d'Irlande", "Miami Heat", "1982", "After World War I", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Augustus Waters", "Jean Antonin Merci\u00e9", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home three days earlier,", "Edward Kenway ( Matt Ryan ), a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus ( sea eagles", "rootlets", "Alex Ryan", "habitat", "2018", "Advanced Systems Format ( ASF )", "100", "Toledo", "embryo", "the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "in Paradise, Nevada", "Alicia Vikander as Lara Croft,", "annually", "Ashoka", "the name of a work gang", "Robert Andrews Millikan", "Puerto Rico Electric Power Authority ( PREPA )", "Devastator", "into the Christian biblical canon", "New England", "AMX - 30", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "during the winter of the 2017 -- 18 network television season on CBS", "New York City", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "in the southwestern part of the island", "considered to be unfair", "wintertime", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bonauto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"has been plagued by massive cost and schedule problems - and almost no progress,\"", "\"We want to reset our relationship and so we will do it together.'\"", "Michigan", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5964397686071072}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, false, false, true, false, true, true, false, true, false, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 0.5, 0.8387096774193548, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8571428571428571, 0.888888888888889, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.9090909090909091, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.18181818181818182, 0.0, 0.9189189189189189, 0.0, 0.32, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-2425", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-8027", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977"], "SR": 0.4375, "CSR": 0.5539772727272727, "EFR": 1.0, "Overall": 0.7769886363636364}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "aluminum foil", "Laurel, Mississippi", "mountain-climbing", "Indianola", "Escorts Limited", "Jean Baptiste Point Du Sable", "1992", "Cher", "Alabama", "Jim Harrison", "Toronto", "Tomorrowland", "fennec fox", "United States Army", "stop motion animation", "Jean Acker", "4,530", "Democritus", "Caesars Entertainment Corporation", "Mary Ellen Mark", "Reinhard Heydrich", "Karl Kraus", "Christopher Rich Wilson", "Maria Brink", "Manitowoc County, Wisconsin", "the Northrop P-61 Black widow", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "Andr\u00e9 3000", "Richard Street", "Democratic Republic of the Congo", "Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "a pioneering New Zealand food writer", "South America", "2006", "perjury and obstruction of justice", "Operation Neptune", "Mary Elizabeth Hartman", "over 9,000", "Rosalind Bailey", "potential of hydrogen", "Alamodome in San Antonio, Texas", "Carrie", "tab", "Kent", "almost 9 million", "Kenya", "2008", "terrorism", "Moses", "Haiti", "Jeff Barry and Andy Kim"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6014823717948717}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, false, true, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.8, 0.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-3253", "mrqa_hotpotqa-validation-2069", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-2340", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2933", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.53125, "CSR": 0.5534722222222221, "EFR": 0.9666666666666667, "Overall": 0.7600694444444445}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "1903", "the power to regulate interstate commerce", "Naomi Wallace", "McLaren-Honda", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "Philip Livingston", "Tayeb Salih.", "King James II of England", "God Save the Queen", "526", "Scotland", "\"rock and roll\"", "Gesellschaft", "Mick Jackson", "Lalit", "his virtuoso playing techniques and compositions in orchestral fusion", "Tampa Bay Lightning", "Steven Selling", "Sully", "Manhattan Project", "the Asia-Pacific War", "Romantic", "Hugh Dowding,", "AMC Entertainment Holdings, Inc.", "New York Islanders", "fennec", "1978", "six different constructors taking the first six positions.", "Canadian", "Pacific Place", "the Matildas", "1989", "Rudebox", "the E22", "Francesco Maria Piave", "Engirundho Vandhaal", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Aamina Sheikh, Hasan Ahmed, Neelam Muneer, Zaheen Tahira, Ismat Zaidi, Sami Khan", "the British Army", "power directly or elect representatives from among themselves to form a governing body, such as a parliament", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale", "Frances Ethel Gumm", "Switzerland", "Quadricycle", "NATO's International Security Assistance Force", "2,000", "Cyprus", "Behati Prinsloo", "Saudi Arabia", "Geraldine A. Ferraro", "two"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6371719426406927}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, false, true, false, false, false, true, true, false, false, false, true, false, false, true, false, true, false, true, false, true, false, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.09090909090909091, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-718", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-5010", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_triviaqa-validation-6575", "mrqa_triviaqa-validation-3592", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-8327"], "SR": 0.5625, "CSR": 0.5536684782608696, "EFR": 1.0, "Overall": 0.7768342391304348}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican", "1996", "5", "Greenland sharks", "The Word", "President Abraham Lincoln's", "St Jude Thaddeus", "Anthoonij van Diemenslandt", "the death penalty", "xerophyte", "Jackie Robinson", "Capri or Nantucket", "Dian Fossey", "MI5", "Harrow", "creme anglaise", "a sauce of lemon juice, parsley, salt, pepper", "pork", "curling", "Victoria Coren Mitchell", "Gettysburg", "Chile", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck", "Mercury", "Venus", "Barack Obama", "Canada's Liberal Party", "a first name", "Dominican Republic", "David Bowie", "Stephen King", "Hinduism", "caryatid", "feet", "most of its land in North America", "Mary Poppins", "Glyn Jones", "Port Moresby Harbour, P.N.G.  Milt and Joan Mann/ CameraMann International", "Connecticut", "Quentin Blake", "whooping cough", "daily production from 1919", "(1939\u20131945)", "kosher", "beginning in 2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1944", "Daniel Nestor, from Canada,", "Jeddah, Saudi Arabia", "death", "Beatrix Potter", "Dan Eggen and Elizabeth Williamson", "How to Keep Young Mentally", "the king"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5796875}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-5516", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-2765", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4157", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-1584", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-4384", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-7827", "mrqa_searchqa-validation-6488"], "SR": 0.515625, "CSR": 0.5528590425531915, "EFR": 1.0, "Overall": 0.7764295212765957}, {"timecode": 47, "before_eval_results": {"predictions": ["zebra", "allergic reaction", "David Beckham", "Culloden", "Runic", "Spain", "cricket", "Planck", "rotherham United", "heat transfer", "Misery", "Styal", "stately", "blind beggar", "Mr Brainwash", "Olusoji Fasuba", "parlophone", "Wild Atlantic Way", "john Denver", "alex", "noddy", "Lackawanna six", "more than 23.5\u00b0 South of the equator", "Backyard Kerplunk Game", "muezzin", "a window", "a ship", "madame", "Apollo 11", "flit", "Tesla", "jockey", "evita", "albino sperm whale", "a shrewd business man", "east fife", "st Pancras International Station", "social environment", "presliced", "Dilbert", "mayor of casterbridge", "dimittis", "French", "Medea", "eastern France", "cribbage", "alexa", "Johannesburg", "French", "muffin man", "Seoul", "Prince James, Duke of York and of Albany", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Veracruz, Mexico", "if you buy a ticket with a credit card, then you won't be on the hook if your airline goes under.", "robert frost", "King Henry VIII", "Crescent City", "Mitsubishi Eclipse"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6395833333333334}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8]}}, "before_error_ids": ["mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5914", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-3862", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-5130", "mrqa_triviaqa-validation-6813", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-2610", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.59375, "CSR": 0.5537109375, "EFR": 0.9615384615384616, "Overall": 0.7576246995192308}, {"timecode": 48, "before_eval_results": {"predictions": ["highway sixty-six", "sesame street", "minced", "cabbage", "south melbourne", "jimmy", "fleece", "Ash tree", "opossum", "n Zealand", "jug band", "60", "auric Goldfinger", "1984", "a fish", "mongols", "1875", "tax collector", "penny", "alexia", "Wars of the Roses", "bagram", "jenkins", "Chrysler", "ushanka", "korky the cat", "civil law", "the United States", "france", "peking", "biathlon", "nampa", "charlie Chan", "c Colorado", "white", "jaws", "paul henderson", "rabbit", "france", "jerry", "Orson welles", "hindu Wisdom", "menorah", "post-impressionist", "france", "Super Bowl Sunday", "long pole", "ding dong bell", "alex", "azalea", "Irish", "Chuck Noland", "Colony of Virginia", "Davos, a mountain resort in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park", "2010", "through Greece, the birthplace of the Olympics,", "10 below", "100 to 150", "coins", "the American Kennel Club", "Omaha", "joseph jessica"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4575892857142857}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, false, true, false, false, false, true, true, false, false, true, true, false, false, true, true, false, true, false, false, false, true, false, false, true, false, true, false, true, false, false, true, false, false, true, false, true, false, false, true, false, false, false, true, false, true, false, true, true, true, true, false, false, false, true, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-2056", "mrqa_triviaqa-validation-6738", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-2687", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-263", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-2158", "mrqa_naturalquestions-validation-4803", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.40625, "CSR": 0.5507015306122449, "EFR": 1.0, "Overall": 0.7753507653061225}, {"timecode": 49, "before_eval_results": {"predictions": ["Quin Ivy", "shahcheh-e Namak", "tobacco", "frenchman", "dutch", "Daniel Boone", "Thames Street", "Theodore Roosevelt", "satyrs", "crabs", "lite bohemian life in Paris", "IBM", "wishbone", "Garrick club", "Lackawanna six", "barnaby", "bitten", "American Civil War", "dark", "jennifer leachman", "Frank Saul", "tuscany", "Basil", "veruca salt", "severn", "australian", "south Africa", "bunch grasses", "Nicaraguan", "Clement Attlee", "Wars of the Roses", "Chemnitz", "statistical", "trout", "Joseph Dubonnet", "jennifer ali", "Guatemala", "American Folk Song", "hair loss", "sprint", "charlie darlings", "robin hood", "Chris Martin", "Pebbles", "jennifer deed", "rugby", "honda", "sterning Dan", "11", "tobacco", "cow", "free floating", "Tom Selleck", "New Orleans", "Peter Parker, a talented young freelance photographer and aspiring scientist, and Miles Morales, a high school student", "Texas Tech University Health Sciences Center", "Loughborough Technical Institute", "Herman Cain", "the United States", "\"border states\" to prevent illegal immigration", "George F. Babbitt", "Oklahoma", "Company", "four"], "metric_results": {"EM": 0.34375, "QA-F1": 0.45736607142857144}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, true, true, true, false, false, true, true, true, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true], "QA-F1": [0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.4, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-2309", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-6699", "mrqa_triviaqa-validation-3675", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-6840", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-6060", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_triviaqa-validation-7243", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-115", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-13441", "mrqa_searchqa-validation-3615"], "SR": 0.34375, "CSR": 0.5465625000000001, "EFR": 0.9523809523809523, "Overall": 0.7494717261904762}, {"timecode": 50, "UKR": 0.7578125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.796875, "KG": 0.4671875, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "University of Kansas", "the Docile Don", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Christian Slater, Richard Dreyfuss", "The Dressmaker", "Oakland, California", "37", "Tufts University", "Owsley Stanley", "The Late Late Show", "Kongo", "Harold Lipshitz", "Spanish", "Ted", "1945", "69.7 million litres", "Neneh Mariann Karlsson", "Sunyani West District", "antelope", "Comodoro Arturo Merino Ben\u00edtez International Airport, Santiago, Chile", "Scotty Grainger Jr.", "9", "(Honda) Verno", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1898", "Nicolas Winding Refn", "devotional", "Giuseppe Verdi", "Laban Movement Analysis", "Cecily Strong", "Sam Waterston", "invoicing", "seasonal television specials, particularly its work in stop motion animation", "4 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "teacher Jaime Escalante", "leading lady", "1901", "Pope John X.", "Art Directors Guild's Excellence in Production Design Award", "Electronic Attack Squadron 135", "Alex Skuby", "Nitty Gritty Dirt Band", "English", "'Q'", "FBI", "a jug", "EMI", "UNICEF", "9 a.m.", "Lord Byron", "Van Helsing", "kufic", "a long-range missile"], "metric_results": {"EM": 0.53125, "QA-F1": 0.649702380952381}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, false, false, true, true, false, false, false, false, true, true, false, true, true, true, true, false, true, false, false], "QA-F1": [0.8, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.4, 0.3333333333333333, 0.0, 0.8571428571428571, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.28571428571428575, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5030", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1652", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-7487", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.53125, "CSR": 0.5462622549019608, "EFR": 1.0, "Overall": 0.7136274509803922}, {"timecode": 51, "before_eval_results": {"predictions": ["Ford Field in Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143,007", "Atat\u00fcrk Museum Mansion", "\"Realty Bites\"", "24", "Razor Ramon", "Morita therapy", "Forbes", "St. George, Maine", "Heart", "senior men's Lithuanian national team", "International Boxing Hall of Fame", "35", "Conservatorio Verdi", "Lester Ben \"Benny\" Binion", "Smoothie King Center", "International Conference on LGBT Human Rights", "Homebrewing", "Umberto II", "Presbyterian Church (USA)", "neuro-orthopaedic", "in their home country", "North Sea", "17 October 2006", "67,575", "Oxford", "Dragons", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "English", "Eric Edward Whitacre", "largest Mission Revival Style building in the United States", "180", "George Adamski", "\"Hand of Thrawn\"", "Switzerland", "McKenna's Fort", "Scunthorpe", "Canadian comedian", "Cook's Landing Place", "Boules", "1936", "1970", "the most prestigious venues in the world, including Royal Albert Hall and The Kennedy Center", "Budget Rent a Car System, Inc.", "Japan", "lion", "1959", "Donna Mills", "Is this the feeling I need to walk with / Tell me why I can't be there where you are", "735 feet ( 224 m )", "(Alaska)", "Blanche and Baby Jane", "maxilla", "Microsoft", "4.6 million", "Iran", "tea rose", "John Pershing", "black Russian", "Rear Window"], "metric_results": {"EM": 0.46875, "QA-F1": 0.613121167027417}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, true, false, false, false, false, true, false, true, false, true, false, false, true, false, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, false, true, false, false, false, false, true, true, true, false, true, false, true, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.8, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 0.3333333333333333, 0.5, 0.5, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.2857142857142857, 0.7499999999999999, 1.0, 1.0, 0.5, 1.0, 0.14285714285714285, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-5314", "mrqa_hotpotqa-validation-4927", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-598", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-4820", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-3576", "mrqa_hotpotqa-validation-673", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-3629", "mrqa_triviaqa-validation-84", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653"], "SR": 0.46875, "CSR": 0.5447716346153846, "EFR": 1.0, "Overall": 0.7133293269230769}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "the central voters list was kept or that citizens were given some form of voter identification", "3", "up to 100,000", "Sachin Tendulkar and Kumar Sangakkara", "Judiththia Aline Keppel", "Camping World Stadium in Orlando", "Advanced Systems Format ( ASF )", "the Ramones", "Al Pacino", "a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "Gospel of Luke", "30 years after Return of the Force", "a leonine contract, a take - it - or - leave - it contract, or a boilerplate contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1960", "The British", "1972", "U.S. states of Oregon and Washington", "coercivity", "2010", "Malware", "Cyndi Grecco", "differs in ingredients", "1900", "dorsally on the forearm", "a chimera", "Terry Kath", "birch", "one person", "The Parlement de Bretagne", "Microsoft Windows", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "1986", "late - September", "derivative financial instrument", "1603", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas", "the medulla oblongata", "2018", "Gibraltar", "Howard Caine", "May 3, 2005", "Andy Cole", "Harry patch", "comedy playhouse", "Paul Maskey", "Child actor", "Saoirse Ronan", "Revolution Studios", "The Kirchners", "north London rivals Tottenham", "Gordon Brown", "Ways and Means Committee", "yellow fever", "winter", "Netflix"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7217174369747898}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 0.3137254901960785, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-4852", "mrqa_newsqa-validation-318", "mrqa_searchqa-validation-1310", "mrqa_searchqa-validation-4527"], "SR": 0.671875, "CSR": 0.5471698113207547, "EFR": 0.9047619047619048, "Overall": 0.6947613432165319}, {"timecode": 53, "before_eval_results": {"predictions": ["Alston", "theory of relativity", "Beethoven", "The Carol Burnett Show", "life's Refinements", "a blend of coconut, fruits, nuts", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Airlines", "her coronation", "Vermont", "(VT)", "a candy store", "oncorhynchus", "Pudd'nhead Wilson", "Kuala Lumpur", "deer", "France", "Spam", "Hector Berlioz 7", "Braxton-Hicks", "Camembert", "Friday", "the Golden Legend", "centaur", "Parkhill", "the Lebanese armed forces", "Manifest Destiny", "Al Gore", "disabilities", "bali", "Streets of Philadelphia", "Germany", "Glucosamine", "Madagascar", "website", "celebration", "astrachan (curly lambswool)", "Susan Faludi", "Dr. Dre", "Al Lang Stadium", "Batista", "fudge", "kanga", "management consulting", "goldfish", "hormones", "a dive", "yellowtail", "Nitrides of boron & silicon", "between the Mediterranean Sea to the north and the Red Sea in the south", "Beijing", "Zeus", "van Morrison", "antelope", "maine", "Rocky Mountain Institute", "21", "a cobblestone-size (10x10 cm ) concrete cube bearing a brass plate inscribed with the name and life dates of victims of Nazi extermination or persecution", "three thousand", "insurgent small arms fire", "3,000 kilometers (1,900 miles)", "Lambic"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5026041666666666}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, false, true, true, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, false, true, true, false, false, false, true, false, false, false, true, true, false, true, false, false, true, false, false, true, true, true, false, false, true, true, false, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.9, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-7425", "mrqa_searchqa-validation-13434", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1007", "mrqa_searchqa-validation-7111", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-7952", "mrqa_searchqa-validation-5611", "mrqa_searchqa-validation-4631", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-13258", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-2434", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_searchqa-validation-379", "mrqa_naturalquestions-validation-6319", "mrqa_triviaqa-validation-1000", "mrqa_triviaqa-validation-7747", "mrqa_hotpotqa-validation-3325", "mrqa_newsqa-validation-1792"], "SR": 0.453125, "CSR": 0.5454282407407407, "EFR": 0.9714285714285714, "Overall": 0.7077463624338625}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "in 1837", "Trace Adkins", "Dan Stevens", "state legislators of Assam", "in a nearby river bottom", "the vascular cambium", "Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas ''", "1987", "John F. Kennedy", "in elocution teaching to demonstrate rounded vowel sounds", "Club Bijou on Chapel Street", "seven", "1999", "Rashida Jones", "Hook", "Bush", "tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai", "45 % of the light is in the photosynthetically active wavelength range", "handheld subscriber equipment", "about 15 metres ( 49 feet ) per year", "1998", "Chris Martin", "the Ming dynasty", "for the red - bed country of its watershed", "Thomas Jefferson, John Adams and Thomas Paine", "The Intolerable Acts", "National Industrial Recovery Act", "semi-autonomous organisational units within the National Health Service in England", "Tedde Moore", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg of Mainz, Germany", "1885", "at the 1964 Republican National Convention in San Francisco, California", "the Finch family's African - American housekeeper", "Somatic", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms, while the Resident Commissioner serves for four years", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "the Philippines", "driving", "Furies", "Marine Corps Air Station Kaneohe Bay", "PlayStation 4", "2015 Orange Bowl", "Seminole Tribe of Florida", "Defense of Marriage Act", "Alinghi", "Eiffel Tower", "barnacles", "animal", "jen crawford"], "metric_results": {"EM": 0.5, "QA-F1": 0.629742891780368}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, false, true, false, false, true, true, true, true, true, true, true, false, false, true, true, false, false, false, false, false, true, true, true, false, true, true, true, false, false, true, true, false, false, false, false, false, true, true, false, false, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 0.19999999999999998, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.06451612903225806, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 0.4, 0.0, 0.0, 0.5, 1.0, 1.0, 0.33333333333333337, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.3333333333333333, 0.4, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3892", "mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-5420", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-4137", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-6901", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-4645", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.5, "CSR": 0.5446022727272728, "EFR": 1.0, "Overall": 0.7132954545454546}, {"timecode": 55, "before_eval_results": {"predictions": ["king Edward III", "golf", "purple", "aeoline", "ascot", "Litas", "Loretta Lynn", "WrestleMania", "born to be Wild", "chop suey", "roen mcManus", "Coronation Street", "shanghai police drama", "South Africa", "Ahmed bakr", "New Zealand", "Tyrrhenian", "Bobby Sands", "mauritania", "Hans Lippershey", "Bolivia", "Bob Giraldi", "Mozambique Channel", "ash", "Edward VII", "Thomas Cranmer", "testicles", "Guatemala", "sachin Tendulkar", "Caroline Aherne", "Byron", "s\u00e8vres", "Mau", "kipps: The Story of a Simple Soul", "frankincense", "Serena Williams", "capital of togo", "Pegida", "wagner", "Utrecht", "1709", "Mitford sisters", "Kansas", "miles Morales", "vine plagues", "Skylab", "ostrich", "Hugh Quarshie", "a stern tube", "Batman", "Beijing", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jack", "Linux Format", "Stage Stores,", "26", "ordered the immediate release", "Shanghai", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6306818181818181}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.36363636363636365, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-2148", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-4809", "mrqa_triviaqa-validation-6700", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_searchqa-validation-4261"], "SR": 0.609375, "CSR": 0.5457589285714286, "EFR": 0.96, "Overall": 0.7055267857142857}, {"timecode": 56, "before_eval_results": {"predictions": ["argentina", "bolivia", "Telegraph Media Group Limited", "the liver", "lite", "Drunk Crosswords", "Galway", "Aldo Moro", "calcium carbonate", "Salman Rushdie", "george eliot", "some 1500 km east of Australia across the Tasman Sea", "meatloaf", "benazir butto", "cricketer", "Sam Mendes", "jennifer steed", "way back Attack", "ninth", "business", "Godiva", "darius danesh", "Mexico", "Towy", "alexandro", "1984", "scotland", "one", "shintoism", "Sussex", "king george IV", "Mickey Mouse", "oxygen", "Prince Albert", "toledo", "quietly", "Dodoma", "radiohead", "Wilson", "Loch lomond", "Pyrenees", "South Korea", "gelatine", "new guinea", "gulf of Aden", "Yorkshire", "a\u00e9roport roissy-Charles de Gaulle", "Sankt Moritz", "the French Revolution", "it lies a long bloody way south of the river", "one of the Vikings nine realms", "a salt formed by the combination of acetic acid with an alkaline, earthy, or metallic base", "iron", "Johnson", "Chris Pine", "Yorgos Lanthimos", "Tottenham ( ) or Spurs", "Venus Williams", "off Somalia's coast.", "Shanghai", "peacock", "John Pershing", "governess", "a large portion of rural Maine, published six days per week in Bangor, Maine"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5372549019607843}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, false, false, false, true, true, false, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.11764705882352941]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-4374", "mrqa_triviaqa-validation-2762", "mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-4296", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-5432", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-1331", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-1755", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-4248", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_searchqa-validation-10653", "mrqa_hotpotqa-validation-4052"], "SR": 0.4375, "CSR": 0.543859649122807, "EFR": 1.0, "Overall": 0.7131469298245614}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "michelle zavoroni", "rennet", "river lee", "Rudolf nureyev", "Jessica", "plac\u0113b\u014d", "weather", "lakes placid", "a political treaty, which gave Vatican its own microstate", "contractions", "david lee", "saint Cecilia", "kristina mladenovic", "morecambe and Wise", "tommy lee jones", "butcher", "cowpox", "fox hunting", "Stockholm", "france", "valigo", "anosmia", "a three-stage Athena rocket", "chemnitz", "rue", "yellow", "sea raven", "baltica.com", "ennio morricone", "saratoga and yorktown", "maizia", "timesigns", "turandot", "mzizima", "mauna Kea", "Eat porridge", "Howard Keel", "comedy", "boutros Ghali", "zugspitze", "Sinclair Lewis", "france", "in the garden of gethsemane", "a logic decision tree", "3", "Bild", "France", "Kristiania", "keirin", "selenium", "vehicle that is both four - wheel - drive and primarily a road car", "Noel Kahn", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "he was diagnosed with skin cancer.", "a group of college students of Pakistani background", "Perseid meteor shower", "accordion", "bones", "Marky Mark"], "metric_results": {"EM": 0.5, "QA-F1": 0.5635416666666666}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, true, false, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, false, false, true, false, true, true, false, true, true, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.2, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8, 0.0, 0.5, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-2776", "mrqa_triviaqa-validation-5030", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-883", "mrqa_triviaqa-validation-5579", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-7268", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-7177", "mrqa_triviaqa-validation-2743", "mrqa_triviaqa-validation-2091", "mrqa_triviaqa-validation-4990", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-4857", "mrqa_naturalquestions-validation-10066", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-2238", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-16209"], "SR": 0.5, "CSR": 0.5431034482758621, "EFR": 0.96875, "Overall": 0.7067456896551725}, {"timecode": 58, "before_eval_results": {"predictions": ["Rubbing", "Jonah", "Hugh", "Delhi", "Jacqueline Susann", "the Amazon", "Hudson River", "spinal column", "Bahamas Junkanoo", "the Sons of Liberty", "Napoleon Bonaparte", "C Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "pomegranate", "Mosquitoes", "Siberia", "William Pitt the Younger", "five", "Friday the 13th", "Rotherham", "The Godfather", "wrinkles", "Nostradamus", "jihad", "harpoons", "Mandy", "financial services", "Conrad Hilton Jr.", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "the enemy line", "the bald eagle", "menudo", "Lammermoor", "hurricanes", "sons", "Kashimr (Azad Kasmir)", "airport", "Nu", "Bourbon French Parfums", "a single death", "Little Mermaid", "Harvey Grant", "injecton", "college grants", "beryl", "a dome", "19 July 1990", "Incudomalleolar joint", "Louis XV", "zimmy", "m Mansion House", "squad of soldiers", "London", "Comme des Gar\u00e7ons", "manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo", "Auckland", "money"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5432291666666667}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, true, false, false, true, false, false, true, true, true, false, false, true, false, false, true, false, false, false, true, true, false, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, true, false, false, false, true, false, true, false, true, false, false, false, true, true, true, false, true, false, true], "QA-F1": [0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2820", "mrqa_searchqa-validation-3868", "mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-11218", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-12813", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-16487", "mrqa_searchqa-validation-2704", "mrqa_searchqa-validation-3807", "mrqa_searchqa-validation-7736", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-12017", "mrqa_searchqa-validation-4163", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-2076", "mrqa_triviaqa-validation-737", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225"], "SR": 0.46875, "CSR": 0.5418432203389831, "EFR": 0.9705882352941176, "Overall": 0.7068612911266202}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "SHAKESPEAREAN", "barrel aging", "Leonard Bernstein", "calcium", "Attendolo", "the Danube", "the albatross", "Se sitcom", "Smashing Pumpkins", "a sentence", "Ohio State", "Sherman", "Pakistan", "Theology of God", "Great Britain", "Sally Field", "Barbara Cartland", "rum", "a Pringles can", "Paul Hamm", "a type of classical male singing voice", "East Siberia", "Nimble", "the Toy Story series", "Clue", "Heckle and Jeckle", "Wonder Woman", "alternating current", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "We Are Marshall", "Fairfax", "the trade winds", "ambassador to South Vietnam", "silk", "Syllabic", "the Unicorn", "Scrabble", "the elbow", "Saturday Night Fever", "Petruchio", "Philippines", "mushrooms", "Che Guevara", "Yale University", "Oscar Wilde", "Helen of Troy", "Dian Fossey", "a map", "an iron -- nickel alloy", "ABC", "an opinion in a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court which gives rise to its judgment", "pear", "Melbourne", "big bopper", "Ringo Starr", "Do Kyung-soo", "Hanna", "Majid Movahedi,", "Both Won Sei Hoon, who heads South Korea's National Intelligence Service, and Defense Minister Kim Kwan Jim", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.\"", "Priam"], "metric_results": {"EM": 0.5625, "QA-F1": 0.605594758064516}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, false, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true, true, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.25806451612903225, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-12007", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-9674", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-2384", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-116", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-10144", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-12241", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-6415", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-9910", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-15230", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2745"], "SR": 0.5625, "CSR": 0.5421875, "EFR": 1.0, "Overall": 0.7128125}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Nani", "four", "Sippin' on Some Syrup", "Zack Snyder", "Arnold", "Los Angeles", "the University of Kentucky", "five", "Gust Avrakotos", "Sim Theme Park", "the first front-wheel drive vehicle from Volvo to be sold in North America", "its riverside location", "1858", "Julie Taymor", "actress", "James Edward Kelly", "Spanish", "Indiana University", "Manhattan", "Homeland", "2016", "Virgin Atlantic", "green and yellow", "Champion Jockey", "March 2012", "John Mills", "Erinsborough", "2015", "Vladimir Menshov", "The Birds", "Londonderry", "York County", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "1949", "Savannah River Site", "Eardwulf", "God and the just cause", "Swiss", "Emperor Augustus", "World War I", "October 4, 1970", "Clayton Mark's", "five", "Rodney Crowell", "Mendel", "near major hotels and in the parking areas of major Chinese supermarkets", "scales", "Frankfurt", "Apollo", "Anil Kapoor", "Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment", "Arthur E. Morgan III,", "quarantina", "the Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6588026556776556}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, false, true, true, true, false, false, true, false, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, false, false, true, true, false, false, false, true, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.5, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.15384615384615383, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4914", "mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-5291", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-3314", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-4817", "mrqa_hotpotqa-validation-399", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3100", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-2324", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-871", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-6034", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.578125, "CSR": 0.5427766393442623, "EFR": 0.9629629629629629, "Overall": 0.705522920461445}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaels", "Chicago Bears", "girls aged 11 to 18", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Cartoon Network", "1983", "Rio Ferdinand", "264,152", "2,664", "841", "Cher", "ABC1 and ABC2", "MG Car Company Limited", "Walt Disney and Ub Iwerks", "1979", "15", "January 23, 1898", "John W. Henry", "Bolton", "Argentinian", "Them", "575 acres (2.08 km\u00b2)", "John Snow", "New York and New Jersey", "2013\u201314", "Melbourne Storm", "University of Nevada", "21", "Dziga Vertov", "Friday", "Oklahoma Sooners", "2002\u201303", "Mondays at 7pm", "1866", "Gaahl", "Serie B league", "1887", "Isabella (Belle) Baumfree", "RAF Tangmere, West Sussex", "North Holland", "Don Bluth", "Golden Calf", "Furious 7", "final of 2011 AFC Asian Cup", "Agatha Christie's Marple", "Mercer", "1951", "35,124", "21 years and 154 days", "September 30", "Jimmy Flynn", "powers in the Eastern Bloc ( the Soviet Union and its satellite states )", "his finger", "Ronald Reagan", "One Thousand and One", "long deployments, lengthy separations from family and the perceived stigma associated with seeking help", "promotes fuel economy and safety while boosted the economy", "forcibly drugging", "James Watt", "T.S. Eliot", "Anastasia", "Games"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6668087121212122}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, false, false, true, true, false, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9090909090909091, 0.5, 1.0, 0.7499999999999999, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.4, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 0.2666666666666667, 0.09523809523809525, 0.25, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-5870", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-4939", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-2042", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-5518", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-541", "mrqa_hotpotqa-validation-3061", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-1687", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-1609", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3679", "mrqa_naturalquestions-validation-5180", "mrqa_triviaqa-validation-7611", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129"], "SR": 0.53125, "CSR": 0.5425907258064516, "EFR": 1.0, "Overall": 0.7128931451612903}, {"timecode": 62, "before_eval_results": {"predictions": ["Dayton Memorial Hall", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode", "Babylon", "a card", "water sprite", "Sean Yseult", "law firm", "1937", "Hillsborough County", "Charles Nungesser", "Burning Man", "Love Streams", "Group Captain Peter Wooldridge Townsend", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "Somerset County, Pennsylvania", "John Nicholas Galleher", "German", "Gareth Jones", "consulting services", "April", "1978", "actor, producer, and director", "Melanie Owen", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "American jewelry designer", "Guns N' Roses", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "the German princely Battenberg family", "dice", "Kal Ho Naa Ho", "Dungeness crab", "Pendlebury, Lancashire", "25 October 1921", "Canadian comedian", "David Anthony O'Leary", "Jeremy Hammond", "Reginald Engelbach", "American", "Black Friday", "Minneapolis", "Jean Erdman", "5.7 million customer accounts", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard Seddon", "the right atrium", "Sitka, Alaska", "take the Rio Group to a new level by creating the organization.", "\"It was incredible. We've had so much rain, and yet today it was beautiful. The rain held off wherever Muhammad Ali went,\" Frankie Neylon, the town's mayor said.", "Bob Bogle", "circumference", "The Hague", "a stationwagon", "2001"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6753850179425838}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, true, false, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 0.9473684210526316, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-4838", "mrqa_hotpotqa-validation-5074", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-3797", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-197", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-2224", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-12404"], "SR": 0.578125, "CSR": 0.5431547619047619, "EFR": 0.9629629629629629, "Overall": 0.7055985449735449}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "two weevils", "\"I'll have my bond\"", "water hemlock", "Beluga whale", "Nicholas II", "a tuna", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "salir", "Thor", "Saint Albans", "astride", "Borneo", "Versailles", "Breakfast cereal", "Raleigh", "whipped cream", "Yellowfin", "Thane", "Jean-Michel Basquiat", "Led Zeppelin", "War", "Dutchman", "Moonlighting", "outskirts of a small Southern town", "Columbo", "John Tyler", "Milwaukee", "the Epistle", "Wall Street", "sake", "Notre Dame", "Portland", "Charles-Franois de Broglie", "The Indianapolis 500", "Toy Story", "improv", "Sarah Jessica Parker", "Hungarian", "Gogol", "David Hare", "Fletcher Christian", "weaving", "Pope John Paul II", "Greenland", "John", "The Marx Brothers", "watermelon", "Robin Cousins, Jason Gardiner, Barber and Ashley Roberts", "enterocytes", "Reverend J. Long", "violin", "sexual imagination", "Mount Godwin Austen", "Garrett Morris", "1966", "12 mi", "Susan Atkins,", "almost 9 million", "nearly 2,000", "al-Maliki"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6303199404761904}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, false, true, false, false, true, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, false, false, true, true, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-6211", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-6512", "mrqa_searchqa-validation-1267", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-7670", "mrqa_searchqa-validation-15074", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-8527", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-1825", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-1786", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-3671"], "SR": 0.5625, "CSR": 0.54345703125, "EFR": 0.9642857142857143, "Overall": 0.705923549107143}, {"timecode": 64, "before_eval_results": {"predictions": ["pumpkins", "Seminole", "billions of dollars in Chinese products each year,", "scout", "228", "themes about love and loss.", "2005", "Washington State's decommissioned Hanford nuclear site,", "consumer confidence", "Fernando Gonzalez", "southern port city of Karachi,", "Dan Parris, 25, and Rob Lehr, 26,", "Jason Chaffetz", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah,", "Russia", "Barack Obama", "Sunday", "Gerfa Yeatts Lunsmann,", "France", "41,280", "be silent.", "Apple co-founder Steve Jobs", "sharia,", "\"gotten the balance right\"", "a dozen", "10", "\"Quiet Nights,\"", "his death cast a shadow over festivities", "Iran", "123 pounds of cocaine and 4.5 pounds of heroin", "engineering and construction", "grabbed the gun", "fractured pelvis and sacrum", "at least nine", "to step up.", "12 years after the discovery of Hettrick's stabbed and sexually mutilated corpse in a field near his trailer.", "Moscow", "Mashhad", "summer", "one", "Bryant Purvis", "Jeanne Tripplehorn", "al Qaeda", "Garth Brooks", "Oxbow,", "Ameneh Bahrami", "different women coping with breast cancer", "Felipe Massa", "Luiz Inacio Lula da Silva", "the release of the four men", "2006", "12.9 - kilometre ( 8 mi )", "Tim Passmore", "Theodosius I", "David Pearson", "Estonia", "is our children learning?\"", "Princess Anne", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Ptolemy", "President Woodrow Wilson", "the middle"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6708714896214897}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, false, false, true, true, true, true, false, true, true, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-1295", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-435", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_hotpotqa-validation-1077", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-11117", "mrqa_searchqa-validation-709"], "SR": 0.578125, "CSR": 0.5439903846153846, "EFR": 0.9629629629629629, "Overall": 0.7057656695156695}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "he never robbed the average guy,", "North Korea", "February 12", "Mandi Hamlin,", "United Nations", "\"falling space debris,\"", "Arkansas", "voluntary manslaughter", "in an ambulance,\"", "Chris Robinson,", "Grease", "Cipro", "34", "24 illnesses in multiple states,\"", "More than 15,000", "\"I know a lot of people probably think it's not enough or that you should be going to protests or demonstrations,\"", "The Sopranos,", "government", "September,", "his comments", "South Africa", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano,", "using injectable vitamin supplements because the quantities are not regulated.", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "400 years ago", "Gulf of Aden,", "Obama", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee,", "\"bystander effect\"", "Wednesday.", "managing his time.", "not including co-pays or deductibles.", "bipartisan", "us to step up.\"", "he believed he was about to be attacked himself.", "education about rainforests.", "13", "drug cartels", "state", "Trevor Rees-Jones,", "at least 28 passengers,", "Arturo Gonzalez Rodriguez,", "Ed McMahon,", "at airports", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "Genocide Prevention Task Force.", "243 days", "Kirstjen Nielsen", "August 5, 1937", "20", "Wisconsin", "Mr Loophole", "Arlo Looking Cloud", "Lake Huron", "1694", "the Golden Fleece", "Gustav", "Amish", "6teen"], "metric_results": {"EM": 0.609375, "QA-F1": 0.680377435064935}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, false, true, false, true, false, true, false, true, true, true, false, true, false, false, true, false, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.06666666666666667, 1.0, 1.0, 1.0, 0.2666666666666667, 1.0, 0.0, 0.2727272727272727, 1.0, 0.5714285714285714, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4136", "mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-1801", "mrqa_newsqa-validation-1822", "mrqa_newsqa-validation-3127", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-2717", "mrqa_newsqa-validation-2960", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-9728", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4692"], "SR": 0.609375, "CSR": 0.5449810606060606, "EFR": 1.0, "Overall": 0.7133712121212121}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "sonar", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Spain", "about a mile north of the village of Dunvegan,", "ArcelorMittal Orbit", "lodge", "Joe Stillwell", "Soviet Union", "a clockwork mechanism", "coelacanth", "hainaut", "Dennis Potter", "calcium", "Eric Coates", "Geoffrey Cox", "Mel Brooks", "California condor", "Ohio", "wind turbines", "Sid James", "The Bill", "0", "Hamlet", "Johannesburg", "Crackerjack", "Charles Dickens", "Rodgers and Hammerstein", "Spain", "minder", "mayonnaise, sweet pickle relish and yellow mustard", "Les Dennis", "kansas city", "Hard Times", "tuscany", "tallest building in the world", "Singapore", "Scooby-Doo!", "Pakistan International Airlines", "gold, red, blue, black and white", "France", "Tomorrow Never Dies", "John Fitzgerald Kennedy", "Hong Kong", "Chuck Yeager", "violet- Elizabeth Bott", "northern France", "stamp", "Moby Dick", "the west coast of Central America", "12.9 - kilometre ( 8 mi )", "the American philosophy of pragmatism", "21 July 2015", "Bern", "28 June 1945", "unknown", "25", "Pakistan's", "Yves Saint Laurent", "Rush", "Yogi Berra", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6430059523809524}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, false, false, true, false, true, false, false, true, true, false, true, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-283", "mrqa_triviaqa-validation-1709", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-5912", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-6089", "mrqa_triviaqa-validation-6792", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-613", "mrqa_triviaqa-validation-7014", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_searchqa-validation-7017", "mrqa_newsqa-validation-2682"], "SR": 0.578125, "CSR": 0.5454757462686567, "EFR": 0.9629629629629629, "Overall": 0.7060627418463239}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "Department of the Interior", "Robert Duncan McNeill", "August 3, 1945", "after obtaining the consent of the United Kingdom", "biscuit", "Olivia Olson", "Beijing", "Pyeongchang County, South Korea", "602", "April 7, 2016", "5.7 million", "Wembley Stadium", "the President", "David Joseph Madden", "The Fixx", "takes place at night", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "Royal Air Force", "sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US privacy Act", "around the time when ARPANET was interlinked with NSFNET", "18th century", "Mariah Carey", "Spektor", "H CO", "seven", "September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "Soviet Union", "435", "sport utility vehicles", "Kanawha Rivers", "The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand", "Frank Oz", "1954", "2010", "Missouri River", "\u00c6thelstan", "lute", "belgian", "John Churchill, 1st Duke of Marlborough", "Gregg Popovich", "Asiana Town", "Araceli Valencia,", "Eleven people", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi (Persian)", "melonymy"], "metric_results": {"EM": 0.5, "QA-F1": 0.6302177829083578}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, false, true, false, true, false, false, false, false, true, true, true, true, false], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.33333333333333337, 0.17391304347826086, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 0.8421052631578948, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.25, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1702", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-335", "mrqa_triviaqa-validation-4040"], "SR": 0.5, "CSR": 0.5448069852941176, "EFR": 0.9375, "Overall": 0.7008363970588236}, {"timecode": 68, "before_eval_results": {"predictions": ["German state of North Rhine-Westphalia", "Roberta Flack", "sesame seeds", "infante", "Pirate Day", "barnaby rudge", "Buddha", "ediopia", "1963", "discus thrower", "tabloid", "festival of Britain on London's South Bank", "chester racecourse", "york", "Jews of the Middle East", "lyndon", "Saint Basil the Blessed", "Peru", "the keel on the outside", "Evander Holyfield", "a crosse or lacrosse stick.", "Buddhist", "New Orleans", "soda", "fat like oil or lard", "Richie McCaw", "brashy", "Ken Burns", "paddy doherty", "Barry Howard and Yvonne", "omega", "Hungary", "so Solid Crew", "blues-rock", "Pennsylvania", "caucausus range", "australian", "morningstown Ride", "Jupiter", "The Woodentops", "a child", "four", "Queens Park Rangers", "wiziwig", "giants", "back fabric", "B\u00e9la Bart\u00f3k", "Hugh Dowding", "Montpelier", "month", "Arthur, Prince of Wales", "annual income of US $11,770", "318", "Chris Rea", "Tomasz Adamek", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine", "March 30, 2025", "Amanda Knox's aunt Janet Huff", "Dubai", "a home in an upscale San Fernando Valley neighborhood,", "deep rooted", "Russia Time Zone", "American adventure comedy film", "Jimmy Carter"], "metric_results": {"EM": 0.46875, "QA-F1": 0.577827380952381}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.22222222222222224, 0.6666666666666666, 0.0, 0.4, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5714285714285715, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.28571428571428575, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-1649", "mrqa_triviaqa-validation-5202", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-6849", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-2964", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-361", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-10485"], "SR": 0.46875, "CSR": 0.5437047101449275, "EFR": 0.9705882352941176, "Overall": 0.707233589087809}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey archer", "Chicago", "California Chrome", "dar es salaam", "Sarah Keays", "miss marple", "Elkie Brooks", "United Parcel Service", "Novak Djokovic", "piano", "c Cambridge", "Bennet", "westlife", "syrupy", "addams", "doubting castle", "arthropoda", "france", "jimmy greaves", "Harry Shearer", "9-13 years", "pirate day", "farthings", "spice girls", "The Golden Child", "AFC Wimbledon", "dutch", "Tombstone", "Friedrich Nietzsche", "Cambridge", "South Africa", "bagram", "pygmalion", "bajan", "blackcurrant liquor", "Dieppe Raid", "dengue fever", "left book club", "triathlon", "customs agent Dave Kujan", "splitting of a parent cell into two independent cells", "strictly come Dancing", "sound and light", "par-5", "jack Russell terrier", "prairie region", "raclette", "kilimanjaro", "the Magic Circle", "Yalta Conference", "to start fires, hunt, and bury their dead", "London", "Cordelia", "London Luton Airport", "Sarah Winnemucca", "Antigua & Barbuda, Argentina, South Africa, Fernando P\u00f3, S\u00e3o Tom\u00e9, Madagascar, Mauritius, Mayotte, R\u00e9union, Seychelles,", "the murder of the boss could never be justified.", "it is in the best interest for both of them.\"", "\"The deceased appeared to have been there for some time.\"", "Vanilla Ice", "Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5379204403053087}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false, false, true, false, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, false, true, true, false, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.5, 0.5454545454545454, 1.0, 0.0, 0.5, 0.0, 0.0, 0.14285714285714285, 0.10526315789473685, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-2520", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-854", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-5185", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-1346", "mrqa_triviaqa-validation-4970", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627", "mrqa_searchqa-validation-3002"], "SR": 0.46875, "CSR": 0.5426339285714286, "EFR": 0.9705882352941176, "Overall": 0.7070194327731093}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew", "complex sentence", "Australia", "Ashrita Furman", "No Secrets", "1994", "April 2010", "12 November 2010", "1 October 2006", "1977", "in 2018", "Missouri", "Swedien and Jones", "in 1902", "Edgar Lungu", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "1999", "the city of Indianapolis", "Latitude", "anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Van Halen", "U.S. dollar", "the team that lost the pre-game coin toss", "Carnaval de Qu\u00e9bec", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W", "If These Dolls Could Talk", "around 2011", "New Jersey Devils of the National Hockey League", "ulnar nerve", "November 2016", "19th - century", "indigenous to many forested parts of the world", "Western Australia", "Carol Worthington", "1830", "biological agents", "thanksgiving for a good harvest", "( born November 28, 1973 )", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Anthony Hopkins", "Jesus Christ", "1996", "holographic", "Spanish", "FAR CONTINING CROWD", "Gillian Leigh Anderson", "the theory of direct scattering and inverse scattering", "45th Infantry Division", "\"it should stay that way.\"", "2009", "an open window", "Dutchman", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.53125, "QA-F1": 0.7136488970588235}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, false, false, false, false, false, true, true, false, true, false, false, true, false, true, true, true, false, false, false, true, true, true, false, true, true, true, true, false, false, false, true, true, false, true, true, false, false, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 0.823529411764706, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.8, 0.0, 0.8571428571428571, 0.4, 0.7142857142857143, 1.0, 1.0, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8314", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-5300", "mrqa_naturalquestions-validation-7359", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9867", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-2623", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-2577", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-2384", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-5292", "mrqa_newsqa-validation-2658", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.53125, "CSR": 0.5424735915492958, "EFR": 0.9, "Overall": 0.6928697183098592}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "inner core and growing bud", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan", "the ball is fed into the gap between the two forward packs", "Total Drama Action", "to the left of the dinner plate", "red", "off the rez", "either in front or on top of the brainstem", "On March 14, 1942", "Aegisthus", "Epithelium", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Vincent Price", "Pakistan", "Tessa Peake - Jones", "an expected or free or continuously changing behaviour", "United Nations Peacekeeping Operations", "part of the normal flora of the human colon", "Noahic Covenant", "Shirley Mae Jones", "Heat transfer by thermal radiation", "John 6 : 67 -- 71", "on August 19, 2016", "Sets heart in mediastinum and limits its motion", "scrolls", "Terrell Suggs", "Cecil Lockhart", "August 22, 1980", "the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "letter series", "on August 21", "in the Blue Ridge Mountains of Virginia", "the Confederacy", "1955", "electron donors", "2", "Montreal Canadiens", "in 1985", "On 1 September 1939, Germany invaded Poland", "three levels", "product-market fit", "Wyatt `` Dusty '' Chandler ( George Strait )", "the last book accepted into the Christian biblical canon", "In the 1920s", "ice giants", "mid-1980s", "Camellia sinensis", "european economic community", "mumbai", "Frank Fertitta, Jr.", "Coronation Street", "Michael A. Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "complicated and deeply flawed", "Crandon, Wisconsin,", "(butterflies and Skippers)", "Rocky Mountain spotted fever", "$500", "Afghan forces in destroying drug labs, markets and convoys,\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.6147063872673705}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, false, false, false, true, true, false, true, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.5, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.35294117647058826, 0.75, 1.0, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.7692307692307693, 1.0, 0.8571428571428571, 1.0, 0.2857142857142857, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.10526315789473684, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.6666666666666666, 0.0, 0.5714285714285715, 0.4444444444444445, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.967741935483871, 0.0, 0.0, 0.0, 1.0, 0.0, 0.16666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-9154", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.46875, "CSR": 0.5414496527777778, "EFR": 1.0, "Overall": 0.7126649305555556}, {"timecode": 72, "before_eval_results": {"predictions": ["Earth Day", "Afghanistan", "mustard", "suffrageette", "(Germany)", "Christopher Darden", "a jelly bean", "a cloudy day", "Daniel Berrigan", "wheat", "Carole King", "Spain", "The Pro-Jig Clamp Set", "Christo", "Wichita", "Agriculture", "Gilligan's Island", "Penelope", "Tom Harkin", "Channel Islands", "Hershey", "Penelope", "a personal pronoun", "Bonobos", "(Einstein)", "Veep", "alex", "lullaby", "a ruby", "Pan's Labyrinth", "Hans Christian Andersen", "John Irving", "a demonstrative pronoun", "The Who", "Europe and Asia", "Xerox", "virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "World War II", "Beijing", "Lee Harvey Oswald", "(George) Armstrong Custer", "Newton's", "a microphone", "Orlando", "Alaska", "a puff", "Mausolus of Caria in Asia Minor", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew", "(Samuel) Joshua", "Saint Cecilia the Patron Saint of Musicians", "Germany", "1989 until 1994", "Suzuki YZF-R6", "nose, cheeks, upper jaw and facial tissue", "Piers Morgan,", "three", "Kim Bauer"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5890438988095238}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.8571428571428571, 0.0, 0.8750000000000001, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-10065", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-16049", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3351", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-13584", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-6286", "mrqa_triviaqa-validation-4653", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681", "mrqa_newsqa-validation-1587"], "SR": 0.515625, "CSR": 0.5410958904109588, "EFR": 0.967741935483871, "Overall": 0.7061425651789659}, {"timecode": 73, "before_eval_results": {"predictions": ["Hairspray", "the Fonz", "Rita Mae Brown", "Bolivia and Paraguay", "Kansas", "a grasshopper", "the commander", "Sure", "1876", "brood", "a spectator", "Humphrey Bogart", "Maryland", "Munich", "a pen", "Herod", "the Lone Ranger", "Malaysia", "Georgetown University", "Bruce Rauner", "Goofy", "Walter Payton", "Mount Everest", "(Winston) Garvey", "a pindar poem", "a bird", "the Tom Thumb", "Strathearn", "the Mad Hatter", "a tryptophan", "Cincinnati", "a bicep tear", "a concert grand", "ketchup", "peanut butter", "Pel", "Tom Petty and the Heartbreakers", "Tuscany", "Tunisia", "Rosa Parks", "an inch", "Paris", "William Henry Harrison", "Corinthian", "carats", "Bern", "Prada", "Chicago", "anything on the inside", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "2015", "tipping point", "Scotland", "epeiric (or \"shelf\") sea", "James Harden", "ethereal wave", "Ronald Lyle \" Ron\" Goldman", "\"Sesame Street\"", "fusion teams", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.625, "QA-F1": 0.6901041666666667}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, true, true, false, false, true, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, true, false, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-360", "mrqa_searchqa-validation-14786", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-12562", "mrqa_searchqa-validation-13507", "mrqa_searchqa-validation-16552", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-4837", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-2988", "mrqa_searchqa-validation-7656", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15724", "mrqa_naturalquestions-validation-7366", "mrqa_triviaqa-validation-4662", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-2410", "mrqa_newsqa-validation-3105"], "SR": 0.625, "CSR": 0.5422297297297297, "EFR": 1.0, "Overall": 0.712820945945946}, {"timecode": 74, "before_eval_results": {"predictions": ["wholesale", "The Tyger", "\"Thunder Road\"", "the Last Supper", "Baccarat", "a bishop", "Harlem", "a haystack", "a boat", "Drug Rehab & Treatment Center", "a cricket", "India", "Children of Men", "Skagway", "a written request", "Hippolyta", "a species", "John Galt", "spinach", "milk", "1,000 watts", "a fecund theory", "World War I", "a student loan", "the Gateway Arch", "Itzhak Perlman", "Wolfgang Johannes Puck", "a dachshund", "the Monitor", "Cyprus", "Milwaukee", "Coffee Syrup", "Kevin Costner", "Hot Lips", "Isadora Duncan", "Pig Latin", "Little Debbie", "Richard Cheney", "Speed Racer", "The USA", "Aristotle", "an emergency room", "The Eagles", "An American Tail", "a bus tour", "anlam", "Honda", "a wallaby", "a leather feather", "Mark Twain", "Greg", "30 October 1918", "Mel Tillis", "Michael Moriarty", "James Christopher Bolam", "pawn", "brazil", "House of Habsburg-Lorraine", "(Obergruppenf\u00fchrer)", "Kansas\u2013Nebraska Act", "Orbiting Carbon Observatory,", "South Africa", "Tuesday", "two"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6526041666666667}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, false, false, false, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-12847", "mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-11529", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-8228", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-3118", "mrqa_searchqa-validation-4702", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-4180", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-7628", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-5344", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_triviaqa-validation-3779", "mrqa_hotpotqa-validation-686"], "SR": 0.59375, "CSR": 0.5429166666666667, "EFR": 0.8846153846153846, "Overall": 0.6898814102564103}, {"timecode": 75, "before_eval_results": {"predictions": ["Muhammad", "following the 2017 season", "Chinese dynasty", "1908", "at specific locations, or origins of replication, in the genome", "Javier Fern\u00e1ndez", "Sarah Brightman as Christine and Steve Barton as Raoul", "silk floss tree", "Hold On", "Gustav Bauer, the head of the new government", "November 2016", "Empiricism", "Identification of alternative plans / policies", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "Greenland ( / \u02c8\u0261ri\u02d0nl\u0259nd / ; Greenlandic : Kalaallit Nunaat, pronounced ( kala\u02d0\u026cit nuna\u02d0t )", "Johnson", "Song of Songs", "Taron Egerton as Johnny", "its vast territory was divided into several successor polities", "acronym", "Sheev Palpatine", "Divyanka Tripathi", "September 24, 2012", "Only two men", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "the homicidal thoughts of a troubled youth", "John C. Reilly", "Daniel A. Dailey", "Mickey Mantle", "addition, subtraction, multiplication, and division", "December 15, 2016", "Kid Creole and the Coconuts", "year 1 BC", "2010", "microfilament", "1983", "John Roberts", "the President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Podujana Peramuna, led by former president Mahinda Rajapaksa, secured the most seats and local authorities.", "1773", "Buddhism", "introverted Sensing ( Si ), Extroverted Thinking ( Te ), introverted Feeling ( Fi ) and Extrovert Intuition ( Ne ) )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "yorkshire", "t.S. Eliot", "tzircons", "Lieutenant Colonel Horace Meek Hickam", "Rihanna", "comments had been taken out of context.", "fractured pelvis and sacrum", "2001", "a loss", "Blackbird", "Luddington", "September 25, 2017"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6103236607142857}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, true, false, false, false, true, true, false, true, true, false, true, true, false, false, false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 0.7142857142857143, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4444444444444445, 0.5714285714285715, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.16666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 1.0, 1.0, 0.375, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-8155", "mrqa_naturalquestions-validation-9766", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-4976", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-9450", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.546875, "CSR": 0.54296875, "EFR": 0.9655172413793104, "Overall": 0.7060721982758621}, {"timecode": 76, "before_eval_results": {"predictions": ["her arranged marriage to Chino, a friend of Bernardo's", "Walter Mondale", "a system of state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "1928", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "at least 28", "Theodore Roosevelt", "once in about 24 hours", "Universal Pictures and Focus Features", "multiple", "restarting play after a minor infringement", "A footling breech", "Catching Fire ( 2013 )", "the President of India", "cunnilingus", "28 %", "American singer Elvis Presley", "N\u0289m\u0289n\u0289\u0289", "Jack Scanlon", "during the 2013", "Elijah Wood", "head - up", "Doug Pruzan", "by October 1986", "Icona Pop", "inside the cell nucleus", "pathology", "the age of about 14", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "ingredients", "Jourdan Miller", "Panzerkampfwagen VIII Maus ( `` Mouse '' )", "limited period of time", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "New England Patriots ( 5 - 4 )", "40 %", "Janie Crawford's `` ripening from a vibrant, but voiceless, teenage girl into a woman with her finger on the trigger of her own destiny", "the east coast of Queensland", "April 2, 2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "St. Louis Blues", "around 1872", "Billy Colman", "starch", "carbon", "on the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery F.C.", "Phelan Beale", "one", "Government Accountability Office report", "\"The Ethiopian army's answer to the rebels has been to viciously attack civilians in the Ogaden,\"", "a suit jacket", "Heroes: Reborn", "a lush, plentiful version of the Egypt of the living", "since 1983."], "metric_results": {"EM": 0.375, "QA-F1": 0.5562720265845266}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, false, false, false, false], "QA-F1": [0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 0.0, 0.26666666666666666, 0.0, 0.7499999999999999, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5714285714285715, 0.8, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.30769230769230765, 0.4615384615384615, 0.0, 0.0, 0.09090909090909091, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.6666666666666666, 0.2, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-1427", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-10195", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-5719", "mrqa_naturalquestions-validation-2782", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_hotpotqa-validation-3250", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-3373", "mrqa_searchqa-validation-1664", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.375, "CSR": 0.5407873376623377, "EFR": 0.975, "Overall": 0.7075324675324676}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes virus, (Another name for shingles is herpes zoster.)", "zork", "roddy Doyle", "Marked by Teachers.com", "Prussia", "Joseph Rudyard Kipling", "Spongebob Squarepants", "Exile", "an enclave which is entirely enclosed by another nation", "South Dakota", "Brian Close", "cabbage worm", "leeds", "Edinburgh", "a traffic warden", "cricketer", "France", "Neptune", "Vimto Fizzy", "phosmphobia", "phoenix", "carry On Cleo", "afro-Asiatic", "sense of taste", "a snare drum", "seafloor spreading and plate tectonic activity picked up, and a period of continental rifting began.", "sesame seed", "hurdles", "The Centaurs", "tallest building in the world", "football", "Metro Goldwyn Mayer Studios Inc.", "Quentin Blake", "Giglio Island", "Copenhagen", "upper haight", "Geoffrey Rush", "Harry patch", "comic cuts", "sight & sound", "Inigo Jones", "sonar", "Nelson Mandela", "Today", "trousseau", "Utah", "Mark Darcy", "reptilian", "Africa, India, Madagascar, Australia and Antarctica", "salyut 1", "Puerto Rico", "Guy Burnet as Theo, DJ Khaled's music producer, who takes a liking to Beca", "62", "Matthew Gregory Wise", "1861", "voice actress", "Playdead", "12.3 million", "July", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "a fathom", "$163 million (180 million Swiss francs)"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5624526515151514}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true, false, true, false, false, false, false, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, false, false, false, true, true, true, false, false, true, false, true, true, true, true, false], "QA-F1": [0.3636363636363636, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-5462", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-7005", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-2362", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-1976", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-7059", "mrqa_triviaqa-validation-479", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_naturalquestions-validation-3208", "mrqa_hotpotqa-validation-5278", "mrqa_hotpotqa-validation-1689", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.484375, "CSR": 0.5400641025641026, "EFR": 1.0, "Overall": 0.7123878205128206}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "an incident which was described by judge Henry Globe as an \"explosion of violence.\"", "1964", "\"tributes,\"", "a \"momentous discovery\"", "Al-Aqsa mosque", "on top again in the final session with a 74 stand", "as soon as 2050,", "Sylt", "media", "Baghdad", "Barack Obama", "10 municipal police officers", "left his indelible fingerprints on the entertainment industry.", "pizza, the other for the drug ketamine.", "Brian David Mitchell,", "Defense of Marriage Act", "Jacob", "Ronaldinho", "Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "\"brain hacking\"", "nine o'clock", "start a dialogue of peace", "al Qaeda,", "Manmohan Singh's", "cope in prison.", "one-of-a-kind navy dress with red lining", "\"My gut started feeling like something just wasn't right,\"", "10,000", "Meira Kumar", "antihistamine and an epinephrine", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's", "Arthur E. Morgan III,", "million dollars", "bribing other wrestlers to lose bouts,", "Eleven", "don't feel Misty Cummings has told them everything she knows.", "10 below", "Steven Gerrard", "$8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Carol Browner", "a warning to those who deny human rights.", "Brazil", "10", "the return of a fallen U.S. service member", "supermodel", "Horseshoe Bartender", "early Christians of Mesopotamia", "16 seasons", "e pluribus unum", "well", "czech republic", "Capture of the Five Boroughs", "Double Crossed", "pornographicstar", "God", "Petroleum", "Fannie Farmer", "democracy and personal freedom"], "metric_results": {"EM": 0.5, "QA-F1": 0.6145772812713601}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true, true, false, true, true, true, true, false, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 1.0, 1.0, 0.33333333333333337, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.6666666666666666, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.7368421052631579, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-1986", "mrqa_newsqa-validation-2378", "mrqa_naturalquestions-validation-4008", "mrqa_triviaqa-validation-744", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-16904", "mrqa_searchqa-validation-15636"], "SR": 0.5, "CSR": 0.5395569620253164, "EFR": 0.96875, "Overall": 0.7060363924050633}, {"timecode": 79, "before_eval_results": {"predictions": ["1866", "Grant", "the Yangtze River", "Judah", "Queen Anne", "the New York Times", "America", "Oklahoma", "the Communist Party", "the Nuclear Age", "Sir Humphry Davy", "seoul", "24 hours", "smallpox", "the Dead Sea", "the fairway", "Hill Street Blues", "elevation", "Mao Zedong", "Harriet M. Welsch", "Mickey Mouse", "Xerox", "blitz", "Jamaica", "gossip", "an exothermic reaction", "canabalism", "Morocco", "Surf's Up", "Yao Ming", "the Department of the Treasury", "dolls", "Marvell", "fruits", "Hindi film", "\"Titanic\"", "Take Me Out to the Ballgame", "a parapet", "Joe Lieberman", "the World's Fair", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Suriname", "Pearl", "(SOE) Platform", "Switzerland", "Vestal virgins", "The Lord of the Rings: The Return of the King", "Fidel", "H CO ( equivalently OC ( OH ) )", "in a thousand years", "W. Edwards Deming", "Clara", "Douglas Trendle", "Warwick", "RickyRubio", "Edith Cavell", "Forbes", "cardio for 45 minutes, five days a week.", "22", "Demjanjuk", "1,776"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6691761363636364}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, false, false, false, false, false, true, false, false, true, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.7272727272727272, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 0.4, 0.8333333333333333, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14620", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-11663", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-9998", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-7330", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-8650", "mrqa_naturalquestions-validation-1834", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-4078", "mrqa_newsqa-validation-2118", "mrqa_naturalquestions-validation-3561"], "SR": 0.53125, "CSR": 0.539453125, "EFR": 0.9666666666666667, "Overall": 0.7055989583333333}, {"timecode": 80, "before_eval_results": {"predictions": ["Homebrewing", "the German Empire", "Tim Whelan", "Waimea Bay", "the Virgin label", "the Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis August Schaeffer", "26,788", "nine", "strongly associated with Gaia and Cybele", "Azeroth", "1,467 rooms", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "\"From Here to Eternity\"", "the Manor of the More", "England, Scotland, and Ireland", "the Workers' Party", "recounts how his own opinions changed about that line", "his exploration and settlement of what is now Kentucky,", "six", "Mauthausen-Gusen", "Adrian Peter McLaren", "Distillery", "Theodore Anthony Nugent", "New York", "Viscount Cranborne", "The Frog Prince", "Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Martins", "Boulder High School in Boulder, Colorado", "Dutch", "November of that year", "Boston, Massachusetts", "Kaley Christine Cuoco", "Brendan O'Brien", "Delphine Software International", "University of Kentucky College of Pharmacy", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "150 - member House of Representatives", "September 15, 2012", "Andy Murray", "Vienna", "malaysia", "Akio Toyoda", "Iran's nuclear program.", "alternative-energy vehicles", "the78rpmrecordspins", "(two)", "the King", "soybeans"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6574373543123544}, "metric_results_detailed": {"EM": [false, false, true, true, false, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, false, false, true, false, false], "QA-F1": [0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.6153846153846153, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.7272727272727272, 1.0, 0.19999999999999998, 0.33333333333333337, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-5694", "mrqa_hotpotqa-validation-739", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-5231", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-5476", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-3760", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-8992", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-10352"], "SR": 0.53125, "CSR": 0.5393518518518519, "EFR": 1.0, "Overall": 0.7122453703703704}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "Allies of World War I", "acid house", "Esteban Ocon", "Lady Frederick Windsor", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham, Alabama", "Nobel Prize in Physics", "Adam Karpel", "rock and roll", "1957", "Windermere, Cumbria (town)", "Sir Frank P. Lowy", "Hermione Baddeley", "Metrolink", "South Australia", "1698", "Greenwood", "Nickelodeon Animation Studio", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "Jenson Alexander Lyons button", "William Shakespeare", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Dar es Salaam", "English Electric Canberra", "3 August 1916", "Smithsonian", "Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoon Fridays", "The Company", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Imperial War Museum", "Tyrann Devine Mathieu", "1933", "British Columbia, Canada", "The Great Gatsby", "willow", "Cliff Thorburn", "Kim Clijsters", "Kenya,", "was hanged in 1979 for the murder of a political opponent two years after he was ousted as prime minister in a military coup.", "Elementary", "The New York City Ballet", "voltage", "Willa Cather"], "metric_results": {"EM": 0.484375, "QA-F1": 0.595250496031746}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, true, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, true, true, true, true, false, true, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, true, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-3557", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-4081", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_hotpotqa-validation-4359", "mrqa_triviaqa-validation-873", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.484375, "CSR": 0.5386814024390244, "EFR": 0.9696969696969697, "Overall": 0.7060506744271988}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Dame Harriet Walter", "Algernod Lanier Washington", "Conservative Party", "Emmy and four", "July 23, 1971", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "2006", "Norwegian", "The Late Late Show", "Ry\u016bky\u016b minzoku", "Commanding General", "\"50 best cities to live in.\"", "Mike Mills", "Parlophone", "January 15, 2016", "IATA: VNO, ICAO: EYVI", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "The Worm", "Herman's Hermits", "Ustad Vilayat Khan", "810", "German", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1902", "Richard Price", "Novel", "Gabriel Iglesias", "3,384,569", "Gambaga", "2 March 1972", "Blue Ridge Parkway", "La Scala, Milan", "every aspect of public and private life", "Gary Ross", "Hanford Site", "Commissioner", "Sam Tick", "Estelle Sylvia Pankhurst", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "2 May 2015", "England", "King Duncan", "Bourbon County", "Qu'est-ce qu'on a fait au Bon Dieu", "Epithelial tissues", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "Ringo Starr", "1882", "off the coast of Dubai", "The incident Sunday evening", "not doing more", "hard disk space", "polio", "the treble clef", "gun charges"], "metric_results": {"EM": 0.671875, "QA-F1": 0.7243055555555555}, "metric_results_detailed": {"EM": [true, false, false, true, false, false, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.5, 0.2222222222222222, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4717", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-438", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_naturalquestions-validation-7459", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732"], "SR": 0.671875, "CSR": 0.5402861445783133, "EFR": 0.9523809523809523, "Overall": 0.7029084193918531}, {"timecode": 83, "before_eval_results": {"predictions": ["May 29, 1917", "Metacomet", "Chicago", "Leon Trotsky", "a dough", "a family tree", "\"All the News That's Fit to Print\"", "Martin Van Buren", "Ugly Betty", "Winnie the Pooh", "Mefistofele", "Alexander Graham Bell", "(Vijay) Singh", "the clouds", "a modem", "Canada", "the Boston Red Sox", "Comedy Central", "Mussolini", "the Essay on Man", "Jane's Electro-Optic Systems", "Christo", "a psychiatrist", "Ichiro Suzuki", "Frank Sinatra", "Africa", "the banjo", "Northern Virginia", "Belle Watling", "Mozart", "the '90s", "the Asylum", "Lord Byron", "Meningitis", "Douglas MacArthur", "3M", "The Rolling Stones", "Edie Falco", "the USA", "the College of William", "the 1936 Summer Olympics", "the CN Tower", "The Hurricane", "Gregor", "Maryland", "the cardinal", "Japan", "the cow", "New Brunswick", "Hindu", "the pronghorn", "starting on January 2, 1971", "San Francisco", "Moscazzano", "Cliff Thorburn", "guizhou Province", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul John Manafort Jr.", "1959", "The son of Gabon's former president", "the United States", "in mid November"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6265625}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, false, true, false, false, false, true, true, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.6666666666666666, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-11538", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-889", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-15564", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-14502", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-16652", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-4122", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_naturalquestions-validation-47", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_newsqa-validation-3923", "mrqa_naturalquestions-validation-8884"], "SR": 0.515625, "CSR": 0.5399925595238095, "EFR": 1.0, "Overall": 0.7123735119047618}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto Shinto", "Hook", "Jabez Stone", "William Howard Taft", "olive brine", "pemmican", "Olivia Newton-John", "Oahu", "Joseph Smith", "Arthropoda", "Harry S. Truman", "Capricorn", "Diane Arbus", "Stuffed Poblano Chiles", "Thomas Jefferson", "the legislature", "tofu", "Old School", "the DEW Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "Kirkus Reviews", "Robert Bruce", "Zinc", "oxys", "Gargantua", "Elke Sommer", "claws", "Robin Williams", "Philadelphia", "laundry soap", "their children", "The Five People You Meet in Heaven", "the anglerfish", "the Big Cat", "Thomas Jefferson Family Cemetery", "Mohandas Gandhi", "Brazil", "Jim Thorpe", "Michael", "Dust Hoffman", "King Lear", "descend", "the Bicentennial Symphony", "the Haunted Mansion", "Rembrandt", "Gilligan\\'s Island", "your timehare", "Buffalo Bill", "Manhattan", "Tom Robinson", "Andy Serkis", "South Africa", "horizontal desire", "Charlie Drake", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun", "Asashoryu", "because of what they had done to Muslims in the past,\"", "United States Holocaust Memorial Museum, The American Academy of Diplomacy and the United States Institute of Peace", "Saracens"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5744791666666667}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, true, true, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, false], "QA-F1": [0.6666666666666666, 0.0, 0.0, 0.5, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.26666666666666666, 0.1, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6258", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-10754", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-4945", "mrqa_searchqa-validation-12089", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-11112", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16785", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-5050", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-2724", "mrqa_triviaqa-validation-5224"], "SR": 0.46875, "CSR": 0.5391544117647059, "EFR": 1.0, "Overall": 0.7122058823529411}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "Postcards from the Edge", "birds", "Virginia", "hot chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "\"The play\"", "The Carol Burnett Show", "a panic", "Gertrude Stein", "Pope John XXIII", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tippi Hedren", "object-oriented programming", "Nova Scotia", "cocoa", "tuna", "Absinthes", "Macragge", "marsupials", "quid", "(John Wilkes) Booth", "Anthony Newley", "ear infection", "Henry", "gigahertz", "Greek", "Jeff Probst", "\"Hopelessly Devoted to You\"", "Nasser", "The Moment of Truth", "Laura", "Cerberus", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "Bill & George Clinton", "the Black Sea", "May 12, 1907", "a penny", "Young Frankenstein", "ShoutWipe", "to form a higher alkane", "comprehend and formulate language", "eusebeia", "Venezuela", "The Shootist", "segas", "National Society of Daughters of the American Revolution", "Johnny Galecki", "44,300", "it has not", "At least 88", "went missing off Catalina Island,", "\"It appears that there was a struggle between the victim and the suspect in the threshold of the hotel room immediately prior to the shooting,\""], "metric_results": {"EM": 0.5625, "QA-F1": 0.6553285256410256}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, false, false, false, true, true, true, true, false, false, true, false, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.5, 0.5, 0.0, 0.9743589743589743]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-13276", "mrqa_searchqa-validation-6865", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-738", "mrqa_searchqa-validation-11816", "mrqa_searchqa-validation-15430", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-14465", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-13742", "mrqa_searchqa-validation-2063", "mrqa_searchqa-validation-10146", "mrqa_naturalquestions-validation-4881", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.5625, "CSR": 0.5394258720930232, "EFR": 0.9642857142857143, "Overall": 0.7051173172757476}, {"timecode": 86, "before_eval_results": {"predictions": ["John Garfield as Al Schmid", "at a given temperature", "season ten", "October 28, 2007", "seven", "absorbed the superhuman powers and the psyche of Carol Danvers", "the Isthmus of Suez", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "5 : 7 -- 8", "between the stomach and the large intestine", "Gupta Empire", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "Egypt", "the base of the right ventricle", "Lager", "Justin Timberlake", "Destiny's Child", "statistical", "Cliff's father", "Husrev Pasha", "Anna Maria Demara", "The Osmonds", "The Drew Las Vegas", "It acts as a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Texas - style chili con carne", "September 8, 2017", "SURFACE AREA OF ROOTS", "Iowa ( 36.6 % )", "Matt Flinders", "1 October 2006", "Natya Shastra", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Egypt", "nasal septum", "IETF", "January 1, 1976", "parthenogenesis", "Identification of alternative plans / policies", "Ludacris", "Jack Scanlon", "Costa Rica, Brazil, and the Philippines", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "the retina", "Anna Devane ( Finola Hughes )", "Donna", "Annette Crosbie", "Bobby Kennedy", "Minder", "leopard", "Patricia Arquette", "University Grants Commission", "Crocker National Bank", "102", "two", "\"Like a Rock\"", "a cat", "King George III", "Norway"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6941344127363864}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, true, false, false, false, true, true, true, true, false, true, true, false, false, false, true, false, true, true, false, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, true, true, false, true, true], "QA-F1": [0.5714285714285715, 0.5454545454545454, 0.0, 1.0, 1.0, 0.761904761904762, 0.5, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.72, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-613", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-6294", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_naturalquestions-validation-10691", "mrqa_hotpotqa-validation-1504", "mrqa_hotpotqa-validation-5241", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-2803", "mrqa_searchqa-validation-1808"], "SR": 0.59375, "CSR": 0.5400502873563218, "EFR": 0.9230769230769231, "Overall": 0.697000442086649}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol. 2", "Arlo Looking Cloud", "Jyothika Sadanah", "Franco-Prussian War", "Hirsch index rating", "Cody Miller", "1951", "Teenitans Go!", "The Ramna Stacks", "Book of Judges", "torpedo boats", "9 February 1971", "San Francisco, California", "Three's Company", "9,984", "Nasim Pedrad", "Marktown", "the Rose Theatre", "1 million", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "237", "timeline of Shakespeare criticism", "Balloon Street, Manchester", "University of Southern California", "6teen", "the port city of Aden", "Noel Gallagher", "James Gandolfini", "U2 360\u00b0 Tour", "Daniel Richard \" Danny\" Green, Jr.", "Scarface", "The Austro-Hungarian Army", "St. George", "Ericsson", "Nova Planta Decree of Majorca and Ibiza", "Helsinki, Finland", "Urijah Faber", "four", "1958", "The Thomas Crown Affair", "Bharat Ratna", "October 11, 1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "the person compelled to pay for reformist programs", "the 1920s", "Sundays", "James Hargreaves", "puff the Magic Dragon", "Hindi", "Sweden in 1967, Iceland in 1968, Nigeria in 1972 and Ghana in 1974.", "flooding", "composer", "Thesaurus", "Bath", "Atlanta", "the hope that a happy day being marked would recur many more times"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7203993055555555}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, false, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.5, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 0.8, 0.6666666666666666, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9166666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-1302", "mrqa_hotpotqa-validation-2792", "mrqa_naturalquestions-validation-8068", "mrqa_triviaqa-validation-3809", "mrqa_newsqa-validation-1318", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-2044", "mrqa_naturalquestions-validation-9361"], "SR": 0.59375, "CSR": 0.5406605113636364, "EFR": 1.0, "Overall": 0.7125071022727273}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus", "as many as 250,000", "Ameneh Bahrami", "40", "state senators", "in an Internet broadband deal with a Chinese firm.", "by text messaging", "Hawaii.", "Haiti", "Brazil", "\"Golden City,\"", "ways to speed up screening of service members and, to the extent possible, their families, when the service members are in uniform and traveling on orders.", "James Whitehouse,", "helping to plan the September 11, 2001, terror attacks,", "Empire of the Sun", "burning World Trade Center", "because the Indians were gathering information about the rebels to give to the Colombian military.", "avid Washington Redskins fan and loved to travel,", "time", "Carnival", "Jason Chaffetz", "summer", "southern port city of Karachi,", "hired translators to eavesdrop on a series of conversations in Arabic, Russian and Mandarin", "it's a matter of money.", "Ricardo Valles de la Rosa", "Islamabad", "Toffelmakaren", "3 p.m. Wednesday", "Microsoft", "1995", "Jaime Andrade", "Casalesi Camorra clan", "Nigeria", "201-262-2800", "South Africa", "very dark and very cold place.", "France", "President Obama", "Tuesday", "to reach car owners who haven't complied fully with recalls", "Mashhad", "Plymouth Rock", "Alina Cho", "Federer", "October 29 and November 5", "a treadmill", "AbdulMutallab", "10", "second", "Central Germany", "Rust", "gastrocnemius muscle", "Granada", "Hickory", "Portugal", "June 17, 2007", "England", "Black Elk", "the basic Bchamel sauce", "Kwanzaa", "\"to look like\"", "Javan leopard"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6896173453739243}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.1818181818181818, 0.7368421052631579, 0.5, 0.8571428571428571, 1.0, 0.6153846153846153, 1.0, 0.9333333333333333, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.15384615384615383, 0.0, 0.0, 0.5, 0.16666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-368", "mrqa_newsqa-validation-3110", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-2942", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2641", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-929", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-91", "mrqa_newsqa-validation-1201", "mrqa_triviaqa-validation-6987", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749"], "SR": 0.5625, "CSR": 0.5409058988764045, "EFR": 0.9642857142857143, "Overall": 0.7054133226324237}, {"timecode": 89, "before_eval_results": {"predictions": ["through a facility in Salt Lake City, Utah,", "(3 degrees Fahrenheit),", "Shemsu Sirgaga", "killing rampage.", "HSH Nordbank Arena", "they did not receive a fair trial.", "The federal officers' bodies", "American Bill Haas", "Larry Ellison,", "The supplemental spending bill provides nearly $162 billion in war funding without the restrictions congressional Democrats vowed to put into place since they took control of Congress", "a renaissance of the game in the region.", "Joan Rivers", "Bob Dole,", "Phoenix, Arizona,", "KBR's", "Copts", "Jeanne Tripplehorn", "two years,", "the body of the aircraft", "North Korea", "will not support the Stop Online Piracy Act,", "pattern matching.\"", "\"Gandhi,\"", "almost 9 million", "U.S. senators", "the situation of America wielding a big stick", "London and Buenos Aires", "she returned to Pakistan", "Hitler did to the Jewish people just 65 years ago,\"", "President Obama", "a bank", "two", "illegal immigrants", "At least 38", "Sri Lanka", "The BBC", "\"wipe out\" the United States", "after they ambushed a convoy carrying supplies for NATO forces in southern Afghanistan,", "is a city of romance, of incredible architecture and history.", "top designers, such as Stella McCartney,", "clogs", "debris", "Jeanne Tripplehorn's", "ALS6,", "The EU naval force", "well over 1,000 pounds", "Iran's Green Movement of protesters", "make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance", "Lindsey Vonn", "three", "postero - medially towards the optic chiasm", "Hugo Weaving", "aragonite", "Lester", "Olympia", "Bruce R. Cook", "Los Angeles", "86,112", "the cat that ate as many as he could get", "a soap opera", "the CPI", "Penrhyn Castle"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5692757150937298}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, true, false, false, true, false, false, false, false, false, true, true, false, true, false, false, true, true, false, false, false, true, false, true, true, false, false, true, true, false, false, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.07692307692307693, 0.26666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.23529411764705882, 1.0, 0.1142857142857143, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1076", "mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-2561", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-213", "mrqa_newsqa-validation-3267", "mrqa_newsqa-validation-436", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1732", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_searchqa-validation-6689", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.46875, "CSR": 0.5401041666666666, "EFR": 0.9705882352941176, "Overall": 0.7065134803921569}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Neptune", "larynx", "the Surgeon", "Ebony", "Cook County", "Sartre", "Wordsworth", "Boston", "James K. Polk", "Harpy", "lacrosse", "Naples", "the March Hare", "the Jews", "a cow pie", "'Paradise Lost'", "Beautiful", "the ice", "Doctor Dolittle", "Graceland", "Mitch Albom", "the beaver", "earthquakes", "Donovan", "supporting Actor", "The Bionic Woman", "the multitude", "wrinkles", "Narnia", "the comet Tempel 1", "Mount Sinai", "Kamehameha", "(Elbert) Gary", "corporality", "crowded", "'Duke'", "Orlans", "\"Another Brick in the Wall\"", "Pulp Fiction", "Hester Prynne", "pajamas", "a nomadic people", "bagpipe", "a stork", "cruises", "Henry David Thoreau", "Encephalitis", "Chile", "Sydney", "the Hudson Bay", "Ellen is restored to life and is married to Bobby", "The long - hair gene", "makaron nesoi", "Another Day in Paradise", "The Danelaw", "Donald Wayne Johnson", "Robert Allen Iger", "Manchester\u2013Boston Regional Airport", "Iowa,", "16", "Japanese officials", "financial gain,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6830729166666667}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, true, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-5423", "mrqa_searchqa-validation-4704", "mrqa_searchqa-validation-4322", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-15887", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-14528", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-12047", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-10583", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-793", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-1662"], "SR": 0.640625, "CSR": 0.5412087912087913, "EFR": 0.9565217391304348, "Overall": 0.7039211060678452}, {"timecode": 91, "before_eval_results": {"predictions": ["Cardiff", "keirin", "welterweight and Light Middleweight", "Christopher Nolan", "Johann", "a highball", "Conan Doyle", "Godfigu", "a heart", "six", "Bashir", "dog sport", "The Double", "arsenic", "omega", "Mickey Mouse", "The Chain", "The Welcome Stranger", "the recorder", "Oman", "Hebrews \" Hall of Faith.", "Ladysmith", "californium", "Robert Guerrero", "the Arizona Diamondbacks", "George Orwell", "Goldie Myerson", "Marc", "\"to the tooth,\"", "William Shakespeare", "1960's", "Some Like It Hot", "Beaujolais", "injecting a 7 percent solution intravenously three times a day", "The National Council for the Unmarried Mother and her Child", "Sarajevo", "Richard I", "Harry bailley", "bullfighting", "leicestershire", "cycling", "Ukraine", "a pea", "Switzerland", "Shanghai", "Twelfth Night", "October 31", "the Swordfish", "France", "Australia", "France", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "1898", "January 1923", "The 1984 South Asian Games", "Rana Daggubati", "four", "1,500", "a group of teenagers.", "38 feet", "the Marquis de Lafayette", "the turquoise", "the birds of America", "2010"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6026041666666666}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false, true, true, true, true, false, false, true, false, false, true, true, true, false, true, false, true, true, false, false, true, true, true, true, false, true, true, false, true, true, false, true, false, false, false, true], "QA-F1": [0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2932", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-600", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-5523", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_naturalquestions-validation-64", "mrqa_hotpotqa-validation-3814", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-6259", "mrqa_searchqa-validation-11134", "mrqa_searchqa-validation-836"], "SR": 0.546875, "CSR": 0.5412703804347826, "EFR": 0.896551724137931, "Overall": 0.6919394209145427}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Thomas Staubach", "1979 to 2013", "two", "2001", "Meghan Markle", "2006", "alcoholic drinks", "Seoul, South Korea", "Dutch", "President of the United States from 1989 to 1993", "political correctness", "Russell Humphreys", "Minnesota to the west, and Wisconsin and the Upper Peninsula of Michigan to the south", "November 23, 2011", "over 3 million", "Mazda", "Jack St. Clair Kilby", "\"Seducing Mr. Perfect\"", "water", "more than 70", "Black pudding", "Animorphs", "Francis the Talking Mule", "two Nobel Peace Prizes", "Masahiko Takeshita", "\"Apatosaurus\"", "TD Garden", "the group focuses on homosexuality, gay sex, and the gay bear subculture", "Sam Kinison", "Melbourne Storm", "Hawaiian language, \"k\u0101ne \u02bb ohe\" means \"bamboo man\"", "2007", "Texas", "Prudence Jane Goward", "Vince Guaraldi", "\"What's My Line?", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Mathew Sacks", "Charles VI", "17 October 2006", "Kansas Joe McCoy", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "The 2018 Unibet Premier League Darts", "first freshman to finish as the runner-up", "Canada", "defense against rain rather than sun", "the eurozone", "Jane Seymour", "Willie Nelson", "1984", "Argentine", "around 3.5 percent", "Ali Bongo", "Antietam", "your medical bills", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6778459821428572}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, false, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.6, 0.5, 0.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.125, 1.0, 1.0, 0.0, 0.4, 0.0, 0.8, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-288", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-2770", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-1237", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-467", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-2159", "mrqa_hotpotqa-validation-5319", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.546875, "CSR": 0.5413306451612903, "EFR": 1.0, "Overall": 0.7126411290322581}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "Bill Cosby", "one of WSU's most famous alumni, Edward R. Murrow", "Liesl", "Stage Stores, Inc.", "Training Day", "1998", "World Famous Gold & Silver Pawn Shop in Las Vegas", "1935", "Argentina", "High Knob", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the IRA's South Armagh Brigade", "Tel Aviv", "Chevy", "the nature of human sexual response", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "PEN America: A Journal for Writers and Readers", "Love Letter", "2013", "Jericho Union Free School District", "January 15, 1975", "John R. Dilworth", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Isabella Hedgeland", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow Airport", "George Martin", "Timo Hildebrand", "Adam Dawes", "Maasai", "Rockland, Maine", "1976", "Vietnam War", "Toto", "9 February 2018", "Todd Griffin", "Gabriel Byrne, Kevin Spacey, Benicio Del Toro, Kevin Pollak, and Stephen Baldwin", "funchal", "British", "Scudetto", "it would", "a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7071676587301587}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true], "QA-F1": [1.0, 0.0, 0.5, 0.0, 0.8, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.2857142857142857, 0.4444444444444445, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2095", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-1236", "mrqa_hotpotqa-validation-2879", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-960", "mrqa_triviaqa-validation-6478", "mrqa_newsqa-validation-2754", "mrqa_searchqa-validation-16694"], "SR": 0.578125, "CSR": 0.5417220744680851, "EFR": 1.0, "Overall": 0.712719414893617}, {"timecode": 94, "before_eval_results": {"predictions": ["the drummer", "Hitler", "Mrs. Miniver", "Simon Cowell", "The Eagles", "the neon light", "the lifejackets", "Ian Fleming", "The Taming of the Shrew", "Anne Frank", "Tahiti", "Cops", "The Bahamas", "a geisha", "France", "the Barbary pirates", "the CIA", "antimicrobial", "the BlackBerry", "40", "Phonetics", "Crosby, Stills & Nash", "Cheers", "the plants", "a missile", "the court of Cassation", "Yucatan", "\"Jeopardy\"", "Afghanistan", "Australia", "a buffalo", "Asia", "The Mortimer D. Sackler", "pitch", "Pete Rose", "Esther", "South Africa", "(Lauren) Bacall", "Goldeneye", "agriculture", "Dumbo", "Edith Wharton", "Bonnie Raitt", "marsupials", "Italian", "The Crow", "the Orioles", "The Magnificent Ambersons", "the mongoose", "Richard Dreyfuss", "Ecuador", "Koine Greek", "four", "appointed by means of a commission ( letters patent ) to keep the peace", "Friends", "guggul", "the solar system", "Ranulf de Gernon, 4th Earl of Chester", "the Runaways", "Pieter van Musschenbroek", "Seoul", "\"It feels great to be back at work,\"", "world War II", "The Krankies"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5941938628899837}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, false, false, false, true, true, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, true, true, true, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2, 1.0, 1.0, 1.0, 0.13793103448275862, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-3231", "mrqa_searchqa-validation-4594", "mrqa_searchqa-validation-13645", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-11623", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-12196", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-804", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_searchqa-validation-1165", "mrqa_searchqa-validation-1101", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_triviaqa-validation-5428", "mrqa_hotpotqa-validation-1508", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108"], "SR": 0.546875, "CSR": 0.5417763157894737, "EFR": 1.0, "Overall": 0.7127302631578948}, {"timecode": 95, "before_eval_results": {"predictions": ["Bork", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "the Mallow", "Antnio Guterres", "Latin", "King Henry VIII", "San Francisco", "\"You can't stop time\"", "Neptune", "Harry Potter and the Chamber of Secrets", "Brutus", "the wild-goose", "Joseph Haydn", "Willa Cather", "Dow Jones", "Aunt Jemima", "the fowls", "dynasties", "Homer", "Amanda Bynes", "Ted Danson", "O. Henry", "The Forteo Mystery", "B.B. King", "Jacqueline Lee (Bouvier) Kennedy Onassis", "Donovan", "the Cephalopod", "Candlestick Park", "a jointer plane", "just compensation", "Vodka", "pastrami", "Adam", "heresy", "Ivy Dickens", "woozy", "thunder", "Ham", "calamine", "Sicily", "Nelson's Column", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Norma's brother", "1 October 1939", "Ming general Wu Sangui", "Philip, Duke of Wharton", "Little arrows", "Rotary", "Craig William Macneill", "William Adelin", "twenty", "Newark's Liberty International Airport,", "more than 4,000", "Lifeway Christian Stores", "Pakistan"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6573660714285714}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, true, true, false, true, false, true, false, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, true, false, false, false, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.28571428571428575, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1854", "mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-2224", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-12114", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-10119", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.59375, "CSR": 0.5423177083333333, "EFR": 0.9615384615384616, "Overall": 0.7051462339743589}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "(Annie) D'Agnolo di Sarto", "Unbreakable", "Holy Week", "Tijuana", "Wizard", "a byte", "Planned Parenthood", "Jamie Lee Curtis", "The Simpsons", "an Abduction", "Alexander Graham Bell", "Tibet", "baffle plate", "corpulent", "Herman", "Erin Go Bragh", "Queen Victoria", "giant slalom", "Medusa", "zoology", "Lucia di Lammermoor", "a map projection", "cricket", "Stephen Hawking", "St. Francis of Assisi", "the luminous intensity", "The Scarlet Letter", "2016", "Drug Rehab & Treatment Center", "pastries", "the Hundred Years' War", "the Met", "milk and honey", "3", "a hump", "The Beatles", "The Bronx", "a carbohydrate", "King Kong", "Cubism", "Umbria", "Popcorn", "M. C. Escher", "Oahu", "the ureter", "F. Scott Fitzgerald", "aria", "Ghostbusters II", "Marquette University", "the monk", "Fall 1998", "allergies", "Bart Howard", "the Netherlands", "Marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"We are a nation of Christians and Muslims, Jews and Hindus -- and nonbelievers.\"", "in early 2008,", "acid", "number five"], "metric_results": {"EM": 0.609375, "QA-F1": 0.7107142857142856}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16364", "mrqa_searchqa-validation-12798", "mrqa_searchqa-validation-15315", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-1885", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-9309", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741", "mrqa_newsqa-validation-1645"], "SR": 0.609375, "CSR": 0.5430090206185567, "EFR": 0.96, "Overall": 0.7049768041237113}, {"timecode": 97, "before_eval_results": {"predictions": ["35 cm", "gold rings", "Gaston Leroux", "Concorde", "gold", "European Economic Community", "new york (1836) and Manchester (1847)", "Vietnam", "florentia", "Wanderers", "Emilia Fox", "Amnesty International", "Krak\u00f3w", "Shaft", "gal", "Ramadan", "Bizet's", "Count Basie Orchestra", "Pegida", "plutonium", "sheree Murphy", "Edward Hopper", "Einstein", "faversham", "Justin Trudeau", "Robin Williams", "time team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "South America", "Christian Wulff", "milk", "usk", "spider", "kevin Rudd", "Daily Herald", "nairobi", "Alan Turing", "tendon", "the anterior interatrial septum", "Puck", "Hula-Hoops", "ap\u00e9ritif", "Persuasion", "Rocky Graziano", "Sweater", "Today newspaper", "Today", "Vincent Gene Craddock", "Midgard", "a cascade of events through phosphorylation of intracellular proteins that ultimately transmit ( `` transduce '' ) the extracellular signal to the nucleus", "USS Chesapeake", "Ben Faulks", "a homotopy-Maclaurin series", "participation in second war with India", "Art of Dying", "Sgt. Jason Bendett", "Apple CEO Tim Cook", "Christopher Savoie", "Plouton", "ingnue", "World War I", "Joseph"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6083333333333334}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, true, true, false, false, true, false, false, false, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, false, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.13333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4376", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-1804", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-1185", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1947", "mrqa_searchqa-validation-6024"], "SR": 0.59375, "CSR": 0.5435267857142857, "EFR": 0.9615384615384616, "Overall": 0.7053880494505494}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "Edinburgh", "a hippopotamus", "cirrus uncinus", "procol harum", "ottune", "british city", "newquay", "Uganda", "st pancras", "lactic acid", "Marseille", "Robinson Crusoe", "newspaper of the Crown", "my Favorite Martian", "whist", "a fear of snakes", "Madagascar", "Wyatt", "month", "one Direction", "The West Wing", "Prince Harry", "1994", "titanium", "leicestershire", "Pegasus", "Alaska", "james fimore Cooper", "brazil", "the rhizome", "grease Western", "eyes", "kurdrechtsofen", "Bowie knife", "Nile", "a rat", "Independence Day", "Tinie Tempah", "porto", "japan", "a collapsible support assembly", "beard", "Amy Dorrit", "oregon", "Sunday Post", "bobby darin", "emirate", "Phil Woolas", "mansfield park", "South Africa", "Cam Clarke", "drivers who qualified for the 2017 Playoffs", "Florida", "twenty-three", "Mexican War on Drugs", "her relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi ethnic minority and the Hutu majority", "The Tempest", "Naples", "Solomon", "heavier than a feather"], "metric_results": {"EM": 0.5, "QA-F1": 0.5847470238095238}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, true, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.4444444444444445, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.28571428571428575]}}, "before_error_ids": ["mrqa_triviaqa-validation-2636", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-4266", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-487", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-4125", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-2492", "mrqa_naturalquestions-validation-9588", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_hotpotqa-validation-3713"], "SR": 0.5, "CSR": 0.5430871212121212, "EFR": 0.90625, "Overall": 0.6942424242424242}, {"timecode": 99, "UKR": 0.78515625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.79296875, "KG": 0.5125, "before_eval_results": {"predictions": ["an angry mob.", "37th", "dismissed all charges", "U.S. Defense Department", "11,", "inmates", "Kenyan and Somali", "prostate cancer,", "Philip Markoff,", "crocodile eggs", "Jacob", "crafts poems telling of the pain and suffering of children just like her;", "Red Lines", "The Kirchners", "an African-American woman", "Arsene Wenger", "Gary Coleman", "Carrousel du Louvre,", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "Marcus Schrenker,", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "June 25.", "Alejandro Peralta Alvarez,", "Kerstin Fritzl,", "Amnesty International.", "The Tinkler.", "\"Let it Roll: Songs by George Harrison\"", "overthrow the socialist government of Salvador Allende in Chile,", "lump in Henry's nether regions", "reached an agreement late Thursday", "snow,", "\"Steamboat Bill, Jr.\"", "dogs who walk on ice in Alaska.", "45 minutes, five days a week.", "school.", "Harrison Ford", "Aniston, Demi Moore and Alicia Keys", "as he tried to throw a petrol bomb", "al-Moayad", "\"I wanted to shove it up that black a--.\"", "Three thousand", "burning of a church.", "The cause of the child's death will be listed as homicide by undetermined means,", "Peruvian Supreme Court", "2,000", "\"I miss your beautiful face and voice,\"", "Cirque du Soleil", "9", "for the rest of the year", "94", "Bobby Darin", "foreign investors", "neck", "wrigley", "CBS", "round five of the 2017 season", "North Dakota", "Phil Spector", "Charlie and the Chocolate Factory", "the toy", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6785075167887668}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, false, true, true, true, false, true, true, true, false, true, true, false, false, false, true, true, false, false, false, true, true, true, false, true, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.25, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-530", "mrqa_newsqa-validation-807", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-10073", "mrqa_naturalquestions-validation-9992", "mrqa_naturalquestions-validation-4326", "mrqa_hotpotqa-validation-2793", "mrqa_searchqa-validation-6438"], "SR": 0.609375, "CSR": 0.54375, "EFR": 0.88, "Overall": 0.702875}]}