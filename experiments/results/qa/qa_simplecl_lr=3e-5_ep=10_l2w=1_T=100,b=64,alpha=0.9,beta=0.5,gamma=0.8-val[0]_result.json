{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]', diff_loss_weight=1.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=10_l2w=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[0]_result.json', stream_id=0, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4160, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["Fresno", "Truth, Justice and Reconciliation Commission", "Pittsburgh Steelers", "mid-18th century", "his sons and grandsons", "1875", "be reborn", "1971", "placing them on prophetic faith", "Cestum veneris", "the arts capital of the UK", "an idealized and systematized version of conservative tribal village customs", "conflict", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "every four years", "three", "live", "Tugh Temur", "teach by rote", "excommunication", "Church of St Thomas the Martyr", "the move from the manufacturing sector to the service sector", "article 49", "Thailand", "immunomodulators", "hotel room", "they owned the Ohio Country", "10 million", "Pictish tribes", "oxides", "Economist Branko Milanovic", "Emergency Highway Energy Conservation Act", "Hurricane Beryl", "a better understanding of the Mau Mau command structure", "Satyagraha", "Jim Gray", "San Francisco Bay Area's Levi's Stadium", "1080i HD", "\"Blue Harvest\" and \"420\"", "Maria Sk\u0142odowska-Curie", "human", "water", "1201", "The Presiding Officer", "mesoglea", "redistributive", "$2 million", "Liao, Jin, and Song", "1313", "small-scale manufacturing of household goods, motor-vehicle parts, and farm implements", "visor helmet", "Mike Tolbert", "semi-arid savanna to the north and east", "Percy Shelley", "Arizona Cardinals", "a lute", "More than 1 million", "Manuel Blum", "unidirectional force", "Central Bridge", "was a major source of water pollution", "graduate and undergraduate students elected to represent members from their respective academic unit", "Dragon's Den", "24 March 1879"], "metric_results": {"EM": 0.828125, "QA-F1": 0.859375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6804", "mrqa_squad-validation-8347", "mrqa_squad-validation-7382", "mrqa_squad-validation-7432", "mrqa_squad-validation-7364", "mrqa_squad-validation-133", "mrqa_squad-validation-652", "mrqa_squad-validation-7719", "mrqa_squad-validation-7324", "mrqa_squad-validation-75", "mrqa_squad-validation-9343"], "SR": 0.828125, "CSR": 0.828125, "EFR": 1.0, "Overall": 0.9140625}, {"timecode": 1, "before_eval_results": {"predictions": ["Oahu", "its central location between the Commonwealth's capitals of Krak\u00f3w and Vilnius", "one (or more)", "linebacker", "the set of triples", "most of the items in the collection, unless those were newly accessioned into the collection", "the Los Angeles Times", "the Broncos", "anticlines and synclines", "Bells Beach SurfClassic", "Paleoproterozoic", "the end itself", "1894", "French Rhin", "Atlantic", "quotient", "less than a year", "The Scottish Parliament", "artisans and farmers", "Shia terrorist groups", "Royal Ujazd\u00f3w Castle", "hard-to-fill", "the 2008\u20132010 specials (The Next Doctor to End of Time Part 2)", "\u00a315\u2013100,000", "mid-Eocene", "the infected corpses", "the United Kingdom, Australia, Canada and the United States", "11", "forces", "2005", "chief electrician", "lower incomes", "Luther states that everything that is used to work sorrow over sin is called the law", "phagocytes", "the center of the curving path", "a shortage of male teachers", "Masovian Primeval Forest", "days, weeks and months", "biodiversity", "two", "Nairobi, Mombasa and Kisumu", "an algorithm for multiplying two integers can be used to square an integer", "Qutb", "Stanford Stadium", "the chosen machine model", "s = \u22122, \u22124,...", "human", "Killer T cells", "British Gas plc", "More than 1 million", "2011", "by the market", "27-30%", "New Orleans", "Jamukha", "Gymnosperms", "Taoism", "Matthew 16:18", "the U.S. ship that was hijacked off Somalia's coast", "Rwanda", "revelry", "his health", "The Pilgrims", "the South"], "metric_results": {"EM": 0.75, "QA-F1": 0.8238195831945831}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-885", "mrqa_squad-validation-5505", "mrqa_squad-validation-2969", "mrqa_squad-validation-9243", "mrqa_squad-validation-4289", "mrqa_squad-validation-7763", "mrqa_squad-validation-7728", "mrqa_squad-validation-2520", "mrqa_squad-validation-6933", "mrqa_squad-validation-1763", "mrqa_squad-validation-366", "mrqa_squad-validation-7527", "mrqa_newsqa-validation-1028", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-471", "mrqa_searchqa-validation-724"], "SR": 0.75, "CSR": 0.7890625, "EFR": 1.0, "Overall": 0.89453125}, {"timecode": 2, "before_eval_results": {"predictions": ["negative", "1 July 1851", "Zhu Yuanzhang", "the greatest good", "50%", "mountainous areas", "Denmark", "quantum mechanics", "75th birthday", "Distinguished Service Medal", "30", "Virgin Media", "destruction of Israel and the establishment of an Islamic state in Palestine", "locomotion", "each six months", "Japanese", "the Electorate of Saxony", "Mark Twain", "the Commission", "1085", "shortening the cutoff", "Battle of Hastings", "1000 CE", "T. T. Tsui Gallery", "a multi-party system", "allows those tainted by sin to nevertheless make a truly free choice to accept or reject God's salvation in Christ.", "Monopoly", "Evita and The Wiz", "The Master", "cholera", "Jingshi Dadian", "purposely damaging their photosynthetic system", "1991", "two", "the Arizona Cardinals", "1991", "Chaffee", "Isiah Bowman", "the poor", "100\u2013150", "John Elway", "Wijk bij Duurstede", "non-peer-reviewed sources", "Economist", "pathogens", "increasingly expected to be compensated for their patient care skills", "declare martial law", "a customs union", "the Roman Catholic Church", "1050s", "political support", "the death of Elisabeth Sladen", "the Spice Girls", "Documents", "the company's factory in Waterford City, Ireland", "nitrogen", "Annemarie Moody", "the Haraboard", "six", "It always begins with the music, of course. The tune sticks with you long after the song is over; the sort of tune that makes it almost impossible to sit still.", "music director", "Illinois", "Rafael Palmeiro", "Wal-Mart Canada Corp."], "metric_results": {"EM": 0.734375, "QA-F1": 0.7761086464211464}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.16216216216216214, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-803", "mrqa_squad-validation-9600", "mrqa_squad-validation-1174", "mrqa_squad-validation-9896", "mrqa_squad-validation-8316", "mrqa_squad-validation-9805", "mrqa_squad-validation-235", "mrqa_squad-validation-6403", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-2735", "mrqa_triviaqa-validation-3701", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-2823", "mrqa_triviaqa-validation-2135", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-5936", "mrqa_hotpotqa-validation-3629"], "SR": 0.734375, "CSR": 0.7708333333333334, "EFR": 1.0, "Overall": 0.8854166666666667}, {"timecode": 3, "before_eval_results": {"predictions": ["Works Council Directive", "42%", "21-minute", "The majority may be powerful but it is not necessarily right", "an Eastern Bloc city", "Sakya", "christopher saints", "Britain", "23", "Fears of being labelled a pedophile or hebephile", "charleston's daughters", "near the surface", "northern China", "giving her brother Polynices a proper burial", "political figures", "The Commission's President (currently an ex-Luxembourg Prime Minister, Jean-Claude Juncker)", "2000 guests", "oxygen", "increase local producer prices by 20\u201325%", "Apollo 1 backup crew", "a body of treaties and legislation", "ARPANET", "39", "the King", "four", "Guinness World Records", "issues under their jurisdiction", "women", "the Edict of Nantes", "abortion, broadcasting policy, civil service, common markets for UK goods and services, constitution, electricity, coal, oil, gas, nuclear energy", "multiple revisions", "philanthropic initiative", "integer factorization problem", "income for food and shelter", "Isel", "adapted quickly and often married outside their immediate French communities", "former Pakistani Prime Minister Benazir Bhutto", "Charles-Fer Ferdinand University", "drowned in the Mur River", "yellow fever outbreaks", "Tracy Wolfson and Evan Washburn", "lysozyme and phospholipase A2", "Brazil", "energy stored in an H+ or hydrogen ion gradient", "the late 19th century", "the Channel Islands", "charleston", "Alberich", "charleston", "travis", "Churchill Downs", "the third largest in the Netherlands, after those of Rotterdam and Amsterdam", "travis", "travis", "christopher", "travis", "the limbic system", "trahan Mubarak", "George Fox", "travis", "Great Expectations", "24 hours a day and 7 days a week", "Sponsorship scandal", "\"Krabby Road\""], "metric_results": {"EM": 0.609375, "QA-F1": 0.6331597222222223}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, false, false, true, false, false, false, false, false, false, false, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2597", "mrqa_squad-validation-801", "mrqa_squad-validation-9286", "mrqa_squad-validation-4293", "mrqa_squad-validation-639", "mrqa_squad-validation-7083", "mrqa_squad-validation-9489", "mrqa_squad-validation-392", "mrqa_squad-validation-7321", "mrqa_squad-validation-3069", "mrqa_squad-validation-7240", "mrqa_squad-validation-1189", "mrqa_squad-validation-8906", "mrqa_squad-validation-2463", "mrqa_triviaqa-validation-1498", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2905", "mrqa_triviaqa-validation-3174", "mrqa_triviaqa-validation-5065", "mrqa_triviaqa-validation-6229", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-6590", "mrqa_triviaqa-validation-3361", "mrqa_triviaqa-validation-6556", "mrqa_hotpotqa-validation-3821"], "SR": 0.609375, "CSR": 0.73046875, "EFR": 0.92, "Overall": 0.825234375}, {"timecode": 4, "before_eval_results": {"predictions": ["higher plants", "Parliament of Victoria", "Zaha Hadid", "Fort Edward", "Science and Discovery", "the Army", "pedagogy", "red algal endosymbiont's original cell membrane", "Grand Canal d'Alsace", "in a number of stages", "The Skirmish of the Brick Church", "Sicily and the south of Europe", "Henry of Navarre", "reduced moist tropical vegetation cover", "wage or salary", "the Roman Catholic Church", "British troops", "John Fox", "Royal Institute of British Architects", "March 1896", "disturbed", "Oireachtas funds", "Ogedei", "Brooklyn", "their cleats", "12 May 1705", "apicomplexan-related", "Academy of the Pavilion of the Star of Literature", "passenger space", "1639", "biostratigraphers", "the web", "the Song dynasty", "2010", "1606", "The Earth's mantle", "1991", "Ticonderoga", "Laszlo Babai and Eugene Luks", "October 2007", "LoyalKaspar", "other ctenophores", "guzzanti", "22", "terror groups that they say were planning numerous suicide attacks, including in the country's largest city of Karachi", "it was a comment that shouldn't have been made and certainly one that he wished he didn't make", "Brian Smith", "a new model is simply out of their reach", "Muslim", "will auction off one of the earliest versions of the Magna Carta later this year", "a unit of Time Warner", "15", "militants from Afghanistan", "Chesley \"Sully\" Sullenberger", "backbreaking labor", "CNN's Campbell Brown", "a woman who may have been contacted through a Craigslist ad", "one", "miley Cyrus", "$1,500", "set up codes to reduce unfair competition", "Travis", "Humberside Airport", "in the past few seasons"], "metric_results": {"EM": 0.71875, "QA-F1": 0.7423980614973262}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false, true, false, true, false, false, false, true, false, true, false, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.3, 0.15999999999999998, 1.0, 1.0, 0.0, 0.8181818181818181, 0.0, 1.0, 0.0, 1.0, 0.23529411764705882, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-8825", "mrqa_squad-validation-10247", "mrqa_squad-validation-4510", "mrqa_squad-validation-3733", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-2606", "mrqa_newsqa-validation-104", "mrqa_newsqa-validation-2883", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-562", "mrqa_newsqa-validation-840", "mrqa_newsqa-validation-1855", "mrqa_naturalquestions-validation-2908", "mrqa_triviaqa-validation-6944", "mrqa_searchqa-validation-574"], "SR": 0.71875, "CSR": 0.728125, "EFR": 1.0, "Overall": 0.8640625}, {"timecode": 5, "before_eval_results": {"predictions": ["Danny Lane", "the United States", "New York City", "Larry Ellison", "the Anglican tradition's Book of Common Prayer", "WLS", "Pi\u0142sudski", "10th century", "shaping ideas about the free market", "The United Methodist Church", "the Connectional Table", "Deformational", "a high-level marketing manager, was given the job of turning the business around", "500,000", "Ofcom", "there was sufficient support in the Scottish Parliament to hold a referendum on Scottish independence", "lectured on the Psalms, the books of Hebrews, Romans, and Galatians", "3.55 inches (90.2 mm)", "2011", "algae", "part of a rule connected with civil disobedience", "June 1978", "Milton Latham", "1914", "the Philippines", "the Broncos", "1950s to 2011", "the spoils of the war", "German Te Deum", "1795", "Bermuda 419", "evaporated to cool oxygen gas", "Infinity Broadcasting Corporation", "\"semi-legal\" and was the only opposition group in Egypt able to field candidates during elections", "1972", "a rudimentary immune system, in the form of enzymes that protect against bacteriophage infections", "1957", "mother-of-pearl made between 500 AD and 2000", "Gene Barry and the half - hour black - and - white shows ran on NBC from 1958 to 1961", "negotiates treaties with foreign nations, but treaties enter into force if ratified by two - thirds of the Senate", "changing display or audio settings quickly, such as brightness, contrast, or volume, and is held down in conjunction with the appropriate key to change the settings", "from an Ohio newspaper on 8 February 1925", "Herbert Hoover, has made at least one State of the Union report as a speech delivered before a joint session of Congress", "radius R of the turntable", "Panning", "Justin Timberlake", "Brazil, China, France, Germany, India, Indonesia, Italy, Japan, South Korea, Mexico, Russia, Turkey, the United Kingdom", "police, troops, and military experts. European nations contribute nearly 6,000 units to this total", "unknown origin", "omitted and an additional panel stating the type of hazard ahead", "Lowe's opened its first three stores in Canada", "the speech, once given during the day, is now typically given in the evening, after 9pm ET ( UTC - 5 )", "Jesse Frederick James Conaway", "infant, schoolboy, lover, soldier, justice, Pantalone and old age", "these scenes usually take place in the present ( 2016 -- 2018, contemporaneous with airing ) and a storyline taking place at a set time in the past ; but some episodes are set in one time period or use multiple flashback time periods", "Morgan Freeman reprising his role as detective Alex Cross", "David Gahan ( / \u0261\u0251\u02d0n / ; born David Callcott ; 9 May 1962 ) is an English singer - songwriter", "the Overlook Hotel in his 1977 bestseller The Shining and its 1980 film adaption of the same name, as well as the location for the 1997 miniseries", "long sustained period of inflation is caused by money supply growing faster than the rate of economic growth", "the day before the long fast for the Lent period in many Christian churches", "Jaipur", "Jonas Olsson, the journalists' Swedish attorney", "battleships and other slow and heavily armed ships", "River Usk"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6290872185197843}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.07142857142857142, 1.0, 1.0, 0.2666666666666667, 0.5, 1.0, 1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 1.0, 0.13333333333333333, 1.0, 0.6666666666666666, 1.0, 0.25, 0.2222222222222222, 0.45454545454545453, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3157894736842105, 1.0, 0.0, 0.0, 0.3636363636363636, 0.631578947368421, 0.08333333333333334, 0.5833333333333334, 0.0, 1.0, 0.8000000000000002, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_squad-validation-10011", "mrqa_squad-validation-4836", "mrqa_squad-validation-9552", "mrqa_squad-validation-2254", "mrqa_squad-validation-6719", "mrqa_squad-validation-7488", "mrqa_squad-validation-9908", "mrqa_squad-validation-3473", "mrqa_squad-validation-9635", "mrqa_squad-validation-6450", "mrqa_squad-validation-5451", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-6665", "mrqa_naturalquestions-validation-3041", "mrqa_naturalquestions-validation-7297", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-10495", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-3737", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-2844", "mrqa_naturalquestions-validation-35", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-3759", "mrqa_naturalquestions-validation-10138", "mrqa_triviaqa-validation-910", "mrqa_newsqa-validation-2048", "mrqa_searchqa-validation-2792", "mrqa_triviaqa-validation-4272"], "SR": 0.515625, "CSR": 0.6927083333333333, "EFR": 0.967741935483871, "Overall": 0.8302251344086021}, {"timecode": 6, "before_eval_results": {"predictions": ["William Hartnell and Patrick Troughton", "always more expensive", "antigen from a pathogen", "their disastrous financial situation", "a Serbian Orthodox priest", "receptions, gatherings or exhibition purposes", "the Pittsburgh Steelers", "Charly", "Henry Cole", "steam turbines", "social and political action", "1936", "the New Birth", "gold", "Denver took the opening kickoff", "Vivienne Westwood", "reduction", "disease", "\"TFIF\"", "Confucian propriety and ancestor veneration", "\"Christ and His salvation\"", "five", "European Court of Justice and the highest national courts", "1888", "business", "BBC Radio 5 Live", "1876", "screw stoking mechanism", "#P", "George Westinghouse", "British failures in North America, combined with other failures in the European theater", "1,548", "Joy", "members of professional misconduct", "end of the season", "10", "Jonas", "African-Americans", "will not support the Stop Online Piracy Act", "Chuck Bass", "completely calm, with little to no wind", "an animal tranquilizer, can put users in a dazed stupor for about two hours,", "in an interview Tuesday on CNN's \"Larry King Live.\"", "Stuttgart on Sunday", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "more than 170", "North Korea's reclusive leader Kim Jong-Il", "first five Potter films", "that you love the environment and hate using fuel", "3 to 17", "two suicide bombers, \"feigning a desire to conduct reconciliation talks, detonated themselves.\"", "a \"stressed and tired force\" made vulnerable by multiple deployments", "James Whitehouse,", "we want to ensure we have all the capacity that may be needed over the course of the coming days", "a series of monthly meals for people with food allergies", "Zimbabwe", "2004", "Mohamed Alanssi", "Ludacris", "Mike Gatting", "Colgate University", "Church of Christ, Scientist", "a fat or fatty acid in which there is at least one double bond within the fatty acid chain", "Luke 6 : 67 -- 71"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6662067099567099}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, false, false, false], "QA-F1": [1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2857142857142857, 0.2, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.0, 0.5, 0.16666666666666666, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.45454545454545453, 0.75]}}, "before_error_ids": ["mrqa_squad-validation-7114", "mrqa_squad-validation-266", "mrqa_squad-validation-800", "mrqa_squad-validation-6001", "mrqa_squad-validation-486", "mrqa_squad-validation-3390", "mrqa_squad-validation-1906", "mrqa_newsqa-validation-1854", "mrqa_newsqa-validation-2660", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-265", "mrqa_newsqa-validation-2123", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-1171", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-284", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-2425", "mrqa_newsqa-validation-3730", "mrqa_newsqa-validation-814", "mrqa_triviaqa-validation-2684", "mrqa_hotpotqa-validation-501", "mrqa_searchqa-validation-1275", "mrqa_naturalquestions-validation-1442", "mrqa_naturalquestions-validation-3770"], "SR": 0.5625, "CSR": 0.6741071428571428, "EFR": 1.0, "Overall": 0.8370535714285714}, {"timecode": 7, "before_eval_results": {"predictions": ["1970s", "his friendship", "increased trade with poor countries", "187 feet", "pH or available iron", "90\u00b0", "materials melted near an impact crater", "$100,000", "Stanford Stadium", "baptism in the Small Catechism", "Jim Gray", "5%", "July 1969", "Hitler's secret police demanded to know if they were hiding a Jew in their house.", "prolamellar body", "spontaneous", "the courts of member states and the Court of Justice of the European Union", "gold", "TARDIS", "Buckland Valley near Bright", "Scottish rivers", "\"Bricks for Warsaw\"", "1978", "1598", "Sheldon Ungar", "86", "tentacles and tentacle sheaths", "in 80 trunks marked N.T.", "\u00a320,427", "21 October 1512", "James O. McKinsey,", "\"Dance Your Ass Off.\"", "\"Freshman Year\" experience", "India", "Zulfikar Ali Bhutto,", "at the lenlow oil refinery in western England, Drax power station in the northeast, Petroplus Coryton Refinery in the southeast", "April 24 through May 2", "Krishna Rajaram,", "early detection and helping other women cope with the disease.", "250,000", "Timothy Masters", "homicide", "in the non-EU berths permitted under Spanish Football Federation (RFEF) rules.", "12 hours", "from the capital, Dhaka, to their homes in Bhola", "Jason Chaffetz", "United States Holocaust Memorial Museum, The American Academy of Diplomacy and the United States Institute of Peace.", "\"Dance Your Ass Off\"", "leniency", "Matthew Fisher", "Herman Cain", "9 a.m.", "North vs. South, black vs. white, Jew vs. Christian, industrial vs. agrarian.", "seeking help", "Japanese officials", "patrolling the pavement", "\"Empire of the Sun,\"", "Norman given name Robert", "the Olympics", "Matthew Ward Winer", "lenardo", "opposite R\u00fcgen island", "Mustique", "green"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6706360675614709}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, false, false, false, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.9032258064516129, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.2, 1.0, 1.0, 0.3636363636363636, 0.0, 0.5, 0.15384615384615385, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7533", "mrqa_squad-validation-2448", "mrqa_squad-validation-1796", "mrqa_squad-validation-6998", "mrqa_squad-validation-8883", "mrqa_squad-validation-1556", "mrqa_newsqa-validation-3558", "mrqa_newsqa-validation-3176", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-55", "mrqa_newsqa-validation-3726", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-320", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-2721", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-2154", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-417", "mrqa_naturalquestions-validation-6514", "mrqa_searchqa-validation-7977", "mrqa_triviaqa-validation-2858"], "SR": 0.609375, "CSR": 0.666015625, "EFR": 0.96, "Overall": 0.8130078125}, {"timecode": 8, "before_eval_results": {"predictions": ["2009", "The British provided medical treatment for the sick and wounded French soldiers and French regular troops were returned to France aboard British ships with an agreement that they were not to serve again in the present war.", "Roman Catholic", "The Master is the Doctor's archenemy, a renegade Time Lord who desires to rule the universe.", "Enric Miralles", "25-foot (7.6 m)", "eight", "Tuesday afternoon", "\"Journey's End\"", "immediate", "Levi's Stadium", "decidedly Wesleyan", "art posters", "Tsakhiagiin Elbegdorj", "Chinggis Khaan", "Einstein", "fast forwarding of accessed content", "CALIPSO", "30 \u00b0C", "primary law, secondary law and supplementary law", "Nicholas Stone", "2,869", "Leonard Bernstein", "Commission v Austria", "9th", "random access machines", "ensure that the prescription is valid", "Stockton and Darlington Railway", "autonomy", "Islamic", "$12.9 million", "Fernando Gonzalez of Chile also went through as he beat Ivan Ljubicic of Croatia 6-4 6-3.", "Graeme Smith", "more than 80 features to his name,", "finance", "terminal brain cancer", "some U.S. senators who couldn't resist taking the vehicles for a spin.", "the Employee Free Choice act", "separated in June 2004", "Animal Planet", "fake his own death", "there were no radar outages and said it had not lost contact with any planes", "54 bodies", "early detection", "Diversity", "$250,000", "40.1 feet", "Nazi Germany", "March 27", "The Kirchners", "directly involved in an Internet broadband deal with a Chinese firm.", "The son of Gabon's former president was declared the winner of the country's presidential elections on Thursday,", "as soon as 2050", "Alfredo Astiz,", "Abdullah Gul,", "Carl Froch", "The Everglades,", "when the cell is undergoing the metaphase of cell division", "the Rock", "New Orleans, Louisiana", "many investors paying huge sums for individual bulbs", "Bistro", "it may mean if you miss a period when you're not expecting.", "it has to be the most difficult sport to be a play-by-play announcer."], "metric_results": {"EM": 0.59375, "QA-F1": 0.667382443944944}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, true, false, true, true, true, false, true, false, false, false, false, false, false, false], "QA-F1": [1.0, 0.13333333333333333, 1.0, 0.2857142857142857, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.3636363636363636, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2222222222222222, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10258", "mrqa_squad-validation-7698", "mrqa_squad-validation-5100", "mrqa_squad-validation-455", "mrqa_squad-validation-9903", "mrqa_squad-validation-5586", "mrqa_newsqa-validation-1529", "mrqa_newsqa-validation-1367", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-1878", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-4185", "mrqa_newsqa-validation-2681", "mrqa_newsqa-validation-904", "mrqa_newsqa-validation-2914", "mrqa_newsqa-validation-3456", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-302", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-1710", "mrqa_hotpotqa-validation-1123", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-9839", "mrqa_searchqa-validation-9016"], "SR": 0.59375, "CSR": 0.6579861111111112, "EFR": 0.9615384615384616, "Overall": 0.8097622863247864}, {"timecode": 9, "before_eval_results": {"predictions": ["EastEnders", "1983", "The Book of Discipline", "His wife Katharina", "theology and philosophy", "Pannerdens Kanaal", "487", "Jonathan Stewart", "O(n2)", "Levi's Stadium", "the General Sejm", "Derek Jacobi", "the net force", "\"loo\", \"hoos\"", "30%\u201350%", "the Natives of these localities are very badly disposed towards the French, and are entirely devoted to the English.", "United States", "CRISPR sequences", "six", "300 km long and up to 40 km wide", "1962", "free radical production", "Video On Demand", "the substance of the statement", "the Edict of Fontainebleau", "15", "\"Well, about time.\"", "Ronaldinho", "it is in providing the basic securities that Turkey can be a great partner.", "25", "a gym", "the couple's surrogate lost the pregnancy.", "environmental and political events", "he fears a desperate country with a potential power vacuum that could lash out.", "at least two and a half hours.", "Elin Nordegren", "Europe, Asia, Africa and the Middle East.", "6,000", "banned substance cortisone.", "President Clinton.", "delivered three machine guns and two silencers to the hip-hop star,", "MDC head Morgan Tsvangirai.", "policing the world and Africa in particular.", "future relations between the Middle East and Washington.", "a canyon", "Thabo Mbeki", "\"Taxman,\" \"While My Guitar Gently Weeps,\" \"Something\" and \"Here Comes the Sun.\"", "posting a $1,725 bail,", "school", "strife in Somalia,", "Tom Hanks, Ayelet Zurer and Ewan McGregor", "Columbia, Illinois", "a violation of a law that makes it illegal to defame, insult or threaten the crown.", "North Korea", "2005", "they did not know how many people were onboard.", "London", "Abigail '' that he loved her", "an individual.", "William Tell", "OutKast", "Groundhog Day", "\" Cleopatra, Queen of Denial\"", "a fairground"], "metric_results": {"EM": 0.546875, "QA-F1": 0.619906191643324}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, false, true, false, false, true, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, false, false, false, true, false, true, false, true, false, false, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.07142857142857144, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2, 1.0, 0.5, 1.0, 0.11764705882352941, 0.0, 0.0, 0.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5278", "mrqa_squad-validation-10185", "mrqa_squad-validation-9194", "mrqa_squad-validation-9484", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-1384", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-3201", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1242", "mrqa_newsqa-validation-3391", "mrqa_newsqa-validation-1133", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-1436", "mrqa_newsqa-validation-1380", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-4142", "mrqa_newsqa-validation-172", "mrqa_newsqa-validation-624", "mrqa_newsqa-validation-2406", "mrqa_newsqa-validation-1778", "mrqa_naturalquestions-validation-5093", "mrqa_triviaqa-validation-2315", "mrqa_hotpotqa-validation-2679", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-11812"], "SR": 0.546875, "CSR": 0.646875, "EFR": 0.9310344827586207, "Overall": 0.7889547413793103}, {"timecode": 10, "before_eval_results": {"predictions": ["Paramount Pictures", "Ferncliff Cemetery in Ardsley, New York,", "pseudorandom", "John Wesley", "Genghis Khan's", "water", "internal strife", "yellow fever", "DC traction motor", "The Prince of P\u0142ock", "France, Italy, Belgium, the Netherlands, Luxembourg and Germany", "Lothar de Maizi\u00e8re", "within the premises of the hospital", "journalist", "Cam Newton", "over $40 million", "Super Bowl XXXIII", "the membrane of the primary endosymbiont", "Beyonc\u00e9 and Bruno Mars", "Theodor Fontane", "33", "chairman and CEO", "Brazil", "July 18, 1994", "fractured pelvis and sacrum -- the triangular bone within the pelvis.", "issued his first military orders as leader of North Korea", "8 to 10 inches of snow", "Willem Dafoe", "\"Maude\"", "Phillip A. Myers.", "general astonishment", "two weeks after Black History Month was mocked in an off-campus party that was placed on the bookcase at the school.", "58", "two Metro transit trains that crashed the day before, killing nine,", "last summer.", "his son, Isaac, and daughter, Rebecca.", "Touma", "Dangjin", "\"novel that you would embarrassed to buy,\"", "Hu Jintao", "magazine", "burns over about two-thirds of his body,", "October 3,", "Adriano", "Larry Zeiger", "shock, quickly followed by speculation about what was going to happen next.", "President Bush", "Jeffrey Jamaleldine", "35,000", "South Africa", "Tim Clark, Matt Kuchar and Bubba Watson", "Haiti", "Sunday", "lightning strikes", "Bill Stanton", "American Airlines", "16 August 1975", "Bonnie Aarons", "one", "kabinett", "Lionsgate.", "James Lofton", "mystic", "hair-like structures that help paramecium move around."], "metric_results": {"EM": 0.609375, "QA-F1": 0.6815611471861471}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.18181818181818182, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5714285714285714, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1572", "mrqa_squad-validation-7230", "mrqa_newsqa-validation-4069", "mrqa_newsqa-validation-3219", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-2778", "mrqa_newsqa-validation-1019", "mrqa_newsqa-validation-2220", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-397", "mrqa_newsqa-validation-1288", "mrqa_newsqa-validation-2807", "mrqa_newsqa-validation-2524", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-1311", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-4182", "mrqa_newsqa-validation-83", "mrqa_newsqa-validation-148", "mrqa_newsqa-validation-1947", "mrqa_triviaqa-validation-1100", "mrqa_hotpotqa-validation-3949", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-9132"], "SR": 0.609375, "CSR": 0.6434659090909092, "EFR": 1.0, "Overall": 0.8217329545454546}, {"timecode": 11, "before_eval_results": {"predictions": ["Central Banking economist", "The combination of hermaphroditism and early reproduction", "Victoria Department of Education", "transported to the Manhattan Storage and Warehouse Company under the Office of Alien Property (OAP) seal", "Manned Spacecraft Center", "economic inequality", "refusing to make a commitment", "use of a decentralized network with multiple paths between any two points, dividing user messages into message blocks,", "Elway", "Philo of Byzantium", "36", "Louis Agassiz", "Melbourne", "Jawaharlal Nehru", "Austrian Polytechnic", "Lorelei", "Euler's totient function", "a better relevant income", "Redwood City, California", "400 m wide", "Netherlands", "David", "pink mice", "antelope", "nipples", "the Precambrian period", "pio-  neers' Society, Ltd.", "Anastasia Dobromyslova", "Lady Gaga", "9", "Space Jam", "radish", "Robert Ludlum", "giant grubs", "(.mov)", "the largest showcase of Grand Prix racing cars in the world", "Saturday Night Live", "Hebrew", "The London Underground Piccadilly Line", "Wisconsin", "orangutan", "Manet", "Charlie and the Chocolate Factory", "Massachusetts", "2005", "1971", "Dodge", "Benny Hill", "Venice", "a peplos", "Enrico Caruso", "Elizabeth Arden", "collapsible support assembly", "Sir Hardy Amies", "Antigua and Barbuda", "the 14th most common surname in Wales", "Kylie Minogue", "Ray Looze", "Bloomingdale Firehouse", "Israel's vice prime minister compared Iran to Nazi Germany", "Golden Gate Yacht Club of San Francisco", "Roger Vivier", "mneagtige stenlandskab Cockpit Country.", "Buddhism"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6320198445877794}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, true, false, false, true], "QA-F1": [0.5, 1.0, 1.0, 0.2608695652173913, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.5, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6153846153846153, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.1111111111111111, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7383", "mrqa_squad-validation-1596", "mrqa_squad-validation-7320", "mrqa_squad-validation-9063", "mrqa_triviaqa-validation-6795", "mrqa_triviaqa-validation-2092", "mrqa_triviaqa-validation-7120", "mrqa_triviaqa-validation-2034", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-6010", "mrqa_triviaqa-validation-4860", "mrqa_triviaqa-validation-5115", "mrqa_triviaqa-validation-7168", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5443", "mrqa_triviaqa-validation-4386", "mrqa_triviaqa-validation-2416", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-6810", "mrqa_triviaqa-validation-6113", "mrqa_triviaqa-validation-1138", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2291", "mrqa_hotpotqa-validation-3960", "mrqa_hotpotqa-validation-4834", "mrqa_newsqa-validation-3753", "mrqa_searchqa-validation-14983", "mrqa_searchqa-validation-13120"], "SR": 0.546875, "CSR": 0.6354166666666667, "EFR": 0.9655172413793104, "Overall": 0.8004669540229885}, {"timecode": 12, "before_eval_results": {"predictions": ["the Southern Border Region", "70-50's", "Panini", "Bills", "anti-colonial movements", "glacial", "protein A", "suspicious of even the greatest thinkers and to test everything himself by experience", "Zhongshu Sheng", "legitimate medical purpose by a licensed practitioner acting in the course of legitimate doctor-patient relationship", "basic constitutional rights and principles", "1788", "2006", "Roman Catholic", "Henry of Navarre", "John Wesley", "the nationalisation law was from 1962, and the treaty was in force from 1958,", "Eternal Heaven", "lowestoft", "Jessica Simpson", "Sue Ryder", "Val Doonican", "Virgil", "France", "T.S. Eliot", "iceland", "Sir Hugo Drax", "Vladivostok", "Sheryl Crow", "Telstar", "juridale", "AFC Wimbledon", "Bob Monkhouse and Kenneth Connor", "Malaysia", "cosmology", "gin", "George Clooney", "Eric Coates", "James Chadwick", "\"No one was saved\"", "Monopoly", "champagne", "an extended period of abundant rainfall lasting many thousands of years", "United States", "Brigit Forsyth", "london", "state of Japan", "a guy named Troilus and a girl named Cressida", "Thomas Edward Lawrence", "Kent", "Paul Lhote", "Standard Motor Company", "white", "Switzerland", "soda water", "people of France to the people of the United States", "79", "ITV", "Scottish national team", "the death of a pregnant soldier", "Derek Mears", "far the lowest expenditures", "David", "\"The Screening Room\""], "metric_results": {"EM": 0.609375, "QA-F1": 0.6582707175612181}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, false, false, true, true, false, false, true, true, false, false, true, false, false, true, true, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 0.8387096774193548, 0.5882352941176471, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.25, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-2659", "mrqa_squad-validation-9126", "mrqa_squad-validation-2078", "mrqa_squad-validation-6426", "mrqa_squad-validation-4116", "mrqa_triviaqa-validation-3847", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-946", "mrqa_triviaqa-validation-302", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-3128", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-5192", "mrqa_triviaqa-validation-2147", "mrqa_triviaqa-validation-6384", "mrqa_triviaqa-validation-1975", "mrqa_triviaqa-validation-1141", "mrqa_triviaqa-validation-1423", "mrqa_triviaqa-validation-5933", "mrqa_triviaqa-validation-3503", "mrqa_naturalquestions-validation-594", "mrqa_hotpotqa-validation-1685", "mrqa_hotpotqa-validation-5428", "mrqa_searchqa-validation-8450", "mrqa_newsqa-validation-3860"], "SR": 0.609375, "CSR": 0.6334134615384616, "EFR": 1.0, "Overall": 0.8167067307692308}, {"timecode": 13, "before_eval_results": {"predictions": ["168,637", "the Barnett Center", "entertainment", "Muhammad ibn Zakar\u012bya R\u0101zi", "Georgia", "articles 1 to 7", "it would appear to be some form of the ordinary Eastern or bubonic plague", "had their own militia", "after the end of the Mexican War", "61", "quality of a country's institutions", "cilia", "friction", "Sky Digital", "2005", "force", "mustelids", "Governor Connally", "saffron", "HYMENAEUS", "Zeus", "albinism", "Straits of Tiran", "Brigit Forsyth", "Call My Bluff", "March 10, 1997", "cuddly new pet", "the Battle of the Three Emperors", "Velazquez", "Arthur Ashe", "lizard", "strong cold southwest wind", "table tennis", "medical manual", "penhaligon", "Gandalf", "auguste gove", "Jinnah International", "Monday", "capital of Venezuela", "rosary", "soap", "cocktail", "Avro Lancaster", "Genesis", "Charlie Brooker", "tea", "Harrods", "2007", "Christina Ricci", "Scarface", "pale yellow", "renoir", "bubba", "June 12, 2018", "Filipino American", "London", "Lambic", "Kindle Fire", "Steven Green", "commas", "auguste fortune", "bridge Street, Huntsville, AL", "Synchronicity"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6269097222222222}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6029", "mrqa_squad-validation-4908", "mrqa_squad-validation-2875", "mrqa_triviaqa-validation-899", "mrqa_triviaqa-validation-4182", "mrqa_triviaqa-validation-2334", "mrqa_triviaqa-validation-977", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3516", "mrqa_triviaqa-validation-264", "mrqa_triviaqa-validation-1630", "mrqa_triviaqa-validation-1129", "mrqa_triviaqa-validation-5254", "mrqa_triviaqa-validation-4070", "mrqa_triviaqa-validation-5060", "mrqa_triviaqa-validation-385", "mrqa_triviaqa-validation-4632", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-2426", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-5320", "mrqa_triviaqa-validation-6994", "mrqa_naturalquestions-validation-3162", "mrqa_newsqa-validation-3314", "mrqa_searchqa-validation-517", "mrqa_searchqa-validation-8598", "mrqa_searchqa-validation-6628"], "SR": 0.53125, "CSR": 0.6261160714285714, "EFR": 1.0, "Overall": 0.8130580357142857}, {"timecode": 14, "before_eval_results": {"predictions": ["seven", "woodblocks", "New Orleans' Mercedes-Benz Superdome, Miami's Sun Life Stadium", "the Teaching Council", "ABC Entertainment Group", "Doctor in Bible", "mountainous areas", "the soul don't leave their bodies to be threatened by the torments and punishments of hell, but enter a prepared bedchamber in which they sleep in peace.\"", "1960", "John Mayow", "3.62", "the Treaties establishing the European Union", "a declining state of mind", "1898", "The Deadly Assassin and Mawdryn undead", "radioisotope thermoelectric generator", "Cody Fern", "Nicklaus", "Jim Gaffigan", "Space is the Place   Jumping on the Moon", "2020", "1974", "332", "1997", "Authority", "senior enlisted sailor", "Spanish moss", "Chinese cooking", "Vienna", "the World Trade Center complex", "Kevin Spacey", "eve", "78", "in lymph", "Bangladesh -- India border", "the President", "G minor", "Coppolas", "Chandan Shetty", "metamorphic rock", "October 1, 2014", "United States", "Claims adjuster", "uterus and uterine tubes", "Darlene Cates", "Atlanta, Georgia", "homicidal thoughts of a troubled youth", "infection", "Garfield Sobers", "12 November 2010", "pneumonoultramicroscopicsilicovolcanoconiosis", "Palm Sunday celebrations", "vertebral column", "three", "annual plants", "sausages", "kew Gardens", "Nikita Khrushchev", "$500,000", "young self-styled anarchists", "reaper", "austerrath", "the BBC building in Glasgow, Scotland", "a kidney transplant"], "metric_results": {"EM": 0.578125, "QA-F1": 0.714695687012263}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, false, true, false, true, false, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, true, false, false, false, false], "QA-F1": [0.5, 1.0, 0.6956521739130436, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.39999999999999997, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 0.3333333333333333, 1.0, 1.0, 1.0, 0.8, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4615384615384615, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8333333333333333, 0.5]}}, "before_error_ids": ["mrqa_squad-validation-653", "mrqa_squad-validation-125", "mrqa_squad-validation-2339", "mrqa_naturalquestions-validation-3828", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-2562", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-8660", "mrqa_naturalquestions-validation-10088", "mrqa_naturalquestions-validation-8545", "mrqa_naturalquestions-validation-8648", "mrqa_naturalquestions-validation-9342", "mrqa_naturalquestions-validation-342", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-6940", "mrqa_naturalquestions-validation-1762", "mrqa_naturalquestions-validation-56", "mrqa_naturalquestions-validation-259", "mrqa_naturalquestions-validation-7767", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-6328", "mrqa_triviaqa-validation-3542", "mrqa_newsqa-validation-3571", "mrqa_searchqa-validation-726", "mrqa_searchqa-validation-196", "mrqa_newsqa-validation-220", "mrqa_newsqa-validation-1279"], "SR": 0.578125, "CSR": 0.6229166666666667, "EFR": 0.9259259259259259, "Overall": 0.7744212962962963}, {"timecode": 15, "before_eval_results": {"predictions": ["T\u00f6regene Khatun", "rising inequality", "a special episode of The Late Show with Stephen Colbert", "small renovations, such as addition of a room, or renovation of a bathroom", "John Madejski Garden", "declare martial law and sent the state militia to maintain order", "Famous musicians", "CBS", "Jean Ribault", "Tetzel", "visitation of the Electorate of Saxony", "$414 million", "Necessity-based", "950 pesos ( approximately $ 18 )", "the fourth C key from left on a standard 88 - key piano keyboard", "Seattle, Washington", "Battle of Antietam", "Andy Cole and Shearer", "In Time", "6th century AD", "Glenn Close", "four times", "Agostino Bassi", "five seasons", "a beach in Malibu, California", "the church at Philippi", "the Dutch", "September 2017", "Professor Kantorek", "1546", "a retired cosmetics mogul", "Bhupendranath Dutt", "a warrior", "Dr. Lexie Grey ( Chyler Leigh )", "Majandra Delfino", "December 19, 1971", "Uruguay", "a lawyer at a Manhattan law firm", "Matt Jones", "National Legal Aid & Defender Association ( NLADA )", "Monk's Caf\u00e9", "domesticated sheep goes back to between 11000 and 9000 BC", "1970s", "Director of the Federal Bureau of Investigation", "a class that teaches students defensive techniques to defend against the Dark Arts", "Isaiah Amir Mustafa", "Julie Stichbury", "Saphira", "5.7 million", "Woody Harrelson, Juliette Lewis, Robert Downey Jr., Tom Sizemore, and Tommy Lee Jones", "Thespis", "Portugal", "John Coffey", "Rachel Kelly Tucker", "Bohemia, now Czech Republic", "earwigs", "Code 02PrettyPretty", "Joe Dever", "the opposition group,", "the abduction of minors", "Nevada", "Pablo Neruda", "Stage Stores", "1881"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5972264280858031}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, false, true, false, true, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 0.42857142857142855, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.3076923076923077, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9090909090909091, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.375, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.4444444444444445, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-434", "mrqa_squad-validation-6739", "mrqa_squad-validation-551", "mrqa_naturalquestions-validation-8676", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-40", "mrqa_naturalquestions-validation-7084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-4609", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-2232", "mrqa_naturalquestions-validation-4761", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-1766", "mrqa_naturalquestions-validation-4731", "mrqa_naturalquestions-validation-2756", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-3253", "mrqa_naturalquestions-validation-5835", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-10559", "mrqa_naturalquestions-validation-2806", "mrqa_triviaqa-validation-4262", "mrqa_triviaqa-validation-1705", "mrqa_hotpotqa-validation-2767", "mrqa_hotpotqa-validation-3870", "mrqa_newsqa-validation-2674", "mrqa_searchqa-validation-5103"], "SR": 0.453125, "CSR": 0.6123046875, "EFR": 0.9142857142857143, "Overall": 0.7632952008928571}, {"timecode": 16, "before_eval_results": {"predictions": ["BBC 1", "Arizona Cardinals", "Bert Bolin", "390 billion individual trees divided into 16,000 species", "igneous, sedimentary, and metamorphic", "US", "six", "11", "hydrogen and helium", "Khitan", "November 1979", "Robert Lane and Benjamin Vail", "Germany", "Francis the Talking Mule", "Helsinki, Finland", "Microsoft Office", "SAVE", "Scandinavian Airlines System", "1993 to 2001", "1951", "NCAA Division I Football Bowl Subdivision", "Martin Truex Jr.", "Easter Rising of 1916", "45%", "more than two decades", "BAFTA TV Award Best Actor", "Jello Biafra drew on Nardwuar's face with a marker pen", "the 1745 rebellion of Charles Edward Stuart", "Burny Mattinson", "Sir William McMahon", "the North Sea coast", "7.63\u00d725mm Mauser", "Academy Award for Best Animated Feature", "Pakistan Aeronautical Complex (PAC)", "Delacorte Press", "Neighbourhoods are often social communities with considerable face-to-face interaction among members", "Secretariat", "Marcus Island", "Hydrogen vehicle", "Fort Valley, Georgia", "King of the Polish-Lithuanian Commonwealth", "\"Southern Living\" Reader's Choice Awards", "Thomas Harold Amer", "Johnson & Johnson", "ZZ Top", "Mahoning County", "Amway", "Parlophone Records", "Durban", "Surrey", "My Sassy Girl", "Charles Russell", "Boyd Gaming", "three different covers", "1968, 1970", "Glenn Close", "Myra Zamparelli", "Neighbours", "Ewan McGregor", "2011", "Browning", "an enslaved African American", "power-sharing talks", "Brown-Waite"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6352374188311689}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, true, false, true, true, false, false, true, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.3636363636363636, 0.2857142857142857, 0.4, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.25, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.3636363636363636, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4415", "mrqa_squad-validation-3667", "mrqa_squad-validation-8087", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-2646", "mrqa_hotpotqa-validation-3144", "mrqa_hotpotqa-validation-1546", "mrqa_hotpotqa-validation-4689", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2396", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-2494", "mrqa_hotpotqa-validation-1661", "mrqa_hotpotqa-validation-5086", "mrqa_hotpotqa-validation-4612", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-1428", "mrqa_hotpotqa-validation-2409", "mrqa_hotpotqa-validation-2771", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-1436", "mrqa_hotpotqa-validation-4859", "mrqa_naturalquestions-validation-2650", "mrqa_triviaqa-validation-2052", "mrqa_newsqa-validation-174", "mrqa_searchqa-validation-9931", "mrqa_searchqa-validation-4338", "mrqa_newsqa-validation-655"], "SR": 0.546875, "CSR": 0.6084558823529411, "EFR": 1.0, "Overall": 0.8042279411764706}, {"timecode": 17, "before_eval_results": {"predictions": ["forces", "theology and philosophy", "ITV", "University of Chicago College Bowl Team", "Philip Webb and William Morris", "7:00 to 9:00 a.m. weekdays", "Japanese", "charter", "1830", "nonfunctional pseudogenes", "the inner chloroplast membrane", "Charlie Harper", "Stevie Wonder", "Beaver", "La Boh\u00e8me", "formic acid", "Talavera de la Reina", "Zimbabwe", "Mr. Boddy", "Edward \"Ted\" Hankey", "Richard Walter Jenkins", "Japan", "Lewis Carroll", "multi-user dungeon", "Mercury", "hound", "Xenophon", "Fuller", "waterline", "Nick Hornby", "The Comedy of Errors", "Charles V", "England", "welch", "weight plates", "\"big house\"", "Hadrian", "US", "human flea", "Moonee Ponds, a suburb in Melbourne, Victoria", "Hamburg", "mulberry", "Tangled", "\"The French Connection\"", "CBS", "Manchester United", "Sergei Prokofiev", "Jessica Simpson", "Culture Club", "In 1906, Finland became the first country in the world to grant women full political rights.", "3000m", "Scotland", "England", "Travis Tritt and Marty Stuart", "Each side had about 18,000 poorly trained and poorly led troops in their first battle", "New Jewel Movement", "sub-Saharan Africa", "U.S. 93", "Anjuna beach in Goa", "Marius Ivanov", "Oshkosh", "two", "\"The World\"", "\"The Sunday Thing\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.659375}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, false, true, false, true, false, true, true, true, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3208", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-7521", "mrqa_triviaqa-validation-4598", "mrqa_triviaqa-validation-4283", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1325", "mrqa_triviaqa-validation-5963", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-3142", "mrqa_triviaqa-validation-2813", "mrqa_triviaqa-validation-1391", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-4941", "mrqa_triviaqa-validation-3443", "mrqa_triviaqa-validation-6151", "mrqa_triviaqa-validation-2812", "mrqa_naturalquestions-validation-767", "mrqa_newsqa-validation-2981", "mrqa_searchqa-validation-5843", "mrqa_searchqa-validation-9843", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-9467"], "SR": 0.59375, "CSR": 0.6076388888888888, "EFR": 1.0, "Overall": 0.8038194444444444}, {"timecode": 18, "before_eval_results": {"predictions": ["low latitude", "1622", "extremely high", "Manakintown", "northwest", "fewer than 10 employees", "Middle Miocene", "new magma", "salt and iron", "Grundschule", "September 29, 2017", "James Martin Lafferty", "balance sheet", "July 2, 1776", "practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another", "2010", "Coppolas and, technically, the Farrow / Previn / Allens", "Anna Faris", "jutting out into the Mediterranean Sea", "ability to comprehend and formulate language", "Splodgenessabounds", "Tyrion", "electron donors", "Laura Jane Haddock", "( 1985 -- 1993 )", "775", "Solange Knowles & Destiny's Child", "Gupta Empire", "December 2, 1942", "Lewis Carroll", "20 November 1989", "Coton in the Elms", "( 55 -- 69 % ) & 4 ( 40 -- 54 % )", "Ella Eyre", "1995", "Definition of the problems and / or goals", "16 August 1975", "December 1974", "`` Killer Within ''", "Western Australia", "aorta", "July 21, 1861", "Dr. Addison Montgomery", "capital and financial markets", "\"An empty line\"", "on the lateral side of the tibia", "Toto", "Thomas Mundy Peterson", "a violation of nature", "September 2017", "one of The Canterbury Tales by Geoffrey Chaucer", "\" Rising Sun Blues ''", "Part 2", "Dumbo", "the \u201cBloody Assizes\u201d", "Christian", "Robert L. Stone", "2008", "Yemen", "jegna", "Robert Langdon", "ABC1 and ABC2", "NBA 2K16", "mistress of the Robes"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6780729230097836}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, true, false, true, true, true, false, false, true, true, false, true, true, false, true, true, false, true, false, true, false, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7843137254901961, 0.0, 0.2857142857142857, 0.0, 0.0, 0.8, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.6666666666666666, 0.28571428571428575, 1.0, 1.0, 0.08695652173913042, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.2, 1.0, 0.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3193", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-31", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-5915", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-3840", "mrqa_naturalquestions-validation-5370", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-1039", "mrqa_naturalquestions-validation-6718", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-1053", "mrqa_naturalquestions-validation-8000", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-8483", "mrqa_naturalquestions-validation-2143", "mrqa_naturalquestions-validation-3164", "mrqa_naturalquestions-validation-10416", "mrqa_triviaqa-validation-4227", "mrqa_searchqa-validation-7111", "mrqa_hotpotqa-validation-4735"], "SR": 0.59375, "CSR": 0.606907894736842, "EFR": 0.9615384615384616, "Overall": 0.7842231781376519}, {"timecode": 19, "before_eval_results": {"predictions": ["everything that is used to work sorrow over sin is called the law, even if it is Christ's life, Christ's death for sin, or God's goodness experienced in creation", "black", "Louisiana, Biloxi, Mississippi, Mobile, Alabama", "Jaime Weston", "1978", "high art and folk music, also all classes, clergy and laity, men, women and children", "warming", "the mid-sixties", "270,000", "Long troop deployments", "Joe Pantoliano", "a Florida girl who disappeared in February, plans to file for divorce from the girl's stepmother", "innovative, exciting skyscrapers", "Rawalpindi", "Michael Jackson", "32 percent", "the Falklands, known as Las Malvinas in Argentina, lie in the South Atlantic Ocean off the Argentinean coast and have been under British rule since 1833.", "Tuesday", "forgery and flying without a valid license", "Anil Kapoor", "19", "President Obama", "unwanted baggage from the 80s", "The Louvre", "snowstorm", "exotic sports cars", "11 healthy eggs", "Moammar", "Manchester, England shows have been moved from Thursday and Friday to the end of her tour on June 17 and 18, the publicist said.The Glasgow, Scotland concert has been shifted from this Sunday to May 1, he said.", "\"Steamboat Bill, Jr.\"", "NATO fighters", "alcohol", "Atlantic Ocean", "President Sheikh Sharif Sheikh Ahmed", "cortisone", "\u00a320 million ($41.1 million) fortune", "Kingman Regional Medical Center", "Laura Ling and Euna Lee", "Manmohan Singh", "Michael Jackson", "be silent", "40 militants and six Pakistan soldiers dead", "Roger Federer", "Stratfor subscriber data, including information on 4,000 credit cards and the company's \"private client\" list,", "Lousiana", "the Southeast", "Misty Croslin", "Steven Chu", "\"A Mother For All Seasons.\"", "The Maraachlis' daughter, Zeina,", "back at work", "the initial necropsy or animal autopsy", "teenager", "Corbin Bleu and Karina Smirnoff", "John Adams, a leader in pushing for independence, had persuaded the committee to select Thomas Jefferson to compose the original draft of the document, which Congress edited to produce the final version", "potatoes", "Zager and Evans", "Bobby Hurley", "his fourth term as At-Large Chairman of the Board of Supervisors of Prince William County, Virginia", "obscenity", "cavalry", "Lapland", "1937", "Emad Hashim"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5607681127822481}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, false, false, true, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, false, false, true, true, false, false, false, false, true, false, false, false, false, false, true, false, false, true, false, false, true, true], "QA-F1": [0.6, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.33333333333333337, 1.0, 0.0, 1.0, 0.5714285714285715, 0.5, 0.6666666666666666, 1.0, 0.923076923076923, 0.6666666666666666, 0.8333333333333333, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715, 0.13793103448275862, 0.0, 1.0, 0.4, 0.23529411764705882, 1.0, 0.0, 0.4, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2520", "mrqa_squad-validation-5702", "mrqa_squad-validation-10180", "mrqa_squad-validation-2400", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-2389", "mrqa_newsqa-validation-1856", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-3473", "mrqa_newsqa-validation-2383", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-3491", "mrqa_newsqa-validation-2785", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-2590", "mrqa_newsqa-validation-3463", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-3018", "mrqa_newsqa-validation-3775", "mrqa_newsqa-validation-679", "mrqa_newsqa-validation-1892", "mrqa_newsqa-validation-355", "mrqa_newsqa-validation-3618", "mrqa_newsqa-validation-1958", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-6786", "mrqa_triviaqa-validation-3831", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-2013", "mrqa_searchqa-validation-8011", "mrqa_hotpotqa-validation-2922"], "SR": 0.421875, "CSR": 0.59765625, "EFR": 1.0, "Overall": 0.798828125}, {"timecode": 20, "before_eval_results": {"predictions": ["late 19th century", "1550 to 1900", "torque variability", "115 \u00b0F (46.1 \u00b0C)", "Latin Rhenus", "1331", "Death wish Coffee", "L", "Cameroon", "1994", "ballots", "fabric", "three empty vodka bottles,", "training Afghan police and troops, before trading his uniform for a diplomat's business suit.", "Bobby Darin,", "compatriot Nico Rosberg", "16", "his former Boca Juniors teammate and national coach Diego Maradona", "she was humiliated by last month's incident, in which she was forced to forcefully remove the piercings", "composer of \"Phantom of the Opera\" and \"Cats\"", "the punishment for the player", "Caylee Anthony, 2,", "Amanda Knox's aunt", "well over 1,000 pounds", "Iran's nuclear program.", "a welcoming, bright blue-purple", "allegedly faking a doctor's note", "ceo Herbert Hainer", "Brett Cummins,", "swimming privileges of a nearby day care center whose children are predominantly African-American.", "inmates", "Col. Elspeth Cameron-Ritchie,", "\"E! News\"", "Three French journalists, a seven-member Spanish flight crew and one Belgian", "jobs", "\"terrifying.\"", "Khalid Sheikh Mohammed, seen in a December sketch, was waterboarded 183 times in a month, a memo says.", "A video purporting to be from a vigilante group whose goal is the eradication of the Zetas cartel from the state of Veracruz, Mexico,", "Republicans", "what will they do now?\"", "An undated photo of Alexandros Grigoropoulos,", "a power-sharing deal with the opposition party's breakaway faction, his party said Tuesday, though Mugabe's opponents denied the claim.", "a 57-year old male", "North Korea intends to launch a long-range missile in the near future,", "Angola", "Gary Brooker", "the creation of an Islamic emirate in Gaza,", "boogeyman Jason Voorhees", "refused to refer the case of Mohammed al-Qahtani to prosecutors", "Sea World in San Antonio", "guard in the jails of Washington, D.C., and on the streets of post- Katrina New Orleans, Stephen Tyrone Johns had settled in to a job he liked at the U.S. Holocaust Memorial Museum,", "50", "the Ku Klux Klan", "1939", "Branford College", "Bury", "husbands", "Malayalam", "August 17, 2017", "a jacket", "mice followed, in the '80s | clone. right", "Hodel", "access to US courts", "the British rock group Coldplay"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5148119470076706}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, false, true, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.10526315789473684, 0.0, 0.0, 1.0, 0.9523809523809523, 0.3157894736842105, 0.25, 1.0, 0.8, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 0.05714285714285715, 0.0, 1.0, 0.0, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8181818181818181, 0.0, 0.16666666666666663, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.2857142857142857, 1.0, 0.22222222222222224, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-543", "mrqa_newsqa-validation-1670", "mrqa_newsqa-validation-1012", "mrqa_newsqa-validation-882", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-2166", "mrqa_newsqa-validation-3046", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-2094", "mrqa_newsqa-validation-465", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-1460", "mrqa_newsqa-validation-927", "mrqa_newsqa-validation-4041", "mrqa_newsqa-validation-1358", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-2400", "mrqa_newsqa-validation-2736", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-3818", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-2942", "mrqa_naturalquestions-validation-3788", "mrqa_triviaqa-validation-6406", "mrqa_triviaqa-validation-1427", "mrqa_hotpotqa-validation-5345", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-13277", "mrqa_naturalquestions-validation-7987"], "SR": 0.421875, "CSR": 0.5892857142857143, "EFR": 0.972972972972973, "Overall": 0.7811293436293436}, {"timecode": 21, "before_eval_results": {"predictions": ["the whole curriculum", "Eliot Ness", "the poor", "oxygen-16", "middle eastern scientists", "Amazoneregenwoud", "regulations and directives", "\u201csplash\u201d", "Nicola Adams", "copper and zinc", "eagle", "Peter Nichols", "Gulf of Aden", "Carlo Collodi,", "Tony Blair,", "Illinois", "shoulders", "Madonna's", "Glasgow", "is a satellite-based navigational system that can tell users exactly where they are on Earth.", "Australia", "giblet", "Pearson PLC.", "Irish Setter", "American Civil War,", "Loch Ness", "Jesuit", "Tasmania", "a gentle cat with a somewhat shy nature around strangers.", "China", "Harrisburg", "polecat", "glockenspiel", "Dr John Sentamu", "rochoon", "Pongo.", "Anne Boleyn", "EMI", "Holly Johnson", "Emma Chambers", "charlemagne", "from its very beginning in 1884 on the 17 foot tall and 67 foot wide Ash Wood Wall.", "Russell Crowe", "Phil Roberts", "roch", "Puck", "Samuel Butler", "chamomile tea", "Ireland", "tarn", "SS Constitution", "Albert Square", "Newbury", "a book of the Old Testament", "70 million people, at that time 21 % of the world's entire population", "Target Corporation", "\"The Omega Man\"", "Michelle Rounds", "doctors assured him using the surgical anesthetic propofol at home to induce sleep was safe as long as he was monitored.", "Oxfam,", "John Jackson Dickison", "the proceeds from sales go to organizations that support prisoners' rights and better conditions for inmates, like Amnesty International.", "Oprah Winfrey.", "his mother."], "metric_results": {"EM": 0.609375, "QA-F1": 0.6426053113553114}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, true, false, true, true, true, false, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true, true, true, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.3076923076923077, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.19999999999999998, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-7382", "mrqa_triviaqa-validation-1109", "mrqa_triviaqa-validation-7121", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5264", "mrqa_triviaqa-validation-3513", "mrqa_triviaqa-validation-6133", "mrqa_triviaqa-validation-3380", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-6307", "mrqa_triviaqa-validation-6055", "mrqa_triviaqa-validation-93", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-4303", "mrqa_triviaqa-validation-1328", "mrqa_triviaqa-validation-2040", "mrqa_triviaqa-validation-1664", "mrqa_naturalquestions-validation-10687", "mrqa_naturalquestions-validation-6287", "mrqa_hotpotqa-validation-1217", "mrqa_searchqa-validation-11802", "mrqa_searchqa-validation-1273", "mrqa_newsqa-validation-2256", "mrqa_newsqa-validation-4003", "mrqa_newsqa-validation-3088"], "SR": 0.609375, "CSR": 0.5901988636363636, "EFR": 1.0, "Overall": 0.7950994318181819}, {"timecode": 22, "before_eval_results": {"predictions": ["coughing and sneezing", "1765", "along the frontiers between New France and the British colonies", "standardized", "when the present amount of funding cannot cover the current costs for labour and materials,", "Vicodin,", "Christianity", "Matthew Henson", "pearls", "Utah Territory", "Carrie Underwood", "liqueur liquor", "he made his horse a consul, his palace a brothel, and his", "Google", "Langston Hughes", "Jimmy", "lillian Russell", "Tito Puente", "lariat", "UNFINISHED", "lST", "mountain lions, bears, deer, and other game", "David Beckham", "Toscanini", "economics is not a science in the way that physics or chemistry is a science.", "Miracle in the Andes", "london", "Montenegro", "discus", "hard", "basidiomycota", "James Earl Ray", "Allison Parker", "Idi Amin", "Deere", "a body, body part, or personal object", "coloured glazes", "Plutarch", "Rudy Giuliani", "masa harina", "40 seconds", "the Vikings", "Mulberry Street", "london", "typhoid fever", "fjord", "the capital of Bavaria", "Williamsburg", "19th Century Inventions", "london", "oxygen gas produced gets trapped in the soap which produces the big ball of foam.", "John Knox", "the internal reproductive anatomy", "more than $1 billion worldwide", "epidemiologists help with study design, collection, and statistical analysis of data, amend interpretation and dissemination of results", "the Big Bopper", "Tesco", "Mallard", "Graham Hill", "the Battelle Energy Alliance", "IT", "debris", "$10 billion", "Bailey, Colorado,"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5095948475544063}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, false, true, false, false, true, true, false, false, true, true, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, true, false, false, false, false, true, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.9411764705882353, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.15384615384615385, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.28571428571428575, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10104", "mrqa_searchqa-validation-1891", "mrqa_searchqa-validation-6948", "mrqa_searchqa-validation-9187", "mrqa_searchqa-validation-11156", "mrqa_searchqa-validation-15814", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-6193", "mrqa_searchqa-validation-11922", "mrqa_searchqa-validation-15426", "mrqa_searchqa-validation-10720", "mrqa_searchqa-validation-8325", "mrqa_searchqa-validation-7416", "mrqa_searchqa-validation-2843", "mrqa_searchqa-validation-5373", "mrqa_searchqa-validation-5223", "mrqa_searchqa-validation-4793", "mrqa_searchqa-validation-4344", "mrqa_searchqa-validation-9424", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15960", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-12592", "mrqa_searchqa-validation-8447", "mrqa_searchqa-validation-11235", "mrqa_searchqa-validation-5331", "mrqa_searchqa-validation-9473", "mrqa_searchqa-validation-16870", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-12608", "mrqa_searchqa-validation-15565", "mrqa_naturalquestions-validation-9005", "mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-4036", "mrqa_hotpotqa-validation-68", "mrqa_newsqa-validation-1997"], "SR": 0.421875, "CSR": 0.5828804347826086, "EFR": 1.0, "Overall": 0.7914402173913043}, {"timecode": 23, "before_eval_results": {"predictions": ["2010", "1493\u20131500", "the Pittsburgh Steelers", "Australia's first public packet-switched data network", "Hamas", "Nintendo", "Atlantic", "cats", "the daughter of Tony Richardson", "(Basel, Switzerland)", "the Argonauts", "prometheus", "the Altamont Speedway Free Festival", "John F. Kennedy", "Tim Gudgin", "Rosslyn Chapel", "conducting", "a MUD (multi-user dungeon)", "(Libya)", "Khaki", "magma", "Miguel Indurain", "Velazquez", "British Arts and Crafts", "Apollo", "African violet", "Pete Best", "Mendip", "president ( Sarah Palin, then-Governor of Alaska)", "the Earth", "(When Will You Marry Me?)", "phosphorus", "Mumbai", "Joan Rivers", "Moses Sithole", "the colony of Suriname", "Justin Trudeau", "to detect \u201cthe presence of distant metallic objects\u201d", "Denis Law", "\"All I Want\"", "William Golding", "Sally Ride", "a cyclone", "Fife", "Money Saving Expert", "Adidas", "the Hunting of the Snark", "Elizabeth Arden", "(Bath, Avon)", "woe", "\"On Her Majesty's Secret Service.\"", "the \"dark squares\"", "flour and water", "Lee Baldwin", "Frankie Valli", "Scotland", "Beauty and the Beast", "Alex Song", "86", "Musharraf", "Tennis Channel", "fox", "60 Minutes", "Jupiter"], "metric_results": {"EM": 0.609375, "QA-F1": 0.676124824929972}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, false, true, false, true, false, false, false, false, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.35294117647058826, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4840", "mrqa_triviaqa-validation-73", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3242", "mrqa_triviaqa-validation-4882", "mrqa_triviaqa-validation-3693", "mrqa_triviaqa-validation-6205", "mrqa_triviaqa-validation-5686", "mrqa_triviaqa-validation-4589", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-3467", "mrqa_triviaqa-validation-7765", "mrqa_triviaqa-validation-6290", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-1491", "mrqa_triviaqa-validation-6494", "mrqa_triviaqa-validation-4289", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-3359", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-6140", "mrqa_hotpotqa-validation-5087", "mrqa_newsqa-validation-848", "mrqa_newsqa-validation-458"], "SR": 0.609375, "CSR": 0.583984375, "EFR": 1.0, "Overall": 0.7919921875}, {"timecode": 24, "before_eval_results": {"predictions": ["illegal boycotts, refusals to pay taxes, draft dodging, distributed denial-of-service attacks, and sit-ins", "the chosen machine model", "20th Century Fox, Lionsgate, Paramount Pictures, Universal Studios and Walt Disney Studios", "1997", "a suite of network protocols", "Christopher Savoie", "15", "nine-wicket win over the world's number one ranked Test nation in Melbourne on Tuesday.", "between Pyongyang and Seoul", "killed a man, and even jumped in his pool, hoping to wash away the evidence.", "11", "change course", "Alwin Landry's supply vessel Damon Bankston", "Chaffetz", "money or other discreet aid for the effort if it could be made available,", "Sarah,", "it has not intercepted any Haitians attempting illegal crossings into U.S. waters.", "environmental", "Brazil", "Afghan police", "Saturday", "38,", "70,000 or so", "Climatecare,", "\"E! News\"", "former Boca Juniors teammate and national coach Diego Maradona", "Steve Williams", "McDonald's", "she crafts poems telling of the pain and suffering of children just like her; girls banned from school, their books burned,", "five female pastors", "2008", "Diego Maradona", "Dog patch Labs", "The Stooges comedic farce entitled \"Three Little Beers,\" to the Ben Hogan biopic \"Follow the Sun,\"", "two", "Itawamba County School District", "the former Massachusetts governor", "The EU naval force", "Plymouth Rock", "Liza Murphy,", "the nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "police", "former U.S. secretary of state", "At least 33", "five", "improve health and beauty.", "prison systems to monitor and detect cell signals.", "it is primarily students often know ahead of time when and where violence will flare up on campus.", "Alwin Landry's", "Krishna Rajaram,", "Sunday,", "death and destruction,", "Sin\u00e9ad ( / \u0283\u026a\u02c8ne\u026ad / shi - NADE ; Irish pronunciation", "southwestern Colorado and northwestern New Mexico", "March 31 to April 8, 2018", "northern irish", "radar", "art", "the 16th season", "the NFL single-season touchdown reception record", "South America", "freestyle", "Florence Nightingale", "Belief"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6137468650700776}, "metric_results_detailed": {"EM": [false, true, false, true, false, true, true, false, false, false, true, true, true, false, false, true, false, false, false, false, true, true, false, true, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false], "QA-F1": [0.0, 1.0, 0.15384615384615385, 1.0, 0.6153846153846153, 1.0, 1.0, 0.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5555555555555556, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.7499999999999999, 0.5, 1.0, 1.0, 0.4, 0.2666666666666667, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.8823529411764706, 1.0, 1.0, 0.25, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6846", "mrqa_squad-validation-610", "mrqa_squad-validation-4673", "mrqa_newsqa-validation-4085", "mrqa_newsqa-validation-3350", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-3169", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-341", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-3042", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-2274", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-4110", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-4017", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-569", "mrqa_newsqa-validation-2480", "mrqa_newsqa-validation-3660", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-7574", "mrqa_naturalquestions-validation-6193", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3290", "mrqa_hotpotqa-validation-4362", "mrqa_hotpotqa-validation-4806", "mrqa_searchqa-validation-3826"], "SR": 0.453125, "CSR": 0.57875, "EFR": 1.0, "Overall": 0.7893749999999999}, {"timecode": 25, "before_eval_results": {"predictions": ["its 50th anniversary special", "Thomas Savery", "Vicodin, generically known as hydrocodone", "Eastern crops such as carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "22,000 years ago onward", "violent separatist campaign", "Eleven", "269,000", "The Swiss art heist follows the recent theft in Switzerland of two paintings by Pablo Picasso, Bjoern Quellenberg,", "38 feet", "Eintracht Frankfurt", "150", "a pool of blood beneath his head.", "Russian bombers", "41,", "Los Alamitos Joint Forces Training Base", "Wally", "137", "the Kurdish militant group in Turkey", "3-2", "autonomy.", "The debris field was found around 10:30 p.m.", "the Russian air force", "34", "The president ordered the eventual closure of Guant Bay prison and CIA \"black site\" prisons", "around 3.5 percent of global greenhouse emissions.", "Amanda Knox's aunt", "The mysterious disappearance of Flight AF 447 over the Atlantic Ocean has fueled speculation among aviation experts about what caused the state-of-the-art airliner to come down.", "ensuring that all prescription drugs on the market are FDA approved,", "The most common patients are Japanese businessmen", "Tom Baer.", "Pakistan", "The oceans are kind of the last frontier for use and development,\"", "bikinis", "Brian Mabry", "iTunes, which completely changed the business of music,", "Sunday.", "60 euros -- $89 --", "American Civil Liberties Union", "refused to refer the case of Mohammed al-Qahtani to prosecutors because of that assessment,", "Some truly mind-blowing structures are being planned for the Middle East.", "first name", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "2006", "In San Diego,", "women who were working as prostitutes", "The Taliban has threatened to kill Bergdahl if foreign troops continue targeting civilians in the name of search operations in Ghazni and Paktika provinces,", "Twitter", "the explosion of a train seconds after it leaves the Liverpool Street Station heading for Aldgate East.", "Henry Ford", "security on the streets, with backing from U.N. peacekeepers.", "heart", "Hyderabad", "Sinai Peninsula", "to stay, abide", "Vegas", "Jackson Pollock", "lyrical", "Mississippi", "October 4, 1970", "King Duncan", "Georgia", "the thimble", "a stride"], "metric_results": {"EM": 0.375, "QA-F1": 0.5111370848345984}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, false, false, false, true, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true, true, false, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 0.8750000000000001, 0.8571428571428571, 0.8, 0.0, 0.0, 0.3157894736842105, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5263157894736842, 1.0, 1.0, 0.0588235294117647, 0.07407407407407408, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.1111111111111111, 0.0, 0.4, 0.888888888888889, 1.0, 0.8, 0.0, 0.1818181818181818, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7809", "mrqa_squad-validation-8068", "mrqa_squad-validation-9432", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-2053", "mrqa_newsqa-validation-4033", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-1697", "mrqa_newsqa-validation-1506", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-3964", "mrqa_newsqa-validation-1114", "mrqa_newsqa-validation-667", "mrqa_newsqa-validation-1062", "mrqa_newsqa-validation-3330", "mrqa_newsqa-validation-1333", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-1274", "mrqa_newsqa-validation-415", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-3819", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-826", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-1434", "mrqa_newsqa-validation-1695", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2757", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-9767", "mrqa_triviaqa-validation-1677", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5837", "mrqa_searchqa-validation-11832"], "SR": 0.375, "CSR": 0.5709134615384616, "EFR": 1.0, "Overall": 0.7854567307692308}, {"timecode": 26, "before_eval_results": {"predictions": ["gaseous oxygen", "chlorophyll b", "Off-Off Campus", "clerical", "pro-democracy activists clashed Friday with Egyptian security forces in central Cairo,", "Krishna Rajaram,", "25", "Booches Billiard Hall,", "finance", "Ross Perot.", "Hong Kong's Victoria Harbor", "2002", "six prostitutes and a runaway involved in the drug trade.", "legitimacy of that race.", "his chest", "three", "Monday", "Scarlett Keeling", "two years,", "Since 1980, the 84-year-old Mugabe has been the country's only ruler.", "regulators in the agency's Colorado office received improper gifts from energy industry representatives and engaged in illegal drug use and inappropriate sexual relations with them.", "give detainees greater latitude in selecting legal representation and afford basic protections to those who refuse to testify.", "in July for A Country Christmas", "Akshay Kumar", "Alan Graham", "they recently killed eight Indians whom the rebels accused of collaborating with the Colombian government,", "\"disagreements\" with the Port Authority of New York and New Jersey,", "during childbirth", "Michelle Rounds", "James Newell Osterberg", "strangulation and asphyxiation and had two broken bones in his neck,", "Phil Spector", "Kim Il Sung", "1994", "numerous suicide attacks,", "Friday", "the death of a pregnant soldier", "Aryan Airlines Flight 1625", "Republicans", "Afghanistan's restive provinces", "\"People of Palestine\"", "dependable Camry", "raping her in a Milledgeville, Georgia, bar during a night of drinking in March.", "Pop star Michael Jackson", "Kingman Regional Medical Center,", "a Yemeni cleric and his personal assistant,", "overthrow the socialist government of Salvador Allende in Chile,", "Miguel Cotto", "9 a.m.", "\"Don't ask, don't tell\"", "military veterans for their efforts in the D-Day landings of 65 years ago", "bartering -- trading goods and services without exchanging money", "semi-autonomous organisational units within the National Health Service in England", "6 - 6", "Bongos", "Inspector William Edward \"Jack\" Frost", "the innermost digit of the forelimb", "1974", "over 20 million", "Peoria, Illinois", "Honolulu", "croaking critters", "King Lear", "Ottoman Empire"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6412200809811104}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, false, true, false, false, false, false, true, false, false, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.72, 0.5714285714285715, 1.0, 0.0, 0.47058823529411764, 1.0, 0.0, 1.0, 0.0, 0.42857142857142855, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.15384615384615385, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.2222222222222222, 1.0, 0.0, 0.0, 0.33333333333333337, 0.0, 1.0, 0.4, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8646", "mrqa_squad-validation-2754", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-3891", "mrqa_newsqa-validation-1696", "mrqa_newsqa-validation-1138", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-270", "mrqa_newsqa-validation-3091", "mrqa_newsqa-validation-1041", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-1032", "mrqa_newsqa-validation-991", "mrqa_newsqa-validation-1847", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2870", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-256", "mrqa_newsqa-validation-2496", "mrqa_newsqa-validation-714", "mrqa_naturalquestions-validation-10451", "mrqa_naturalquestions-validation-9563", "mrqa_triviaqa-validation-4992", "mrqa_triviaqa-validation-5602", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-5856", "mrqa_searchqa-validation-11586"], "SR": 0.5625, "CSR": 0.5706018518518519, "EFR": 1.0, "Overall": 0.7853009259259259}, {"timecode": 27, "before_eval_results": {"predictions": ["early 1990s", "leaf-shaped", "silver", "1755", "AbdulMutallab", "trading goods and services without exchanging money", "Kenner, Louisiana", "John Dillinger,", "what caused the collapse of the building", "Seasons of My Heart", "Haleigh Cummings,", "Whitney Houston", "Kris Allen,", "Brazil's response to the HIV/AIDS fight has been widely praised and adopted as a model around the world.", "Lashkar-e-Tayyiba (LeT)", "$1.5 million", "2006", "Rev. Alberto Cutie", "Angels", "Indian army and separatist militants", "\"There's no chance of it being open on time.", "South Carolina Republican Party Chairwoman Karen Floyd", "14", "a Starbucks", "BADBUL", "98 people,", "1993", "on extreme caution because of the recent pirate attacks.", "Paul Ryan", "state senators", "Dr. Jennifer Arnold and husband Bill Klein,", "between government soldiers and Taliban militants in the Swat Valley.", "South Dakota State Penitentiary", "Iran", "last month's Mumbai terror attacks", "people have chosen their rides based on what their", "in July", "the 103 children that a French charity attempted to take to France from Chad for adoption", "Four Americans", "Josef Fritzl,", "Glasgow, Scotland", "38", "near the George Washington Bridge,", "President Bush", "fake his own death by crashing his private plane into a Florida swamp.", "at Hansa (Malmborgsgatan 6)", "fractured pelvis and sacrum", "Wednesday at the age of 95", "abduction of minors", "gun", "Jeanne Tripplehorn", "U.S. Vice President Dick Cheney", "19 June 2018", "Flag Day in 1954", "11 p.m. to 3 a.m", "Charlotte Corday", "Thailand", "Scotch Whisky", "Norwood, Massachusetts", "Manchester, England", "Drowning Pool", "apteka", "Vermont", "metoprolol"], "metric_results": {"EM": 0.625, "QA-F1": 0.7235852599268547}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.9655172413793104, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3636363636363636, 0.4444444444444445, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.8, 0.0, 0.0, 0.0, 1.0, 0.08333333333333333, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-1144", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-1193", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-933", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-2763", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-2108", "mrqa_newsqa-validation-436", "mrqa_triviaqa-validation-3389", "mrqa_hotpotqa-validation-4117", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-12398"], "SR": 0.625, "CSR": 0.5725446428571428, "EFR": 1.0, "Overall": 0.7862723214285714}, {"timecode": 28, "before_eval_results": {"predictions": ["700,000", "coordinating lead author of the Fifth Assessment Report", "rule", "1981,", "forgery and flying without a valid license,", "\"I wanted to shove it up that black a--.\"", "Daniel Radcliffe", "nomination of Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens", "Genocide Prevention Task Force.", "if they persist and go forward, we will take it up in appropriate channels.", "The European Commission", "Whitney Houston", "firefighter", "a president who understands the world today, the future we seek and the change we need. We need Barack Obama as the next president of the United States.", "Kurt Cobain", "seven", "the \"face of the peace initiative has been attacked,\"", "misdemeanor assault charges", "the shipping industry -- responsible for 5% of global greenhouse gas emissions, according to the United Nations -- embraces this technology the same way the public has,\"", "Anil Kapoor.", "the eradication of the Zetas cartel from the state of Veracruz, Mexico", "\"The Rosie Show,\"", "Form Design Center.", "collaborating with the Colombian government,", "Christianity and Judaism,", "the Dalai Lama's", "Russia", "around 8 p.m. local time Thursday", "Passers-by", "one day,", "executive director of the Americas Division of Human Rights Watch,", "750", "300", "Matthew Fisher", "The Ski Train", "Big Brother.", "Ozzy Osbourne", "AbdulMutallab,", "some U.S. senators", "inconclusive", "5:20 p.m. at Terminal C", "some 700 vessels were illegally operating in the region and fishing the local stock to near depletion.", "$250,000", "100% of its byproducts", "School-age girls", "5,600", "a million", "Sen. Arlen Specter", "Deutschneudorf,", "state and federal level.", "a deceased organ donor,", "he discussed foreplay, sexual conquests and how he picks up women, all taboo subjects in deeply conservative Saudi Arabia.", "a vertebral column ( spine )", "December 11, 2014", "Michael Madhusudan Dutta", "Goldtrail", "Spain", "the Royal Festival Hall", "Douglas Hofstadter", "\"The Dark Tower\"", "American", "Little Women", "Castle Rock", "The Ten Best Pizzerias in Naples"], "metric_results": {"EM": 0.625, "QA-F1": 0.7011625560574976}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, false, true, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.9655172413793104, 1.0, 0.1, 0.0, 1.0, 0.4, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.125, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.10526315789473685, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.08695652173913043, 1.0, 0.125, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9810", "mrqa_newsqa-validation-2811", "mrqa_newsqa-validation-722", "mrqa_newsqa-validation-1657", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-4057", "mrqa_newsqa-validation-3979", "mrqa_newsqa-validation-2796", "mrqa_newsqa-validation-1043", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-3826", "mrqa_newsqa-validation-3413", "mrqa_newsqa-validation-3480", "mrqa_newsqa-validation-1056", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-692", "mrqa_newsqa-validation-203", "mrqa_naturalquestions-validation-4028", "mrqa_hotpotqa-validation-4809", "mrqa_searchqa-validation-9830"], "SR": 0.625, "CSR": 0.5743534482758621, "EFR": 0.9583333333333334, "Overall": 0.7663433908045978}, {"timecode": 29, "before_eval_results": {"predictions": ["downward pressure on wages", "El Tem\u00fcr's son Ragibagh", "438,000", "Marty Ingels", "radio frequency connector", "Pakistan A", "Ever Bank Field", "7 members appointed by the chief executive", "the German Campaign of 1813", "John Churchill,", "1965", "Paris", "Championnat National 3", "Culiac\u00e1n, Sinaloa, in the northwest of Mexico", "seven", "Syracuse", "1963", "coca wine", "handheld", "Knoxville, Tennessee", "Washington, D.C.", "Gal\u00e1pagos giant rat", "Tom Kartsotis", "2017", "Wayman Lawrence Tisdale", "Mexico", "Srinagar", "Northern Ireland", "late 19th and early 20th centuries", "movie scripts written by ghost writers, nonfiction books on military subjects, and video games", "22,500", "the Harpe brothers", "Eric Liddell", "2002", "Gregg Harper", "Shohola Falls", "small forward", "ARY Films", "Erinsborough", "Marine Corps", "Robert A. Iger", "Major Charles White Whittlesey", "the Ais native population", "Virginia", "NBA Slam Dunk Contest", "$10\u201320 million", "January 28, 2016", "Kennedy Road", "a field in Somerset County, Pennsylvania,", "Drowning Pool", "Colin Blakely", "two Nobel Peace Prizes", "IB Primary Years Program for children aged 3 to 12", "Richard Parker", "the southernmost tip of the South American mainland", "Cecil B. De Mille", "allergic reaction", "is the younger daughter of King George VI and Queen Elizabeth, and the only sibling of Queen Elizabeth II.", "3,000 kilometers (1,900 miles)", "is that natural resources around the islands should be protected, and Britain must accept international resolutions labeling the Falklands a disputed area.", "Swiss art heist", "Russia,", "golden wine", "Australia"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6169642857142856}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, true, true, true, false, true, true, false, true, false, true, false, true, false, false, true], "QA-F1": [0.3333333333333333, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.28571428571428575, 0.5, 1.0, 0.0, 1.0, 0.4444444444444444, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7189", "mrqa_squad-validation-8164", "mrqa_hotpotqa-validation-4079", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1936", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-3219", "mrqa_hotpotqa-validation-3435", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-1213", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-1101", "mrqa_hotpotqa-validation-708", "mrqa_hotpotqa-validation-4935", "mrqa_hotpotqa-validation-2134", "mrqa_hotpotqa-validation-2220", "mrqa_hotpotqa-validation-1421", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-59", "mrqa_hotpotqa-validation-5021", "mrqa_hotpotqa-validation-3533", "mrqa_hotpotqa-validation-765", "mrqa_hotpotqa-validation-4163", "mrqa_naturalquestions-validation-9130", "mrqa_triviaqa-validation-2774", "mrqa_triviaqa-validation-5424", "mrqa_newsqa-validation-3888", "mrqa_searchqa-validation-2585", "mrqa_searchqa-validation-6793"], "SR": 0.53125, "CSR": 0.5729166666666667, "EFR": 1.0, "Overall": 0.7864583333333334}, {"timecode": 30, "before_eval_results": {"predictions": ["British", "October 16, 2012", "deforestation", "Germany's position in a Europe", "London", "Dave Thomas", "a farmers' co-op", "Danish", "1903", "the attack on Pearl Harbor", "other individuals, teams, or entire organizations.", "ten years of probation", "In Pursuit", "Bolton", "Monty Python's Flying Circus", "Kansas City crime family", "Werner Nowitzki", "lifetime achievements", "Alexandre Dimitri Song Billong", "Doc Hollywood", "1999", "200", "Theme Park World", "Formula E.", "New Jersey", "various deities, beings, and heroes", "86,112", "Celtic", "Ouse and Foss", "Springfield, Massachusetts", "British comedian", "\"Apatosaurus\"", "1885", "American", "Frank Thomas' Big Hurt", "\"Polovtsy\"", "Margarine Unie", "Winecoff Hotel fire", "New York City", "The Seduction of Hillary Rodham", "2005", "Lambic", "Tom Clancy's The Division", "Argentina", "Larry Alphonso Johnson Jr.", "Mike Mills", "the veto power", "Joseph E. Grosberg", "\"Chelsea Lately\"", "the Arrondissement of Strasbourg", "Turkmenistan", "Wembley Stadium, London", "Sally Field", "Tatsumi", "along the Californian coast at The Inn at Newport Ranch", "New York", "the discus", "Aston Hall", "2005", "228", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "Post Traumatic Stress disorder", "Copenhagen", "Nez Perce"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6846685606060606}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, false, true, true, true, true, true, false, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.6399999999999999, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5454545454545454, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3341", "mrqa_hotpotqa-validation-3921", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-1467", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-2533", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-3926", "mrqa_hotpotqa-validation-814", "mrqa_hotpotqa-validation-207", "mrqa_hotpotqa-validation-4284", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-3569", "mrqa_hotpotqa-validation-332", "mrqa_hotpotqa-validation-2230", "mrqa_hotpotqa-validation-547", "mrqa_hotpotqa-validation-55", "mrqa_hotpotqa-validation-3090", "mrqa_hotpotqa-validation-4633", "mrqa_naturalquestions-validation-2250", "mrqa_triviaqa-validation-3906", "mrqa_triviaqa-validation-5351", "mrqa_newsqa-validation-3106", "mrqa_newsqa-validation-3905", "mrqa_searchqa-validation-6975"], "SR": 0.59375, "CSR": 0.5735887096774194, "EFR": 1.0, "Overall": 0.7867943548387097}, {"timecode": 31, "before_eval_results": {"predictions": ["Fresno", "79", "Iceland", "Wyoming", "Silent Snow, Secret Snow", "a Timber Mountain", "Iowa", "Georgia", "Nassau", "a pearl oyster", "HIV", "Martin Van Buren", "a grande vitesse", "La donna e mobile", "aardwolf", "Beijing", "a mile", "Inuk", "Death Valley", "Yves Saint Laurent", "reindeer", "Fortinbras", "a schooner & 1 sloop", "Anna Mary Robertson", "a magical girl", "georgia", "georgia", "a polar bear", "a tornado", "John Fogerty", "Monty Python and the Holy Grail", "negative electrode", "Milton Berle", "George Herbert Walker Bush", "Congolese", "lunar module", "Chile", "Dan Marino", "Mars", "clownfish", "E = mc2", "The Love Guru", "Las Vegas", "millet", "a butterfly", "georgia", "a chimpanzee", "Baja California", "a soothsayer", "Yitzhak Rabin", "Saul", "Gettysburg", "Jack Gleeson", "Plank", "Buddhism", "Jean Bernadotte", "Portugal", "Graham Bond", "Johnson & Johnson", "acidic bogs", "20 March to 1 May 2003", "has not fully implemented appropriate security practices to protect the control systems used to operate its critical infrastructures,\"", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "12.3 million people worldwide"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5444568452380952}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, true, false, true, false, true, true, false, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, true, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.08333333333333333, 0.42857142857142855, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-10705", "mrqa_searchqa-validation-15396", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-8253", "mrqa_searchqa-validation-5343", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-6655", "mrqa_searchqa-validation-15130", "mrqa_searchqa-validation-3343", "mrqa_searchqa-validation-14888", "mrqa_searchqa-validation-12835", "mrqa_searchqa-validation-12657", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-6838", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-6900", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-13071", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-11713", "mrqa_searchqa-validation-8189", "mrqa_searchqa-validation-6612", "mrqa_searchqa-validation-8550", "mrqa_searchqa-validation-10037", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1602", "mrqa_triviaqa-validation-4765", "mrqa_hotpotqa-validation-187", "mrqa_newsqa-validation-3607", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-3574"], "SR": 0.515625, "CSR": 0.57177734375, "EFR": 1.0, "Overall": 0.785888671875}, {"timecode": 32, "before_eval_results": {"predictions": ["During the Second World War", "62", "Henry Addington", "40", "Libya", "Shania Twain", "Hillsborough", "glucagon", "The New York Yankees", "rapid eye movement", "green", "Ann Dunham", "his cousin, Saddam Hussein", "French", "Jim Branning", "Ohio", "Francis Matthews", "photographic", "magnetite", "Noah", "London", "New", "Sarah Ferguson", "Mercury", "watt", "Jennifer Williams", "Subway", "Madagascar", "Swansea City", "Gatcombe Park", "Rio de Janeiro", "optimism", "aged 75", "Jennifer Lopez", "1664", "Eurythmics", "Fred Perry", "Downton Abbey", "Martina Hingis", "a painter", "a Cyclops", "The Woodentops", "Michael Miles", "Sheryl Crow", "Lemuel", "Pomona", "Italy", "The Streets", "the Great Appalachian Valley", "a black Ferrari", "a branch of mathematics", "grizzly bear", "Michaeloriarty", "June 1992", "24", "1952", "Campbell's", "Kirkcudbright", "the soldiers", "cortisone.", "the United States can learn much from Turkey's expertise on Afghanistan and Pakistan.", "Jennifer Aronofsky", "a typeface", "lungs"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6154246794871794}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, false, true, false, false, true, true, true, true, true, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, false, true, false, true, true, false, false, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 0.5, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.33333333333333337, 1.0, 0.15384615384615383, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-5772", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-163", "mrqa_triviaqa-validation-3073", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1023", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-4621", "mrqa_triviaqa-validation-7198", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-1545", "mrqa_triviaqa-validation-3570", "mrqa_triviaqa-validation-5093", "mrqa_triviaqa-validation-7109", "mrqa_triviaqa-validation-4092", "mrqa_triviaqa-validation-5967", "mrqa_triviaqa-validation-2786", "mrqa_triviaqa-validation-7650", "mrqa_triviaqa-validation-2413", "mrqa_naturalquestions-validation-7976", "mrqa_hotpotqa-validation-3742", "mrqa_hotpotqa-validation-852", "mrqa_hotpotqa-validation-3001", "mrqa_newsqa-validation-1162", "mrqa_newsqa-validation-4171", "mrqa_searchqa-validation-14318", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-16567"], "SR": 0.546875, "CSR": 0.5710227272727273, "EFR": 0.9310344827586207, "Overall": 0.751028605015674}, {"timecode": 33, "before_eval_results": {"predictions": ["hymns", "deadly explosives", "Knutsford", "insulin", "cheddar", "Hudson Bay", "florida", "hay fever", "st. James Palace, London", "Getafix", "Brighton", "Belfast", "wind", "fire", "Robin Hood", "West Point", "Andy Warhol", "Spain", "jon clement", "stanley", "the solar system", "potatoes", "Moldovan", "Mitsubishi A6M Zero Fighter", "the Dartford Warblers", "fridericus Franciscus", "Estimate", "clare", "iron", "yankees", "Madness", "Buxton", "discretion", "Christian Dior", "Rudyard Kipling", "Leeds", "Philippines", "beaver", "Mel Blanc", "a frog", "clement", "Ellen DeGeneres", "rochdale ward of Milnrow", "5000 meters", "racing", "rennet", "Newfoundland and Labrador", "crow", "Yellowstone", "St. Thomas", "Philippines", "Hugh Laurie", "Buddhism", "Jonny Buckland", "Ohio", "Melbourne", "Osbald", "Scarface", "forgery and flying without a valid license", "UEFA Cup finalists Werder Bremen beat Athletic Bilbao 3-0 to top Group L,", "Liza Murphy", "Spock", "Bishkek Tajikistan", "Andorra, Belgium, Germany, Italy, Luxembourg, Monaco, Spain and Switzerland"], "metric_results": {"EM": 0.546875, "QA-F1": 0.5874999999999999}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, false, true, true, false, false, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, false, false], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.19999999999999998]}}, "before_error_ids": ["mrqa_squad-validation-2399", "mrqa_triviaqa-validation-3524", "mrqa_triviaqa-validation-502", "mrqa_triviaqa-validation-781", "mrqa_triviaqa-validation-7206", "mrqa_triviaqa-validation-2126", "mrqa_triviaqa-validation-5143", "mrqa_triviaqa-validation-304", "mrqa_triviaqa-validation-6877", "mrqa_triviaqa-validation-6732", "mrqa_triviaqa-validation-6154", "mrqa_triviaqa-validation-5801", "mrqa_triviaqa-validation-3424", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-5436", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-1401", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-4987", "mrqa_triviaqa-validation-4909", "mrqa_triviaqa-validation-7614", "mrqa_triviaqa-validation-6068", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-1976", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-5602", "mrqa_newsqa-validation-2281", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-11382"], "SR": 0.546875, "CSR": 0.5703125, "EFR": 0.9655172413793104, "Overall": 0.7679148706896552}, {"timecode": 34, "before_eval_results": {"predictions": ["Battle of Fort Bull", "business districts", "prairies", "bologna, Italy", "george sandayana", "opossum", "Alice Cooper", "heart failure", "trumpet", "dupin", "tall", "s&DR", "appalachians", "Herald of Free Enterprise", "ballet", "dupin", "george i", "lizards", "manhattan", "Frankie Laine", "The Mystery of Edwin Drood", "pommel horse", "bird", "Dick Van Dyke", "egremont", "Numb3rs", "de Goya", "Medea", "dupin", "Canada", "ink", "pears soap", "Some Like It Hot", "manhattan", "Ireland", "Mike Meyers", "fish", "plutonium", "igneous", "Passepartout", "welcome", "Spain", "Spain", "shrek", "26.3 km", "Cleveland Brown", "dupin", "One Direction", "tall John silver", "Jupiter", "dupin poirot", "Charles Lindbergh", "September 2001", "Baaghi", "lead dioxide", "boxer", "East Kn Boyle", "beer", "an older generation", "Pakistan's High Commission in India", "astonishment", "Hunter S. Thompson", "Tchaikovsky", "Howard Carter"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5515625}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, false, false, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, true, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.5, 0.6666666666666666, 0.5, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-288", "mrqa_triviaqa-validation-4535", "mrqa_triviaqa-validation-918", "mrqa_triviaqa-validation-1369", "mrqa_triviaqa-validation-4418", "mrqa_triviaqa-validation-5426", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1963", "mrqa_triviaqa-validation-1724", "mrqa_triviaqa-validation-4276", "mrqa_triviaqa-validation-535", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-6449", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-4931", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-4530", "mrqa_triviaqa-validation-4715", "mrqa_triviaqa-validation-931", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-6918", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-3623", "mrqa_naturalquestions-validation-8994", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-3917", "mrqa_hotpotqa-validation-4664", "mrqa_newsqa-validation-2739", "mrqa_newsqa-validation-78"], "SR": 0.484375, "CSR": 0.5678571428571428, "EFR": 1.0, "Overall": 0.7839285714285714}, {"timecode": 35, "before_eval_results": {"predictions": ["alcohol", "John Forster", "matlock", "American Civil War", "isle of shoa", "flies", "Arafura Sea", "passeiphae\u2019s wooden Cow", "the Euphrates River", "Bavarian", "to make wrinkles in one's face", "Spain", "carousel", "bullfights", "paulys", "Tenor", "cat food", "fidelio", "black eyed peas", "Julian Fellowes", "Denmark", "brandy", "The Last King of Scotland", "black eyed peas", "pembrokeshire", "G. Ramon", "jean feldman", "marty feldmaninoff", "Finland", "stars with gravity so strong that not even light", "Mille Miglia", "snake salamander", "charles heston", "silver", "Muriel Spark", "happy birthday", "seven", "snake", "Pickwick Papers", "presliced bread", "Saga Noren", "raven", "jean", "isle of passe", "nelsons Column", "the Etruscans", "Ken Burns", "isle of manhattan", "Great Britain", "Pyotr Ilich tchaikovsky", "Mujib,", "black eyed peas", "Donna", "season four", "sinoatrial node", "Yubin, Yeeun", "tomato", "Republican", "because of the way Britain implements European Union employment directives.", "the Civil Protection Authority.", "March 24,", "Prince Philip of Edinburgh", "equinox", "Pocahontas"], "metric_results": {"EM": 0.390625, "QA-F1": 0.44218749999999996}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, false, false, true, false, false, true, true, true, false, false, false, true, false, true, true, false, true, false, false, false, false, false, true, false, true, false, false, false, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-5537", "mrqa_triviaqa-validation-3430", "mrqa_triviaqa-validation-818", "mrqa_triviaqa-validation-4295", "mrqa_triviaqa-validation-3419", "mrqa_triviaqa-validation-6684", "mrqa_triviaqa-validation-3517", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7743", "mrqa_triviaqa-validation-3566", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5879", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-6920", "mrqa_triviaqa-validation-6882", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-192", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-1458", "mrqa_triviaqa-validation-3021", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-4328", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-5215", "mrqa_triviaqa-validation-7156", "mrqa_triviaqa-validation-6047", "mrqa_triviaqa-validation-3182", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-7321", "mrqa_triviaqa-validation-2185", "mrqa_triviaqa-validation-4758", "mrqa_hotpotqa-validation-1247", "mrqa_newsqa-validation-2799", "mrqa_newsqa-validation-629", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-14619"], "SR": 0.390625, "CSR": 0.5629340277777778, "EFR": 1.0, "Overall": 0.7814670138888888}, {"timecode": 36, "before_eval_results": {"predictions": ["the Iranian Islamic Revolution", "Kim", "city of acacias", "branson", "Gordon Ramsay", "luton Town", "Robert Kennedy", "sulfur dioxide and nitrogen oxides", "Margot betti", "ringway", "Portuguese", "Travelocity", "Avengers", "raresborough", "comets", "comets", "a ghost", "canola", "joan crawford", "joanna Lumley", "nathan detroit", "Bolivia", "John Donne", "Uranus", "Rio Grande", "comets", "nathan crawford", "30th anniversary", "joan Fontaine", "king james i", "One Foot in the Grave", "Bronx Mowgli", "joan crawford", "George Santayana", "Finger Tab", "windermere", "crackerjack", "Tomas de torquemada", "Daniel barenboim", "Canada", "rum and coke", "city of Seattle", "ghee", "George III", "joan crawford", "Hyperbole", "oldpatrick", "June", "David Graham", "Ceylon", "screwdrivers", "Denver Broncos", "Symphony No. 40 in G minor", "My Summer Story", "1974", "Nightmares", "Amberley Village", "lack of a cause of death", "President Obama", "Elisabeth,", "cixi", "Brigham Young", "pearl", "chalk quarry"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5088541666666667}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, false, false, true, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, false, false, false, false, true, false, true, false, true, false, false, false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true], "QA-F1": [0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9574", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-334", "mrqa_triviaqa-validation-1471", "mrqa_triviaqa-validation-876", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-5591", "mrqa_triviaqa-validation-3877", "mrqa_triviaqa-validation-4188", "mrqa_triviaqa-validation-1540", "mrqa_triviaqa-validation-476", "mrqa_triviaqa-validation-3764", "mrqa_triviaqa-validation-4661", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-2139", "mrqa_triviaqa-validation-6678", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-1270", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-4966", "mrqa_triviaqa-validation-7411", "mrqa_triviaqa-validation-3564", "mrqa_triviaqa-validation-422", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-6654", "mrqa_triviaqa-validation-7079", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-3013", "mrqa_triviaqa-validation-3756", "mrqa_triviaqa-validation-7258", "mrqa_naturalquestions-validation-2297", "mrqa_hotpotqa-validation-5545", "mrqa_newsqa-validation-995", "mrqa_newsqa-validation-2908", "mrqa_searchqa-validation-7120"], "SR": 0.4375, "CSR": 0.5595439189189189, "EFR": 1.0, "Overall": 0.7797719594594594}, {"timecode": 37, "before_eval_results": {"predictions": ["a not-for-profit United States computer networking consortium", "neutral", "aisles", "Alex Ryan", "Sakshi Malik", "Columbia River Gorge", "adrenal medulla", "49 cents", "1876", "geologist James Hutton", "14 \u00b0 41 \u2032 34", "joy of living", "420", "George Strait", "sovereignty over some or all of the current territory of the U.S. state of Texas", "1989", "Shawn", "Kiss", "London, England", "San Francisco", "February 10, 2017", "Kelly Reno", "provides the public with financial information about a nonprofit organization", "By 1770 BC", "Niveditha, Diwakar, Shruti", "two", "John C. Reilly", "mitochondria or chloroplasts", "Anakin and Obi - Wan", "Travis Tritt and Marty Stuart", "1976", "Bee Gees", "Matt Czuchry", "Pradyumna", "1902", "On the west", "Psychomachia", "Seton Hall University", "two", "0.30 in", "Cress", "Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "January 2018", "Sir Donald Bradman", "Tokyo", "1978", "Nicki Minaj", "alcohol or smoking, biological agents, stress, or chemicals to mortality or morbidity", "Gloria", "Canadian Rockies", "The Maginot Line", "Prussia", "dumbo", "purple", "Charles Guiteau", "Gettysburg Address", "iTunes", "$273 million", "India", "Garacad, Somalia", "Desperate Housewives", "Cannonball Run", "Morelos", "Tuesday"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6567247621215812}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, false, false, false, false, true, false, false, false, true, true, false, false, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.23529411764705882, 1.0, 1.0, 0.8, 0.4, 0.0, 0.0, 1.0, 0.787878787878788, 0.0, 0.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.6, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.25, 0.42857142857142855, 1.0, 0.5, 1.0, 0.782608695652174, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-9576", "mrqa_naturalquestions-validation-1181", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-9966", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-2937", "mrqa_naturalquestions-validation-3916", "mrqa_naturalquestions-validation-8470", "mrqa_naturalquestions-validation-6583", "mrqa_naturalquestions-validation-10396", "mrqa_naturalquestions-validation-233", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-2502", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-10034", "mrqa_naturalquestions-validation-5308", "mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6832", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-8025", "mrqa_naturalquestions-validation-4038", "mrqa_naturalquestions-validation-2334", "mrqa_naturalquestions-validation-8514", "mrqa_triviaqa-validation-7642", "mrqa_newsqa-validation-2554", "mrqa_searchqa-validation-2335"], "SR": 0.53125, "CSR": 0.5587993421052632, "EFR": 0.9333333333333333, "Overall": 0.7460663377192982}, {"timecode": 38, "before_eval_results": {"predictions": ["James Gamble & Reuben Townroe", "25 years after the release of their first record", "the United States", "Kim Basinger", "fall of 2015", "the adrenal medulla produces a hormonal cascade that results in the secretion of catecholamines, especially norepinephrine and epinephrine", "Kusha", "in the pancreas by protein biosynthesis as a precursor called chymotrypsinogen that is enzymatically inactive", "Joseph M. Scriven", "Lady Gaga", "Chicago metropolitan area in 1982", "The president", "Domhnall Gleeson", "eusebeia", "horticulture", "Notts County", "a term used in German language surnames either as a nobiliary particle indicating a noble patrilineality or as a simple preposition that approximately means of or from in the case of commoners", "Stephen A. Douglas", "1984", "a loanword of the Visigothic word guma `` man ''", "Pakistan", "21 February", "Tagalog or English", "Bryan Cranston", "the thylakoid membranes", "a mental disorder characterized by at least two weeks of low mood that is present across most situations", "Felix Baumgartner", "Wake County, it lies just north of the state capital, Raleigh", "January 1923", "The Minneapolis Miracle was the final play of the 2017 / 18 Divisional Round game against the New Orleans Saints", "520 - Southern Arizona", "average energy of 251 keV", "between $10,000 and $30,000", "R2E Micral CCMC", "1931", "the University of Oxford, where John was a fellow and later a lecturer at Lincoln College", "Queenstown ( now Cobh ) in Ireland", "Gladys Knight & the Pips", "1959", "The `` Southern Cause ''", "Randy", "that country's surprise attack on Pearl Harbor the prior day", "Joseph Stalin", "into the intermembrane space", "a divergent tectonic plate boundary", "Idaho", "Sara Gilbert", "13", "First Lieutenant Israel Greene", "Gunpei Yokoi", "Lizzy Greene", "yellow, orange, or red wax rind", "Sir John Major", "Roddy Doyle", "Daniil Shafran", "TD Garden", "Venus", "starting a dialogue while maintaining sanctions,", "10 below in Chicago, Illlinois.", "General Motors'", "David McCullough", "Rendezvous with Rama", "CERN", "saudade"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6285554869758374}, "metric_results_detailed": {"EM": [false, false, false, true, false, true, true, false, true, true, false, false, true, false, false, false, false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, false, true, true, false, false, true, true, false, false, false, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, false], "QA-F1": [0.0, 0.09523809523809525, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.7499999999999999, 0.4, 1.0, 0.0, 0.0, 0.0, 0.851063829787234, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8695652173913044, 1.0, 0.23529411764705882, 0.0, 0.0, 0.32, 1.0, 1.0, 0.14814814814814817, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6153846153846153, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2857142857142857, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5569", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-10377", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-8727", "mrqa_naturalquestions-validation-321", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-4929", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-2876", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-4359", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-1344", "mrqa_naturalquestions-validation-3724", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-5939", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-10724", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-5292", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-6088", "mrqa_newsqa-validation-3486", "mrqa_newsqa-validation-1076", "mrqa_searchqa-validation-3219", "mrqa_triviaqa-validation-2762"], "SR": 0.515625, "CSR": 0.5576923076923077, "EFR": 0.967741935483871, "Overall": 0.7627171215880894}, {"timecode": 39, "before_eval_results": {"predictions": ["comb-rows", "A Turtle's Tale : Sammy's Adventures", "Jenny Slate", "the root respiration", "Philippe Petit", "R2E Micral CCMC", "January 2004", "southwest and along the Yangtze", "Toby Keith", "development of electronic computers in the 1950s", "17 - year - old", "punk rock", "Set six months after Kratos killed his wife and child, he has been imprisoned by the three Furies for breaking his blood oath to Ares", "Teri Hatcher", "a piece of foam insulation broke off from the Space Shuttle external tank and struck the left wing of the orbiter", "XXXX", "experimental psychology", "53", "between the Eastern Ghats and the Bay of Bengal", "Julie Adams", "Rachael Harris", "John Porter", "Don Cook", "Dirk Benedict", "Bonnie Aarons", "either late 2018 or early 2019", "interstellar medium", "declared state laws establishing separate public schools for black and white students to be unconstitutional", "McKim Marriott", "John F. Kelly", "Santiago Ram\u00f3n y Cajal", "1886", "either small fission systems or radioactive decay for electricity or heat", "Joseph Stalin", "man", "September, 2016", "is a biocidal effect of metals, especially heavy metals, that occurs even in low concentrations", "1978", "defense against rain rather than sun", "1940", "Sarah Lavrof", "Mark Jackson", "Michael Buffer", "\"one body and one Spirit just as you were called to the one hope that belongs to your call one Lord, one faith, one baptism, one God and Father of all, who is over all and through all and in all", "on location", "the federal government", "1958", "Cody Fern", "the American Civil War", "prophets and beloved religious leaders", "4.5", "Juan Manuel de Ayala", "Joseph Smith,", "funny Folks (1874 - 1894)", "1909", "John Duigan", "179", "Princess Diana", "Mikkel Kessler", "curfew", "Me and Bobby McGee", "shark", "Fast Food Nation", "ABBA"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6041662330724831}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, false, false, false, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, true, false, false, true, false, true, false, true, true, true], "QA-F1": [1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.3076923076923077, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.14545454545454545, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-714", "mrqa_naturalquestions-validation-1682", "mrqa_naturalquestions-validation-9107", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-7310", "mrqa_naturalquestions-validation-5447", "mrqa_naturalquestions-validation-5070", "mrqa_naturalquestions-validation-10199", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-2842", "mrqa_naturalquestions-validation-753", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9410", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-4103", "mrqa_naturalquestions-validation-4366", "mrqa_naturalquestions-validation-1549", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-9827", "mrqa_naturalquestions-validation-7901", "mrqa_naturalquestions-validation-222", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-3353", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-765", "mrqa_hotpotqa-validation-2429", "mrqa_hotpotqa-validation-4917", "mrqa_newsqa-validation-302", "mrqa_searchqa-validation-10341"], "SR": 0.515625, "CSR": 0.556640625, "EFR": 1.0, "Overall": 0.7783203125}, {"timecode": 40, "before_eval_results": {"predictions": ["monophyletic", "\"We tortured (Mohammed al-) Qahtani,\"", "eight Indian army troopers, including one officer, and 17 militants,", "Joan Rivers", "\"You're The One That I Want\"", "glamour and hedonism", "2-0", "15,000", "58 people", "Michael Schumacher", "\"Neural devices are innovating at an extremely rapid rate and hold tremendous promise for the future,\"", "numerous suicide attacks,", "\"The Herald, the state-run newspaper", "two weeks ago", "NATO", "Switzerland", "Monday", "second", "Nazi Party members, shovels in hand, digging up graves of American soldiers held as slaves by Nazi Germany during World War II.", "\"it is impossible to turn back the tide of globalization.\"", "T.I.", "state of southern Mexico", "Michael Holmes.", "a class A traffic violation that can command a fine of $627,", "41,", "Nick Adenhart", "a strict interpretation of the law,", "Derek Mears", "Sylt", "rural Tennessee.", "Tuesday afternoon", "the southern city of Naples", "fake his own death by crashing his private plane into a Florida swamp.", "11", "don't have to visit laundromats because they enjoy the luxury of a free laundry service.", "dual nationality", "to show that a visitor had been to the grave.", "Ali Bongo", "The Transportation Security Administration", "\"We connected meaningfully about the important issues that have emerged over recent days, and I offered him my sincere apologies for any offense to our veterans caused by this report.", "Two pages", "A Brazilian supreme court judge", "Derek Mears", "Operation Pipeline Express", "help rebuild the nation's highways, bridges and other public-use facilities. The government will spend 570 billion pesos ($42 billion) to help Mexicans who are unemployed or underemployed", "East Java", "St. Louis, Missouri.", "NATO fighters", "High Court Judge Justice Davis", "Adam Lambert and Kris Allen", "some of the most gigantic pumpkins in the world, going through a metamorphosis from blobs of orange to art as night falls", "2018 and 2019", "P.V. Sindhu", "Mexico", "Snickers", "monoceros", "capone", "Walt Disney World Resort in Lake Buena Vista, Florida", "uncle Juan Nepomuceno Guerra", "Bergen", "embalming", "capital of Cali,", "a graphical user interface", "the American Kennel Club"], "metric_results": {"EM": 0.46875, "QA-F1": 0.626191937548229}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, false, true, false, true, false, false, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, true, true, true, false, true, false, true, true, false, true, false, true, false, false, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, false, false, false], "QA-F1": [1.0, 1.0, 0.47058823529411764, 1.0, 0.0, 0.375, 1.0, 0.5, 0.6666666666666666, 1.0, 0.9333333333333333, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.3870967741935484, 0.07142857142857142, 0.0, 0.6, 0.0, 0.19999999999999998, 1.0, 1.0, 0.29629629629629634, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9166666666666666, 1.0, 0.0, 1.0, 1.0, 0.10256410256410257, 1.0, 0.4, 1.0, 0.3333333333333333, 0.48484848484848486, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5384615384615384, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-2913", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-4145", "mrqa_newsqa-validation-2439", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-3947", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2422", "mrqa_newsqa-validation-1973", "mrqa_newsqa-validation-1247", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-2031", "mrqa_newsqa-validation-3472", "mrqa_newsqa-validation-3183", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-4151", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-239", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1761", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-8460", "mrqa_triviaqa-validation-2013", "mrqa_triviaqa-validation-7151", "mrqa_hotpotqa-validation-2685", "mrqa_hotpotqa-validation-4241", "mrqa_hotpotqa-validation-877", "mrqa_searchqa-validation-7810", "mrqa_searchqa-validation-1293", "mrqa_naturalquestions-validation-10583"], "SR": 0.46875, "CSR": 0.5544969512195121, "EFR": 1.0, "Overall": 0.7772484756097561}, {"timecode": 41, "before_eval_results": {"predictions": ["Battle of Sainte-Foy", "during the 1890s Klondike Gold Rush, when strong sled dogs were in high demand", "Stephen A. Douglas", "1997", "Directed distance is a positive, zero, or negative scalar quantity", "layered systems of sovereignty", "Megan Park", "the formal currency of the European Union", "Kate Walsh", "September 14, 2008", "Kent Robbins", "Mars Hill, 150 miles ( 240 km ) to the northeast", "1648 - 51 war against Khmelnytsky Uprising in Ukraine", "2002", "they find cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "The pour point of a liquid", "allows the fuel pressure to be controlled via pulse - width modulation of the pump voltage", "A remittance", "Akshay Kumar", "Shirley Mae Jones", "15 February 1998", "5.7 million", "believed to cost between $10,000 and $30,000", "mining", "Cedric Alexander", "The hybridization of these species prevents healthy males from forming, whereas males exist in both parent species ( see Sexual differentiation )", "David Joseph Madden", "In England, births were initially registered with churches, who maintained registers of births", "Kris Kringle", "Javier Fern\u00e1ndez", "provide jobs for young men and to relieve families who had difficulty finding jobs during the Great Depression in the United States", "Phillipa Soo", "collect menstrual flow", "pigs", "General George Washington", "Spanish", "Virgil Tibbs", "an integral membrane protein that builds up a proton gradient across a biological membrane", "along the Bundle of His and through bundle branches", "four", "Jack Nicklaus", "Norman Greenbaum", "Tim Rice", "six", "to solve South Africa's `` ethnic problems '' by creating complementary economic and political units for different ethnic groups", "the Jos Plateau", "Missouri River", "the right to vote", "frontal lobe", "10 June 1940", "Tandi", "Alberich", "ear", "brazil", "The Dressmaker", "$10.5 million", "Tim Whelan", "on September 21.", "Winter Park at Union Station in Denver, Colorado.", "a district advisory council, a neighborhood group that looks at local needs and passes on its assessments to the provincial government.", "President Charles Logan and Graem Bauer,", "King Arthur", "Howie Mandel", "Virgin America"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6356107026143791}, "metric_results_detailed": {"EM": [true, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, false, true, true, true, false, false, false, true, true, false, true, false, false, true, false, true, true, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, true, false, false, false, false, true, true, true], "QA-F1": [1.0, 0.5555555555555556, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.4, 1.0, 0.8, 0.6666666666666666, 0.7000000000000001, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8235294117647058, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2666666666666667, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-5368", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-3725", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-5940", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-9591", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-1224", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-7049", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-1091", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-3267", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-2212", "mrqa_naturalquestions-validation-7807", "mrqa_naturalquestions-validation-578", "mrqa_naturalquestions-validation-6887", "mrqa_newsqa-validation-3002", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-939", "mrqa_searchqa-validation-16518"], "SR": 0.53125, "CSR": 0.5539434523809523, "EFR": 0.9, "Overall": 0.7269717261904762}, {"timecode": 42, "before_eval_results": {"predictions": ["Ancient Egypt", "vaporization of water", "in Middlesex County, Province of Massachusetts Bay", "chlorine and bromine from manmade organohalogens", "Michael Buffer", "Thomas Edison", "Article One of the United States Constitution", "Zeus", "During Hanna's recovery masquerade celebration", "Abid Ali Neemuchwala", "between the Mediterranean Sea to the north and the Red Sea in the south", "to bring, and \u03bd\u03af\u03ba\u03b7, n\u00edk\u00ea, `` victory '', i.e. `` she who brings victory ''", "Field Marshal Paul von Hindenburg", "Ceramic art", "the Soviet Union", "Covington, Kentucky", "New Mexico", "to condense the steam coming out of the cylinders or turbines", "December 15, 2017", "about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15", "L.K. Advani", "differential erosion", "Glenn Close", "the middle of the Sermon on the Mount", "about 375 miles ( 600 km ) south of Newfoundland", "Andy Serkis", "West Ham United ( 1980 )", "2018", "Puerto Rico Energy Commission, another government agency whose board of directors is also appointed by the governor", "by two easily observed features", "Norman Greenbaum", "the notion that an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "electron shells", "a pair of compasses", "Charlotte Thornton", "the Northeast Monsoon or Retreating Monsoon", "a fifteenth full - length studio album", "President Lyndon Johnson", "approximately 1945", "Ariana Clarice Richards", "Jonathan Breck", "Husrev Pasha", "Daya Jethalal Gada", "2,140 kilometres ( 1,330 mi )", "by producing an egg through parthenogenesis", "1926", "in East Asia", "starting in 1560s", "Frankie Muniz", "Lou Rawls", "between 1765 and 1783", "Vanaheim", "Illinois", "Alice in Wonderland", "Los Angeles", "Elijah Jordan Wood", "96,867", "recall notices", "The show went on without the self-proclaimed \"King of the South,\" whose car and home in the Atlanta suburb of College Park were searched after his arrest.", "prostate cancer,", "a dragon", "Lord Fauntleroy", "a key ring or a decorative key fob", "yellow"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6203506480292195}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, false, true, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, false, true, false, false, true, true, true, false, false, false, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.5384615384615384, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.7272727272727272, 1.0, 0.9, 0.5333333333333333, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.9387755102040816, 0.14814814814814814, 0.6666666666666666, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.19047619047619047, 0.08333333333333333, 1.0, 0.7878787878787877, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.0, 0.0, 0.33333333333333337, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-9222", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-10512", "mrqa_naturalquestions-validation-1622", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-5010", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-1969", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-2901", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-4983", "mrqa_naturalquestions-validation-7293", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-10354", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-3001", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-1965", "mrqa_triviaqa-validation-2833", "mrqa_hotpotqa-validation-1759", "mrqa_hotpotqa-validation-1134", "mrqa_newsqa-validation-2360", "mrqa_newsqa-validation-1248", "mrqa_searchqa-validation-1526", "mrqa_searchqa-validation-5636", "mrqa_searchqa-validation-11152"], "SR": 0.46875, "CSR": 0.5519622093023255, "EFR": 0.8823529411764706, "Overall": 0.717157575239398}, {"timecode": 43, "before_eval_results": {"predictions": ["May 21, 2013", "2007", "a'pick yourself up and dust yourself off and keep going ', female - empowerment song", "relieve families who had difficulty finding jobs during the Great Depression in the United States", "Lynne", "2013", "as the arms of the king of Ireland", "Miami Heat", "1982", "After World War I", "in the mid - to late 1920s", "Napoleon Bonaparte", "Juan Francisco Ochoa", "Augustus Waters", "Pierre Mallet", "Virgil Ogletree, a numbers operator who was wanted for questioning in the bombing of rival numbers racketeer and future boxing promoter Don King's home three days earlier,", "Edward Kenway ( Matt Ryan ), a Welsh privateer - turned - pirate and eventual member of the Assassin Order", "Haliaeetus", "a thick bunch of rootlets", "Alex Ryan", "a habitat", "2018", "Advanced Systems Format ( ASF )", "100", "Toledo", "Transvaginal ultrasonography", "During the last Ice Age", "Haikou on the Hainan Island", "Robert Irsay", "in Paradise, Nevada", "Alicia Vikander as Lara Croft", "in late January or early February", "Ashoka", "the compartments known as Relieving Chambers", "Robert Andrews Millikan,", "Puerto Rico Electric Power Authority", "Devastator", "into the Christian biblical canon", "Connecticut, Maine, Massachusetts, New Hampshire, Rhode Island, and Vermont", "AX - 30", "honey bees", "Mary Chapin Carpenter", "the Louvre Museum in Paris", "over two days in July 2011", "2018", "Florida", "the life of the Bennetts, a dysfunctional family consisting of two brothers, their rancher father, and his divorced wife and local bar owner", "in the southwestern part of the island", "in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "wintertime", "Pangaea", "Newcastle Brown Ale", "Western Australia", "Vaclav Havel", "Mary Bonauto, Susan Murray, and Beth Robinson", "Chelsea", "North America", "\"It was perfect work, ready to go for the stimulus package,\"", "\"peregruzka\"", "$60 billion on America's infrastructure.", "Dean Acheson", "Bob Kerrey", "Jane Goodall", "Forrest Gump"], "metric_results": {"EM": 0.453125, "QA-F1": 0.6280579338296093}, "metric_results_detailed": {"EM": [false, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, false, true, false, true, false, true, false, true, false, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true], "QA-F1": [0.0, 0.5, 0.7741935483870968, 0.962962962962963, 1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.3636363636363636, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 0.4705882352941177, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3636363636363636, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.9189189189189189, 0.0, 0.975609756097561, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.7272727272727273, 1.0, 1.0, 0.09523809523809525, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-151", "mrqa_naturalquestions-validation-5665", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-9856", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-7862", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5052", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-4427", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-8441", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-8662", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-4351", "mrqa_naturalquestions-validation-9426", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4675", "mrqa_naturalquestions-validation-7067", "mrqa_naturalquestions-validation-8696", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-5474", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-8027", "mrqa_triviaqa-validation-2697", "mrqa_hotpotqa-validation-1693", "mrqa_newsqa-validation-2449", "mrqa_newsqa-validation-2352", "mrqa_newsqa-validation-1977"], "SR": 0.453125, "CSR": 0.5497159090909092, "EFR": 1.0, "Overall": 0.7748579545454546}, {"timecode": 44, "before_eval_results": {"predictions": ["\u00a330m", "lightweight aluminum foil", "Laurel, Mississippi", "mountain-climbing", "Indianola", "Life Insurance Corporation of India, the largest life insurance company of India", "the British military", "1964", "the Goddess of Pop", "Appalachians", "James Harrison", "Toronto", "Tomorrowland", "fennec fox", "United States Army", "stop motion animation", "Jean Acker", "4,530", "Leucippus", "Caesars Entertainment Corporation", "Mary Ellen Mark", "Reinhard Heydrich", "Karl Kraus", "Brock Hart", "Maria Brink", "Manitowoc County, Wisconsin", "the Northrop P-61 Black Widow", "Adelaide", "World Famous Gold & Silver Pawn Shop", "Sri Lanka Freedom Party", "Bishop's Stortford", "ambassador to Ghana", "Emmy, Grammy, Oscar and Tony awards", "1991", "Leatherheads", "September 25, 2017", "John Delaney", "Tampa", "the Beatles", "Richard Street", "Zaire", "the Fundamentalist Church of Jesus Christ of Latter-Day Saints", "Pakistan", "Shohola Falls", "French cuisine", "South America", "2006", "four months in jail", "The Major of St. Lo", "Mary Elizabeth Hartman", "over 9,000 employees", "Tom Seaton", "potential of hydrogen", "Alamodome in San Antonio, Texas", "Carrie", "a tab", "Kent", "almost 9 million", "Kenya", "2008", "terrorism", "Moses", "Chapter 5", "Wilson Pickett"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6677483974358974}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, true, false, true, true, false, true, true, true, false, false, false, false, true, true, true, true, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.8, 1.0, 0.0, 0.0, 0.3076923076923077, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.2, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5593", "mrqa_hotpotqa-validation-5862", "mrqa_hotpotqa-validation-1816", "mrqa_hotpotqa-validation-3755", "mrqa_hotpotqa-validation-5461", "mrqa_hotpotqa-validation-582", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-6", "mrqa_hotpotqa-validation-3470", "mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-4630", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-2679", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-4327", "mrqa_hotpotqa-validation-3689", "mrqa_hotpotqa-validation-5620", "mrqa_naturalquestions-validation-9081", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-4197", "mrqa_searchqa-validation-516", "mrqa_searchqa-validation-13590", "mrqa_naturalquestions-validation-9677"], "SR": 0.609375, "CSR": 0.5510416666666667, "EFR": 1.0, "Overall": 0.7755208333333333}, {"timecode": 45, "before_eval_results": {"predictions": ["calcitriol", "Mazda", "1858", "Australian", "September 1903", "the power to regulate interstate commerce", "Naomi Wallace", "McLaren-Honda", "Tufts College", "People's Republic of China", "Azeroth", "Squam Lake", "The Livingston family of New York", "Tayeb Salih", "King James II", "God Save the Queen", "526", "Scotland", "\"rock and roll\"", "GmbH", "Mick Jackson", "Lalit", "her performances of \"khyal\", \"thumri\", and \"bhajans\"", "Tampa Bay Lightning", "Steven Selling", "Sully", "Manhattan Project", "the Asia-Pacific War", "Romantic", "Hugh Dowding", "AMC Entertainment Holdings, Inc.", "New York Islanders", "fennec", "1978", "John Surtees", "French", "Pacific Place", "The team's official nickname is the Matildas", "\"Bad Blood\"", "\"SexyBack\"", "about 5320 km", "Giuseppe Verdi", "\"Super Hit\"", "Sacramento Kings", "Walldorf", "Fife", "Fyvie Castle", "Faisal Qureshi", "the British Army", "\"rule of the majority\"", "Boletus edulis", "Robert Remak", "JackScanlon", "Steve Hale ( who was first introduced in the season five episode `` Sisters in Crime '' ), who later becomes a real fixture in her life ( and a regular character beginning in season six )", "Judy Garland", "Switzerland", "Model T", "NATO's International Security Assistance Force", "2,000", "Cyprus", "Maroon 5", "Saudi Arabia", "Geraldine A. Ferraro", "two"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6498511904761906}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, false, true, false, false, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, true, false, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.33333333333333337, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.28571428571428575, 0.0, 0.7499999999999999, 0.25, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.6666666666666666, 1.0, 0.3333333333333333, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-4054", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-1718", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-4880", "mrqa_hotpotqa-validation-3627", "mrqa_hotpotqa-validation-4906", "mrqa_hotpotqa-validation-3467", "mrqa_hotpotqa-validation-216", "mrqa_hotpotqa-validation-5523", "mrqa_hotpotqa-validation-803", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2185", "mrqa_hotpotqa-validation-1909", "mrqa_hotpotqa-validation-4290", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-2129", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-5273", "mrqa_hotpotqa-validation-506", "mrqa_hotpotqa-validation-1827", "mrqa_hotpotqa-validation-3084", "mrqa_hotpotqa-validation-5589", "mrqa_naturalquestions-validation-4995", "mrqa_naturalquestions-validation-5048", "mrqa_newsqa-validation-321", "mrqa_searchqa-validation-8327"], "SR": 0.546875, "CSR": 0.5509510869565217, "EFR": 1.0, "Overall": 0.7754755434782609}, {"timecode": 46, "before_eval_results": {"predictions": ["less than a year", "tepuis", "The King and I", "Republican National Committee's website address is GOP.com", "1996", "5", "Greenland shark", "The Word", "President Abraham Lincoln's", "St Jude Thaddeus", "Van Diemenslandt", "death penalty statutes", "xerophyte", "Jackie Robinson", "Brooklyn", "Dian Fossey", "MI5", "Harrow", "creme anglaise", "onions", "chicken", "curling", "Victoria Coren Mitchell", "Gettysburg", "Chile\u2019s", "Majorca (Mallorca)", "Great Expectations", "Laputa", "Lee Harvey Oswald", "Clara Wieck Schumann", "Mercury", "Venus", "President Barack Obama", "Canada's Liberal Party", "Bologna Song Lyrics", "Cuba", "David Bowie", "Stephen King", "Hinduism", "A caryatid", "feet", "Great Britain returned Manila and Havana to Spain", "Mary Poppins", "Glyn Jones", "Port Moresby Harbour", "Connecticut", "Quentin Blake", "whooping cough", "The Daily Herald", "numerous", "\"permissible.\"", "2016", "the courts", "2017", "Chief of Protocol", "Diamond White", "1944", "Daniel Nestor, from Canada,", "Jeddah, Saudi Arabia,", "death", "Beatrix Potter", "George Stephanopoulos", "Reader's Digest", "Divide the living child in two"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6205729166666667}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, false, false, true, true, true, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.8, 0.8, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-4745", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-347", "mrqa_triviaqa-validation-3458", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-762", "mrqa_triviaqa-validation-1742", "mrqa_triviaqa-validation-5056", "mrqa_triviaqa-validation-5642", "mrqa_triviaqa-validation-6276", "mrqa_triviaqa-validation-5346", "mrqa_triviaqa-validation-1987", "mrqa_triviaqa-validation-3260", "mrqa_triviaqa-validation-3963", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-5266", "mrqa_triviaqa-validation-4157", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-3479", "mrqa_naturalquestions-validation-7812", "mrqa_naturalquestions-validation-6076", "mrqa_naturalquestions-validation-9246", "mrqa_newsqa-validation-1157", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2520", "mrqa_searchqa-validation-3262", "mrqa_searchqa-validation-6488"], "SR": 0.515625, "CSR": 0.5501994680851063, "EFR": 1.0, "Overall": 0.7750997340425532}, {"timecode": 47, "before_eval_results": {"predictions": ["a horse", "allergic reaction", "bob anderson", "the last battle on Scottish soil took place on a nearby moor at Culloden", "Runic", "portugal", "tennis", "alex kirchhoff", "rotherham United", "heat transfer", "misery", "Styal", "stately", "blind beggar", "b Banksy", "floroy Burrell", "parlophone", "Wild Atlantic Way", "john Denver", "oscar", "noddy", "lackawanna six", "canada", "a Tree Swing", "a muezzin", "a window", "a ship", "madame bovary", "Apollo 8:58PM", "Dry Ice", "Nikola Tesla", "alex h Henderson", "evita", "a sperm whale", "a shrewd business man", "east fife", "hong kong", "social environment", "a machine that cuts the bread finely while efficiently and securely wrapping", "Dilbert", "a man whose impulses are at war with one another,", "nunc dimittis", "French", "a dragon", "h Burgundy", "cribbage", "hong kong", "Johannesburg", "France", "muffin man", "hong kong", "Prince James, Duke of York and of Albany", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "Mike Nesmith", "Pansexuality", "Tony Ducks", "1754", "drugs", "Galveston, Texas,", "airlines around the world shut down every year.", "Robert Frost", "King Henry VIII", "oscar", "Mitsubishi Lancer"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5227907509157509}, "metric_results_detailed": {"EM": [false, true, false, false, true, false, false, false, true, false, true, true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, false, false, true, false, true, true, false, true, false, true, false, true, false, true, true, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, false, true, false, false, false], "QA-F1": [0.0, 1.0, 0.0, 0.15384615384615385, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.16666666666666669, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.5714285714285715]}}, "before_error_ids": ["mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-6521", "mrqa_triviaqa-validation-3328", "mrqa_triviaqa-validation-922", "mrqa_triviaqa-validation-1189", "mrqa_triviaqa-validation-2878", "mrqa_triviaqa-validation-3407", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-739", "mrqa_triviaqa-validation-3833", "mrqa_triviaqa-validation-6048", "mrqa_triviaqa-validation-5792", "mrqa_triviaqa-validation-7001", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-6884", "mrqa_triviaqa-validation-5895", "mrqa_triviaqa-validation-5433", "mrqa_triviaqa-validation-2627", "mrqa_triviaqa-validation-1258", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-4691", "mrqa_triviaqa-validation-3204", "mrqa_triviaqa-validation-6813", "mrqa_triviaqa-validation-4781", "mrqa_triviaqa-validation-582", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-5014", "mrqa_hotpotqa-validation-3408", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-1947", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-12618", "mrqa_naturalquestions-validation-9564"], "SR": 0.484375, "CSR": 0.548828125, "EFR": 0.9696969696969697, "Overall": 0.7592625473484849}, {"timecode": 48, "before_eval_results": {"predictions": ["jimmy farfrae", "Sesame Street", "veg", "cabbage", "south west", "mister magoo", "fleece", "ash", "marsupials", "new Zealand", "children", "60", "eagle", "1983", "frog", "Mongols", "1875", "tax collector", "pennies", "marmara", "wars of the Roses", "bagram", "jimmy farfrae", "Chrysler", "ushanka", "mrigg", "classical Theology", "United States", "Brazil", "spain", "biathlon", "nee farfrae", "chang apana", "Vienna", "white", "jaws", "jimmy farfrae", "rabbit", "Scottish flag", "farfrae", "Orson Welles", "Sanskrit", "menorah", "Dutch", "texas", "Super Bowl Sunday", "quant pole", "jimmy stout", "Carole King", "Rhododendron", "Ireland", "Chuck Noland", "the Colony of Virginia", "in Graub\u00fcnden, in the eastern Alps region of Switzerland", "Clive Staples Lewis", "Tsavo East National Park", "2010", "in a ceremony at the ancient Greek site of Olympia", "10 below", "100 to 150", "turtles", "the American Kennel Club", "Omaha", "poultry"], "metric_results": {"EM": 0.40625, "QA-F1": 0.4709703947368421}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, false, true, false, false, false, false, false, false, true, true, false, false, true, true, false, true, false, false, false, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true, true, true, true, false, false, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.4, 0.0, 0.0, 1.0, 1.0, 0.5, 0.8421052631578948, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3951", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-1990", "mrqa_triviaqa-validation-7027", "mrqa_triviaqa-validation-1515", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-3262", "mrqa_triviaqa-validation-6865", "mrqa_triviaqa-validation-7507", "mrqa_triviaqa-validation-2687", "mrqa_triviaqa-validation-3203", "mrqa_triviaqa-validation-2494", "mrqa_triviaqa-validation-2957", "mrqa_triviaqa-validation-704", "mrqa_triviaqa-validation-4363", "mrqa_triviaqa-validation-5072", "mrqa_triviaqa-validation-3019", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-3053", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-2263", "mrqa_triviaqa-validation-1687", "mrqa_triviaqa-validation-5229", "mrqa_triviaqa-validation-2168", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-726", "mrqa_triviaqa-validation-6306", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-6564", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1073", "mrqa_newsqa-validation-1255", "mrqa_searchqa-validation-16460", "mrqa_searchqa-validation-11366", "mrqa_searchqa-validation-4136"], "SR": 0.40625, "CSR": 0.5459183673469388, "EFR": 0.9736842105263158, "Overall": 0.7598012889366272}, {"timecode": 49, "before_eval_results": {"predictions": ["jennifer farfrae", "Iran", "alcohol", "frenchman", "dennifer", "Daniel Boone", "Thames Street", "Theodore Roosevelt", "satyrs", "jellyfish", "lite bohemian life in Paris", "IBM", "wishbone", "Garrick Club", "Lackawanna 6", "master Humphrey\u2019s Clock", "Susan Bullock", "American Civil War", "\"black\"", "Cybill Shepherd", "jimmy Robertson", "Florence", "st Basil", "jennifer goon", "severn", "doris pilkington Garimara", "South Africa", "bunch grasses", "Nicaraguan", "tartan", "duke of Suffolk", "Chemnitz", "jennifer farfrae", "a big mackinaw", "ap\u00e9ritif", "jennifer anson", "be\u2022lize", "folklorists", "alopecia", "sprint", "Charlie Drake", "Robin Hood", "Chris Martin", "bobble", "george gently", "rugby", "honda", "a Scottish pop band", "11", "tobacco", "cows", "free floating", "Tom Selleck", "New Orleans", "a comic book superhero", "Texas Tech University", "loughborough Technical Institute", "Herman Cain", "the government of Said Barre", "that the National Guard reallocated reconnaissance helicopters and robotic surveillance craft to the \"border states\" to prevent illegal immigration.", "George F. Babbitt", "Oklahoma", "Elaine Stritch", "four"], "metric_results": {"EM": 0.34375, "QA-F1": 0.4357314560439561}, "metric_results_detailed": {"EM": [false, true, false, false, false, false, false, true, true, false, false, false, true, true, false, false, false, true, true, false, false, true, false, false, true, false, false, false, true, false, false, true, false, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, true, false, false, false, true, false, true], "QA-F1": [0.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.4, 1.0, 0.0, 0.6153846153846153, 0.8, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-2041", "mrqa_triviaqa-validation-3510", "mrqa_triviaqa-validation-2933", "mrqa_triviaqa-validation-6231", "mrqa_triviaqa-validation-7701", "mrqa_triviaqa-validation-7063", "mrqa_triviaqa-validation-1188", "mrqa_triviaqa-validation-640", "mrqa_triviaqa-validation-3165", "mrqa_triviaqa-validation-3429", "mrqa_triviaqa-validation-6698", "mrqa_triviaqa-validation-6699", "mrqa_triviaqa-validation-51", "mrqa_triviaqa-validation-1836", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-1934", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-1066", "mrqa_triviaqa-validation-3543", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-3092", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-1300", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-6968", "mrqa_triviaqa-validation-1960", "mrqa_triviaqa-validation-3296", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-523", "mrqa_triviaqa-validation-816", "mrqa_triviaqa-validation-5486", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-3984", "mrqa_triviaqa-validation-7243", "mrqa_naturalquestions-validation-10279", "mrqa_naturalquestions-validation-8560", "mrqa_hotpotqa-validation-2612", "mrqa_hotpotqa-validation-2146", "mrqa_newsqa-validation-1054", "mrqa_newsqa-validation-1442", "mrqa_searchqa-validation-13441", "mrqa_searchqa-validation-3615"], "SR": 0.34375, "CSR": 0.541875, "EFR": 1.0, "Overall": 0.7709375}, {"timecode": 50, "UKR": 0.751953125, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-0", "mrqa_hotpotqa-validation-1076", "mrqa_hotpotqa-validation-1123", "mrqa_hotpotqa-validation-117", "mrqa_hotpotqa-validation-1195", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-157", "mrqa_hotpotqa-validation-1598", "mrqa_hotpotqa-validation-1715", "mrqa_hotpotqa-validation-177", "mrqa_hotpotqa-validation-1889", "mrqa_hotpotqa-validation-1943", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-2082", "mrqa_hotpotqa-validation-2237", "mrqa_hotpotqa-validation-2373", "mrqa_hotpotqa-validation-2687", "mrqa_hotpotqa-validation-2772", "mrqa_hotpotqa-validation-2882", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3225", "mrqa_hotpotqa-validation-351", "mrqa_hotpotqa-validation-3704", "mrqa_hotpotqa-validation-3705", "mrqa_hotpotqa-validation-3810", "mrqa_hotpotqa-validation-3839", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-3906", "mrqa_hotpotqa-validation-3949", "mrqa_hotpotqa-validation-4001", "mrqa_hotpotqa-validation-4005", "mrqa_hotpotqa-validation-410", "mrqa_hotpotqa-validation-4191", "mrqa_hotpotqa-validation-4401", "mrqa_hotpotqa-validation-4436", "mrqa_hotpotqa-validation-4570", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4760", "mrqa_hotpotqa-validation-4834", "mrqa_hotpotqa-validation-4876", "mrqa_hotpotqa-validation-4917", "mrqa_hotpotqa-validation-501", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5087", "mrqa_hotpotqa-validation-5135", "mrqa_hotpotqa-validation-5240", "mrqa_hotpotqa-validation-5600", "mrqa_hotpotqa-validation-5643", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-5897", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-681", "mrqa_hotpotqa-validation-841", "mrqa_hotpotqa-validation-877", "mrqa_hotpotqa-validation-947", "mrqa_hotpotqa-validation-993", "mrqa_naturalquestions-validation-10054", "mrqa_naturalquestions-validation-10232", "mrqa_naturalquestions-validation-10433", "mrqa_naturalquestions-validation-10452", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-10659", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1300", "mrqa_naturalquestions-validation-1494", "mrqa_naturalquestions-validation-1587", "mrqa_naturalquestions-validation-1736", "mrqa_naturalquestions-validation-1783", "mrqa_naturalquestions-validation-1785", "mrqa_naturalquestions-validation-2068", "mrqa_naturalquestions-validation-2159", "mrqa_naturalquestions-validation-220", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-2482", "mrqa_naturalquestions-validation-2580", "mrqa_naturalquestions-validation-2692", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-2803", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3052", "mrqa_naturalquestions-validation-3162", "mrqa_naturalquestions-validation-327", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3770", "mrqa_naturalquestions-validation-3788", "mrqa_naturalquestions-validation-3804", "mrqa_naturalquestions-validation-3893", "mrqa_naturalquestions-validation-39", "mrqa_naturalquestions-validation-395", "mrqa_naturalquestions-validation-3985", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4365", "mrqa_naturalquestions-validation-4471", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-5105", "mrqa_naturalquestions-validation-5467", "mrqa_naturalquestions-validation-5550", "mrqa_naturalquestions-validation-5553", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-5724", "mrqa_naturalquestions-validation-5802", "mrqa_naturalquestions-validation-594", "mrqa_naturalquestions-validation-5960", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-6204", "mrqa_naturalquestions-validation-6216", "mrqa_naturalquestions-validation-622", "mrqa_naturalquestions-validation-6248", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-6523", "mrqa_naturalquestions-validation-654", "mrqa_naturalquestions-validation-6620", "mrqa_naturalquestions-validation-6621", "mrqa_naturalquestions-validation-6692", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6764", "mrqa_naturalquestions-validation-6887", "mrqa_naturalquestions-validation-6936", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-7382", "mrqa_naturalquestions-validation-7408", "mrqa_naturalquestions-validation-7425", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-7553", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-8346", "mrqa_naturalquestions-validation-8446", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-8503", "mrqa_naturalquestions-validation-854", "mrqa_naturalquestions-validation-8558", "mrqa_naturalquestions-validation-8607", "mrqa_naturalquestions-validation-8659", "mrqa_naturalquestions-validation-8814", "mrqa_naturalquestions-validation-8910", "mrqa_naturalquestions-validation-8948", "mrqa_naturalquestions-validation-8990", "mrqa_naturalquestions-validation-9130", "mrqa_naturalquestions-validation-9188", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-928", "mrqa_naturalquestions-validation-9341", "mrqa_naturalquestions-validation-9390", "mrqa_naturalquestions-validation-9422", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-9516", "mrqa_naturalquestions-validation-9574", "mrqa_naturalquestions-validation-9752", "mrqa_newsqa-validation-1047", "mrqa_newsqa-validation-1096", "mrqa_newsqa-validation-1130", "mrqa_newsqa-validation-115", "mrqa_newsqa-validation-1159", "mrqa_newsqa-validation-1170", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1654", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1720", "mrqa_newsqa-validation-1823", "mrqa_newsqa-validation-184", "mrqa_newsqa-validation-1947", "mrqa_newsqa-validation-2101", "mrqa_newsqa-validation-224", "mrqa_newsqa-validation-2240", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2331", "mrqa_newsqa-validation-2397", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2559", "mrqa_newsqa-validation-2638", "mrqa_newsqa-validation-2639", "mrqa_newsqa-validation-2676", "mrqa_newsqa-validation-2689", "mrqa_newsqa-validation-27", "mrqa_newsqa-validation-2710", "mrqa_newsqa-validation-2724", "mrqa_newsqa-validation-2725", "mrqa_newsqa-validation-2772", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2793", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-2884", "mrqa_newsqa-validation-2886", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-302", "mrqa_newsqa-validation-3078", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3138", "mrqa_newsqa-validation-3143", "mrqa_newsqa-validation-3203", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3261", "mrqa_newsqa-validation-3262", "mrqa_newsqa-validation-3376", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-3487", "mrqa_newsqa-validation-3504", "mrqa_newsqa-validation-3513", "mrqa_newsqa-validation-3523", "mrqa_newsqa-validation-3543", "mrqa_newsqa-validation-3606", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3658", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3840", "mrqa_newsqa-validation-3868", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-3893", "mrqa_newsqa-validation-390", "mrqa_newsqa-validation-3915", "mrqa_newsqa-validation-3960", "mrqa_newsqa-validation-3974", "mrqa_newsqa-validation-4058", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-4074", "mrqa_newsqa-validation-4096", "mrqa_newsqa-validation-4132", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4184", "mrqa_newsqa-validation-458", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-525", "mrqa_newsqa-validation-576", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-629", "mrqa_newsqa-validation-655", "mrqa_newsqa-validation-696", "mrqa_newsqa-validation-76", "mrqa_newsqa-validation-767", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-80", "mrqa_newsqa-validation-814", "mrqa_newsqa-validation-820", "mrqa_newsqa-validation-895", "mrqa_newsqa-validation-927", "mrqa_searchqa-validation-10384", "mrqa_searchqa-validation-10782", "mrqa_searchqa-validation-11152", "mrqa_searchqa-validation-11820", "mrqa_searchqa-validation-12398", "mrqa_searchqa-validation-12828", "mrqa_searchqa-validation-13033", "mrqa_searchqa-validation-13484", "mrqa_searchqa-validation-13941", "mrqa_searchqa-validation-13982", "mrqa_searchqa-validation-14619", "mrqa_searchqa-validation-14727", "mrqa_searchqa-validation-15040", "mrqa_searchqa-validation-15484", "mrqa_searchqa-validation-15660", "mrqa_searchqa-validation-16041", "mrqa_searchqa-validation-16840", "mrqa_searchqa-validation-16966", "mrqa_searchqa-validation-2009", "mrqa_searchqa-validation-2043", "mrqa_searchqa-validation-2051", "mrqa_searchqa-validation-2973", "mrqa_searchqa-validation-3113", "mrqa_searchqa-validation-3232", "mrqa_searchqa-validation-3818", "mrqa_searchqa-validation-4136", "mrqa_searchqa-validation-5881", "mrqa_searchqa-validation-620", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-6482", "mrqa_searchqa-validation-6975", "mrqa_searchqa-validation-7120", "mrqa_searchqa-validation-7443", "mrqa_searchqa-validation-8165", "mrqa_searchqa-validation-8323", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-950", "mrqa_searchqa-validation-9648", "mrqa_searchqa-validation-9840", "mrqa_searchqa-validation-9931", "mrqa_squad-validation-10062", "mrqa_squad-validation-1016", "mrqa_squad-validation-1189", "mrqa_squad-validation-1201", "mrqa_squad-validation-1291", "mrqa_squad-validation-1412", "mrqa_squad-validation-1454", "mrqa_squad-validation-163", "mrqa_squad-validation-1776", "mrqa_squad-validation-178", "mrqa_squad-validation-1893", "mrqa_squad-validation-2052", "mrqa_squad-validation-2087", "mrqa_squad-validation-2137", "mrqa_squad-validation-2144", "mrqa_squad-validation-2168", "mrqa_squad-validation-2429", "mrqa_squad-validation-2622", "mrqa_squad-validation-2780", "mrqa_squad-validation-2875", "mrqa_squad-validation-2903", "mrqa_squad-validation-2969", "mrqa_squad-validation-2972", "mrqa_squad-validation-3037", "mrqa_squad-validation-3043", "mrqa_squad-validation-3069", "mrqa_squad-validation-3162", "mrqa_squad-validation-3237", "mrqa_squad-validation-3390", "mrqa_squad-validation-3473", "mrqa_squad-validation-3687", "mrqa_squad-validation-3957", "mrqa_squad-validation-4044", "mrqa_squad-validation-4158", "mrqa_squad-validation-4178", "mrqa_squad-validation-4328", "mrqa_squad-validation-4437", "mrqa_squad-validation-446", "mrqa_squad-validation-4580", "mrqa_squad-validation-4590", "mrqa_squad-validation-4613", "mrqa_squad-validation-4708", "mrqa_squad-validation-4764", "mrqa_squad-validation-4773", "mrqa_squad-validation-479", "mrqa_squad-validation-4836", "mrqa_squad-validation-4890", "mrqa_squad-validation-4908", "mrqa_squad-validation-4927", "mrqa_squad-validation-5034", "mrqa_squad-validation-5067", "mrqa_squad-validation-5082", "mrqa_squad-validation-516", "mrqa_squad-validation-5437", "mrqa_squad-validation-5481", "mrqa_squad-validation-5498", "mrqa_squad-validation-55", "mrqa_squad-validation-5611", "mrqa_squad-validation-5725", "mrqa_squad-validation-5905", "mrqa_squad-validation-597", "mrqa_squad-validation-639", "mrqa_squad-validation-6403", "mrqa_squad-validation-6530", "mrqa_squad-validation-6655", "mrqa_squad-validation-6933", "mrqa_squad-validation-7141", "mrqa_squad-validation-7230", "mrqa_squad-validation-7230", "mrqa_squad-validation-7264", "mrqa_squad-validation-7284", "mrqa_squad-validation-7451", "mrqa_squad-validation-749", "mrqa_squad-validation-7872", "mrqa_squad-validation-7897", "mrqa_squad-validation-7949", "mrqa_squad-validation-8068", "mrqa_squad-validation-811", "mrqa_squad-validation-8136", "mrqa_squad-validation-8159", "mrqa_squad-validation-8182", "mrqa_squad-validation-8316", "mrqa_squad-validation-8435", "mrqa_squad-validation-8440", "mrqa_squad-validation-8447", "mrqa_squad-validation-8471", "mrqa_squad-validation-9162", "mrqa_squad-validation-9307", "mrqa_squad-validation-9653", "mrqa_squad-validation-9655", "mrqa_squad-validation-9703", "mrqa_squad-validation-9740", "mrqa_squad-validation-998", "mrqa_triviaqa-validation-1186", "mrqa_triviaqa-validation-1276", "mrqa_triviaqa-validation-1321", "mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-1442", "mrqa_triviaqa-validation-1463", "mrqa_triviaqa-validation-1494", "mrqa_triviaqa-validation-15", "mrqa_triviaqa-validation-1624", "mrqa_triviaqa-validation-1677", "mrqa_triviaqa-validation-1700", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-180", "mrqa_triviaqa-validation-1808", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1856", "mrqa_triviaqa-validation-1906", "mrqa_triviaqa-validation-2025", "mrqa_triviaqa-validation-2158", "mrqa_triviaqa-validation-2274", "mrqa_triviaqa-validation-2364", "mrqa_triviaqa-validation-2473", "mrqa_triviaqa-validation-2484", "mrqa_triviaqa-validation-253", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2622", "mrqa_triviaqa-validation-2812", "mrqa_triviaqa-validation-2877", "mrqa_triviaqa-validation-2913", "mrqa_triviaqa-validation-2977", "mrqa_triviaqa-validation-3105", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-324", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3324", "mrqa_triviaqa-validation-3354", "mrqa_triviaqa-validation-3420", "mrqa_triviaqa-validation-3479", "mrqa_triviaqa-validation-3500", "mrqa_triviaqa-validation-3592", "mrqa_triviaqa-validation-3597", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-3622", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-3859", "mrqa_triviaqa-validation-3889", "mrqa_triviaqa-validation-3930", "mrqa_triviaqa-validation-4007", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-4080", "mrqa_triviaqa-validation-4100", "mrqa_triviaqa-validation-411", "mrqa_triviaqa-validation-430", "mrqa_triviaqa-validation-450", "mrqa_triviaqa-validation-4576", "mrqa_triviaqa-validation-4606", "mrqa_triviaqa-validation-4608", "mrqa_triviaqa-validation-464", "mrqa_triviaqa-validation-4856", "mrqa_triviaqa-validation-5028", "mrqa_triviaqa-validation-5139", "mrqa_triviaqa-validation-516", "mrqa_triviaqa-validation-5275", "mrqa_triviaqa-validation-5277", "mrqa_triviaqa-validation-5299", "mrqa_triviaqa-validation-5326", "mrqa_triviaqa-validation-5343", "mrqa_triviaqa-validation-5547", "mrqa_triviaqa-validation-5556", "mrqa_triviaqa-validation-5588", "mrqa_triviaqa-validation-5645", "mrqa_triviaqa-validation-5656", "mrqa_triviaqa-validation-5677", "mrqa_triviaqa-validation-5678", "mrqa_triviaqa-validation-5711", "mrqa_triviaqa-validation-5730", "mrqa_triviaqa-validation-5836", "mrqa_triviaqa-validation-5865", "mrqa_triviaqa-validation-5866", "mrqa_triviaqa-validation-6057", "mrqa_triviaqa-validation-6070", "mrqa_triviaqa-validation-6149", "mrqa_triviaqa-validation-6252", "mrqa_triviaqa-validation-6310", "mrqa_triviaqa-validation-6392", "mrqa_triviaqa-validation-6423", "mrqa_triviaqa-validation-660", "mrqa_triviaqa-validation-663", "mrqa_triviaqa-validation-67", "mrqa_triviaqa-validation-6881", "mrqa_triviaqa-validation-6886", "mrqa_triviaqa-validation-6917", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-6979", "mrqa_triviaqa-validation-6994", "mrqa_triviaqa-validation-7113", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-7279", "mrqa_triviaqa-validation-7297", "mrqa_triviaqa-validation-7314", "mrqa_triviaqa-validation-735", "mrqa_triviaqa-validation-7429", "mrqa_triviaqa-validation-7447", "mrqa_triviaqa-validation-7552", "mrqa_triviaqa-validation-7554", "mrqa_triviaqa-validation-7638", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-7698", "mrqa_triviaqa-validation-7736", "mrqa_triviaqa-validation-7755", "mrqa_triviaqa-validation-7778", "mrqa_triviaqa-validation-822", "mrqa_triviaqa-validation-838", "mrqa_triviaqa-validation-851", "mrqa_triviaqa-validation-879", "mrqa_triviaqa-validation-91", "mrqa_triviaqa-validation-989", "mrqa_triviaqa-validation-991"], "OKR": 0.828125, "KG": 0.46015625, "before_eval_results": {"predictions": ["RAF Mount Pleasant", "University of Kansas", "the Docile Don", "Walcha", "Michelle Anne Sinclair", "Adam Levine", "Tim Allen", "The Dressmaker", "Oakland, California", "37", "Tufts University", "Owsley Stanley", "The Late Late Show", "Kongo language", "Harold Lipshitz", "Spanish", "\"The Cleveland Show\" (2009\u20132013)", "1945", "69.7 million", "Neneh Mariann Karlsson", "Fiapre", "pronghorn antelope", "Comodoro Arturo Merino Ben\u00edtez International Airport", "Scotty Grainger", "9", "(Honda) Verno\" dealerships", "8,648", "Alfonso Cuar\u00f3n", "1886", "September 30, 2017", "1902", "Nicolas Winding Refn", "devotional", "Fortunino Francesco Verdi", "Laban Movement Analysis", "Cecily Strong", "J. Robert Oppenheimer", "invoicing the employees' work based on an hourly rate", "seasonal television specials, particularly its work in stop motion animation", "4 km", "1853", "Love", "The Supremes", "48,982", "Vincent Landay", "Edward James Olmos", "a leading lady", "1901", "Pope John X", "Best Art Direction", "(VAQ-135)", "Doug Pruzan", "The Nitty Gritty Dirt Band", "English", "'Q'", "FBI", "a vessel", "(Terra Firma) bought EMI in 2007.", "UNICEF", "Tuesday,", "George Byron", "Van Helsing", "(Aramaic)", "a long-range missile"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6196428571428572}, "metric_results_detailed": {"EM": [false, true, false, false, false, true, false, true, false, true, true, true, true, false, false, true, false, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, true, false, true, false, true, false, true, true, false, false, true, false, true, true, false, false, false, true, false, false, true, false, false], "QA-F1": [0.8, 1.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.4, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.8, 0.4, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4900", "mrqa_hotpotqa-validation-3514", "mrqa_hotpotqa-validation-5413", "mrqa_hotpotqa-validation-963", "mrqa_hotpotqa-validation-2455", "mrqa_hotpotqa-validation-5030", "mrqa_hotpotqa-validation-5173", "mrqa_hotpotqa-validation-5546", "mrqa_hotpotqa-validation-4434", "mrqa_hotpotqa-validation-3163", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-2336", "mrqa_hotpotqa-validation-2366", "mrqa_hotpotqa-validation-1475", "mrqa_hotpotqa-validation-893", "mrqa_hotpotqa-validation-400", "mrqa_hotpotqa-validation-3953", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-5801", "mrqa_hotpotqa-validation-186", "mrqa_hotpotqa-validation-3956", "mrqa_hotpotqa-validation-1310", "mrqa_hotpotqa-validation-4087", "mrqa_hotpotqa-validation-2480", "mrqa_hotpotqa-validation-2058", "mrqa_naturalquestions-validation-34", "mrqa_triviaqa-validation-7487", "mrqa_triviaqa-validation-2358", "mrqa_newsqa-validation-2096", "mrqa_newsqa-validation-1329", "mrqa_searchqa-validation-4962", "mrqa_searchqa-validation-14277", "mrqa_newsqa-validation-1661"], "SR": 0.484375, "CSR": 0.5407475490196079, "EFR": 1.0, "Overall": 0.7161963848039216}, {"timecode": 51, "before_eval_results": {"predictions": ["Ford Field in Detroit, Michigan", "comedy", "Mickey's Christmas Carol", "143,007", "Atat\u00fcrk Museum Mansion", "Realty Bites", "24", "Razor Ramon", "object relations theory", "Forbes", "St. George", "Kramer Guitars", "Lithuanian", "International Boxing Federation", "35", "Conservatorio Verdi in Milan", "Ben", "Smoothie King Center", "World Outgames", "homebrew", "Umberto II", "Presbyterian Church", "neuro-orthopaedic Irish veterinary surgeon", "Hookend Recording Studios in Checkendon, Oxfordshire", "North Sea", "17 October 2006", "67,575", "Oxford", "OSRIC", "Emad Hashim", "5320 km", "Heinkel Flugzeugwerke", "Italian", "Eric Whitacre", "Mission Inn Hotel & Spa", "180", "George Adamski", "Vision of the Future", "Switzerland", "an ancient Celtic ringfort", "Scunthorpe", "Canadian comedian", "Captain Cook's Landing Place", "the Summer Olympic Games unofficial programme in 1900", "1862", "1970", "The Kennedy Center", "Budget Rent a Car", "Japan", "cave lion", "1959", "Donna Mills", "is a pop and R&B ballad, with Latin pop influences", "735 feet", "Maine", "Blanche", "maxilla", "Microsoft", "4.6 million", "Iran", "tea rose", "John J. Pershing", "black Russian", "Rear Window"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6539556751727804}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, true, false, false, true, true, true, false, false, false, false, true, false, false, true, true, false, false, true, true, true, false, false, true, true, true, false, true, false, false, true, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, true, true, true, false, true, false, true, true], "QA-F1": [0.888888888888889, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.18181818181818182, 1.0, 1.0, 1.0, 0.5, 0.0, 0.6666666666666666, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.4, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.16666666666666666, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 1.0, 0.3157894736842105, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5352", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-2374", "mrqa_hotpotqa-validation-2502", "mrqa_hotpotqa-validation-1099", "mrqa_hotpotqa-validation-47", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-3081", "mrqa_hotpotqa-validation-1576", "mrqa_hotpotqa-validation-2018", "mrqa_hotpotqa-validation-4002", "mrqa_hotpotqa-validation-1219", "mrqa_hotpotqa-validation-4492", "mrqa_hotpotqa-validation-3169", "mrqa_hotpotqa-validation-2313", "mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1568", "mrqa_hotpotqa-validation-4460", "mrqa_hotpotqa-validation-1502", "mrqa_hotpotqa-validation-580", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-4448", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-558", "mrqa_naturalquestions-validation-1476", "mrqa_naturalquestions-validation-7250", "mrqa_triviaqa-validation-84", "mrqa_newsqa-validation-4083", "mrqa_searchqa-validation-10653"], "SR": 0.53125, "CSR": 0.5405649038461539, "EFR": 1.0, "Overall": 0.7161598557692307}, {"timecode": 52, "before_eval_results": {"predictions": ["September 19, 2017", "Billy Idol", "pools campaign contributions from members and donates those funds to campaign for or against candidates, ballot initiatives, or legislation", "non-voters", "3", "up to 100,000", "Sachin Tendulkar", "Judiththia Aline Keppel", "Camping World Stadium in Orlando", "Advanced Systems Format ( ASF )", "the Ramones", "Al Pacino", "comedy web television series", "Gospel of Luke", "30 years after Return of the Wars", "A standard form contract", "Diego Tinoco", "sport utility vehicles", "Melbourne", "The Drew Las Vegas", "October 2008", "John Hancock", "1963", "the British military launched a campaign to capture the Colony of Canada ( part of New France )", "The 1972 Dolphins were the third NFL team to accomplish a perfect regular season", "Columbia River Gorge in the U.S. states of Oregon and Washington", "coercivity", "2010", "malicious software", "Cyndi Grecco", "ingredients", "1900", "dorsally on the forearm", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "Terry Kath", "roofing material", "one person", "The Parlement de Bretagne", "Microsoft Windows", "the Court declared state laws establishing separate public schools for black and white students to be unconstitutional", "September 1995", "late - September", "derivative financial instrument", "1623", "a normally inaccessible mini-game in the 2004 video game Grand Theft Auto : San Andreas", "The vasomotor centre ( VMC ) is a portion of the medulla oblongata that, together with the cardiovascular center and respiratory center, regulates blood pressure and other homeostatic processes", "2018", "Gibraltar, a British Overseas Territory, located at the southern tip of the Iberian Peninsula", "Howard Caine", "May 3, 2005", "Andy Cole", "Harry patch", "comedy playhouse", "Paul Maskey", "child actor or child actress", "Saoirse Ronan", "Revolution Studios", "The Kirchners", "Croatia playmaker", "Gordon Brown", "veterans", "yellow fever", "winter", "Netflix"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6337437741990444}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, false, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, false, false, false, true, false, true, true, true, true, false, true, false, true, false, false, false, false, false, false, false, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8333333333333334, 0.046511627906976744, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4615384615384615, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.14285714285714288, 1.0, 0.0, 1.0, 0.4, 0.0, 0.967741935483871, 0.0, 0.5714285714285715, 0.0, 0.0, 1.0, 0.16, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4524", "mrqa_naturalquestions-validation-2148", "mrqa_naturalquestions-validation-3835", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-802", "mrqa_naturalquestions-validation-5586", "mrqa_naturalquestions-validation-10188", "mrqa_naturalquestions-validation-923", "mrqa_naturalquestions-validation-288", "mrqa_naturalquestions-validation-8465", "mrqa_naturalquestions-validation-5927", "mrqa_naturalquestions-validation-1203", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-7021", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-10090", "mrqa_naturalquestions-validation-7143", "mrqa_naturalquestions-validation-226", "mrqa_naturalquestions-validation-8414", "mrqa_naturalquestions-validation-6545", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-3959", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-4852", "mrqa_hotpotqa-validation-3162", "mrqa_newsqa-validation-318", "mrqa_searchqa-validation-4527"], "SR": 0.546875, "CSR": 0.5406839622641509, "EFR": 0.9310344827586207, "Overall": 0.7023905640045542}, {"timecode": 53, "before_eval_results": {"predictions": ["Al Lenhardt", "the Big Bang Theory of Creation", "Handel", "Green Acres", "6 3 5 - 4 7 7 4", "a chocolate-covered blend of coconut, nuts, and fruit", "the Doppler shift", "Lobster Newberg", "Shel Silverstein", "American Airlines", "her coronation", "Vermont", "Windsor", "a candy store", "oncorhynchus", "Pudd'nhead Wilson", "Osaka", "the tapir", "France", "Spam", "Stephen Dedalus", "early", "Cheeses of France", "Friday", "the Golden Legend", "centaur", "Mentor", "a Lebanese politician", "Nigeria", "Al Gore", "the Americans with Disabilities Act", "Bali", "Philadelphia", "Cyprus", "Glucosamine", "Madagascar", "Wikipedia", "a celebration, stunt, spectacle", "astrachan (curly lambswool)", "Susan Faludi", "Dr. Dre", "Al Lang Stadium", "Fidel Castro", "fudge", "a story of the Transcontinental Railroad", "Laborers' International Union", "gold", "auxins", "a dive in which the diver bends in midair to touch the toe", "yellow", "watermelon", "between the Mediterranean Sea to the north and the Red Sea in the south", "Los Angeles", "Zeus", "Van Morrison", "antelopes", "distributor", "Rocky Mountain Institute", "21", "a cobblestone-size (10x10 cm ) concrete cube bearing a brass plate inscribed with the name and life dates of victims of Nazi extermination or persecution", "three thousand", "insurgent small arms fire", "about 3,000 kilometers (1,900 miles),", "Lambic and Oud bruin"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4982638888888889}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, false, true, true, true, true, false, true, false, false, false, true, true, true, false, false, false, true, false, true, true, false, false, true, false, false, false, true, true, true, true, false, false, true, false, false, true, true, false, false, false, false, false, false, true, false, false, true, true, true, false, true, true, false, true, false, false, false], "QA-F1": [0.0, 0.33333333333333337, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.888888888888889, 0.4]}}, "before_error_ids": ["mrqa_searchqa-validation-3854", "mrqa_searchqa-validation-7434", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-9715", "mrqa_searchqa-validation-14299", "mrqa_searchqa-validation-15543", "mrqa_searchqa-validation-7691", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-7145", "mrqa_searchqa-validation-14860", "mrqa_searchqa-validation-7425", "mrqa_searchqa-validation-1451", "mrqa_searchqa-validation-12711", "mrqa_searchqa-validation-1851", "mrqa_searchqa-validation-1007", "mrqa_searchqa-validation-5107", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-1108", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-7952", "mrqa_searchqa-validation-11345", "mrqa_searchqa-validation-13258", "mrqa_searchqa-validation-2314", "mrqa_searchqa-validation-10587", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-3481", "mrqa_searchqa-validation-904", "mrqa_searchqa-validation-12755", "mrqa_searchqa-validation-6093", "mrqa_searchqa-validation-9966", "mrqa_naturalquestions-validation-6319", "mrqa_naturalquestions-validation-4242", "mrqa_triviaqa-validation-7747", "mrqa_hotpotqa-validation-3325", "mrqa_newsqa-validation-1792", "mrqa_newsqa-validation-3349", "mrqa_hotpotqa-validation-3487"], "SR": 0.421875, "CSR": 0.5384837962962963, "EFR": 0.972972972972973, "Overall": 0.7103382288538539}, {"timecode": 54, "before_eval_results": {"predictions": ["Keeley Clare Julia Hawes", "1837", "Trace Adkins", "Dan Stevens", "the state legislators of Assam", "a travelling circus", "the stems and roots of certain vascular plants", "the Greek name `` \u0391\u03bd\u03b4\u03c1\u03ad\u03b1\u03c2 / Andreas '', cf. English Andrew", "1987", "John F. Kennedy", "in teaching elocution", "on the Isle of FERNANDO 'S!, a fictional location based in Puerto de la Cruz, Tenerife", "seven", "1999", "Rashida Jones", "Hook", "Bush", "the merging of tissues in the vicinity of the nose", "December 1, 2009", "the eighth episode in the ninth season of the American animated television series South Park", "70 million", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "Haji Sahib of Turangzai", "45 %", "handheld subscriber equipment", "66 \u00b0 33 \u2032 47.0 '' north of the Equator", "1998", "Chris Martin", "Ming dynasty", "the red - bed country of its watershed", "Thomas Paine", "The Intolerable Acts", "National Industrial Recovery Act", "semi-autonomous organisational units within the National Health Service in England", "Peter Billingsley", "Cyanea capillata", "1996", "Hyderabad", "Johannes Gutenberg", "1885", "San Francisco, California", "the Finch family's African - American housekeeper", "( such as the muscles of the limbs, abdominal, and intercostal muscles ), which are involved in locomotion", "Pyeongchang County, Gangwon Province, South Korea", "New York City", "two - year terms", "The Vamps, Conor Maynard, Bronnie, Ella Eyre, Sheppard and Louisa Johnson", "invoices", "Tenochtitlan", "Ravi River", "O'Meara", "Philippines", "driving Miss Daisy", "the Greek Goddess of Revenge", "Kaneohe Bay", "PlayStation 4", "the 2015 Orange Bowl", "Seminole Tribe", "the Defense of Marriage Act", "Alinghi", "the Eiffel tower", "barnacles", "Lobo", "gerry adaption of Angels & Demons"], "metric_results": {"EM": 0.5, "QA-F1": 0.6423728887641427}, "metric_results_detailed": {"EM": [true, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, true, false, true, true, false, false, true, true, true, false, false, true, true, true, false, false, false, false, true, true, false, false, true, false, true, true, true, true, false, false, true, false, false, false, false, true, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.4615384615384615, 0.5263157894736842, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333333, 0.0, 0.5882352941176471, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.3333333333333333, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9546", "mrqa_naturalquestions-validation-556", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-5876", "mrqa_naturalquestions-validation-3605", "mrqa_naturalquestions-validation-5469", "mrqa_naturalquestions-validation-8386", "mrqa_naturalquestions-validation-2169", "mrqa_naturalquestions-validation-1882", "mrqa_naturalquestions-validation-3132", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-10202", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-2794", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-2582", "mrqa_naturalquestions-validation-451", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5925", "mrqa_triviaqa-validation-892", "mrqa_hotpotqa-validation-2067", "mrqa_hotpotqa-validation-4645", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-2466", "mrqa_searchqa-validation-11506", "mrqa_triviaqa-validation-7361"], "SR": 0.5, "CSR": 0.537784090909091, "EFR": 0.96875, "Overall": 0.7093536931818182}, {"timecode": 55, "before_eval_results": {"predictions": ["king Edward III", "golf", "purple", "aeoline", "ascot racecourse in Berkshire", "Litas", "Loretta Lynn", "WrestleMania", "steppenwolf", "chop suey", "jennifer adams", "gordon adams", "baltimore police drama", "evevraj smashes six sixes in one over", "bing.com", "New Zealand", "Tyrrhenian Sea", "berry adams", "mauritania", "h Hans lippershey", "Bolivia", "gordon scorsese", "the Mozambique Channel", "ash tree", "Edward VII", "capmer", "testicles", "Guatemala", "gerry gordon laker", "gordon adherne", "jett rink", "s\u00e8vres", "Mau Mau Revolution", "kipps: The Story of a Simple Soul", "guggul adams", "serena wenderson", "capital of Togo", "Pegida", "g\u00f6tterd\u00e4mmerung", "Utrecht", "1709", "Mitford sisters", "kansas", "capone", "vitifoliae", "baltica", "ostrich", "h Hugh quarshie", "a hollow tube that runs through the bottom of the ship from the main engine to the propeller", "capone", "korea", "Kimberlin Brown", "seven", "Kid Creole and the Coconuts", "Jack Ridley", "Linux Format", "Stage Stores", "26", "ordered the immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guantanamo Bay, Cuba.", "Beijing", "Kool- aid", "Treaty of Versailles", "Ken Russell", "Russia and China"], "metric_results": {"EM": 0.421875, "QA-F1": 0.4966382575757576}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, false, true, false, false, false, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, false, true, true, true, false, false, true, true, false, false, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.33333333333333337, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.48484848484848486, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-7160", "mrqa_triviaqa-validation-1803", "mrqa_triviaqa-validation-1051", "mrqa_triviaqa-validation-2333", "mrqa_triviaqa-validation-2754", "mrqa_triviaqa-validation-2694", "mrqa_triviaqa-validation-4775", "mrqa_triviaqa-validation-930", "mrqa_triviaqa-validation-3145", "mrqa_triviaqa-validation-3596", "mrqa_triviaqa-validation-6158", "mrqa_triviaqa-validation-5554", "mrqa_triviaqa-validation-5479", "mrqa_triviaqa-validation-5425", "mrqa_triviaqa-validation-4057", "mrqa_triviaqa-validation-3454", "mrqa_triviaqa-validation-366", "mrqa_triviaqa-validation-597", "mrqa_triviaqa-validation-2148", "mrqa_triviaqa-validation-1601", "mrqa_triviaqa-validation-5428", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4809", "mrqa_triviaqa-validation-6700", "mrqa_triviaqa-validation-7623", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-3071", "mrqa_triviaqa-validation-7530", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-2256", "mrqa_triviaqa-validation-3131", "mrqa_triviaqa-validation-5930", "mrqa_hotpotqa-validation-2944", "mrqa_hotpotqa-validation-4642", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-2488", "mrqa_searchqa-validation-4261"], "SR": 0.421875, "CSR": 0.5357142857142857, "EFR": 0.972972972972973, "Overall": 0.7097843267374517}, {"timecode": 56, "before_eval_results": {"predictions": ["argentina", "Bolivia", "The Telegraph", "liver", "portugal", "Drunk", "archway", "Aldo Moro", "Calcium carbonate", "Salman Rushdie", "george eliot", "along with the harbour, Te Papa and the hills", "koftas", "benazir butto", "cricketer", "Sam mendes", "tara king", "way back Attack", "ninth", "business", "godiva", "skimmer", "Mexico", "river Towy", "aljavan", "1984", "scotland", "three", "shinto", "Sussex", "george iv", "Mickey Mouse", "oxygen", "son", "tokyo", "do I have to use", "Dodoma", "skronk", "Wilson", "lomond", "el aneto", "South Korea", "gelatine", "new guinea", "gulf of aden", "north Yorkshire", "a\u00e9roport de la Nation", "sankt Moritz", "the French Revolution", "the Old Kent Road", "will lead them into an afterlife and into one of the Vikings nine realms", "an anion", "lithium - ion batteries", "creation of the office in 1789", "Christopher Whitelaw Pine", "Yorgos Lanthimos", "Tottenham ( ) or Spurs", "Unseeded", "off Somalia's coast.", "Shanghai", "cape", "Pershing", "governess", "a Maine politician"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5593750000000001}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, true, false, false, false, false, true, true, false, false, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, true, false, false, true, false, false, true, true, false, false, true, true, false, false, false, false, true, true, false, false, false, true, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.3333333333333333]}}, "before_error_ids": ["mrqa_triviaqa-validation-3680", "mrqa_triviaqa-validation-3016", "mrqa_triviaqa-validation-4296", "mrqa_triviaqa-validation-3412", "mrqa_triviaqa-validation-2112", "mrqa_triviaqa-validation-5432", "mrqa_triviaqa-validation-3116", "mrqa_triviaqa-validation-745", "mrqa_triviaqa-validation-3487", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-4480", "mrqa_triviaqa-validation-5679", "mrqa_triviaqa-validation-3148", "mrqa_triviaqa-validation-2943", "mrqa_triviaqa-validation-5888", "mrqa_triviaqa-validation-446", "mrqa_triviaqa-validation-6420", "mrqa_triviaqa-validation-1010", "mrqa_triviaqa-validation-4127", "mrqa_triviaqa-validation-4566", "mrqa_triviaqa-validation-6236", "mrqa_triviaqa-validation-6376", "mrqa_triviaqa-validation-3964", "mrqa_triviaqa-validation-361", "mrqa_triviaqa-validation-3828", "mrqa_naturalquestions-validation-1202", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4370", "mrqa_hotpotqa-validation-3603", "mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-1022", "mrqa_searchqa-validation-10590", "mrqa_hotpotqa-validation-4052"], "SR": 0.484375, "CSR": 0.5348135964912281, "EFR": 1.0, "Overall": 0.7150095942982456}, {"timecode": 57, "before_eval_results": {"predictions": ["William Shakespeare", "michelle mcmanborn", "micelles", "river lee", "Rudolf nureyev", "Jessica", "plac\u0113b\u014d", "weather", "Lake Placid", "papal state", "contractions", "william boyd", "saint c Cecilia", "Caroline Garcia", "morecambe & wiseman", "tommy lee jones", "butcher", "cowpox", "deer hunting", "Stockholm", "france", "by Dire Straits", "anosmia", "celestialis", "chemnitz", "rue", "yellow", "raven", "caracas", "ennio morricone", "france bacoyne", "Spain", "time team", "turandot", "Ethiopia", "summit", "valour", "Howard Keel", "marriage", "boutros Ghali", "france", "Sinclair Lewis", "new Mexico", "garden of gethsemane", "mediterranean", "3", "Sunday Times", "france", "katiania", "keirin", "selenium", "for any vehicle which drives on all four wheels, but may not be designed for off - road use", "an American actor", "Tbilisi", "Las Vegas", "2006", "number five", "natural gas", "Michael Jackson was in good health, contrary to media reports he was diagnosed with skin cancer.", "Shiza Shahid,", "the Perseid meteor shower", "accordions", "bones", "Mark Wahlberg"], "metric_results": {"EM": 0.5, "QA-F1": 0.5755208333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, false, false, true, true, false, true, false, true, true, true, false, true, true, false, true, true, true, false, false, false, true, false, true, false, true, false, false, false, false, false, true, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.4, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.4, 1.0, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-404", "mrqa_triviaqa-validation-2776", "mrqa_triviaqa-validation-5768", "mrqa_triviaqa-validation-883", "mrqa_triviaqa-validation-4653", "mrqa_triviaqa-validation-5969", "mrqa_triviaqa-validation-7431", "mrqa_triviaqa-validation-2366", "mrqa_triviaqa-validation-2804", "mrqa_triviaqa-validation-7268", "mrqa_triviaqa-validation-3054", "mrqa_triviaqa-validation-2593", "mrqa_triviaqa-validation-2743", "mrqa_triviaqa-validation-1884", "mrqa_triviaqa-validation-5363", "mrqa_triviaqa-validation-7300", "mrqa_triviaqa-validation-6041", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-3101", "mrqa_triviaqa-validation-4499", "mrqa_triviaqa-validation-2116", "mrqa_triviaqa-validation-2129", "mrqa_triviaqa-validation-4425", "mrqa_triviaqa-validation-4857", "mrqa_naturalquestions-validation-10066", "mrqa_naturalquestions-validation-6769", "mrqa_hotpotqa-validation-5219", "mrqa_hotpotqa-validation-794", "mrqa_newsqa-validation-3655", "mrqa_searchqa-validation-3009", "mrqa_searchqa-validation-6518"], "SR": 0.5, "CSR": 0.5342133620689655, "EFR": 0.96875, "Overall": 0.708639547413793}, {"timecode": 58, "before_eval_results": {"predictions": ["Frottage", "Jonah", "The Color Purple", "Constantinople", "Jacqueline Susann", "the Amazon", "Hudson River", "spinal column", "New Year's Day", "the Sons of Liberty", "Napoleon Bonaparte", "Cecil Rhodes", "Hindenburg", "atrium", "Valley Forge", "gold", "mediterranean", "Siberia", "William Pitt the Younger", "five", "The One Where Jason's Mom Did It", "Rotherham", "The Godfather", "melanoma", "Nostradamus", "jihad", "harpoons", "Mandy Well you came", "financial services", "Conrad Hilton Jr.,", "Jasper Johns", "plutonium", "cyanotype", "Zimbabwe", "Battle of Trafalgar", "the bald eagle", "menudo", "a dramma tragico", "hurricanes", "Home Improvement", "Great Lakes", "Airport", "alphabets", "Bourbon French Parfums", "a statistic", "The Little Mermaid", "brothers", "injecton", "Pell grants", "emerald", "a dome", "19 July 1990", "anvil", "Louis XV", "germany", "mansion house", "senior", "Los Angeles", "Comme des Gar\u00e7ons", "Manasseh Cutler Hall", "Karl Kr\u00f8yer", "Nasser Medical Institute in Cairo,", "Auckland", "getting bald or fear of being around bald people"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5244791666666666}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, false, true, true, false, true, false, false, true, true, false, false, true, false, false, true, false, true, false, true, false, false, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1815", "mrqa_searchqa-validation-4370", "mrqa_searchqa-validation-6293", "mrqa_searchqa-validation-12288", "mrqa_searchqa-validation-15988", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-13023", "mrqa_searchqa-validation-4925", "mrqa_searchqa-validation-12684", "mrqa_searchqa-validation-14549", "mrqa_searchqa-validation-9097", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-12130", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-16444", "mrqa_searchqa-validation-12173", "mrqa_searchqa-validation-6389", "mrqa_searchqa-validation-11670", "mrqa_searchqa-validation-4488", "mrqa_searchqa-validation-2704", "mrqa_searchqa-validation-1202", "mrqa_searchqa-validation-3807", "mrqa_searchqa-validation-14124", "mrqa_searchqa-validation-12017", "mrqa_searchqa-validation-1938", "mrqa_searchqa-validation-6110", "mrqa_naturalquestions-validation-1731", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-737", "mrqa_hotpotqa-validation-1611", "mrqa_newsqa-validation-111", "mrqa_newsqa-validation-1225", "mrqa_triviaqa-validation-2596"], "SR": 0.484375, "CSR": 0.5333686440677966, "EFR": 0.9696969696969697, "Overall": 0.7086599977529533}, {"timecode": 59, "before_eval_results": {"predictions": ["Alabama", "GTG", "whisky", "Leonard Bernstein", "magnesium", "Venice", "Danube", "the albatross", "George Costanza", "Smashing Pumpkins", "sentences", "Ohio State", "Sherman", "India", "Theology of God", "Leinster", "Sally Field", "Barbara Cartland", "Rum", "a Pringles can", "Paul Hamm", "profundo", "East Siberia", "Nimble", "Tom Hanks", "Clue", "a theatrical cartoon series", "#5367", "alternating current", "Walter Cronkite", "Robert Burns", "Bicentennial Man", "Marshall", "General Motors", "the trade winds", "(July 5, 1902)", "silk", "w", "Unicorn", "Scrabble", "humerus", "Saturday Night Fever", "Petruchio", "Philippines", "mushrooms", "Guevara", "Yale University", "Oscar Wilde", "Helen of Troy", "Dian Fossey", "a map", "an iron -- nickel alloy and some other elements", "ABC", "an opinion in a legal case in certain legal systems written by one or more judges expressing disagreement with the majority opinion of the court", "pear", "Melbourne", "Jape", "Ringo Starr", "Do Kyung-soo", "Hanna, Alberta", "a spurned suitor.", "\"came under fire\" after admitting they learned of the death from TV news coverage,", "\"all the world's largest producers of greenhouse gas emissions, including developed and developing nations,\" to come together and \"set a long-term goal for reducing\" greenhouse emissions.", "king of troy"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6519362745098038}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, false, true, false, false, false, false, true, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.32, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.47058823529411764, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6548", "mrqa_searchqa-validation-14429", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-9674", "mrqa_searchqa-validation-4274", "mrqa_searchqa-validation-15083", "mrqa_searchqa-validation-116", "mrqa_searchqa-validation-3853", "mrqa_searchqa-validation-2557", "mrqa_searchqa-validation-15665", "mrqa_searchqa-validation-9632", "mrqa_searchqa-validation-10544", "mrqa_searchqa-validation-2948", "mrqa_searchqa-validation-14151", "mrqa_searchqa-validation-13514", "mrqa_searchqa-validation-4918", "mrqa_searchqa-validation-15230", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-10610", "mrqa_naturalquestions-validation-5251", "mrqa_naturalquestions-validation-2319", "mrqa_naturalquestions-validation-186", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-249", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-2777", "mrqa_newsqa-validation-2745", "mrqa_triviaqa-validation-6487"], "SR": 0.5625, "CSR": 0.5338541666666667, "EFR": 1.0, "Overall": 0.7148177083333334}, {"timecode": 60, "before_eval_results": {"predictions": ["26 November", "50 million", "Pacific Place", "1002", "Anandji Virji Shah", "Lu\u00eds Nani", "four", "Sippin' on some Syrup", "Sergeant Purley Stebbins", "Maersk Group", "All My Children", "Karl-Anthony Towns", "five", "Charlie Wilson", "Sim Theme Park", "a facelifted 850 saloon", "its riverside location", "1858", "Julie Taymor", "actor", "James Edward Kelly", "Spanish", "Purdue University", "Manhattan", "Homeland", "2016", "Virgin Atlantic", "green and yellow", "Champion Jockey", "March 2012", "Sir Thomas Daniel Courtenay", "Erinsborough", "2015", "Vladimir Menshov", "The Birds", "Londonderry", "York County", "National Basketball Development League", "Father Dougal McGuire", "Bill Curry", "UFC Fight Pass", "1949", "Savannah River Plant", "\u00c6thelred I", "God and the just cause", "Swiss", "emperor Tiberius", "World War I", "at age 27", "Marktown", "five", "Rodney Crowell", "Mendel", "along a given curbside for the arrival of the bus", "scales", "d\u00fcsseldorf", "apollon", "Anil Kapoor", "\"Rightwing Extremism: Current Economic and Political Climate Fueling Resurgence in Radicalization and Recruitment.\"", "Arthur E. Morgan III,", "quarantina", "the Silk Road", "ABBA", "Spain"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7269412878787879}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, false, false, false, false, false, true, true, true, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.6666666666666666, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.09090909090909091, 0.0, 1.0, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4914", "mrqa_hotpotqa-validation-1854", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-2935", "mrqa_hotpotqa-validation-5688", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-1969", "mrqa_hotpotqa-validation-1788", "mrqa_hotpotqa-validation-1393", "mrqa_hotpotqa-validation-399", "mrqa_hotpotqa-validation-1371", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-1949", "mrqa_hotpotqa-validation-3127", "mrqa_hotpotqa-validation-2022", "mrqa_hotpotqa-validation-1010", "mrqa_hotpotqa-validation-1812", "mrqa_naturalquestions-validation-6949", "mrqa_triviaqa-validation-2692", "mrqa_triviaqa-validation-1428", "mrqa_newsqa-validation-867", "mrqa_searchqa-validation-14894", "mrqa_naturalquestions-validation-6011"], "SR": 0.640625, "CSR": 0.5356045081967213, "EFR": 0.9130434782608695, "Overall": 0.6977764722915182}, {"timecode": 61, "before_eval_results": {"predictions": ["Gaels", "Chicago Bears", "girls aged 11 to 18", "Taylor Swift", "Adolfo Rodr\u00edguez Sa\u00e1", "Freeform", "Adult Swim", "1983", "Rio Ferdinand", "264,152", "2,664", "841", "Cher", "ABC1 and ABC2", "MG Car Company Limited", "Walt Disney", "1979", "15 mi", "January 23, 1898", "John Henry", "Bolton", "Argentinian", "Them", "575 acres (2.08 km\u00b2)", "John Snow", "The New York and New Jersey campaign", "2013\u201314", "Melbourne Storm", "University of Nevada, Las Vegas", "21", "The Republic of Armenia", "Tuesday", "Oklahoma Sooners", "2011", "7pm", "1866", "Gaahl", "Serie B", "1887", "Sojourner Truth", "1 Squadron and 3 Squadron", "North Holland in the west of the country", "Don Bluth", "Golden Calf", "The Lykan Hypersport", "The seventeenth edition of the IAAF World Championships", "Agatha Christie", "Mercer University", "1951", "35,124", "21 years and 154 days", "March 29, 2018", "James P. Flynn", "the Western Bloc ( the United States, its NATO allies and others )", "his finger", "Ronald Wilson Reagan", "One Thousand and One", "Long troop deployments in Iraq, above, and Afghanistan", "fuel economy and safety while boosts the economy.", "forcibly injecting them with psychotropic drugs while trying to shuttle them out of the country during their deportation.", "James Watt", "T.S. Eliot", "Anastasia Romanov", "Games"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6761479801900998}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, true, false, false, true, true, false, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, false, true, true, false, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false, true, true, false, false, false, true, true, false, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.16666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.3636363636363636, 0.6666666666666666, 1.0, 1.0, 0.0, 0.1, 0.5217391304347826, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5336", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-3573", "mrqa_hotpotqa-validation-5870", "mrqa_hotpotqa-validation-4097", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-4408", "mrqa_hotpotqa-validation-4802", "mrqa_hotpotqa-validation-5797", "mrqa_hotpotqa-validation-3044", "mrqa_hotpotqa-validation-985", "mrqa_hotpotqa-validation-1341", "mrqa_hotpotqa-validation-5250", "mrqa_hotpotqa-validation-1228", "mrqa_hotpotqa-validation-3306", "mrqa_hotpotqa-validation-1453", "mrqa_hotpotqa-validation-3282", "mrqa_hotpotqa-validation-3317", "mrqa_hotpotqa-validation-3430", "mrqa_hotpotqa-validation-3443", "mrqa_hotpotqa-validation-5832", "mrqa_hotpotqa-validation-1285", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-5180", "mrqa_triviaqa-validation-7611", "mrqa_newsqa-validation-2892", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-129", "mrqa_searchqa-validation-4629"], "SR": 0.546875, "CSR": 0.5357862903225806, "EFR": 1.0, "Overall": 0.715204133064516}, {"timecode": 62, "before_eval_results": {"predictions": ["The Dayton Memorial Hall", "13 October 1958", "Walt Disney and Ub Iwerks", "barcode readers", "the Processional Way", "a card", "water sprite", "Sean Yseult", "the name of court systems in several common law jurisdictions", "October 5, 1937", "Hillsborough County", "Charles Nungesser", "Burning Man", "Love Streams", "Group Captain Peter Wooldridge Townsend", "August 10, 1933", "Dallas", "Black Panthers", "globetrotters", "Francis Schaeffer", "a field in Somerset County, Pennsylvania", "Simon Bolivar Buckner", "German", "Gareth Jones", "consulting services", "April", "1978", "actor", "Melanie Owen", "1983", "Indian state of Gujarat", "143,007", "May 4, 1924", "American jewelry designer", "Guns N' Roses", "the Nebula Award, the Philip K. Dick Award, and the Hugo Award", "The Big Bang Theory", "the German princely Battenberg family", "dice", "Kal Ho Naa Ho", "Dungeness crab", "Pendlebury", "25 October 1921", "Canadian comedian", "Martin O'Neill", "Stratfor", "Reginald Engelbach", "American", "the fourth Thursday", "Golden Valley, Minnesota", "Jean Erdman", "5.7 million customer accounts", "During Hanna's recovery masquerade celebration", "Anakin Skywalker", "Richard Seddon", "the heart", "Juneau, Alaska", "take the Rio Group to a new level by creating the organization.", "\"Now that we know Muhammad is an Ennis man, we will be back,\"", "Bob Bogle", "around", "The Hague", "a stationwagon", "2001"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6786744916267942}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, true, false, false, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, true, true, false, true, true, false, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2105263157894737, 0.5, 0.6666666666666666, 0.5, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727272, 1.0, 1.0, 0.0, 0.0, 0.9473684210526316, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1130", "mrqa_hotpotqa-validation-2204", "mrqa_hotpotqa-validation-515", "mrqa_hotpotqa-validation-1641", "mrqa_hotpotqa-validation-1897", "mrqa_hotpotqa-validation-3075", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-20", "mrqa_hotpotqa-validation-2419", "mrqa_hotpotqa-validation-4162", "mrqa_hotpotqa-validation-4163", "mrqa_hotpotqa-validation-4046", "mrqa_hotpotqa-validation-632", "mrqa_hotpotqa-validation-5306", "mrqa_hotpotqa-validation-3842", "mrqa_hotpotqa-validation-2117", "mrqa_hotpotqa-validation-4838", "mrqa_hotpotqa-validation-5074", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-5521", "mrqa_hotpotqa-validation-5232", "mrqa_hotpotqa-validation-1714", "mrqa_naturalquestions-validation-9222", "mrqa_triviaqa-validation-328", "mrqa_triviaqa-validation-7459", "mrqa_newsqa-validation-2224", "mrqa_newsqa-validation-3319", "mrqa_searchqa-validation-12404"], "SR": 0.5625, "CSR": 0.5362103174603174, "EFR": 0.9285714285714286, "Overall": 0.7010032242063492}, {"timecode": 63, "before_eval_results": {"predictions": ["a torpedo", "two weevils", "\"justice\"", "between cultivated carrots and the wild", "the beluga whale", "Nicholas II", "tuna", "shalom", "Russia", "a chimp", "The Larry Sanders Show", "Argentina", "Thor", "the Princes of Nassau", "astride", "Borneo", "Mount Vernon", "a nutty flavor", "Raleigh", "whipped cream", "tuna", "Macbeth", "Jean-Michel Basquiat", "Led Zeppelin", "War & Peace", "Dutchman", "Cybill Shepherd", "Truman Capote", "Columbo", "John Tyler", "Milwaukee", "sin", "Wall Street", "sake", "Notre Dame", "Portland", "Lafayette", "The Indianapolis 500", "Toy Story", "improv", "Carrie Bradshaw", "Eustace", "Nikolaj Gogol", "David Hare", "Fletcher Christian", "weaving", "Pope John Paul II", "Greenland", "John", "The Marx Brothers", "watermelon", "Robin Cousins", "the duodenum", "Reverend J. Long", "violin", "a provocative and idiosyncratic feminist\u02bcs", "The Free Dictionary", "Garrett Morris", "1966", "12", "Susan Atkins", "almost 9 million", "three thousand", "al-Maliki"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6652157738095238}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, true, true, false, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337]}}, "before_error_ids": ["mrqa_searchqa-validation-6211", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-1267", "mrqa_searchqa-validation-10557", "mrqa_searchqa-validation-5508", "mrqa_searchqa-validation-8531", "mrqa_searchqa-validation-5195", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-15074", "mrqa_searchqa-validation-14769", "mrqa_searchqa-validation-724", "mrqa_searchqa-validation-2728", "mrqa_searchqa-validation-13220", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-6694", "mrqa_searchqa-validation-2412", "mrqa_searchqa-validation-1825", "mrqa_searchqa-validation-1593", "mrqa_searchqa-validation-15871", "mrqa_naturalquestions-validation-5497", "mrqa_triviaqa-validation-1169", "mrqa_triviaqa-validation-4356", "mrqa_hotpotqa-validation-1437", "mrqa_hotpotqa-validation-667", "mrqa_newsqa-validation-3671"], "SR": 0.59375, "CSR": 0.537109375, "EFR": 1.0, "Overall": 0.71546875}, {"timecode": 64, "before_eval_results": {"predictions": ["some of the most gigantic pumpkins in the world,", "Seminole", "billions of dollars in Chinese products each year,", "a German citizen", "228", "a traditional form of lounge music that flourished in 1940's Japan.", "2005", "contaminated groundwater, hundreds of buildings used for plutonium enrichment that need to be torn down, and underground tanks that are full of radioactive sludge.", "consumer confidence", "Fernando Gonzalez", "in the southern port city of Karachi", "The pilot,", "Jason Chaffetz", "processing data, requiring that all flight-plan information be processed through a facility in Salt Lake City, Utah,", "the Gulf of Aden", "U.S. President-elect Barack Obama", "Sunday", "Bienvenido Latag", "France", "380,000", "be silent.", "iTunes", "Kenyan and Somali governments", "\"gotten the balance right\"", "a dozen", "10", "Quiet Nights", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "in almost all [Middle East and North Africa] countries,", "more than 200 arrests and the recovery of 123 pounds of cocaine and 4.5 pounds of heroin", "engineering and construction", "it was split 10-2.", "fractured pelvis and sacrum", "five", "to step up.", "murder", "Moscow", "Mashhad", "summer", "one", "Bryant Purvis", "Tripplehorn", "al Qaeda,", "Garth Brooks", "in Oxbow,", "Bahrami", "different women coping with breast cancer", "Michael Schumacher", "Lula da Silva", "the release of the four men", "2006", "12.9 - kilometre", "Jim Ruggiere", "Theodosius I", "David Pearson", "Estonia", "not", "Princess Elizabeth", "Sergeant First Class", "Champion Jockey", "Frederic Remington", "Ptolemy", "President Woodrow Wilson", "a skull"], "metric_results": {"EM": 0.46875, "QA-F1": 0.6499718684093684}, "metric_results_detailed": {"EM": [false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, true, false, true, false, true, false, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, false, false, true, false, true, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.9090909090909091, 1.0, 0.0, 0.2222222222222222, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.42857142857142855, 0.7142857142857143, 0.72, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.923076923076923, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.8, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1764", "mrqa_newsqa-validation-150", "mrqa_newsqa-validation-2742", "mrqa_newsqa-validation-2448", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-909", "mrqa_newsqa-validation-2081", "mrqa_newsqa-validation-44", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-1825", "mrqa_newsqa-validation-2617", "mrqa_newsqa-validation-2232", "mrqa_newsqa-validation-4133", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-236", "mrqa_newsqa-validation-2197", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-1644", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-2545", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-10081", "mrqa_naturalquestions-validation-1147", "mrqa_triviaqa-validation-6462", "mrqa_triviaqa-validation-616", "mrqa_searchqa-validation-3653", "mrqa_searchqa-validation-11117", "mrqa_searchqa-validation-709"], "SR": 0.46875, "CSR": 0.5360576923076923, "EFR": 1.0, "Overall": 0.7152584134615385}, {"timecode": 65, "before_eval_results": {"predictions": ["269,000", "\"I always kind of admired him, oddly.\"", "North Korea", "February 12", "Mandi Hamlin", "United Nations", "\"falling space debris,\"", "located outside the military recruiting center.", "voluntary manslaughter", "immediately put Morgan on a helicopter to Rainbow Babies and Children's Hospital in Cleveland,", "Chris Robinson", "Sandy Olssen", "a \"black box\" label warning", "34", "E. coli", "More than 15,000", "\"I know a lot of people probably think it's not enough or that you should be going to protests or demonstrations,\"", "The Sopranos", "government", "September,", "his comments while Saudi authorities discuss whether he should be charged with a crime,", "South Africa", "Dick Cheney,", "The apartment building collapsed together with two other buildings on March 3.", "Mary Procidano,", "using injectable vitamin supplements", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "400 years ago", "Gulf of Aden,", "\"To the Muslim world, we seek a new way forward, based on mutual interest and mutual respect.\"", "31 meters (102 feet) long and 15 meters (49 feet) wide,", "Caylee Anthony,", "the immorality of these deviant young men does not provide solutions that prevent gang rape from happening.", "Wednesday.", "managing his time.", "require an act of Congress,", "bipartisan", "us to step up.\"", "he acted in self defense in punching businessman Marcus McGhee.", "education about rainforests.", "three", "Vicente Carrillo Leyva,", "state", "Trevor Rees-Jones,", "28 passengers,", "the leader of a drug cartel", "Ed McMahon,", "London Heathrow's Terminal 5.", "creation of an Islamic emirate in Gaza,", "Prince George's County Correctional Center,", "Genocide Prevention Task Force,", "243 days", "Kirstjen Nielsen", "August 5, 1937", "20", "Wisconsin", "Mr Loophole", "Arlo Looking Cloud", "East coast of the United States", "1694", "the Golden Fleece", "Gustav", "Amish", "6teen"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6705915579948087}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.06666666666666667, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.2727272727272727, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.11764705882352941, 1.0, 0.5, 0.0, 0.4, 0.5, 0.0, 1.0, 1.0, 0.10526315789473685, 1.0, 1.0, 0.0, 1.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1748", "mrqa_newsqa-validation-3289", "mrqa_newsqa-validation-2262", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2911", "mrqa_newsqa-validation-3127", "mrqa_newsqa-validation-3060", "mrqa_newsqa-validation-3246", "mrqa_newsqa-validation-3322", "mrqa_newsqa-validation-2563", "mrqa_newsqa-validation-999", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-1429", "mrqa_newsqa-validation-34", "mrqa_newsqa-validation-3555", "mrqa_newsqa-validation-2960", "mrqa_newsqa-validation-242", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-681", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-2735", "mrqa_naturalquestions-validation-9728", "mrqa_triviaqa-validation-1217", "mrqa_hotpotqa-validation-4692"], "SR": 0.59375, "CSR": 0.5369318181818181, "EFR": 1.0, "Overall": 0.7154332386363637}, {"timecode": 66, "before_eval_results": {"predictions": ["Jeffery Deaver", "sonar jamming", "Pete Best", "Robert Taylor", "Vincent Van Gogh", "Spain", "about a mile north of the village of Dunvegan", "the 114.5 metre sculpture", "\"lodges\"", "Stilwell", "the Soviet Union", "the solar system", "coelacanth", "Belgium", "Dennis Potter", "Calcium", "Eric Coates", "Geoffrey Cox", "Mel Brooks", "California condor", "Ohio", "wind turbines", "tabidan Grizelda", "The Bill", "0", "Hamlet", "Johannesburg", "Crackerjack pencil", "Bleak House", "Rodgers and Hammerstein", "Spain", "Minder", "mustard", "Les Dennis", "Kansas City", "\"Book 1: Sowing\"", "toscana (Tuscany) Region", "tallest building in the world", "Singapore", "Scooby-Doo!", "Pakistan International Airlines", "gold, red, blue, black and white", "France", "Tomorrow Never Dies", "jaundice", "Hong Kong", "Chuck Yeager", "budita Melody Lysette Langford", "northern France", "stamp collecting", "Moby Dick", "Red Sea and the east African coast across the Indian Ocean, and across the Pacific Ocean to the west coast of Central America", "12.9 - kilometre ( 8 mi )", "a sociological perspective", "21 July 2015", "Bern", "28 June 1945", "not", "25", "Pakistan", "Yves Saint Laurent", "Eric Clapton", "Topix", "his business dealings for possible securities violations"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6523065476190477}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, true, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.2, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.6666666666666666, 0.0, 0.0, 0.4, 0.2857142857142857, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.09523809523809525, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6]}}, "before_error_ids": ["mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-5468", "mrqa_triviaqa-validation-1833", "mrqa_triviaqa-validation-89", "mrqa_triviaqa-validation-1954", "mrqa_triviaqa-validation-2376", "mrqa_triviaqa-validation-1698", "mrqa_triviaqa-validation-7211", "mrqa_triviaqa-validation-6792", "mrqa_triviaqa-validation-4722", "mrqa_triviaqa-validation-4401", "mrqa_triviaqa-validation-5940", "mrqa_triviaqa-validation-7335", "mrqa_triviaqa-validation-3366", "mrqa_triviaqa-validation-1294", "mrqa_triviaqa-validation-3663", "mrqa_triviaqa-validation-7066", "mrqa_triviaqa-validation-821", "mrqa_triviaqa-validation-4003", "mrqa_triviaqa-validation-7164", "mrqa_triviaqa-validation-613", "mrqa_naturalquestions-validation-6452", "mrqa_naturalquestions-validation-1450", "mrqa_hotpotqa-validation-4788", "mrqa_newsqa-validation-1330", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-11790", "mrqa_newsqa-validation-2682"], "SR": 0.546875, "CSR": 0.537080223880597, "EFR": 1.0, "Overall": 0.7154629197761194}, {"timecode": 67, "before_eval_results": {"predictions": ["to convert single - stranded genomic RNA into double - stranded cDNA", "Alaska", "Christina Pickles", "August 9, 1945", "after obtaining the consent of the United Kingdom", "products under the same name", "Olivia Olson", "Beijing", "Pyeongchang County, South Korea", "928", "April 7, 2016", "5.7 million customer accounts", "Wembley Stadium", "the President", "David Joseph Madden", "The Fixx", "at night", "Jack Nicklaus", "Plank", "Executive Residence of the White House Complex", "Royal Air Force", "sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "the benefits of the US Privacy Act", "around the time when ARPANET was interlinked with NSFNET in the late 1980s", "18th century", "Mariah Carey", "Spektor", "H CO", "seven", "September of that year", "Gertrude Niesen", "October 14, 2017", "Krypton", "November 25, 2002", "IBM", "Ukrainian Soviet Socialist Republic", "435", "sport utility vehicles", "Elk and Kanawha Rivers", "The Bellamy Brothers", "because of the way they used `` rule '' and `` method '' to go about their religious affairs", "Massachusetts", "the plane crash", "Sir Mix - a-Lot", "June 1991", "July 8, 1997", "New Zealand", "Frank Oz", "1954", "2010", "Missouri River", "malmesbury", "viola", "france", "John Churchill, 1st Duke of Marlborough", "Gregg Popovich", "Asiana Town", "Araceli Valencia,", "people", "16 Indiana National Guard soldiers", "bees", "Jefferson Davis", "Farsi (Persian)", "emphasis or heightened effect"], "metric_results": {"EM": 0.5, "QA-F1": 0.5923186873433584}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, true, false, true, false, false, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, false, true, true, true, true, false], "QA-F1": [0.5263157894736842, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.1904761904761905, 1.0, 1.0, 1.0, 0.0, 0.7368421052631579, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 0.5, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 0.25, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1974", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4414", "mrqa_naturalquestions-validation-7635", "mrqa_naturalquestions-validation-1344", "mrqa_naturalquestions-validation-8584", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-950", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-677", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-3182", "mrqa_naturalquestions-validation-3285", "mrqa_naturalquestions-validation-8688", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-5511", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6383", "mrqa_triviaqa-validation-5828", "mrqa_triviaqa-validation-4085", "mrqa_triviaqa-validation-6897", "mrqa_hotpotqa-validation-2886", "mrqa_hotpotqa-validation-1702", "mrqa_newsqa-validation-2025", "mrqa_newsqa-validation-335", "mrqa_triviaqa-validation-4040"], "SR": 0.5, "CSR": 0.5365349264705883, "EFR": 0.9375, "Overall": 0.7028538602941177}, {"timecode": 68, "before_eval_results": {"predictions": ["france", "Roberta Flack", "sesame", "infante", "Sunday", "barnaby rudge", "Buddha", "Ethiopia", "1963", "discus thrower", "tabloid", "the Sidgwick Avenue arts faculty", "Chester Racecourse", "york", "Jews", "Romanian", "saint basil", "Peru", "the keel", "Evander Holyfield", "crosse", "Buddhism", "new Orleans", "soda", "fat like oil or lard", "Steve Hansen", "brashy", "Ken Burns", "paddy doherty", "Barry Howard and Diane Holland", "phi", "Hungary", "So Solid Crew", "Yardbirds", "Pennsylvania", "the Caucasus", "scotland", "morningtown Ride", "Jupiter", "watch with mother", "son or daughter", "8", "Queens Park Rangers", "wake", "giants", "flannel", "b\u00e9la mal\u00e1zs", "Hugh Dowding", "Montpelier", "February", "king johnson", "every year", "318", "Chris Rea", "Tomasz Adamek", "a scholar during the Joseon Dynasty who begins to write erotic novels, and becomes the lover of the King's favorite concubine", "March 30, 2025", "Amanda Knox's aunt Janet Huff", "Gulf of Aden,", "rabbit hole,", "planted", "Russia", "Crackle", "Carter"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5489087301587302}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, false, true, true, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, true, false, true, false, false, true, false, true, false, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_triviaqa-validation-2948", "mrqa_triviaqa-validation-7661", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-643", "mrqa_triviaqa-validation-5458", "mrqa_triviaqa-validation-1786", "mrqa_triviaqa-validation-4946", "mrqa_triviaqa-validation-2190", "mrqa_triviaqa-validation-7645", "mrqa_triviaqa-validation-7499", "mrqa_triviaqa-validation-2330", "mrqa_triviaqa-validation-6464", "mrqa_triviaqa-validation-6849", "mrqa_triviaqa-validation-826", "mrqa_triviaqa-validation-6533", "mrqa_triviaqa-validation-214", "mrqa_triviaqa-validation-5258", "mrqa_triviaqa-validation-3236", "mrqa_triviaqa-validation-1193", "mrqa_triviaqa-validation-4768", "mrqa_triviaqa-validation-4652", "mrqa_triviaqa-validation-5860", "mrqa_triviaqa-validation-3362", "mrqa_triviaqa-validation-1848", "mrqa_triviaqa-validation-955", "mrqa_triviaqa-validation-4490", "mrqa_naturalquestions-validation-5317", "mrqa_hotpotqa-validation-412", "mrqa_newsqa-validation-3210", "mrqa_newsqa-validation-638", "mrqa_searchqa-validation-6026", "mrqa_searchqa-validation-10485", "mrqa_searchqa-validation-7826"], "SR": 0.484375, "CSR": 0.5357789855072463, "EFR": 1.0, "Overall": 0.7152026721014492}, {"timecode": 69, "before_eval_results": {"predictions": ["oregon", "Jeffrey arthur", "Chicago", "filly", "dar es salaam", "Sarah Keays", "miss marple", "elkie Brooks", "what can Brown do", "graham perolari", "piano", "cestrian", "Bennet", "spice girls", "glycerol", "addams", "oscar", "beetles", "arthur", "graaves", "Harry Shearer", "9-13 years", "pirate day", "farthings", "spice girls", "48 Hours", "arthurian", "Dutch", "tombstone", "Nietzsche", "cestrian", "South Africa", "bagram", "pygmalion", "English", "cassis", "dieppe", "dengue fever", "left-wing", "triathlon", "barbershop quartet", "the splitting of cells into additional cell bodies", "something in The Air", "\"sound and light\"), or a sound and light show", "what", "fox terrier", "arthur", "raclette", "kilimanjaro", "magic Circle", "european", "to start fires, hunt, and bury their dead", "Wimbledon, London", "Cordelia", "London Luton Airport", "Sarah Winnemucca Hopkins", "wild boar, and red, fallow and roe deer", "he said Chaudhary's death should serve as a warning to management,", "they don't feelMisty Cummings, then known asMisty Croslin, was the last person known to have seen Haleigh and her 4-year-old brother into bed about 8 p.m.", "he spent the first night in his car.\"", "Vanilla Ice", "Wordsworth", "Voltaire", "the summit of Cadillac Mountain"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5015473803157626}, "metric_results_detailed": {"EM": [true, false, false, false, true, true, true, true, false, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, false, true, false, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, true, true], "QA-F1": [1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5454545454545454, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5454545454545454, 0.6666666666666666, 0.0, 0.5, 0.0, 0.11764705882352941, 0.0, 0.05714285714285714, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1706", "mrqa_triviaqa-validation-4264", "mrqa_triviaqa-validation-3186", "mrqa_triviaqa-validation-7669", "mrqa_triviaqa-validation-2321", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-4988", "mrqa_triviaqa-validation-4618", "mrqa_triviaqa-validation-356", "mrqa_triviaqa-validation-5295", "mrqa_triviaqa-validation-478", "mrqa_triviaqa-validation-2639", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-4412", "mrqa_triviaqa-validation-2018", "mrqa_triviaqa-validation-6478", "mrqa_triviaqa-validation-2422", "mrqa_triviaqa-validation-5378", "mrqa_triviaqa-validation-6127", "mrqa_triviaqa-validation-1030", "mrqa_triviaqa-validation-4654", "mrqa_triviaqa-validation-7513", "mrqa_triviaqa-validation-2411", "mrqa_triviaqa-validation-1346", "mrqa_triviaqa-validation-4970", "mrqa_naturalquestions-validation-6736", "mrqa_naturalquestions-validation-8147", "mrqa_naturalquestions-validation-9011", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-5735", "mrqa_hotpotqa-validation-1716", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-3771", "mrqa_newsqa-validation-3627", "mrqa_searchqa-validation-3002"], "SR": 0.4375, "CSR": 0.534375, "EFR": 1.0, "Overall": 0.7149218749999999}, {"timecode": 70, "before_eval_results": {"predictions": ["Geraldine Margaret Agnew", "a complex sentence", "Australia", "Ashrita Furman", "No Secrets", "1994", "2010", "12 November 2010", "1 October 2006", "1977", "2018", "Missouri", "Swedien and Jones", "in 1902", "Frederick Chiluba", "4 January 2011", "Dougie MacLean", "the band's logo in gold lettering over black sleeve", "1999", "the city of Indianapolis", "the topography and the dominant wind direction, several climatic types occur which can be the same as found in temperate latitudes, and even polar regions", "blighted ovum or anembryonic gestation", "Michael Rosen", "Jos\u00e9 Mart\u00ed", "103", "Van Halen", "$100", "the referee", "Bonhomme Carnaval", "26 \u00b0 37 \u2032 N 81 \u00b0 50 \u2032 W", "the end of the episode", "around 2011", "New Jersey, United States", "ulnar nerve", "2018", "19th - century", "large ( 0.3 to 1.0 in or 0.76 to 2.54 cm )", "Western Australia", "Carol Worthington", "1830", "chemicals", "thanksgiving for a good harvest", "born November 28, 1973", "a contemporary drama in a rural setting", "Justice Harlan", "Bart Howard", "Triple threat", "Bangalore", "Anthony Hopkins", "Jesus Christ", "1996", "holography", "france", "martin", "Gillian Anderson", "direct scattering and inverse scattering", "45th Infantry Division", "\"it should stay that way.\"", "2009", "an open window", "Menotti", "Coleridge", "Pygmalion", "the yen"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6956706640989729}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, false, true, false, true, true, false, false, false, true, true, true, false, false, false, true, true, true, false, true, true, true, false, false, false, true, false, true, false, true, true, false, false, true, true], "QA-F1": [0.8571428571428571, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 0.823529411764706, 1.0, 0.0, 0.0, 0.8333333333333333, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.7142857142857143, 0.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 0.11764705882352941, 0.5714285714285715, 1.0, 1.0, 1.0, 0.888888888888889, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8333333333333333, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8314", "mrqa_naturalquestions-validation-7632", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9867", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-10040", "mrqa_naturalquestions-validation-3556", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-3721", "mrqa_naturalquestions-validation-8117", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-8417", "mrqa_naturalquestions-validation-1049", "mrqa_naturalquestions-validation-805", "mrqa_naturalquestions-validation-6995", "mrqa_naturalquestions-validation-1705", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-6113", "mrqa_naturalquestions-validation-2556", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-7692", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-6168", "mrqa_triviaqa-validation-5434", "mrqa_hotpotqa-validation-706", "mrqa_newsqa-validation-2658", "mrqa_searchqa-validation-4464", "mrqa_searchqa-validation-2541"], "SR": 0.546875, "CSR": 0.5345510563380282, "EFR": 0.896551724137931, "Overall": 0.6942674310951918}, {"timecode": 71, "before_eval_results": {"predictions": ["John Goodman", "Brooke Wexler", "Lou Rawls", "A\u00e7a\u00ed palm ( Euterpe oleracea )", "elected to their positions in the Senate by their respective party caucuses, the Senate Democratic Caucus and the Senate Republican Conference", "David Gahan ( / \u0261\u0251\u02d0n / ; born David Callcott ; 9 May 1962 )", "the ball is fed into the gap between the two forward packs and they both compete for the ball to win possession", "the third season", "on the table or, more formally, may be kept on a side table", "red", "off the rez", "either in front or on top of the brainstem", "On March 14, 1942", "Aegisthus and Thyestes", "Epithelium", "Erika Mitchell Leonard", "American production duo The Chainsmoker", "Vincent Price", "India", "Tessa Peake - Jones", "It is an expected or free or continuously changing behaviour and may have a given individual social status or social position", "United Nations Peacekeeping Operations", "It is part of the normal flora of the human colon and is generally commensal, but can cause infection if displaced into the bloodstream or surrounding tissue following surgery, disease, or trauma", "a religious covenant that is described in the Bible", "Shirley Mae Jones", "Heat transfer by thermal radiation may be minimized by silvering flask surfaces facing the gap", "Luke 6 : 12 -- 16", "theatrically released in the United States on August 19, 2016", "Sets heart in mediastinum and limits its motion", "The word first came into common usage in the late 18th century", "Terrell Suggs", "celebrity alumna Cecil Lockhart", "August 22, 1980", "the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "a large, high - performance luxury coupe sold in very limited numbers", "The New Day would continue to successfully retain their championship against Gallows and Anderson in the following months, such as SummerSlam on August 21, Clash of Champions on September 25 and the following night on Raw", "part of Virginia State Route 48, which also includes the Virginia portion of the Blue Ridge Parkway, but this designation is not signed", "the Confederacy", "The melody and the first three verses were written by Pete Seeger in 1955 and published in Sing Out!. magazine", "acceptors via redox ( both reduction and oxidation occurring simultaneously ) reactions, and couples this electron transfer with the transfer of protons ( H ions ) across a membrane", "2", "Montreal Canadiens", "in the 1960s", "On 1 September 1939, on 3 September, after a British ultimatum to Germany to cease military operations was ignored, Britain and France declared war on Germany", "three", "a so called minimum viable product that addresses and solves a problem or need that exists", "Wyatt `` Dusty '' Chandler ( George Strait )", "last book", "In the 1920s, Louis W. Sauer developed a weak vaccine for whooping cough at Evanston Hospital ( Evanston, IL )", "ice giants", "on what became known to locals as `` Black Monday '', and continued into the mid-1980s", "Camellia sinensis", "european economic community", "Mumbai", "Frank Fertitta, Jr.", "\"Coronation Street\"", "Michael A. Cremo", "backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry rewards.", "complicated and deeply flawed", "a house party in Crandon, Wisconsin,", "Butterflies", "Rocky Mountain spotted fever", "$500", "drug labs, markets and convoys."], "metric_results": {"EM": 0.390625, "QA-F1": 0.5139109872955444}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, false, true, false, true, false, true, false, false, false, true, false, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, true, false, true, false, true, true, true, false, false, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.5, 1.0, 0.35294117647058826, 0.75, 1.0, 0.0, 1.0, 0.11428571428571428, 0.0, 0.12903225806451613, 0.22222222222222224, 1.0, 0.7272727272727273, 1.0, 0.5, 1.0, 0.125, 0.0, 0.6666666666666666, 1.0, 0.15384615384615385, 0.18181818181818182, 0.0, 0.0625, 1.0, 0.10526315789473684, 0.08, 1.0, 1.0, 0.0, 0.07692307692307693, 1.0, 0.0, 0.5714285714285715, 1.0, 0.11764705882352941, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.967741935483871, 0.0, 0.28571428571428575, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5242", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-1528", "mrqa_naturalquestions-validation-7264", "mrqa_naturalquestions-validation-2024", "mrqa_naturalquestions-validation-6305", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-7012", "mrqa_naturalquestions-validation-5114", "mrqa_naturalquestions-validation-10501", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-8393", "mrqa_naturalquestions-validation-627", "mrqa_naturalquestions-validation-9154", "mrqa_naturalquestions-validation-3347", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-1471", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-2164", "mrqa_naturalquestions-validation-6049", "mrqa_naturalquestions-validation-1813", "mrqa_naturalquestions-validation-2682", "mrqa_naturalquestions-validation-6333", "mrqa_naturalquestions-validation-8439", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-7912", "mrqa_naturalquestions-validation-7089", "mrqa_naturalquestions-validation-9774", "mrqa_triviaqa-validation-3027", "mrqa_hotpotqa-validation-1747", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-843", "mrqa_newsqa-validation-2315", "mrqa_searchqa-validation-2419", "mrqa_searchqa-validation-2088", "mrqa_newsqa-validation-2177"], "SR": 0.390625, "CSR": 0.5325520833333333, "EFR": 0.9743589743589743, "Overall": 0.7094290865384615}, {"timecode": 72, "before_eval_results": {"predictions": ["Earth Day", "Afghanistan", "lecithin", "suffrage", "Gamgee", "Christopher Darden", "a Jelly Belly", "a cloudy day", "(Dan) Berrigan", "wheat", "Carole King", "Spain", "The Pro-Jig Clamp Set", "Christo", "Wichita", "U.S. Department of Agriculture", "Gilligan's Island", "Penelope", "Tom Harkin", "the Channel Islands", "Krackel", "Penelope", "aronoun", "Bonobo", "Harry's Harbor", "Veep", "a naval", "lullaby", "a ruby", "Pan's Labyrinth", "Barrie", "John Irving", "a demonstrative pronoun", "the Who", "Europe and Asia", "Xerox", "a virgin", "Pierre Trudeau", "earned run average", "anxiety disorder", "World War II", "Beijing", "(Lee) Oswald", "(George) Armstrong Custer", "Newton's Second Law", "a breath", "Orlando", "Alaska", "a puff", "The Mausoleum at Halicarnassus", "Qi", "Number 4, Privet Drive, Little Whinging in Surrey, England", "John Smith", "L.K. Advani, an Indian politician who served as the Deputy Prime Minister of India from 2002 to 2004, and was the Leader of the Opposition in the 15th Lok Sabha", "Matthew", "seattle", "saint cecilia", "Germany", "1989 until 1994", "Suzuki YZF-R6", "the nose, cheeks, upper jaw and facial tissue from a female cadaver", "Joan Rivers", "three", "Kim Bauer"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6589246553884711}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, true, false, false, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, false, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, false, false, true, true, true, true, false, true, true, false, false, false, true, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.9473684210526316, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6525", "mrqa_searchqa-validation-383", "mrqa_searchqa-validation-14432", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-9796", "mrqa_searchqa-validation-12366", "mrqa_searchqa-validation-5330", "mrqa_searchqa-validation-10141", "mrqa_searchqa-validation-2375", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-3499", "mrqa_searchqa-validation-2136", "mrqa_searchqa-validation-2799", "mrqa_searchqa-validation-12661", "mrqa_searchqa-validation-2902", "mrqa_searchqa-validation-4115", "mrqa_searchqa-validation-10453", "mrqa_searchqa-validation-6714", "mrqa_searchqa-validation-2800", "mrqa_searchqa-validation-960", "mrqa_searchqa-validation-13584", "mrqa_searchqa-validation-12352", "mrqa_searchqa-validation-9881", "mrqa_triviaqa-validation-6286", "mrqa_hotpotqa-validation-2319", "mrqa_hotpotqa-validation-1741", "mrqa_newsqa-validation-1681"], "SR": 0.578125, "CSR": 0.5331763698630136, "EFR": 0.9629629629629629, "Overall": 0.7072747415651952}, {"timecode": 73, "before_eval_results": {"predictions": ["Hairspray", "Happy Days", "Rita Mae Brown", "Bolivia and Paraguay", "Kansas", "grasshopper", "the commander", "Sure", "1876", "brood", "a bystander", "The Big Sleep", "Maryland", "Lowenbrau", "the pen", "Herod", "the Lone Ranger", "Malaysia", "Georgetown University", "Bruce Rauner", "Mickey Mouse", "the Walter Payton", "Mount Everest", "(Winston) Rodney", "a pindar poem", "a duck", "the Tom Thumb", "the Island of Kent", "the Mad Hatter", "sleepiness", "Cincinnati", "to aid the athlete", "a concert grand", "ketchup", "peanut butter", "soccer", "Tom Petty and the Heartbreakers", "Tuscany", "Tunisia", "Rosa Parks", "the inch", "France", "William Henry Harrison", "Corinthian", "carats", "Bern", "Prada", "Chicago", "the umbilical cord", "Pinta", "possible", "October 22, 2017", "Terrell Owens", "February 27, 2015", "tipping point", "scotland", "epeiric (or \"shelf\") sea", "James Harden", "eworldly wave", "Ronald Lyle \" Ron\" Goldman", "\"Sesame Street\"", "usion teams", "Rolling Stone", "Ren\u00e9 Descartes"], "metric_results": {"EM": 0.6875, "QA-F1": 0.7520833333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, false, false, false, true, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3333333333333333, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14786", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-13681", "mrqa_searchqa-validation-12916", "mrqa_searchqa-validation-16907", "mrqa_searchqa-validation-12228", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-8753", "mrqa_searchqa-validation-14945", "mrqa_searchqa-validation-4837", "mrqa_searchqa-validation-13871", "mrqa_searchqa-validation-10415", "mrqa_searchqa-validation-7656", "mrqa_searchqa-validation-16369", "mrqa_searchqa-validation-15724", "mrqa_triviaqa-validation-4662", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-2410", "mrqa_newsqa-validation-3105", "mrqa_newsqa-validation-510"], "SR": 0.6875, "CSR": 0.5352618243243243, "EFR": 1.0, "Overall": 0.7150992398648649}, {"timecode": 74, "before_eval_results": {"predictions": ["Urban Outfitters", "The Tyger", "\"The River\"", "The Last Supper", "Baccarat", "a bishop", "Harlem", "(Jheronimus) Bosch", "hull", "a drug rehab", "a cricket", "India", "Children of Men", "Alaska", "a petition", "Hippolyta", "a Species", "John Galt", "spinach", "milk", "1,000 watts", "a toadstool", "World War I", "a student loan", "the Gateway Arch", "Itzhak Perlman", "( Wolfgang) Streep", "Dachshund", "the Monitor", "Cyprus", "Milwaukee", "Coffee milk", "Kevin Costner", "the \"Hot Lips\" Houlihan", "Isadora Duncan", "Pig Latin", "Little Debbie", "( Gerald) Ford", "Speed Racer", "U.S.A", "Aristotle", "(ER)", "the Eagles", "An American Tail", "a Starline Tour bus", "an argyle", "Toyota", "(Setonix brachyurus)", "a leather feather", "Mark Twain", "Thomas Gibson", "30 October 1918", "Johnny Darrell", "Michael Moriarty", "(James Christopher) Bolam", "pawn", "brazil", "House of Habsburg-Lorraine", "the new rank of \"SS-Oberst-Gruppenf\u00fchrer\"", "Kansas\u2013Nebraska Act of 1854", "Orbiting Carbon Observatory,", "South Africa", "Tuesday.", "two"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6734374999999999}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, false, false, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, true, true, true, false, true, false, false, true, true, false, true, false, true, false, true, false, true, false, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.8, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9795", "mrqa_searchqa-validation-2629", "mrqa_searchqa-validation-11529", "mrqa_searchqa-validation-1283", "mrqa_searchqa-validation-8228", "mrqa_searchqa-validation-13235", "mrqa_searchqa-validation-16232", "mrqa_searchqa-validation-13579", "mrqa_searchqa-validation-16121", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-4180", "mrqa_searchqa-validation-5816", "mrqa_searchqa-validation-10468", "mrqa_searchqa-validation-16046", "mrqa_searchqa-validation-16543", "mrqa_searchqa-validation-11419", "mrqa_searchqa-validation-4652", "mrqa_searchqa-validation-3857", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-774", "mrqa_searchqa-validation-9788", "mrqa_naturalquestions-validation-4288", "mrqa_triviaqa-validation-1400", "mrqa_triviaqa-validation-3779", "mrqa_hotpotqa-validation-686", "mrqa_hotpotqa-validation-837"], "SR": 0.59375, "CSR": 0.5360416666666667, "EFR": 1.0, "Overall": 0.7152552083333333}, {"timecode": 75, "before_eval_results": {"predictions": ["the Islamic prophet Muhammad", "following the 2017 season", "to the country", "from 1900 to 1920", "at specific locations, or origins of replication, in the genome", "Javier Fern\u00e1ndez", "Michael Crawford", "silk floss", "Hold On", "Gustav Bauer", "November 2016", "Empiricism", "Evaluation of alternative plans / policies", "Augustus Waters, an ex-basketball player and amputee", "continent of North America", "Johnson", "Song of Songs", "Taron Egerton", "its vast territory was divided into several successor polities", "acronym", "Sheev Palpatine", "Divyanka Tripathi and Karan Patel", "September 24, 2012", "Only two men", "Michael Christopher McDowell", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "the homicidal thoughts of a troubled youth", "John C. Reilly", "Daniel A. Dailey", "Mickey Mantle", "to addition, subtraction, multiplication, and division are represented by the +, -, *, and / keys, respectively.", "December 15, 2016", "Kid Creole and the Coconuts", "immediately follows the year 1 BC", "2010", "a microfilament", "1983", "John Roberts", "the President of the United States", "1978", "Ravi River", "May 19, 2017", "47 cents", "Sri Lanka Podujana Peramuna, led by former president Mahinda Rajapaksa", "1773", "Buddhism", "introverted Sensing ( Si ), Extroverted Thinking ( Fi ) and Extrovert Intuition ( Ne ) )", "March 16, 2018", "Joseph M. Scriven", "Heat transfer by thermal radiation may be minimized", "Frederik Barth", "peacock", "midland", "t.S. Eliot", "Russell Humphreys", "Hickam Air Force Base", "Rihanna", "comments had been taken out of context.", "fractured pelvis and sacrum", "2001", "to recognize gain or loss on the settlement of foreign currency", "Blackbird", "Meredith Grey", "September 25, 2017"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6591257700632701}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, true, false, true, true, false, false, true, false, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [0.5, 0.0, 0.0, 0.4, 0.7142857142857143, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.14285714285714285, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.4615384615384615, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.22222222222222224, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6637", "mrqa_naturalquestions-validation-2552", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-9440", "mrqa_naturalquestions-validation-9670", "mrqa_naturalquestions-validation-4074", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-9119", "mrqa_naturalquestions-validation-7312", "mrqa_naturalquestions-validation-3859", "mrqa_naturalquestions-validation-5502", "mrqa_naturalquestions-validation-5986", "mrqa_naturalquestions-validation-5096", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-10364", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-4419", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-1368", "mrqa_naturalquestions-validation-6706", "mrqa_triviaqa-validation-6929", "mrqa_triviaqa-validation-813", "mrqa_hotpotqa-validation-5781", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-3561", "mrqa_newsqa-validation-1576", "mrqa_searchqa-validation-5337", "mrqa_searchqa-validation-14889"], "SR": 0.5625, "CSR": 0.536389802631579, "EFR": 1.0, "Overall": 0.7153248355263158}, {"timecode": 76, "before_eval_results": {"predictions": ["makes Maria a dress to wear to the neighborhood dance", "Walter Mondale", "state ownership of the means of production, collective farming, industrial manufacturing and centralized administrative planning", "1942", "awarded to the team that lost the pre-game coin toss", "21 June 2007", "at least 28", "Donald Trump", "24 hours", "Universal Pictures and Focus Features", "multiple origins of replication on each linear chromosome that initiate at different times ( replication timing ), with up to 100,000 present in a single human cell", "restarting play after a minor infringement", "A footling breech", "Mockingjay -- Part 2 ( 2015 )", "the President of India", "cunnilingus", "28 %", "Gladys Music, Presley's publishing company", "are a Native American nation from the Great Plains whose historic territory, known as Comancheria, consisted of present - day eastern New Mexico, southeastern Colorado, southwestern Kansas, western Oklahoma, northern Chihuahua", "Jack Scanlon", "the eighth episode of Arrow's second season", "Elijah Wood", "head - up", "Doug Pruzan", "by October 1986", "Melanie Martinez", "in organelles, such as mitochondria or chloroplasts", "pathology", "age of about 14", "Thomas Hobbes in his Leviathan", "William the Conqueror", "Shawn Wayans", "Wisconsin", "slavery", "differ in ingredients", "Bali, Indonesia", "Panzerkampfwagen VIII Maus ( `` Mouse '' )", "exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee", "toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise", "New England", "40 %", "Janie Crawford's `` ripening from a vibrant, but voiceless, teenage girl into a woman with her finger on the trigger of her own destiny", "in the east coast of Queensland", "April 2, 2018", "Lana Del Rey", "Jerry Leiber and Mike Stoller", "Sonu Nigam", "Arnold Schoenberg", "Boston Bruins", "around 1872", "Colman", "starch", "carbon", "on the first Monday of September", "Prudential Center in Newark, New Jersey", "Lisburn Distillery Football Club", "Ken Howard", "one", "Government Accountability Office report", "write-off against ethnic Somalis by rebels and Ethiopian troops are rampant.", "double-breasted", "Heroes", "to name the demons", "since 1983."], "metric_results": {"EM": 0.421875, "QA-F1": 0.6033608701347672}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, false, true, false, true, true, false, true, false, false, false, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, true, true, false, false, false, true, true, false, false, true, true, false, false], "QA-F1": [0.13333333333333333, 0.0, 0.25, 1.0, 1.0, 0.0, 0.26666666666666666, 0.0, 0.8, 1.0, 0.5, 1.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.0, 0.0, 0.35294117647058826, 1.0, 0.7692307692307692, 0.5714285714285715, 0.8, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.8571428571428571, 0.0, 0.4615384615384615, 0.0, 0.0, 0.09090909090909091, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.4, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-4664", "mrqa_naturalquestions-validation-952", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-9467", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2014", "mrqa_naturalquestions-validation-1659", "mrqa_naturalquestions-validation-1427", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-2323", "mrqa_naturalquestions-validation-42", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-9330", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-750", "mrqa_naturalquestions-validation-5007", "mrqa_naturalquestions-validation-3707", "mrqa_naturalquestions-validation-9487", "mrqa_naturalquestions-validation-359", "mrqa_naturalquestions-validation-7336", "mrqa_naturalquestions-validation-8823", "mrqa_naturalquestions-validation-7246", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-390", "mrqa_naturalquestions-validation-1459", "mrqa_naturalquestions-validation-8301", "mrqa_naturalquestions-validation-10195", "mrqa_naturalquestions-validation-4719", "mrqa_naturalquestions-validation-5719", "mrqa_triviaqa-validation-3040", "mrqa_hotpotqa-validation-5804", "mrqa_hotpotqa-validation-218", "mrqa_newsqa-validation-3856", "mrqa_newsqa-validation-2043", "mrqa_searchqa-validation-15577", "mrqa_newsqa-validation-377"], "SR": 0.421875, "CSR": 0.5349025974025974, "EFR": 0.972972972972973, "Overall": 0.709621989075114}, {"timecode": 77, "before_eval_results": {"predictions": ["herpes virus", "zork", "roddy dogger", "phoebus dicksens", "Prussia", "jennifer kipling", "Spongebob", "Exile", "an enclave which is entirely enclosed by another nation.", "South Dakota", "Brian Close", "cabbage worm", "Leeds", "Edinburgh", "a meter maid", "cricket", "switzerland", "phoebus", "phoebus", "phobia", "leicestershire", "carry On Cleo", "phoebus", "sense of taste", "snare drum", "shallow seas", "sesame", "hurdles", "The Centaurs", "tallest building", "football", "phonies", "peter Rabbit and Hunca-Munca", "Giglio Island", "czech republic", "jennifer alberta stanyan Street and the Golden Gate Park Panhandle", "phoebus", "Harry patch", "funny Folks", "an British film magazine published 13 times a year (every four weeks) by Future Publishing", "wren", "ra(dio) d(etecting a(nd) r(anging)", "Nelson Mandela", "Today", "confetti", "phoebus", "Mark Darcy", "reptilian", "landmasses", "salyut 1", "japan", "Evermoist", "62", "Matthew Gregory Wise", "1861", "Zola", "Limbo", "12.3 million", "July", "U.S. Vice President Dick Cheney", "New Hampshire", "a miniskirt", "the fathom", "$163 million (180 million Swiss francs)"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5130208333333333}, "metric_results_detailed": {"EM": [false, false, false, false, true, false, true, true, false, true, true, false, true, true, true, true, false, false, false, false, true, true, false, false, false, false, true, false, true, true, false, false, false, false, false, false, false, true, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, true, true, false, true, true, false, true, true, true, true, false], "QA-F1": [0.5, 0.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.5]}}, "before_error_ids": ["mrqa_triviaqa-validation-2781", "mrqa_triviaqa-validation-3244", "mrqa_triviaqa-validation-4651", "mrqa_triviaqa-validation-5462", "mrqa_triviaqa-validation-7531", "mrqa_triviaqa-validation-2443", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-2233", "mrqa_triviaqa-validation-7709", "mrqa_triviaqa-validation-2362", "mrqa_triviaqa-validation-1171", "mrqa_triviaqa-validation-3917", "mrqa_triviaqa-validation-1204", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-2359", "mrqa_triviaqa-validation-7059", "mrqa_triviaqa-validation-479", "mrqa_triviaqa-validation-3465", "mrqa_triviaqa-validation-1835", "mrqa_triviaqa-validation-5990", "mrqa_triviaqa-validation-2432", "mrqa_triviaqa-validation-5170", "mrqa_triviaqa-validation-765", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-720", "mrqa_triviaqa-validation-7167", "mrqa_triviaqa-validation-3484", "mrqa_triviaqa-validation-57", "mrqa_triviaqa-validation-520", "mrqa_triviaqa-validation-3713", "mrqa_triviaqa-validation-4918", "mrqa_triviaqa-validation-2317", "mrqa_hotpotqa-validation-5278", "mrqa_newsqa-validation-3866", "mrqa_newsqa-validation-4029"], "SR": 0.4375, "CSR": 0.5336538461538461, "EFR": 0.9722222222222222, "Overall": 0.7092220886752136}, {"timecode": 78, "before_eval_results": {"predictions": ["Three", "he believed he was about to be attacked himself.", "1964", "paid tribute to pop legend Michael Jackson,", "\"momentous discovery\"", "Al-Aqsa mosque", "finished on top again in the final session with a 74 stand", "as soon as 2050,", "Sylt", "media", "in the southern city of Najaf.", "Barack Obama", "Arnoldo Rueda Medina.", "left his indelible fingerprints on the entertainment industry.", "ketamine.", "Brian David Mitchell,", "Defense of Marriage", "Jacob,", "Ronaldinho", "Bush family political dynasty, the British royal family, Frank Sinatra, Elizabeth Taylor, Jacqueline Kennedy Onassis and Nancy Reagan.", "people will be malicious and try to compromise peoples' health using computers, especially if neural devices become more widespread.\"", "1957", "start a dialogue of peace based on the conversations she had with Americans along the way.", "al Qaeda,", "Manmohan Singh's", "help the convicts find calmness in a prison", "J. Crew.", "turning on in the first place.", "10,000", "Meira Kumar", "antihistamine and an epinephrine auto-injector", "CNN", "allegations that a dorm parent mistreated students at the school.", "Virgin America", "1940's Japan.", "Arthur E. Morgan III,", "million dollars", "bribing other wrestlers to lose bouts,", "Eleven", "\"the evidence and investigatory effort has minimized the likelihood that Haleigh's disappearance is the work of a strangers.\"", "(3 degrees Fahrenheit),", "Steven Gerrard", "$8.8 million", "Karl Eikenberry", "\"The Closer.\"", "Carol Browner", "conviction of Peru's ex-president is a warning to those who deny human rights", "Brazil", "top 50", "the return of a fallen U.S. service member", "designers", "George Quinn as Craig Belden", "early Christians of Mesopotamia", "16 seasons", "e pluribus unum", "well", "China", "Capture of the Five Boroughs", "Double Crossed", "pornographicstar", "the burning bush", "water", "Fannie Farmer", "liberty as its main idea, promoting free expression, freedom of choice, other social freedoms, and \"laissez-faire\" capitalism"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6389880952380953}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, false, true, true, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, true, true, true, true, false, false, false, false, false, false, true, true, true, false, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 0.14285714285714285, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.1, 1.0, 1.0, 0.14285714285714288, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.5, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.19047619047619047]}}, "before_error_ids": ["mrqa_newsqa-validation-38", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-1351", "mrqa_newsqa-validation-2731", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-4080", "mrqa_newsqa-validation-1606", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2370", "mrqa_newsqa-validation-403", "mrqa_newsqa-validation-3695", "mrqa_newsqa-validation-3782", "mrqa_newsqa-validation-1175", "mrqa_newsqa-validation-1671", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-869", "mrqa_newsqa-validation-3572", "mrqa_newsqa-validation-1123", "mrqa_newsqa-validation-334", "mrqa_newsqa-validation-3772", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-1390", "mrqa_naturalquestions-validation-4008", "mrqa_hotpotqa-validation-3392", "mrqa_searchqa-validation-15636", "mrqa_hotpotqa-validation-3140"], "SR": 0.5625, "CSR": 0.5340189873417722, "EFR": 1.0, "Overall": 0.7148506724683544}, {"timecode": 79, "before_eval_results": {"predictions": ["Togus", "Ulysses S. Grant", "Yangtze", "Jacob", "Queen Anne", "The New York Times", "America", "Oklahoma", "the Communist Party", "the Nuclear Age", "Sir Humphry Davy", "seoul", "9,034 mile", "smallpox", "the Dead Sea", "the fairway", "Hill Street Blues", "elevation", "Mao Zedong", "Harriet", "Mickey Mouse", "Fuji", "a blitz", "Jamaica", "gossip", "an exothermic reaction", "the Chocolate Factory", "Morocco", "Surf's Up", "Yao Ming", "tax law enforcement", "clothing", "Marvell", "pizza", "Bollywood", "\"Titanic\"", "Take Me Out to the Ballgame", "a parapet", "Joe Lieberman", "the Bible", "coffee", "Nike", "Margaret Thatcher", "gas masks", "Suriname", "Pearl", "pilots", "Switzerland", "Vestal Virgins", "The Lord of the Rings", "President Raul Castro", "H CO ( equivalently OC ( OH ) )", "in a thousand years", "the United States Navy", "clara", "Douglas Trendle", "Mark Freeland", "Ricky Marco", "Edith Cavell", "Forbes", "45 minutes, five days a week.", "22", "John Demjanjuk,", "2,579"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6561553030303029}, "metric_results_detailed": {"EM": [false, true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, true, false, true, true, false, false, true, false, false, true, true, false, false, false, false, true, true, false, true], "QA-F1": [0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.7272727272727272, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.4, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.4, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-13653", "mrqa_searchqa-validation-11663", "mrqa_searchqa-validation-2045", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-8082", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-4390", "mrqa_searchqa-validation-13569", "mrqa_searchqa-validation-5471", "mrqa_searchqa-validation-5140", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-5551", "mrqa_searchqa-validation-16286", "mrqa_searchqa-validation-9998", "mrqa_searchqa-validation-11363", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-8042", "mrqa_searchqa-validation-16591", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-5810", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-8650", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-4966", "mrqa_triviaqa-validation-1871", "mrqa_hotpotqa-validation-3653", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-3343", "mrqa_newsqa-validation-2118"], "SR": 0.546875, "CSR": 0.5341796875, "EFR": 0.9655172413793104, "Overall": 0.707986260775862}, {"timecode": 80, "before_eval_results": {"predictions": ["homebrewer", "the German Empire", "Tim Whelan", "Waimea Bay", "Virgin", "The Boeing EA-18G Growler", "George Harrison", "The bald eagle", "1923", "7pm", "Francis Schaeffer", "26,788", "10", "associated with the mother goddess", "Azeroth", "1,467 rooms", "Marco Fu", "Jean- Marc Vall\u00e9e", "Adelaide", "Strange Interlude", "2004", "Hall & Oates", "\"From Here to Eternity\"", "the Manor of the More", "England, Scotland, and Ireland", "the Workers' Party", "those who work with animals", "his exploration and settlement", "six", "Mauthausen-Gusen", "Adrian Peter McLaren (born 21 April 1980 in Kimberley, Northern Cape)", "Distillery", "Ted Nugent", "Dobbs Ferry, New York", "Viscount Cranborne", "The 49th Disney animated feature film", "Surtees Racing Organisation team", "Them", "Levi Weeks", "Bruce R. Cook", "Mandarin", "Obafemi Akinwunmi Martins", "at Boulder High School in Boulder, Colorado", "Dutch", "November of that year", "Boston, Massachusetts", "\"8 Simple Rules\"", "Brendan O'Brien", "Delphine Software International", "Sullivan University", "October 21, 2016", "various locations in Redford's adopted home state of Utah", "31 - member Senate", "September 15, 2012", "Andy Murray", "victoria", "Malaysia", "Akio Toyoda", "Iran's nuclear program.", "alternative-energy vehicles", "\"Bix\" Beiderbecke", "dicephalous", "(William) Sommers", "M&M's"], "metric_results": {"EM": 0.53125, "QA-F1": 0.65}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, true, true, true, false, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, true, true, false, false, false, true, false, true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.42857142857142855, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 0.6, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.5714285714285715, 1.0, 0.19999999999999998, 0.5, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2203", "mrqa_hotpotqa-validation-30", "mrqa_hotpotqa-validation-1019", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-3650", "mrqa_hotpotqa-validation-1566", "mrqa_hotpotqa-validation-5448", "mrqa_hotpotqa-validation-4254", "mrqa_hotpotqa-validation-1100", "mrqa_hotpotqa-validation-1210", "mrqa_hotpotqa-validation-2379", "mrqa_hotpotqa-validation-1809", "mrqa_hotpotqa-validation-2136", "mrqa_hotpotqa-validation-4687", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-821", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-5821", "mrqa_hotpotqa-validation-3760", "mrqa_hotpotqa-validation-2743", "mrqa_naturalquestions-validation-123", "mrqa_naturalquestions-validation-1533", "mrqa_naturalquestions-validation-2411", "mrqa_triviaqa-validation-5406", "mrqa_triviaqa-validation-4430", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-2930", "mrqa_searchqa-validation-8992", "mrqa_searchqa-validation-870", "mrqa_searchqa-validation-15999"], "SR": 0.53125, "CSR": 0.5341435185185186, "EFR": 1.0, "Overall": 0.7148755787037037}, {"timecode": 81, "before_eval_results": {"predictions": ["Bhaktivedanta Manor", "Ariel Ram\u00edrez", "Potomac River", "four", "1853", "The Allies of World War I, or Entente Powers", "Acid house", "Esteban Ocon", "Lady Frederick Windsor", "Perfume: The Story of a Murderer", "Agent 99", "Razor Ramon", "Birmingham", "half", "Adam Karpel", "rock and roll", "1991", "Windermere, Cumbria", "Sir Frank P. Lowy", "Hermione Baddeley", "Metrolink", "Australia", "1698", "Greenwood", "Brian A. Miller", "July 25 to August 4", "Restoration Hardware", "John William Henry II", "2009", "Jenson button", "William Shakespeare", "The Books", "evangelical Christian periodical", "Annales de chimie et de physique", "Nairobi, Kenya", "The English Electric Canberra", "3 August 1916", "Washington, D.C.", "the Chechen Republic", "Harry Robbins \"Bob\" Haldeman", "Cartoon Cartoon Fridays", "The Company", "5", "Eleanor of Aquitaine", "Latium", "April 1, 1949", "England", "Ericsson", "interstate commerce", "1935", "Michael Redgrave", "Tyrann Devine Mathieu", "1933", "British Columbia, Canada", "The Great Gatsby", "cricket bat making process", "Cliff Willie", "Kim Clijsters", "Africa.", "Bhutto's husband issued a statement Thursday from his home in Dubai", "basic", "New York City Ballet", "volts", "Willa Cather"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6401423229548229}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, true, true, true, false, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, false, true, false, true, false, true, true, false, true, true, false, true, true, false, false, false, true, true, false, true, false, true, true, true, true, true, false, false, false, false, false, false, false, false, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.7692307692307693, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.6666666666666666, 0.5, 0.15384615384615383, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-2729", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-1991", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-4433", "mrqa_hotpotqa-validation-2902", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-130", "mrqa_hotpotqa-validation-2579", "mrqa_hotpotqa-validation-1381", "mrqa_hotpotqa-validation-2893", "mrqa_hotpotqa-validation-3020", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-5597", "mrqa_hotpotqa-validation-4813", "mrqa_hotpotqa-validation-473", "mrqa_hotpotqa-validation-3489", "mrqa_hotpotqa-validation-1073", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-1244", "mrqa_hotpotqa-validation-4041", "mrqa_hotpotqa-validation-4314", "mrqa_triviaqa-validation-873", "mrqa_triviaqa-validation-388", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-2426", "mrqa_newsqa-validation-847", "mrqa_searchqa-validation-9177", "mrqa_searchqa-validation-7787", "mrqa_searchqa-validation-5952"], "SR": 0.515625, "CSR": 0.5339176829268293, "EFR": 1.0, "Overall": 0.7148304115853659}, {"timecode": 82, "before_eval_results": {"predictions": ["1988", "Natalie Chandler", "Algernod Lanier Washington", "Conservative Party", "four", "July 23, 1971", "Ashgabat, Turkmenistan", "the Earth", "Standard Oil", "in both 2007 and 2008", "Norwegian", "The Late Late Show", "Ry\u016bky\u016b minzoku", "Commanding General", "\"50 best cities to live in.\"", "Mike Mills", "Parlophone", "January 15, 2016", "\"Vilniaus oro uostas\"", "George Clooney, Thekla Reuten, Violante Placido, Irina Bj\u00f6rklund, and Paolo Bonacelli", "\"The Worm\"", "Herman's Hermits", "Annapurna Devi", "810", "German", "the Vietnam War", "Anatoly Vasilyevich Lunacharsky", "1946", "Child 44", "novel", "Gabriel Jesus Iglesias", "3,384,569", "Gambaga", "2 March 1972", "The parkway", "La Scala, Milan", "every aspect of public and private life wherever feasible", "Gary Ross", "The Hanford Site", "Commissioner", "Sam Tick", "Cockney art student Avril", "Aaliyah Dana Haughton", "Spain", "The Royal Albert Hall", "Leatherheads", "2 May 2015", "England", "King Duncan", "Bourbon County", "Serial (Bad) Weddings", "Epithelium ( / \u02cc\u025bp\u026a\u02c8\u03b8i\u02d0li\u0259m / )", "Amybeth McNulty", "just after the Super Bowl", "Wichita", "ringo", "1882", "off the coast of Dubai", "Sunday evening", "not doing more since taking office.\"", "the AT bus", "polio", "the treble clef", "until a bond hearing Friday,"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6911024305555555}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, false, false, true, false, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, false, true, true, true, false, true, false, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 0.33333333333333337, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8750000000000001, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1179", "mrqa_hotpotqa-validation-5370", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-3919", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-3182", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-438", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-3703", "mrqa_hotpotqa-validation-904", "mrqa_hotpotqa-validation-4794", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-5549", "mrqa_hotpotqa-validation-1844", "mrqa_naturalquestions-validation-7459", "mrqa_triviaqa-validation-3181", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1427", "mrqa_searchqa-validation-882", "mrqa_searchqa-validation-2732", "mrqa_newsqa-validation-1245"], "SR": 0.609375, "CSR": 0.5348268072289157, "EFR": 1.0, "Overall": 0.715012236445783}, {"timecode": 83, "before_eval_results": {"predictions": ["83 Beals Street", "Metacomet", "Chicago", "Leon Trotsky", "the bread", "the atlas", "The New York Times", "Martin Van Buren", "Ugly Betty", "Winnie the Pooh", "Agnese Bonucci", "Alexander Graham Bell", "Vijay Singh", "the Sea of Mist", "a modem", "China", "the Boston Red Sox", "The Daily Show", "Mussolini", "Man", "Jane's Electro-Optic Systems 2006-2007", "Christo", "Cheers", "Ichiro Suzuki", "Frank Sinatra", "Aden", "the banjo", "the Army of Northern Virginia", "Belle Watling", "Mozart", "American alternative rock band", "Blackwell's Island Asylum", "Lord Byron", "the meningitis", "Douglas MacArthur", "3M", "The Rolling Stones", "Edie Falco", "The USA", "Oneonta College", "1936", "the CN Tower", "The Hurricane", "inheritance", "Baltimore", "the cardinal", "Japan", "the mad cow", "Prince Edward Island", "Hindu", "the pronghorn", "January 2, 1971", "in San Francisco", "Moscazzano", "cliff thorburn", "China's total population,", "Daedalus", "Conservatorio Verdi", "close range combat", "Paul Manafort", "1959.", "Ali Bongo", "the United States", "in mid November"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6302455357142858}, "metric_results_detailed": {"EM": [false, false, true, false, false, false, true, true, true, true, false, true, true, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, true, false, false, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, true, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_searchqa-validation-7412", "mrqa_searchqa-validation-11803", "mrqa_searchqa-validation-16524", "mrqa_searchqa-validation-11538", "mrqa_searchqa-validation-15607", "mrqa_searchqa-validation-1302", "mrqa_searchqa-validation-1523", "mrqa_searchqa-validation-12656", "mrqa_searchqa-validation-7948", "mrqa_searchqa-validation-8713", "mrqa_searchqa-validation-8259", "mrqa_searchqa-validation-2208", "mrqa_searchqa-validation-9445", "mrqa_searchqa-validation-15675", "mrqa_searchqa-validation-15564", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-14502", "mrqa_searchqa-validation-9378", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-3977", "mrqa_searchqa-validation-10010", "mrqa_searchqa-validation-15098", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-3473", "mrqa_searchqa-validation-12578", "mrqa_naturalquestions-validation-10030", "mrqa_triviaqa-validation-2502", "mrqa_hotpotqa-validation-3714", "mrqa_naturalquestions-validation-8884"], "SR": 0.546875, "CSR": 0.5349702380952381, "EFR": 1.0, "Overall": 0.7150409226190476}, {"timecode": 84, "before_eval_results": {"predictions": ["Shinto", "Captain Hook", "the Devil and Daniel Webster", "Taft's monument", "olive brine", "buffalo", "Chloe Lattanzi", "Oahu", "Joseph Smith", "arthropoda", "Harry S. Truman", "ZODIAC", "Diane Arbus", "chiles rellenos", "Thomas Jefferson", "the enactment of a law", "tofu", "Old School", "the Distant Early Warning Line", "Henry VIII", "Bonn", "mathematical research", "Pope John Paul II", "the magazine", "Robert Bruce", "Zinc", "Oxygen", "gargantuan", "Elke Sommer", "hoof", "Robin Williams", "Philadelphia", "laundry soap", "Victor Emmanuel", "Morrie Schwartz", "the anglerfish", "the Big Cat", "Thomas Jefferson Family Plot", "Gandhi", "Brazil", "Jim Thorpe", "The Office", "Jack Crabb", "Anna Shakespeare", "descend toward the ground", "the Bicentennial Symphony", "the Haunted Mansion Holiday", "Rembrandt", "Gilligan's Island", "your timeshare", "the Cowboy Artists of", "Stanwyck's bedroom window overlooks the night skyline of Manhattan", "Atticus Finch", "Andy Serkis", "South Africa", "horizontal desire", "charlie darin", "Esp\u00edrito Santo Financial Group", "Herman's Hermits", "Punjabi/Pashtun descent", "Asashoryu", "because of what they had done to Muslims in the past,\"", "United States Holocaust Memorial Museum, The American Academy of Diplomacy and the United States Institute of Peace.", "Newcastle Falcons"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5185763888888888}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, true, true, false, false, false, true, false, true, false, true, true, false, true, false, false, true, false, true, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, false, false, false, false, true, true, true, false, true, true, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.4, 0.0, 0.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.0, 0.2222222222222222, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 0.0, 0.26666666666666666, 0.1, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14874", "mrqa_searchqa-validation-15165", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-10629", "mrqa_searchqa-validation-16755", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-5260", "mrqa_searchqa-validation-16513", "mrqa_searchqa-validation-13151", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-6258", "mrqa_searchqa-validation-6978", "mrqa_searchqa-validation-12706", "mrqa_searchqa-validation-3190", "mrqa_searchqa-validation-2225", "mrqa_searchqa-validation-1850", "mrqa_searchqa-validation-12089", "mrqa_searchqa-validation-7856", "mrqa_searchqa-validation-10624", "mrqa_searchqa-validation-9210", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-1104", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-16785", "mrqa_searchqa-validation-16304", "mrqa_searchqa-validation-3762", "mrqa_searchqa-validation-14778", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-9476", "mrqa_searchqa-validation-5050", "mrqa_naturalquestions-validation-6465", "mrqa_naturalquestions-validation-7461", "mrqa_triviaqa-validation-4084", "mrqa_hotpotqa-validation-660", "mrqa_newsqa-validation-1128", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-2724"], "SR": 0.421875, "CSR": 0.533639705882353, "EFR": 1.0, "Overall": 0.7147748161764705}, {"timecode": 85, "before_eval_results": {"predictions": ["Crime and Punishment", "Postcards from the Edge", "birds", "Virginia", "chocolate", "\"Elementary, My Dear Watson\"", "Ramadan", "\"The play\"", "\"Mork & Mindy\"", "Wee", "Gertrude Stein", "Pope John XXIII", "love", "Inigo Jones", "Charles Ponzi", "Earhart", "Tippi", "object-oriented programming", "Nova Scotia", "chocolate", "Solomon Islands", "a liqueur", "the Lord of Macragge", "marsupials", "quid", "Lincoln", "Anthony Newley", "swimming with a white vinegar-rubbing alcohol solution", "Henry", "the 2.4 GHz", "the Cyrillic alphabet", "Jeff Probst", "\"Sacrifice\"", "Nasser", "The Moment of Truth", "Laura", "Ethiopia", "Charles Manson", "Jerusalem", "Xerox", "Billy Crystal", "the thyroid", "Hephaestus", "Hurricane Katrina", "pineapple", "Bill & George Clinton", "the Black Sea", "Katharine Hepburn", "the 1, 5, 10, 20, 50, and 100", "Young Frankenstein", "ShoutWipe", "to form a higher alkane", "comprehend and formulate language", "Hellenic Polytheism", "Venezuela", "The Shootist", "Sega Saturn", "the National Society of Daughters of the American Revolution", "Johnny Galecki", "44,300", "it has not", "At least 88", "drowning death,", "Markoff,"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6182291666666666}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, false, false, true, true, true, true, false, false, false, false, true, true, false, false, false, true, true, false, false, false, false, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, true, true, true, true, false, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 1.0, 0.5, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-590", "mrqa_searchqa-validation-6865", "mrqa_searchqa-validation-15120", "mrqa_searchqa-validation-247", "mrqa_searchqa-validation-1059", "mrqa_searchqa-validation-1681", "mrqa_searchqa-validation-9410", "mrqa_searchqa-validation-7724", "mrqa_searchqa-validation-10836", "mrqa_searchqa-validation-11816", "mrqa_searchqa-validation-15430", "mrqa_searchqa-validation-7355", "mrqa_searchqa-validation-7969", "mrqa_searchqa-validation-14465", "mrqa_searchqa-validation-7460", "mrqa_searchqa-validation-15985", "mrqa_searchqa-validation-16963", "mrqa_searchqa-validation-2305", "mrqa_searchqa-validation-11701", "mrqa_searchqa-validation-863", "mrqa_searchqa-validation-5936", "mrqa_searchqa-validation-2063", "mrqa_searchqa-validation-10146", "mrqa_triviaqa-validation-7745", "mrqa_hotpotqa-validation-4024", "mrqa_newsqa-validation-1675", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-3967", "mrqa_newsqa-validation-839"], "SR": 0.546875, "CSR": 0.5337936046511628, "EFR": 0.9655172413793104, "Overall": 0.7079090442060946}, {"timecode": 86, "before_eval_results": {"predictions": ["Ann Doran as Ella May Merchant", "at a given temperature", "season ten", "October 28, 2007", "seven", "absorbed the superhuman powers and the psyche of Carol Danvers", "between the Mediterranean Sea to the Red Sea", "privatized", "Stephen A. Douglas", "abdicated in November 1918", "the First Epistle of John", "between the stomach and the large intestine", "Western Satraps by Chandragupta II", "Vicente Fox", "Atelier de Construction d'Issy - Les - Moulineaux", "Egypt", "the pulmonary arteries", "Lager", "U.S. Bank Stadium", "Destiny's Child", "statistical advantage", "Cliff's father, Russell Huxtable", "Husrev Pasha", "Will", "The Osmonds", "The Drew Las Vegas", "polymerizing the first few glucose molecules", "shredded cheese", "September 8, 2017", "SURFACE AREA OF ROOTS", "Iowa", "Matt Flinders", "1 October 2006", "The Natya Shastra", "Nucleotides", "generally believed to be in the Superstition Mountains, near Apache Junction, east of Phoenix, Arizona", "Hebrew", "nasal septum", "Session Initiation Protocol", "January 1, 1976", "parthenogenesis", "Evaluation of alternative plans / policies", "Ludacris", "Jack Scanlon", "fruiting in the following six months", "Welch, West Virginia", "Andy Cole", "ulnar nerve", "in the eye", "Donna Mills", "Donna", "annette Crosbie", "Bobby Kennedy", "minder", "The leopard", "Patricia Arquette", "Bangalore University", "Symbionese Liberation Army", "101", "two", "Like a Rock", "a cat", "King George III of Britain", "Norway"], "metric_results": {"EM": 0.625, "QA-F1": 0.7024900674982912}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, false, false, true, false, false, false, false, true, true, true, false, true, false, false, false, false, true, false, true, true, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, false, false, true], "QA-F1": [0.5, 0.5454545454545454, 0.0, 1.0, 1.0, 0.761904761904762, 0.6666666666666667, 0.0, 1.0, 0.4210526315789474, 0.0, 0.20000000000000004, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.7142857142857143, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.7499999999999999, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3882", "mrqa_naturalquestions-validation-10613", "mrqa_naturalquestions-validation-3822", "mrqa_naturalquestions-validation-2309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-953", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-6431", "mrqa_naturalquestions-validation-5589", "mrqa_naturalquestions-validation-10571", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-613", "mrqa_naturalquestions-validation-10257", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-4247", "mrqa_naturalquestions-validation-7398", "mrqa_naturalquestions-validation-6340", "mrqa_hotpotqa-validation-1504", "mrqa_searchqa-validation-1808", "mrqa_searchqa-validation-366"], "SR": 0.625, "CSR": 0.5348419540229885, "EFR": 0.9166666666666666, "Overall": 0.698348599137931}, {"timecode": 87, "before_eval_results": {"predictions": ["The Province of Syracuse", "Guardians of the Galaxy Vol. 2", "Arlo Looking Cloud", "Jyothika Sadanah", "The Franco-Prussian War", "Hirsch index rating", "Cody Miller", "1951", "Teenitans Go!", "The Ramna Stacks", "The Book of Judges", "torpedo boats", "9 February 1971", "San Francisco, California", "\"Three's Company\"", "9,984", "Diondre Cole", "Marktown", "The Rose Theatre", "1 million", "Trey Parker and Matt Stone", "La Scala, Milan", "Fidenza", "237", "timeline of Shakespeare criticism", "balloons Street, Manchester", "University of Southern California", "6teen", "the port city of Aden", "Noel Gallagher", "Michael Rispoli", "The U2 360\u00b0 Tour", "Danny Green", "Scarface", "The Austro-Hungarian Army", "St. George, Maine", "Ericsson (\"Telefonaktiebolaget L. M. Ericsson\")", "he abdicated in favour of his son Louis", "Vancouver", "Urijah Faber", "four", "3 May 1958", "The Thomas Crown Affair", "Bharat Ratna", "October 11, 1901", "Taoiseach of Ireland", "Unbreakable", "The Spiderwick Chronicles", "Sacramento Kings", "Sam Kinison", "Ferdinand Magellan", "Franklin Roosevelt", "the 1920s", "on - and off - premises sales in one form or another on Sundays at some restricted time", "James Hargreaves", "Puff the Magic Dragon", "Hindi", "Samoa", "flooding", "composer", "the duchess", "Bath", "Atlanta", "the hope that a happy day being marked would recur many more times"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7068576388888889}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, true, true, false, true, true, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, true, true, false, true, false, true, false, true, true, false, true, false, false, false, false, true, true, true, false, true, true, true, true, true, true, false, true, false, true, false, true, true, false, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.5, 0.4, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 1.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.5, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.16666666666666666, 0.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.9166666666666666]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4345", "mrqa_hotpotqa-validation-2747", "mrqa_hotpotqa-validation-4156", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-4312", "mrqa_hotpotqa-validation-5354", "mrqa_hotpotqa-validation-2145", "mrqa_hotpotqa-validation-4727", "mrqa_hotpotqa-validation-5220", "mrqa_hotpotqa-validation-5398", "mrqa_hotpotqa-validation-5655", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1871", "mrqa_hotpotqa-validation-2003", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-1207", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-5018", "mrqa_hotpotqa-validation-527", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-2792", "mrqa_naturalquestions-validation-5215", "mrqa_naturalquestions-validation-8068", "mrqa_triviaqa-validation-3809", "mrqa_newsqa-validation-4010", "mrqa_searchqa-validation-2044", "mrqa_naturalquestions-validation-9361"], "SR": 0.578125, "CSR": 0.5353338068181819, "EFR": 1.0, "Overall": 0.7151136363636363}, {"timecode": 88, "before_eval_results": {"predictions": ["four", "12-hour-plus shifts of backbreaking labor, virtually zero outside recognition, and occasional accusations of being shills for the timber industry", "as many as 250,000", "Ameneh Bahrami", "40", "state senators", "2005", "\"Dancing With the Stars.\"", "Hawaii.", "Tara Livesay", "Brazil's", "her most important work is her charity, the Happy Hearts Fund.", "\"Common Access Cards,\"", "Her husband and attorney, James Whitehouse,", "helping to plan the September 11, 2001, terror attacks,", "\"Empire of the Sun,\"", "to encourage votes for a Republican presidential candidate,", "because the Indians were gathering information about the rebels to give to the Colombian military.", "Washington Redskins fan and loved to travel,", "time", "Carnival", "3rd District of Utah.", "2007,", "in the southern port city of Karachi,", "allegedly involved in forged credit cards and identity theft", "that anything could have stopped Robert Hawkins from going on a murderous rampage at an Omaha, Nebraska, shopping mall", "Ricardo Valles de la Rosa,", "Islamabad", "Toffelmakaren.", "Wednesday", "Microsoft.", "1995", "Jaime Andrade", "Casalesi Camorra clan", "Nigeria,", "201-262-2800.", "South Africa", "said about 25 gallons of water were detected in the crater,", "France,", "President Obama", "late Tuesday night,", "to reach car owners who haven't complied fully with recalls.", "Mashhad, Iran.", "Plymouth Rock", "Alina Cho", "Spaniard Carlos Moya", "last week,", "treadmill", "Tukel", "10", "This will be the second", "Central Germany", "Rust", "gastrocnemius muscle", "Granada", "axe", "Portugal", "June 17, 2007", "England", "Black Elk Speaks", "spinach", "Kwanzaa", "\"to look like\"", "Javan leopard"], "metric_results": {"EM": 0.5, "QA-F1": 0.6169039535670728}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, false, true], "QA-F1": [1.0, 0.10526315789473684, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.10526315789473685, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.9090909090909091, 0.3636363636363636, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 0.0, 0.3333333333333333, 0.16666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3354", "mrqa_newsqa-validation-706", "mrqa_newsqa-validation-2826", "mrqa_newsqa-validation-2877", "mrqa_newsqa-validation-3820", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-728", "mrqa_newsqa-validation-1906", "mrqa_newsqa-validation-3174", "mrqa_newsqa-validation-446", "mrqa_newsqa-validation-1101", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-982", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-2369", "mrqa_newsqa-validation-2641", "mrqa_newsqa-validation-3906", "mrqa_newsqa-validation-929", "mrqa_newsqa-validation-1428", "mrqa_newsqa-validation-3592", "mrqa_newsqa-validation-2362", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-1201", "mrqa_newsqa-validation-2642", "mrqa_triviaqa-validation-6987", "mrqa_hotpotqa-validation-4378", "mrqa_searchqa-validation-1182", "mrqa_searchqa-validation-2749"], "SR": 0.5, "CSR": 0.534936797752809, "EFR": 1.0, "Overall": 0.7150342345505617}, {"timecode": 89, "before_eval_results": {"predictions": ["through a facility in Salt Lake City, Utah,", "10 below", "Shemsu Sirgaga", "killing rampage.", "Eintracht Frankfurt", "they did not receive a fair trial.", "The federal officers' bodies", "American Bill Haas", "Larry Ellison,", "without the restrictions congressional Democrats vowed to put into place since they took control of Congress nearly two years ago.", "in the 20 years since the Berlin Wall has fallen there has been a renaissance of the game in the region.", "Piers Morgan,", "The public endorsement", "Phoenix, Arizona,", "KBR", "Coptic Christians and Muslims", "Aniston, Demi Moore and Alicia Keys", "two years,", "the body of the aircraft", "the United States, Japan, Russia, South Korea and China,", "chairman of the House Budget Committee,", "\"pattern matching.\"", "\"Gandhi,\"", "almost 9 million", "some U.S. senators", "the situation of America", "London and Buenos Aires", "was asked by authorities not to travel in cars with tinted windows -- which protected me from identification by terrorists -- or travel with privately armed guards,\"", "Hitler did to the Jewish people just 65 years ago,\"", "Nafees A. Syed,", "a bank", "two", "the Harris Fire.", "At least 38", "Sri Lanka", "The BBC", "\"wipe out\" the United States if provoked.", "Sunday,", "is a city of romance, of incredible architecture and history.", "top designers, such as Stella McCartney,", "clogs", "debris", "Aniston, Demi Moore and Alicia Keys", "ALS6,", "The EU naval force", "well over 1,000 pounds", "Iran's Green Movement of protesters", "make the new truck safer, but also could make it more expensive to repair after a collision.", "Friday,", "provides nearly $162 billion in war funding", "Vonn", "three levels", "the optic chiasm", "Hugo Weaving", "aragonite", "\u201creckless\u201d", "Olympia", "Bruce R. Cook", "Los Angeles", "86,112", "the right doctor for me", "a soap opera", "the CPI", "Penrhyn Castle"], "metric_results": {"EM": 0.546875, "QA-F1": 0.668122441284206}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, false, true, true, true, false, false, false, false, true, false, false, false, false, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false, false, false, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.1, 0.15384615384615385, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 0.8, 0.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.23529411764705882, 1.0, 0.923076923076923, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-2045", "mrqa_newsqa-validation-2857", "mrqa_newsqa-validation-157", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-1586", "mrqa_newsqa-validation-2024", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-2435", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-2657", "mrqa_newsqa-validation-3302", "mrqa_newsqa-validation-3015", "mrqa_newsqa-validation-2929", "mrqa_newsqa-validation-3833", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-1432", "mrqa_newsqa-validation-2767", "mrqa_newsqa-validation-1767", "mrqa_newsqa-validation-452", "mrqa_newsqa-validation-163", "mrqa_naturalquestions-validation-10277", "mrqa_naturalquestions-validation-3358", "mrqa_triviaqa-validation-4977", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-3909", "mrqa_searchqa-validation-6689", "mrqa_searchqa-validation-11100", "mrqa_triviaqa-validation-2306"], "SR": 0.546875, "CSR": 0.5350694444444444, "EFR": 1.0, "Overall": 0.7150607638888888}, {"timecode": 90, "before_eval_results": {"predictions": ["(William) Inge", "anthrax", "Neptune", "larynx", "the Surgeon General of the United States", "Ebony", "Cook County", "Sartre", "(William) Wordsworth", "St. Louis", "James K. Polk", "Harpy", "lacrosse", "Naples", "the Hatter", "the Romans", "a cow pie", "'Paradise Lost'", "beautiful", "the White Sea", "Doctor Dolittle", "Graceland", "Mitch Albom", "the beaver", "earthquakes", "Donovan", "Best Supporting Actor", "The Bionic Woman", "the multitude", "wrinkles", "Narnia", "the comet Tempel 1", "cedar park", "Kamehameha", "(Elbert) Gary", "corporality", "crowded", "\"Duke\" Stivic\"", "Orleans", "\"Another Brick in the Wall\"", "Pulp Fiction", "Hester Prynne", "pajamas", "China Airlines", "a bagpipe", "a stork", "BOWLING", "Henry David Thoreau", "Encephalitis", "the Philippines", "Sydney", "central Saskatchewan", "is married to Bobby", "The long - hair gene", "makaron nesoi", "Another Day in Paradise", "Danelaw", "Don Johnson", "Robert Allen Iger", "Manchester\u2013Boston Regional Airport", "Iowa,", "16", "shoot down the object", "financial gain,"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7049479166666667}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, true, true, false, true, false, false, true, false, false, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, true, true, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.33333333333333337, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.4, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2401", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-11722", "mrqa_searchqa-validation-4704", "mrqa_searchqa-validation-14750", "mrqa_searchqa-validation-11959", "mrqa_searchqa-validation-12389", "mrqa_searchqa-validation-15887", "mrqa_searchqa-validation-9947", "mrqa_searchqa-validation-14528", "mrqa_searchqa-validation-10975", "mrqa_searchqa-validation-10496", "mrqa_searchqa-validation-15600", "mrqa_searchqa-validation-7404", "mrqa_searchqa-validation-11566", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-10583", "mrqa_triviaqa-validation-1702", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-793", "mrqa_newsqa-validation-1072", "mrqa_newsqa-validation-1662"], "SR": 0.640625, "CSR": 0.5362293956043955, "EFR": 1.0, "Overall": 0.7152927541208791}, {"timecode": 91, "before_eval_results": {"predictions": ["Wales", "race cyclists sprint for victory following a speed-controlled start behind a motorized or non-motorized pacer", "British boxing Middleweight", "Christopher Nolan", "Johann", "highball", "Arthur Conan Doyle", "Godfigu", "a heart", "6", "Bashir", "dog sport", "The Double", "arsenic", "omega", "Mickey Mouse", "the dachm", "the \"Welcome Stranger\"", "the recorder", "Oman", "Genesis", "Ladysmith", "californium", "Robert Guerrero", "the Arizona Diamondbacks", "George Orwell", "David Ben -Gurion", "Marc", "a tuna roe", "William Shakespeare", "1960's", "Some Like It Hot", "Burgundy", "injecting a 7 percent solution intravenously three times a day", "The National Council for the Unmarried Mother and her Child", "Sarajevo", "King Henry I", "Harry Bailley", "bullfighting", "Leicestershire", "cycling", "Crimean Tatar", "bedding", "Switzerland", "Shanghai", "Twelfth Night", "Girl Scout Promise", "the Swordfish", "France", "Australia", "France", "17 - year - old Augustus Waters, an ex-basketball player and amputee", "July 4, 1898", "December 1922", "South Asian Games", "Rana Daggubati", "four", "1,500", "a group of teenagers.\"", "38 feet", "the Marquis de Lafayette", "turquoise", "the birds of America", "2010"], "metric_results": {"EM": 0.515625, "QA-F1": 0.5769345238095238}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, false, false, false, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, false, true, false, true, true, true, false, false, false, true, false, false, true, true, true, false, false, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.5, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1334", "mrqa_triviaqa-validation-5840", "mrqa_triviaqa-validation-2392", "mrqa_triviaqa-validation-4256", "mrqa_triviaqa-validation-600", "mrqa_triviaqa-validation-221", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-7724", "mrqa_triviaqa-validation-6550", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-5590", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-3727", "mrqa_triviaqa-validation-4508", "mrqa_triviaqa-validation-5014", "mrqa_triviaqa-validation-5418", "mrqa_triviaqa-validation-6545", "mrqa_triviaqa-validation-1439", "mrqa_triviaqa-validation-3077", "mrqa_triviaqa-validation-2053", "mrqa_triviaqa-validation-6589", "mrqa_triviaqa-validation-7051", "mrqa_triviaqa-validation-5484", "mrqa_naturalquestions-validation-4071", "mrqa_hotpotqa-validation-369", "mrqa_hotpotqa-validation-3814", "mrqa_newsqa-validation-3440", "mrqa_searchqa-validation-6259", "mrqa_searchqa-validation-11134", "mrqa_searchqa-validation-836"], "SR": 0.515625, "CSR": 0.5360054347826086, "EFR": 0.9032258064516129, "Overall": 0.6958931232468443}, {"timecode": 92, "before_eval_results": {"predictions": ["Tomasz Adamek", "51,271", "Roger Staubach", "1979 to 2013", "two", "1987", "Meghan Markle", "2007", "alcoholic drinks", "Seoul, South Korea", "Dutch", "President of the United States", "political correctness", "Russell Humphreys", "Wisconsin", "January 24, 2012", "over 3 million", "Mazda", "Jack Kilby", "\"My Father\"", "water", "more than 70", "milk", "Animorphs", "Francis", "two Nobel Peace Prizes", "The Emperor of Japan", "\"Apatosaurus\"", "TD Garden", "their cover of David Bowie's 1979 song \"Boys Keep Swinging\"", "Sam Kinison", "Melbourne Storm", "Hawaiian language, \"k\u0101ne \u02bb ohe\" means \"bamboo man\"", "2007", "Kent, Washington", "Prudence Jane Goward", "Vincent Anthony Guaraldi", "\"What's My Line? \"", "Kim So-hyun", "seasonal television specials, particularly its work in stop motion animation", "Carol Ann Duffy", "Lauren Lane", "Joseph I", "17 October 2006", "\"When the Levee Breaks\"", "29,000", "Dire Straits", "Niger\u2013Congo", "Princess Jessica", "The 2018 Unibet Premier League Darts", "first freshman to finish as the runner-up", "Canada", "often linked to high - ranking ( though not necessarily royalty ) in China", "the eurozone", "Jane Seymour", "Willie Nelson", "1984", "Argentina", "15 percent", "Ali Bongo", "Antietam National Battlefield", "your premium", "Princeton", "Miguel Cotto"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7458472083472083}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, false, true, true, false, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.4444444444444445, 0.5, 0.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.5454545454545454, 0.4, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-3594", "mrqa_hotpotqa-validation-3037", "mrqa_hotpotqa-validation-3421", "mrqa_hotpotqa-validation-4762", "mrqa_hotpotqa-validation-3364", "mrqa_hotpotqa-validation-5615", "mrqa_hotpotqa-validation-3385", "mrqa_hotpotqa-validation-51", "mrqa_hotpotqa-validation-1662", "mrqa_hotpotqa-validation-1349", "mrqa_hotpotqa-validation-1284", "mrqa_hotpotqa-validation-3381", "mrqa_hotpotqa-validation-1708", "mrqa_hotpotqa-validation-3920", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-4007", "mrqa_hotpotqa-validation-5319", "mrqa_naturalquestions-validation-1162", "mrqa_newsqa-validation-2508", "mrqa_searchqa-validation-2586", "mrqa_searchqa-validation-15208", "mrqa_searchqa-validation-4038"], "SR": 0.640625, "CSR": 0.537130376344086, "EFR": 1.0, "Overall": 0.7154729502688172}, {"timecode": 93, "before_eval_results": {"predictions": ["American", "Bill Cosby", "Edward R. Murrow", "Liesl", "Stage Stores, Inc.", "Harsh Times", "1998", "Gold & Silver Pawn Shop in Las Vegas", "1972", "Argentina", "High Knob", "Dayton's department store", "1 September 1864", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "Iranian-American", "Buck Owens and the Buckaroos", "the Provisional Irish Republican Army (IRA) in Northern Ireland", "Tel Aviv", "Chevy Motor Car Company", "the tissues of the outer third of the vagina", "Overijssel, Netherlands", "great-grandfather of Miami Marlin Christian Yelich", "PEN America", "Love Letter", "2013", "Commack School District", "January 15, 1975", "John R. Dilworth for Cartoon Network", "actor and former fashion model", "18.7 miles", "Oracle Corporation", "Titus Lucretius Carus", "water sprite", "Hopeless Records", "August Heckscher", "Isabella Hedgeland", "Pennsylvania's 18th congressional district", "The Five", "anabolic\u2013androgenic steroids", "Dulwich", "Red Dead Redemption", "Sierre", "Buffalo", "Heathrow Airport (IATA: LHR, ICAO: EGLL)", "George Martin", "Timo Hildebrand", "Adam Dawes", "Enkare Nairobi\"", "Rockland, Maine", "2009", "Vietnam War", "Toto", "9 February 2018", "Cheap Trick", "Kevin Spacey", "funchal", "british", "Scudetto", "it would", "because a new model is simply out of their reach.", "Caroline Ponsonby", "Florida", "Burkina Faso", "Agriculture"], "metric_results": {"EM": 0.609375, "QA-F1": 0.723007910186219}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, true, true, true, true, true, false, true, false, false, true, false, false, false, false, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.2222222222222222, 1.0, 0.0, 0.1818181818181818, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9411764705882353, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4757", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-1852", "mrqa_hotpotqa-validation-108", "mrqa_hotpotqa-validation-5243", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5743", "mrqa_hotpotqa-validation-2158", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-4194", "mrqa_hotpotqa-validation-3448", "mrqa_hotpotqa-validation-798", "mrqa_hotpotqa-validation-3449", "mrqa_hotpotqa-validation-5128", "mrqa_hotpotqa-validation-3403", "mrqa_hotpotqa-validation-672", "mrqa_hotpotqa-validation-215", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-5191", "mrqa_hotpotqa-validation-4272", "mrqa_hotpotqa-validation-960", "mrqa_hotpotqa-validation-961", "mrqa_newsqa-validation-2754", "mrqa_newsqa-validation-2965", "mrqa_searchqa-validation-16694"], "SR": 0.609375, "CSR": 0.5378989361702128, "EFR": 1.0, "Overall": 0.7156266622340425}, {"timecode": 94, "before_eval_results": {"predictions": ["drummer", "Hitler", "Greer Garson", "Simon Cowell", "The Eagles", "a neon sign", "lifejackets", "Ian Fleming", "The Taming of the Shrew", "Anne Frank", "Bora Bora", "Cops", "The Bahamas", "a geisha", "France", "the Barbary pirates", "the CIA", "an antiseptic", "the iPhone", "Jesus", "Phonetics", "Crosby, Stills & Nash", "Frasier", "a tree", "a missile", "the Court of Cassation", "Mexico", "a rock-and-roll", "Afghanistan", "Australia", "a buffalo", "lice", "The Columbia University College of Physicians and Surgeons", "pitch", "Pete Rose", "Esther", "South Africa", "Bacall", "Goldeneye", "anthropology", "Dumbo", "Edith Wharton", "Aretha Franklin", "marsupials", "English", "The Crow", "Oakland Orioles", "Orson Welles", "the mongoose", "Jack Aubrey", "Ecuador", "Koine Greek : apokalypsis", "four", "elected or appointed by means of a commission", "Friends", "olibanum", "the solar system", "Isobel", "the series \"Runaways\"", "Pieter van Musschenbroek", "Seoul", "I've been feeling better every single day since surgery and this weekend my doctors gave me the green light to get back to work.\"", "Superman brought down the Ku Klux Klan,", "krankie"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6105756222943723}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, false, false, true, false, true, false, false, false, false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, false, true, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.25, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.13636363636363635, 0.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_searchqa-validation-9874", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-14617", "mrqa_searchqa-validation-4594", "mrqa_searchqa-validation-13645", "mrqa_searchqa-validation-2987", "mrqa_searchqa-validation-9617", "mrqa_searchqa-validation-11593", "mrqa_searchqa-validation-6734", "mrqa_searchqa-validation-5729", "mrqa_searchqa-validation-15760", "mrqa_searchqa-validation-14357", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-12196", "mrqa_searchqa-validation-11477", "mrqa_searchqa-validation-5897", "mrqa_searchqa-validation-6749", "mrqa_searchqa-validation-4014", "mrqa_searchqa-validation-10964", "mrqa_searchqa-validation-10367", "mrqa_searchqa-validation-6577", "mrqa_searchqa-validation-3821", "mrqa_searchqa-validation-1101", "mrqa_naturalquestions-validation-833", "mrqa_naturalquestions-validation-2476", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-4503", "mrqa_newsqa-validation-75", "mrqa_newsqa-validation-108", "mrqa_triviaqa-validation-7411"], "SR": 0.53125, "CSR": 0.537828947368421, "EFR": 0.9333333333333333, "Overall": 0.7022793311403508}, {"timecode": 95, "before_eval_results": {"predictions": ["Clarence Thomas", "Penguin Books", "Kokomo", "Profiles in Courage", "Berkeley", "the summer session", "Lady Godiva", "Beat The Clock", "the Mallow", "Antnio Guterres", "Latin", "King Henry VIII", "San Francisco", "her daughter", "Neptune", "Harry Potter and the Chamber of Secrets", "Brutus", "the wild-goose", "Joseph Haydn", "Willa Cather", "the Dow Jones industrial average", "Aunt Jemima", "the fowls", "Dynasties", "Homer", "Nick Cannon", "Ted Danson", "O. Henry", "middle-aged", "Memphis", "Jacqueline Lee \"Jackie\" Kennedy Onassis (1929 - 1994)", "Donovan", "plankton", "Candlestick Park", "jointer plane", "just compensation", "vodka", "pastrami", "Adam", "heresy", "Ivy Dickens", "Woozy", "thunder", "Ham", "Calamine", "Sicily", "Admiral Horatio Nelson", "Luxor", "Drew Barrymore", "Philip Seymour Hoffman", "Sherlock Holmes", "Caleb", "1957", "Hong Taiji", "th\u00e9l\u00e8me[7][9]", "Little arrows", "Rotary", "Craig William Macneill", "Matilda of Anjou", "twenty", "at the exit in question,\"", "more than 4,000", "Lifeway Christian Stores", "Pakistan"], "metric_results": {"EM": 0.609375, "QA-F1": 0.6890128968253968}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, true, true, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, true, true, true, false, true, true, true, false, true, false, true, false, true, false, true, false, true, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444445, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.28571428571428575, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-2232", "mrqa_searchqa-validation-9222", "mrqa_searchqa-validation-3012", "mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-3436", "mrqa_searchqa-validation-4745", "mrqa_searchqa-validation-15065", "mrqa_searchqa-validation-8870", "mrqa_searchqa-validation-13244", "mrqa_searchqa-validation-7791", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-9992", "mrqa_searchqa-validation-9043", "mrqa_searchqa-validation-13657", "mrqa_searchqa-validation-4483", "mrqa_searchqa-validation-2081", "mrqa_naturalquestions-validation-1904", "mrqa_naturalquestions-validation-10184", "mrqa_naturalquestions-validation-9639", "mrqa_triviaqa-validation-1852", "mrqa_hotpotqa-validation-1558", "mrqa_hotpotqa-validation-1300", "mrqa_newsqa-validation-3479", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-2278"], "SR": 0.609375, "CSR": 0.53857421875, "EFR": 0.96, "Overall": 0.7077617187499999}, {"timecode": 96, "before_eval_results": {"predictions": ["swans", "\"Ozymandias\" poet", "Unbreakable", "Holy Week", "Tijuana", "a Wizard", "a bit", "Planned Parenthood", "Jamie Lee Curtis", "King of the Hill", "an Abduction", "Alexander Graham Bell", "the north-east", "a baffle", "Hulk", "Herman", "Erin Go Bragh", "Queen Victoria", "giant", "Medusa", "zoology", "Lucia di Lammermoor", "a globes", "cricket", "Stephen Hawking", "St. Francis", "the luminous intensity", "The Scarlet Letter", "2016", "a rehab facility", "pastries", "The Hundred Years' War", "the Met", "milk and honey", "3", "a hump", "The Beatles", "Bronx", "glucose", "King Kong", "Cubism", "Umbria", "ghee", "M. C. Escher", "Oahu", "the ureter", "Scott Fitzgerald", "an aria", "Ghostbusters II", "Marquette University", "Rothschild", "Fall 1998", "overclosure of the mouth", "Bart Howard", "france", "marillion", "Usain Bolt", "Keeper of the Great Seal of Scotland", "J. K. Rowling", "Victorian England", "\"we seek a new way forward, based on mutual interest and mutual respect.\"", "in early 2008,", "acid attack", "number five"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6614583333333334}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, false, true, false, false, true, true, true, false, false, false, false, false, true, false, false, false, true, false, true, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.8, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16082", "mrqa_searchqa-validation-572", "mrqa_searchqa-validation-16101", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-6016", "mrqa_searchqa-validation-11715", "mrqa_searchqa-validation-9048", "mrqa_searchqa-validation-12137", "mrqa_searchqa-validation-9557", "mrqa_searchqa-validation-13015", "mrqa_searchqa-validation-3371", "mrqa_searchqa-validation-15106", "mrqa_searchqa-validation-4441", "mrqa_searchqa-validation-4428", "mrqa_searchqa-validation-1885", "mrqa_searchqa-validation-3270", "mrqa_searchqa-validation-143", "mrqa_searchqa-validation-9309", "mrqa_searchqa-validation-7573", "mrqa_searchqa-validation-2023", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-333", "mrqa_naturalquestions-validation-2666", "mrqa_triviaqa-validation-3952", "mrqa_hotpotqa-validation-694", "mrqa_newsqa-validation-2565", "mrqa_newsqa-validation-2741"], "SR": 0.578125, "CSR": 0.5389819587628866, "EFR": 0.9629629629629629, "Overall": 0.7084358593451698}, {"timecode": 97, "before_eval_results": {"predictions": ["15 cm", "gold rings", "Gaston Leroux", "concorde", "gold", "eec", "czech republicans", "Vietnam", "Florentius", "Wanderers", "emilia fox", "Amnesty International", "krak\u00f3w", "Shaft", "gal", "Ramadan", "bizet", "the Count Basie Orchestra", "Pegida", "plutonium", "Carol Thatcher", "Edward Hopper", "Einstein", "faversham", "Justin Trudeau", "Michael Jackson", "time team", "Thom Yorke", "OKLAHOMA!", "UNESCO", "Bolivia", "Christian Wulff", "milk", "usk", "spider", "Malcolm Turnbull", "Daily Herald", "nairobi", "Alan Turing", "bone", "the coronary sinus", "a \"puck,\"", "hula hoops", "ap\u00e9ritif", "Lady Susan", "Rocky Graziano", "a sweater", "Today newspaper", "Today", "Gene Vincent", "Midgard", "a hyper - active kinase", "the Chesapeake", "Ben Faulks", "a Taylor series", "the right bank of the Gomti River", "Art of Dying", "Sgt. Jason Bendett of the 3rd Platoon, A Company, 2nd Light armored Reconnaissance Battalion,", "Tuesday's iPhone 4S news,", "Christopher Savoie", "Jason", "ingenue", "WWI", "Joseph"], "metric_results": {"EM": 0.640625, "QA-F1": 0.683639705882353}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, false, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, false, true, true, false, true, true, true, false, false, true, false, false, false, true, false, true, true, true, false, false, false, true, false, false, true, false, false, true, true, true, false, true], "QA-F1": [0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1962", "mrqa_triviaqa-validation-3617", "mrqa_triviaqa-validation-3787", "mrqa_triviaqa-validation-2539", "mrqa_triviaqa-validation-4277", "mrqa_triviaqa-validation-7423", "mrqa_triviaqa-validation-6370", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-1946", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-4097", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-5209", "mrqa_triviaqa-validation-4083", "mrqa_naturalquestions-validation-9271", "mrqa_naturalquestions-validation-2098", "mrqa_hotpotqa-validation-1861", "mrqa_hotpotqa-validation-1240", "mrqa_newsqa-validation-1862", "mrqa_newsqa-validation-2253", "mrqa_searchqa-validation-1427"], "SR": 0.640625, "CSR": 0.5400191326530612, "EFR": 1.0, "Overall": 0.7160507015306121}, {"timecode": 98, "before_eval_results": {"predictions": ["Queen Victoria", "eagles", "Jerry Mouse", "cirrus uncinus", "procol harum", "alberta", "flarney", "st. Ives", "ugandan", "st pancras", "lactic acid", "vienne", "robinson Crusoe", "once a week", "my Favorite martian", "tarot", "claustrophobia", "china", "Wyatt", "April", "one Direction", "Diary of a Tuber", "prince Harry", "1994", "titanium", "pushchair friendly", "Pegasus", "alaskan", "Mark Twain", "brazil", "horseradish", "leather", "eyes", "netherlands", "bowie knife", "Nile", "a rat", "Independence Day", "tinie Tempah", "netherlands", "Catholic", "baby Buggy", "beards", "little Dorrit", "newham", "The Sunday Post", "darin", "shariqah", "phil Woolas", "mansfield park", "South Africa", "Ian Harrowell", "drivers who meet more exclusive criteria", "Florida", "twenty-three", "Mexican War on Drugs", "relationship with Apple co-founder Steve Jobs", "opium", "Basilan", "Tutsi and Hutu rivalry", "The Tempest", "Naples", "Solomon", "weighed against the feather of truth"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5402281746031745}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, false, true, false, false, false, true, false, false, false, true, true, false, false, true, false, false, true, false, true, true, false, false, true, true, false, false, true, false, false, true, true, true, false, false, true, false, true, false, true, false, false, true, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 0.4, 1.0, 0.5, 1.0, 0.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.888888888888889]}}, "before_error_ids": ["mrqa_triviaqa-validation-2746", "mrqa_triviaqa-validation-6145", "mrqa_triviaqa-validation-5217", "mrqa_triviaqa-validation-2099", "mrqa_triviaqa-validation-5353", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2107", "mrqa_triviaqa-validation-3760", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3452", "mrqa_triviaqa-validation-829", "mrqa_triviaqa-validation-5613", "mrqa_triviaqa-validation-6415", "mrqa_triviaqa-validation-3363", "mrqa_triviaqa-validation-5529", "mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-4319", "mrqa_triviaqa-validation-2295", "mrqa_triviaqa-validation-2257", "mrqa_triviaqa-validation-4862", "mrqa_triviaqa-validation-3198", "mrqa_triviaqa-validation-4677", "mrqa_triviaqa-validation-4125", "mrqa_triviaqa-validation-2115", "mrqa_triviaqa-validation-1907", "mrqa_triviaqa-validation-6822", "mrqa_triviaqa-validation-6169", "mrqa_triviaqa-validation-2492", "mrqa_naturalquestions-validation-9588", "mrqa_naturalquestions-validation-9149", "mrqa_hotpotqa-validation-2377", "mrqa_hotpotqa-validation-260", "mrqa_newsqa-validation-3408", "mrqa_newsqa-validation-3659", "mrqa_hotpotqa-validation-3713"], "SR": 0.453125, "CSR": 0.5391414141414141, "EFR": 0.9714285714285714, "Overall": 0.710160872113997}, {"timecode": 99, "UKR": 0.740234375, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1090", "mrqa_hotpotqa-validation-1203", "mrqa_hotpotqa-validation-1295", "mrqa_hotpotqa-validation-1481", "mrqa_hotpotqa-validation-1593", "mrqa_hotpotqa-validation-1647", "mrqa_hotpotqa-validation-1680", "mrqa_hotpotqa-validation-1700", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-1722", "mrqa_hotpotqa-validation-1819", "mrqa_hotpotqa-validation-1829", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-1915", "mrqa_hotpotqa-validation-2013", "mrqa_hotpotqa-validation-2021", "mrqa_hotpotqa-validation-2070", "mrqa_hotpotqa-validation-209", "mrqa_hotpotqa-validation-2187", "mrqa_hotpotqa-validation-2193", "mrqa_hotpotqa-validation-2332", "mrqa_hotpotqa-validation-2478", "mrqa_hotpotqa-validation-2519", "mrqa_hotpotqa-validation-2832", "mrqa_hotpotqa-validation-2909", "mrqa_hotpotqa-validation-2922", "mrqa_hotpotqa-validation-3008", "mrqa_hotpotqa-validation-3060", "mrqa_hotpotqa-validation-3076", "mrqa_hotpotqa-validation-3180", "mrqa_hotpotqa-validation-3181", "mrqa_hotpotqa-validation-324", "mrqa_hotpotqa-validation-3461", "mrqa_hotpotqa-validation-3487", "mrqa_hotpotqa-validation-3515", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-3814", "mrqa_hotpotqa-validation-3911", "mrqa_hotpotqa-validation-3951", "mrqa_hotpotqa-validation-3998", "mrqa_hotpotqa-validation-4049", "mrqa_hotpotqa-validation-4219", "mrqa_hotpotqa-validation-4273", "mrqa_hotpotqa-validation-4286", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-4367", "mrqa_hotpotqa-validation-4380", "mrqa_hotpotqa-validation-4403", "mrqa_hotpotqa-validation-4407", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-4545", "mrqa_hotpotqa-validation-457", "mrqa_hotpotqa-validation-461", "mrqa_hotpotqa-validation-4710", "mrqa_hotpotqa-validation-4735", "mrqa_hotpotqa-validation-4750", "mrqa_hotpotqa-validation-4770", "mrqa_hotpotqa-validation-4788", "mrqa_hotpotqa-validation-4821", "mrqa_hotpotqa-validation-4878", "mrqa_hotpotqa-validation-4891", "mrqa_hotpotqa-validation-5075", "mrqa_hotpotqa-validation-5138", "mrqa_hotpotqa-validation-5148", "mrqa_hotpotqa-validation-5152", "mrqa_hotpotqa-validation-5326", "mrqa_hotpotqa-validation-5333", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5414", "mrqa_hotpotqa-validation-5515", "mrqa_hotpotqa-validation-5833", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-5878", "mrqa_hotpotqa-validation-616", "mrqa_hotpotqa-validation-689", "mrqa_hotpotqa-validation-79", "mrqa_hotpotqa-validation-851", "mrqa_naturalquestions-validation-10691", "mrqa_naturalquestions-validation-10719", "mrqa_naturalquestions-validation-10721", "mrqa_naturalquestions-validation-1092", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1193", "mrqa_naturalquestions-validation-1357", "mrqa_naturalquestions-validation-1431", "mrqa_naturalquestions-validation-1448", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-2006", "mrqa_naturalquestions-validation-2144", "mrqa_naturalquestions-validation-2183", "mrqa_naturalquestions-validation-2201", "mrqa_naturalquestions-validation-2264", "mrqa_naturalquestions-validation-2429", "mrqa_naturalquestions-validation-2542", "mrqa_naturalquestions-validation-2548", "mrqa_naturalquestions-validation-2572", "mrqa_naturalquestions-validation-2631", "mrqa_naturalquestions-validation-2666", "mrqa_naturalquestions-validation-2782", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2908", "mrqa_naturalquestions-validation-3006", "mrqa_naturalquestions-validation-3019", "mrqa_naturalquestions-validation-3124", "mrqa_naturalquestions-validation-3351", "mrqa_naturalquestions-validation-3353", "mrqa_naturalquestions-validation-338", "mrqa_naturalquestions-validation-3474", "mrqa_naturalquestions-validation-3483", "mrqa_naturalquestions-validation-3510", "mrqa_naturalquestions-validation-3561", "mrqa_naturalquestions-validation-361", "mrqa_naturalquestions-validation-3851", "mrqa_naturalquestions-validation-3950", "mrqa_naturalquestions-validation-4214", "mrqa_naturalquestions-validation-4242", "mrqa_naturalquestions-validation-4288", "mrqa_naturalquestions-validation-4302", "mrqa_naturalquestions-validation-4695", "mrqa_naturalquestions-validation-4846", "mrqa_naturalquestions-validation-4940", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-4966", "mrqa_naturalquestions-validation-525", "mrqa_naturalquestions-validation-5264", "mrqa_naturalquestions-validation-5312", "mrqa_naturalquestions-validation-5328", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5613", "mrqa_naturalquestions-validation-5845", "mrqa_naturalquestions-validation-5936", "mrqa_naturalquestions-validation-5995", "mrqa_naturalquestions-validation-6027", "mrqa_naturalquestions-validation-6046", "mrqa_naturalquestions-validation-6141", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-64", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-6720", "mrqa_naturalquestions-validation-7020", "mrqa_naturalquestions-validation-7029", "mrqa_naturalquestions-validation-7051", "mrqa_naturalquestions-validation-715", "mrqa_naturalquestions-validation-7151", "mrqa_naturalquestions-validation-72", "mrqa_naturalquestions-validation-7350", "mrqa_naturalquestions-validation-7461", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-7814", "mrqa_naturalquestions-validation-8115", "mrqa_naturalquestions-validation-8154", "mrqa_naturalquestions-validation-8397", "mrqa_naturalquestions-validation-852", "mrqa_naturalquestions-validation-859", "mrqa_naturalquestions-validation-8638", "mrqa_naturalquestions-validation-8685", "mrqa_naturalquestions-validation-8870", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8964", "mrqa_naturalquestions-validation-9039", "mrqa_naturalquestions-validation-9059", "mrqa_naturalquestions-validation-9218", "mrqa_naturalquestions-validation-9246", "mrqa_naturalquestions-validation-941", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-9506", "mrqa_naturalquestions-validation-9716", "mrqa_naturalquestions-validation-9722", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-9765", "mrqa_naturalquestions-validation-9802", "mrqa_newsqa-validation-1084", "mrqa_newsqa-validation-1121", "mrqa_newsqa-validation-1165", "mrqa_newsqa-validation-1218", "mrqa_newsqa-validation-1225", "mrqa_newsqa-validation-1331", "mrqa_newsqa-validation-1412", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1496", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-1648", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-1732", "mrqa_newsqa-validation-1737", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-191", "mrqa_newsqa-validation-1922", "mrqa_newsqa-validation-1944", "mrqa_newsqa-validation-1978", "mrqa_newsqa-validation-1998", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-2011", "mrqa_newsqa-validation-203", "mrqa_newsqa-validation-2039", "mrqa_newsqa-validation-2043", "mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-2079", "mrqa_newsqa-validation-2087", "mrqa_newsqa-validation-2142", "mrqa_newsqa-validation-2155", "mrqa_newsqa-validation-2178", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2265", "mrqa_newsqa-validation-2299", "mrqa_newsqa-validation-2312", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2371", "mrqa_newsqa-validation-2378", "mrqa_newsqa-validation-2419", "mrqa_newsqa-validation-2483", "mrqa_newsqa-validation-2579", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2622", "mrqa_newsqa-validation-281", "mrqa_newsqa-validation-2927", "mrqa_newsqa-validation-2971", "mrqa_newsqa-validation-3", "mrqa_newsqa-validation-3099", "mrqa_newsqa-validation-3109", "mrqa_newsqa-validation-3122", "mrqa_newsqa-validation-3129", "mrqa_newsqa-validation-3150", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3184", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-321", "mrqa_newsqa-validation-322", "mrqa_newsqa-validation-323", "mrqa_newsqa-validation-3257", "mrqa_newsqa-validation-3278", "mrqa_newsqa-validation-3293", "mrqa_newsqa-validation-3349", "mrqa_newsqa-validation-3353", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-3466", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-3511", "mrqa_newsqa-validation-3566", "mrqa_newsqa-validation-361", "mrqa_newsqa-validation-3620", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3793", "mrqa_newsqa-validation-383", "mrqa_newsqa-validation-3894", "mrqa_newsqa-validation-3914", "mrqa_newsqa-validation-3954", "mrqa_newsqa-validation-4016", "mrqa_newsqa-validation-4103", "mrqa_newsqa-validation-4120", "mrqa_newsqa-validation-4155", "mrqa_newsqa-validation-4170", "mrqa_newsqa-validation-4175", "mrqa_newsqa-validation-4192", "mrqa_newsqa-validation-4196", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-451", "mrqa_newsqa-validation-523", "mrqa_newsqa-validation-524", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-552", "mrqa_newsqa-validation-57", "mrqa_newsqa-validation-591", "mrqa_newsqa-validation-665", "mrqa_newsqa-validation-666", "mrqa_newsqa-validation-701", "mrqa_newsqa-validation-745", "mrqa_newsqa-validation-78", "mrqa_newsqa-validation-846", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-884", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-997", "mrqa_searchqa-validation-10025", "mrqa_searchqa-validation-10101", "mrqa_searchqa-validation-10241", "mrqa_searchqa-validation-10547", "mrqa_searchqa-validation-10578", "mrqa_searchqa-validation-10588", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-10696", "mrqa_searchqa-validation-11141", "mrqa_searchqa-validation-11579", "mrqa_searchqa-validation-11699", "mrqa_searchqa-validation-11813", "mrqa_searchqa-validation-11835", "mrqa_searchqa-validation-11866", "mrqa_searchqa-validation-1195", "mrqa_searchqa-validation-12095", "mrqa_searchqa-validation-12886", "mrqa_searchqa-validation-13371", "mrqa_searchqa-validation-13411", "mrqa_searchqa-validation-1373", "mrqa_searchqa-validation-13757", "mrqa_searchqa-validation-13800", "mrqa_searchqa-validation-14133", "mrqa_searchqa-validation-14277", "mrqa_searchqa-validation-14360", "mrqa_searchqa-validation-14442", "mrqa_searchqa-validation-14523", "mrqa_searchqa-validation-14604", "mrqa_searchqa-validation-14731", "mrqa_searchqa-validation-14890", "mrqa_searchqa-validation-14916", "mrqa_searchqa-validation-14939", "mrqa_searchqa-validation-15296", "mrqa_searchqa-validation-15850", "mrqa_searchqa-validation-15886", "mrqa_searchqa-validation-15999", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-16014", "mrqa_searchqa-validation-16155", "mrqa_searchqa-validation-16530", "mrqa_searchqa-validation-16533", "mrqa_searchqa-validation-1980", "mrqa_searchqa-validation-2000", "mrqa_searchqa-validation-2021", "mrqa_searchqa-validation-2307", "mrqa_searchqa-validation-2604", "mrqa_searchqa-validation-2720", "mrqa_searchqa-validation-2776", "mrqa_searchqa-validation-3052", "mrqa_searchqa-validation-3342", "mrqa_searchqa-validation-3571", "mrqa_searchqa-validation-3721", "mrqa_searchqa-validation-3934", "mrqa_searchqa-validation-4019", "mrqa_searchqa-validation-4161", "mrqa_searchqa-validation-426", "mrqa_searchqa-validation-4613", "mrqa_searchqa-validation-4913", "mrqa_searchqa-validation-4921", "mrqa_searchqa-validation-50", "mrqa_searchqa-validation-5032", "mrqa_searchqa-validation-547", "mrqa_searchqa-validation-5525", "mrqa_searchqa-validation-5585", "mrqa_searchqa-validation-5704", "mrqa_searchqa-validation-5813", "mrqa_searchqa-validation-5873", "mrqa_searchqa-validation-6296", "mrqa_searchqa-validation-6684", "mrqa_searchqa-validation-6863", "mrqa_searchqa-validation-6874", "mrqa_searchqa-validation-7035", "mrqa_searchqa-validation-7469", "mrqa_searchqa-validation-7512", "mrqa_searchqa-validation-7664", "mrqa_searchqa-validation-7675", "mrqa_searchqa-validation-7784", "mrqa_searchqa-validation-7821", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-8418", "mrqa_searchqa-validation-8821", "mrqa_searchqa-validation-8894", "mrqa_searchqa-validation-9132", "mrqa_searchqa-validation-9228", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9614", "mrqa_searchqa-validation-9881", "mrqa_squad-validation-10180", "mrqa_squad-validation-10185", "mrqa_squad-validation-10337", "mrqa_squad-validation-10399", "mrqa_squad-validation-111", "mrqa_squad-validation-1311", "mrqa_squad-validation-1555", "mrqa_squad-validation-1572", "mrqa_squad-validation-1763", "mrqa_squad-validation-1897", "mrqa_squad-validation-1974", "mrqa_squad-validation-2032", "mrqa_squad-validation-2731", "mrqa_squad-validation-2875", "mrqa_squad-validation-2985", "mrqa_squad-validation-3423", "mrqa_squad-validation-3441", "mrqa_squad-validation-3473", "mrqa_squad-validation-392", "mrqa_squad-validation-4114", "mrqa_squad-validation-4128", "mrqa_squad-validation-4178", "mrqa_squad-validation-4436", "mrqa_squad-validation-4546", "mrqa_squad-validation-4708", "mrqa_squad-validation-479", "mrqa_squad-validation-4927", "mrqa_squad-validation-558", "mrqa_squad-validation-6637", "mrqa_squad-validation-7079", "mrqa_squad-validation-7141", "mrqa_squad-validation-7333", "mrqa_squad-validation-7488", "mrqa_squad-validation-7599", "mrqa_squad-validation-7698", "mrqa_squad-validation-801", "mrqa_squad-validation-8030", "mrqa_squad-validation-8308", "mrqa_squad-validation-8513", "mrqa_squad-validation-9162", "mrqa_squad-validation-9184", "mrqa_squad-validation-9254", "mrqa_squad-validation-9600", "mrqa_squad-validation-9921", "mrqa_triviaqa-validation-1159", "mrqa_triviaqa-validation-1314", "mrqa_triviaqa-validation-1392", "mrqa_triviaqa-validation-1427", "mrqa_triviaqa-validation-1516", "mrqa_triviaqa-validation-1645", "mrqa_triviaqa-validation-1663", "mrqa_triviaqa-validation-1822", "mrqa_triviaqa-validation-1915", "mrqa_triviaqa-validation-1977", "mrqa_triviaqa-validation-2118", "mrqa_triviaqa-validation-2141", "mrqa_triviaqa-validation-2151", "mrqa_triviaqa-validation-2196", "mrqa_triviaqa-validation-2315", "mrqa_triviaqa-validation-235", "mrqa_triviaqa-validation-2596", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2614", "mrqa_triviaqa-validation-2796", "mrqa_triviaqa-validation-2806", "mrqa_triviaqa-validation-2874", "mrqa_triviaqa-validation-2891", "mrqa_triviaqa-validation-2907", "mrqa_triviaqa-validation-3037", "mrqa_triviaqa-validation-3074", "mrqa_triviaqa-validation-3110", "mrqa_triviaqa-validation-3114", "mrqa_triviaqa-validation-3118", "mrqa_triviaqa-validation-3121", "mrqa_triviaqa-validation-3210", "mrqa_triviaqa-validation-3241", "mrqa_triviaqa-validation-3290", "mrqa_triviaqa-validation-3369", "mrqa_triviaqa-validation-338", "mrqa_triviaqa-validation-3503", "mrqa_triviaqa-validation-3549", "mrqa_triviaqa-validation-3624", "mrqa_triviaqa-validation-3771", "mrqa_triviaqa-validation-3779", "mrqa_triviaqa-validation-3868", "mrqa_triviaqa-validation-388", "mrqa_triviaqa-validation-3973", "mrqa_triviaqa-validation-3989", "mrqa_triviaqa-validation-4022", "mrqa_triviaqa-validation-4028", "mrqa_triviaqa-validation-4065", "mrqa_triviaqa-validation-4098", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4117", "mrqa_triviaqa-validation-4139", "mrqa_triviaqa-validation-4153", "mrqa_triviaqa-validation-4481", "mrqa_triviaqa-validation-4588", "mrqa_triviaqa-validation-4594", "mrqa_triviaqa-validation-4840", "mrqa_triviaqa-validation-4884", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-5003", "mrqa_triviaqa-validation-5038", "mrqa_triviaqa-validation-5063", "mrqa_triviaqa-validation-5142", "mrqa_triviaqa-validation-5151", "mrqa_triviaqa-validation-5484", "mrqa_triviaqa-validation-5489", "mrqa_triviaqa-validation-5618", "mrqa_triviaqa-validation-5630", "mrqa_triviaqa-validation-5652", "mrqa_triviaqa-validation-5732", "mrqa_triviaqa-validation-5777", "mrqa_triviaqa-validation-582", "mrqa_triviaqa-validation-5904", "mrqa_triviaqa-validation-5991", "mrqa_triviaqa-validation-6206", "mrqa_triviaqa-validation-6212", "mrqa_triviaqa-validation-6227", "mrqa_triviaqa-validation-6260", "mrqa_triviaqa-validation-6291", "mrqa_triviaqa-validation-6381", "mrqa_triviaqa-validation-6510", "mrqa_triviaqa-validation-6669", "mrqa_triviaqa-validation-6747", "mrqa_triviaqa-validation-688", "mrqa_triviaqa-validation-690", "mrqa_triviaqa-validation-692", "mrqa_triviaqa-validation-6945", "mrqa_triviaqa-validation-700", "mrqa_triviaqa-validation-7034", "mrqa_triviaqa-validation-7159", "mrqa_triviaqa-validation-7286", "mrqa_triviaqa-validation-7298", "mrqa_triviaqa-validation-7361", "mrqa_triviaqa-validation-7639", "mrqa_triviaqa-validation-77", "mrqa_triviaqa-validation-772", "mrqa_triviaqa-validation-802", "mrqa_triviaqa-validation-858", "mrqa_triviaqa-validation-972", "mrqa_triviaqa-validation-989"], "OKR": 0.826171875, "KG": 0.5, "before_eval_results": {"predictions": ["stoned", "three", "dismissed all charges Wednesday night and ordered the release of the four men", "U.S. Defense Department", "11,", "inmates", "Kenyan and Somali", "prostate cancer,", "22-year-old college student in Boston, Massachusetts,", "crocodile eggs", "Jacob,", "crafts poems telling of the pain and suffering of children just like her;", "\"Red Lines,\"", "The Kirchners", "an African-American woman for the job.", "Arsene Wenger", "Arnold Drummond", "in the Carrousel du Louvre,", "left his indelible fingerprints on the entertainment industry.", "Revolutionary Armed Forces of Colombia,", "his business dealings", "toxic smoke from burn pits", "nearly three weeks after the body of a pregnant soldier was found in a hotel near Fort Bragg.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "\"El Senor de los Cielos,\"", "Kerstin Fritzl,", "Amnesty International.", "Dr. Octopus", "\"Let it Roll: Songs by George Harrison\"", "\"to do the dirty work,\"", "a lump in Henry's nether regions", "not", "snow,", "\"Steamboat Bill, Jr.\"", "dogs who walk on ice in Alaska.", "45 minutes, five days a week.", "students at the school.", "Harrison Ford", "Alicia Keys", "as he tried to throw a petrol bomb", "al-Moayad", "\"I now realize how my comments could be construed as racist,\"", "almost one-third of the Los Angeles police force", "attack on Christians in some time -- but far from the only one.", "cause of the child's death will be listed as homicide by undetermined means,", "in Darfur.", "about 2,000", "facing Lake Washington", "(l-r)", "9", "for the rest of the year", "hydrogen", "Kevin Spacey", "foreign investors", "neck", "wrigley", "CBS", "round five of the 2017 season", "North Dakota", "Tom Wolfe", "Charlie and the Chocolate Factory", "Death of a Salesman", "Sports Illustrated", "Colonel"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5565125253036437}, "metric_results_detailed": {"EM": [false, false, false, true, true, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, false, false, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true], "QA-F1": [0.0, 0.0, 0.42857142857142855, 1.0, 1.0, 1.0, 0.0, 1.0, 0.30769230769230765, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.15384615384615383, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6, 0.0, 0.0, 0.0, 1.0, 1.0, 0.25, 0.5714285714285715, 0.5, 1.0, 0.5, 0.0, 1.0, 0.10526315789473685, 0.0, 0.13333333333333333, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-530", "mrqa_newsqa-validation-807", "mrqa_newsqa-validation-3805", "mrqa_newsqa-validation-2231", "mrqa_newsqa-validation-834", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-1827", "mrqa_newsqa-validation-2952", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1398", "mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2925", "mrqa_newsqa-validation-2850", "mrqa_newsqa-validation-3869", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-3880", "mrqa_newsqa-validation-421", "mrqa_newsqa-validation-4077", "mrqa_newsqa-validation-3798", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-120", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-955", "mrqa_newsqa-validation-2431", "mrqa_newsqa-validation-1992", "mrqa_newsqa-validation-1961", "mrqa_newsqa-validation-2133", "mrqa_naturalquestions-validation-4326", "mrqa_hotpotqa-validation-2793", "mrqa_hotpotqa-validation-34"], "SR": 0.484375, "CSR": 0.53859375, "EFR": 0.9696969696969697, "Overall": 0.714939393939394}]}