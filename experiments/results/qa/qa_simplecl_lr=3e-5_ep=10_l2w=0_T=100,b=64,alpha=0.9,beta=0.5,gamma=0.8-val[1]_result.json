{"method_class": "simple_cl", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/qa_simplecl_lr=3e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]', diff_loss_weight=0.0, gradient_accumulation_steps=1, kg_eval_freq=50, kg_eval_mode='metric', kr_eval_freq=50, kr_eval_mode='metric', learning_rate=3e-05, max_grad_norm=0.1, num_epochs=10.0, okr_sample_seed=1337, okr_sample_size=512, save_ckpt_freq=100, skip_instant_eval=False, total_steps=10000, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/qa_simplecl_lr=3e-5_ep=10_l2w=0_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val[1]_result.json', stream_id=1, submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8-val.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 4170, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["the Cobham\u2013Edmonds thesis", "15 February 1546", "special efforts", "17", "southwestern France", "CBS Sports", "different viewpoints and political parties", "Thomas Commerford Martin", "24 August \u2013 3 October 1572", "long, slender tentacles", "45 minutes", "Town Moor", "BBC HD", "Ealy", "August 15, 1971", "a squared integer", "declared Japan a \"nonfriendly\" country", "a cubic interpolation formula", "huge mouths armed with groups of large, stiffened cilia that act as teeth", "1852", "an intuitive understanding", "the Small Catechism", "learning of the execution of Johann Esch and Heinrich Voes", "Super Bowl XLVII", "Ozone depletion and global warming", "widespread education", "chloroplasts", "Warraghiggey", "The Scotland Act 1998", "The Bachelor", "delivery of these messages by store and forward switching", "9000 BP", "criminal investigations", "2002", "sculptures, friezes and tombs", "Sonderungsverbot", "The Simpsons", "826", "English", "energize electrons", "Catholicism", "Robert R. Gilruth", "He prayed, consulted friends, and gave his response the next day", "young men who had not fought", "Manakin Town", "tidal delta", "A Charlie Brown Christmas", "formal", "Establishing \"natural borders\"", "(sworn brother or blood brother)", "Tyneside's shipbuilding heritage, and inventions which changed the world", "structural collapse, cost overruns, and/or litigation", "severely reduced rainfall and increased temperatures", "sponges", "Cam Newton", "science fiction", "Sonia Shankman Orthogenic School", "an aided or an unaided school", "steam turbine plant", "metamorphic processes", "faith", "article 49", "the meeting of the Church's General Assembly", "missing self"], "metric_results": {"EM": 0.765625, "QA-F1": 0.781423611111111}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, true, false, true, true, true, false, false, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-526", "mrqa_squad-validation-2974", "mrqa_squad-validation-1763", "mrqa_squad-validation-4621", "mrqa_squad-validation-2394", "mrqa_squad-validation-8719", "mrqa_squad-validation-8896", "mrqa_squad-validation-5773", "mrqa_squad-validation-5812", "mrqa_squad-validation-2113", "mrqa_squad-validation-5676", "mrqa_squad-validation-5226", "mrqa_squad-validation-337", "mrqa_squad-validation-1662", "mrqa_squad-validation-6947"], "SR": 0.765625, "CSR": 0.765625, "EFR": 1.0, "Overall": 0.8828125}, {"timecode": 1, "before_eval_results": {"predictions": ["The Adventures of Ozzie and Harriet", "The Open Championship golf and The Wimbledon tennis tournaments", "32.9%", "365.2425 days of the year", "health care", "1970s", "Sunni Arabs from Iraq and Syria", "P,NP-complete, orNP-intermediate", "Daniel Burke", "the highest terrace", "major national and international patient information projects", "three", "net force", "12 January", "1976\u201377", "Cleveland, Phoenix, Detroit and Denver", "zoning and building code requirements", "river Deabolis", "1968", "King George III", "Baden-W\u00fcrttemberg", "lines or a punishment essay", "Book of Discipline", "complicated definitions", "lead author", "TFEU article 294", "G. H. Hardy", "30-second", "Royal Ujazd\u00f3w Castle", "Church and the Methodist-Christian theological tradition", "the main hall", "the Teaching Council", "One could wish that Luther had died before ever", "Russell T Davies", "Cape Town", "Gospi\u0107, Austrian Empire", "Classic FM's Hall of Fame", "optimisation", "2014", "late 1970s", "30%", "1983", "Happy Days", "1,230 kilometres", "23 November 1963", "Apollo 20", "six divisions", "scoil phr\u00edobh\u00e1ideach", "business", "teachers in publicly funded schools", "Saul Bellow, political philosopher, literary critic and author of the New York Times bestseller \"The Closing of the American Mind\" Allan Bloom", "1991", "organisms", "41", "carbon", "the fertile highlands", "harder", "50% to 60%", "Norman Greenbaum", "Depending on the particular legal rules that apply to each circumstance, a party to a court case who is unhappy with the result might be able to challenge that result in an appellate court on specific grounds", "The Prisoners ( Temporary Discharge for Ill Health ) Act", "Carol Ann Susi", "Daenerys Targaryen", "Raabta"], "metric_results": {"EM": 0.78125, "QA-F1": 0.818827322595705}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.5, 0.0, 1.0, 1.0, 0.14285714285714285, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.11764705882352941, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6323", "mrqa_squad-validation-9752", "mrqa_squad-validation-1791", "mrqa_squad-validation-6388", "mrqa_squad-validation-6059", "mrqa_squad-validation-8616", "mrqa_squad-validation-2611", "mrqa_squad-validation-6282", "mrqa_squad-validation-1906", "mrqa_squad-validation-8035", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7792", "mrqa_hotpotqa-validation-1006"], "SR": 0.78125, "CSR": 0.7734375, "EFR": 0.9285714285714286, "Overall": 0.8510044642857143}, {"timecode": 2, "before_eval_results": {"predictions": ["235", "NP", "\"Smith and Jones\"", "1767", "53,000", "Fu\u00dfach", "leptin, pituitary growth hormone, and prolactin", "accelerate to six times its normal speed", "7 West 66th Street", "patent archives", "Members of Parliament", "4-week period", "six", "His wife Katharina", "Colorado Desert", "John Pell, Lord of Pelham Manor", "United States", "2014", "Alberto Calder\u00f3n", "Roger NFL", "1950s", "1980s", "Cologne, Germany", "second use of the law", "free", "1973", "1971", "Mansfeld", "Warsaw Stock Exchange", "390 billion", "a suite of network protocols", "eighteenth century", "journal Nature", "2009", "Franz Pieper", "geochemical evolution of rock units", "three times", "rhetoric", "Genoese traders", "the flail of God", "Saudi Arabia and Iran", "149,025", "1898", "Lunar Module Pilot", "citizenship", "Merritt Island", "accountants", "return home", "June 4, 2014", "kinetic friction force", "\u2153 to Tesla", "signal amplification", "Lituya Bay in Alaska", "120 m ( 390 ft )", "Game of Throne", "100 members", "photoelectric", "Welch, West Virginia", "Declaration of Indian Independence ( Purna Swaraj )", "twelve Wimpy Kid books", "Hal David and Burt Bacharach", "five points", "the Ironclads", "Spain"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7865065056471308}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, false, true, false, true, true, true, false, true, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.16666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.375, 1.0, 1.0, 0.888888888888889, 0.0, 1.0, 0.4, 1.0, 0.34285714285714286, 0.38095238095238093, 0.0, 0.5, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4731", "mrqa_squad-validation-5972", "mrqa_squad-validation-9559", "mrqa_squad-validation-2689", "mrqa_squad-validation-80", "mrqa_squad-validation-9173", "mrqa_squad-validation-4415", "mrqa_squad-validation-4673", "mrqa_squad-validation-1841", "mrqa_squad-validation-1220", "mrqa_naturalquestions-validation-3722", "mrqa_naturalquestions-validation-2438", "mrqa_naturalquestions-validation-3498", "mrqa_naturalquestions-validation-8782", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-6125", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-2643", "mrqa_searchqa-validation-3996"], "SR": 0.703125, "CSR": 0.75, "EFR": 0.9473684210526315, "Overall": 0.8486842105263157}, {"timecode": 3, "before_eval_results": {"predictions": ["immunosuppressive", "William of Volpiano and John of Ravenna", "April 1523", "Excellent job opportunities", "rebellion is much more destructive", "The principle of inclusions and components", "they were accepted and allowed to worship freely", "12 December 2007", "six", "redistributive taxation", "rubisco", "recalled and replaced by Jeffery Amherst", "Egypt", "algae", "4,404.5 people per square mile", "the Data Distribution Centre and the National Greenhouse Gas Inventories Programme", "chromoplasts and amyloplasts", "the Chinese", "Stairs", "genetically modified plants", "around 300,000", "three", "Von Miller", "Africa", "the clinical services that pharmacists can provide for their patients", "Raghuram Rajan", "soluble components (molecules) found in the organism\u2019s \u201chumors\u201d rather than its cells", "Mark Ronson", "the Calvin cycle which uses rubisco", "their Annual Conference", "Philo of Byzantium", "the mayor (the President of Warsaw), who may sign them into law", "cloud storage service", "Doritos", "Warsaw University of Technology building", "the Great Yuan", "Lenin", "the Solim\u00f5es Basin", "Charles Darwin", "23 November", "oppidum Ubiorum", "Denver's Executive Vice President of Football Operations and General Manager", "Downtown Riverside", "Capital Cities Communications", "lamprey and hagfish", "physicians and other healthcare professionals", "the Golden Gate Bridge", "Michael Schumacher", "10.5 %", "The Man", "President Gerald Ford", "Jane Fonda", "Janie Crawford", "the optic disc to the optic chiasma and continues as the optic tract to the lateral geniculate nucleus, pretectal nuclei, and superior colliculus", "Jerry Ekandjo", "961", "in awe of Novalee, and had seen her enter the store at closing time, smashes through the window to help deliver her child", "December 1971", "the Undying Lands", "the middle of the 15th century", "6 March 1983", "Viola Larsen", "horror fiction", "26,000"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7313358516483517}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.923076923076923, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.42857142857142855, 0.0, 0.5714285714285715, 1.0, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.1904761904761905, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4108", "mrqa_squad-validation-8830", "mrqa_squad-validation-10293", "mrqa_squad-validation-4759", "mrqa_squad-validation-8763", "mrqa_squad-validation-6154", "mrqa_squad-validation-298", "mrqa_squad-validation-6614", "mrqa_squad-validation-670", "mrqa_squad-validation-8833", "mrqa_squad-validation-962", "mrqa_squad-validation-9298", "mrqa_squad-validation-384", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-8136", "mrqa_naturalquestions-validation-3368", "mrqa_naturalquestions-validation-6445", "mrqa_naturalquestions-validation-5812", "mrqa_naturalquestions-validation-1000", "mrqa_naturalquestions-validation-421", "mrqa_naturalquestions-validation-4134", "mrqa_naturalquestions-validation-4433", "mrqa_hotpotqa-validation-454"], "SR": 0.640625, "CSR": 0.72265625, "EFR": 1.0, "Overall": 0.861328125}, {"timecode": 4, "before_eval_results": {"predictions": ["infrequent rain", "the king of France", "approximately 80 avulsions", "15", "Fort Presque Isle (near present-day Erie, Pennsylvania)", "wireless", "Bruno Mars", "the Yuan dynasty", "same-gender marriages with resolutions", "one of the pigments that makes many red algae red", "after their second year", "1960s", "the freedom to provide services", "Napoleon", "Immunology", "geophysical surveys", "topographic", "130 million cubic foot (3.7 million cubic meter)", "the 50 fund", "was particularly forceful, stating that British colonists would not be safe as long as the French were present.", "ctenophores and cnidarians", "motivated students", "Michael Mullett", "15", "James Gamble & Reuben Townroe", "dissension and unrest", "the Establishment Clause of the First Amendment or individual state Blaine Amendments", "\"Turks\" (Muslims) and Catholics", "six", "Big Ten Conference", "Thames River", "Cisco Systems", "shipping toxic waste", "anarchists", "carrots, turnips, new varieties of lemons, eggplants, and melons, high-quality granulated sugar, and cotton", "immunoglobulins and T cell receptors", "previously separated specialties", "their parent thylakoid", "a motorway underpass without pedestrian access", "to protect their tribal lands from commercial interests", "religious beliefs according to the Scottish census", "evading it", "the kettle and the Cricket", "Gandhi", "Bucharest", "The Little Foxes", "the Betamax", "Vincent van Gogh", "12/3, 10/3 or 3/4", "Danny Lee", "the University of Arizona", "Marshall Dillon", "the Bosporus Bridge links", "the north part of Kuta", "Ted Cruz", "a device that produces a nearly parallel, nearly... 1955-60", "Sami-Tasse", "Juno", "Peat moss", "why", "Andrew Taggart, Emily Warren and Scott Harris", "the fear of riding in a car", "American", "Enrique Torres"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6256087662337662}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, false, false, true, false, false, false, true, true, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.1818181818181818, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.28571428571428575, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5714285714285715, 1.0, 0.5, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9357", "mrqa_squad-validation-110", "mrqa_squad-validation-8840", "mrqa_squad-validation-4461", "mrqa_squad-validation-3703", "mrqa_squad-validation-10186", "mrqa_squad-validation-1960", "mrqa_squad-validation-8131", "mrqa_squad-validation-7088", "mrqa_squad-validation-8767", "mrqa_squad-validation-5214", "mrqa_squad-validation-9406", "mrqa_squad-validation-6721", "mrqa_searchqa-validation-12428", "mrqa_searchqa-validation-12311", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-5639", "mrqa_searchqa-validation-10360", "mrqa_searchqa-validation-12426", "mrqa_searchqa-validation-12931", "mrqa_searchqa-validation-14767", "mrqa_searchqa-validation-6541", "mrqa_searchqa-validation-15379", "mrqa_searchqa-validation-10506", "mrqa_searchqa-validation-16377", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-11224", "mrqa_naturalquestions-validation-124", "mrqa_triviaqa-validation-6073", "mrqa_newsqa-validation-496"], "SR": 0.53125, "CSR": 0.684375, "EFR": 0.9666666666666667, "Overall": 0.8255208333333333}, {"timecode": 5, "before_eval_results": {"predictions": ["bacteriophage T4", "6.7", "second-largest", "time and space", "the Meuse", "a Western Union superintendent", "Super Bowl XLIV", "1891", "New Orleans", "hunting", "the member state cannot enforce conflicting laws", "the work of British bacteriologist J. F. D. Shrewsbury", "a mouth that can usually be closed by muscles; a pharynx (\"throat\"); a wider area in the center that acts as a stomach; and a system of internal canals", "inversely", "Europe", "he was illiterate in Czech, another required subject", "colonies", "$37.6 billion", "Kalenjin", "1269", "the 17th century", "Time Warner Cable", "toward the Atlantic", "economic", "CrossCountry", "ITV", "SAP Center in San Jose", "Variable lymphocytes receptors (VLRs)", "the Edict of Fontainebleau", "Levi's Stadium", "ten million people", "the Lippe", "Video On Demand content", "time and storage", "mid-May", "the courts of member states and the Court of Justice of the European Union", "Thomas Edison", "1971", "quantum mechanics", "Lawrence, Nassau County, New York", "League of the Three Emperors", "Engineering", "143,007", "Bill Clinton", "Waltham", "Secretariat", "coaxial", "Mary Harron", "Boston, Providence, Hartford, New York City, Philadelphia, Wilmington, Baltimore, and Washington, D.C.,", "Thomas Christopher Ince", "American Chopper", "drawing the name out of a hat", "German", "Fort Valley, Georgia", "American", "Easy (TV series)", "Belvoir", "Congo River", "Abigail", "Murwillumbah, New South Wales, Australia", "Anansi", "corruption", "24 hours", "Dover Beach"], "metric_results": {"EM": 0.734375, "QA-F1": 0.8427489566228791}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, false, false, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.48275862068965514, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.75, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-1775", "mrqa_squad-validation-4919", "mrqa_squad-validation-1187", "mrqa_squad-validation-8544", "mrqa_squad-validation-457", "mrqa_squad-validation-6676", "mrqa_squad-validation-9753", "mrqa_squad-validation-1672", "mrqa_squad-validation-7214", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-61", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-2452", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-2315", "mrqa_triviaqa-validation-1616", "mrqa_searchqa-validation-14229"], "SR": 0.734375, "CSR": 0.6927083333333333, "EFR": 1.0, "Overall": 0.8463541666666666}, {"timecode": 6, "before_eval_results": {"predictions": ["1540s", "the Court of Justice of the European Union", "its circle logo", "three", "negative", "fear of their lives", "80%", "1521", "Gibraltar and the \u00c5land islands", "distorting the grana and thylakoids", "exceeds any given number", "Hulagu Khan", "poet", "quality rental units", "Grover Cleveland", "to overthrow a government", "entertainment", "A vote clerk", "high growth rates", "a vicious and destructive civil war", "Sony", "Stagecoach", "Silk Road", "San Diego", "a German Nazi colonial administration", "four public charter schools", "wealth concentrates in the possession of already-wealthy individuals or entities", "Spanish", "Structural geologists", "president and CEO of ABC", "indulgences for the living", "BSkyB", "terrorist organisation", "Cam Newton", "The U2 360\u00b0 Tour", "The 5 foot 9 inch tall twins", "James Victor Chesnutt", "Benjamin Burwell Johnston, Jr.", "Sinclair Oil Corporation", "Taylor Swift", "Eric Edward Whitacre", "the Joint Chiefs of Staff", "Linux Format", "Jasenovac", "Rabat", "between 11 or 13 and 18", "Heather Elizabeth Langenkamp (born July 17, 1964)", "Henry Gwyn Jeffreys Moseley", "racing", "Vilnius Airport (IATA: VNO, ICAO: EYVI)", "Bury St Edmunds, Suffolk, England", "The WB supernatural drama series \"Charmed\"", "Cleopatra \" Cleo\" Demetriou ( ; Greek: \u039a\u03bb\u03b5\u03bf\u03c0\u03ac\u03c4\u03c1\u03b1 \u0394\u03b7\u03bc\u03b7\u03c4\u03c1\u03af\u03bf\u03c5 ; born 23 April 2001)", "English former international footballer", "Oregon Ducks", "Rickie Lee Skaggs", "48,982", "Ashanti", "79", "Algeria", "The State newspaper in Columbia, South Carolina's capital", "Biafra", "The Stanza della Segnatura", "Atlantic City"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7364459325396825}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, true, false, true, true, false, true, false, true], "QA-F1": [1.0, 0.2, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.4, 0.3333333333333333, 0.0, 1.0, 0.8, 1.0, 0.0, 0.5, 0.0, 1.0, 0.4444444444444445, 0.6666666666666666, 0.0, 0.8, 0.7499999999999999, 0.33333333333333337, 0.0, 0.5714285714285715, 0.8, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3939", "mrqa_squad-validation-5774", "mrqa_squad-validation-6788", "mrqa_squad-validation-6029", "mrqa_squad-validation-9665", "mrqa_squad-validation-7543", "mrqa_squad-validation-5651", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-1013", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5649", "mrqa_hotpotqa-validation-5559", "mrqa_hotpotqa-validation-4642", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-2639", "mrqa_hotpotqa-validation-1291", "mrqa_hotpotqa-validation-226", "mrqa_hotpotqa-validation-976", "mrqa_hotpotqa-validation-234", "mrqa_hotpotqa-validation-49", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-3862", "mrqa_hotpotqa-validation-151", "mrqa_hotpotqa-validation-5300", "mrqa_newsqa-validation-3377", "mrqa_searchqa-validation-1971"], "SR": 0.578125, "CSR": 0.6763392857142857, "EFR": 1.0, "Overall": 0.8381696428571428}, {"timecode": 7, "before_eval_results": {"predictions": ["IgG", "Amazoneregenwoud", "co-NP", "BBC Radio Newcastle", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "the working fluid", "suite of network protocols created by Digital Equipment Corporation", "American Baptist Education Society", "Dutch", "the solution", "means to invest in new sources of creating wealth or to otherwise leverage the accumulation of wealth", "the center of mass", "attention-seeking and disruptive students", "more than $45,000", "Defensive ends", "MLB", "the papacy", "through homologous recombination", "the Alter Rhein (\"Old Rhine\")", "in protest against the occupation of Prussia by Napoleon", "improved markedly", "about the northern (German) shore of the lake, off the island of Lindau", "computer programs", "General Conference of the United Methodist Church", "1996", "dreams", "The Judiciary", "a deterministic Turing machine", "Bart Starr", "allotrope", "the Karluk Kara-Khanid ruler", "Perth, Western Australia", "Ian Rush", "Gerry Adams", "New Orleans Saints", "2016", "four", "Harris Museum, Harris Institute or Art School, Harris Technical School and the Harris Orphanage", "Alfred Edward Housman", "capital of the Socialist Republic of Vietnam", "Sevens", "fennec", "Bart Conner", "fantasy role-playing game", "Martin \"Marty\" McCann", "Black Mountain College", "a historic house museum", "Bothtec", "Cody Miller", "140 to 219", "the \"Father of Liberalism\"", "Garth Jennings", "Pablo Escobar", "African descent", "Mexico City", "Sleeping Beauty", "2005", "1985", "Raphael Blyton", "The son of Gabon's former president", "Wheat Chex cereal", "Ray Harroun", "Emily Blunt", "David Tennant"], "metric_results": {"EM": 0.65625, "QA-F1": 0.7382440476190477}, "metric_results_detailed": {"EM": [true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, true, false, true, true, false, false, false, true, false, true, false, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.09523809523809523, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 0.4, 0.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3019", "mrqa_squad-validation-7547", "mrqa_squad-validation-9183", "mrqa_squad-validation-9287", "mrqa_squad-validation-1819", "mrqa_hotpotqa-validation-265", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-2127", "mrqa_hotpotqa-validation-840", "mrqa_hotpotqa-validation-2974", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-1684", "mrqa_hotpotqa-validation-2702", "mrqa_hotpotqa-validation-1875", "mrqa_hotpotqa-validation-398", "mrqa_hotpotqa-validation-4405", "mrqa_hotpotqa-validation-3885", "mrqa_naturalquestions-validation-4388", "mrqa_triviaqa-validation-1573", "mrqa_searchqa-validation-15869", "mrqa_naturalquestions-validation-1618"], "SR": 0.65625, "CSR": 0.673828125, "EFR": 1.0, "Overall": 0.8369140625}, {"timecode": 8, "before_eval_results": {"predictions": ["Russian", "cellular respiration", "railroad", "non-revolutionary", "during the compression stage relatively little work is required to drive the pump", "Lunar Excursion Module", "the Zwickau prophets", "six years", "700", "the 5th Avenue laboratory fire", "the history of arms", "two", "minor", "Fringe or splinter movements", "17", "lower temperatures", "architect or engineer", "1917", "Columbus Avenue and West 66th Street", "TeacherspayTeachers.com", "stratigraphic", "commensal flora", "a + bi", "Dallas, Texas", "Central Asian Muslims", "from home viewers", "1330 Avenue of the Americas in Manhattan", "Alberta and British Columbia", "\"Pimp My Ride\"", "Don Johnson", "\"Section.80\"", "25 million", "8,515", "13 October 1958", "tailless delta wing", "Environmental Protection Agency", "between 1932 and 1934", "an English professional footballer", "Los Angeles", "England", "Armin Meiwes", "Jean- Marc Vall\u00e9e", "Miss Universe 2010", "Dusty Dvoracek", "boxer", "Boston University", "Fulham", "A55", "Ranulf de Gernon", "\u00c6thelstan", "West Tambaram", "44", "NCAA's Division I", "Harriet Tubman", "Manchester United", "Dragon TV", "Greek-American", "A diastema", "Alison Krauss", "Iran", "Bigfoot", "Papua New Guinea", "Renoir", "Manchester"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7769412878787878}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, true, true, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7272727272727273, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.5, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.3636363636363636, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-6789", "mrqa_squad-validation-1501", "mrqa_squad-validation-9859", "mrqa_squad-validation-7643", "mrqa_hotpotqa-validation-4363", "mrqa_hotpotqa-validation-510", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-2323", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4164", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-2300", "mrqa_hotpotqa-validation-5108", "mrqa_hotpotqa-validation-1633", "mrqa_hotpotqa-validation-3597", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-305", "mrqa_naturalquestions-validation-3553"], "SR": 0.703125, "CSR": 0.6770833333333333, "EFR": 1.0, "Overall": 0.8385416666666666}, {"timecode": 9, "before_eval_results": {"predictions": ["$32 billion", "variable steam cut off", "Orange County", "The chloroplast peripheral reticulum", "1962", "European Court of Justice held that a Commissioner giving her dentist a job, for which he was clearly unqualified, did in fact not break any law", "Rugby", "Germany", "politically and socially unstable", "Theatre Museum", "90\u00b0", "iTunes", "most organic molecules", "French", "Museum of the Moving Image in London", "sent missionaries, backed by a fund to financially reward converts to Catholicism", "pyrenoid and thylakoids", "Woodward Park", "refusal to submit to arrest", "25 May 1521", "essentially holy people", "diplomacy or military force", "increase in the land available for cultivation", "the value of the spin", "pivotal event", "the transgender movement", "John Alexander", "David Michael Bautista Jr.", "Black Friday", "American actor, singer and a DJ", "Prince Amedeo", "Lambic", "Mazatl\u00e1n", "Assistant Director Neil J. Welch", "March 30, 2025", "England", "Kentucky, Virginia, and Tennessee", "Autopia", "Yasir Hussain", "USC Marshall School of Business", "Stephen Ireland", "Marco Hietala", "Estadio de L\u00f3pez Cort\u00e1zar", "Kohlberg K Travis Roberts", "Fort Albany", "I'm Shipping Up to Boston", "4145 ft above mean sea level and a top to bottom height of over 2500 ft", "Central Park", "Robert John Day", "Tifinagh", "James Tinling", "Italy", "2015 Masters Tournament", "Kristoffer Rygg", "Sullivan University College of Pharmacy", "William Shakespeare", "Bob Dylan", "Erika Mitchell Leonard", "Santiago", "couscous", "1.5 million", "morphine sulfate oral solution 20 mg/ml", "The Firm", "noddy Rhoehit"], "metric_results": {"EM": 0.609375, "QA-F1": 0.666803183639047}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false, false, true, true, false, true, true, true, false, false, true, false, false, true, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, true, true, false, true, true, false, true, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.45161290322580644, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.88, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.22222222222222224, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 1.0, 1.0, 0.23529411764705882, 1.0, 0.4, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.35294117647058826, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3371", "mrqa_squad-validation-4147", "mrqa_squad-validation-3440", "mrqa_squad-validation-2943", "mrqa_squad-validation-7674", "mrqa_squad-validation-3130", "mrqa_squad-validation-8651", "mrqa_squad-validation-4572", "mrqa_squad-validation-6797", "mrqa_squad-validation-9735", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5242", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3280", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-5477", "mrqa_hotpotqa-validation-97", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-3553", "mrqa_hotpotqa-validation-1500", "mrqa_naturalquestions-validation-10208", "mrqa_newsqa-validation-1668", "mrqa_searchqa-validation-3622"], "SR": 0.609375, "CSR": 0.6703125, "EFR": 1.0, "Overall": 0.83515625}, {"timecode": 10, "before_eval_results": {"predictions": ["November 1979", "the Mocama", "suburban", "vertebrates", "Fears of being labelled a pedophile or hebephile", "it consumes ATP and oxygen, releases CO2, and produces no sugar", "Panthers", "Sanders", "even greater inequality and potential economic instability", "Gamal Abdul Nasser", "Immunodeficiencies", "counterflow", "John B. Goodenough", "his arrest was not covered in any newspapers in the days, weeks and months after it happened", "arrows, swords, and leather shields", "Cybermen", "he was profoundly influenced by a math teacher Martin Sekuli\u0107", "Standard Model", "Tolui", "the Rhine-Ruhr region", "pedagogy", "Prevenient grace", "Kansas State", "Captain Cook's Landing Place", "Chris Pine", "Yoo Seung-ho", "the Battle of the Philippines", "NCAA Division I", "The The Onion", "Mickey's PhilharMagic", "A Bug's Life", "1978", "May 2008", "Italy", "La Familia Michoacana", "Uzumaki", "Tom Jones", "the RATE project (Radioisotopes and the Age of The Earth)", "Barbara Niven", "13\u20133", "Eliot Spitzer", "5,042", "European", "the first integrated circuit", "Tianhe Stadium", "1952", "the fourth Thursday", "Giuseppe Verdi", "Germanic", "New Jersey", "Massachusetts", "Ector County", "Jim Davis", "Buck Owens", "the World Health Organization", "Emmanuel Ofosu Yeboah", "the coasts of Australia, New Zealand, Tahiti, Hawaii, Senegal, Ghana, Nigeria and South Africa", "Heather Stebbins", "the cat", "Sir Giles Gilbert Scott", "the rig did not know whether it was working when they fled the burning rig", "the Comoros Islands", "Onomastic Sobriquets In The Food And Beverage Industry", "the cat"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7042477720450282}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, true, false, true, true, true, true, true, false, true, true, false, true, false, true, false, false, true, false, false, true, true, true, true, false, true, false, true, true, true, true, true, true, false, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.923076923076923, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.04878048780487805, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-797", "mrqa_squad-validation-7502", "mrqa_squad-validation-1166", "mrqa_squad-validation-6166", "mrqa_squad-validation-1877", "mrqa_hotpotqa-validation-2725", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-3072", "mrqa_hotpotqa-validation-2977", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-1039", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-1174", "mrqa_hotpotqa-validation-4956", "mrqa_hotpotqa-validation-3200", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-2783", "mrqa_naturalquestions-validation-7415", "mrqa_triviaqa-validation-7398", "mrqa_newsqa-validation-2204", "mrqa_newsqa-validation-3339", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-10351"], "SR": 0.640625, "CSR": 0.6676136363636364, "EFR": 0.9130434782608695, "Overall": 0.7903285573122529}, {"timecode": 11, "before_eval_results": {"predictions": ["UHF", "deflate", "Battle of Olustee", "French", "Only 100\u2013150", "Philo of Byzantium", "The climate is cooler in the savannah grasslands around the capital city, Nairobi, and especially closer to Mount Kenya", "in marine waters worldwide", "$60,000 in cash and stock and a royalty of $2.50 per AC horsepower produced by each motor", "his mother's genetics and influence", "\"shock\"", "cytotoxic natural killer cells and Ctls (cytotoxic T lymphocytes)", "a new element to the standard Christian suspicion of Judaism", "the building is ready to occupy", "boom-and-bust cycles", "all trains calling at Edinburgh and a small number of trains extended to Glasgow, Aberdeen and Inverness", "Richard Allen and Absalom Jones", "earn as much as a healthy young man", "Jamukha", "1969", "a whole industry", "the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations", "in body bags", "near Warsaw, Kentucky", "Arthur E. Morgan III", "April 2010", "McCartney", "does not involve MDC head Morgan Tsvangirai", "lack of a cause of death", "200", "The drug is legal for medical use, though they are still working out the details. A 13-year-old boy joins a gang and is given free ketamine.Glass capsules containing ketamine", "opposition party members", "Missouri", "a \"Racism and racist conversations have no place today in America.\"", "executive director of the Americas Division of Human Rights Watch", "Casa de Campo International Airport", "90", "KARK", "a space for aspiring entrepreneurs to brainstorm with like-minded people", "in her home", "the Employee Free Choice act", "Bush", "more than 200", "This is not a project for commercial gain", "best-of-three series", "Kaka", "a Japanese ex-wife", "Dan Parris, 25, and Rob Lehr, 26", "near Fort Bragg", "two", "The federal government has set aside nearly $2 billion in stimulus funds to clean up Washington State's decommissioned Hanford nuclear site", "Jacob", "Molotov cocktails, rocks and glass", "as many as 250,000", "The singer's personal security guard", "Ark of the Covenant ( the Aron Habrit in Hebrew )", "Jean F Kernel ( 1497 -- 1558 ), a French physician", "The truth was, that as she now stood excited, wild, and honest as the day, her alluring beauty bore out so fully the epithets he had bestowed upon it", "Richmondshire", "1994", "The Conjuring", "The Gallipoli Campaign", "a large bay that protrudes northeast from Lake Huron into Ontario, Canada", "Nowhere Boy"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5646059732531457}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, false, false, false, true, false, false, false, false, true, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.3157894736842105, 0.8571428571428571, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 0.07692307692307693, 0.0, 0.0, 0.0, 1.0, 0.7692307692307693, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.5, 1.0, 0.2608695652173913, 1.0, 1.0, 0.4, 0.0, 0.6, 0.22222222222222224, 0.0, 0.0, 1.0, 1.0, 0.0, 0.15384615384615385, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3087", "mrqa_squad-validation-4611", "mrqa_squad-validation-8397", "mrqa_squad-validation-4524", "mrqa_squad-validation-1257", "mrqa_squad-validation-2493", "mrqa_squad-validation-5287", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-3036", "mrqa_newsqa-validation-2573", "mrqa_newsqa-validation-867", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-3389", "mrqa_newsqa-validation-998", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-3944", "mrqa_newsqa-validation-3300", "mrqa_newsqa-validation-689", "mrqa_newsqa-validation-3958", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-822", "mrqa_newsqa-validation-3415", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-2804", "mrqa_newsqa-validation-2294", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3068", "mrqa_naturalquestions-validation-6898", "mrqa_naturalquestions-validation-5769", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-6176", "mrqa_searchqa-validation-2548", "mrqa_searchqa-validation-8335"], "SR": 0.453125, "CSR": 0.6497395833333333, "EFR": 0.9714285714285714, "Overall": 0.8105840773809523}, {"timecode": 12, "before_eval_results": {"predictions": ["threatened \"Old Briton\" with severe consequences if he continued to trade with the British.", "wealth", "Christ who is the victor over sin, death, and the world.", "Napoleon", "the growth of mass production", "James O. McKinsey", "private actors", "Bell Northern Research", "a body of treaties and legislation", "1227", "lower lake", "three", "Elders", "227,000", "Private Bill Committees", "Bruno Mars", "The catechism", "Stagg Field", "Ian Botham", "Pyotr Tchaikovsky", "Vincent Motorcycle Company", "richmond", "Salvador Allende", "Harold Pinter", "Hawaii", "Erik Thorvaldson", "Apollo", "the 1940 Rodgers and Hart musical", "Mary Seacole", "green", "Indonesia", "supreme religious leader", "richmond", "European Economic Community", "Christine Keeler", "Jesus", "John Joseph \"Jack Nicholson\" Nicholson", "four", "Netherlands", "\"Sugar Baby Love\"", "Coretta Scott King", "Sean", "Bill and Taffy Danoff", "sperm fertilizes an oocyte and together they form a zygote.", "Travis", "The Show", "Robert Kennedy", "Q", "umbrellas", "richmond Kipling", "barber", "richmond", "Murrah Federal Office Building", "Evita", "tobacco", "fortified complex", "bohrium", "Eleanor of Aquitaine", "Mickey Gilley's Club", "hardly ever any stories about male celebrities fighting.", "a delegation of American Muslim and Christian leaders", "richmond", "richmond", "Juan Martin Del Potro."], "metric_results": {"EM": 0.53125, "QA-F1": 0.5871031746031746}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, false, false, true, false, true, false, true, false, true, true, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, false, true, true, true, false, true, false, false, true, true, false, true, false, false, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 0.0, 1.0, 0.8571428571428571, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2262", "mrqa_squad-validation-4257", "mrqa_squad-validation-9418", "mrqa_triviaqa-validation-980", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-6314", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-2240", "mrqa_triviaqa-validation-1390", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-3027", "mrqa_triviaqa-validation-4836", "mrqa_triviaqa-validation-859", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-2028", "mrqa_triviaqa-validation-7105", "mrqa_triviaqa-validation-1740", "mrqa_triviaqa-validation-2326", "mrqa_triviaqa-validation-6944", "mrqa_triviaqa-validation-215", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-2003", "mrqa_triviaqa-validation-6974", "mrqa_naturalquestions-validation-4905", "mrqa_hotpotqa-validation-3819", "mrqa_hotpotqa-validation-729", "mrqa_newsqa-validation-3987", "mrqa_searchqa-validation-4120", "mrqa_searchqa-validation-5929"], "SR": 0.53125, "CSR": 0.640625, "EFR": 0.9666666666666667, "Overall": 0.8036458333333334}, {"timecode": 13, "before_eval_results": {"predictions": ["Polignac's conjecture", "Chilaun", "Pittsburgh Steelers", "Sky Digital", "Allston Science Complex", "divergent boundaries", "9th century", "many", "1775\u20131795", "Dorothy and Michael Hintze", "William Ellery Channing and Ralph Waldo Emerson", "lower canal at Fu\u00dfach, in order to counteract the constant flooding and strong sedimentation in the western Rhine Delta.", "Wesleyan Holiness Consortium", "James Clerk Maxwell", "in whole by charging their students tuition fees.", "Dublin, Cork, Youghal and Waterford", "Tangled", "Thered King", "moles", "diogenes Laertius", "fred island", "Anne Boleyn", "Calvin Coolidge", "Steve McQueen", "Portugal", "tenor saxophone", "three", "komando Pasukan Khusus", "in the northwest of England", "a liquid form", "zanesville", "claire McCain", "Antarctica", "gilding", "aniridia", "stearns Eliot", "River Forth", "woe", "NOW Magazine", "julie James", "Italy", "Canada", "typhoid fever", "Tina Turner", "action figure", "al Bundy", "2010", "probability", "Venezuela", "fredwood", "ozone layer", "40", "phrenology", "San Francisco", "Fall 1998", "Xanthippus", "Chris Weidman", "Drillers Stadium", "one", "Virgin America", "juliet john phelan", "aaroni", "Iran's parliament speaker", "fK Ventspils."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6012152777777777}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.8, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-9233", "mrqa_squad-validation-6983", "mrqa_triviaqa-validation-308", "mrqa_triviaqa-validation-5194", "mrqa_triviaqa-validation-6316", "mrqa_triviaqa-validation-5996", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-2587", "mrqa_triviaqa-validation-6124", "mrqa_triviaqa-validation-2222", "mrqa_triviaqa-validation-6947", "mrqa_triviaqa-validation-7045", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-4777", "mrqa_triviaqa-validation-824", "mrqa_triviaqa-validation-813", "mrqa_triviaqa-validation-4391", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6030", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-7510", "mrqa_triviaqa-validation-2290", "mrqa_triviaqa-validation-2927", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-1733", "mrqa_hotpotqa-validation-1390", "mrqa_searchqa-validation-2972", "mrqa_searchqa-validation-15784", "mrqa_newsqa-validation-2281"], "SR": 0.546875, "CSR": 0.6339285714285714, "EFR": 0.9655172413793104, "Overall": 0.7997229064039408}, {"timecode": 14, "before_eval_results": {"predictions": ["an adult plant's apical meristems", "Tangut", "Persia", "Parliament Square, High Street and George IV Bridge in Edinburgh", "Revolutionary", "Beijing", "three years", "27 July 2008", "chemically bonded to each other", "Aristotle", "St. George's Church", "Missy", "the former Strathclyde Regional Council debating chamber in Glasgow, and to the University of Aberdeen", "public official", "the most cost efficient bidder", "sassafras", "Continent", "thighbone", "Olympia", "Ukraine", "shrews", "stanley johnson", "fire", "amber", "Princeton University", "The executioner's Song", "detroit", "bishkek Tajikistan", "anamosa", "grouchy", "The Comedy of Ephesus", "asylum", "film", "knife", "galaxies", "Cologne", "detroit", "an ingot", "Kosovo", "James Jeffords", "Prague", "tennis", "laurel", "shrews", "Sir Winston Churchill", "shrews", "detroit", "Aunt Esme", "kofi Annan", "boys", "windjammer", "stanley johnson", "germanicus", "Augusta", "counter clockwise", "March 31, 2013", "prufrock and other observations", "prufrock", "December 24, 1973", "David Weissman", "bikinis", "Dalai Lama's current \"middle way approach,\"", "memories of his mother", "Israel"], "metric_results": {"EM": 0.375, "QA-F1": 0.45279017857142856}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, true, true, false, false, false, true, false, false, false, true, true, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.33333333333333337, 1.0, 1.0, 0.0, 0.761904761904762, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 0.25, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8346", "mrqa_squad-validation-2105", "mrqa_squad-validation-3488", "mrqa_squad-validation-7818", "mrqa_squad-validation-9402", "mrqa_squad-validation-6801", "mrqa_searchqa-validation-2291", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-15477", "mrqa_searchqa-validation-16197", "mrqa_searchqa-validation-12064", "mrqa_searchqa-validation-4727", "mrqa_searchqa-validation-6146", "mrqa_searchqa-validation-9588", "mrqa_searchqa-validation-9762", "mrqa_searchqa-validation-4439", "mrqa_searchqa-validation-6335", "mrqa_searchqa-validation-12761", "mrqa_searchqa-validation-1187", "mrqa_searchqa-validation-13745", "mrqa_searchqa-validation-14997", "mrqa_searchqa-validation-3873", "mrqa_searchqa-validation-15019", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-12545", "mrqa_searchqa-validation-297", "mrqa_searchqa-validation-4426", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-1976", "mrqa_searchqa-validation-5100", "mrqa_searchqa-validation-3586", "mrqa_searchqa-validation-6518", "mrqa_searchqa-validation-2445", "mrqa_searchqa-validation-4459", "mrqa_searchqa-validation-10412", "mrqa_triviaqa-validation-224", "mrqa_triviaqa-validation-6129", "mrqa_newsqa-validation-3502", "mrqa_newsqa-validation-477", "mrqa_newsqa-validation-3084"], "SR": 0.375, "CSR": 0.6166666666666667, "EFR": 1.0, "Overall": 0.8083333333333333}, {"timecode": 15, "before_eval_results": {"predictions": ["younger", "gambling", "28,000", "Muhammad ibn Zakar\u012bya R\u0101zi", "river Deabolis", "April 20", "a Gaulish name", "1996", "wine", "Germany", "Melbourne", "enter the priesthood", "Seattle Seahawks", "IBM", "a violinist", "Paula Abdul", "a farm in Strongsville, Ohio", "the language of the five northern and north-eastern provinces", "MasterCard", "Robert C. Stempel", "Nashville", "the olfactory nerve", "Ivan the Terrible", "Nancy Astor", "supplementary", "Grant Russell", "the Toronto Maple", "Grant Wood", "a performance process", "Utah", "Rum", "the Rabbit", "Johann Strauss II", "a supplementary pal", "Grant Wood", "the University of Siena", "a candy store", "a beer", "Anthony Fokker", "Nacho Libre", "copper", "a representation in words or pictures of black magic or of dealings with the devil", "a hemlock", "Lowell Bergman", "National Poetry Month", "a supplementary sauce", "supplementary", "Casablanca", "Grant Wood", "the Bunsen burner", "a geisha", "a mermaid", "altruism", "Frederic Remington", "Juan Francisco Ochoa", "Grant Wood", "a tin star", "film noir", "The Legend of Sleepy Hollow", "Doc Hollywood", "Afghanistan", "two", "Belgium", "Rio de Janeiro"], "metric_results": {"EM": 0.5, "QA-F1": 0.5671875}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, false, true, true, true, true, false, false, false, false, true, false, true, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, false, false, true, true, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, true, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-9248", "mrqa_squad-validation-9270", "mrqa_searchqa-validation-8976", "mrqa_searchqa-validation-10558", "mrqa_searchqa-validation-2440", "mrqa_searchqa-validation-14330", "mrqa_searchqa-validation-668", "mrqa_searchqa-validation-11884", "mrqa_searchqa-validation-16099", "mrqa_searchqa-validation-6942", "mrqa_searchqa-validation-10427", "mrqa_searchqa-validation-13453", "mrqa_searchqa-validation-508", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-2337", "mrqa_searchqa-validation-6772", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-10926", "mrqa_searchqa-validation-1728", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-15167", "mrqa_searchqa-validation-9332", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-5589", "mrqa_searchqa-validation-15471", "mrqa_searchqa-validation-12729", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-3653", "mrqa_naturalquestions-validation-309", "mrqa_triviaqa-validation-1590", "mrqa_triviaqa-validation-3675", "mrqa_newsqa-validation-2036"], "SR": 0.5, "CSR": 0.609375, "EFR": 1.0, "Overall": 0.8046875}, {"timecode": 16, "before_eval_results": {"predictions": ["Keraite", "respiration", "1997", "late 1920s", "\u00a34.2bn", "27 July 2008", "unequal", "October 1973", "dragonnades", "Isiah Bowman", "assembly center", "Ominde Commission", "the Weser River", "(Evita) Peron", "Ho", "circumference", "the igloo", "Detroit Rock City", "the Blue Jays", "President Lincoln", "R.L. Stine", "hate crimes based on gender", "King Julien XIII", "Nicolas Sarkozy", "the Rubicon", "(Conello", "17", "Louisa May Alcott", "Play-Doh", "Aphrodite", "(Peter B Thomas C Gabriel", "The Prince and the Pauper", "cola", "Hillary Clinton", "King Philip", "(Bellerophon)", "Balaam", "the Wharton School of the University of Pennsylvania", "The Caine Mutiny", "(Robbie) Robertson", "(founded 1932)", "(John) Coltrane", "the peace sign", "oxygen", "the Sphinx", "Jan Hus", "the USA Network", "the Mavericks", "Onegin", "Macy's", "a spinning jenny", "Santa Claus", "(Danzel) Snchez", "a nurse", "the courts", "attached to another chromosome", "Goosnargh", "Australia", "The Jefferson Memorial", "aged between 11 or 13 and 18", "Michoacan Family", "( Brad Blauser,", "his salary", "the punishment for the player who had previously admitted in interviews that he had struggled to adapt to the different culture and religious life in Sudan."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6225675366300367}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, true, false, true, false, false, false, false, false, true, false, false, true, true, true, false, true, false, false, true, true, true, false, false, false, false, true, false, true, true, true, false, true, false, true, false, true, false, false, true, false, false, true, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 0.5, 1.0, 0.5, 0.0, 0.5714285714285715, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.923076923076923, 1.0, 0.0, 1.0, 0.23076923076923078]}}, "before_error_ids": ["mrqa_squad-validation-1796", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-12183", "mrqa_searchqa-validation-834", "mrqa_searchqa-validation-9233", "mrqa_searchqa-validation-16726", "mrqa_searchqa-validation-8945", "mrqa_searchqa-validation-6610", "mrqa_searchqa-validation-8220", "mrqa_searchqa-validation-15303", "mrqa_searchqa-validation-1355", "mrqa_searchqa-validation-6202", "mrqa_searchqa-validation-11707", "mrqa_searchqa-validation-10168", "mrqa_searchqa-validation-15283", "mrqa_searchqa-validation-568", "mrqa_searchqa-validation-15453", "mrqa_searchqa-validation-8757", "mrqa_searchqa-validation-15626", "mrqa_searchqa-validation-16417", "mrqa_searchqa-validation-4373", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-5998", "mrqa_searchqa-validation-13161", "mrqa_searchqa-validation-6265", "mrqa_naturalquestions-validation-794", "mrqa_triviaqa-validation-4973", "mrqa_hotpotqa-validation-3410", "mrqa_newsqa-validation-1148", "mrqa_newsqa-validation-1759"], "SR": 0.515625, "CSR": 0.6038602941176471, "EFR": 0.967741935483871, "Overall": 0.7858011148007591}, {"timecode": 17, "before_eval_results": {"predictions": ["September 5, 1985", "mannerist architecture", "stratigraphers", "members of trade unions", "23.9%", "earn as much as a healthy young man", "Centrum", "Tesla", "the telephone ring", "the Party of National Unity", "22", "the Dauphin", "Phillip Marlowe", "piracy", "Yutaka Enatsu", "The Crystal Method", "the Philippines", "The Mausoleum", "Million Dollar Baby", "Syria", "SABENA", "The Old Man and the Sea", "French", "Joe Louis", "the Nemean lion", "The Three Musketeers", "the Bayeux Tapestry", "Front Porch", "China", "Sunni", "notes placed at the bottom of a page", "Stephen Hawking", "Mrcus Tullius Cicero", "Memphis", "Mountain Dew", "Blanche DuBois", "Quilt", "FRAM", "the House of Representatives", "a Belgian-owned Canadian beer company", "Michael Moore", "Oman", "Chevy", "girl", "Pennsylvania", "El burlador de Sevilla", "Ian Fleming", "Headless Horseman", "London", "Yellowstone", "Ronald Reagan", "Fiddler on the Roof", "Ethiopian", "six 50 minute ( one - hour with advertisements ) episodes", "1992", "pH", "Bromley-By- Bowen", "the Ruul", "Cartoon Network", "Caylee Anthony", "know what is important in life", "a former Afghan president who had been leading the Afghan peace council", "nuclear", "The drama of the action in-and-around the golf course"], "metric_results": {"EM": 0.640625, "QA-F1": 0.6703431372549019}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, true, false, true, true, true, false, true, false, false, false, true, false, true, false, true, true, true, true, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true, true, true, true, false, true, false, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.23529411764705882, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1882", "mrqa_squad-validation-1659", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-1272", "mrqa_searchqa-validation-11215", "mrqa_searchqa-validation-7710", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-2195", "mrqa_searchqa-validation-1087", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-14588", "mrqa_searchqa-validation-12176", "mrqa_searchqa-validation-3176", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-6024", "mrqa_searchqa-validation-7140", "mrqa_naturalquestions-validation-3267", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-316", "mrqa_newsqa-validation-2395", "mrqa_newsqa-validation-286", "mrqa_newsqa-validation-4110"], "SR": 0.640625, "CSR": 0.6059027777777778, "EFR": 1.0, "Overall": 0.8029513888888888}, {"timecode": 18, "before_eval_results": {"predictions": ["the Pittsburgh Steelers", "1993", "June 1979", "friend", "tentacles", "Robert R. Gilruth", "a computational resource", "same-gender marriages", "2006", "the mid-18th century", "an emulsified sauce", "A Raisin in the Sun", "Sistine Chapel", "Ukraine", "a halfback", "a trowel", "\"Big Bang\"", "The Sex Pistols", "endodontist", "Mars", "Denmark", "Genoa", "Galt", "Jersey Boys", "a bulletin board", "Utah", "Paula merrill", "a pink-blooming variety", "The Hampton Inn", "a gold palm", "John Janetzko", "Copeina arnoldi", "Paul McCartney", "fish", "Paoletas", "P.S.", "horror Thriller HD Movie Network", "Caddy Shack", "Tokyo", "Panama", "Confession", "Narnia", "Finnegans Wake", "William Wordsworth", "Aesir", "grizzly bears", "a quake", "Judas", "elephant", "Pomerania", "Denmark", "covert", "\"All for our Country\"", "May 2010", "in the majority of the markets the company has entered", "Guanabara Bay", "Thailand", "gender queer", "Minister for Social Protection", "Berga", "the estate", "McFerrin, Robin Williams, and Bill Irwin", "ase", "Russia"], "metric_results": {"EM": 0.375, "QA-F1": 0.44042467948717945}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, true, true, true, false, false, true, false, false, true, false, true, true, false, false, true, false, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, false, true, false, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 1.0, 0.15384615384615383, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-499", "mrqa_squad-validation-1696", "mrqa_searchqa-validation-4484", "mrqa_searchqa-validation-5116", "mrqa_searchqa-validation-1295", "mrqa_searchqa-validation-9558", "mrqa_searchqa-validation-15811", "mrqa_searchqa-validation-4973", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-8360", "mrqa_searchqa-validation-13718", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-4853", "mrqa_searchqa-validation-7964", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-12757", "mrqa_searchqa-validation-8014", "mrqa_searchqa-validation-3043", "mrqa_searchqa-validation-175", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-1971", "mrqa_searchqa-validation-5720", "mrqa_searchqa-validation-15094", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-12251", "mrqa_searchqa-validation-3547", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-9991", "mrqa_searchqa-validation-11541", "mrqa_searchqa-validation-15717", "mrqa_searchqa-validation-15305", "mrqa_searchqa-validation-10266", "mrqa_searchqa-validation-9572", "mrqa_naturalquestions-validation-554", "mrqa_triviaqa-validation-2612", "mrqa_hotpotqa-validation-2217", "mrqa_newsqa-validation-2421", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-2870"], "SR": 0.375, "CSR": 0.59375, "EFR": 1.0, "Overall": 0.796875}, {"timecode": 19, "before_eval_results": {"predictions": ["to avoid trivialization", "tobacco", "Earth", "53,000", "one", "Israeli poet", "two", "20,000", "the kip", "skeletal muscle and the brain", "2014", "a single peptide bond or one amino acid with two peptide bonds", "Montreal", "Sunday evenings", "sperm and ova", "volcanic activity", "Montgomery", "Rock Island, Illinois", "April 9, 2012", "Squamish, British Columbia, Canada", "Proposition 103", "mindfulness", "Charlene Holt", "Leland Stottlemeyer", "1991", "118", "Cornett family", "acid rain", "October 22, 2017", "they can not be produced using currently available resources", "he cheated on Miley", "2001", "flawed", "735", "1871", "Ric Flair", "Toledo, Bowling Green, and Mount Union", "board of trade", "a cladding of a different glass, or plastic", "Abraham Gottlob Werner", "Wakanda and the Savage Land", "prejudice in favour of or against one thing, person, or group compared with another", "Ancy Lostoma duodenale", "February 28 or March 1", "a Lebanese limited production supercar", "the American Civil War", "to establish an electrochemical gradient ( often a proton gradient ) across a membrane", "Cecil Lockhart", "Mara Jade", "British and French Canadian fur traders", "semi-autonomous organisational units", "Leon Huff", "a man called Lysander", "Jupiter", "Greek", "15", "John Robert Cocker", "Silvan Shalom", "a simple puzzle video game", "a palace", "the olfactory nerve", "Eucalyptus", "a lion", "oxygen"], "metric_results": {"EM": 0.453125, "QA-F1": 0.568038609674639}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, false, false, false, false, false, true, true, true, false, true, true, false, true, false, false, false, true, true, true, false, false, true, false, false, false, true, false, false, false, false, false, false, false, false, false, true, false, true, true, false, false, false, false, false, false, true, false, true, true, true, true, true, false, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.0, 0.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 0.28571428571428575, 0.4705882352941177, 0.0, 0.2, 0.8, 0.4, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8896", "mrqa_squad-validation-880", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-6481", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-8350", "mrqa_naturalquestions-validation-6931", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-8951", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-7488", "mrqa_naturalquestions-validation-2890", "mrqa_naturalquestions-validation-7650", "mrqa_naturalquestions-validation-2928", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-1976", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-6015", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-4809", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4824", "mrqa_naturalquestions-validation-10319", "mrqa_naturalquestions-validation-373", "mrqa_naturalquestions-validation-2518", "mrqa_naturalquestions-validation-5804", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-5964", "mrqa_hotpotqa-validation-4926", "mrqa_triviaqa-validation-2227"], "SR": 0.453125, "CSR": 0.58671875, "EFR": 0.9714285714285714, "Overall": 0.7790736607142856}, {"timecode": 20, "before_eval_results": {"predictions": ["petroleum", "the Cloth of St Gereon", "Thomas Sowell", "70", "marriage set the seal of approval on clerical marriage", "Biblical ideal of congregations' choosing their own ministers", "1886", "\"Blue Harvest\" and \"420\"", "Jacob Zuma", "gang rape", "\"Listen, don't rush on boats to leave the country.", "10", "Wednesday", "201-262-2800", "different women coping with breast cancer", "over 1,000 pounds", "\"No need to fight the oppression of the former Mubarak regime.\"", "Mutassim", "south of there... from Memphis [Tennessee] to Little Rock [ Arkansas], and even over to Chattanooga (Tennessee)", "Polo", "\"The Jacksons: A Family Dynasty\"", "Amstetten", "computer problems left travelers across the United States waiting in airports", "Silvan Shalom", "Jonathan Breeze", "Steve Jobs", "12-hour-plus", "prisoners", "September", "consumer confidence", "5:20 p.m.", "North vs. South", "India", "1,700 year old Roman mosaic entitled Chamber of the Ten Maidens", "Davidson", "Swat Valley", "Friday", "1979", "the United States", "GospelToday", "Akio Toyoda", "\"There's no chance of it being open on time. Work has basically stopped.\"", "urbina would file papers shortly with an appeals court seeking an emergency stay to stop the judge's order in its tracks.", "Giovani dos Santos is set to take up the vacant slot alongside Cameroon international Samuel Eto'o and Ivory Coast midfielder Yaya Toure in the non-EU berths permitted under Spanish Football Federation (RFEF) rules", "Michael Schumacher", "Gustav", "gun", "Henrik Stenson", "orphans", "40", "Derek Mears", "tax incentives for businesses hiring veterans as well as job training for all service members leaving the military.", "two years", "1966", "winter solstice", "Whitsunday", "Aberdeen", "\"Dumb and Dumber\"", "Nokia Sugar Bowl", "Earl Warren", "converging lens", "autu", "\" Aqua ''", "The Force Fighters ( 2015 )"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6176012645657576}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, false, false, true, false, true, false, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, true, false, true, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, false, true, true, false, true, true, true, false, true, true, false, true, false, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 0.18181818181818182, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 0.923076923076923, 0.8571428571428571, 0.0, 1.0, 0.25, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.5, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.9411764705882353, 0.052631578947368425, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1640", "mrqa_squad-validation-2757", "mrqa_squad-validation-2466", "mrqa_newsqa-validation-565", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-1762", "mrqa_newsqa-validation-912", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1010", "mrqa_newsqa-validation-1953", "mrqa_newsqa-validation-2907", "mrqa_newsqa-validation-911", "mrqa_newsqa-validation-2509", "mrqa_newsqa-validation-1149", "mrqa_newsqa-validation-3853", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3051", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-1559", "mrqa_newsqa-validation-167", "mrqa_newsqa-validation-2301", "mrqa_newsqa-validation-928", "mrqa_newsqa-validation-1549", "mrqa_triviaqa-validation-3457", "mrqa_hotpotqa-validation-1094", "mrqa_searchqa-validation-9508", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7239", "mrqa_naturalquestions-validation-3422"], "SR": 0.484375, "CSR": 0.5818452380952381, "EFR": 1.0, "Overall": 0.7909226190476191}, {"timecode": 21, "before_eval_results": {"predictions": ["Cologne, Germany", "occupational stress among teachers.", "San Diego-Carlsbad-San Marcos metropolitan area", "chief electrician", "Newton", "static friction, generated between the object and the table surface", "the assassination of US President John F. Kennedy", "\"We shall come into Kenya if you don't go back.\"", "Union Station in Denver, Colorado.", "Casalesi Camorra clan", "Awearness Fund", "in a muddy barley field owned by farmer Alan Graham outside Bangor, about 10 miles from Belfast.", "the missions are rewriting lunar science text books and revolutionizing what scientists know about Earth's closest neighbor.", "not the one to be dealt with by us.\"", "\"Maude\"", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "Wednesday.", "Cash for Clunkers", "\"I'm certainly not nearly as good of a speaker as he is.\"", "9:20 p.m. ET Wednesday.", "Venus Williams", "Mashhad, Iran.", "Amanda Knox", "great jazz", "$530 million in debt", "\"Doogie Howser, M.D.\"", "Luiz Inacio Lula da Silva", "his father's parenting skills.", "two contestants.", "Bill", "J.G. Ballard", "Dr. Conrad Murray", "Michelle", "getting out of the game, and I wondered what will they do now?\"", "1981", "17 Again", "Nigeria", "$81,8709.", "Republican", "EU naval force", "Allison Bridges", "Omar Bongo", "overnight passenger boats", "Hyundai Steel", "skeletal dysplasia, a bone-growth disorder that causes dwarfism,", "London Heathrow's Terminal 5.", "racism is not at play", "February 12", "more than 30", "whether to recognize Porfirio Lobo as the legitimate president of Honduras.", "India", "Steve Williams", "military action because we're getting frustrated seems to me somewhat dangerous.", "White House Executive chef", "Russell Huxtable", "Willy Russell", "Budapest", "\"Mortal Kombat\" fighting game franchise.", "Northumbrian", "get thee to a nunnery", "the couple were hastily tried and convicted by a special trial.", "Argentinian", "Mercedes-Benz Superdome in New Orleans, Louisiana.", "Otto Eduard Leopold"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5119320477316801}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, false, true, false, false, false, false, false, true, true, true, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, false, true, true, true, false, true, false, true, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.25, 1.0, 1.0, 0.4, 0.15384615384615383, 0.0, 0.5714285714285715, 1.0, 0.0, 0.11764705882352941, 0.5454545454545454, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.4, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.1, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-2717", "mrqa_squad-validation-10313", "mrqa_squad-validation-7746", "mrqa_newsqa-validation-2235", "mrqa_newsqa-validation-1485", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-3097", "mrqa_newsqa-validation-3905", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-3382", "mrqa_newsqa-validation-2328", "mrqa_newsqa-validation-808", "mrqa_newsqa-validation-1770", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-3634", "mrqa_newsqa-validation-2545", "mrqa_newsqa-validation-3280", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-3778", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-4199", "mrqa_newsqa-validation-1544", "mrqa_newsqa-validation-545", "mrqa_newsqa-validation-2245", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1387", "mrqa_newsqa-validation-607", "mrqa_newsqa-validation-1462", "mrqa_newsqa-validation-2221", "mrqa_newsqa-validation-729", "mrqa_naturalquestions-validation-613", "mrqa_triviaqa-validation-110", "mrqa_hotpotqa-validation-4514", "mrqa_searchqa-validation-7642", "mrqa_searchqa-validation-8602", "mrqa_hotpotqa-validation-107"], "SR": 0.40625, "CSR": 0.5738636363636364, "EFR": 1.0, "Overall": 0.7869318181818181}, {"timecode": 22, "before_eval_results": {"predictions": ["experiments in X-ray imaging", "WMO Executive Council and UNEP Governing Council", "Saxon chancellery", "New York and Virginia,", "two", "glowed even when turned off.", "five female pastors", "resources that could sustain future exploration of the moon and beyond.", "that a ship docked on the mainland was preparing to transport tubes to the Falklands for oil and gas exploration.", "April 6, 1994", "Prague", "backbreaking labor", "a federal judge in Mississippi", "the department has been severely affected by the earthquake,", "$22 million", "severe flooding", "a music video on his land.", "at the Lindsey oil refinery", "$55.7 million", "\"The Real Housewives of Atlanta\"", "18", "88", "that in May her husband had knocked her down, held a loaded gun to her head and then threatened to commit suicide,", "a president who understands the world today, the future we seek and the change we need.", "military trials for some Guant Bay detainees.", "Michael Jackson", "Larry King", "Steven Chu", "racially motivated.", "Michael Partain", "women.", "the longest domestic relay in Olympic history", "Zimbabwe.", "No. 1", "nine", "four bodies", "Friday", "'City of Silk' in Kuwait", "Rima Fakih", "Tuesday night", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "Ben Roethlisberger", "one", "Lee Myung-Bak", "Damon Bankston", "scientists", "involvement during World War II in killings at a Nazi German death camp in Poland.", "opium", "warning about tendon problems.", "84-year-old", "Robert Park", "Miss USA", "paronic Gulfs", "Nalini Negi", "2017 - 12 - 10 )", "Runcorn", "collarbone", "paris", "UFC 50: The War of '04", "June 11, 1973", "San Diego County Fair", "Toy Story", "Emiliano Zapata", "A Fairy Tale of Home"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5821566631808799}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, false, true, true, true, true, true, false, false, false, false, true, true, false, true, false, true, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, false, false, false, false, true, true, false, false], "QA-F1": [0.6666666666666666, 1.0, 0.0, 0.22222222222222224, 1.0, 1.0, 0.0, 0.8235294117647058, 0.0, 0.5, 0.19999999999999998, 0.23529411764705882, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 0.5714285714285715, 0.0, 1.0, 0.0, 1.0, 0.923076923076923, 0.9565217391304348, 0.10256410256410256, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.23529411764705882, 1.0, 0.16666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.7499999999999999, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1407", "mrqa_squad-validation-2356", "mrqa_squad-validation-3127", "mrqa_newsqa-validation-2277", "mrqa_newsqa-validation-3903", "mrqa_newsqa-validation-1904", "mrqa_newsqa-validation-409", "mrqa_newsqa-validation-2823", "mrqa_newsqa-validation-4067", "mrqa_newsqa-validation-3096", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-3160", "mrqa_newsqa-validation-765", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-426", "mrqa_newsqa-validation-4203", "mrqa_newsqa-validation-1350", "mrqa_newsqa-validation-1161", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1522", "mrqa_newsqa-validation-4089", "mrqa_newsqa-validation-743", "mrqa_newsqa-validation-2040", "mrqa_newsqa-validation-3681", "mrqa_newsqa-validation-2206", "mrqa_newsqa-validation-2114", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1418", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-53", "mrqa_triviaqa-validation-3875", "mrqa_triviaqa-validation-7532", "mrqa_hotpotqa-validation-1190", "mrqa_hotpotqa-validation-482", "mrqa_searchqa-validation-2383", "mrqa_searchqa-validation-4464"], "SR": 0.4375, "CSR": 0.5679347826086957, "EFR": 1.0, "Overall": 0.7839673913043479}, {"timecode": 23, "before_eval_results": {"predictions": ["help red algae catch more sunlight in deep water", "lost in the 5th Avenue laboratory fire of March 1895.", "economic inequality", "Davros", "Church and the Methodist-Christian theological tradition in order to profess their ultimate faith in Christ.", "Behind the Sofa", "Tulsa, Oklahoma.", "56", "Yemen", "2005", "Karen Floyd", "two soldiers and two civilians", "those missing", "Haiti", "Susan Boyle", "Saturday", "Spain", "Jared Polis", "Janet and La Toya,", "Dangjin", "30", "Michael Krane,", "lightning strikes", "Evans", "Italian government", "flooding", "threatening messages", "stop Noriko Savoie from being able to travel to Japan for summer vacation.", "Citizens", "fake his own death", "\"in the interest of justice.\"", "martial arts,", "\"oil may be present in thin intervals but that reservoir quality is poor.\"", "then-Sen. Obama", "Congress", "curfew", "Anne Frank's account of hiding from Jewish persecution in Nazi-occupied Amsterdam", "June,", "the government in Islamabad \"has so far not received any information or evidence relating to the Mumbai incident from the government of India.", "Zuma", "out of either heavy flannel or wool -- fabrics that would not be transparent when wet -- and covered the entire body from neck to toe.", "nine", "Iraq", "2000", "about 50", "a group of teenagers.", "in body bags on the roadway near the bus,", "al Fayed's security team", "Desmond Tutu", "$17,000", "Toy Story", "$81,880", "to provide school districts with federal funds, in the form of competitive grants, to establish innovative educational programs for students with limited English speaking ability", "a transformiation, change of mind, repentance, and atonement", "Jason Lee", "REM sleep", "a noun", "Kent", "beer and soft drinks", "five aerial victories.", "Cherokee River", "Snowball", "Apollo 13", "Florida"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6503653297238823}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, true, false, true, false, false, true, false, true, true, true, false, false, false, true, false, false, false, false, false, false, true, false, true, true, false, true, true, false, true, false, false, true, true, false, true, false, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.9333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.962962962962963, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.15384615384615385, 0.0, 0.15789473684210525, 1.0, 0.29629629629629634, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-8595", "mrqa_squad-validation-10100", "mrqa_newsqa-validation-938", "mrqa_newsqa-validation-2765", "mrqa_newsqa-validation-652", "mrqa_newsqa-validation-628", "mrqa_newsqa-validation-4010", "mrqa_newsqa-validation-1899", "mrqa_newsqa-validation-2686", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-3888", "mrqa_newsqa-validation-1941", "mrqa_newsqa-validation-2780", "mrqa_newsqa-validation-1195", "mrqa_newsqa-validation-3500", "mrqa_newsqa-validation-3039", "mrqa_newsqa-validation-3671", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-1449", "mrqa_newsqa-validation-3440", "mrqa_newsqa-validation-2957", "mrqa_newsqa-validation-2616", "mrqa_naturalquestions-validation-5851", "mrqa_triviaqa-validation-2050", "mrqa_triviaqa-validation-1721", "mrqa_hotpotqa-validation-162", "mrqa_searchqa-validation-8458"], "SR": 0.578125, "CSR": 0.568359375, "EFR": 1.0, "Overall": 0.7841796875}, {"timecode": 24, "before_eval_results": {"predictions": ["black-and-yellow", "Frederick II the Great", "Muslims in the semu class", "manually suppress the fire", "compound", "Nigeria", "Lindsey Vonn", "Unseeded Frenchwoman Aravane Rezai", "him to step down as majority leader.", "United Nations World Food Program vessels", "gang rape", "ClimateCare, one of Europe's most experienced providers of carbon offsets,", "The Louvre", "invited camps in the Philadelphia area to use his facility because of the number of pools in the region closed due to budget cuts this summer.", "like the video-game challenge of continuously trying to best your own fuel economy achievements,\"", "1979", "Heshmatollah Attarzadeh", "jazz", "an antihistamine and an epinephrine auto-injector for emergencies", "Bangladesh", "Michael Arrington,", "12 million", "President Sheikh Sheikh Ahmed", "Sonia, a single mother with HIV in Brazil, travels four hours to reach a government-run health facility that provides her with free drug treatment.", "Britain's Got Talent", "military personnel", "100-plus stores nationwide", "11 healthy eggs", "one Iraqi soldier,", "40 former U.S. Marines or sons of Marines who lived at Camp Lejeune", "her fianc\u00e9,", "racial intolerance.", "dairy and eggs,", "Carrillo Leyva,", "Symbionese Liberation Army", "$8.8 million", "to work together to stabilize Somalia and cooperate in security and military operations.", "compromise the public broadcaster's appearance of impartiality.", "it -- you know -- black is beautiful,\"", "$104,168,000", "Picasso's muse and mistress, Marie-Therese Walter.", "to stop the Afghan opium trade", "a new GI Bill that expands education benefits for veterans who have served since the 9/11 attacks, provides a 13-week extension of unemployment benefits and more than $2 billion in disaster assistance for parts of the Midwest", "off the coast of Dubai", "military veterans", "Springfield, Virginia.", "27 Awa", "Mark Obama Ndesandjo", "The premier of \"Dance\" rated highly for Oxygen,", "Russian residents and worldwide viewers", "Boxes of the Lost Ark", "fatally shooting a limo driver on February 14, 2002.", "nucleus", "Treaty of Paris", "Sebastian Lund ( Rob Kerkovich )", "President Obama", "Tom Watson", "Sandi Toksvig", "Hispania Racing F1", "prime minister", "Walt Disney World", "Iceland", "wedlock", "platinum"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5283778136869169}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, true, true, false, true, true, false, false, false, true, false, false, false, false, false, false, true, false, false, true, true, false, false, false, false, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 1.0, 0.0, 0.08695652173913043, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.5714285714285715, 0.4, 0.05555555555555555, 1.0, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.14285714285714288, 0.0, 0.6666666666666666, 0.0, 1.0, 0.12500000000000003, 0.10256410256410256, 1.0, 1.0, 0.0, 0.4, 0.5, 0.25, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3288", "mrqa_newsqa-validation-2073", "mrqa_newsqa-validation-2504", "mrqa_newsqa-validation-1461", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-3724", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-4068", "mrqa_newsqa-validation-1103", "mrqa_newsqa-validation-2276", "mrqa_newsqa-validation-4025", "mrqa_newsqa-validation-1788", "mrqa_newsqa-validation-1109", "mrqa_newsqa-validation-4161", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3550", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-1557", "mrqa_newsqa-validation-899", "mrqa_newsqa-validation-2194", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1290", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-2489", "mrqa_newsqa-validation-3557", "mrqa_newsqa-validation-4117", "mrqa_newsqa-validation-3860", "mrqa_newsqa-validation-1744", "mrqa_naturalquestions-validation-366", "mrqa_naturalquestions-validation-4367", "mrqa_naturalquestions-validation-1282", "mrqa_triviaqa-validation-4927", "mrqa_hotpotqa-validation-1346", "mrqa_hotpotqa-validation-364", "mrqa_hotpotqa-validation-2685", "mrqa_searchqa-validation-8678"], "SR": 0.40625, "CSR": 0.561875, "EFR": 1.0, "Overall": 0.7809375000000001}, {"timecode": 25, "before_eval_results": {"predictions": ["unity of God", "Treaty of Logstown", "Jordan Norwood", "RNA silencing", "concurring, smaller assessments of special problems instead of the large scale", "Jonathan Demme,", "New Zealand", "Tamar", "rhododendron", "9", "specialist", "beetle", "phylum", "Wayne Allwine", "Westminster Abbey", "holography", "Pelias", "Joshua Radin", "Northumbria", "Harvard", "cricketer", "Seymour Hersh,", "quant", "copper and zinc", "Tigris", "Cordelia,", "pamphlets, posters, ballads", "dermatitis", "33", "spicy", "Joseph Smith,", "Huntington Beach, California", "platinum", "moon", "13", "stola", "The Apartment", "France", "Winston Churchill", "Stockholm", "Peter Parker", "kibbutznik", "Giorgio Armani,", "bullfight", "Sparks", "Ginger Rogers", "Mayflower", "Comedy Playhouse", "citric", "Charles Darwin", "John Denver", "a handkerchief", "Marie Van Brittan Brown", "southern California", "1995", "Bourbon", "Taylor Swift", "Rihanna", "had his personal.40-caliber Glock when police found him.", "a class to help women \" learn how to dance and feel sexy,\"", "Amy Bishop Anderson,", "calathus", "the Louvre", "American private, not-for-profit, coeducational research university"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5282986111111112}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, false, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, false, false, true, true, false, true, false, false, true, true, false, false, false, true, true, false, false, false, true, true, false, true, true, true, false, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.9, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.7777777777777778, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6547", "mrqa_squad-validation-8618", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-147", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6296", "mrqa_triviaqa-validation-7070", "mrqa_triviaqa-validation-7210", "mrqa_triviaqa-validation-3096", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-2160", "mrqa_triviaqa-validation-3082", "mrqa_triviaqa-validation-2301", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-5986", "mrqa_triviaqa-validation-4947", "mrqa_triviaqa-validation-1059", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-6175", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-7521", "mrqa_hotpotqa-validation-649", "mrqa_hotpotqa-validation-1047", "mrqa_newsqa-validation-2320", "mrqa_newsqa-validation-1413", "mrqa_newsqa-validation-2288", "mrqa_searchqa-validation-7980", "mrqa_searchqa-validation-2376"], "SR": 0.46875, "CSR": 0.5582932692307692, "EFR": 0.9411764705882353, "Overall": 0.7497348699095022}, {"timecode": 26, "before_eval_results": {"predictions": ["\"The Day of the Doctor\"", "third", "affordable housing", "Mao Zedong", "Verona", "Pontiac Silverdome", "tusks", "steppanyaki", "Frank McCourt", "jules Verne", "stella mccartney", "Margo Leadbetter", "eec", "a", "city of Sheffield, England", "Famous Players-Lasky Corporation", "the Beatles", "Gerald Durrell", "jzebel", "canterbury", "jason", "canterbury", "Halifax", "mccartney", "stella mccartney", "Frank Wilson", "Carlos the jackal", "Edwina Currie", "st Moritz Winter Olympics", "Robert Maxwell", "1768", "\u201cFor Gallantry;\u201d", "Tuesday's", "republic", "Cahaba", "margo", "tahrir Square", "osmium", "d'Artagnan", "27", "Jack Ruby", "tintoretto", "Michael Anderson", "Saudi Arabia", "Lester", "Thailand", "Sydney", "doves", "canada", "Prince Philip", "canterbury", "Tokyo", "Edgar Lungu", "49 cents", "a resting heart rate over 100 beats per minute", "672", "\"Linda McCartney's Life in Photography\"", "cantercoast MFA Program in Creative Writing", "e-mail", "Juan Martin Del Potro.", "27", "england", "Richard Cory", "Buddhism"], "metric_results": {"EM": 0.4375, "QA-F1": 0.4604166666666667}, "metric_results_detailed": {"EM": [false, false, true, true, true, true, false, false, true, true, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, true, false, true, true], "QA-F1": [0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7774", "mrqa_squad-validation-8026", "mrqa_triviaqa-validation-5980", "mrqa_triviaqa-validation-2150", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-4292", "mrqa_triviaqa-validation-5022", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-86", "mrqa_triviaqa-validation-6746", "mrqa_triviaqa-validation-4200", "mrqa_triviaqa-validation-6100", "mrqa_triviaqa-validation-2529", "mrqa_triviaqa-validation-1354", "mrqa_triviaqa-validation-4872", "mrqa_triviaqa-validation-4476", "mrqa_triviaqa-validation-6186", "mrqa_triviaqa-validation-4287", "mrqa_triviaqa-validation-1589", "mrqa_triviaqa-validation-2096", "mrqa_triviaqa-validation-5632", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-7193", "mrqa_triviaqa-validation-438", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3600", "mrqa_triviaqa-validation-7370", "mrqa_triviaqa-validation-1451", "mrqa_triviaqa-validation-6259", "mrqa_triviaqa-validation-3354", "mrqa_naturalquestions-validation-10131", "mrqa_hotpotqa-validation-5372", "mrqa_hotpotqa-validation-733", "mrqa_newsqa-validation-279", "mrqa_searchqa-validation-12829"], "SR": 0.4375, "CSR": 0.5538194444444444, "EFR": 0.9722222222222222, "Overall": 0.7630208333333333}, {"timecode": 27, "before_eval_results": {"predictions": ["two", "80", "more than 70", "out leaving him penniless.", "benazir Bhutto", "Iran's nuclear program.", "at least 27", "louis armstrong", "Daniel Cain", "acid", "Wally", "1993", "after Wood went missing off Catalina Island,", "Rima Fakih", "Afghanistan", "Everglades", "made 109 as Sri Lanka, seeking a win to level the series at 1-1,", "1950s", "64", "Iran's parliament speaker", "27-year-old", "young self-styled anarchists", "about $163 million (180 million Swiss francs)", "unwanted baggage from the 80s", "climate change", "oaxaca", "Orbiting Carbon Observatory", "Switzerland", "Kenneth Cole", "Janet and La Toya", "Nine out of 10 children", "hours", "combat veterans", "improve health and beauty.", "U.S. Chamber of Commerce", "burned over 65 percent of his body after being set on fire,", "al-Shabaab", "by posting a $1,725 bail,", "sustain future exploration of the moon and beyond.", "his business dealings for possible securities violations", "Opryland", "circles", "attempting illegal crossings", "he was diagnosed with skin cancer.", "al Qaeda", "jeremy gaffney", "\"It's a really dumb thing to say,\"", "The oceans", "beat and binding Andrade,", "doctors", "off the coast of Dubai", "Bill Haas", "oona caplin", "1932", "between 1923 and 1925", "Gilda", "jeremy dryden", "table tennis", "Tamil", "DreamWorks Animation", "Indianola", "Empire", "Disraeli", "a black stripe"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5612403404344194}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, false, false, false, false, false, false, true, false, true, false, true, true, true, false, true, false, false, false, false, true, true, true, true, true, true, false, true, true, false, true, false, true, false, false, false, false, false, true, false, false, true, false, true, true, true, false, false, false, true, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.8, 0.4, 0.8, 0.0, 0.0, 0.5714285714285715, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.7368421052631579, 1.0, 0.0, 1.0, 0.6, 0.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1302", "mrqa_newsqa-validation-850", "mrqa_newsqa-validation-43", "mrqa_newsqa-validation-1042", "mrqa_newsqa-validation-2128", "mrqa_newsqa-validation-563", "mrqa_newsqa-validation-1645", "mrqa_newsqa-validation-1698", "mrqa_newsqa-validation-1450", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-2898", "mrqa_newsqa-validation-3066", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-2507", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-4157", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-1713", "mrqa_newsqa-validation-2682", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2051", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-3655", "mrqa_newsqa-validation-260", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-2022", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-3633", "mrqa_naturalquestions-validation-4072", "mrqa_triviaqa-validation-4193", "mrqa_hotpotqa-validation-2564", "mrqa_hotpotqa-validation-1816", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-15354"], "SR": 0.4375, "CSR": 0.5496651785714286, "EFR": 1.0, "Overall": 0.7748325892857143}, {"timecode": 28, "before_eval_results": {"predictions": ["a hybrid Bermuda 419 turf", "25-foot", "manipulates symbols", "Hyundai", "Monday night", "Florida", "kidnapping the children and concealing their identities.", "40", "brutalized by the Catholic Church in the 1600s", "in a public housing project,", "toxic smoke from burn pits", "one of South Africa's most famous musicians,", "two Israeli soldiers,", "space shuttle Discovery", "World-renowned security expert Gavin de Becker", "a nuclear weapon", "Japan", "Arizona", "Southeast Asia and India.", "Tetris,", "outside influences", "aid to Gaza,", "flipped and landed on its right side", "suppress the memories and to live as normal a life", "Tuesday in Los Angeles.", "immediate release into the United States of 17 Chinese Muslims", "the helicopter went down in Talbiya,", "his death cast a shadow over festivities ahead of South Africa's highly- anticipated appearance in the rugby World Cup final with England this weekend.", "Cash for Clunkers program", "\"project work\"", "queen Oprah Winfrey.", "80 percent of the woman's face", "London", "to try to make life a little easier for these families by organizing the distribution of wheelchairs,", "Ozzy Osbourne", "$50", "Australian officials", "the iconic Hollywood headquarters of Capitol Records,", "Dr. Jennifer Arnold and husband Bill Klein,", "gun", "38", "Argentine", "the underprivileged.", "Somalia's piracy problem was fueled by environmental and political events.", "\"17 Again,\"", "Kabul", "22", "Steven Gerrard", "12.3 million", "the area was sealed off,", "Rima Fakih", "Old Trafford", "to help bring creative projects to life", "season two", "Mary Elizabeth Patterson", "West Side Story", "Fifth", "Nepal", "Merck Sharp & Dohme", "Fort Albany", "Knoxville, Tennessee", "Jawaharlal Nehru", "transpiration", "a bipolar episode"], "metric_results": {"EM": 0.484375, "QA-F1": 0.6099275085294822}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, false, true, false, false, false, false, false, false, false, false, false, true, true, false, true, true, true, true, false, false, true, false, false, true, true, true, true, true, true, false, false, false, false, true, true, true, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.4, 0.3636363636363636, 0.3333333333333333, 0.42857142857142855, 0.8571428571428571, 0.0, 0.4, 1.0, 1.0, 0.4210526315789474, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-1789", "mrqa_newsqa-validation-1996", "mrqa_newsqa-validation-919", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-585", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1178", "mrqa_newsqa-validation-2784", "mrqa_newsqa-validation-3939", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3534", "mrqa_newsqa-validation-1277", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-4044", "mrqa_newsqa-validation-4064", "mrqa_newsqa-validation-4004", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1244", "mrqa_newsqa-validation-1905", "mrqa_newsqa-validation-3686", "mrqa_newsqa-validation-1785", "mrqa_newsqa-validation-1418", "mrqa_newsqa-validation-1265", "mrqa_naturalquestions-validation-10292", "mrqa_triviaqa-validation-79", "mrqa_hotpotqa-validation-4763", "mrqa_searchqa-validation-10091", "mrqa_searchqa-validation-5587", "mrqa_searchqa-validation-4465"], "SR": 0.484375, "CSR": 0.5474137931034483, "EFR": 0.9696969696969697, "Overall": 0.7585553814002091}, {"timecode": 29, "before_eval_results": {"predictions": ["Mike Carey", "oxygen", "Betty Meggers", "ancient cult activity", "US - grown fruit", "ovaries, fallopian tubes, uterus, vulva, vagina, testes, vas deferens, seminal vesicles, prostate and penis", "Russian army", "interstellar medium", "August 6", "Doug Diemoz", "Colony of Virginia", "Monk's Caf\u00e9", "in the central plains", "al - Mamlakah al - \u02bbArab\u012byah", "Southport, North Carolina", "in ancient Mesopotamia", "a computer maintenance utility", "July 4, 1776", "pick yourself up and dust yourself off and keep going '", "John Garfield", "by captains of sailing ships to cross the world's oceans for centuries", "October 12, 1979", "Lorazepam", "2013 non-fiction book of the same name by David Finkel", "jonny", "Brenda ''", "a ranking used in combat sports,", "Husrev Pasha", "Stephanie Judith Tanner", "the palmar aspect of these fingers", "McFerrin", "Watson and Crick", "Gorakhpur", "Patris et Filii et Spiritus Sancti", "the Rashidun Caliphs", "Lake Powell", "a decorative ornament", "September 6, 2019", "Article One of the United States Constitution", "substitute good", "Marries", "over 74", "1987", "cunnilingus", "October 2000", "New York City", "Prafulla Chandra Ghosh", "economic recession", "in sequence with each heartbeat", "Hermann Ebbinghaus", "The Miracles", "used obscure languages as a means of secret communication during wartime", "Donny Osmond", "Carthaginian Empire and the expanding Roman Republic", "George Herbert Walker Bush", "\"VIVA Media GmbH\"", "The 7.63\u00d725mm Mauser", "seven", "Muslim", "two remaining crew members from the helicopter,", "Saturday's Hungarian Grand Prix.", "Rickey Henderson", "Lake Baikal", "adventure park"], "metric_results": {"EM": 0.375, "QA-F1": 0.5236874236874237}, "metric_results_detailed": {"EM": [true, false, true, false, false, false, true, false, false, false, false, false, false, false, true, false, false, true, false, true, false, false, false, false, false, false, false, true, false, false, true, false, false, true, true, true, false, true, true, true, false, true, false, false, true, true, false, true, false, true, true, false, true, false, false, false, true, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0, 0.3076923076923077, 0.5, 0.0, 0.5, 0.4, 0.8, 0.0, 1.0, 0.0, 0.2857142857142857, 1.0, 0.7142857142857143, 1.0, 0.14285714285714285, 0.4, 0.0, 0.0, 0.0, 0.0, 0.3846153846153846, 1.0, 0.0, 0.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6, 1.0, 0.0, 1.0, 1.0, 0.15384615384615385, 1.0, 0.2222222222222222, 0.4, 0.0, 1.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-3937", "mrqa_naturalquestions-validation-1725", "mrqa_naturalquestions-validation-10402", "mrqa_naturalquestions-validation-3677", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-8903", "mrqa_naturalquestions-validation-4803", "mrqa_naturalquestions-validation-328", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-7589", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-2194", "mrqa_naturalquestions-validation-7376", "mrqa_naturalquestions-validation-4463", "mrqa_naturalquestions-validation-7407", "mrqa_naturalquestions-validation-8181", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-10283", "mrqa_naturalquestions-validation-4605", "mrqa_naturalquestions-validation-9835", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-6787", "mrqa_naturalquestions-validation-1382", "mrqa_naturalquestions-validation-9488", "mrqa_naturalquestions-validation-6579", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-4496", "mrqa_triviaqa-validation-3604", "mrqa_triviaqa-validation-5010", "mrqa_hotpotqa-validation-3467", "mrqa_newsqa-validation-1417", "mrqa_newsqa-validation-3585", "mrqa_newsqa-validation-1733", "mrqa_searchqa-validation-9259", "mrqa_searchqa-validation-5753"], "SR": 0.375, "CSR": 0.5416666666666667, "EFR": 0.95, "Overall": 0.7458333333333333}, {"timecode": 30, "before_eval_results": {"predictions": ["address information", "Pleurobrachia", "1953", "AT&T", "North Carolina", "Hutter and Hurry Harry", "shoes", "nine", "Rashid Akmaev,", "acetylene", "walk, behave or speak in ways that aren't considered \"ordinary\"", "fiber", "shrews", "a rose", "walker", "sand", "Nanjing", "Montana", "the Holy Grail", "Louis XIV", "\"What a joy to breathe the balmy air of Grosvenor Square\"", "Fox Network", "the Belgae", "Joe Lieberman", "the Boston Marathon", "fibreboard", "tin", "riven Henderson", "Frida Kahlo", "his father had boycotted Thomas Jefferson's", "\"Y\" 2 \"K\": An Eskimo", "\"Fat man, you shoot a great game of pool.\"", "\"Donna,\"", "William Randolph Hearst", "a rock basalt", "ale", "Homo sapiens", "telephone operator", "Busted", "john jones", "\"The New Colossus\"", "yelped", "riga", "Sarah, Duchess of York", "walk surfboard", "the middleweight champion,", "bronchodilators", "Forty", "Argon Glow Lamps", "Red", "car", "Earl Long", "Louis Hynes", "Dylan Walters", "1999", "vitamin D", "five", "Alberto Juantorena", "R&B", "Awake", "Doctor of Philosophy", "Pakistan", "in Atlanta", "Elena Kagan to fill the seat of retiring Supreme Court Justice John Paul Stevens has caused quite a stir on the political left and right,"], "metric_results": {"EM": 0.390625, "QA-F1": 0.4385416666666667}, "metric_results_detailed": {"EM": [false, true, true, true, false, false, true, false, false, true, false, true, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, true, false, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, false, false, false, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, false], "QA-F1": [0.16666666666666669, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.4, 1.0, 0.5, 1.0, 0.6666666666666666, 0.16666666666666669]}}, "before_error_ids": ["mrqa_squad-validation-4798", "mrqa_searchqa-validation-9835", "mrqa_searchqa-validation-10169", "mrqa_searchqa-validation-13591", "mrqa_searchqa-validation-10473", "mrqa_searchqa-validation-135", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-6842", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-13464", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-4041", "mrqa_searchqa-validation-14644", "mrqa_searchqa-validation-231", "mrqa_searchqa-validation-1693", "mrqa_searchqa-validation-1994", "mrqa_searchqa-validation-3900", "mrqa_searchqa-validation-7137", "mrqa_searchqa-validation-6465", "mrqa_searchqa-validation-3641", "mrqa_searchqa-validation-3715", "mrqa_searchqa-validation-15246", "mrqa_searchqa-validation-3579", "mrqa_searchqa-validation-15750", "mrqa_searchqa-validation-15306", "mrqa_searchqa-validation-16233", "mrqa_searchqa-validation-16940", "mrqa_searchqa-validation-4165", "mrqa_searchqa-validation-14012", "mrqa_searchqa-validation-15632", "mrqa_searchqa-validation-3528", "mrqa_naturalquestions-validation-5485", "mrqa_naturalquestions-validation-5355", "mrqa_triviaqa-validation-7493", "mrqa_hotpotqa-validation-2866", "mrqa_hotpotqa-validation-5297", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-723"], "SR": 0.390625, "CSR": 0.5367943548387097, "EFR": 1.0, "Overall": 0.7683971774193549}, {"timecode": 31, "before_eval_results": {"predictions": ["non-Mongol physicians", "Prospect Park", "the iris", "the volume", "a squint", "Breakfast at Tiffany's", "Diners' Club", "Christian Dior", "August Wilson", "Juliet", "Notre Dame", "Table cloth", "Jamie", "Bligh", "Cecil Rhodes", "Edinburgh", "Swaziland", "Kevin Spacey", "Union Square", "Pennsylvania Railroad", "Mike Huckabee", "Queen", "a headache", "the Chance", "mulberry", "Edmund Hillary", "Samuel Beckett", "Rachel Carson", "Vietnam", "sports", "David Geffen", "Franklin D. Roosevelt", "Kate Middleton", "America Ferrera", "an R", "Zechariah", "New Jersey", "Lake Ontario", "Matt LeBlanc", "Marissa Jaret Winokur", "Gilbert", "kismet", "Willy Wonka", "a battery", "aluminum", "General McClellan", "Ned Kelly", "a piles of papers", "gravitational force", "Isis", "a quiver", "Heroes", "on the two tablets", "the source of the donor organ", "seven", "Max Planck", "Rocky Marciano", "Stevie Wonder", "Ludwig van Beethoven", "March 13, 2013", "Chelsea Vanessa Peretti", "two years,", "Keith Hackett", "as time goes on, it kind of becomes more and more of a phenomenon.\""], "metric_results": {"EM": 0.59375, "QA-F1": 0.6505208333333333}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, false, true, true, false, false, true, true, true, true, false, false, false, false, false, true, true, false, false, false, true, false, true, true, false, true, false, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-15142", "mrqa_searchqa-validation-11182", "mrqa_searchqa-validation-3537", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-13455", "mrqa_searchqa-validation-8443", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-5737", "mrqa_searchqa-validation-9783", "mrqa_searchqa-validation-15708", "mrqa_searchqa-validation-16012", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-4624", "mrqa_searchqa-validation-1379", "mrqa_searchqa-validation-11731", "mrqa_searchqa-validation-10344", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-15973", "mrqa_searchqa-validation-10868", "mrqa_searchqa-validation-13240", "mrqa_naturalquestions-validation-10310", "mrqa_naturalquestions-validation-410", "mrqa_hotpotqa-validation-513", "mrqa_newsqa-validation-313", "mrqa_newsqa-validation-2123"], "SR": 0.59375, "CSR": 0.53857421875, "EFR": 1.0, "Overall": 0.769287109375}, {"timecode": 32, "before_eval_results": {"predictions": ["in weight", "Fresno Street", "the Black Death", "Elton John", "John Stuart Mill", "Emperor Norton", "CIA", "piano", "Rickey Henderson", "Jawaharlal Nehru", "the wild relative D. carota ssp. maritimus", "John Grunsfeld", "Llados", "1976", "Galileo Descartes", "a quark", "the Lamentations of Zeno", "Rudy Giuliani", "the First Amendment", "Virginia", "Thor", "New Jersey", "The Omega Man", "a pantry", "a cylinder", "1984 Summer Olympics", "Hugo Chvez", "Shamir", "Hinduism", "tin", "Diana", "The Rime of the Ancient Mariner", "pine tar", "the Lincoln Tunnel", "Aidan Quinn", "Lindsay Davenport", "Los Angeles", "the east wind", "King Edward", "the Labour Party", "the pen", "Mexico", "Douglas Adams", "Strindberg", "Hawaii", "Stephen Crane", "France", "Sophocles", "Mark Cuban", "Thought Police", "a bust", "Central Park", "Alice", "Part 2", "Coconut Cove", "a piano", "trumpet", "Mel Gibson", "2.1 million", "Edward James Olmos", "Lynyrd Skynyrd", "President Omar Bongo,", "South Africa", "Ignazio La Russa"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6689980158730158}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, true, true, true, false, false, false, false, true, false, false, false, true, true, true, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false, true, true, false, false, false, true, true, true, false, true, true, true, true, true, true, true, false, false, false, false, false, true, true, true, true, false, false, true, true], "QA-F1": [0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3434", "mrqa_squad-validation-4703", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-10316", "mrqa_searchqa-validation-513", "mrqa_searchqa-validation-8138", "mrqa_searchqa-validation-3592", "mrqa_searchqa-validation-16331", "mrqa_searchqa-validation-12683", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-3792", "mrqa_searchqa-validation-11191", "mrqa_searchqa-validation-10213", "mrqa_searchqa-validation-8063", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-9313", "mrqa_searchqa-validation-14835", "mrqa_searchqa-validation-1923", "mrqa_searchqa-validation-1405", "mrqa_naturalquestions-validation-4007", "mrqa_naturalquestions-validation-10416", "mrqa_naturalquestions-validation-1310", "mrqa_triviaqa-validation-7160", "mrqa_hotpotqa-validation-4767", "mrqa_newsqa-validation-3926"], "SR": 0.59375, "CSR": 0.5402462121212122, "EFR": 0.9615384615384616, "Overall": 0.7508923368298368}, {"timecode": 33, "before_eval_results": {"predictions": ["the BBC on VHS, on MP3 CD-ROM, and as special features on DVD", "pathogens, an allograft", "a pool of blood beneath his head.", "the closure of a terminal for hours while authorities rescreened thousands of passengers.", "28", "back at work", "in Oxbow, a town of about 238 people,", "201-262-2800", "opium", "\"Bishops, who is also known as Amy Bishop, is \"aware of what she's done and she's very sorry for it.\"", "Saturday,", "Hussein's Revolutionary Command Council", "drugs", "the Dalai Lama", "Myanmar over the weekend,", "The station", "protest child trafficking and shout anti-French slogans Wednesday in Abeche, Chad.", "forgery and flying without a valid license,", "Arkansas", "Cash for Clunkers", "environmental efforts", "North Korea intends to launch a long-range missile in the near future,", "terrorism,", "hardship for terminally ill patients and their caregivers,", "different women coping with breast cancer in", "missile strike or confrontation between the two countries at sea.", "Police", "sodium dichromate, an inorganic compound containing a highly toxic form of chromium known as hexavalent chromium.", "Roger Federer", "Miami Beach, Florida,", "over 1000 square meters in forward deck space, allowing for such features as a full garden and pool, a tennis court, or several heli-pads.", "CNN", "no chance", "a children's hospital in St. Louis, Missouri.", "he was one of 10 gunmen who attacked several targets in Mumbai on November 26,", "two years ago.", "two", "William Shakespeare", "the self-styled revolutionary Symbionese Liberation Army -- perhaps best known for kidnapping Patricia Hearst --", "not guilty of affray by a court in his home city on Friday.", "two tickets to Italy on Expedia.", "Colombia", "a welcoming, bright blue-purple during the day, a softer violet hue after dusk, and a deep, calm near-black on red-eyes when it's time to sleep", "resources", "1981,", "Los Angeles", "16", "Pope Benedict XVI", "South Africa", "NATO forces", "some free milk.", "African National Congress Deputy President Kgalema Motlanthe,", "the Ming dynasty", "George II ( George Augustus ; German : Georg II. August ; 30 October / 9 November 1683 -- 25 October 1760 )", "2014 -- 15,", "November 5, 2013", "Javier Bardem", "Scotland", "Bremen, Germany", "Terry the Tomboy", "Araminta Ross", "Mrs. Potts", "M&M'S (Spokescandy)", "the Brave"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6178571989693313}, "metric_results_detailed": {"EM": [false, true, false, false, true, true, false, true, true, false, false, true, true, false, false, true, false, true, true, false, false, true, true, true, false, false, true, false, true, true, false, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, true, true, false, false, false, true, true, false, true, false, true, true, false, true, true, false, false, false], "QA-F1": [0.15384615384615385, 1.0, 0.0, 0.16666666666666669, 1.0, 1.0, 0.25, 1.0, 1.0, 0.07692307692307691, 0.6666666666666666, 1.0, 1.0, 0.0, 0.5, 1.0, 0.13333333333333333, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.7999999999999999, 0.16666666666666666, 1.0, 0.11764705882352941, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5333333333333333, 0.888888888888889, 1.0, 1.0, 0.0, 0.4, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7682", "mrqa_newsqa-validation-533", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3455", "mrqa_newsqa-validation-2292", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-478", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-922", "mrqa_newsqa-validation-4037", "mrqa_newsqa-validation-0", "mrqa_newsqa-validation-438", "mrqa_newsqa-validation-214", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-352", "mrqa_newsqa-validation-1194", "mrqa_newsqa-validation-4099", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-38", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-609", "mrqa_newsqa-validation-2897", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-1981", "mrqa_naturalquestions-validation-7108", "mrqa_triviaqa-validation-6451", "mrqa_hotpotqa-validation-145", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-10871", "mrqa_searchqa-validation-3588"], "SR": 0.515625, "CSR": 0.5395220588235294, "EFR": 1.0, "Overall": 0.7697610294117647}, {"timecode": 34, "before_eval_results": {"predictions": ["3", "the Koori", "weren't taking it well.", "Washington State's decommissioned Hanford nuclear site,", "Yemen,", "creditors going out of business for one reason or another,", "nearly $2 billion", "a businessman, team owner, radio-show host and author.", "the mastermind behind the September 11, 2001, terrorist attacks on the United States.", "(Roger) Federer", "Kenya", "children of street cleaners and firefighters.", "Piers Morgan,", "$3 billion,", "hardship for terminally ill patients and their caregivers", "Honduran", "Brazil", "three different videos that we like and want to know which ones you think are the best.", "strife in Somalia", "Roy", "the WBO welterweight title", "relatives of the five suspects,", "Meredith Kercher.", "trying to save their client from the death penalty", "Demi Moore", "a joint communique declaring Al-Shabaab \"a common enemy to both countries.\"", "Friday,", "cancerous tumors.", "20", "Matthew Fisher", "$1.5 million", "Tim Clark, Matt Kuchar and Bubba Watson", "40", "model of sustainability.", "glamour and hedonism", "a $158 green skirt and $298 bead and rhinestone cardigan", "Department of Homeland Security Secretary Janet Napolitano", "543", "cancer patients", "Robert Gates", "Israel", "on 112 acres about 30 miles southwest of Nashville,", "in critical condition", "in Seoul,", "Nicole", "that she was going to be on the Olympic medals podium.", "next week.", "Adam Lambert", "regulators in the agency's Colorado office", "early detection and helping other women cope with the disease.", "James Whitehouse,", "journalists and the flight crew will be freed,", "Indian monks", "Lionel Hardcastle", "Stephen Lang", "Dick Van Dyke", "(Bokm\u00e5l)", "a spirit", "Revengers Tragedy", "1972", "Hilda Neihardt", "Hogan Family", "the hippopotamus", "St Paul"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5696480990683294}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, false, false, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.8, 0.9333333333333333, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.3157894736842105, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.375, 0.0, 0.4444444444444445, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.15384615384615385, 1.0, 1.0, 0.0, 0.3636363636363636, 0.5, 0.5714285714285714, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666]}}, "before_error_ids": ["mrqa_newsqa-validation-1893", "mrqa_newsqa-validation-1946", "mrqa_newsqa-validation-2445", "mrqa_newsqa-validation-2873", "mrqa_newsqa-validation-1364", "mrqa_newsqa-validation-1932", "mrqa_newsqa-validation-1587", "mrqa_newsqa-validation-342", "mrqa_newsqa-validation-6", "mrqa_newsqa-validation-4146", "mrqa_newsqa-validation-2156", "mrqa_newsqa-validation-440", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-4022", "mrqa_newsqa-validation-2998", "mrqa_newsqa-validation-1685", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-4152", "mrqa_newsqa-validation-1092", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-1083", "mrqa_newsqa-validation-1829", "mrqa_newsqa-validation-84", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-2667", "mrqa_newsqa-validation-2915", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-923", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-2761", "mrqa_triviaqa-validation-5808", "mrqa_triviaqa-validation-2276", "mrqa_hotpotqa-validation-3472", "mrqa_hotpotqa-validation-4378", "mrqa_searchqa-validation-7879"], "SR": 0.453125, "CSR": 0.5370535714285714, "EFR": 1.0, "Overall": 0.7685267857142857}, {"timecode": 35, "before_eval_results": {"predictions": ["walked to the Surveyor, photographed it, and removed some parts which they returned to Earth.", "Border Reiver", "July 4, 1826", "rum", "Nantucket", "an Islamic leadership position.", "maple tree", "Malibu", "Sisyphus", "measure of sound", "Australia", "Ayla", "Rudolf Hess", "Cubism", "Gettysburg", "Paul Simon", "crabs", "Prospero", "Purple", "the Black Sea", "The Battle of the Little Bighorn", "Shakers", "a bellwether", "Time and Free Will", "potato chips", "Boxer", "The Spiderwick Chronicles", "Florence Harding", "Las Vegas", "\"Don't Think Twice\"", "the Rose Bowl", "Degas", "Henna", "light tunais", "Napa Valley", "Italy", "Washington, D.C.", "Atlanta", "klezmer", "Japan", "Saturday Night Fever", "12 men", "Nancy Pelosi", "a journal", "Jupiter", "Sadat", "National Ice Cream Day", "Mary Shelley", "50 million cells per litre (quart)", "Volitan Lionfish", "Charlie Sheen", "Edwin", "Bonnie Aarons", "Wednesday, 5 September 1666", "pop ballad", "Master of thunder, the god of the desert and aridity,", "Lou Gehrig", "meaning and origin.", "1949", "Aamir Khan", "My Gorgeous Life", "Argentina", "High Court Judge Justice Davis", "Cipro, Levaquin, Avelox, Noroxin and Floxin."], "metric_results": {"EM": 0.546875, "QA-F1": 0.635202205882353}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, true, false, false, false, true, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, true, true, true, false, true, false, false, false, true, false, true, true], "QA-F1": [0.35294117647058826, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-4001", "mrqa_searchqa-validation-193", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-7465", "mrqa_searchqa-validation-2343", "mrqa_searchqa-validation-4034", "mrqa_searchqa-validation-3570", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-1935", "mrqa_searchqa-validation-12541", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14608", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-5061", "mrqa_searchqa-validation-4780", "mrqa_searchqa-validation-821", "mrqa_searchqa-validation-2511", "mrqa_searchqa-validation-9342", "mrqa_searchqa-validation-2104", "mrqa_searchqa-validation-7619", "mrqa_searchqa-validation-7041", "mrqa_searchqa-validation-14485", "mrqa_searchqa-validation-12049", "mrqa_searchqa-validation-12788", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-7591", "mrqa_hotpotqa-validation-5386", "mrqa_hotpotqa-validation-827", "mrqa_newsqa-validation-3884"], "SR": 0.546875, "CSR": 0.5373263888888888, "EFR": 1.0, "Overall": 0.7686631944444444}, {"timecode": 36, "before_eval_results": {"predictions": ["lower-pressure boiler feed water", "Luzon", "Virginia", "one is worth trying", "silver", "Supernanny", "Atlantic", "Catawba Wine", "mosque", "(Henry) Hudson", "a plane", "dry ice", "Roosevelt", "Entourage", "eel", "Philadelphia", "Manhattan", "the unicorns", "The Presidential Election of 1856", "France", "Gilbert", "Hilda Rosner", "the Taj Mittal", "English Monarchs", "Carmen", "Margaret Mitchell", "La Esmerelda", "Sultans of Swing", "Pandarus", "one holding a secondary rank in an office or post", "Hoop Dreams", "Sphinx", "Satchmo Armstrong", "Mecca", "American New Wave", "Arby\\'s", "coffee", "one", "(Robert) Burns", "The Incredible Hulk", "Winnipeg", "Memphis Belle", "Burkina Faso", "the Central Pacific", "Attorney General", "fjgur tunguml", "a wolf", "The NFL", "Edith Piaf", "Ivan III", "a prologue", "birch", "an investor couple", "Jack Gleeson", "(Phil) Hurtt", "animals", "Massachusetts", "Starachowice", "Fredric March", "2009", "Democratic National Convention", "meteorologist", "$104,327,006", "\"17 Again,\""], "metric_results": {"EM": 0.515625, "QA-F1": 0.5766369047619048}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, true, false, true, true, false, true, false, true, true, true, false, false, false, false, false, false, true, true, true, true, false, false, false, false, false, true, false, false, false, true, true, false, true, false, false, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, true, false, true, true, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.5714285714285715, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6752", "mrqa_searchqa-validation-11176", "mrqa_searchqa-validation-5635", "mrqa_searchqa-validation-15899", "mrqa_searchqa-validation-5283", "mrqa_searchqa-validation-14918", "mrqa_searchqa-validation-13205", "mrqa_searchqa-validation-10220", "mrqa_searchqa-validation-2613", "mrqa_searchqa-validation-16500", "mrqa_searchqa-validation-4018", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-12153", "mrqa_searchqa-validation-11632", "mrqa_searchqa-validation-8556", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-15286", "mrqa_searchqa-validation-2262", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-8958", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-15272", "mrqa_searchqa-validation-4107", "mrqa_searchqa-validation-12396", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-5571", "mrqa_naturalquestions-validation-2026", "mrqa_triviaqa-validation-3956", "mrqa_hotpotqa-validation-2162", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-3951"], "SR": 0.515625, "CSR": 0.5367398648648649, "EFR": 1.0, "Overall": 0.7683699324324325}, {"timecode": 37, "before_eval_results": {"predictions": ["Liechtenstein", "Impressionists", "Henry Brown Jr.", "oats", "Mitt Romney", "Ivan the Terrible", "Sally Field", "Henry Lindbergh", "Eritrea", "pi", "tin", "the Mississippi River", "Clark Griswold", "w", "Marriott", "France", "Quebec", "The Secret", "the goldfields", "Collagen", "China", "a compound", "the cranes", "a claw", "Alzheimer", "the Gulf of Mexico", "Austin", "Euclid\\'s Elements", "Eva Peron", "Cain", "Ed Asner", "X-Men", "Louvre", "achinook", "Prison Break", "Mars", "Maine", "a sheep's milk cheese", "Meg", "Rainer Maria Rilke", "deuce", "Hans Christian Andersen", "Peter Bogdanovich", "Billy Joel", "Jerusalem", "The drama of French life", "the Quaternary Period", "nolo contendere", "Junior Walker", "Czech Republic", "a tuna", "the NIRA", "John Ernest Crawford", "beta decay", "Prussia", "Priam", "Mariette", "Ike Barinholtz", "Aron Ralston", "Australian", "the sins of the members of the church,", "$22 million", "\"17 Again,\"", "Bardstown"], "metric_results": {"EM": 0.65625, "QA-F1": 0.6666666666666666}, "metric_results_detailed": {"EM": [true, false, false, true, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, true, true, false, true, false, true, false, false, true, true, true, true, true, false, true, true, true, false, true, false, true, true, true, true, false, false, false, true, true, true, false, true, true, true, true, true, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9798", "mrqa_searchqa-validation-15864", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-10268", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-3426", "mrqa_searchqa-validation-7541", "mrqa_searchqa-validation-10441", "mrqa_searchqa-validation-15664", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-1987", "mrqa_searchqa-validation-10123", "mrqa_searchqa-validation-1615", "mrqa_searchqa-validation-16600", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-16291", "mrqa_searchqa-validation-14545", "mrqa_searchqa-validation-8068", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-5774"], "SR": 0.65625, "CSR": 0.5398848684210527, "EFR": 1.0, "Overall": 0.7699424342105263}, {"timecode": 38, "before_eval_results": {"predictions": ["tuition", "Holden Caulfield", "Bill Hickok", "Leptospirosis", "a recession", "a whale", "Jay Silverheels", "Singapore", "The Chieftain", "a dance tune", "a canoe", "Peter Bretter", "Witness", "Jack the Ripper", "3800", "Henry Gibson", "phylum", "Spain", "the brain", "burning of the White", "Macbeth", "a paean", "Mary Poppins", "non-hitter", "The Fresh Prince of Bel-Air", "Nod", "watermelon", "bathwater", "marriage", "Livin' On A Prayer", "non-Hijja", "a lollipop", "Marie Antoinette", "Ford", "Mme Skodowska Curie", "Roger Brooke Taney", "diagonals", "German", "Katamari Damacy", "Mark Twain", "Margaret Thatcher", "Wellington", "an oxide", "forest", "Olympia", "Waylon Jennings", "Doctor Zhivago", "Brazil", "British Columbia", "Sydney Pollack", "a scrapple", "Oona Castilla Chaplin", "October 6, 2017", "John Cooper Clarke", "the different levels of importance of human psychological and physical needs", "one", "Norfolk Island", "Wright brothers", "sexual activity", "Sam Tick", "Sandro Bondi refused", "voluntary depletion", "\"Benedict also expressed \"deep sorrow\" at the death of two women killed in a stampede at one of his events in Angola", "Pygmalion"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5608878968253967}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, false, false, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, false, false, true, false, false, true, true, false, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, true, true, true, false, false, false, true, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4, 0.8, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.1111111111111111, 0.5, 0.9523809523809523, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-5349", "mrqa_searchqa-validation-14698", "mrqa_searchqa-validation-4628", "mrqa_searchqa-validation-16680", "mrqa_searchqa-validation-2204", "mrqa_searchqa-validation-3282", "mrqa_searchqa-validation-14988", "mrqa_searchqa-validation-14938", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-6033", "mrqa_searchqa-validation-6665", "mrqa_searchqa-validation-4413", "mrqa_searchqa-validation-6803", "mrqa_searchqa-validation-4288", "mrqa_searchqa-validation-3430", "mrqa_searchqa-validation-7477", "mrqa_searchqa-validation-683", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-8689", "mrqa_searchqa-validation-4043", "mrqa_searchqa-validation-1961", "mrqa_searchqa-validation-13348", "mrqa_searchqa-validation-14951", "mrqa_searchqa-validation-11444", "mrqa_searchqa-validation-2282", "mrqa_triviaqa-validation-2536", "mrqa_triviaqa-validation-387", "mrqa_triviaqa-validation-3945", "mrqa_hotpotqa-validation-4013", "mrqa_newsqa-validation-630", "mrqa_newsqa-validation-4164", "mrqa_newsqa-validation-600"], "SR": 0.484375, "CSR": 0.5384615384615384, "EFR": 0.9696969696969697, "Overall": 0.754079254079254}, {"timecode": 39, "before_eval_results": {"predictions": ["Brazil", "Boogie Woogie Boy", "Europe", "Jack Nicholson", "Glory", "Sweeney Todd", "The Bridge on the River Kwai", "the Fall of Constantinople", "a wedding", "Jefferson", "Ford", "Quiz", "a ready-to-use cotton swab", "California", "Dixie", "a nonprofit institution that helps improve policy and decisionmaking", "Warren Harding", "a pattern", "William", "Francis Crick", "Jay and Silent Bob", "Monson", "Abkhazia", "Twelfth Night", "Hawaii", "a key", "Tito", "a terriers", "Ratatouille", "synchronism", "Calvin Coolidge", "Mark Cuban", "Rudolph Giuliani", "eyes", "Tony Dungy", "the Danube", "Andrew Johnson", "26.2", "life", "a shrews", "the endgame", "GIGO", "Johannes Brahms", "Charleston", "Italian", "The Grapes of Wrath", "a bicentennial", "Byzantium", "Mayo", "Led Zeppelin", "a Tesla coil", "Denmark", "Tara", "March 15, 1945", "Charles Darwin", "Old Trafford", "Spider-Man", "Honey Irani", "global peace", "Kalahari", "Mrs. Graham", "Bob Dole", "Ben Kingsley", "managing his time"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5554315476190476}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, false, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, true, true, true, true, true, true, false, false, true, false, false, true, false, true, false, false, false, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.33333333333333337, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5]}}, "before_error_ids": ["mrqa_searchqa-validation-16066", "mrqa_searchqa-validation-3741", "mrqa_searchqa-validation-6543", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-8782", "mrqa_searchqa-validation-15434", "mrqa_searchqa-validation-6190", "mrqa_searchqa-validation-12158", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-16349", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-2211", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11808", "mrqa_searchqa-validation-9351", "mrqa_searchqa-validation-1130", "mrqa_searchqa-validation-631", "mrqa_searchqa-validation-5025", "mrqa_searchqa-validation-10828", "mrqa_searchqa-validation-5754", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-15687", "mrqa_searchqa-validation-2876", "mrqa_searchqa-validation-7544", "mrqa_searchqa-validation-11314", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-9270", "mrqa_naturalquestions-validation-6266", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-4134", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-3011", "mrqa_newsqa-validation-4073"], "SR": 0.46875, "CSR": 0.53671875, "EFR": 1.0, "Overall": 0.768359375}, {"timecode": 40, "before_eval_results": {"predictions": ["63", "Baden-W\u00fcrttemberg", "James Weldon Johnson", "a 2003 South Korean horror film", "Oakdale", "Missouri", "FAI Junior", "Flaw", "alt-right", "The Drudge Report", "15,000 people", "Yellow fever", "an all-female a cappella singing group", "1934", "a record of 13\u20133,", "We Need a Little Christmas", "Tsavo East National Park", "New York Islanders", "Algirdas", "nearly 80 years", "Jean Acker", "the Championship", "The Gettysburg Address", "Whitney Houston", "Mbapp\u00e9", "The Rite of Spring", "David Allen", "26,000", "Kristin Scott Thomas", "Ed Lee", "1958", "1993", "American burlesque", "Afro-Russian", "Loretta Lynn", "Lancashire, England", "a Boeing B-17 Flying Fortress", "1 December 1948", "11", "the XXIV Summer Universiade", "2012", "1994", "Leawood, Kansas", "1999", "Pinellas County", "beer", "London", "Ployer Peter Hill", "Mindy Kaling", "1988", "Leonard Cohen", "Erika Mitchell Leonard", "Mase Dinehart", "Tevye", "Sir Tom Finney", "Cameroon", "its own safety as well as all others that may be exposed to the fluid samples they draw", "by military personnel to hazardous materials", "two", "Iggy Pop invented punk rock.", "The Merchant of Venice", "a man", "Leonardo DiCaprio", "'go f * * k yourself '"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6496987336601308}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.888888888888889, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 0.35294117647058826, 0.4, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-313", "mrqa_hotpotqa-validation-4014", "mrqa_hotpotqa-validation-5337", "mrqa_hotpotqa-validation-1022", "mrqa_hotpotqa-validation-1749", "mrqa_hotpotqa-validation-5532", "mrqa_hotpotqa-validation-5344", "mrqa_hotpotqa-validation-4069", "mrqa_hotpotqa-validation-5298", "mrqa_hotpotqa-validation-3874", "mrqa_hotpotqa-validation-4678", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-2880", "mrqa_hotpotqa-validation-4472", "mrqa_hotpotqa-validation-3112", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-2151", "mrqa_naturalquestions-validation-10208", "mrqa_naturalquestions-validation-7201", "mrqa_naturalquestions-validation-3523", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-3552", "mrqa_newsqa-validation-1030", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-16547", "mrqa_naturalquestions-validation-6326"], "SR": 0.5625, "CSR": 0.5373475609756098, "EFR": 1.0, "Overall": 0.7686737804878049}, {"timecode": 41, "before_eval_results": {"predictions": ["a fumble", "10", "did not identify any of the dead.", "Les Bleus", "2005", "more than 4,000", "Arlen Specter (D-Pennsylvania)", "angry mob.", "normal maritime", "Sri Lanka", "killed Lauterbach", "an average of 25 percent", "fatally shooting a limo driver", "Al Nisr Al Saudi", "as", "piano", "$250,000", "a \"prostitute\"", "Columbian mammoth fossil", "tax", "Los Ticos", "acute stress disorder", "Russia and China", "Facebook and Google,", "through a facility in Salt Lake City, Utah", "Manmohan Singh's Congress party", "Haiti", "on March 21.", "Pakistan", "23 years.", "head injury.", "Tim Cahill", "an open window", "Leo Frank", "Paul McCartney and Ringo Starr", "Haiti's capital, Port-au-Prince", "President Robert Mugabe", "don't have to visit laundromats", "three", "Diversity", "on-loan David Beckham claimed his first goal in Italian football.", "\"He is more American than German.\"", "\"Twilight\"", "forgery and flying without a valid license", "11", "A third beluga whale belonging to the world's largest aquarium has died", "Fayetteville, North Carolina,", "The crash destroyed four homes and killed two people who lived in at least one of the homes", "the Taliban", "Hillary Clinton", "Rihanna", "angular rotation", "the right side of the heart to the lungs", "54 Mbit / s", "in the County of Gloucestershire", "B-24 Liberator", "\"Brings out the tiger in you, in you!\"", "Oakdale", "Melbourne", "Guillermo del Toro", "jedoublen/jeopardy", "Monty Python and the Holy Grail", "Sweden", "FMCSA"], "metric_results": {"EM": 0.578125, "QA-F1": 0.7023048566017316}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, true, true, false, false, true, false, true, true, true, false, true, true, true, false, true, false, true, true, false, false, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, true, true, false, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.8, 1.0, 1.0, 0.7272727272727273, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.625, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.2857142857142857, 1.0, 0.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.28571428571428575, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-3527", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-2523", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-1512", "mrqa_newsqa-validation-338", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-908", "mrqa_newsqa-validation-3461", "mrqa_newsqa-validation-354", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-3049", "mrqa_newsqa-validation-1914", "mrqa_newsqa-validation-151", "mrqa_newsqa-validation-2100", "mrqa_newsqa-validation-3619", "mrqa_newsqa-validation-2519", "mrqa_naturalquestions-validation-5552", "mrqa_triviaqa-validation-1429", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-376", "mrqa_searchqa-validation-2346", "mrqa_searchqa-validation-10945"], "SR": 0.578125, "CSR": 0.5383184523809523, "EFR": 1.0, "Overall": 0.7691592261904762}, {"timecode": 42, "before_eval_results": {"predictions": ["Accountants", "Chinese", "Zimbabwe,", "Italian Serie A title", "Darrel Mohler", "her dancing against a stripper's pole.", "the \" Michoacan Family,\"", "WTA Tour titles", "Morgan Tsvangirai", "42", "taking on the swords of the Taliban.", "\"In the next several hundred years, life there may be difficult, and the cities may become impractical unless we can build large structures,", "80 percent", "1979", "\"Follow the Sun,\"", "Elena Kagan", "Blagojevich", "an auxiliary lock", "1-1", "\"His sole reason for being on Flight 253 was to kill all of the passengers and himself.", "Myanmar", "\"We don't see at this point any indication of an individual out in the neighborhoods committing additional crimes or homicides,", "his business dealings", "\"Fourteen gunmen", "poems telling of the pain and suffering of children", "the program was made with the parents' full consent.", "(the Democratic VP candidate", "The Red Cross, UNHCR and UNICEF", "Moscow", "debris", "\"Can I just say how pleased I am with today's verdict,\"", "capital murder and three counts of attempted murder", "Basel", "17", "a Daytime Emmy Lifetime Achievement Award.", "state senators", "31 meters (102 feet)", "nude beaches.", "how preachy and awkward cancer movies can get.", "the girl's stepmother,", "shark River Park in Monmouth County", "three out of four", "Islamabad", "partying your face off in public is not the way to reclaim your good guy image.", "Capitol Hill,", "\"The IAEA has inspected the known nuclear sites of Iran.", "1940's", "March 22,", "think are the best.", "Mediterranean Sea.", "\"Antichrist\"", "a major fall in stock prices", "Thomas Jefferson", "Jeff East", "Orion", "brown", "Selfie", "23 March 1991", "South Australia", "Los Alamos National Laboratory", "the Rat", "rain", "Crawford", "Pyrenees"], "metric_results": {"EM": 0.515625, "QA-F1": 0.641570152682285}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, false, true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 1.0, 0.0, 0.5, 0.11764705882352941, 0.08, 0.5714285714285715, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2222222222222222, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5333333333333333, 0.5, 0.4, 0.0, 0.8, 1.0, 1.0, 0.125, 1.0, 0.0, 0.0, 1.0, 0.0, 0.3636363636363636, 1.0, 0.12500000000000003, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1419", "mrqa_newsqa-validation-3392", "mrqa_newsqa-validation-495", "mrqa_newsqa-validation-3076", "mrqa_newsqa-validation-1635", "mrqa_newsqa-validation-1683", "mrqa_newsqa-validation-561", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-1204", "mrqa_newsqa-validation-3871", "mrqa_newsqa-validation-2683", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3073", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1389", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-1772", "mrqa_newsqa-validation-3976", "mrqa_newsqa-validation-3431", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-3774", "mrqa_newsqa-validation-868", "mrqa_newsqa-validation-1891", "mrqa_newsqa-validation-1269", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-800", "mrqa_naturalquestions-validation-1799", "mrqa_hotpotqa-validation-2985", "mrqa_hotpotqa-validation-5834", "mrqa_hotpotqa-validation-920"], "SR": 0.515625, "CSR": 0.5377906976744187, "EFR": 1.0, "Overall": 0.7688953488372093}, {"timecode": 43, "before_eval_results": {"predictions": ["the north,", "the legitimacy of that race.", "At least 88", "North Korea intends to launch a long-range missile in the near future,", "Kurt Cobain", "Former detainees", "33-year-old", "that these \"fusion teams,\" as they're being called, have come into effect.", "hardship for terminally ill patients and their caregivers,", "Jaime Andrade", "Zac Efron", "finance", "$2 billion", "pesos", "In the 1920s,", "The station", "Karthik Rajaram,", "The Arkansas weatherman", "Robert Mugabe", "the wife of Gov. Mark Sanford,", "Afghanistan's Helmand province,", "Saturday.", "$1.5 million", "a violent government crackdown seeped out.", "could be secretly working on a nuclear weapon", "the fact that the teens were charged as adults.", "death squad killings", "Elena Kagan", "Hyundai's", "100 percent", "Saturday about 20 feet above flood stage.", "Pakistan's", "prisoners at the South Dakota State Penitentiary", "seven", "200", "Pakistan", "Seminole Tribe", "a Muslim with Lebanese heritage,", "in a Johannesburg church that has become a de facto transit camp.", "Barack Obama,", "helicopters and robotic surveillance craft to the \"border states\"", "U.S. Secretary of State Hillary Clinton,", "maintain an \"aesthetic environment\" and ensure public safety,", "165-room", "second time", "Jund Ansar Allah", "1,500", "most of those who managed to survive the incident hid in a boiler room and storage closets", "$50 less,", "$60 billion on America's infrastructure.", "ALS6,", "Malayalam", "Mad - Eye Moody and Hedwig", "1960 Summer Olympics in Rome", "Villa Park", "small-holder farmer", "pool", "1822", "The Dressmaker", "Trilochanapala", "garlic", "a buffalo", "ruby slippers", "the frontal lobe"], "metric_results": {"EM": 0.453125, "QA-F1": 0.5817616260551043}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, false, true, true, true, true, false, true, false, true, false, false, false, false, false, true, true, false, false, true, false, true, false, true, false, false, true, true, true, true, false, false, false, false, false, false, true, true, false, false, true, false, false, false, true, true, false, false, true, false, false, true, true, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.5, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 0.28571428571428575, 0.0, 1.0, 1.0, 0.0, 0.08695652173913043, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.3076923076923077, 0.2857142857142857, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.8, 0.5714285714285715, 1.0, 1.0, 0.7499999999999999, 0.33333333333333337, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-2068", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-509", "mrqa_newsqa-validation-2444", "mrqa_newsqa-validation-1457", "mrqa_newsqa-validation-364", "mrqa_newsqa-validation-3950", "mrqa_newsqa-validation-656", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-727", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-1048", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1223", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-2651", "mrqa_newsqa-validation-2228", "mrqa_newsqa-validation-1445", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2642", "mrqa_newsqa-validation-2732", "mrqa_newsqa-validation-2000", "mrqa_newsqa-validation-3316", "mrqa_newsqa-validation-1975", "mrqa_naturalquestions-validation-922", "mrqa_naturalquestions-validation-8741", "mrqa_triviaqa-validation-2424", "mrqa_triviaqa-validation-4307", "mrqa_hotpotqa-validation-2278", "mrqa_searchqa-validation-11223", "mrqa_searchqa-validation-2281"], "SR": 0.453125, "CSR": 0.5358664772727273, "EFR": 1.0, "Overall": 0.7679332386363636}, {"timecode": 44, "before_eval_results": {"predictions": ["Bermuda 419 turf", "Los Angeles", "Christopher Livingstone \" Chris\" Eubank Jr.", "Florida", "Benj Pasek and Justin Paul", "Andes", "1952", "Angola", "19th", "January 28, 2016", "Araminta Ross", "Roger Staubach", "1944", "Johns Creek", "Franconia, New Hampshire", "Guadalcanal", "Dumbo", "War & Peace", "Amberley Village", "19th century", "Berea College", "the United Football League", "Luca Guadagnino", "Liesl", "Germany and other parts of Central Europe", "New York Islanders", "Amy Smart", "26,788", "the Troubles", "1967", "Marktown", "jus sanguinis", "Radcliffe College", "James A. Garfield", "Ford", "heavier than a feather", "India", "Lutheranism", "Charmed", "25 million", "The Snowman", "Ella Fitzgerald", "X-Men", "Rain Man", "Interscope Records", "Robert Grosvenor", "3,672", "Henry Luce", "I'm Shipping Up to Boston", "Switzerland", "British singer and \"Britain's Got Talent\" winner Jai McDowall", "central", "the mainland of the Australian continent", "the beginning of the American colonies", "Nicola Adams", "\"bay of geese,\"", "Russia", "shows the world that you love the environment and hate using fuel,\"", "Steven Green", "Fayetteville, North Carolina,", "Chaucer", "rattlesnakes", "Riddles", "healthy, wealthy, and wise"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5138347170008355}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, true, false, false, true, true, false, true, false, true, false, false, true, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, false, false, true, false, true, true, true, false, false, true, false, false, false, false, true, false, false, false, false, false, true, false, true, false, true, false, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 0.0, 0.7499999999999999, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 0.28571428571428575, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 0.0, 0.0, 0.10526315789473684, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-1648", "mrqa_hotpotqa-validation-1058", "mrqa_hotpotqa-validation-1815", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-4795", "mrqa_hotpotqa-validation-2787", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-4037", "mrqa_hotpotqa-validation-44", "mrqa_hotpotqa-validation-797", "mrqa_hotpotqa-validation-2671", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-4978", "mrqa_hotpotqa-validation-3854", "mrqa_hotpotqa-validation-2626", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-593", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-2355", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-3942", "mrqa_hotpotqa-validation-5", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-1044", "mrqa_hotpotqa-validation-4828", "mrqa_naturalquestions-validation-5624", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-1433", "mrqa_triviaqa-validation-3532", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2515", "mrqa_searchqa-validation-12418", "mrqa_searchqa-validation-13986"], "SR": 0.46875, "CSR": 0.534375, "EFR": 0.9705882352941176, "Overall": 0.7524816176470588}, {"timecode": 45, "before_eval_results": {"predictions": ["Kelvin Benjamin", "murder", "the United States, NATO member states, Russia and India", "30", "crocodile eggs", "Colorado prosecutor", "Polis", "Saturday.", "Haiti", "in July for A Country Christmas,", "sniff out cell phones.", "the single-engine Cessna 206 went down, half a nautical mile from the shoreline of the city of Quebradillas.", "Haron Bialek", "\"17 Again\"", "North Korea intends to launch a long-range missile in the near future,", "Wigan Athletic", "Mitt Romney", "two years ago.", "businessman", "Picasso's muse and mistress, Marie-Therese Walter.", "low-calorie meals", "Heshmatollah Attarzadeh", "the ireport form", "the Middle East and North Africa,", "Nine out of 10 children", "police", "women", "a crocodile", "a bronze medal in the women's figure skating final,", "more than 200.", "Congress", "Susan Boyle", "ways to speed up screening of service members and, to the extent possible, their families,", "Phillip A. Myers.", "Obama's", "King Gyanendra,", "\"The cause of the child's death will be listed as homicide by undetermined means,", "Casey Anthony,", "officers at a Texas  airport", "12 off-duty federal agents in southwestern Mexico,", "UNICEF", "the pregnancy.", "228", "Kerstin and two of her brothers,", "the first near-total face transplant in the United States,", "when daughter Sasha exhibited signs of potentially deadly meningitis when she was 4 months old.", "Joan Rivers", "supermodel and philanthropist", "Jacob Zuma,", "in the Oaxacan countryside of southern Mexico", "Wenger", "slavery", "Little Mo ( Kacey Ainsworth ) and Zoe ( Michelle Ryan ), and grandmother Mo ( Laila Morse )", "Latin liberalia studia", "Enid Blyton", "Johnny Mathis", "The Golden Child (1986)", "Champion Jockey", "Luca Guadagnino", "Ms. Jackson", "the caged bird", "it makes sense because it's a month after her last race", "a jigger", "a bomber"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6603070175438597}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, true, true, false, true, true, false, false, true, true, true, false, false, false, true, false, true, true, false, true, false, false, false, true, false, true, true, false, false, false, false, false], "QA-F1": [1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.33333333333333337, 1.0, 0.5263157894736842, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.7499999999999999, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.2666666666666667, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3171", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-272", "mrqa_newsqa-validation-3961", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-4013", "mrqa_newsqa-validation-5", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-134", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-1574", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-2820", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-1676", "mrqa_newsqa-validation-3932", "mrqa_newsqa-validation-1390", "mrqa_newsqa-validation-319", "mrqa_naturalquestions-validation-2472", "mrqa_naturalquestions-validation-1360", "mrqa_triviaqa-validation-6120", "mrqa_triviaqa-validation-4", "mrqa_hotpotqa-validation-5640", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-6553", "mrqa_searchqa-validation-2431", "mrqa_triviaqa-validation-7461"], "SR": 0.5625, "CSR": 0.5349864130434783, "EFR": 1.0, "Overall": 0.7674932065217391}, {"timecode": 46, "before_eval_results": {"predictions": ["\"spectacular\"", "\"We need a president who understands the world today, the future we seek and the change we", "Nirvana", "\"The Apple Inc. co-founder Steve Wozniak and his partner show off their moves", "\"The Costa Mesa Police Department", "12.3 million", "Mexico", "Argentine", "Vivek Wadhwa,", "Brett Cummins,", "Indian army", "Saturday", "Nicole", "the legitimacy of that race.", "the diversity the collaborations provide,", "Dennis Davern,", "Africa", "American", "bartering -- trading goods and services without exchanging money", "Wednesday.", "get better skin, burn fat and boost her energy.", "Chinese", "Newcastle", "\"Nothing But Love\"", "allegedly involved in forged credit cards", "on June 6, 1944,", "\"We're trying to express ourselves and expose the lies,\"", "1-0 draw", "October 19,", "\"It was a wrong thing to say,", "Seoul,", "promotes fuel economy and safety", "ALS6,", "eight", "Siri", "he has no plans to fritter his cash away on fast cars, drink and celebrity parties.", "246", "Grayback forest-", "the children of street cleaners and firefighters.", "\"The U.S. intelligence community does not believe North Korea intends to launch a long-range missile in the near future,", "that a U.S. helicopter crashed in northeastern Baghdad as", "attempting illegal crossings", "American Civil Liberties Union", "\"We're just buttoning up a lot of our clay levees and putting a few more sandbags in place,", "38,", "Her husband and attorney, James Whitehouse,", "American schools.", "three", "\"doodles\" on its home page,", "cancer,", "two", "Arnold Schoenberg", "Brooklyn, New York", "Jean Fernel", "vorkosigan", "Japan", "fox hunting", "New York", "travel", "16,116", "\"Cry-Baby\"", "sugar", "mary mary", "Rowan Blanchard"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6645854504690711}, "metric_results_detailed": {"EM": [true, false, true, false, true, true, true, true, false, true, false, false, true, true, false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, false, true, false, true, true, true, false, true, false, true, false, false, true, true, false, true, true, false, false, false, true, true, true, true, true, false, true, true, true, false, true, false, false, false, true], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 0.15384615384615383, 1.0, 1.0, 1.0, 0.0, 0.8571428571428571, 0.15384615384615385, 0.0, 1.0, 0.9090909090909091, 1.0, 0.1111111111111111, 1.0, 1.0, 1.0, 0.04761904761904762, 1.0, 0.0, 1.0, 0.7692307692307693, 0.9333333333333333, 1.0, 1.0, 0.13793103448275862, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-428", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3895", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-714", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3198", "mrqa_newsqa-validation-2502", "mrqa_newsqa-validation-4082", "mrqa_newsqa-validation-3227", "mrqa_newsqa-validation-2812", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-774", "mrqa_newsqa-validation-4062", "mrqa_newsqa-validation-212", "mrqa_newsqa-validation-1778", "mrqa_newsqa-validation-3841", "mrqa_newsqa-validation-1994", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1764", "mrqa_triviaqa-validation-1729", "mrqa_hotpotqa-validation-2280", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-11573", "mrqa_searchqa-validation-917"], "SR": 0.578125, "CSR": 0.5359042553191489, "EFR": 1.0, "Overall": 0.7679521276595744}, {"timecode": 47, "before_eval_results": {"predictions": ["Corendon Dutch Airlines", "A Rush of Blood to the Head", "5", "Chicago", "\"The Ones Who Walk Away from Omelas\"", "child actor", "Richard Nixon", "drew the name out of a hat", "Brett Ryan Eldredge", "I-League", "two or three", "The Beatles' Apple label", "Sophia Winkleman", "animal", "1853", "1983", "Citizens for a Sound Economy", "2027 Fairmount Avenue between Corinthian Avenue and North 22nd Street", "1946 and 1947", "5,112", "1992", "retail, office and residential", "14,673", "6'5\" and 190 pounds", "Mickey Gilley", "a series of bilateral treaties", "a puppy", "Mexican", "December 24, 1973", "1933", "the backside", "Ulver and the Troms\u00f8 Chamber Orchestra", "1730", "London Luton Airport", "the Salzburg Festival", "McComb, Mississippi", "Afghanistan", "1959", "Imelda Marcos", "Randall Boggs", "Part II", "Bunker Hill", "the European or Eurasian cave lion", "the Royal Navy", "World War II", "Knoxville", "\"Three's Company\"", "P.O.S,", "Labour", "music industry magazines", "Erich Maria Remarque", "September 14, 2008", "79", "Frank Theodore `` Ted '' Levine ( born May 29, 1957 )", "Romania", "the James Gang", "Mt Kenya", "Aung San Suu Kyi", "Afghan National Security Forces at the site.", "Her husband and attorney, James Whitehouse,", "Cairo", "Secretariat", "lobbies", "Lehman Bros International (Europe)"], "metric_results": {"EM": 0.5, "QA-F1": 0.6112293956043955}, "metric_results_detailed": {"EM": [false, true, true, true, true, true, false, false, false, false, false, false, false, false, true, true, true, false, true, false, true, false, false, false, true, false, false, false, true, true, true, false, true, false, true, true, true, true, true, true, false, false, false, true, true, false, true, true, true, false, false, true, true, false, true, false, false, true, false, true, true, false, false, false], "QA-F1": [0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.8000000000000002, 0.0, 0.0, 0.8571428571428571, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.4615384615384615, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.4, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.33333333333333337, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-738", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-802", "mrqa_hotpotqa-validation-1668", "mrqa_hotpotqa-validation-3675", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-744", "mrqa_hotpotqa-validation-1093", "mrqa_hotpotqa-validation-887", "mrqa_hotpotqa-validation-621", "mrqa_hotpotqa-validation-5691", "mrqa_hotpotqa-validation-1330", "mrqa_hotpotqa-validation-4520", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-4960", "mrqa_hotpotqa-validation-1017", "mrqa_hotpotqa-validation-2921", "mrqa_hotpotqa-validation-1931", "mrqa_hotpotqa-validation-2053", "mrqa_hotpotqa-validation-183", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-5531", "mrqa_naturalquestions-validation-4043", "mrqa_triviaqa-validation-6146", "mrqa_triviaqa-validation-5309", "mrqa_newsqa-validation-1795", "mrqa_searchqa-validation-6735", "mrqa_searchqa-validation-10434", "mrqa_triviaqa-validation-2701"], "SR": 0.5, "CSR": 0.53515625, "EFR": 0.96875, "Overall": 0.751953125}, {"timecode": 48, "before_eval_results": {"predictions": ["ragweed", "St Petersburg", "gari", "the line of scrimmage", "Vulcan", "best-selling poem", "Fawn Hall", "waive", "\"American Idol\"", "Barnum & Bailey Circus", "Johnny Weissmuller", "cathode", "a torque wrench", "gold", "Marlon Brando", "m.H.G. Middle Dutch", "\"Inventing Impressionism\"", "Kentucky", "ruddy", "Brussels", "Macbeth", "General Lee", "piracy", "Fyodor Dostoevsky", "Martin Luther", "Clue", "best story writer", "Norway", "Andrew Johnson", "every seven years", "Mike Connors", "\"J Jungle Jim\"", "Jim Inhofe", "sancire", "Corpus Christi", "South Africa", "the best and heaviest living birds in the world", "a preamble", "a shift", "keller", "Desperate Housewives", "Galileo Galilei", "Canada", "Get Smart", "a pin", "a bat", "West Virginia", "James Madison", "movie theater", "the deep-90s", "kritikos", "Khrushchev", "1904", "a young girl", "Bobby Tambling", "ambidextrous", "chariots", "Humberside Airport", "265 million", "100 million", "help poor families buy more energy-efficient electrical appliances.", "a head injury.", "Pope Benedict XVI refused Wednesday to soften the Vatican's ban on condom use", "Charles II"], "metric_results": {"EM": 0.5, "QA-F1": 0.5645833333333333}, "metric_results_detailed": {"EM": [true, false, false, false, true, false, true, true, false, false, true, true, true, true, true, false, false, false, true, true, true, false, true, false, true, true, false, true, false, false, true, false, false, false, true, false, false, true, true, false, true, false, true, false, false, false, true, false, false, false, false, true, true, false, false, true, true, true, true, true, false, true, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.5, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-599", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-6362", "mrqa_searchqa-validation-507", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-12540", "mrqa_searchqa-validation-8856", "mrqa_searchqa-validation-3259", "mrqa_searchqa-validation-4061", "mrqa_searchqa-validation-15736", "mrqa_searchqa-validation-4039", "mrqa_searchqa-validation-4314", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-9370", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-2710", "mrqa_searchqa-validation-60", "mrqa_searchqa-validation-10801", "mrqa_searchqa-validation-9942", "mrqa_searchqa-validation-16389", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-12146", "mrqa_searchqa-validation-14589", "mrqa_searchqa-validation-15062", "mrqa_naturalquestions-validation-1805", "mrqa_triviaqa-validation-1836", "mrqa_newsqa-validation-3448", "mrqa_newsqa-validation-1663"], "SR": 0.5, "CSR": 0.534438775510204, "EFR": 1.0, "Overall": 0.767219387755102}, {"timecode": 49, "before_eval_results": {"predictions": ["the NSA", "the Heisman", "Brandi Chastain", "the Androscoggin", "Pamela Anderson", "carioca", "Treasure Island", "Pocahontas", "improvisation", "(P.B.) Kennedy", "an octave", "a push-button valve", "Great American Novel", "( Matthew) Broderick", "Joseph Campbell", "Margaret Mitchell", "Charles Busch", "a draft horse", "Ernest Lawrence", "a rodeo", "a fresco", "Nevil Shute", "a poet", "Jesse Jackson", "the House of Saxe-Coburg-Gotha", "Department of Homeland Security", "the Black Sea", "a leotard", "Bulworth", "a plc", "the mouthpiece", "Cuba", "Lord of the Rings", "Olivia Newton-John", "a bug spray", "Manhattan", "February 2", "Leontyne Price", "a composting material", "Lauren Hutton", "Christopher Columbus", "Phil Mickelson", "Carrie Bradshaw", "a spring", "Vaduz", "a burnus", "City of Philadelphia", "peanut butter", "Invisible Man", "a leather", "Lex Luthor", "food and clothing", "( Schwarzenegger ) and his companion, the thief Malak ( Walter )", "Master Christopher Jones", "hieroglyphic", "a Sequel", "St Moritz in Switzerland", "October", "Drifting", "Ellesmere Port, United Kingdom", "Sunday evening", "three out of four", "poems", "\"Nebo Zovyot\""], "metric_results": {"EM": 0.46875, "QA-F1": 0.5381944444444444}, "metric_results_detailed": {"EM": [false, false, true, false, true, true, true, true, true, false, false, false, true, true, true, true, false, false, true, true, false, true, false, true, false, false, true, true, true, false, true, false, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, true, true, false, true, false, false, true, false, false, false, false, true, false, false, false, true, true], "QA-F1": [0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 0.4444444444444445, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9727", "mrqa_searchqa-validation-6040", "mrqa_searchqa-validation-4026", "mrqa_searchqa-validation-11420", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-8249", "mrqa_searchqa-validation-10212", "mrqa_searchqa-validation-10510", "mrqa_searchqa-validation-4813", "mrqa_searchqa-validation-7250", "mrqa_searchqa-validation-13674", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-1364", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-14252", "mrqa_searchqa-validation-5787", "mrqa_searchqa-validation-3195", "mrqa_searchqa-validation-11061", "mrqa_searchqa-validation-273", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-11045", "mrqa_searchqa-validation-8315", "mrqa_searchqa-validation-2904", "mrqa_naturalquestions-validation-8163", "mrqa_naturalquestions-validation-7715", "mrqa_triviaqa-validation-2737", "mrqa_triviaqa-validation-4457", "mrqa_triviaqa-validation-1028", "mrqa_hotpotqa-validation-241", "mrqa_hotpotqa-validation-3602", "mrqa_newsqa-validation-3484", "mrqa_newsqa-validation-1301"], "SR": 0.46875, "CSR": 0.5331250000000001, "EFR": 1.0, "Overall": 0.7665625}, {"timecode": 50, "UKR": 0.701171875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1046", "mrqa_hotpotqa-validation-1047", "mrqa_hotpotqa-validation-1241", "mrqa_hotpotqa-validation-1328", "mrqa_hotpotqa-validation-1483", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-1622", "mrqa_hotpotqa-validation-1632", "mrqa_hotpotqa-validation-1640", "mrqa_hotpotqa-validation-1704", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1765", "mrqa_hotpotqa-validation-1821", "mrqa_hotpotqa-validation-2057", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2118", "mrqa_hotpotqa-validation-2280", "mrqa_hotpotqa-validation-2333", "mrqa_hotpotqa-validation-2387", "mrqa_hotpotqa-validation-2388", "mrqa_hotpotqa-validation-2459", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2746", "mrqa_hotpotqa-validation-2768", "mrqa_hotpotqa-validation-2865", "mrqa_hotpotqa-validation-3172", "mrqa_hotpotqa-validation-323", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3527", "mrqa_hotpotqa-validation-357", "mrqa_hotpotqa-validation-3600", "mrqa_hotpotqa-validation-3750", "mrqa_hotpotqa-validation-4145", "mrqa_hotpotqa-validation-4160", "mrqa_hotpotqa-validation-4266", "mrqa_hotpotqa-validation-4370", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4425", "mrqa_hotpotqa-validation-4445", "mrqa_hotpotqa-validation-4528", "mrqa_hotpotqa-validation-454", "mrqa_hotpotqa-validation-4638", "mrqa_hotpotqa-validation-4853", "mrqa_hotpotqa-validation-4881", "mrqa_hotpotqa-validation-4937", "mrqa_hotpotqa-validation-4962", "mrqa_hotpotqa-validation-4986", "mrqa_hotpotqa-validation-4996", "mrqa_hotpotqa-validation-5100", "mrqa_hotpotqa-validation-5101", "mrqa_hotpotqa-validation-5103", "mrqa_hotpotqa-validation-5300", "mrqa_hotpotqa-validation-5324", "mrqa_hotpotqa-validation-5445", "mrqa_hotpotqa-validation-548", "mrqa_hotpotqa-validation-5495", "mrqa_hotpotqa-validation-5817", "mrqa_hotpotqa-validation-5818", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-586", "mrqa_hotpotqa-validation-5894", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-716", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-827", "mrqa_hotpotqa-validation-91", "mrqa_hotpotqa-validation-97", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-10380", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1199", "mrqa_naturalquestions-validation-1399", "mrqa_naturalquestions-validation-1714", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-232", "mrqa_naturalquestions-validation-2635", "mrqa_naturalquestions-validation-2668", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3468", "mrqa_naturalquestions-validation-3641", "mrqa_naturalquestions-validation-3837", "mrqa_naturalquestions-validation-392", "mrqa_naturalquestions-validation-4455", "mrqa_naturalquestions-validation-4554", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-5176", "mrqa_naturalquestions-validation-5315", "mrqa_naturalquestions-validation-5675", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-6200", "mrqa_naturalquestions-validation-7101", "mrqa_naturalquestions-validation-7108", "mrqa_naturalquestions-validation-7266", "mrqa_naturalquestions-validation-7527", "mrqa_naturalquestions-validation-7715", "mrqa_naturalquestions-validation-7930", "mrqa_naturalquestions-validation-794", "mrqa_naturalquestions-validation-8306", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-8702", "mrqa_naturalquestions-validation-9013", "mrqa_naturalquestions-validation-9079", "mrqa_naturalquestions-validation-9436", "mrqa_naturalquestions-validation-9447", "mrqa_newsqa-validation-1016", "mrqa_newsqa-validation-1030", "mrqa_newsqa-validation-1039", "mrqa_newsqa-validation-1052", "mrqa_newsqa-validation-1055", "mrqa_newsqa-validation-1057", "mrqa_newsqa-validation-1061", "mrqa_newsqa-validation-1107", "mrqa_newsqa-validation-1116", "mrqa_newsqa-validation-1134", "mrqa_newsqa-validation-1137", "mrqa_newsqa-validation-1166", "mrqa_newsqa-validation-121", "mrqa_newsqa-validation-1216", "mrqa_newsqa-validation-123", "mrqa_newsqa-validation-1236", "mrqa_newsqa-validation-1268", "mrqa_newsqa-validation-1335", "mrqa_newsqa-validation-1340", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1393", "mrqa_newsqa-validation-1400", "mrqa_newsqa-validation-1406", "mrqa_newsqa-validation-1408", "mrqa_newsqa-validation-1414", "mrqa_newsqa-validation-1415", "mrqa_newsqa-validation-1435", "mrqa_newsqa-validation-1465", "mrqa_newsqa-validation-1524", "mrqa_newsqa-validation-154", "mrqa_newsqa-validation-1572", "mrqa_newsqa-validation-1584", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-163", "mrqa_newsqa-validation-1631", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1672", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1674", "mrqa_newsqa-validation-1690", "mrqa_newsqa-validation-1702", "mrqa_newsqa-validation-1740", "mrqa_newsqa-validation-178", "mrqa_newsqa-validation-1805", "mrqa_newsqa-validation-1836", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-1963", "mrqa_newsqa-validation-1965", "mrqa_newsqa-validation-1990", "mrqa_newsqa-validation-2", "mrqa_newsqa-validation-2075", "mrqa_newsqa-validation-2150", "mrqa_newsqa-validation-2158", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-228", "mrqa_newsqa-validation-2283", "mrqa_newsqa-validation-2288", "mrqa_newsqa-validation-2340", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2399", "mrqa_newsqa-validation-2401", "mrqa_newsqa-validation-2408", "mrqa_newsqa-validation-2434", "mrqa_newsqa-validation-2437", "mrqa_newsqa-validation-2472", "mrqa_newsqa-validation-2475", "mrqa_newsqa-validation-249", "mrqa_newsqa-validation-2519", "mrqa_newsqa-validation-2560", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2671", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-2752", "mrqa_newsqa-validation-279", "mrqa_newsqa-validation-2801", "mrqa_newsqa-validation-2902", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2976", "mrqa_newsqa-validation-2979", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3056", "mrqa_newsqa-validation-3095", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3181", "mrqa_newsqa-validation-3186", "mrqa_newsqa-validation-3211", "mrqa_newsqa-validation-3222", "mrqa_newsqa-validation-3270", "mrqa_newsqa-validation-3329", "mrqa_newsqa-validation-3339", "mrqa_newsqa-validation-3343", "mrqa_newsqa-validation-3356", "mrqa_newsqa-validation-3377", "mrqa_newsqa-validation-3381", "mrqa_newsqa-validation-3409", "mrqa_newsqa-validation-3437", "mrqa_newsqa-validation-3483", "mrqa_newsqa-validation-3493", "mrqa_newsqa-validation-3503", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3574", "mrqa_newsqa-validation-363", "mrqa_newsqa-validation-3646", "mrqa_newsqa-validation-3690", "mrqa_newsqa-validation-37", "mrqa_newsqa-validation-373", "mrqa_newsqa-validation-3732", "mrqa_newsqa-validation-3747", "mrqa_newsqa-validation-3764", "mrqa_newsqa-validation-3783", "mrqa_newsqa-validation-3786", "mrqa_newsqa-validation-3791", "mrqa_newsqa-validation-385", "mrqa_newsqa-validation-3874", "mrqa_newsqa-validation-3883", "mrqa_newsqa-validation-3898", "mrqa_newsqa-validation-3949", "mrqa_newsqa-validation-3951", "mrqa_newsqa-validation-4015", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4050", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4073", "mrqa_newsqa-validation-4083", "mrqa_newsqa-validation-4090", "mrqa_newsqa-validation-4135", "mrqa_newsqa-validation-423", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-48", "mrqa_newsqa-validation-499", "mrqa_newsqa-validation-511", "mrqa_newsqa-validation-530", "mrqa_newsqa-validation-54", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-622", "mrqa_newsqa-validation-64", "mrqa_newsqa-validation-712", "mrqa_newsqa-validation-723", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-818", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-845", "mrqa_newsqa-validation-957", "mrqa_newsqa-validation-958", "mrqa_newsqa-validation-974", "mrqa_searchqa-validation-10011", "mrqa_searchqa-validation-10042", "mrqa_searchqa-validation-10087", "mrqa_searchqa-validation-10175", "mrqa_searchqa-validation-10398", "mrqa_searchqa-validation-10501", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-10941", "mrqa_searchqa-validation-11328", "mrqa_searchqa-validation-11492", "mrqa_searchqa-validation-11686", "mrqa_searchqa-validation-1175", "mrqa_searchqa-validation-11948", "mrqa_searchqa-validation-1197", "mrqa_searchqa-validation-12123", "mrqa_searchqa-validation-12193", "mrqa_searchqa-validation-12269", "mrqa_searchqa-validation-12405", "mrqa_searchqa-validation-12670", "mrqa_searchqa-validation-12748", "mrqa_searchqa-validation-12778", "mrqa_searchqa-validation-12825", "mrqa_searchqa-validation-13072", "mrqa_searchqa-validation-13226", "mrqa_searchqa-validation-13240", "mrqa_searchqa-validation-13458", "mrqa_searchqa-validation-13875", "mrqa_searchqa-validation-1393", "mrqa_searchqa-validation-13989", "mrqa_searchqa-validation-14148", "mrqa_searchqa-validation-14601", "mrqa_searchqa-validation-14624", "mrqa_searchqa-validation-14703", "mrqa_searchqa-validation-14821", "mrqa_searchqa-validation-15062", "mrqa_searchqa-validation-15112", "mrqa_searchqa-validation-15176", "mrqa_searchqa-validation-15186", "mrqa_searchqa-validation-15278", "mrqa_searchqa-validation-1530", "mrqa_searchqa-validation-15354", "mrqa_searchqa-validation-15436", "mrqa_searchqa-validation-15556", "mrqa_searchqa-validation-16418", "mrqa_searchqa-validation-16521", "mrqa_searchqa-validation-16638", "mrqa_searchqa-validation-16666", "mrqa_searchqa-validation-16725", "mrqa_searchqa-validation-16842", "mrqa_searchqa-validation-1695", "mrqa_searchqa-validation-205", "mrqa_searchqa-validation-2122", "mrqa_searchqa-validation-219", "mrqa_searchqa-validation-2257", "mrqa_searchqa-validation-2279", "mrqa_searchqa-validation-2376", "mrqa_searchqa-validation-239", "mrqa_searchqa-validation-2453", "mrqa_searchqa-validation-2507", "mrqa_searchqa-validation-255", "mrqa_searchqa-validation-2689", "mrqa_searchqa-validation-3011", "mrqa_searchqa-validation-306", "mrqa_searchqa-validation-3179", "mrqa_searchqa-validation-3242", "mrqa_searchqa-validation-3344", "mrqa_searchqa-validation-3394", "mrqa_searchqa-validation-3404", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-3952", "mrqa_searchqa-validation-4479", "mrqa_searchqa-validation-4604", "mrqa_searchqa-validation-4643", "mrqa_searchqa-validation-4650", "mrqa_searchqa-validation-4891", "mrqa_searchqa-validation-5194", "mrqa_searchqa-validation-5318", "mrqa_searchqa-validation-5602", "mrqa_searchqa-validation-5862", "mrqa_searchqa-validation-5924", "mrqa_searchqa-validation-5984", "mrqa_searchqa-validation-6162", "mrqa_searchqa-validation-6219", "mrqa_searchqa-validation-6241", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-656", "mrqa_searchqa-validation-6601", "mrqa_searchqa-validation-6675", "mrqa_searchqa-validation-6718", "mrqa_searchqa-validation-6764", "mrqa_searchqa-validation-6959", "mrqa_searchqa-validation-6991", "mrqa_searchqa-validation-7049", "mrqa_searchqa-validation-7140", "mrqa_searchqa-validation-7377", "mrqa_searchqa-validation-7379", "mrqa_searchqa-validation-7409", "mrqa_searchqa-validation-7557", "mrqa_searchqa-validation-7560", "mrqa_searchqa-validation-7620", "mrqa_searchqa-validation-7780", "mrqa_searchqa-validation-7879", "mrqa_searchqa-validation-8503", "mrqa_searchqa-validation-8505", "mrqa_searchqa-validation-855", "mrqa_searchqa-validation-8597", "mrqa_searchqa-validation-8715", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8786", "mrqa_searchqa-validation-9107", "mrqa_searchqa-validation-9296", "mrqa_searchqa-validation-932", "mrqa_searchqa-validation-9428", "mrqa_searchqa-validation-945", "mrqa_searchqa-validation-9496", "mrqa_searchqa-validation-9810", "mrqa_searchqa-validation-9903", "mrqa_squad-validation-1002", "mrqa_squad-validation-10020", "mrqa_squad-validation-10100", "mrqa_squad-validation-10186", "mrqa_squad-validation-10254", "mrqa_squad-validation-10306", "mrqa_squad-validation-1146", "mrqa_squad-validation-1204", "mrqa_squad-validation-1506", "mrqa_squad-validation-1758", "mrqa_squad-validation-1906", "mrqa_squad-validation-1943", "mrqa_squad-validation-1960", "mrqa_squad-validation-2059", "mrqa_squad-validation-2225", "mrqa_squad-validation-2351", "mrqa_squad-validation-2466", "mrqa_squad-validation-2487", "mrqa_squad-validation-2530", "mrqa_squad-validation-2880", "mrqa_squad-validation-298", "mrqa_squad-validation-3265", "mrqa_squad-validation-3279", "mrqa_squad-validation-3703", "mrqa_squad-validation-3840", "mrqa_squad-validation-4047", "mrqa_squad-validation-4290", "mrqa_squad-validation-4315", "mrqa_squad-validation-4330", "mrqa_squad-validation-4353", "mrqa_squad-validation-4415", "mrqa_squad-validation-4455", "mrqa_squad-validation-4468", "mrqa_squad-validation-4517", "mrqa_squad-validation-4524", "mrqa_squad-validation-4673", "mrqa_squad-validation-4759", "mrqa_squad-validation-4812", "mrqa_squad-validation-4876", "mrqa_squad-validation-4998", "mrqa_squad-validation-5010", "mrqa_squad-validation-5170", "mrqa_squad-validation-549", "mrqa_squad-validation-5568", "mrqa_squad-validation-5581", "mrqa_squad-validation-5643", "mrqa_squad-validation-5812", "mrqa_squad-validation-5917", "mrqa_squad-validation-6106", "mrqa_squad-validation-6176", "mrqa_squad-validation-6218", "mrqa_squad-validation-6282", "mrqa_squad-validation-6547", "mrqa_squad-validation-6645", "mrqa_squad-validation-6694", "mrqa_squad-validation-670", "mrqa_squad-validation-6741", "mrqa_squad-validation-6797", "mrqa_squad-validation-6801", "mrqa_squad-validation-6842", "mrqa_squad-validation-6927", "mrqa_squad-validation-6941", "mrqa_squad-validation-7035", "mrqa_squad-validation-7069", "mrqa_squad-validation-7159", "mrqa_squad-validation-7674", "mrqa_squad-validation-7674", "mrqa_squad-validation-7757", "mrqa_squad-validation-7790", "mrqa_squad-validation-7818", "mrqa_squad-validation-7855", "mrqa_squad-validation-7937", "mrqa_squad-validation-8047", "mrqa_squad-validation-8503", "mrqa_squad-validation-8651", "mrqa_squad-validation-8733", "mrqa_squad-validation-8745", "mrqa_squad-validation-8833", "mrqa_squad-validation-8836", "mrqa_squad-validation-8896", "mrqa_squad-validation-9080", "mrqa_squad-validation-910", "mrqa_squad-validation-9170", "mrqa_squad-validation-9270", "mrqa_squad-validation-9298", "mrqa_squad-validation-9311", "mrqa_squad-validation-9398", "mrqa_squad-validation-940", "mrqa_squad-validation-9411", "mrqa_squad-validation-9543", "mrqa_squad-validation-9726", "mrqa_squad-validation-9752", "mrqa_squad-validation-9815", "mrqa_triviaqa-validation-1268", "mrqa_triviaqa-validation-1470", "mrqa_triviaqa-validation-1474", "mrqa_triviaqa-validation-1546", "mrqa_triviaqa-validation-1573", "mrqa_triviaqa-validation-1611", "mrqa_triviaqa-validation-1729", "mrqa_triviaqa-validation-1733", "mrqa_triviaqa-validation-1762", "mrqa_triviaqa-validation-1928", "mrqa_triviaqa-validation-1959", "mrqa_triviaqa-validation-1989", "mrqa_triviaqa-validation-210", "mrqa_triviaqa-validation-2997", "mrqa_triviaqa-validation-3020", "mrqa_triviaqa-validation-3039", "mrqa_triviaqa-validation-3044", "mrqa_triviaqa-validation-326", "mrqa_triviaqa-validation-3455", "mrqa_triviaqa-validation-364", "mrqa_triviaqa-validation-3819", "mrqa_triviaqa-validation-3821", "mrqa_triviaqa-validation-4", "mrqa_triviaqa-validation-42", "mrqa_triviaqa-validation-4536", "mrqa_triviaqa-validation-4568", "mrqa_triviaqa-validation-492", "mrqa_triviaqa-validation-5445", "mrqa_triviaqa-validation-5581", "mrqa_triviaqa-validation-580", "mrqa_triviaqa-validation-5880", "mrqa_triviaqa-validation-6008", "mrqa_triviaqa-validation-6176", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-6325", "mrqa_triviaqa-validation-6375", "mrqa_triviaqa-validation-6451", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-6803", "mrqa_triviaqa-validation-6824", "mrqa_triviaqa-validation-6965", "mrqa_triviaqa-validation-7295", "mrqa_triviaqa-validation-7351", "mrqa_triviaqa-validation-7438", "mrqa_triviaqa-validation-803", "mrqa_triviaqa-validation-993"], "OKR": 0.84375, "KG": 0.484375, "before_eval_results": {"predictions": ["Fatih Ozmen", "the Volvo 850", "Skyscraper", "Stingrays", "Norway", "Tom Jones", "VIMN Russia", "Homer Hickam, Jr.", "2015", "Hilo", "BAFTA Award for Best Actress in a Leading Role", "Schaeffler", "band director", "Visigoths", "Anaheim", "Reinhard Heydrich", "Big Ben", "Standard Oil", "\"The Longest Yard\"", "Chiwetel Umeadi Ejiofor", "president", "19th-century", "Hillary Scott", "Stratfor", "Vice President", "Tottenham Hotspur", "1958", "Vixen", "a scholar during the Joseon Dynasty", "Rymill Park", "Balloon Street, Manchester", "May 1, 2011", "Monroe County", "political", "Adelaide Lightning", "Operation Neptune", "Lancia-Abarth #037", "Lonely", "ten", "Diamond White", "Ferrara", "created the American Land-Grant universities and colleges", "Indooroopilly Shopping Centre", "2006", "Matt Flynn", "Indian", "hamburgers", "England", "little hairs", "Luigi Segre", "the legislature", "February 9, 2018", "CCMC", "Nacio Herb Brown", "Geoff Hurst", "the Precambrian", "Mull", "his death cast a shadow over festivities ahead of South Africa's highly-anticipated appearance in the rugby World Cup final with England this weekend.", "shooting himself three times in the head with a.40-caliber pistol,", "a progressive neurological disease", "Paul Newman", "Puccini", "John Candy", "milk and honey"], "metric_results": {"EM": 0.5, "QA-F1": 0.5824652777777778}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, false, true, true, false, false, false, false, false, true, true, false, true, true, false, true, true, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, true, false, true, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, false, true, false, false, true, true, true, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 0.0, 0.0, 0.4, 0.2, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5838", "mrqa_hotpotqa-validation-490", "mrqa_hotpotqa-validation-4382", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-4691", "mrqa_hotpotqa-validation-4667", "mrqa_hotpotqa-validation-2991", "mrqa_hotpotqa-validation-4170", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-221", "mrqa_hotpotqa-validation-1714", "mrqa_hotpotqa-validation-350", "mrqa_hotpotqa-validation-3265", "mrqa_hotpotqa-validation-4277", "mrqa_hotpotqa-validation-3304", "mrqa_hotpotqa-validation-412", "mrqa_hotpotqa-validation-5125", "mrqa_hotpotqa-validation-5866", "mrqa_hotpotqa-validation-1417", "mrqa_hotpotqa-validation-4995", "mrqa_hotpotqa-validation-3399", "mrqa_hotpotqa-validation-2876", "mrqa_hotpotqa-validation-3759", "mrqa_hotpotqa-validation-5140", "mrqa_hotpotqa-validation-2260", "mrqa_hotpotqa-validation-4406", "mrqa_naturalquestions-validation-2732", "mrqa_naturalquestions-validation-5600", "mrqa_triviaqa-validation-4774", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-2317", "mrqa_searchqa-validation-13015"], "SR": 0.5, "CSR": 0.5324754901960784, "EFR": 0.96875, "Overall": 0.7061044730392156}, {"timecode": 51, "before_eval_results": {"predictions": ["1979", "a wooden Indian", "Chiltern", "1898", "Stacey Kent", "31 December 1908 \u2013 20 September 2005", "Arthur Freed", "Kalokuokamaile", "Gothic Revival mansion", "Rochester", "Sam Waterston", "George Timothy Clooney", "January 4, 1976", "237 square miles", "11,163", "an album", "its air-cushioned sole", "The White Knights of the Ku Klux Klan", "WikiLeaks", "Nine-card Brag", "Montana State University", "Tool", "the Wikimedia Foundation", "Flashback: The Quest for Identity", "ARY Group", "1987", "dementia", "two Grammy awards", "Port of Boston", "Switzerland", "Las Vegas", "1961", "Rochdale, North West England", "the Israeli Declaration of Independence", "1971", "Blue Origin", "Target Corporation", "small forward position", "2012", "United States", "Robert Sargent Shriver Jr.", "No. 17", "Mark Neary Donohue Jr.", "Peach", "Switzerland", "Richard Price", "Archie Andrews", "George Mikan", "June 11, 1986", "2018\u201319 UEFA Europa League group stage", "Magdalen College", "Lake Powell", "Malvolio", "the Royal Air Force", "Separate Tables", "devonian", "devonian", "near the Somali coast", "a Daytime Emmy Lifetime Achievement Award.", "October 29 and November 5.", "Joseph Holt", "hunter sauce", "The Quest of Erebor", "carbon"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6925544507575758}, "metric_results_detailed": {"EM": [true, true, false, true, true, false, true, true, false, false, true, false, true, false, true, true, false, false, true, false, true, true, true, false, false, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, false, true, true, true, false, true, false, true, false, true, true, true, false, true, false, false, false, true, false, false, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.375, 0.5, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.8, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.8, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-5486", "mrqa_hotpotqa-validation-2199", "mrqa_hotpotqa-validation-5442", "mrqa_hotpotqa-validation-1055", "mrqa_hotpotqa-validation-5541", "mrqa_hotpotqa-validation-3989", "mrqa_hotpotqa-validation-4711", "mrqa_hotpotqa-validation-1391", "mrqa_hotpotqa-validation-996", "mrqa_hotpotqa-validation-4869", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1217", "mrqa_hotpotqa-validation-1452", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-405", "mrqa_hotpotqa-validation-2206", "mrqa_hotpotqa-validation-2803", "mrqa_hotpotqa-validation-1263", "mrqa_naturalquestions-validation-950", "mrqa_triviaqa-validation-2289", "mrqa_triviaqa-validation-3042", "mrqa_newsqa-validation-645", "mrqa_newsqa-validation-91", "mrqa_searchqa-validation-6747", "mrqa_searchqa-validation-1741"], "SR": 0.59375, "CSR": 0.5336538461538461, "EFR": 1.0, "Overall": 0.7125901442307693}, {"timecode": 52, "before_eval_results": {"predictions": ["My Antonia", "King Henry VIII", "lead", "the Rose Bowl", "a VC-25", "amber", "Denmark", "cute puppies", "The Waves", "Nazareth", "freestyle", "pen", "pornography", "Stargate", "Lou Reed", "Stonewall Jackson", "celtic", "celtic celtings", "hemp", "celt", "The X-Files", "Frankie Muniz", "a dinosaur", "Hudson Bay", "Louis Braille", "kinetic", "Santera", "Richard Bach", "a Statue of Liberty", "quicksand", "The Return of the Native", "AOL", "Pop-Tarts", "Minnesota", "the San Antonio River", "a cornucopia", "Bob Fosse", "Ankara", "condensation", "be", "Winchester", "Chinese", "The Larry Sanders Show", "The Virgin Spring", "Like Water for Chocolate", "NigerCongo", "Applebee's", "John Tyler", "Daniel Craig", "humility", "computer science", "the Mount Mannen in Norway and at the Isle of Sheppey in England", "A footling breech", "if the concentration of a compound exceeds its solubility", "Pulitzer Prize", "Gloucestershire", "In this world nothing can be said to be certain, except death & taxes", "Pan Am Railways", "Berthold Heinrich K\u00e4mpfert", "1960s", "between South America and Africa.", "celtick has set the fashion world on fire.", "fake his own death by crashing his private plane into a Florida swamp.", "the Stockton & Darlington Railway"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6268672733516484}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, false, true, true, true, false, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.625, 1.0, 0.923076923076923, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.7142857142857143, 0.0, 1.0, 0.8571428571428571]}}, "before_error_ids": ["mrqa_searchqa-validation-13696", "mrqa_searchqa-validation-7806", "mrqa_searchqa-validation-3773", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-8158", "mrqa_searchqa-validation-5567", "mrqa_searchqa-validation-7184", "mrqa_searchqa-validation-540", "mrqa_searchqa-validation-1235", "mrqa_searchqa-validation-13490", "mrqa_searchqa-validation-2922", "mrqa_searchqa-validation-6879", "mrqa_searchqa-validation-10982", "mrqa_searchqa-validation-4716", "mrqa_searchqa-validation-15189", "mrqa_searchqa-validation-4954", "mrqa_searchqa-validation-15500", "mrqa_naturalquestions-validation-3230", "mrqa_naturalquestions-validation-2965", "mrqa_triviaqa-validation-3526", "mrqa_triviaqa-validation-4700", "mrqa_triviaqa-validation-5698", "mrqa_hotpotqa-validation-4336", "mrqa_hotpotqa-validation-316", "mrqa_newsqa-validation-2782", "mrqa_newsqa-validation-1004", "mrqa_triviaqa-validation-5426"], "SR": 0.578125, "CSR": 0.5344929245283019, "EFR": 1.0, "Overall": 0.7127579599056604}, {"timecode": 53, "before_eval_results": {"predictions": ["Michael Rosen", "Saint Etienne", "After Shawn's kidnapping", "a device placed in a container of beer to manage the characteristics of the beer's head", "cool, dark, and moist areas, such as tree holes or rock crevices, in which to sleep", "cleansing ritual", "kenya soil", "a cover slip or cover glass, a smaller and thinner sheet of glass that is placed over the specimen", "Gary Player", "Andy Cole and Shearer", "season two", "in the sequence of pieces of DNA called genes", "maintains a global crowdfunding platform focused on creativity and merchandising", "warm and short with an average high of 23 \u00b0 C ( 73 \u00b0 F )", "the head of the United States Mint", "the Atlantic coast of Africa", "Madison, Wisconsin, United States", "September 1972", "the 13 -- 3 Eagles soared past the Minnesota Vikings and the Atlanta Falcons in the playoffs", "Gustav Bauer", "detritus", "the magnetic stripe `` anomalies '' on the ocean floor", "126", "Brooke Wexler", "Lulu", "1961", "111", "three countries", "a dromedary", "13", "the five - year time jump", "A complex sentence", "Halliwell, French, Timomatic and Sandilands", "a inertial force that acts on objects that are in motion relative to a rotating reference frame", "the five - year time jump", "James Rodr\u00edguez", "Donald Sutherland", "James Madison", "the NFL", "Daya Jethalal Gada", "74", "the type of hazard ahead", "various submucosal membrane sites of the body", "a noble gas", "Immigration and Naturalization Service's Forensics Document Laboratory", "four distinct levels of protein structure", "Janie Crawford", "Justin Timberlake", "In their first appearance, The Tenth Planet ( 1966 ), they are explained as being the product of humans from Earth's nearly identical `` twin planet '' of Mondas", "Bob Dylan, George Harrison, Jeff Lynne, Roy Orbison, and Tom Petty", "September 2017", "Hercule Poirot", "Charles Strickland", "USA Today serving as its megaphone.", "creeks, fringing the southwest mouth of Lagos Lagoon,", "Martin Scorsese", "Ian Fleming", "well over 1,000 pounds", "the creation of a long-term plan to help Haiti recover from the devastating effects of the earthquake and Argentina's conflict with Great Britain over oil drilling offshore", "off the coast of Dubai", "the Inuit Tapirisat", "Chayka", "a robe", "the death of a pregnant soldier"], "metric_results": {"EM": 0.40625, "QA-F1": 0.5001366959938274}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, false, false, true, false, true, false, false, false, false, false, true, true, false, true, true, true, true, true, true, true, true, false, false, true, false, true, false, false, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, false, false, true, false, false, false, true, true, true, false, false, false, false, false, true], "QA-F1": [1.0, 0.0, 0.0, 0.631578947368421, 0.8571428571428571, 0.08333333333333334, 0.0, 0.0, 1.0, 0.0, 1.0, 0.18181818181818182, 0.9411764705882353, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.41379310344827586, 1.0, 0.30769230769230765, 0.2857142857142857, 1.0, 1.0, 0.23076923076923078, 0.3076923076923077, 0.4444444444444445, 1.0, 0.0, 0.2857142857142857, 0.25, 1.0, 1.0, 1.0, 0.12121212121212122, 0.0, 0.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8747", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-6999", "mrqa_naturalquestions-validation-1052", "mrqa_naturalquestions-validation-9812", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-2498", "mrqa_naturalquestions-validation-10292", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-2220", "mrqa_naturalquestions-validation-9985", "mrqa_naturalquestions-validation-1946", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-7286", "mrqa_naturalquestions-validation-7710", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-132", "mrqa_naturalquestions-validation-8216", "mrqa_naturalquestions-validation-10367", "mrqa_naturalquestions-validation-527", "mrqa_naturalquestions-validation-10271", "mrqa_naturalquestions-validation-553", "mrqa_naturalquestions-validation-6993", "mrqa_naturalquestions-validation-5943", "mrqa_naturalquestions-validation-7203", "mrqa_naturalquestions-validation-388", "mrqa_naturalquestions-validation-8483", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-4748", "mrqa_hotpotqa-validation-3974", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-973", "mrqa_searchqa-validation-5130", "mrqa_searchqa-validation-5562", "mrqa_searchqa-validation-8459"], "SR": 0.40625, "CSR": 0.5321180555555556, "EFR": 0.9473684210526315, "Overall": 0.7017566703216375}, {"timecode": 54, "before_eval_results": {"predictions": ["Oona Castilla Chaplin", "Mike Czerwien", "one of the seven heavenly virtues typically said to date back to `` Psychomachia, '' an epic poem written in the fifth century", "chili con carne, nachos, hard tacos and fajitas", "George Harrison", "Kanawha Rivers", "1803", "President pro tempore of the Senate", "c. 3000 BC", "password recovery tool for Microsoft Windows", "Charlotte Thornton", "Western Australia", "Buffalo Bill", "May 3, 2005", "the angel Balthazar changes history in the sixth season episode `` My Heart Will Go On ''", "California, Utah and Arizona", "Hem Chandra Bose", "1773", "John J. Flanagan", "1988", "a judicial officer, of a lower or puisne court, elected or appointed by means of a commission ( letters patent ) to keep the peace", "at slightly different times when viewed from different points on Earth", "Jeff East", "Charlene Holt", "The Selective Service System of the United States conducted two lotteries to determine the order of call to military service in the Vietnam War for men born from 1944 to 1950", "May 31, 2012", "Sets heart in mediastinum and limits its motion", "Alex Skuby", "Matt Monro", "12.65 m", "The management team", "1999", "supervillains", "the courts", "Malvolio", "Beyonc\u00e9", "Arkansas", "to mark the birth centenary of Pandit Jawaharlal Nehru", "Isaac Morris", "Atlanta", "22", "Helena", "Joseph Sherrard Kearns", "Cyndi Grecco", "Michael Phelps", "Taron Egerton", "S\u00e9rgio Mendes", "John F. Kelly", "cylinder of glass or plastic that runs along the fiber's length", "anembryonic gestation", "741 weeks", "Zimbabwe", "London", "Sarah Palin", "Tampa", "Battle of Prome", "kitty Hawk", "John Lennon and George Harrison,", "the ship of violating Chinese and international laws during its patrols,", "it was like going somewhere very special, far away, because under the Communist regime you didn't travel that much and Prague was \"wow.\"", "Tater Tots", "Bahrain", "Q.E.D.", "(EMMETT) Dalton Gang"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6714965878918677}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, false, false, false, false, true, false, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, false, true, true, true, true, false, true, true, false, true, false, false, true, true, true, true, true, false, true, false, false, false, true, false, true, true, true, true, true, true, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 0.56, 0.4615384615384615, 1.0, 0.6666666666666666, 0.0, 0.28571428571428575, 0.8, 0.058823529411764705, 1.0, 0.5714285714285715, 1.0, 1.0, 0.8387096774193548, 0.4, 1.0, 1.0, 1.0, 1.0, 0.0, 0.060606060606060615, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.25, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.8571428571428572, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.06666666666666667, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2865", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-7483", "mrqa_naturalquestions-validation-6727", "mrqa_naturalquestions-validation-8982", "mrqa_naturalquestions-validation-902", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-8298", "mrqa_naturalquestions-validation-9741", "mrqa_naturalquestions-validation-440", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-5968", "mrqa_naturalquestions-validation-2717", "mrqa_naturalquestions-validation-1719", "mrqa_naturalquestions-validation-8408", "mrqa_naturalquestions-validation-3783", "mrqa_naturalquestions-validation-7692", "mrqa_naturalquestions-validation-1782", "mrqa_naturalquestions-validation-10598", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5094", "mrqa_naturalquestions-validation-7078", "mrqa_naturalquestions-validation-4428", "mrqa_newsqa-validation-3310", "mrqa_newsqa-validation-2827", "mrqa_searchqa-validation-16172", "mrqa_searchqa-validation-833", "mrqa_searchqa-validation-8575"], "SR": 0.5625, "CSR": 0.5326704545454546, "EFR": 0.8928571428571429, "Overall": 0.6909648944805195}, {"timecode": 55, "before_eval_results": {"predictions": ["the spoiled, bedridden daughter of wealthy businessman James Cotterell ( Ed Begley )", "Matt Monro", "support, movement, protection, production of blood cells, storage of minerals, and endocrine regulation", "Aristotle", "Reproductive system", "Peter Andrew Beardsley MBE", "USS Chesapeake", "Celtic", "Columbia River Gorge", "the Northeast Monsoon", "2013", "Hold On", "forests and animals", "2015", "Neil Young", "the closing of the atrioventricular valves and semilunar valves, respectively", "`` Product / market fit means being in a good market with a product that can satisfy that market", "London", "Robert Cappucci", "Hem Chandra Bose", "Ernest Rutherford", "the presence of correctly oriented P waves on the electrocardiogram ( ECG )", "the sacroiliac joint", "png HTTP / 1.1", "the Brewster family", "1 mile ( 1.6 km )", "pop ballad", "8 December 1985", "during prophase I of meiosis", "2007", "Arnold Schoenberg", "an English parson may'have his nose up in the air ', upturned like the chicken's rear end", "the air mass gains altitude it quickly cools down adiabatically, which can raise the relative humidity to 100 % and create clouds and, under the right conditions, precipitation", "the books of Exodus and Deuteronomy", "Scarlett Johansson", "InterContinental Hotels Group", "Benzodiazepines", "Steve Valentine", "John J. Flanagan", "the outside ( skin ) and the inside cavities and lumina of bodies", "2007", "Her cameo was filmed on the set of the Sex and The City prequel, The Carrie Diaries ; the producers like to imagine that she was directing an episode", "10,605", "Jeffannah Newmarch", "Ferrari", "Alamodome in San Antonio, Texas", "Sun Harvester", "superkingdom", "the national or royal anthem in a number of Commonwealth realms, their territories, and the British Crown Dependencies", "pathology", "Jo Anne Worley", "My Big Fat Gypsy Wedding", "Sir Roger Casement", "Robert Lloyd", "Boston, Massachusetts", "Colonel Patrick John Mercer, OBE (born 26 June 1956)", "Bob Hurley", "improve the military's suicide-prevention programs.", "five", "\"The Closer.\"", "(Antony) Benedict", "Madonna", "the Eiffel Tower", "Aaron Hall"], "metric_results": {"EM": 0.5, "QA-F1": 0.5957181965528147}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, true, true, true, false, true, true, false, false, true, true, false, true, false, true, true, false, true, false, false, true, true, true, true, false, true, false, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, false, true, false, false, false, false, true, false, false, false, true, true, false, true, false, false], "QA-F1": [0.0, 1.0, 0.47058823529411764, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.8, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.7096774193548387, 0.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9, 0.0, 0.1290322580645161, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.09523809523809522, 1.0, 0.0, 0.25, 0.8, 0.0, 1.0, 0.0, 0.4, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6469", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-774", "mrqa_naturalquestions-validation-4470", "mrqa_naturalquestions-validation-5317", "mrqa_naturalquestions-validation-387", "mrqa_naturalquestions-validation-9034", "mrqa_naturalquestions-validation-7731", "mrqa_naturalquestions-validation-9275", "mrqa_naturalquestions-validation-7165", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5831", "mrqa_naturalquestions-validation-581", "mrqa_naturalquestions-validation-10307", "mrqa_naturalquestions-validation-9047", "mrqa_naturalquestions-validation-3037", "mrqa_naturalquestions-validation-1802", "mrqa_naturalquestions-validation-7468", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-6522", "mrqa_naturalquestions-validation-6865", "mrqa_naturalquestions-validation-4149", "mrqa_naturalquestions-validation-46", "mrqa_triviaqa-validation-1894", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-4482", "mrqa_hotpotqa-validation-2296", "mrqa_hotpotqa-validation-4760", "mrqa_newsqa-validation-1887", "mrqa_searchqa-validation-1762", "mrqa_searchqa-validation-14136", "mrqa_hotpotqa-validation-3771"], "SR": 0.5, "CSR": 0.5320870535714286, "EFR": 0.96875, "Overall": 0.7060267857142858}, {"timecode": 56, "before_eval_results": {"predictions": ["Gerald Ford", "10 May 1940", "Raghu", "16", "1877", "1999", "Old Trafford", "Tami Lynn", "from U + 2234 \u2234 therefore ( HTML & # 8756 ; &there4 ; )", "the United States", "Max", "April 13, 2018", "Jenna Boyd", "Spencer Treat Clark", "Sedimentary rock", "Theodore Roosevelt", "Nepal", "julriaen Aernoutsz", "4 September 1936", "heat", "1940", "Authority", "April 1st", "jonell Elliot", "24 hours later", "Francisco Pizarro", "a habitat", "Ben Faulks", "Lady Gaga", "can negatively affect a person's personal, work, or school life, as well as sleeping, eating habits, and general health", "1989", "Liam Cunningham", "Andrea Charles", "Walter Pauk", "After Margaret Thatcher became Prime Minister in May 1979", "an osseo - cartilaginous", "Daoism", "the forex market", "`` Sing the Blues '' by Guy Mitchell", "Sir Ernest Rutherford", "Adam Shankman", "American adult animated science fiction comedy series created by Justin Roiland and Dan Harmon for Cartoon Network's late - night programming block Adult Swim", "gastrocnemius", "Al Pacino", "from Thomas Hobbes in his Leviathan", "March 26, 1973", "in London's West End in 1986", "a forest", "President Lyndon Johnson", "prenatal development of the human heart", "a Christmas Tree", "1840", "2007", "Branson", "first baseman", "Tumi", "River Shiel", "Ozzy Osbourne", "Polo", "are not for sale,", "ego", "Nova Scotia", "Sir Isaac Newton", "love letter"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6443222402597403}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, false, false, true, true, true, false, true, false, true, false, true, false, true, true, true, false, false, true, false, true, true, false, true, true, false, true, false, false, false, false, false, true, true, false, false, false, false, true, false, false, true, false, true, true, true, true, true, false, true, true, false, false, true, true, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.8, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.16, 0.6666666666666666, 0.0, 0.9090909090909091, 1.0, 0.2857142857142857, 0.0, 1.0, 0.4000000000000001, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.8, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7058", "mrqa_naturalquestions-validation-6337", "mrqa_naturalquestions-validation-6556", "mrqa_naturalquestions-validation-305", "mrqa_naturalquestions-validation-10610", "mrqa_naturalquestions-validation-6084", "mrqa_naturalquestions-validation-504", "mrqa_naturalquestions-validation-8075", "mrqa_naturalquestions-validation-2821", "mrqa_naturalquestions-validation-215", "mrqa_naturalquestions-validation-7164", "mrqa_naturalquestions-validation-9444", "mrqa_naturalquestions-validation-1008", "mrqa_naturalquestions-validation-6943", "mrqa_naturalquestions-validation-5120", "mrqa_naturalquestions-validation-5809", "mrqa_naturalquestions-validation-3236", "mrqa_naturalquestions-validation-5366", "mrqa_naturalquestions-validation-2170", "mrqa_naturalquestions-validation-7608", "mrqa_naturalquestions-validation-9536", "mrqa_naturalquestions-validation-9024", "mrqa_naturalquestions-validation-1038", "mrqa_naturalquestions-validation-5526", "mrqa_naturalquestions-validation-7486", "mrqa_hotpotqa-validation-3278", "mrqa_newsqa-validation-1003", "mrqa_newsqa-validation-2096", "mrqa_searchqa-validation-10569"], "SR": 0.546875, "CSR": 0.5323464912280702, "EFR": 0.9655172413793104, "Overall": 0.7054321215214762}, {"timecode": 57, "before_eval_results": {"predictions": ["England", "England", "one - mile - wide ( 1.6 km )", "a numeric scale used to specify the acidity or basicity of an aqueous solution", "acquire an advantage without deviating from basic strategy", "that country's surprise attack on Pearl Harbor the prior day", "the coffee shop Monk's", "Fred E. Ahlert", "January 2017 patch", "Ozzie Smith", "Mark Jackson", "1983", "Resident Commissioner", "by January 2018", "in all land - living organisms, both alive and dead, as well as carbon stored in soils", "September 30", "avian origin", "Gerald Ford", "September 8, 2017", "1998", "a political ideology", "Spektor", "an object that forms", "Cell nuclei", "1973", "on Thursdays at 8 : 00 pm ( ET )", "Ren\u00e9 Verdon", "a key signature at the beginning to designate the pitches that make up that scale", "a thirty - second call to one of a number of friends ( who provide their phone numbers in advance )", "a dysphemic vocalisation in the Second Temple period of a theonym based on the root ``k `` king ''", "P.V. Sindhu", "Carpenter", "Asuka", "126", "Klaus Meine", "Brazil", "the UNESCO / ILO Recommendation concerning the Status of Teachers", "issued upon a military service member's retirement, separation, or discharge from active duty in the Armed Forces of the United States", "a radius 1.5 times the Schwarzschild radius", "eliminate or reduce the trade barriers among all countries in the Americas, excluding Cuba", "Rich Mullins", "during prenatal development in the central part of each developing bone", "in skeletal muscle", "American country music duo Brooks & Dunn", "England", "Felicity Huffman", "In 1908", "Sir Henry Cole", "the fictional town of West Egg on prosperous Long Island in the summer of 1922", "Eukarya", "a traditional holiday originating in China, occurring near the summer solstice", "Luigi Pirandello", "Russ Conway", "the liver", "Heineken International", "Brian Patrick Friel", "Charlie Wilson", "Mark Sanford,", "Lance Cpl. Maria Lauterbach", "step up.", "Prohibition", "Joe Louis", "Richard Cory", "Mayan"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5834409549022678}, "metric_results_detailed": {"EM": [false, false, false, false, false, false, false, false, true, true, true, false, false, false, false, false, false, true, true, true, true, true, false, true, false, false, false, false, false, false, true, true, true, true, false, true, false, false, true, false, true, false, false, true, false, true, false, false, false, true, false, true, true, true, false, true, true, false, false, true, true, true, true, false], "QA-F1": [0.0, 0.0, 0.7499999999999999, 0.14285714285714288, 0.0, 0.6153846153846153, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.8, 0.21052631578947367, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6956521739130436, 0.14285714285714288, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.8888888888888888, 1.0, 0.9600000000000001, 1.0, 0.33333333333333337, 0.5714285714285715, 1.0, 0.0, 1.0, 0.6666666666666666, 0.3, 0.8181818181818181, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-8858", "mrqa_naturalquestions-validation-9703", "mrqa_naturalquestions-validation-3108", "mrqa_naturalquestions-validation-8652", "mrqa_naturalquestions-validation-5554", "mrqa_naturalquestions-validation-9809", "mrqa_naturalquestions-validation-339", "mrqa_naturalquestions-validation-9559", "mrqa_naturalquestions-validation-9251", "mrqa_naturalquestions-validation-2106", "mrqa_naturalquestions-validation-9157", "mrqa_naturalquestions-validation-8474", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-3495", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3698", "mrqa_naturalquestions-validation-10148", "mrqa_naturalquestions-validation-4586", "mrqa_naturalquestions-validation-4497", "mrqa_naturalquestions-validation-5636", "mrqa_naturalquestions-validation-2085", "mrqa_naturalquestions-validation-8275", "mrqa_naturalquestions-validation-7261", "mrqa_naturalquestions-validation-7605", "mrqa_naturalquestions-validation-3697", "mrqa_naturalquestions-validation-2440", "mrqa_naturalquestions-validation-1155", "mrqa_naturalquestions-validation-1971", "mrqa_naturalquestions-validation-2713", "mrqa_naturalquestions-validation-3189", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-94", "mrqa_hotpotqa-validation-572", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-2524", "mrqa_searchqa-validation-5902"], "SR": 0.4375, "CSR": 0.5307112068965517, "EFR": 0.9166666666666666, "Overall": 0.6953349497126438}, {"timecode": 58, "before_eval_results": {"predictions": ["William Wyler", "Mercedes -Benz G - Class", "1986", "Idaho", "October 14, 2017", "Exodus", "digestion of proteins", "1979 -- 80 season", "separately in England and Wales", "iron", "the Reverse - Flash", "Los Angeles, California", "the British Empire", "a cake", "King's Chamber", "Nebuchadnezzar", "Eddie Murphy", "17 - year - old", "1923", "the brain and spinal cord", "Seattle, Washington", "( 27 January -- 16 April 1898 )", "on the slopes of Mt. Hood in Oregon", "Ewan McGregor", "LED illuminated display", "cranberry sauce", "1917", "2004", "Anna Faris", "smen", "the Israelites were encamped at the foot of biblical Mount Sinai", "Macon Blair", "non-coding sequences", "to identify persons who are unable or don't want to drive", "the Convention's first act, on 10 August 1792, was to establish the French First Republic and officially strip the king of all political powers", "four", "divergent tectonic plate", "Steve Russell", "peace between two entities ( especially between man and God or between two countries ), or to the well - being, welfare or safety of an individual or a group of individuals", "New York University", "into the intermembrane space", "Northeast Monsoon or Retreating Monsoon", "2017 -- 18 UEFA Champions League knockout phase began on 13 February", "276", "early 1960s", "President Yahya Khan", "Thespis", "France", "Wednesday, 5 September 1666", "March 1995", "Zuzu & Zaza Zebra", "endometriosis", "1960", "Justin Trudeau", "2006", "Walldorf", "Marvel Comics characters Steve Rogers / Captain America", "crude oil", "fiber supplements, probiotics, antidepressants, behavioral-based therapies, psychotherapy, food modification, acupuncture, and laxatives", "the FBI", "a ferry", "Leland Stanford", "Oaxaca", "Nepal"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6614103218009468}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, false, false, false, false, false, true, false, true, false, true, false, false, false, true, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, true, true, false, true], "QA-F1": [1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.19999999999999998, 1.0, 0.9090909090909091, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.3076923076923077, 0.33333333333333337, 0.8750000000000001, 0.0, 0.2857142857142857, 0.0, 0.5, 1.0, 0.0, 1.0, 0.8, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8571428571428571, 1.0, 0.5945945945945945, 1.0, 0.0, 1.0, 0.3076923076923077, 0.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 0.9600000000000001, 1.0, 1.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-1586", "mrqa_naturalquestions-validation-2946", "mrqa_naturalquestions-validation-4711", "mrqa_naturalquestions-validation-2238", "mrqa_naturalquestions-validation-4919", "mrqa_naturalquestions-validation-4412", "mrqa_naturalquestions-validation-10439", "mrqa_naturalquestions-validation-7342", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-1277", "mrqa_naturalquestions-validation-3760", "mrqa_naturalquestions-validation-10161", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-2830", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-1890", "mrqa_naturalquestions-validation-8796", "mrqa_naturalquestions-validation-9332", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-645", "mrqa_naturalquestions-validation-180", "mrqa_naturalquestions-validation-912", "mrqa_naturalquestions-validation-2206", "mrqa_naturalquestions-validation-844", "mrqa_hotpotqa-validation-881", "mrqa_newsqa-validation-3428", "mrqa_newsqa-validation-98", "mrqa_searchqa-validation-10231"], "SR": 0.53125, "CSR": 0.5307203389830508, "EFR": 0.9, "Overall": 0.6920034427966102}, {"timecode": 59, "before_eval_results": {"predictions": ["regulatory site", "Jason Marsden", "Ireland", "Vicente Fox", "Daryl Sabara", "February 6, 2005", "Pepsi", "Abiotic", "9 ( VIIII )", "a useless, time - wasting activity", "head coach", "July 2012", "Audrey II", "Tim Russert", "Jodie Foster", "to connect the CNS to the limbs and organs, essentially serving as a relay between the brain and spinal cord and the rest of the body", "January 2018", "John Prine and Roger Cook", "climate on the Earth", "Herman Hollerith", "94 by 50 feet", "transmission", "Gibraltar", "a chimera ( a mixture of several animals ), who would probably be classified as a carnivore overall", "January 12, 2017", "The Miracles", "provide information about advance health care directives to adult patients upon their admission to the healthcare facility", "Marie Fredriksson", "Brooklyn Heights fortifications", "two of its circular spaces, then consuming fruit pies", "the British Empire", "at a castle during a ball and offers the host, a coldhearted prince, a rose for shelter", "Michael Crawford", "the Devastator", "the final episode of the series", "2010", "Ram Nath Kovind", "Abid Ali Neemuchwala", "August 16, 1945", "1950s", "Napoleon Bonaparte", "XXXX", "by the early - to - mid fourth century", "Made a decision to turn our will and our lives over to the care of God as we understood Him", "De pictura", "January 2, 1971", "J. Presper Eckert and John William Mauchly's ENIAC", "diastema ( plural diastemata )", "July 21, 1861", "Brooklyn, New York", "Efren Manalang Reyes", "Pink Floyd", "Chicago", "Dijon", "Lucas Stephen Grabeel", "15,022", "model", "the test results by the medical examiner's office,", "teenage", "Thursday,", "Vietnam", "a bass", "Richard", "Michael Rispoli"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6730294067491648}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, false, true, false, false, false, true, true, true, true, true, true, false, false, true, true, false, true, false, true, true, false, false, false, false, false, false, true, true, true, true, true, true, false, false, true, true, false, false, false, true, false, true, true, true, true, true, true, true, true, false, true, false, false, true, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.14285714285714288, 1.0, 1.0, 0.6153846153846153, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.9090909090909091, 0.2580645161290323, 0.0, 1.0, 0.18181818181818182, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6618", "mrqa_naturalquestions-validation-1195", "mrqa_naturalquestions-validation-7208", "mrqa_naturalquestions-validation-2758", "mrqa_naturalquestions-validation-3087", "mrqa_naturalquestions-validation-4792", "mrqa_naturalquestions-validation-9757", "mrqa_naturalquestions-validation-2010", "mrqa_naturalquestions-validation-5885", "mrqa_naturalquestions-validation-9195", "mrqa_naturalquestions-validation-5282", "mrqa_naturalquestions-validation-3032", "mrqa_naturalquestions-validation-1584", "mrqa_naturalquestions-validation-234", "mrqa_naturalquestions-validation-1664", "mrqa_naturalquestions-validation-8689", "mrqa_naturalquestions-validation-8171", "mrqa_naturalquestions-validation-2481", "mrqa_naturalquestions-validation-4961", "mrqa_naturalquestions-validation-3750", "mrqa_hotpotqa-validation-3979", "mrqa_newsqa-validation-3727", "mrqa_newsqa-validation-2984", "mrqa_searchqa-validation-9020", "mrqa_searchqa-validation-8465", "mrqa_triviaqa-validation-7581"], "SR": 0.59375, "CSR": 0.5317708333333333, "EFR": 0.9230769230769231, "Overall": 0.6968289262820513}, {"timecode": 60, "before_eval_results": {"predictions": ["a for - profit business, nonprofit organization, or a government agency", "1998", "used their knowledge of Native American languages as a basis to transmit coded messages", "Anna gives Jeremy a vial of her blood, telling him that if he drinks it he will die and become a undead.", "Tom Brady", "James Rodr\u00edguez", "a computer maintenance utility included in Microsoft Windows designed to free up disk space on a computer's hard drive", "1837", "petition for a writ of certiorari, filed by a party to a case that has been decided by one of the United States courts of appeals or by the United United States Court of Appeals for the Armed Forces", "silk floss tree", "Ferm\u00edn Francisco de Lasu\u00e9n", "Fats Waller", "macadamia nuts", "79", "adenine ( A ), uracil ( U ), guanine ( G ), thymine ( T ), and cytosine ( C )", "49 cents", "Jason Lee", "the Nationalists, a Falangist, Carlist, Catholic, and largely aristocratic conservative group led by General Francisco Franco", "Lorenzo Lamas", "Mahatma Gandhi", "the people of the United States", "the eighth season", "Erica Rivera", "John Young", "Russia", "2019", "Charles Perrault", "April 2010", "James `` Jamie '' Dornan", "widow - maker infarction due to a high death risk", "Sam Waterston", "Brazil, Bolivia, Paraguay and Argentina", "Nicklaus", "1957", "Pink Floyd", "ummat al - Islamiyah", "Brazil", "Parashara ( c. 400 -- c. 500 AD )", "Domhnall Gleeson", "Spanish botanist and physician Petrus Jacobus Stevus ( Pedro Jaime Esteve 1500 -- 1556 ), a professor of botany at the University of Valencia", "agriculture", "St. John's, Newfoundland and Labrador", "from the Greek \u0392\u03bf\u03ce\u03c4\u03b7\u03c2, Bo\u014dt\u0113s, meaning `` herdsman '' or `` plowman '' ( literally, `` ox - driver '' ; from \u03b2\u03bf\u1fe6\u03c2", "zootomy", "into the bloodstream or surrounding tissue following surgery, disease, or trauma", "1923", "1871 A.D.", "an episode typically ends as a cliffhanger showing the first few moments of Sam's next leap ( along with him again uttering `` Oh, boy! '' on discovering his situation ),", "a brownstone in Brooklyn Heights, New York, at 10 Stigwood Avenue", "1966", "early known period on the alluvial plain", "options for radio in a digital age", "Peter Sellers", "Colonel Thomas Andrew \u201cTom\u201d Parker", "Atlantic Ocean", "mistress of the Robes", "Australian Electoral Division", "Conway ( Arkansas)", "Kurt Cobain's", "semi-autobiographical account of the war years,", "Dedalus Wagner", "The Killing Fields", "the Endeavour", "said the trip had caused fury among some in the military who saw it as a waste of time and money at a time when British forces are thinly-stretched, fighting in Iraq and Afghanistan."], "metric_results": {"EM": 0.515625, "QA-F1": 0.6052833997173137}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, true, false, true, true, true, true, true, false, true, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, false, true, false, true, false, false, false, false, true, true, false, true, false, false, false, true, false, true, true, false, false, true, false, false, true, true, false], "QA-F1": [0.11111111111111112, 0.0, 0.06666666666666667, 0.0, 0.0, 1.0, 0.9142857142857143, 1.0, 0.16666666666666669, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 0.0, 0.13333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0909090909090909, 1.0, 0.0, 1.0, 0.0, 1.0, 0.08000000000000002, 1.0, 1.0, 0.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 0.7272727272727272, 0.9285714285714286, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.33333333333333337, 1.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.25, 0.0, 1.0, 1.0, 0.9836065573770492]}}, "before_error_ids": ["mrqa_naturalquestions-validation-2426", "mrqa_naturalquestions-validation-1679", "mrqa_naturalquestions-validation-5352", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-3093", "mrqa_naturalquestions-validation-10092", "mrqa_naturalquestions-validation-7950", "mrqa_naturalquestions-validation-1439", "mrqa_naturalquestions-validation-1135", "mrqa_naturalquestions-validation-1375", "mrqa_naturalquestions-validation-9371", "mrqa_naturalquestions-validation-8909", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-3390", "mrqa_naturalquestions-validation-297", "mrqa_naturalquestions-validation-6050", "mrqa_naturalquestions-validation-9181", "mrqa_naturalquestions-validation-2326", "mrqa_naturalquestions-validation-7826", "mrqa_naturalquestions-validation-9085", "mrqa_naturalquestions-validation-4885", "mrqa_naturalquestions-validation-9026", "mrqa_naturalquestions-validation-4990", "mrqa_naturalquestions-validation-9058", "mrqa_triviaqa-validation-4907", "mrqa_triviaqa-validation-2476", "mrqa_hotpotqa-validation-3716", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-3279", "mrqa_searchqa-validation-1451", "mrqa_newsqa-validation-1282"], "SR": 0.515625, "CSR": 0.5315061475409837, "EFR": 0.8709677419354839, "Overall": 0.6863541528952936}, {"timecode": 61, "before_eval_results": {"predictions": ["March 21, 2016", "to form a higher alkane", "shared", "Jason Marsden", "New Mexico", "In 1889", "in Poems : Series 1, a collection of Dickinson's poems assembled and edited by her friends Mabel Loomis Todd and Thomas Wentworth Higginson", "William the Conqueror", "March 2, 2016", "2018", "five", "September 1972", "James Rodr\u00edguez", "Oceania", "The Vamps", "Mickey Rourke", "Hemingway", "1980s", "David Gahan", "Emma Watson", "Acts passed by the Congress of the United States and its predecessor, the Continental Congress", "2018", "from 6 -- 14 July", "2010", "no more than 4.25 inches ( 108 mm )", "Judi Dench", "November 27, 2017", "159", "Chris Rea", "between $10,000 and $30,000", "Kelly Reno", "Ozzie Smith", "8 December 1985", "1836", "Thomas Jefferson", "Elijah Wood", "cat in the hat", "Brad Dourif", "counter clockwise", "Joanne Wheatley", "vice president", "a combination of the rise of literacy, technological advances in printing, and improved economics of distribution", "Donna Mills", "1994 season", "Matt Flinders", "parthenogenic", "the major contributor and the associated free software philosophy", "efferent nerves that directly innervate", "1773", "The First Battle of Bull Run ( the name used by Union forces )", "Don Cook", "kautta", "(modern p\u00f4le antarctique)", "The Pilgrim's Progress", "Bourbon County", "Argentina", "Bohemia", "Sen. Barack Obama", "Sri Lanka's Tamil rebels", "Osama bin Laden's", "(Jack) London", "( Arthur) Clarke", "the Koran", "whooping cough"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6764793281653747}, "metric_results_detailed": {"EM": [false, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, false, false, true, true, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, false, true, true, false, false, true, false, false, false, false, false, true, true, false, true, true, false, true, false, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9302325581395349, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.8571428571428571, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.32, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 0.8, 1.0, 1.0, 0.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.8, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7262", "mrqa_naturalquestions-validation-4951", "mrqa_naturalquestions-validation-10461", "mrqa_naturalquestions-validation-8961", "mrqa_naturalquestions-validation-5406", "mrqa_naturalquestions-validation-9802", "mrqa_naturalquestions-validation-7819", "mrqa_naturalquestions-validation-2618", "mrqa_naturalquestions-validation-5457", "mrqa_naturalquestions-validation-1856", "mrqa_naturalquestions-validation-7513", "mrqa_naturalquestions-validation-4768", "mrqa_naturalquestions-validation-7855", "mrqa_naturalquestions-validation-8452", "mrqa_naturalquestions-validation-5631", "mrqa_naturalquestions-validation-9772", "mrqa_naturalquestions-validation-9141", "mrqa_naturalquestions-validation-4444", "mrqa_naturalquestions-validation-2571", "mrqa_naturalquestions-validation-3340", "mrqa_naturalquestions-validation-2842", "mrqa_triviaqa-validation-3715", "mrqa_triviaqa-validation-2992", "mrqa_triviaqa-validation-1069", "mrqa_hotpotqa-validation-5483", "mrqa_newsqa-validation-648", "mrqa_searchqa-validation-7166", "mrqa_triviaqa-validation-4519"], "SR": 0.5625, "CSR": 0.5320060483870968, "EFR": 0.9285714285714286, "Overall": 0.697974870391705}, {"timecode": 62, "before_eval_results": {"predictions": ["the television series, The Lone Ranger for one season from 1952 until 1953", "beneath the liver", "Rudy Clark", "Abbot Suger", "Yuzuru Hanyu", "Tim Russert", "Europe", "toys or doorbell installations", "a microfilament", "in positions 14 - 15, 146 - 147 and 148 - 149", "the northernmost point on the Earth", "the second `` A '', Red Coat", "Eduardo", "M\u00e1ximo Gomez and Antonio Maceo", "1971", "Leo Arnaud", "Emmanuelle Chriqui", "Carlos Alan Autry Jr.", "16 March 2018", "the Dolby Theatre in Hollywood, Los Angeles, California", "Merry Clayton ( born December 25, 1948 )", "a bronze statue designed by Thomas Crawford ( 1814 -- 1857 ) that, since 1863, has crowned the dome of the U.S. Capitol building in Washington, D.C.", "judges", "1912", "George Harrison", "Djokovic", "James Hutton", "late 1922", "2017", "a scythe", "to connect the CNS to the limbs and organs", "Leonard Bernstein", "Toronto and locations in Canada and the United States using Canadian - built Bombardier Dash - 8 Q 400 turboprop aircraft", "listing the telephone numbers of individuals and families who have requested that telemarketers not contact them", "September 2017", "October 2012", "Kaley Christine Cuoco ( / \u02c8ke\u026ali \u02c8kwo\u028ako\u028a / KAY - lee KWOH - koh", "2013", "English singer - songwriter Dido", "Isekai wa Sum\u0101tofon to Tomo ni", "the final scene of the fourth season", "Phillip Paley", "2010", "Jakkur, Bangalore, India", "New Orleans going north through Chicago and to New York", "the Americas", "10.5 %", "ecological regions", "White House Executive Chef", "the International Border ( IB )", "lead vocalist Bart Millard", "a large noctuid moth, Mormo maura", "Rolihlahla Mandela", "Midnight Cowboy", "Austrian", "heavy metal", "Long Island", "Muslims as Americans.", "Tuesday from eyewitnesses who were aboard several boats stormed by Israeli forces as they approached Gaza the day before.", "The Ministry of Defense said the maneuver was part of a planned training exercise designed to help the prince learn to fly in combat situations.", "Elizabeth I (queen of England) Sir", "French colonial power", "Chief Oshkosh Monument", "River Welland"], "metric_results": {"EM": 0.5, "QA-F1": 0.6227563541870229}, "metric_results_detailed": {"EM": [false, true, false, true, true, true, false, false, false, false, false, false, false, false, true, true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, false, true, false, true, true, true, false, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, false, true, true, false, false, false, false, false, false, false, false, false], "QA-F1": [0.5333333333333333, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.9411764705882353, 0.0, 0.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.16666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5185185185185185, 1.0, 0.07692307692307691, 1.0, 1.0, 1.0, 0.5, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.08695652173913045, 0.8947368421052632, 0.5, 0.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4954", "mrqa_naturalquestions-validation-6573", "mrqa_naturalquestions-validation-4416", "mrqa_naturalquestions-validation-2648", "mrqa_naturalquestions-validation-9609", "mrqa_naturalquestions-validation-7225", "mrqa_naturalquestions-validation-2721", "mrqa_naturalquestions-validation-2900", "mrqa_naturalquestions-validation-4759", "mrqa_naturalquestions-validation-2381", "mrqa_naturalquestions-validation-9658", "mrqa_naturalquestions-validation-4619", "mrqa_naturalquestions-validation-6087", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-7298", "mrqa_naturalquestions-validation-8628", "mrqa_naturalquestions-validation-8734", "mrqa_naturalquestions-validation-8182", "mrqa_naturalquestions-validation-7639", "mrqa_naturalquestions-validation-8560", "mrqa_naturalquestions-validation-10077", "mrqa_triviaqa-validation-7273", "mrqa_triviaqa-validation-5245", "mrqa_hotpotqa-validation-529", "mrqa_hotpotqa-validation-5848", "mrqa_newsqa-validation-1307", "mrqa_newsqa-validation-1292", "mrqa_newsqa-validation-1285", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-9194", "mrqa_searchqa-validation-9115", "mrqa_hotpotqa-validation-1201"], "SR": 0.5, "CSR": 0.5314980158730158, "EFR": 1.0, "Overall": 0.7121589781746032}, {"timecode": 63, "before_eval_results": {"predictions": ["Meri", "2018", "the closing of the atrioventricular valves and semilunar valves, respectively", "The Hustons", "sacroiliac joint", "Monitoring of effects of plans / policies", "Cuernavaca, Durango", "development of electronic computers", "Employers", "Balaam ( Numbers 22 : 28 )", "Bhupendranath Dutt", "George III's German - born wife, Charlotte of Mecklenburg - Strelitz", "April 13, 2018", "on a bread plate, sometimes in the napkin ), napkin, and flatware ( knives and spoons to the right of the central plate, and forks to the left )", "Andrew McCarthy as Blane McDonough", "Jakkur, Bangalore, India", "in a thousand years", "2001", "the European economy had collapsed", "brothers Henry, Jojo and Ringo Garza", "Ben Findon", "incudomalleolar joint", "Terry Reid", "Sweden had been an active supporter of the League of Nations and most of Sweden's political energy in the international arena had been directed towards the preservation of the", "from a 1969 plan for a system of reusable spacecraft of which it was the only item funded for development", "supported modern programming practices and enabled business applications to be developed with Flash", "Forbes Burnham", "Saturday", "Isekai wa Sum\u0101tofon", "the tsar's Moscow residence", "the court from its members", "Alicia Vikander as Lara Croft", "over 300,000", "April 21, 2015", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "115", "eight", "Lori Rom", "in a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "Arlen `` The Chief '' Bitterbuck", "Cameron Fraser", "Austin and Pflugerville", "three times", "Exodus 20 : 7", "four", "25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "Utah, Arizona, Wyoming, and Oroville, California", "Jack Barry", "Hugo Weaving", "from the heraldic crest carved in the lintel on St. Ignatius'family home in Azpeitia, Spain", "Lana Del Rey", "The Matterhorn", "calypso", "jiles Perry Richardson", "The Pentagon", "Pisgah National Forest", "Johnnie Ray", "Robert Mugabe", "Capitol Hill,", "provided Syria and Iraq 500 cubic meters of water a second,", "impressionism", "Pussycat Dolls Present", "tuberculosis", "May 4"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5738144694217209}, "metric_results_detailed": {"EM": [true, false, true, true, true, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, false, false, false, false, true, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, true, true, false, false, true, true, false, true, true, true, false, true, false, false, true, true, true, true, false, true, true], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 0.0, 0.8571428571428571, 1.0, 0.6153846153846153, 0.3333333333333333, 0.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 0.0, 1.0, 0.33333333333333337, 0.0, 0.06896551724137931, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 0.4, 1.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 1.0, 0.9411764705882353, 0.0, 0.0, 0.5, 0.0, 1.0, 1.0, 0.9523809523809523, 0.5, 1.0, 1.0, 0.11764705882352941, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7614", "mrqa_naturalquestions-validation-8460", "mrqa_naturalquestions-validation-1165", "mrqa_naturalquestions-validation-8063", "mrqa_naturalquestions-validation-230", "mrqa_naturalquestions-validation-5515", "mrqa_naturalquestions-validation-177", "mrqa_naturalquestions-validation-2023", "mrqa_naturalquestions-validation-7844", "mrqa_naturalquestions-validation-1834", "mrqa_naturalquestions-validation-1325", "mrqa_naturalquestions-validation-4860", "mrqa_naturalquestions-validation-4240", "mrqa_naturalquestions-validation-1731", "mrqa_naturalquestions-validation-522", "mrqa_naturalquestions-validation-7356", "mrqa_naturalquestions-validation-10252", "mrqa_naturalquestions-validation-3386", "mrqa_naturalquestions-validation-4905", "mrqa_naturalquestions-validation-9931", "mrqa_naturalquestions-validation-462", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-8203", "mrqa_naturalquestions-validation-225", "mrqa_naturalquestions-validation-3609", "mrqa_naturalquestions-validation-2806", "mrqa_naturalquestions-validation-2847", "mrqa_naturalquestions-validation-3995", "mrqa_naturalquestions-validation-6991", "mrqa_naturalquestions-validation-1767", "mrqa_naturalquestions-validation-8484", "mrqa_naturalquestions-validation-3801", "mrqa_triviaqa-validation-2582", "mrqa_hotpotqa-validation-3339", "mrqa_hotpotqa-validation-4240", "mrqa_searchqa-validation-8333"], "SR": 0.4375, "CSR": 0.530029296875, "EFR": 0.9166666666666666, "Overall": 0.6951985677083333}, {"timecode": 64, "before_eval_results": {"predictions": ["Agra", "2018\u201319 UEFA Europa League", "FIFA Women's World Cup", "Dan Brandon Bilzerian", "Len Wiseman", "Viglen Ltd", "1896", "Randall Boggs", "Detroit, Michigan", "Roots: The Saga of an American Family", "St. Louis Cardinals", "Pittsburgh", "local South Australian and Australian produced content", "Hindi", "Ronald Wilson Reagan", "Los Angeles", "Ben Johnston", "Nia Temple Sanchez", "Vanessa Anne Hudgens", "top division of Mexican football, Liga MX", "A Amber Laura Heard", "Peter O'Toole", "March 8, 1942", "The song features a synthesizer-heavy arrangement", "January 30, 1930", "Doctor", "The Government of Ireland", "James Weldon Johnson", "Wilmington, North Carolina, United States", "1979", "Taylor Swift", "the first and second segment", "Kew Gardens", "7 January 1936", "Towards the Sun", "\"The Braes of Balquhither\"", "Westminster system", "I. helicon", "For Love Alone", "January 19, 1943", "King of France", "J. Robert Oppenheimer", "Transporter 3", "March 14, 2000", "Gauteng province", "Vietnam War", "William Theodore Walton III", "Darling River", "The Boz", "140 million", "American", "Teri Garr", "the employer", "the 1965 -- 66 season", "Wyoming", "The Krankies", "Apeirophosmphobia", "immediate release", "black, red or white,", "trying to prevent attempted defections as the country goes through a tumultuous transition,", "the '90s", "Ellicott City", "sprint", "Southport, North Carolina"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6489087301587302}, "metric_results_detailed": {"EM": [true, true, false, false, true, false, true, true, true, true, true, true, false, true, false, true, true, false, false, false, false, true, false, false, true, true, false, true, false, true, true, false, true, true, true, false, true, true, true, false, false, false, true, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.8, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 0.0, 1.0, 1.0, 0.8, 0.0, 0.4444444444444445, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.0, 1.0, 0.7499999999999999, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.28571428571428575, 0.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-257", "mrqa_hotpotqa-validation-3931", "mrqa_hotpotqa-validation-5143", "mrqa_hotpotqa-validation-4357", "mrqa_hotpotqa-validation-5573", "mrqa_hotpotqa-validation-4217", "mrqa_hotpotqa-validation-3311", "mrqa_hotpotqa-validation-5596", "mrqa_hotpotqa-validation-652", "mrqa_hotpotqa-validation-1413", "mrqa_hotpotqa-validation-4781", "mrqa_hotpotqa-validation-3741", "mrqa_hotpotqa-validation-3342", "mrqa_hotpotqa-validation-1602", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-5837", "mrqa_hotpotqa-validation-245", "mrqa_hotpotqa-validation-2957", "mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-3275", "mrqa_hotpotqa-validation-4810", "mrqa_hotpotqa-validation-5565", "mrqa_naturalquestions-validation-8444", "mrqa_triviaqa-validation-1171", "mrqa_newsqa-validation-1564", "mrqa_newsqa-validation-23", "mrqa_newsqa-validation-2777", "mrqa_searchqa-validation-12166", "mrqa_searchqa-validation-9071"], "SR": 0.546875, "CSR": 0.5302884615384615, "EFR": 1.0, "Overall": 0.7119170673076922}, {"timecode": 65, "before_eval_results": {"predictions": ["Tsung-Dao Lee", "sitcom", "Albert", "September 30, 2017", "237,520", "the New York Giants", "skiing and mountaineering", "Eliot Cutler", "The MGM Grand fire", "Odense Boldklub", "William of Blois", "Jared Leto", "Gweilo", "Howard University College of Medicine", "PrinceAimone", "1942", "The Wu-Tang Clan", "For Love Alone", "song recorded by the American rapper Eminem,", "rock music", "G\u00e9rard Depardieu", "from the Nazi German occupation of France and against the collaborationist Vichy r\u00e9gime during the Second World War", "Las Vegas", "Appleby-in-Westmorland", "from 1345 to 1377", "Indiana University", "James Bond", "Syracuse University", "Kings Point, New York", "Robbie Gould", "the CBS soap opera \"The Young and the Restless\"", "Hempstead", "Port Clinton", "1942", "Wayne Conley", "the Australian coast", "Hurricane Faith", "turns out to be a terrible date and Marge realizes that it is Homer she really wants.", "the Celtics", "Supernatural", "CHO", "eight", "from 1848 to 1852", "Sippin' on Some Syrup", "Jim Harrison", "Sir Patrick Barnewall", "Arabella Churchill", "Lester", "two Grammy awards", "The S7 series", "2017", "Qutab Ud - Din - Aibak", "September 2000", "Thomas Jefferson", "Luxembourg", "Golda Meir", "the Muffin Man", "President George Bush", "250,000", "former boxing champion Vernon Forrest,", "Yonkers", "blown", "folkloric", "Dan Aykroyd"], "metric_results": {"EM": 0.5, "QA-F1": 0.5848262810559006}, "metric_results_detailed": {"EM": [true, false, false, true, false, true, true, true, false, true, false, false, true, false, false, false, true, true, false, false, true, false, true, true, true, true, true, true, true, false, false, false, true, false, true, true, true, false, false, false, true, true, false, false, false, false, false, true, true, true, true, true, false, false, true, true, true, false, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.28571428571428575, 0.0, 0.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5217391304347825, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.5, 0.4, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 0.5714285714285715, 0.0, 1.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4493", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-3606", "mrqa_hotpotqa-validation-886", "mrqa_hotpotqa-validation-5663", "mrqa_hotpotqa-validation-5542", "mrqa_hotpotqa-validation-851", "mrqa_hotpotqa-validation-1577", "mrqa_hotpotqa-validation-2799", "mrqa_hotpotqa-validation-3401", "mrqa_hotpotqa-validation-3260", "mrqa_hotpotqa-validation-5499", "mrqa_hotpotqa-validation-1629", "mrqa_hotpotqa-validation-1435", "mrqa_hotpotqa-validation-1557", "mrqa_hotpotqa-validation-3052", "mrqa_hotpotqa-validation-4086", "mrqa_hotpotqa-validation-5825", "mrqa_hotpotqa-validation-3246", "mrqa_hotpotqa-validation-5487", "mrqa_hotpotqa-validation-3638", "mrqa_hotpotqa-validation-1614", "mrqa_hotpotqa-validation-1542", "mrqa_hotpotqa-validation-3219", "mrqa_naturalquestions-validation-8759", "mrqa_naturalquestions-validation-10202", "mrqa_newsqa-validation-2677", "mrqa_newsqa-validation-368", "mrqa_newsqa-validation-30", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-3848", "mrqa_naturalquestions-validation-1925"], "SR": 0.5, "CSR": 0.5298295454545454, "EFR": 1.0, "Overall": 0.7118252840909091}, {"timecode": 66, "before_eval_results": {"predictions": ["Captain Mark Phillips", "Hillsborough", "Paraguay", "126 mph", "Absalom", "Terry Hall", "December", "Anthony Joshua", "George IV", "Zsa Zsa Gabor", "ambidextrous", "Louis Daguerre", "Stephen Hawking", "pangea", "a living architect", "Guy the Gorilla", "a micrometer or one millionth of a meter", "Port Moresby", "green", "Oscar II", "pyrotechnic", "South Korea", "Annie Lennox", "a boar", "a superhero", "Typhon", "Syria", "Wyoming", "Professor Brian Cox", "Stephen King", "Albert Finney", "Scotland", "24", "George Washington James Buchanan", "Tuvalu", "Meta", "the 'Flower of Scotland'", "about a mile north of the village of Dunvegan", "a viola da gamba (literally 'viol of the legs)", "The Spice Girls", "Mr Loophole", "Istanbul", "a drinking song", "Texas", "Pablo Picasso", "reparations", "Rajasthan", "African violets", "bali", "Glee", "British general", "Ratonhnhak\u00e9 : ton and Haytham Kenway", "Djokovic", "1912", "Fennec fox", "1927", "Ladislav Mat\u011bjka", "Vernon Forrest,", "Linda Hogan", "development of two courses on the Black Sea coast in Bulgaria.", "N.C. Wyeth", "viruses", "Steve Wynn", "a substitute good"], "metric_results": {"EM": 0.578125, "QA-F1": 0.5994791666666667}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, true, true, true, false, true, false, true, false, false, false, false, true, false, false, true, false, true, false, false, true, true, true, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, true, true, true, true, true], "QA-F1": [0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.2, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1508", "mrqa_triviaqa-validation-1046", "mrqa_triviaqa-validation-2287", "mrqa_triviaqa-validation-4191", "mrqa_triviaqa-validation-4454", "mrqa_triviaqa-validation-6913", "mrqa_triviaqa-validation-1855", "mrqa_triviaqa-validation-6128", "mrqa_triviaqa-validation-6075", "mrqa_triviaqa-validation-3729", "mrqa_triviaqa-validation-104", "mrqa_triviaqa-validation-2064", "mrqa_triviaqa-validation-2412", "mrqa_triviaqa-validation-1689", "mrqa_triviaqa-validation-991", "mrqa_triviaqa-validation-3326", "mrqa_triviaqa-validation-3266", "mrqa_triviaqa-validation-4405", "mrqa_triviaqa-validation-6457", "mrqa_triviaqa-validation-6990", "mrqa_triviaqa-validation-4970", "mrqa_triviaqa-validation-2516", "mrqa_triviaqa-validation-3610", "mrqa_triviaqa-validation-3214", "mrqa_naturalquestions-validation-3922", "mrqa_hotpotqa-validation-5590", "mrqa_newsqa-validation-2391"], "SR": 0.578125, "CSR": 0.5305503731343284, "EFR": 1.0, "Overall": 0.7119694496268657}, {"timecode": 67, "before_eval_results": {"predictions": ["$249", "cambodia", "o'Gara", "tranquil beaches,", "took on water", "werder bremen", "Secretary of State", "Iran's", "nearly three out of four", "Fernando Caceres", "six Africans dead.", "no evidence", "best-of-three series.", "the 11th century Preah Vihear temple", "Bahrain", "voluntary manslaughter", "Jenny Sanford", "timothy", "Miami Beach, Florida,", "\"Percy Jackson & The Olympians,\"", "cell phones", "two contestants.", "Jenny MacKeown", "Roland S. Martin", "Graeme Smith", "former U.S. secretary of state", "tried to fake his own death by crashing his private plane into a Florida swamp.", "54-year-old judge,", "\"Nothing But Love\" comeback tour,", "helicopters and boats, as well as vessels from other agencies,", "terrorize is a crime,", "two tickets to Italy on Expedia.", "Oxbow,", "the FAA received no reports from pilots in the air of any sightings but the agency recieved \"n numerous\" calls from people on the ground from Dallas, Texas, south to Austin, Texas.", "21-year-old", "Jacob Zuma", "toffelmakaren", "former Procol Harum bandmate Gary Brooker", "response to a civil disturbance call, but no criminal charges were filed,", "Pew Research Center", "must take immunosuppression drugs for life so that the body does not reject the donated tissue,", "Kenyan and Somali", "30,000", "1983", "\"Let me here tell you something about myself and my biography, in which there is a benefit and a lesson,\"", "North Korea", "Jobs", "Garth Brooks", "40-year-old", "Facebook and Google,", "1983", "Carolyn Sue Jones", "American country music group The Nitty Gritty Dirt Band", "a central place in Christian eschatology", "Phil Mickelson", "dumbo", "skiffle quartet", "1969", "\"$10,000 Kelly,\"", "Estadio de L\u00f3pez Cort\u00e1zar", "yishai", "Perkins", "director", "men use violence within relationships to exercise power and control"], "metric_results": {"EM": 0.53125, "QA-F1": 0.604418614498645}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, false, false, true, false, true, false, false, false, true, true, false, true, false, false, true, false, false, false, true, false, false, false, true, false, false, true, false, true, true, false, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.22222222222222224, 1.0, 0.5714285714285715, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.3333333333333333, 0.8, 1.0, 0.24390243902439027, 1.0, 1.0, 0.0, 1.0, 0.42857142857142855, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.25, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_newsqa-validation-308", "mrqa_newsqa-validation-1224", "mrqa_newsqa-validation-3131", "mrqa_newsqa-validation-47", "mrqa_newsqa-validation-1305", "mrqa_newsqa-validation-2636", "mrqa_newsqa-validation-2463", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3232", "mrqa_newsqa-validation-1855", "mrqa_newsqa-validation-3649", "mrqa_newsqa-validation-694", "mrqa_newsqa-validation-2986", "mrqa_newsqa-validation-2271", "mrqa_newsqa-validation-4086", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2568", "mrqa_newsqa-validation-2005", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-824", "mrqa_newsqa-validation-3999", "mrqa_newsqa-validation-1919", "mrqa_newsqa-validation-1711", "mrqa_newsqa-validation-1093", "mrqa_naturalquestions-validation-34", "mrqa_naturalquestions-validation-833", "mrqa_triviaqa-validation-6636", "mrqa_searchqa-validation-5451", "mrqa_searchqa-validation-2492", "mrqa_naturalquestions-validation-9387"], "SR": 0.53125, "CSR": 0.5305606617647058, "EFR": 1.0, "Overall": 0.7119715073529411}, {"timecode": 68, "before_eval_results": {"predictions": ["BADBUL", "as soon as 2050,", "Molotov cocktails, rocks and glass.", "after Michael Jackson's death in the Holmby Hills, California, mansion he rented.", "German Chancellor Angela Merkel", "The son of Gabon's former president", "to put a lid on the marking of Ashura", "their homes in Bhola", "off Somalia's coast.", "in time as another American icon's wheels come off.", "AS Roma beat Lecce 3-2", "President Barack Obama,", "Southern Baptist Convention,", "in body bags on the roadway near the bus,", "Tuesday in Los Angeles.", "an American who entered the country illegally", "2000.", "at least 300", "Thursday,", "always hot and humid", "Israeli", "The drama of the action in-and-around the golf course", "2008.", "act against those who used Pakistani soil to perpetrate attacks.", "25", "a key find by paleontologists at Los Angeles' George C. Page Museum.", "Ciudad Juarez, across the border from El Paso, Texas.", "105-year", "Michael Schumacher", "Jobs", "Jenny Sanford", "remote part of northwestern Montana", "a 100-day killing rampage.", "stealing the personal credit information of thousands of unsuspecting American and European consumers,", "Bailey, Colorado,", "U.S. Justice Department", "Unseeded Frenchwoman Aravane Rezai", "noose incident occurred two weeks after Black History Month", "How I Met Your Mother", "British", "six", "he was released Friday and taken to the Australian embassy in Bangkok, where he stayed until leaving for Australia at about midnight.", "a bank", "the kind of bipartisan rhetoric Obama has espoused on the campaign trail.", "Barnes & Noble", "14", "Michael Arrington,", "well over 1,000 pounds", "stand down.", "his past and his future", "Mombasa, Kenya,", "a loanword of the Visigothic word guma `` man ''", "Taron Egerton", "Italy", "hard Times", "purpurea", "Nellie Melba", "Clark Gable", "1979", "the backside", "Sweden", "garcinia cambogia", "Pablo Picasso", "improved the speed of encryption of communications at both ends in front line operations during World War II"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6117478155709539}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, true, false, false, false, true, true, false, false, true, true, true, false, true, true, true, false, true, false, false, false, true, true, true, true, false, false, false, false, false, false, true, false, true, false, true, true, true, true, false, true, true, true, false, false, true, true, true, false, true, false, false, true, false, false, false, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.923076923076923, 0.4, 1.0, 0.3636363636363636, 0.33333333333333337, 0.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.21276595744680848, 0.0, 0.0, 0.0, 0.5, 1.0, 0.0, 1.0, 0.6, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.2857142857142857, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-3611", "mrqa_newsqa-validation-3923", "mrqa_newsqa-validation-1058", "mrqa_newsqa-validation-241", "mrqa_newsqa-validation-2415", "mrqa_newsqa-validation-2513", "mrqa_newsqa-validation-259", "mrqa_newsqa-validation-1280", "mrqa_newsqa-validation-3235", "mrqa_newsqa-validation-2781", "mrqa_newsqa-validation-1168", "mrqa_newsqa-validation-1519", "mrqa_newsqa-validation-2170", "mrqa_newsqa-validation-2453", "mrqa_newsqa-validation-3660", "mrqa_newsqa-validation-3200", "mrqa_newsqa-validation-1997", "mrqa_newsqa-validation-2118", "mrqa_newsqa-validation-3287", "mrqa_newsqa-validation-394", "mrqa_newsqa-validation-3889", "mrqa_newsqa-validation-703", "mrqa_newsqa-validation-3306", "mrqa_newsqa-validation-2426", "mrqa_naturalquestions-validation-3019", "mrqa_triviaqa-validation-4494", "mrqa_hotpotqa-validation-2994", "mrqa_hotpotqa-validation-5465", "mrqa_searchqa-validation-9014", "mrqa_searchqa-validation-7337", "mrqa_searchqa-validation-10753"], "SR": 0.515625, "CSR": 0.5303442028985508, "EFR": 0.967741935483871, "Overall": 0.7054766026764844}, {"timecode": 69, "before_eval_results": {"predictions": ["cavities and surfaces of blood vessels and organs throughout the body", "Tim Russert", "on the microscope's stage", "P.V. Sindhu", "Nick Kroll", "April 1917", "Australia's Sir Donald Bradman", "two - stroke engines and chain drive", "revenge", "Kevin Sumlin", "Paradise", "Detective Eddie Thawne", "Hathi Jr", "a liquid crystal on silicon ( LCoS )", "Spektor", "The Star Spangled Banner", "Bill Russell", "Luke Luke 18 : 1 - 8", "July 2010", "a protocol ( http ), a hostname ( www.example.com ), and a file name ( index.HTML )", "343 m / s in air", "1997", "Carol Worthington", "September 6, 2019", "1972", "1853", "uprooted", "at angles less than vertical", "Battle of Antietam", "at an intersection with U.S. Route 340 ( US 340 ) near Front Royal", "Clarence Anglin", "Andrew Garfield", "normal conditions", "the 1980s", "Pasek & Paul", "a 1920 play R.U.R. by the Czech writer, Karel \u010capek", "a series of prospective studies that examine epidemiology and the long - term effects of nutrition, hormones, environment, and nurses'work - life on health and disease development", "2013", "Billie `` The Blue Bear ''", "eusebeia", "Daniel Suarez", "White House Executive Chef", "place of trade", "25 years", "the bank's own funds", "One Night in the Tropics", "Waylon Jennings", "libretto", "the Rolling Stones", "Sun Tzu", "Pre-evaluation, strategic planning, operative planning, implementation, and post-evaluated", "eucalyptus", "inflation", "\"Taffy\" Salaman", "John M. Dowd", "December 17, 1974", "the Northrop P-15 Reporter", "26", "The woman", "2050,", "West Point", "Paul Bunyan", "thyroid", "1965"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6557716528640443}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, false, false, false, false, false, true, false, true, false, false, false, false, false, false, false, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, true, true, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, true, true, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 1.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.8571428571428571, 0.0, 0.5, 0.0, 0.5, 0.3333333333333333, 1.0, 0.4347826086956522, 1.0, 0.0, 0.5714285714285715, 0.888888888888889, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.16, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 0.28571428571428575, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-182", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-9821", "mrqa_naturalquestions-validation-4466", "mrqa_naturalquestions-validation-81", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-754", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-10225", "mrqa_naturalquestions-validation-4592", "mrqa_naturalquestions-validation-2768", "mrqa_naturalquestions-validation-8229", "mrqa_naturalquestions-validation-6058", "mrqa_naturalquestions-validation-6254", "mrqa_naturalquestions-validation-4345", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-6856", "mrqa_naturalquestions-validation-6897", "mrqa_naturalquestions-validation-458", "mrqa_naturalquestions-validation-4881", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-221", "mrqa_naturalquestions-validation-8500", "mrqa_naturalquestions-validation-3303", "mrqa_naturalquestions-validation-8374", "mrqa_triviaqa-validation-6937", "mrqa_hotpotqa-validation-993", "mrqa_newsqa-validation-1639"], "SR": 0.546875, "CSR": 0.5305803571428571, "EFR": 0.9310344827586207, "Overall": 0.6981823429802956}, {"timecode": 70, "before_eval_results": {"predictions": ["the President", "Walter Pauk", "Madison's", "Brevet Colonel Robert E. Lee", "a specific task", "January 2, 1971", "minced meat", "White Sox", "a mascot", "until 1792", "Longliners", "Sebastian Vettel", "Reginald Jeeves", "China", "2017", "Upstate New York", "Carol Ann Susi", "a stem", "Nala", "the Canadian rock band Nickelback", "P.V. Sindhu", "Anglican", "the closing of the atrioventricular valves and semilunar valves, respectively", "the investment bank Friedman Billings Ramsey", "the NFL", "14 \u00b0 41 \u2032 34 '' N 17 \u00b0 26 \u2032 48 '' W \ufeff / 14.69278 ; - 17.44667", "1 January 1904", "a password recovery tool for Microsoft Windows", "35 to 40 hours per week", "by week 4 of development", "a worldwide storm", "somatic cell nuclear transfer ( SCNT )", "The UN General Assembly", "Benzodiazepines", "two", "David Ben - Gurion", "as far west as Las Vegas, as far north as Indianapolis and Denver, and as far east as Richmond, Virginia", "the 7th century", "in the North Cascades range of, Washington", "Ray Charles", "a jazz funeral without a body", "2004", "May 31, 2012", "Nick Stahl in Terminator 3 : Rise of the Machines ( 2003 )", "Malware", "an ex ( plural is exes ) is someone with whom a person was once associated, in a relationship, marriage, or once talked to", "Beorn", "South Dakota", "Ronald Reagan, who was 73 years, 274 days of age at the time of his election to a second term", "100,000", "1967", "Rajasthan", "Sodor", "eye", "44,300", "2008", "Frisian", "Long Island", "\"You saw the joy that the British had, that the Americans had, and saw them here through their representatives celebrating and acting as if we Zimbabwe are either an extension of Britain or... America.", "11", "bones", "ALICE", "Thailand", "500-room"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6607013499844382}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, true, true, false, false, false, true, false, true, true, true, true, false, true, true, true, true, true, false, true, false, false, false, true, true, false, false, true, true, true, true, false, false, false, true, false, false, true, false, true, false, true, false, false, false, true, true, true, true, true, true, false, true, false, true, true, false, false, true], "QA-F1": [1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 0.8571428571428571, 0.35294117647058826, 0.058823529411764705, 1.0, 1.0, 0.0, 0.888888888888889, 1.0, 1.0, 1.0, 1.0, 0.5185185185185185, 0.8, 0.6, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.08333333333333333, 1.0, 0.0, 0.19999999999999998, 0.07999999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.09523809523809522, 1.0, 1.0, 0.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-6307", "mrqa_naturalquestions-validation-9852", "mrqa_naturalquestions-validation-2577", "mrqa_naturalquestions-validation-2710", "mrqa_naturalquestions-validation-3564", "mrqa_naturalquestions-validation-3384", "mrqa_naturalquestions-validation-2462", "mrqa_naturalquestions-validation-2011", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-2168", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-2207", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-554", "mrqa_naturalquestions-validation-7785", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-9897", "mrqa_naturalquestions-validation-8737", "mrqa_naturalquestions-validation-7641", "mrqa_naturalquestions-validation-10707", "mrqa_naturalquestions-validation-7659", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-2146", "mrqa_hotpotqa-validation-2098", "mrqa_newsqa-validation-3943", "mrqa_searchqa-validation-6656", "mrqa_searchqa-validation-7551"], "SR": 0.578125, "CSR": 0.53125, "EFR": 0.9259259259259259, "Overall": 0.6972945601851852}, {"timecode": 71, "before_eval_results": {"predictions": ["Mae West", "Diana Vickers", "Tina Turner", "Woodrow Wilson", "Striding Edge", "stylist and assistant", "a clown, as he is called  in the cast of characters of \"As You Like  It,\"", "the Titanic", "Capua", "Hadrian", "Madagascar", "\"view of the Forest of Fontainebleau\"", "Michel Denance", "Manet", "Gary Scarlet", "Challenger", "Edinburgh City F.C.", "Lacock Abbey", "Richard Jordan", "Canada", "'Hansel and Gretel' cottage", "Honda", "Greenock", "ABBA", "sonja Henie", "eight", "Lord Snooty", "Greyfriars Bobby", "Rudolf Hess", "The University of Tasmania", "Stieg Larsson", "music Stories", "1957", "le Menech", "steel", "Rotherham United", "Priestley", "German greyhound, gazelle hound or tazi", "international team competition in sport,", "Periodic Table", "baka hunter-gatherers", "a region of SW Asia between the lower and middle reaches of the Tigris and Euphrates rivers", "Timothy Carroll", "Cuba", "indiget", "Patience", "Chubby Checker", "Tim Roth", "establish radio communication with each other by touching them together or bringing them into close proximity, usually no more than a few centimetres.", "Salvador Dal\u00ed", "par three 16th hole", "in San Francisco", "after 5 years", "Brooke Wexler as Irona", "The 2004 Nokia Sugar Bowl", "aging issues", "July", "one of Europe's most experienced providers of carbon offsets,", "businesses hiring veterans as well as job training for all service members leaving the military.", "a fine of $20 for the alcohol consumption, $80 for driving under the influence as well as receiving 40 lash for the incident which is said to have taken place in the capital Khartoum on August 21.", "the American Civil War", "How do we know when irrational exuberance has unduly escalated asset values,", "a peashooter", "UFC Fight Pass"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5620608660130718}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, false, true, true, false, false, true, false, true, false, true, false, true, false, true, true, true, true, false, true, true, true, false, true, false, true, false, true, true, false, false, false, true, false, false, false, false, false, true, true, false, false, true, false, false, false, false, true, true, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.13333333333333333, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 0.23529411764705882, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.4444444444444445, 0.058823529411764705, 0.8, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-3237", "mrqa_triviaqa-validation-6581", "mrqa_triviaqa-validation-6334", "mrqa_triviaqa-validation-4888", "mrqa_triviaqa-validation-1065", "mrqa_triviaqa-validation-5576", "mrqa_triviaqa-validation-4322", "mrqa_triviaqa-validation-5566", "mrqa_triviaqa-validation-5665", "mrqa_triviaqa-validation-4408", "mrqa_triviaqa-validation-2521", "mrqa_triviaqa-validation-4791", "mrqa_triviaqa-validation-4046", "mrqa_triviaqa-validation-4501", "mrqa_triviaqa-validation-7482", "mrqa_triviaqa-validation-3166", "mrqa_triviaqa-validation-4119", "mrqa_triviaqa-validation-452", "mrqa_triviaqa-validation-3584", "mrqa_triviaqa-validation-4282", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2277", "mrqa_triviaqa-validation-5816", "mrqa_naturalquestions-validation-10030", "mrqa_naturalquestions-validation-8965", "mrqa_naturalquestions-validation-8308", "mrqa_hotpotqa-validation-1233", "mrqa_newsqa-validation-2506", "mrqa_newsqa-validation-1548", "mrqa_newsqa-validation-1758", "mrqa_searchqa-validation-1880", "mrqa_searchqa-validation-11196"], "SR": 0.484375, "CSR": 0.5305989583333333, "EFR": 0.9696969696969697, "Overall": 0.7059185606060605}, {"timecode": 72, "before_eval_results": {"predictions": ["bobby Darin", "Thames", "Altamont Speedway", "sprockets", "26 miles", "tibia and fibula", "jellyfish", "Samson", "Connecticut", "Daedalus", "gary clifton", "augusta", "a goad", "Miles Morales", "14", "radar", "Queen Elizabeth II", "bbc", "hippocampus", "Frank Miller", "tennis", "gary Orwell", "Atlantic Ocean", "New Zealand History", "Chatsworth House", "spain", "Budapest", "eyes", "chainsaws", "augusta", "aug. 24", "taurine cattle", "Julius Caesar", "Venezuela", "Southwest Airlines", "spain", "bbc", "Derwent", "sesame", "Laos", "Allardyce", "General Henri-Philippe Petain,", "bbc", "Miami", "Bill Haley & His comets", "spain", "1768", "Joan Rivers", "bikila", "William Refrigerator", "Ghana", "as an extension to this procedure", "observing the magnetic stripe `` anomalies '' on the ocean floor", "1999", "Easy", "seven", "Karl Johan Schuster", "to the U.S. Holocaust Memorial Museum", "Robert Barnett,", "Diego Milito", "dont Wanna leave Ft. Dutchboy", "Dumbo the Flying elephant", "1580s North Carolina", "Python"], "metric_results": {"EM": 0.359375, "QA-F1": 0.48508279914529917}, "metric_results_detailed": {"EM": [true, true, false, false, false, false, false, true, true, true, false, false, true, false, true, true, true, false, false, true, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, false, true, true, false, false, false, true, false, false, true, true, false, false, true, false, false, true, false, false, false, false, false, false, false, false, false, true], "QA-F1": [1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 0.5, 0.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.923076923076923, 1.0, 0.0, 0.0, 0.0, 0.888888888888889, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 1.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-408", "mrqa_triviaqa-validation-4380", "mrqa_triviaqa-validation-4012", "mrqa_triviaqa-validation-6192", "mrqa_triviaqa-validation-6757", "mrqa_triviaqa-validation-5979", "mrqa_triviaqa-validation-4668", "mrqa_triviaqa-validation-6323", "mrqa_triviaqa-validation-2103", "mrqa_triviaqa-validation-2212", "mrqa_triviaqa-validation-7637", "mrqa_triviaqa-validation-2820", "mrqa_triviaqa-validation-4913", "mrqa_triviaqa-validation-7597", "mrqa_triviaqa-validation-4492", "mrqa_triviaqa-validation-2972", "mrqa_triviaqa-validation-4199", "mrqa_triviaqa-validation-4019", "mrqa_triviaqa-validation-2423", "mrqa_triviaqa-validation-7364", "mrqa_triviaqa-validation-32", "mrqa_triviaqa-validation-7682", "mrqa_triviaqa-validation-2011", "mrqa_triviaqa-validation-5974", "mrqa_triviaqa-validation-1703", "mrqa_triviaqa-validation-4173", "mrqa_triviaqa-validation-5380", "mrqa_triviaqa-validation-2048", "mrqa_triviaqa-validation-3916", "mrqa_triviaqa-validation-7344", "mrqa_naturalquestions-validation-9063", "mrqa_naturalquestions-validation-8205", "mrqa_hotpotqa-validation-3333", "mrqa_hotpotqa-validation-1534", "mrqa_hotpotqa-validation-2017", "mrqa_newsqa-validation-2420", "mrqa_newsqa-validation-2030", "mrqa_newsqa-validation-2755", "mrqa_searchqa-validation-2901", "mrqa_searchqa-validation-7110", "mrqa_searchqa-validation-4706"], "SR": 0.359375, "CSR": 0.5282534246575342, "EFR": 0.9512195121951219, "Overall": 0.7017539623705312}, {"timecode": 73, "before_eval_results": {"predictions": ["Scottish national team", "Speedway World Championship", "Mercer University", "\"Time\"", "Babylon", "1501", "The Shins", "11,791", "Eliot Cutler", "Manchester", "Hellenism", "The Ansonia Hotel", "Washington", "Helen Mirren", "racehorse breeder", "schutzstaffel", "Edward Albert Heimberger", "The Bye Bye Man", "Chevron Corporation", "\"Wragby Road\"", "Indianapolis", "paintings", "Premier League", "Sleepy Hollow", "Jane Mayer", "Obafemi Martins", "Austin E. Knowlton School of Architecture", "143,007", "Philadelphia", "9th, 10th, 11th & 12th Chinese People's Political Consultative Conference", "American television personality and film actress best known as the hostess of \"Wheel of Fortune\"", "2 July 1903", "molecular oxygen", "King Duncan", "St Andrews Agreement", "Royal College of Music", "4145 ft", "Japan Airlines Flight 123", "Lake County, Illinois", "Netflix", "2013", "The American relay of Michael Phelps, Ryan Lochte, Peter Vanderkaay, and Keller", "suburb of Adelaide in the City of Port Adelaide Enfield", "schoolteacher", "People v. Turner", "William Harold \"Bill\" Ponsford", "Aamina Sheikh", "one", "Mortal Kombat", "Mike Holmgren", "gauteng province", "Herman Hollerith", "6 -- 14 July", "parashiyot ( plural ) or parshahs ( anglicized pluralization )", "paramitas", "1881", "photography", "\"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags and jewelry with forged credit cards,\"", "Steve Jobs", "hippies, 20-somethings and celebrities like actor Richard Gere.", "blintze", "Texas Chainsaw Massacre", "Joe DiMaggio", "Caster Semenya"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6767735972584319}, "metric_results_detailed": {"EM": [false, false, false, true, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, false, true, true, true, true, false, true, true, false, false, false, false, true, true, true, true, false, true, false, true, false, false, false, true, false, false, true, true, true, true, true, true, false, false, true, false, false, false, false, false, true, true, true], "QA-F1": [0.0, 0.3333333333333333, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 0.0, 0.35294117647058826, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0625, 1.0, 0.0, 1.0, 0.3076923076923077, 0.19999999999999998, 0.4, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8918918918918919, 0.0, 0.18181818181818182, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-5428", "mrqa_hotpotqa-validation-1851", "mrqa_hotpotqa-validation-1285", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-1492", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-680", "mrqa_hotpotqa-validation-2716", "mrqa_hotpotqa-validation-4463", "mrqa_hotpotqa-validation-5036", "mrqa_hotpotqa-validation-5397", "mrqa_hotpotqa-validation-5373", "mrqa_hotpotqa-validation-2257", "mrqa_hotpotqa-validation-2474", "mrqa_hotpotqa-validation-3775", "mrqa_hotpotqa-validation-3785", "mrqa_hotpotqa-validation-508", "mrqa_hotpotqa-validation-5795", "mrqa_hotpotqa-validation-5010", "mrqa_naturalquestions-validation-3546", "mrqa_triviaqa-validation-1757", "mrqa_triviaqa-validation-3539", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-3692", "mrqa_searchqa-validation-13349"], "SR": 0.59375, "CSR": 0.5291385135135135, "EFR": 0.9615384615384616, "Overall": 0.703994770010395}, {"timecode": 74, "before_eval_results": {"predictions": ["Jesuits", "ribonucleic acid (RNA)", "ketchup", "an Inuit house", "a compound eyes of flies", "timbaland", "\"Dancing with the Stars\"", "Burma", "Latvia", "spleen", "Auf Wiedersehen", "rely", "Ramses", "wine", "The esophagus", "Super Bowl VI", "the Bible", "a twist", "Madame Tussaud", "Biscay", "Ziz", "March", "Ferdinand Magellan", "Kevin Spacey", "a brothel", "an equatorial bulge", "The Aviator", "Gioachino Rossini", "Veracruz", "a tail", "Nashville", "Hanging Gardens", "The Last Starfighter", "Billy Crystal", "a tan", "LaSalle", "Qubec", "antipope", "the TV series", "Dunedin", "Moonlighting", "Corpus Christi", "Mentor", "Ruth Bader Ginsburg", "Edward R. Murrow", "Port of Chittagong", "In vitro fertilisation", "Diogenes", "pastries", "Whatchamacallit", "the Electric Company", "On September 24, 2012, Hulu Plus signed a multi-year deal with WWE to stream all of the company's TV shows and some of its web series which includes Raw", "Roger Dean Stadium", "March 31, 2013", "'Lady Madonna'", "Celsius", "Jeremy Irons", "January", "Jennifer Grey", "Donald Wayne Johnson", "giving birth to baby daughter Jada, who was watching her mum from the stands again on Saturday.", "4,000", "Princess Diana", "Melbourne"], "metric_results": {"EM": 0.53125, "QA-F1": 0.6289855072463768}, "metric_results_detailed": {"EM": [true, true, true, false, false, true, false, true, false, true, true, true, false, false, true, false, true, true, true, false, false, true, false, true, false, false, false, false, false, true, false, false, false, true, true, false, false, false, false, false, true, true, true, false, true, false, false, true, false, true, true, false, true, true, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.3333333333333333, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5217391304347825, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6585", "mrqa_searchqa-validation-4940", "mrqa_searchqa-validation-10572", "mrqa_searchqa-validation-6347", "mrqa_searchqa-validation-1722", "mrqa_searchqa-validation-11920", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-1613", "mrqa_searchqa-validation-6459", "mrqa_searchqa-validation-2269", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-15633", "mrqa_searchqa-validation-4556", "mrqa_searchqa-validation-3466", "mrqa_searchqa-validation-13743", "mrqa_searchqa-validation-4143", "mrqa_searchqa-validation-3193", "mrqa_searchqa-validation-7581", "mrqa_searchqa-validation-661", "mrqa_searchqa-validation-5131", "mrqa_searchqa-validation-85", "mrqa_searchqa-validation-14509", "mrqa_searchqa-validation-5114", "mrqa_searchqa-validation-16566", "mrqa_searchqa-validation-9376", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-9557", "mrqa_naturalquestions-validation-5096", "mrqa_triviaqa-validation-6455", "mrqa_newsqa-validation-801"], "SR": 0.53125, "CSR": 0.5291666666666667, "EFR": 1.0, "Overall": 0.7116927083333333}, {"timecode": 75, "before_eval_results": {"predictions": ["18", "Randy VanWarmer", "October 2012", "Sylvester Stallone", "between 1765 and 1783", "The Miracles", "1900", "The nucleus provides a site for genetic transcription that is segregated from the location of translation in the cytoplasm, allowing levels of gene regulation that are not available to prokaryotes", "about 25 -- 30 \u00b0 C / km ( 28 -- 34 \u00b0 F / mi )", "the year AD 1600", "1963", "king Gautamiputra Satakarni", "Jos\u00e9 Mart\u00ed", "it violated their rights as Englishmen to `` No taxation without representation '', that is, to be taxed only by their own elected representatives and not by a British parliament in which they were not represented", "16 August 1975", "MFSK", "28 July 1914 to 11 November 1918", "Lager", "908 mbar ( hPa ; 26.81 inHg )", "North Carolina", "February 7, 2018", "October 2000 and European release date of April 2001", "The Lutheran Church of Sweden", "commemorating fealty and filial piety", "on the fictional Iron River Ranch, Colorado", "Valens", "American singer - songwriter - actress Debbie Gibson", "Lula", "31 January 1934", "Austin", "the southeastern United States", "gastrocnemius", "Daniel A. Dailey", "Jesus'birth", "President Yahya Khan", "Ramanaa", "In intestinal bacteria also play a role in synthesizing vitamin B and vitamin K as well as metabolizing bile acids", "Kyla Coleman", "Bill Belichick", "September 1972", "Dennis Locorriere", "Garbi\u00f1e Muguruza", "Spanish / Basque origin", "Lilian Bellamy", "about 13,000 astronomical units ( 0.21 ly )", "Shirley Mae Jones", "Motorola", "Neil Young", "`` 200 lakh rupees ''", "Chuck Noland", "many forested parts of the world", "arithmetic", "Finger Tab", "red squirrels", "Michael Swango", "Maria von Trapp", "Skatoony", "Felipe Calderon", "low-calorie", "0-0 draw away to Saudi Arabia", "the Romanov Dynasty", "Mexico", "the coyote", "Majid Movahedi,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6923073433919023}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, false, true, false, false, false, true, false, true, true, true, true, false, false, true, false, true, true, false, false, false, false, false, false, true, true, true, false, false, false, false, true, true, true, true, true, true, true, false, true, false, true, false, true, false, true, false, false, true, true, true, false, false, false, false, true, true, false], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 0.9600000000000001, 1.0, 0.0, 0.0, 0.0, 1.0, 0.9428571428571428, 1.0, 1.0, 1.0, 1.0, 0.6, 0.11764705882352941, 1.0, 0.3636363636363636, 1.0, 1.0, 0.11764705882352942, 0.0, 0.5, 0.0, 0.5, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 0.7058823529411765, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.5, 1.0, 0.8333333333333333, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 0.5, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-344", "mrqa_naturalquestions-validation-3515", "mrqa_naturalquestions-validation-6066", "mrqa_naturalquestions-validation-1878", "mrqa_naturalquestions-validation-3109", "mrqa_naturalquestions-validation-6234", "mrqa_naturalquestions-validation-7223", "mrqa_naturalquestions-validation-8156", "mrqa_naturalquestions-validation-4771", "mrqa_naturalquestions-validation-10469", "mrqa_naturalquestions-validation-6012", "mrqa_naturalquestions-validation-7939", "mrqa_naturalquestions-validation-4113", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-1026", "mrqa_naturalquestions-validation-3604", "mrqa_naturalquestions-validation-7227", "mrqa_naturalquestions-validation-3484", "mrqa_naturalquestions-validation-4659", "mrqa_naturalquestions-validation-7393", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9002", "mrqa_naturalquestions-validation-6207", "mrqa_naturalquestions-validation-1705", "mrqa_triviaqa-validation-6953", "mrqa_triviaqa-validation-178", "mrqa_newsqa-validation-3444", "mrqa_newsqa-validation-4076", "mrqa_newsqa-validation-3229", "mrqa_searchqa-validation-12989", "mrqa_newsqa-validation-1646"], "SR": 0.515625, "CSR": 0.5289884868421053, "EFR": 0.967741935483871, "Overall": 0.7052054594651953}, {"timecode": 76, "before_eval_results": {"predictions": ["$199.4 million", "Total Drama World Tour", "Christopher Lloyd", "senators", "robbery", "the fictional town of West Egg on prosperous Long Island", "sovereignty", "Authority", "Jughead Jones", "American rock band Los Lonely Boys", "Great Plains and U.S. Interior Highlands region", "cakes", "Kiss", "from 18 September to 31 October", "Julie Adams", "After a visit by Adolf Hitler, Bruno goes to see Shmuel and sneaks him food", "Anthony Quinn as Craig Belden", "January 2004", "Ella Eyre", "Hank J. Deutschendorf II", "Tennessee Titan 22 - 21, allowing Derrick Henry to rush for 156 yards", "Stephen Stills", "southern Turkey", "to encounter antigens passing through the mucosal epithelium", "Ashoka", "Spanish / Basque origin", "a contemporary drama in a rural setting", "1916", "Billie Jean King", "a sweet alcoholic drink made with rum, fruit juice, and syrup or Grenadine", "2017", "October 28, 2007", "Laura Vallejo", "embryo", "a primer, by polymerizing the first few glucose molecules, after which other enzymes take over", "Matt Monro", "a Nativity scene", "IV", "No. 1 seed Virginia and No. 4 seed Arizona, and second round losses by No. 3 seed Tennessee, led to the South Region becoming the first ever to not advance any of its top four seeds to the Sweet Sixteen", "Saphira hatches", "the BETA game was released in September 2017", "an Irish feminine name", "the British group Ace", "Spike", "a ligand - binding site on a receptor or enzyme", "After releasing Xander from the obligation to be Sweet's `` bride '', tells the group how much fun they have been ( `` What You Feel -- Reprise '' ) and disappears", "Agamemnon", "a multinational chain of full service, upscale hotels catering to business travelers and to the meetings and conventions market", "Mainland Greece forms the southernmost part of the Balkan peninsula with two additional smaller peninsulas projecting from it : the Chalcidice and the Peloponnese", "Jason Flemyng", "the Isthmus of Corinth", "Norman Mailer", "Vickers Vimy", "plc", "Part I", "17 October 2006", "Dr. Alberto Taquini", "$1.5 million.", "San Diego,", "CNN.com", "jazz", "echidna", "Forrest Gump", "31 meters (102 feet) long and 15 meters (49 feet) wide,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.594798766961596}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, false, true, false, true, true, false, true, false, false, true, true, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, false, true, true, true, false, false, true, false, false, true, false, false, false, false, false, true, false, true, true, false, true, true, true, true, true, false, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.5714285714285715, 1.0, 1.0, 1.0, 0.14285714285714285, 0.4, 0.25, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.7368421052631579, 0.0, 1.0, 0.0, 0.0, 0.6363636363636364, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.5, 1.0, 0.22222222222222224, 0.07407407407407408, 0.0, 0.1, 0.1, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-4547", "mrqa_naturalquestions-validation-8037", "mrqa_naturalquestions-validation-3559", "mrqa_naturalquestions-validation-5640", "mrqa_naturalquestions-validation-7211", "mrqa_naturalquestions-validation-8603", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-4008", "mrqa_naturalquestions-validation-825", "mrqa_naturalquestions-validation-4981", "mrqa_naturalquestions-validation-9672", "mrqa_naturalquestions-validation-8294", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-9908", "mrqa_naturalquestions-validation-2953", "mrqa_naturalquestions-validation-921", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-9409", "mrqa_naturalquestions-validation-7110", "mrqa_naturalquestions-validation-2873", "mrqa_naturalquestions-validation-2293", "mrqa_naturalquestions-validation-4850", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-4094", "mrqa_naturalquestions-validation-9451", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-2064", "mrqa_naturalquestions-validation-2067", "mrqa_triviaqa-validation-6055", "mrqa_newsqa-validation-3170", "mrqa_searchqa-validation-14736"], "SR": 0.515625, "CSR": 0.528814935064935, "EFR": 0.9354838709677419, "Overall": 0.6987191362065354}, {"timecode": 77, "before_eval_results": {"predictions": ["Pegasus", "As You Like It", "Apollo 8", "Live and Let Die", "Giuliano Bugiardini", "palladium", "pulsar", "Seth", "Hyundai", "\"Erroneous\" Number One", "Hitler", "It's True", "the 2010 FIFA World Cup", "Elizabeth I", "month", "Italy", "1960's", "Mel Brooks", "Belgium", "chlorophyll", "Paul Dukas", "Iceland", "Uranus", "rum", "apple", "Arbroath", "Roddy Doyle", "the U.S Olympic Trials", "Separate Tables", "the sound of the human voice could be reproduced,", "Beatrix Potter", "magpie", "comets", "men", "Kansas City", "Raul Castro", "Space Oddity", "Scotland", "UK Butterflies", "Illinois", "green", "Splash", "South Africa", "menorah", "A Beautiful Mind", "an \"enigmatic New Zealand slug\" Smeagol", "otters", "John McCarthy", "John Mortimer", "Alpen muesli", "DC", "an omnivorous open woodland bird with a strong territorial instinct", "Liam Cunningham", "Foofa", "Fuenlabrada", "Los Angeles Xtreme, San Francisco Demons and Memphis Maniax", "E22", "security breach", "at checkposts and military camps in the Mohmand agency,", "Mashhad", "St Bernard", "France", "Barnard College", "the equator,"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6182291666666666}, "metric_results_detailed": {"EM": [false, true, false, true, false, false, true, true, false, false, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, false, false, false, true, true, false, true, true, true, true, true, false, false, true, true, true, false, false, false, true, true, false, true, false, true, false, false, false, true, false, false], "QA-F1": [0.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.4, 0.5, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1337", "mrqa_triviaqa-validation-125", "mrqa_triviaqa-validation-4389", "mrqa_triviaqa-validation-5903", "mrqa_triviaqa-validation-5293", "mrqa_triviaqa-validation-6348", "mrqa_triviaqa-validation-958", "mrqa_triviaqa-validation-1265", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6491", "mrqa_triviaqa-validation-3008", "mrqa_triviaqa-validation-2258", "mrqa_triviaqa-validation-113", "mrqa_triviaqa-validation-7621", "mrqa_triviaqa-validation-6469", "mrqa_triviaqa-validation-3681", "mrqa_triviaqa-validation-4753", "mrqa_triviaqa-validation-1628", "mrqa_triviaqa-validation-2314", "mrqa_naturalquestions-validation-5687", "mrqa_hotpotqa-validation-844", "mrqa_hotpotqa-validation-2404", "mrqa_newsqa-validation-2885", "mrqa_newsqa-validation-1775", "mrqa_searchqa-validation-4403", "mrqa_searchqa-validation-4278", "mrqa_newsqa-validation-3978"], "SR": 0.578125, "CSR": 0.5294471153846154, "EFR": 1.0, "Overall": 0.711748798076923}, {"timecode": 78, "before_eval_results": {"predictions": ["France", "Granada", "Verdi", "the month of May", "Al Pacino", "Mohanda Karamchand", "hard", "Mr. golding", "a nerve cell cluster  or a group of nerve cell bodies located in the autonomic nervous system", "vitamin B3", "co-president of chatham house", "phillies", "Funchal", "hardwood", "spaghetti harvest", "Northern Ireland", "hard", "duchamp", "quatermass experiment", "Mumbai", "the Labyrinth", "1875", "raven", "hound", "sue", "Estimate", "hard", "Narendra Modi", "Richard Wagner", "quentin tarantino", "Argentina", "hard", "Kitzb\u00fchel", "Tunisia", "gail Webb", "prairies", "Romania", "brindisi", "Muriel", "Emeril Lagasse", "Belle Epoque Casino", "Esmeralda", "bialystock", "the Holy Land", "Eva Herzigov\u00e1", "phillies", "jerry", "rigbit", "hard fiction", "Colombia", "island", "the anterolateral corner of the spinal cord", "magnetic stripe `` anomalies '' on the ocean floor", "the ruling city of the Northern Kingdom of Israel, Samaria", "folk-song", "Martin Joseph O'Malley", "1992", "sculptures", "Sunday's strike", "al Qaeda,", "the Old Man", "Edward I", "the Cranberries", "there were no radar outages and said it had not lost contact with any planes during the computer glitch."], "metric_results": {"EM": 0.421875, "QA-F1": 0.5368019082633053}, "metric_results_detailed": {"EM": [true, true, true, false, true, false, false, false, false, false, false, false, true, false, true, false, false, true, true, true, true, true, true, false, true, true, false, true, true, false, true, false, true, true, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, true, false, false, true, true, false, false, true, true, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 0.5, 0.35294117647058826, 0.6666666666666666, 0.28571428571428575, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.25000000000000006, 1.0, 1.0, 0.33333333333333337, 0.8, 1.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.5, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-1074", "mrqa_triviaqa-validation-4300", "mrqa_triviaqa-validation-994", "mrqa_triviaqa-validation-5135", "mrqa_triviaqa-validation-5551", "mrqa_triviaqa-validation-5714", "mrqa_triviaqa-validation-6114", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-5434", "mrqa_triviaqa-validation-3940", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-617", "mrqa_triviaqa-validation-1150", "mrqa_triviaqa-validation-6121", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-3345", "mrqa_triviaqa-validation-439", "mrqa_triviaqa-validation-6986", "mrqa_triviaqa-validation-3676", "mrqa_triviaqa-validation-2959", "mrqa_triviaqa-validation-6490", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-6999", "mrqa_triviaqa-validation-35", "mrqa_triviaqa-validation-3903", "mrqa_triviaqa-validation-428", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-2699", "mrqa_naturalquestions-validation-7511", "mrqa_hotpotqa-validation-2327", "mrqa_hotpotqa-validation-4500", "mrqa_newsqa-validation-2485", "mrqa_newsqa-validation-2233", "mrqa_searchqa-validation-11262", "mrqa_searchqa-validation-7161", "mrqa_newsqa-validation-904"], "SR": 0.421875, "CSR": 0.5280854430379747, "EFR": 0.9459459459459459, "Overall": 0.7006656527967842}, {"timecode": 79, "before_eval_results": {"predictions": ["Astor", "Addis Ababa", "peacock", "French", "HMS amethyst", "Libya", "tomato", "Kyoto", "Fancy Dress Shop", "Bull Moose Party", "hippo", "james laurel", "resistance", "hanie McDaniel", "South Africa", "know", "discretion", "eva", "william mountford", "George Washington", "Corinth Canal", "human rights lawyer", "Iceland", "ascot", "european", "Kris Jenner", "gangsters", "doe", "king macbeth of Scotland", "UK Independence Party", "Argentina", "South Sudan", "cars, jewelry, stamps, art, wines, pens, antiques, cigars, even sneakers", "Darby and Joan", "toplis", "julian augustus", "IT Crowd", "\u00ef\u00bf\u00bd nastase", "carters", "hollywoodl", "Richard Curtis", "terms of endearment", "China", "hirst", "1790", "hole of spango", "chamomile", "carrie boolie", "orchid", "Hilary Swank", "abdeen", "latitude 90 \u00b0 North", "the 18th century", "eight hours ( UTC \u2212 08 : 00 )", "just 18 minutes", "England", "nationalism", "\"Raiders of the Lost Ark\"", "Afghanistan's Helmand province,", "hooligan", "theology", "Fred Astaire", "sanctions", "european"], "metric_results": {"EM": 0.46875, "QA-F1": 0.5608333333333333}, "metric_results_detailed": {"EM": [true, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, true, false, false, true, true, true, true, true, false, false, false, true, false, false, true, false, false, true, false, false, false, false, false, false, true, true, true, false, true, false, true, false, true, true, false, true, false, false, false, true, false, false, false, false, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 0.5, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.3333333333333333, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.6666666666666666, 0.5, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.16, 0.6, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-3717", "mrqa_triviaqa-validation-2433", "mrqa_triviaqa-validation-2739", "mrqa_triviaqa-validation-4551", "mrqa_triviaqa-validation-5839", "mrqa_triviaqa-validation-5552", "mrqa_triviaqa-validation-200", "mrqa_triviaqa-validation-1666", "mrqa_triviaqa-validation-3356", "mrqa_triviaqa-validation-2987", "mrqa_triviaqa-validation-2354", "mrqa_triviaqa-validation-7585", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-2302", "mrqa_triviaqa-validation-1829", "mrqa_triviaqa-validation-6223", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-4225", "mrqa_triviaqa-validation-959", "mrqa_triviaqa-validation-3948", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-1343", "mrqa_triviaqa-validation-1797", "mrqa_triviaqa-validation-7640", "mrqa_triviaqa-validation-3226", "mrqa_naturalquestions-validation-3505", "mrqa_naturalquestions-validation-9875", "mrqa_hotpotqa-validation-4993", "mrqa_hotpotqa-validation-5333", "mrqa_newsqa-validation-3862", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-2404", "mrqa_searchqa-validation-4372", "mrqa_searchqa-validation-2116"], "SR": 0.46875, "CSR": 0.52734375, "EFR": 0.9705882352941176, "Overall": 0.7054457720588235}, {"timecode": 80, "before_eval_results": {"predictions": ["Wisconsin", "Charles Habib Malik, Lebanon", "senators", "2", "in the dress shop", "Robert Gillespie Adamson IV", "Colon Street", "off the rez", "Jason Momoa", "1969", "Tim Passmore", "2003", "at 5 : 7 -- 8", "eventually into the Hudson Bay", "acid excreted as a gas by the lungs", "Miami Heat", "March 29, 2018", "50", "the manifestation of God's presence as perceived by humans according to the Abrahamic religions", "Emmanuelle Chriqui", "British Indian Association", "autopistas", "set to 0.05 ( 5 % ), implying that it is acceptable to have a 5 % probability of incorrectly rejecting the null hypothesis", "Tom Burlinson, Red Symons and Dannii Minogue", "The controlled synthesis of materials as thin films ( a process referred to as deposition ) is a fundamental step in many applications", "Tulsa, Oklahoma", "Kristy Swanson", "Joanna Moskawa", "Bonanza Creek Ranch", "Tbilisi, Capital of Georgia", "genome", "North Atlantic Ocean", "The Comanche / k\u0259\u02c8m\u00e6nt\u0283i\u02d0 / ( Comanche : N\u0289m\u0289n\u0289\u0289 )", "United Nations", "October 1, 2015, when the green class A was retired", "2026", "318", "the Director of National Intelligence", "Michael Crawford", "Patris et Filii et Spiritus Sancti", "Kida", "September 28, 2017", "Staci Keanan", "Brooklyn, New York", "1837", "\"Lagaan ( English : Taxation ; also called Lagaan : Once Upon a Time in India )", "1996", "American rock band Los Lonely Boys", "appearances", "the foreign exchange market ( FX )", "The Hustons", "The Sunday Post", "Karl Pilkington", "peking", "1860", "\"Back to December\"", "Buck Owens", "\"Beverly Hills Chihuahua\"", "\"Empire of the Sun,\"", "U.S.", "modificre", "molly ringwald", "merce", "Skull & Crossbones"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7161443648182957}, "metric_results_detailed": {"EM": [true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, false, false, false, true, true, true, false, false, false, true, true, true, false, false, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, false, false, false, false, true, false, true], "QA-F1": [1.0, 0.8571428571428571, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.7499999999999999, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.10526315789473684, 0.0, 0.1875, 1.0, 1.0, 1.0, 0.4, 0.4, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-3860", "mrqa_naturalquestions-validation-10102", "mrqa_naturalquestions-validation-9602", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-9220", "mrqa_naturalquestions-validation-9687", "mrqa_naturalquestions-validation-8728", "mrqa_naturalquestions-validation-9316", "mrqa_naturalquestions-validation-4206", "mrqa_naturalquestions-validation-7714", "mrqa_naturalquestions-validation-8096", "mrqa_naturalquestions-validation-4746", "mrqa_naturalquestions-validation-8026", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-9877", "mrqa_naturalquestions-validation-715", "mrqa_triviaqa-validation-7286", "mrqa_newsqa-validation-4104", "mrqa_newsqa-validation-3277", "mrqa_newsqa-validation-1024", "mrqa_searchqa-validation-11768", "mrqa_searchqa-validation-15045"], "SR": 0.640625, "CSR": 0.5287422839506173, "EFR": 0.9565217391304348, "Overall": 0.7029121796162104}, {"timecode": 81, "before_eval_results": {"predictions": ["Sun Tzu", "purple species", "Cleopatra", "nuclear warheads", "capitals", "pizza crust", "Sarah Jessica Parker", "Long Island Sound", "Hawaii", "Fauvism", "Auguste Deter", "Christopher Darden", "Jenny", "gestation", "ravens", "j.R. Tolkien", "James Franco", "the Blue Ridge Mountain Range", "Guiana", "a mixture of iron oxide and aluminum oxide", "Buddha", "Apple", "Southampton, Virginia", "catfish", "shanghai mccartney", "Piazza del Campo", "Atonement", "a feeling of sadness about something that you did or did not do", "Olivia Newton-John", "Virginia", "Oneonta College", "dogs", "Mayhaw jelly", "Matthew Vassar", "New York", "cutlery", "The Police", "Air France", "little johnny", "Heracles", "trudge", "The Doobie Brothers", "Albert Camus", "Volvo", "Rhode Island", "Falsetto", "the Indian Ocean", "a syringe", "Charlotte Corday", "nanosecond", "Didelphodon vorax", "Mason Alan Dinehart", "a key role in chain elongation in fatty acid biosynthesis and polyketide biosynthesis", "on location", "2010", "cymbal", "Madagascar", "Thomas William Hiddleston", "Estadio Victoria", "Borough of Allerdale", "President Robert Mugabe's", "70,000", "Israel", "Owsley Stanley"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5578869047619048}, "metric_results_detailed": {"EM": [true, false, false, false, false, false, true, true, true, true, false, false, true, true, true, false, true, false, false, false, false, true, false, false, false, false, true, false, false, true, false, false, false, false, false, false, true, true, false, false, false, false, false, true, true, false, true, false, true, true, false, true, false, true, true, true, true, false, true, false, false, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 0.5, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.28571428571428575, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 0.2857142857142857, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.6666666666666666, 0.4, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-6955", "mrqa_searchqa-validation-14267", "mrqa_searchqa-validation-13181", "mrqa_searchqa-validation-6021", "mrqa_searchqa-validation-3114", "mrqa_searchqa-validation-1554", "mrqa_searchqa-validation-4715", "mrqa_searchqa-validation-12632", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-1183", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-1201", "mrqa_searchqa-validation-4338", "mrqa_searchqa-validation-1527", "mrqa_searchqa-validation-15178", "mrqa_searchqa-validation-12500", "mrqa_searchqa-validation-9661", "mrqa_searchqa-validation-6884", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-11009", "mrqa_searchqa-validation-16540", "mrqa_searchqa-validation-9895", "mrqa_searchqa-validation-8284", "mrqa_searchqa-validation-12514", "mrqa_searchqa-validation-13846", "mrqa_searchqa-validation-5489", "mrqa_searchqa-validation-2254", "mrqa_searchqa-validation-13394", "mrqa_searchqa-validation-9609", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-506", "mrqa_searchqa-validation-1975", "mrqa_naturalquestions-validation-2110", "mrqa_hotpotqa-validation-980", "mrqa_hotpotqa-validation-868", "mrqa_newsqa-validation-3390"], "SR": 0.4375, "CSR": 0.5276295731707317, "EFR": 0.9722222222222222, "Overall": 0.7058297340785907}, {"timecode": 82, "before_eval_results": {"predictions": ["the Nautilus", "the Hopi", "China", "Pope John Paul II", "the Yangtze River", "Gnarls", "the Parthenon", "(My) Therapist", "Marilyn Monroe", "Souvlaki", "Richard III", "the bald eagle", "the Louvre", "4,840 square yards", "Galpagos", "(Hille) Bobbe", "the Black Sox Scandal", "(rooikat)", "Grenadine", "Constantine", "the Aleutian", "alchemy", "\"youth\"", "autobahn", "English", "the California quail", "curtsy", "lacrosse", "Toronto", "accent", "King David", "Riboflavin", "Hiawatha", "Indiana Jones", "Michigan", "Blue", "freelance", "Philadelphia", "Goodyear", "\"The Hobbit\"", "the Red Sox", "\"The Big Lebowski\"", "Yale University", "Graceland", "the Caspian Sea", "lace", "Lee Marvin", "Prince Edward Island", "Westminster Abbey", "Superbad", "\"The Granite State\"", "1871", "$2.187 billion", "On the west", "France", "the acai berry", "The Benedictine Order", "Pansexuality", "\"Titus Andronicus\"", "an American actor, singer and a DJ (under the name Ans\u00f8lo)", "Jennifer Kesse,", "\"The Little Couple,\"", "eight-week", "2001"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6253472222222223}, "metric_results_detailed": {"EM": [false, false, false, true, false, false, false, true, true, true, true, true, true, false, false, false, true, false, true, true, false, true, false, true, false, false, true, true, true, false, true, true, false, true, true, true, true, true, true, true, false, false, false, true, true, true, true, true, true, true, true, false, true, false, false, false, true, false, false, false, false, false, true, false], "QA-F1": [0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.22222222222222224, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-9065", "mrqa_searchqa-validation-2829", "mrqa_searchqa-validation-15986", "mrqa_searchqa-validation-13597", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-4928", "mrqa_searchqa-validation-7058", "mrqa_searchqa-validation-9159", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-9327", "mrqa_searchqa-validation-13324", "mrqa_searchqa-validation-2798", "mrqa_searchqa-validation-14340", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-11580", "mrqa_searchqa-validation-6810", "mrqa_searchqa-validation-14126", "mrqa_searchqa-validation-16140", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-5308", "mrqa_triviaqa-validation-5499", "mrqa_triviaqa-validation-3637", "mrqa_hotpotqa-validation-3408", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-3145", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-1388", "mrqa_hotpotqa-validation-943"], "SR": 0.546875, "CSR": 0.5278614457831325, "EFR": 1.0, "Overall": 0.7114316641566265}, {"timecode": 83, "before_eval_results": {"predictions": ["George Washington", "The Office", "Jesus Christ", "penguins", "vrai", "Napoleon Bonaparte", "A.J. Foyt", "a vulture", "Nantucket", "Ebony", "Trinity", "Algeria", "(Franz) Joseph Haydn", "Dick Cheney", "the black market", "an", "The Rocky Horror Picture Show", "Japan", "Sicilian pizza", "a turtle", "the Empire State Building", "White blood cells", "a picayune", "a dogwood", "Quebec", "Larry McMurtry", "Kellogg", "Helen of Troy", "Undergarment", "W=Fd", "Napoleon", "ivory", "the Arctic area of Spmi", "Ben & Jerry", "Rigoletto", "Tim Tebow", "schizophrenia", "Catherine of Aragon", "the American Bell Telephone Company", "Pancho Gonzales", "the Aleutians", "the Mormons", "Lady Jane Grey", "867-5309", "the crescent moon", "Iraq", "an an Earthworm", "Nicolaus Copernicus", "an egg yolk", "William Safire", "Leonardo Da Vinci", "from London to Canterbury to visit the shrine of Saint Thomas Becket at Canterbury Cathedral", "Charlton Heston", "Andrea Brooks", "the fallopian tube", "Some Like It Hot", "Barbara Eden", "\"The Maltese Falcon\"", "T. R. M. Howard", "Parlophone", "9:20 p.m. ET Wednesday.", "DBG,", "1995", "four"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6859375}, "metric_results_detailed": {"EM": [false, true, false, true, true, false, true, true, false, false, true, true, false, true, true, false, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, false, false, true, false, false, false, true, true, true, true, false, true, false, true, true, true, true], "QA-F1": [0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 0.8, 0.13333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-3177", "mrqa_searchqa-validation-9848", "mrqa_searchqa-validation-4701", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-4076", "mrqa_searchqa-validation-11669", "mrqa_searchqa-validation-2764", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-7924", "mrqa_searchqa-validation-13890", "mrqa_searchqa-validation-7241", "mrqa_searchqa-validation-6397", "mrqa_searchqa-validation-5063", "mrqa_searchqa-validation-1070", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-7466", "mrqa_searchqa-validation-8128", "mrqa_searchqa-validation-699", "mrqa_searchqa-validation-12489", "mrqa_searchqa-validation-10311", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-5572", "mrqa_searchqa-validation-1989", "mrqa_naturalquestions-validation-9348", "mrqa_naturalquestions-validation-7457", "mrqa_hotpotqa-validation-5196", "mrqa_hotpotqa-validation-3182"], "SR": 0.578125, "CSR": 0.5284598214285714, "EFR": 1.0, "Overall": 0.7115513392857142}, {"timecode": 84, "before_eval_results": {"predictions": ["Russia", "Henry VIII", "Judas Iscariot", "Windsor, Ontario", "Douglas", "comrade", "the Great Gatsby", "a fox", "Sexuality", "Salaries", "Solomon", "Roger Federer", "a bicycle", "Johnson County", "Jericho", "a push", "Alexander Solzhenitsyn", "farce", "Mexico", "Easter", "John Denver", "Hurricane Katrina", "Paris", "leeches", "the American Revolution", "the Philippines", "St Mark", "Eragon", "Penny Lane", "Louisiana", "Mexico", "a jolly Roger", "engrave", "Daisy Miller", "the Legion of Honour", "a X", "a ship", "Kamehameha", "a fox", "Jamestown", "Jerry Maguire", "the north magnetic pole", "Oyster", "Walt Disney\\'s", "Candlestick Park", "Zimbabwe", "a bowstring", "Patty Duke", "a Pronouns", "Hoffmann", "a calico", "Frankie Muniz", "during season two", "A compound sentence", "40", "Neptune", "Nowhere Boy", "August", "an Anglo-Saxon tumulus (or \"barrow\")", "Richa Sharma", "Haiti", "financial gain,", "a Nazi concentration camp,", "Agent Mark Steinberg"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7374999999999999}, "metric_results_detailed": {"EM": [true, true, false, true, false, true, false, true, true, true, true, false, true, true, true, true, false, false, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, true, false, true, true, true, false, false, true, true, true, true, false, false, true, false, false, false, true, true, true, false, false, true, true, true, false, false], "QA-F1": [1.0, 1.0, 0.6666666666666666, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.8, 0.5, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.4, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-8842", "mrqa_searchqa-validation-109", "mrqa_searchqa-validation-6222", "mrqa_searchqa-validation-14335", "mrqa_searchqa-validation-4907", "mrqa_searchqa-validation-7179", "mrqa_searchqa-validation-5056", "mrqa_searchqa-validation-14845", "mrqa_searchqa-validation-666", "mrqa_searchqa-validation-2536", "mrqa_searchqa-validation-6449", "mrqa_searchqa-validation-10202", "mrqa_searchqa-validation-271", "mrqa_searchqa-validation-8196", "mrqa_searchqa-validation-11098", "mrqa_searchqa-validation-1469", "mrqa_naturalquestions-validation-9752", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-8329", "mrqa_hotpotqa-validation-5599", "mrqa_hotpotqa-validation-1226", "mrqa_newsqa-validation-1945", "mrqa_newsqa-validation-3759"], "SR": 0.640625, "CSR": 0.5297794117647059, "EFR": 1.0, "Overall": 0.7118152573529412}, {"timecode": 85, "before_eval_results": {"predictions": ["Boston", "Winnie the Pooh", "Italian", "Eggs Benedict", "the Taj Mahal", "Frank Lloyd Wright", "Brahma", "Jon Stewart", "The Sweet", "Tiger Woods", "the Amazon", "Harry Houdini", "Falconer", "Queen Latifah", "Ezra Cornell", "Strawberry Fields", "The Hague", "Geena Davis", "Pharmacy", "Amos (Bobby) Roosevelt", "the NFL", "Doolittle", "pulmonary", "Shakespeare in Love", "Oscar De La Hoya", "the ABBA", "the League of Nations", "Marlee Matlin", "a house", "The X-Files", "Babar", "Mensa", "Edward Hopper", "oratorios", "the Roadhouse", "a snake god", "a toddler", "the Salt Lake City", "Italy", "the (acorn) squash", "the Warsaw Pact", "Athens", "230", "an anode", "the TNG episode", "The National Teachers Hall of Fame", "the Bicentennial", "the Chickasaw", "the epidermis", "the Texas Rangers", "Fluoxetine", "H CO ( equivalently OC ( OH ) )", "Middle Eastern alchemy", "Brooklyn, New York", "Eton College and Balliol", "Leeds", "the Bexar, Mexican General Santa Anna determined to retake this key location and at the same time impress upon the Texans the futility of further resistance to Mexican rule.", "Dwight D. Eisenhower", "Battleship", "Ilinca", "pizza,", "has to move out of her rental house because it is facing foreclosure", "Why he's more American than a German,", "Santiago Ram\u00f3n y Cajal"], "metric_results": {"EM": 0.5625, "QA-F1": 0.5843750000000001}, "metric_results_detailed": {"EM": [true, false, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, false, false, true, true, false, true, false, false, false, false, false, false, false, false, false, false, true, true, true, false, true, false, false, true, false, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-10138", "mrqa_searchqa-validation-14183", "mrqa_searchqa-validation-7391", "mrqa_searchqa-validation-5581", "mrqa_searchqa-validation-14331", "mrqa_searchqa-validation-9730", "mrqa_searchqa-validation-14350", "mrqa_searchqa-validation-16428", "mrqa_searchqa-validation-10775", "mrqa_searchqa-validation-13169", "mrqa_searchqa-validation-10858", "mrqa_searchqa-validation-1894", "mrqa_searchqa-validation-16201", "mrqa_searchqa-validation-16198", "mrqa_searchqa-validation-7363", "mrqa_searchqa-validation-3434", "mrqa_searchqa-validation-12882", "mrqa_searchqa-validation-11773", "mrqa_searchqa-validation-10056", "mrqa_searchqa-validation-14355", "mrqa_triviaqa-validation-4961", "mrqa_triviaqa-validation-2999", "mrqa_hotpotqa-validation-5190", "mrqa_hotpotqa-validation-1212", "mrqa_newsqa-validation-264", "mrqa_newsqa-validation-2692", "mrqa_naturalquestions-validation-4103"], "SR": 0.5625, "CSR": 0.5301598837209303, "EFR": 1.0, "Overall": 0.711891351744186}, {"timecode": 86, "before_eval_results": {"predictions": ["Happy feet", "a full distance", "a real animal", "Joseph", "Chicago", "Aphrodite", "Cannery Row", "the Palatine hill", "California", "the Mississippi", "Alpha", "Quebec", "abalone", "Texas Chainsaw Massacre", "a rotunda", "a oak leaf cluster", "Manet", "Plutarch", "Mediolanum", "Corin", "Shropshire", "a blood pump", "Afghanistan", "satin", "Lady Godiva", "Job", "Vasco da Gama", "Millard", "a chino", "Finnegans Wake", "Es Selamu", "the black market", "Adrianna Kezar", "earthquakes", "Maastricht", "Delilah", "synapses", "a croissant", "Rocky Down Mexico Way", "air", "fuchsia", "a metacarpal", "a pool", "Warsaw", "a trowel", "the Mercury Seven", "Taiwan", "Gettysburg", "burkini", "trout", "a farce", "soon after", "the first season of NCIS", "$75,000", "blue", "15", "a yard", "Agent Carter", "Orson Welles", "Manhattan, New York City", "56,", "Secretary of State", "Bright Automotive,", "James Hogg"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6441220238095238}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, true, true, true, true, false, true, true, true, true, false, true, true, false, false, true, false, true, false, true, true, true, true, true, true, false, true, false, true, true, true, true, false, false, false, false, false, false, false, true, false, true, true, false, true, false, false, false, true, false, false, false, true, true, false, true, true, true, true], "QA-F1": [1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.5, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.3333333333333333, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_searchqa-validation-16474", "mrqa_searchqa-validation-1883", "mrqa_searchqa-validation-5964", "mrqa_searchqa-validation-16459", "mrqa_searchqa-validation-2960", "mrqa_searchqa-validation-4065", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8200", "mrqa_searchqa-validation-16219", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-9319", "mrqa_searchqa-validation-718", "mrqa_searchqa-validation-0", "mrqa_searchqa-validation-8225", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-5239", "mrqa_searchqa-validation-6883", "mrqa_searchqa-validation-12749", "mrqa_searchqa-validation-3449", "mrqa_searchqa-validation-2311", "mrqa_searchqa-validation-9618", "mrqa_naturalquestions-validation-1404", "mrqa_naturalquestions-validation-9595", "mrqa_triviaqa-validation-2736", "mrqa_triviaqa-validation-1095", "mrqa_triviaqa-validation-5762", "mrqa_hotpotqa-validation-24"], "SR": 0.578125, "CSR": 0.5307112068965517, "EFR": 1.0, "Overall": 0.7120016163793104}, {"timecode": 87, "before_eval_results": {"predictions": ["Tim Russert", "the CEDA", "Michael Crawford", "Alka Yagnik", "Pat McCormick", "Louis Mountbatten", "Zerach Warhaftig", "April 6, 1917", "assemble a stable, protective protein shell to protect the genome from lethal chemical and physical agents", "close to 5,770", "Geoffrey Zakarian", "4.5 pounds or 2.04 kg", "Mary Elizabeth ( Margaret Hoard )", "Scott Schwartz", "Paris", "the homicidal thoughts of a troubled youth", "Florida", "Husrev Pasha", "Patrick Warburton", "Alan Shearer", "Robert Duvall", "$66.5 million", "helps digestion by breaking the bonds linking amino acids, a process known as proteolysis", "Southern political leaders'resistance to attempts by Northern antislavery political forces to block the expansion of slavery into the western territories", "The Osmonds", "political pamphlet", "island countries", "Anakin Skywalker", "Jeff East", "one", "Thomas Lennon", "Jesse Triplett", "Kevin Garnett", "a star", "Brazil", "Selena Gomez", "U.S. state of Washington", "the 2nd century", "Triple threat", "1998", "Dimitar Berbatov and Carlos Tevez", "foreign investors", "Louis XVIII", "a U.S. design patent as `` teardrop - shaped marker icon including a shadow", "James Ray", "prejudice in favour of or against one thing, person, or group compared with another, usually in a way considered to be unfair", "2004", "The User State Migration Tool ( USMT )", "Robber baron", "1953", "Watson", "Mount Aconcagua", "Bake Off", "1924", "Eugene Levy", "zona glomerulosa", "Fionnula Flanagan", "last summer.", "social activism.", "three-time", "banker", "eyelid", "the Cubs", "a thief"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5346814289165083}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, false, true, false, false, true, false, true, false, false, true, true, true, false, true, true, true, false, false, true, false, false, true, true, false, true, false, false, false, true, true, false, false, true, false, false, false, false, false, true, true, true, false, true, false, true, true, false, false, false, true, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.4444444444444445, 0.0, 1.0, 0.782608695652174, 0.5454545454545454, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.7741935483870968, 0.10526315789473684, 1.0, 0.25, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 0.0, 0.11764705882352941, 1.0, 1.0, 0.4, 0.8, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 0.0]}}, "before_error_ids": ["mrqa_naturalquestions-validation-9825", "mrqa_naturalquestions-validation-6424", "mrqa_naturalquestions-validation-2202", "mrqa_naturalquestions-validation-7190", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-4449", "mrqa_naturalquestions-validation-7509", "mrqa_naturalquestions-validation-8260", "mrqa_naturalquestions-validation-6021", "mrqa_naturalquestions-validation-4495", "mrqa_naturalquestions-validation-2942", "mrqa_naturalquestions-validation-685", "mrqa_naturalquestions-validation-5638", "mrqa_naturalquestions-validation-10209", "mrqa_naturalquestions-validation-8383", "mrqa_naturalquestions-validation-4426", "mrqa_naturalquestions-validation-2008", "mrqa_naturalquestions-validation-5305", "mrqa_naturalquestions-validation-3281", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-8763", "mrqa_naturalquestions-validation-4032", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-3269", "mrqa_naturalquestions-validation-4265", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-7362", "mrqa_triviaqa-validation-1386", "mrqa_triviaqa-validation-3335", "mrqa_hotpotqa-validation-3321", "mrqa_hotpotqa-validation-995", "mrqa_newsqa-validation-1117", "mrqa_newsqa-validation-152", "mrqa_searchqa-validation-14144", "mrqa_searchqa-validation-14176", "mrqa_triviaqa-validation-4676"], "SR": 0.4375, "CSR": 0.5296519886363636, "EFR": 0.9444444444444444, "Overall": 0.7006786616161615}, {"timecode": 88, "before_eval_results": {"predictions": ["Cologne, Germany,", "Philip Markoff,", "a bag", "Federer", "Galveston, Texas, to Veracruz, Mexico,", "Diego Milito's", "Because 10 percent of women who have a mammogram could find 100 percent of breast cancers,\"", "\"They had the live jackets... they were staying in one house and they had hidden the suicide jackets not far from that (house) in the hills,\"", "Salt Lake City, Utah,", "normal maritime traffic", "Malmo City", "to make space for two ocean wind farms -- taking up 2 percent of the state's waters -- without angering fishing industries, killing whales or harming ecosystems.", "Rocky Ford brand cantaloupes", "these planning processes are urgently needed and have been a long time in coming.", "In the last four weeks, authorities arrested three men with suicide vests who were plotting to carry out the attacks,", "\"I would like to present you with a little gift that represents what President Obama and Vice President Biden and I have been saying and that is: 'We want to reset our relationship and so we will do it together.'\"", "club managers,", "Long Island", "90", "the FBI.", "Reggae legend Lucky Dube,", "the Kurdish militant group", "At least 14", "\"It hurts my heart to see him in pain, but it enlightens at the same time to know my son is strong enough to make it through on a daily basis,\"", "Kerstin Fritzl,", "the Defense of Marriage Act", "Europe", "\"We've got more work to do to ensure that government treats all its citizens equally, to fight injustice and intolerance in all its forms and to bring about that more perfect union,\"", "immediate release into the United States of 17 Chinese Muslims who have been held for several years in the U.S. military facility at Guant Bay, Cuba.", "Greeley, Colorado,", "Festival Foods in Kansas City, Missouri,", "air and sprayed water cannons to disperse the crowd.", "drugs", "Daniel Radcliffe", "1.2 million", "\"It was a wrong thing to say, something that we both acknowledge,\"", "12.3 million", "Krishna Rajaram,", "a rocket", "Patrick McGoohan,", "saying Chaudhary's death was warning to management.", "Taher Nunu", "state senators", "2,000 euros ($2,963)", "Anil Kapoor", "the Obama administration needs to think of \"victory\" not only in the short term and from a purely anti-terrorism perspective, but also in consideration of the people who have lived and will continue to live in those lands.", "Yemen.", "The federal officers' bodies", "Carl", "the Chao Phraya River and its many canals.", "journalists and the flight crew will be freed,", "a writ of certiorari", "pigs", "James Corden", "Norway", "Hamlet", "The Hague Conventions", "Chris Hemsworth", "Viscount Cranborne", "England and Ireland", "beef", "Suleyman", "the rainforest", "Ramadan"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6253560562089433}, "metric_results_detailed": {"EM": [true, false, true, false, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, false, false, false, true, false, false, false, false, false, true, false, false, true, true, true, false, true, true, false, false, false, true, true, true, true, false, true, true, false, false, true, true, true, true, true, true, true, true, true, false, false, false, true, true], "QA-F1": [1.0, 0.4444444444444445, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 0.0, 0.06451612903225806, 1.0, 0.8, 0.0, 0.07407407407407407, 1.0, 0.5555555555555556, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.5, 1.0, 0.6666666666666666, 0.8571428571428571, 0.0, 0.043478260869565216, 0.15384615384615385, 1.0, 0.2, 0.13333333333333333, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.08695652173913045, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-834", "mrqa_newsqa-validation-1361", "mrqa_newsqa-validation-4012", "mrqa_newsqa-validation-358", "mrqa_newsqa-validation-1095", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1923", "mrqa_newsqa-validation-4168", "mrqa_newsqa-validation-4166", "mrqa_newsqa-validation-1534", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-594", "mrqa_newsqa-validation-1508", "mrqa_newsqa-validation-798", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-1426", "mrqa_newsqa-validation-3362", "mrqa_newsqa-validation-1427", "mrqa_newsqa-validation-1561", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-3825", "mrqa_newsqa-validation-2815", "mrqa_newsqa-validation-1662", "mrqa_newsqa-validation-2061", "mrqa_newsqa-validation-3565", "mrqa_newsqa-validation-4173", "mrqa_newsqa-validation-4107", "mrqa_newsqa-validation-1212", "mrqa_hotpotqa-validation-3169", "mrqa_searchqa-validation-11658", "mrqa_searchqa-validation-3763"], "SR": 0.515625, "CSR": 0.5294943820224719, "EFR": 1.0, "Overall": 0.7117582514044944}, {"timecode": 89, "before_eval_results": {"predictions": ["The 133d Air Refueling Squadron (133 ARS)", "Kim So-hyun", "president of Guggenheim Partners", "\"talking Dead\"", "night of 9\u201310 March 1945", "2011", "John D Rockefeller's", "during the early 1970s", "Asiana Town", "American R&B singer, guitarist, songwriter and music producer", "Rockland County", "Manitowoc County, Wisconsin", "south-east", "1967", "alcoholic drinks", "Confindustria and FIEG", "Chrysler", "South Australia", "chimpanzee", "Eyes Wide Shut", "The Royal Navy", "Robert Digges Wimberly Connor", "Rage Against the Machine", "the Beatles", "Baden-W\u00fcrttemberg, Germany", "2001 NBA All-Star Game", "Takura", "95 AD", "1614", "Italian", "\"Grimjack\" (from First Comics)", "Mondays", "James Ager Worthy", "Snowball II is killed off", "HSBC Building", "1987", "Elizabeth Keka\u02bbaniau La\u02bbanui", "17 October 2006", "melodic hard rock", "The Home Rule League", "Anne Fletcher", "November 1822", "Mulberry", "Suspiria", "BBC Focus", "federal Senator Stephen A. Douglas of Illinois and President Franklin Pierce", "Scandinavian design", "Buck Owens", "Big Machine Records", "a delivery service company in the United Kingdom and is one of the largest couriers along with Royal Mail", "Flaw", "October 27, 2016", "1972", "the initiator must go through an intensive week - long initiation process in which the teaching of the ritual skills and moral behavior occurs informally and nonverbally", "Davy Crockett", "elbow", "the Tigris", "African National Congress Deputy President Kgalema Motlanthe,", "\"Piers Morgan Tonight\"", "misdemeanor assault charges", "Florida", "The Partridge Family", "Mickey Spillane", "housing, business and infrastructure repairs,"], "metric_results": {"EM": 0.515625, "QA-F1": 0.6347716473950027}, "metric_results_detailed": {"EM": [false, false, false, false, false, true, false, false, false, false, true, true, false, true, true, false, true, false, false, false, false, true, false, true, false, true, false, true, true, true, false, true, false, false, false, false, false, true, true, true, true, false, true, true, true, false, true, true, true, false, true, false, true, true, true, true, true, false, false, true, true, true, true, false], "QA-F1": [0.8, 0.0, 0.4, 0.0, 0.7499999999999999, 1.0, 0.6666666666666666, 0.8, 0.8, 0.18181818181818182, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.3333333333333333, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.3157894736842105, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4603", "mrqa_hotpotqa-validation-2029", "mrqa_hotpotqa-validation-1509", "mrqa_hotpotqa-validation-163", "mrqa_hotpotqa-validation-3590", "mrqa_hotpotqa-validation-574", "mrqa_hotpotqa-validation-247", "mrqa_hotpotqa-validation-1702", "mrqa_hotpotqa-validation-3795", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5233", "mrqa_hotpotqa-validation-4391", "mrqa_hotpotqa-validation-5188", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-5567", "mrqa_hotpotqa-validation-1112", "mrqa_hotpotqa-validation-1556", "mrqa_hotpotqa-validation-4966", "mrqa_hotpotqa-validation-2177", "mrqa_hotpotqa-validation-2807", "mrqa_hotpotqa-validation-3504", "mrqa_hotpotqa-validation-3455", "mrqa_hotpotqa-validation-252", "mrqa_hotpotqa-validation-4756", "mrqa_hotpotqa-validation-2513", "mrqa_hotpotqa-validation-837", "mrqa_hotpotqa-validation-3832", "mrqa_naturalquestions-validation-1728", "mrqa_newsqa-validation-1382", "mrqa_newsqa-validation-2587", "mrqa_newsqa-validation-3369"], "SR": 0.515625, "CSR": 0.5293402777777778, "EFR": 1.0, "Overall": 0.7117274305555557}, {"timecode": 90, "before_eval_results": {"predictions": ["Earl Palmer", "Ardeth Bay", "2009", "singer", "Pakistan", "1754", "\"To Save a Life\"", "Germany national team", "d\u00edsabl\u00f3t", "David Villa", "Adrian Peter McLaren", "2013", "an early colonist of South Australia", "Cleopatra", "Leon Marcus Uris", "Knoxville, Tennessee", "cancer", "Devraj", "Fuli", "25 November 2015", "Craig William Macneill", "January 14,", "2,664", "Tamil", "Objectivism", "Chicago", "Gatwick Airport", "Riot Act", "Helensvale", "January 30, 1930", "2015", "October 29, 1985", "35,124", "Estadio de L\u00f3pez Cort\u00e1zar", "Sir Seretse Khama", "Scandinavian design", "Mike Pence", "Barack Obama's Cabinet", "Flex-fuel", "Bulgarian", "1949", "Trappist beer", "\"Waiting for Guffman\"", "Presbyterian Church", "138,535 people", "Ry\u016bky\u016ban", "1972", "Stern-Plaza", "Life Is a Minestrone", "Columbia Records", "The Spiderwick Chronicles", "Jewel Akens", "gravity", "improve communication", "South Africa", "Ann Widdecombe", "Jennifer Eccles", "\"TSA has reviewed the procedures themselves and agrees that they need to be changed,\"", "sailing", "Robert", "dolls", "Hombre", "CO2", "Walgreens"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6537459935897436}, "metric_results_detailed": {"EM": [false, false, true, false, false, true, false, false, false, true, true, true, false, true, true, true, false, false, false, false, true, false, true, true, true, true, true, true, false, true, false, false, true, true, false, true, true, false, false, true, true, true, true, true, false, false, true, true, true, false, true, true, true, true, true, true, true, false, true, true, false, false, false, false], "QA-F1": [0.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.8, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2564102564102564, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-4945", "mrqa_hotpotqa-validation-3064", "mrqa_hotpotqa-validation-1592", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-982", "mrqa_hotpotqa-validation-4771", "mrqa_hotpotqa-validation-5526", "mrqa_hotpotqa-validation-1539", "mrqa_hotpotqa-validation-4501", "mrqa_hotpotqa-validation-4116", "mrqa_hotpotqa-validation-3907", "mrqa_hotpotqa-validation-413", "mrqa_hotpotqa-validation-2734", "mrqa_hotpotqa-validation-3930", "mrqa_hotpotqa-validation-2266", "mrqa_hotpotqa-validation-2717", "mrqa_hotpotqa-validation-1218", "mrqa_hotpotqa-validation-5529", "mrqa_hotpotqa-validation-5035", "mrqa_hotpotqa-validation-1363", "mrqa_hotpotqa-validation-1867", "mrqa_hotpotqa-validation-1457", "mrqa_newsqa-validation-386", "mrqa_searchqa-validation-4335", "mrqa_searchqa-validation-10988", "mrqa_searchqa-validation-11743", "mrqa_searchqa-validation-10146"], "SR": 0.578125, "CSR": 0.5298763736263736, "EFR": 1.0, "Overall": 0.7118346497252748}, {"timecode": 91, "before_eval_results": {"predictions": ["Close Encounters of the Third Kind", "Sony", "the Jaguar", "Tony\\'s", "Friday", "Sabino Canyon", "Orlando Bloom", "Babe Ruth", "the 1960s", "Arkansas", "Mike Tyson", "the Virgo", "contemporary", "Coyote", "pastoral", "Tito Puente", "Hydrogen", "Johnny Cash", "the malignant disease", "Margaret, Countess of Snowdon", "Las Vegas", "San Francisco", "the 1940s", "Mary Baker Eddy", "Bank One Corp.", "the College of William & Mary", "the Wright Brothers", "Badminton", "John Deere", "Elizabeth Barrett Browning", "Chrysler", "Reptiles", "Georgia", "Key lime pie", "Lettuce", "Haroun", "the bumblebee", "Savannah", "Rickey Henderson", "parquet", "Alice Walker", "F Troop", "Russia", "Lincoln", "Eva Pern", "Port Royal", "a key", "Ghost", "Francisco Pizarro", "the Assyrian empire", "Marat", "Cetshwayo", "Bay of Montevideo", "a bank, drawn on the bank's own funds and signed by a cashier", "a spirit-lifting jingle", "Pat Houston", "BATH, England", "1.5 million", "Macomb County", "Kristoffer Rygg", "the Texas A&M Offshore Sailing Team", "Monday night.", "eight.", "biographer"], "metric_results": {"EM": 0.546875, "QA-F1": 0.6455492424242424}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, true, false, true, true, false, false, false, false, true, true, false, false, false, true, true, true, true, false, false, true, true, true, false, false, false, true, false, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, false, true, true, true, false, false, false, false, false, true, true, false, false, true, false], "QA-F1": [1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 0.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.8, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.18181818181818182, 0.0, 0.0, 0.6666666666666666, 0.8, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-4871", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-6087", "mrqa_searchqa-validation-7846", "mrqa_searchqa-validation-13146", "mrqa_searchqa-validation-13929", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-595", "mrqa_searchqa-validation-254", "mrqa_searchqa-validation-14099", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-955", "mrqa_searchqa-validation-11502", "mrqa_searchqa-validation-9724", "mrqa_searchqa-validation-14435", "mrqa_searchqa-validation-6272", "mrqa_searchqa-validation-10442", "mrqa_searchqa-validation-3322", "mrqa_searchqa-validation-1574", "mrqa_searchqa-validation-14501", "mrqa_searchqa-validation-12942", "mrqa_naturalquestions-validation-3303", "mrqa_triviaqa-validation-7696", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-3665", "mrqa_hotpotqa-validation-2255", "mrqa_newsqa-validation-4011", "mrqa_newsqa-validation-556", "mrqa_hotpotqa-validation-4539"], "SR": 0.546875, "CSR": 0.5300611413043479, "EFR": 1.0, "Overall": 0.7118716032608695}, {"timecode": 92, "before_eval_results": {"predictions": ["Luzon", "Brancusi", "Quantico, Virginia", "the East River", "William Shakespeare", "William Shakespeare", "british", "Alaska", "Sputnik", "Richmond", "the 1960s", "Java", "baryton", "Reginald", "dove", "Room-temperature vulcanization", "the Linton", "Ali", "September 20, 1934", "Dead Man\\'s Chest", "Frederick Forsyth", "Chesterfield, Virginia", "a wolf", "british", "salt", "a disorderly Conduct", "Rossini", "Texas", "Lapland", "Tom Canty", "Andrzej Wajda", "Joan Didion", "a frigate", "Baltimore", "the Bay of Bengal", "jedoublen", "Clinton", "Terrific", "geology", "six sides", "Olympia", "the ship of Fools", "scare zones", "Tom", "blue", "Margaret Mitchell", "Frances", "Vin Diesel", "Bali Royal Cremation", "the French & Indian War", "manic", "central Saskatchewan", "lighter fluid", "prendick has knocked over a lamp", "bobby (disease)", "bahn", "Caernarfon", "Nairobi, Kenya", "Love Streams", "My Beautiful Dark Twisted Fantasy", "between June 20 and July 20.", "Michael Krane,", "Virgin America", "the Vatican's ban on condom use"], "metric_results": {"EM": 0.484375, "QA-F1": 0.5442708333333333}, "metric_results_detailed": {"EM": [true, false, false, true, true, false, false, true, true, true, false, true, false, false, false, false, false, false, false, true, true, false, false, false, true, false, true, true, true, false, false, true, false, false, true, false, false, true, false, false, true, true, false, false, false, true, true, true, false, true, true, true, true, false, false, false, false, true, true, true, true, true, true, false], "QA-F1": [1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_searchqa-validation-1244", "mrqa_searchqa-validation-16790", "mrqa_searchqa-validation-5559", "mrqa_searchqa-validation-8449", "mrqa_searchqa-validation-10070", "mrqa_searchqa-validation-6502", "mrqa_searchqa-validation-173", "mrqa_searchqa-validation-13847", "mrqa_searchqa-validation-2299", "mrqa_searchqa-validation-14332", "mrqa_searchqa-validation-6877", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-14143", "mrqa_searchqa-validation-11414", "mrqa_searchqa-validation-13171", "mrqa_searchqa-validation-3320", "mrqa_searchqa-validation-4824", "mrqa_searchqa-validation-15084", "mrqa_searchqa-validation-15704", "mrqa_searchqa-validation-15802", "mrqa_searchqa-validation-13701", "mrqa_searchqa-validation-10543", "mrqa_searchqa-validation-315", "mrqa_searchqa-validation-14800", "mrqa_searchqa-validation-15780", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-6507", "mrqa_searchqa-validation-14713", "mrqa_naturalquestions-validation-894", "mrqa_triviaqa-validation-6984", "mrqa_triviaqa-validation-812", "mrqa_triviaqa-validation-6867", "mrqa_newsqa-validation-1663"], "SR": 0.484375, "CSR": 0.5295698924731183, "EFR": 1.0, "Overall": 0.7117733534946236}, {"timecode": 93, "before_eval_results": {"predictions": ["Mesopotamia", "Gettysburg College", "Tim McGraw", "provides the public with financial information about a nonprofit organization", "Lulu", "Tony Orlando and Dawn", "David Ogden Stiers", "2017", "drivers who were 2016 Pole Award winners, former Clash race winners, ( Daytona 500 pole winners who competed full - time in 2016, and drivers who qualified for the 2016 Chase", "17 December 1968", "Pebble Beach", "in a Saiyan's \u014czaru ( \u5927 \u733f, lit. `` Great Ape '' ) form", "`` Audrey II ''", "January 2017", "NIRA", "1922", "Julie Debbie Kavner", "Justin Timberlake", "The Chainsmokers", "13 May 1787", "New York ( from James's English title )", "his brother", "Seattle, Washington, site of the Century 21 Exposition, the 1962 World's Fair", "honey bees", "Article 1, Section 2, Clause 3 of the United States Constitution", "McFerrin", "Napoleon", "Hem Chandra Bose", "September 27, 2017", "Fusajiro Yamauchi", "March 31 to April 8, 2018", "Tbilisi", "Tiffany Adams Coyne", "Jupiter", "hyperinflation", "1939", "Richard Masur", "Kyla Pratt", "Tagalog", "Sauron", "Lana Del Rey", "house edge", "159", "The Third Five - year Plan", "The chant was first adopted by the university's science club in 1886", "Maria works in a bridal shop with Anita, the girlfriend of her brother, Bernardo", "increases the life of the pump, allows a smaller and lighter device to be used, and reduces electrical load", "A patent is a set of exclusive rights granted by a sovereign state or intergovernmental organization to an inventor or assignee for a limited period of time in exchange for detailed public disclosure of an invention", "commemorating fealty and filial piety", "in the stems and roots of certain vascular plants", "when the cell is undergoing the metaphase of cell division ( where all chromosomes are aligned in the center of the cell in their condensed form )", "euro", "Robin Hood\\'s A Holy Grail", "Snowshoe Hare", "February 13, 1946", "Crystal Dynamics", "Congo River", "Jason Chaffetz", "Da Vinci Code", "Jenny Sanford", "Khrushchev", "Julie Andrews", "Headless Horseman", "Leo Frank, a northern Jew who'd moved to Atlanta to supervise the National Pencil Company factory."], "metric_results": {"EM": 0.546875, "QA-F1": 0.6821122289228696}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, false, true, false, false, true, false, true, false, false, true, false, false, false, true, false, false, false, true, true, true, true, true, false, true, true, false, false, true, true, true, false, true, true, false, true, true, false, false, false, false, true, false, false, true, false, false, true, true, true, true, true, false, true, true, true, false], "QA-F1": [1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.9824561403508771, 1.0, 0.0, 0.0, 1.0, 0.8, 1.0, 0.6666666666666666, 0.6666666666666666, 1.0, 0.4, 0.0, 0.2857142857142857, 1.0, 0.8571428571428572, 0.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.5, 0.7368421052631579, 0.17391304347826086, 0.4615384615384615, 1.0, 0.2, 0.0909090909090909, 1.0, 0.3333333333333333, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.25]}}, "before_error_ids": ["mrqa_naturalquestions-validation-7158", "mrqa_naturalquestions-validation-8873", "mrqa_naturalquestions-validation-9129", "mrqa_naturalquestions-validation-3362", "mrqa_naturalquestions-validation-1801", "mrqa_naturalquestions-validation-1770", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-8206", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-9878", "mrqa_naturalquestions-validation-495", "mrqa_naturalquestions-validation-7443", "mrqa_naturalquestions-validation-8186", "mrqa_naturalquestions-validation-4540", "mrqa_naturalquestions-validation-6193", "mrqa_naturalquestions-validation-5123", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-7598", "mrqa_naturalquestions-validation-5555", "mrqa_naturalquestions-validation-8707", "mrqa_naturalquestions-validation-5241", "mrqa_naturalquestions-validation-6148", "mrqa_naturalquestions-validation-688", "mrqa_naturalquestions-validation-8254", "mrqa_naturalquestions-validation-8159", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3305", "mrqa_newsqa-validation-3374", "mrqa_newsqa-validation-3849"], "SR": 0.546875, "CSR": 0.5297539893617021, "EFR": 0.9310344827586207, "Overall": 0.6980170694240646}, {"timecode": 94, "before_eval_results": {"predictions": ["direct scattering and inverse scattering", "Thon Maker", "Battle of Chester", "youngest TV director ever", "28 January 1864", "on the shore, associated with \"the Waters of Death\" that Gilgamesh had to cross to reach Utnapishtim, the far-away\"", "playback singer, director, writer and producer", "Cielos del Sur S.A.", "English", "National Basketball Development League", "Neville Chamberlain", "Boulder High School in Boulder, Colorado", "Revengers Tragedy", "Japan", "rural", "6", "Larry Alphonso Johnson Jr.", "Gabriel Jesus Iglesias", "January 4, 1821", "Pantone Matching System (PMS)", "Las Vegas Boulevard", "intelligent design", "Barbara Ryan Coleman", "Jack Elam", "Adelaide Botanic Garden, Hutt Street, and Victoria Park", "Naruto Uzumaki", "Kansas", "nearly 80 years", "Chevrolet Corvette Stingrays", "thirtysomething", "eclectic mix of musical styles incorporating elements of disco, pop, reggae, and early rap music", "The Wachowskis", "our le M\u00e9rite", "mastered recordings for many well known musicians, including David Bowie", "Drowning Pool", "casino video game co-developed by Cinemaware and Virtual Toysfor the PlayStation 2 and Xbox gaming consoles", "the Food and Agriculture Organization", "forms", "Bharat Ratna", "Cesar Millan", "Eurasia", "Beauty and the Beast", "Bardney", "Holinshed's Chronicle", "June 26, 2018", "University Grants Commission", "25 October 1921", "Australian", "Bonkyll Castle", "February 5, 2015", "William Shakespeare", "giant planet", "alveolar process", "Duisburg", "Hugh Quarshie", "Maria Alexandrovna", "Tokyo", "Provo, Utah, hospital,", "Madonna", "Fareed Zakaria", "Easter Island", "Eli Whitney", "Today", "25"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7108493890977443}, "metric_results_detailed": {"EM": [false, false, true, true, true, false, false, false, true, true, true, false, true, false, true, false, true, false, false, false, true, true, false, true, true, true, true, true, true, false, false, true, false, false, true, false, true, false, true, true, true, true, true, true, false, false, true, false, true, true, false, false, true, true, true, false, true, false, true, true, true, true, false, true], "QA-F1": [0.8333333333333333, 0.8, 1.0, 1.0, 1.0, 0.3157894736842105, 0.2857142857142857, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.47619047619047616, 1.0, 0.6666666666666666, 0.33333333333333337, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.4, 1.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-706", "mrqa_hotpotqa-validation-839", "mrqa_hotpotqa-validation-2121", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-5255", "mrqa_hotpotqa-validation-436", "mrqa_hotpotqa-validation-2351", "mrqa_hotpotqa-validation-2344", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-4457", "mrqa_hotpotqa-validation-4558", "mrqa_hotpotqa-validation-2634", "mrqa_hotpotqa-validation-5478", "mrqa_hotpotqa-validation-2696", "mrqa_hotpotqa-validation-5042", "mrqa_hotpotqa-validation-1206", "mrqa_hotpotqa-validation-1606", "mrqa_hotpotqa-validation-3468", "mrqa_hotpotqa-validation-5406", "mrqa_hotpotqa-validation-5241", "mrqa_hotpotqa-validation-4047", "mrqa_hotpotqa-validation-2510", "mrqa_naturalquestions-validation-5155", "mrqa_triviaqa-validation-514", "mrqa_newsqa-validation-1831", "mrqa_searchqa-validation-2056"], "SR": 0.59375, "CSR": 0.5304276315789473, "EFR": 1.0, "Overall": 0.7119449013157895}, {"timecode": 95, "before_eval_results": {"predictions": ["250 million copies", "Ben Ainslie", "1978", "The Golden Egg", "Scott Mosier", "1945", "Roy Spencer", "1964", "the Union Hill section of Kansas City, Missouri", "VH1", "January", "Russian", "Harrison Ford", "July 25", "Hong Kong Mak\u00e9l\u00e9l\u00e9", "singer", "\"Northern Lights\"", "coca wine", "Mach number", "Jordan Ridgeway", "Maine", "Encore Las Vegas", "\"Baa, Baa, Black sheep\"", "It's Always Sunny in Philadelphia", "John Francis Kelly", "Madeleine L' Engle", "1972", "John F. Kennedy", "paracyclist", "Mandarin", "Kevin Spacey", "pro-vice-chancellor", "Song Il-gon", "Teen Titans Go!", "Mickey Mouser", "Grammy Award", "right-hand", "Sheen Michaels Entertainment", "Sela Ann Ward", "whaling", "Houston Rockets", "DI Humphrey Goodman", "Daphnis et Chlo\u00e9", "Nebraska Cornhuskers women's basketball", "Metro-Goldwyn-Mayer", "Doomtree", "My Backyard", "Sun Woong", "American professional boxer", "Aloe Vera of America", "creeks", "1992", "the Second Continental Congress", "Roger Dean Stadium", "cirrocumulus", "Compiegne", "San Diego Opera", "Sunday afternoon.", "The Da Vinci Code", "Dogpatch Labs", "iceberg", "a hydrogen fuel cell", "Queen Victoria", "Venus Williams"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7191964285714285}, "metric_results_detailed": {"EM": [false, true, true, false, false, false, true, false, false, true, false, false, false, false, false, true, true, true, false, true, false, true, true, true, true, false, true, false, true, false, true, true, true, true, false, false, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, false, true, true, true, true, true, true], "QA-F1": [0.8, 1.0, 1.0, 0.0, 0.0, 0.5, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.5714285714285715, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.4, 1.0, 0.8571428571428571, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-74", "mrqa_hotpotqa-validation-5147", "mrqa_hotpotqa-validation-3264", "mrqa_hotpotqa-validation-5551", "mrqa_hotpotqa-validation-4280", "mrqa_hotpotqa-validation-3806", "mrqa_hotpotqa-validation-65", "mrqa_hotpotqa-validation-5809", "mrqa_hotpotqa-validation-5332", "mrqa_hotpotqa-validation-5447", "mrqa_hotpotqa-validation-4833", "mrqa_hotpotqa-validation-4102", "mrqa_hotpotqa-validation-4196", "mrqa_hotpotqa-validation-5569", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-2619", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-5071", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-1332", "mrqa_hotpotqa-validation-5435", "mrqa_triviaqa-validation-4831", "mrqa_newsqa-validation-3838"], "SR": 0.640625, "CSR": 0.5315755208333333, "EFR": 1.0, "Overall": 0.7121744791666667}, {"timecode": 96, "before_eval_results": {"predictions": ["Prince Sung-won", "1927", "16,116", "the 2012 Summer Olympics", "at the end of the 18th century", "1942", "The Highwaymen", "Estadio de L\u00f3pez Cort\u00e1zar", "Syracuse", "Kim Jong-hyun", "The Bears", "Gillian Anderson", "the alternative rock band R.E.M.", "Ice Princess", "The Summer Olympic Games", "Oldham County, Kentucky", "1896", "Oracle Corporation", "143,007", "SARS", "5.3", "chocolate-colored", "The 1962 Italian Grand Prix", "1908", "Neneh Cherry", "The Marshall Mathers", "Love Streams", "In a Better World", "the Shropshire Union Canal", "Easy", "The Killer", "2015", "Dutch", "Lowestoft, Suffolk", "Trey Parker", "\"Pimp My Ride\"", "Big 12 Conference", "Hillsborough County", "Dancing with the Stars", "a wooden Indian", "John Francis Kelly", "early Romantic period", "$700 million", "the Sun", "Bhushan Patel", "1692", "authority over interstate commerce including navigation by river", "The Wu-Tang Clan", "\"Kids\"", "Mortal Kombat", "Kew Gardens", "third", "May 2016", "Kristy Swanson", "colonel", "(Conan) Doyle", "isosceles", "put a lid on the marking of Ashura", "Afghanistan,", "homicide", "The Challah", "leather", "the cornea", "Eleanor Roosevelt"], "metric_results": {"EM": 0.703125, "QA-F1": 0.7871167027417028}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, false, true, true, false, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, false, true, true, true, true, true, true, true, false, false, true, true, false, true, true, true, true, false, true, false, true, false, true, false, true, true, false, true, true, true, true, false, true, false, true, false, true, true, true], "QA-F1": [0.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5714285714285715, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.4, 1.0, 0.18181818181818182, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3971", "mrqa_hotpotqa-validation-2376", "mrqa_hotpotqa-validation-5480", "mrqa_hotpotqa-validation-4316", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-2618", "mrqa_hotpotqa-validation-4804", "mrqa_hotpotqa-validation-447", "mrqa_hotpotqa-validation-3344", "mrqa_hotpotqa-validation-4011", "mrqa_hotpotqa-validation-2286", "mrqa_hotpotqa-validation-148", "mrqa_hotpotqa-validation-164", "mrqa_hotpotqa-validation-1401", "mrqa_hotpotqa-validation-2482", "mrqa_naturalquestions-validation-303", "mrqa_triviaqa-validation-2789", "mrqa_newsqa-validation-1218", "mrqa_searchqa-validation-13280"], "SR": 0.703125, "CSR": 0.5333440721649485, "EFR": 0.8947368421052632, "Overall": 0.6914755578540424}, {"timecode": 97, "before_eval_results": {"predictions": ["(Eddie) Redmayne", "Caucasus range", "David Bowie", "Steve Davis", "Granada", "Article III", "Karl Marx", "The Paramounts", "Marilyn Monroe", "cyanoguttatus", "1957", "1912", "transsexual", "Michael V. Gazzo", "south of England", "Scotland Yard", "Inverness-shire", "fair", "a parachute", "Rudyard Kipling", "1921", "\u201cHamish Macbeth\u201d", "Desdemona", "avocado", "Frans Hals", "centre-right", "Ford", "black bean", "Frank Sinatra", "1830", "w WJacobs", "Parthenon", "Paddy Doherty", "Thomas Aquinas", "ap\u00e9ro", "an elephant", "Tigran Petrosyan", "end with a vowel", "Westminster Abbey", "Canada", "Seal", "Edward VII", "Tombstone", "Santo Ant\u00e3o", "Mr. Men and 33 Little Miss", "Worcester Cathedral", "Uranus", "December 7, 1941", "the middle ear", "Kerri Strug", "Neil Armstrong", "Ant & Dec", "John Ernest Crawford", "March 1930", "Gillian Anderson", "Electronic Attack Squadron 135", "95 AD", "170", "\"Californiaornication\"", "Carol Fowler", "awe-inspiring", "the Caspian Sea", "Francisco Pizarro", "1922 to 1991"], "metric_results": {"EM": 0.4375, "QA-F1": 0.5105902777777778}, "metric_results_detailed": {"EM": [true, false, true, false, true, false, true, false, true, false, true, false, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, false, false, true, false, true, true, true, false, true, false, false, true, true, true, true, true, false, false, false, false, false, false, false, true, true, true, true, true, false, true, true, false, false, false, false, true, false], "QA-F1": [1.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.4444444444444444, 0.6666666666666666, 0.0, 0.5, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0]}}, "before_error_ids": ["mrqa_triviaqa-validation-4131", "mrqa_triviaqa-validation-5467", "mrqa_triviaqa-validation-5066", "mrqa_triviaqa-validation-4459", "mrqa_triviaqa-validation-1316", "mrqa_triviaqa-validation-7266", "mrqa_triviaqa-validation-7293", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-6728", "mrqa_triviaqa-validation-6630", "mrqa_triviaqa-validation-7326", "mrqa_triviaqa-validation-5204", "mrqa_triviaqa-validation-6617", "mrqa_triviaqa-validation-2651", "mrqa_triviaqa-validation-1602", "mrqa_triviaqa-validation-5738", "mrqa_triviaqa-validation-3700", "mrqa_triviaqa-validation-3878", "mrqa_triviaqa-validation-3536", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-1752", "mrqa_triviaqa-validation-3730", "mrqa_triviaqa-validation-3744", "mrqa_triviaqa-validation-3800", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-782", "mrqa_triviaqa-validation-1718", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-2035", "mrqa_triviaqa-validation-229", "mrqa_hotpotqa-validation-2058", "mrqa_newsqa-validation-3100", "mrqa_newsqa-validation-4053", "mrqa_searchqa-validation-8143", "mrqa_searchqa-validation-15233", "mrqa_naturalquestions-validation-7080"], "SR": 0.4375, "CSR": 0.5323660714285714, "EFR": 0.9722222222222222, "Overall": 0.7067770337301587}, {"timecode": 98, "before_eval_results": {"predictions": ["sent an e-mail to reporters Wednesday with the subject line \"Vice presidential...\"", "Afghanistan's", "digging at the site", "Several suspects are believed to have engaged in \"nationwide shopping sprees, staying at five-star hotels, renting luxury automobiles and private jets, and purchasing tens of thousands of dollars worth of high-end electronics and expensive handbags", "his health and about a comeback.", "poems", "then-presidential candidate Barack Obama,", "Gloria Allred,", "581 points", "The Everglades, known as the River of Grass,", "Herman Cain", "Brett Cummins,", "3-0", "what caused the collapse of the building which contained the city's historical archives, bringing down parts of the two nearby structures.", "Mobile County Circuit Judge Herman Thomas", "celebrities", "Iraqi economy.\"", "Phillip A. Myers.", "I brought \"Swingin' Down the Lane.\"", "to share personal information.\"", "London and Buenos Aires", "Sheik Mohammed Ali", "Iraqi Prime Minister Nouri al-Maliki", "Egypt", "Ali -- who was crowned Sportsman of the Century by Sports Illustrated in 1999 -- had his Irish heritage uncovered by genealogists in 2002.", "rayny ford and husband Bill Klein,", "win over Oscar de la Hoya, Britain's Ricky Hatton and Cotto.", "Austin, Texas,", "17-month", "him to be included in the family allowance,", "Manmohan Singh's", "the war of words in the Republican Party centered around Rush Limbaugh.", "for death squad killings carried out during his rule in the 1990s.", "100 meter", "sniff out cell phones.", "Fayetteville, North Carolina,", "Bill Haas", "Consumer Reports", "28", "step up.\"", "42 years old", "since 1983.", "health ailment or beauty concern.\"", "100", "Al Alberto Espinoza", "Derek Mears", "\"I want to get the job done. We have identified a problem -- let's go solve it together.\"", "fastest circumnavigation of the globe in a powerboat", "$106,482,500", "fifth successive season", "Haeftling,", "Armenia", "Asuka", "Bart Millard", "nismo", "stone arch bridges", "jMW Turner", "the Marx Brothers", "India", "World War I", "a supervisor", "Shakespeare in Love", "w. Somerset maugham", "leicestershire"], "metric_results": {"EM": 0.421875, "QA-F1": 0.5607742860209965}, "metric_results_detailed": {"EM": [true, true, false, false, false, true, false, false, false, false, true, true, true, false, false, false, true, true, false, true, false, false, true, true, false, false, false, true, false, false, true, false, false, true, true, false, true, true, true, true, true, false, false, false, false, true, false, false, true, false, true, false, true, true, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 0.0, 0.9210526315789475, 0.0, 1.0, 0.3333333333333333, 0.0, 0.6666666666666666, 0.2857142857142857, 1.0, 1.0, 1.0, 0.38095238095238093, 0.7272727272727272, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.6153846153846153, 0.0, 1.0, 0.0, 0.15384615384615383, 1.0, 0.0, 0.2105263157894737, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.9090909090909091, 0.6666666666666666, 0.6666666666666666, 1.0, 0.1, 0.2857142857142857, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_newsqa-validation-1067", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-447", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-2844", "mrqa_newsqa-validation-1729", "mrqa_newsqa-validation-3910", "mrqa_newsqa-validation-3242", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-2272", "mrqa_newsqa-validation-1336", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-810", "mrqa_newsqa-validation-3319", "mrqa_newsqa-validation-1383", "mrqa_newsqa-validation-3506", "mrqa_newsqa-validation-234", "mrqa_newsqa-validation-1952", "mrqa_newsqa-validation-2326", "mrqa_newsqa-validation-1989", "mrqa_newsqa-validation-1391", "mrqa_newsqa-validation-377", "mrqa_newsqa-validation-3323", "mrqa_newsqa-validation-2082", "mrqa_newsqa-validation-2476", "mrqa_newsqa-validation-2745", "mrqa_newsqa-validation-2541", "mrqa_newsqa-validation-2749", "mrqa_naturalquestions-validation-2024", "mrqa_triviaqa-validation-5314", "mrqa_triviaqa-validation-3928", "mrqa_triviaqa-validation-5307", "mrqa_hotpotqa-validation-1985", "mrqa_hotpotqa-validation-3049", "mrqa_hotpotqa-validation-3326", "mrqa_searchqa-validation-11769", "mrqa_searchqa-validation-14191"], "SR": 0.421875, "CSR": 0.53125, "EFR": 0.972972972972973, "Overall": 0.7067039695945946}, {"timecode": 99, "UKR": 0.701171875, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-1002", "mrqa_hotpotqa-validation-1014", "mrqa_hotpotqa-validation-1069", "mrqa_hotpotqa-validation-1298", "mrqa_hotpotqa-validation-1314", "mrqa_hotpotqa-validation-136", "mrqa_hotpotqa-validation-1374", "mrqa_hotpotqa-validation-1508", "mrqa_hotpotqa-validation-1511", "mrqa_hotpotqa-validation-153", "mrqa_hotpotqa-validation-1618", "mrqa_hotpotqa-validation-1707", "mrqa_hotpotqa-validation-1746", "mrqa_hotpotqa-validation-1834", "mrqa_hotpotqa-validation-2073", "mrqa_hotpotqa-validation-2075", "mrqa_hotpotqa-validation-2094", "mrqa_hotpotqa-validation-2132", "mrqa_hotpotqa-validation-2181", "mrqa_hotpotqa-validation-2245", "mrqa_hotpotqa-validation-2255", "mrqa_hotpotqa-validation-227", "mrqa_hotpotqa-validation-24", "mrqa_hotpotqa-validation-2425", "mrqa_hotpotqa-validation-2463", "mrqa_hotpotqa-validation-2489", "mrqa_hotpotqa-validation-251", "mrqa_hotpotqa-validation-2640", "mrqa_hotpotqa-validation-2652", "mrqa_hotpotqa-validation-2718", "mrqa_hotpotqa-validation-2764", "mrqa_hotpotqa-validation-277", "mrqa_hotpotqa-validation-2798", "mrqa_hotpotqa-validation-2844", "mrqa_hotpotqa-validation-2852", "mrqa_hotpotqa-validation-2862", "mrqa_hotpotqa-validation-3024", "mrqa_hotpotqa-validation-3145", "mrqa_hotpotqa-validation-3278", "mrqa_hotpotqa-validation-3289", "mrqa_hotpotqa-validation-3301", "mrqa_hotpotqa-validation-3387", "mrqa_hotpotqa-validation-3658", "mrqa_hotpotqa-validation-367", "mrqa_hotpotqa-validation-3679", "mrqa_hotpotqa-validation-3713", "mrqa_hotpotqa-validation-3753", "mrqa_hotpotqa-validation-377", "mrqa_hotpotqa-validation-3771", "mrqa_hotpotqa-validation-3996", "mrqa_hotpotqa-validation-4124", "mrqa_hotpotqa-validation-4169", "mrqa_hotpotqa-validation-4378", "mrqa_hotpotqa-validation-4435", "mrqa_hotpotqa-validation-4514", "mrqa_hotpotqa-validation-4674", "mrqa_hotpotqa-validation-475", "mrqa_hotpotqa-validation-4868", "mrqa_hotpotqa-validation-4888", "mrqa_hotpotqa-validation-5179", "mrqa_hotpotqa-validation-5201", "mrqa_hotpotqa-validation-5206", "mrqa_hotpotqa-validation-5221", "mrqa_hotpotqa-validation-5223", "mrqa_hotpotqa-validation-5251", "mrqa_hotpotqa-validation-5283", "mrqa_hotpotqa-validation-5310", "mrqa_hotpotqa-validation-5311", "mrqa_hotpotqa-validation-5412", "mrqa_hotpotqa-validation-5531", "mrqa_hotpotqa-validation-5630", "mrqa_hotpotqa-validation-5780", "mrqa_hotpotqa-validation-5840", "mrqa_hotpotqa-validation-585", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-5895", "mrqa_hotpotqa-validation-634", "mrqa_hotpotqa-validation-657", "mrqa_hotpotqa-validation-70", "mrqa_hotpotqa-validation-719", "mrqa_hotpotqa-validation-751", "mrqa_hotpotqa-validation-900", "mrqa_hotpotqa-validation-906", "mrqa_hotpotqa-validation-969", "mrqa_naturalquestions-validation-10077", "mrqa_naturalquestions-validation-10138", "mrqa_naturalquestions-validation-1044", "mrqa_naturalquestions-validation-10446", "mrqa_naturalquestions-validation-10454", "mrqa_naturalquestions-validation-10693", "mrqa_naturalquestions-validation-1134", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-124", "mrqa_naturalquestions-validation-1255", "mrqa_naturalquestions-validation-1282", "mrqa_naturalquestions-validation-1310", "mrqa_naturalquestions-validation-1329", "mrqa_naturalquestions-validation-1704", "mrqa_naturalquestions-validation-1756", "mrqa_naturalquestions-validation-1840", "mrqa_naturalquestions-validation-2067", "mrqa_naturalquestions-validation-2151", "mrqa_naturalquestions-validation-228", "mrqa_naturalquestions-validation-2299", "mrqa_naturalquestions-validation-2349", "mrqa_naturalquestions-validation-2459", "mrqa_naturalquestions-validation-2471", "mrqa_naturalquestions-validation-2506", "mrqa_naturalquestions-validation-2555", "mrqa_naturalquestions-validation-2621", "mrqa_naturalquestions-validation-2686", "mrqa_naturalquestions-validation-269", "mrqa_naturalquestions-validation-2781", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2951", "mrqa_naturalquestions-validation-3033", "mrqa_naturalquestions-validation-3288", "mrqa_naturalquestions-validation-3325", "mrqa_naturalquestions-validation-3432", "mrqa_naturalquestions-validation-3613", "mrqa_naturalquestions-validation-4043", "mrqa_naturalquestions-validation-4092", "mrqa_naturalquestions-validation-4156", "mrqa_naturalquestions-validation-4385", "mrqa_naturalquestions-validation-4501", "mrqa_naturalquestions-validation-4572", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4701", "mrqa_naturalquestions-validation-4775", "mrqa_naturalquestions-validation-4960", "mrqa_naturalquestions-validation-5093", "mrqa_naturalquestions-validation-5109", "mrqa_naturalquestions-validation-5118", "mrqa_naturalquestions-validation-5582", "mrqa_naturalquestions-validation-5600", "mrqa_naturalquestions-validation-5703", "mrqa_naturalquestions-validation-5761", "mrqa_naturalquestions-validation-5769", "mrqa_naturalquestions-validation-5781", "mrqa_naturalquestions-validation-582", "mrqa_naturalquestions-validation-5826", "mrqa_naturalquestions-validation-6075", "mrqa_naturalquestions-validation-6232", "mrqa_naturalquestions-validation-6408", "mrqa_naturalquestions-validation-6426", "mrqa_naturalquestions-validation-6794", "mrqa_naturalquestions-validation-7062", "mrqa_naturalquestions-validation-7206", "mrqa_naturalquestions-validation-7250", "mrqa_naturalquestions-validation-7366", "mrqa_naturalquestions-validation-7591", "mrqa_naturalquestions-validation-7624", "mrqa_naturalquestions-validation-7661", "mrqa_naturalquestions-validation-7827", "mrqa_naturalquestions-validation-7886", "mrqa_naturalquestions-validation-7967", "mrqa_naturalquestions-validation-8014", "mrqa_naturalquestions-validation-8046", "mrqa_naturalquestions-validation-8056", "mrqa_naturalquestions-validation-8329", "mrqa_naturalquestions-validation-8526", "mrqa_naturalquestions-validation-8594", "mrqa_naturalquestions-validation-863", "mrqa_naturalquestions-validation-8741", "mrqa_naturalquestions-validation-8832", "mrqa_naturalquestions-validation-9092", "mrqa_naturalquestions-validation-9208", "mrqa_naturalquestions-validation-9219", "mrqa_naturalquestions-validation-9276", "mrqa_naturalquestions-validation-9400", "mrqa_naturalquestions-validation-9404", "mrqa_naturalquestions-validation-9435", "mrqa_naturalquestions-validation-9454", "mrqa_naturalquestions-validation-9595", "mrqa_naturalquestions-validation-9816", "mrqa_naturalquestions-validation-9830", "mrqa_naturalquestions-validation-9875", "mrqa_naturalquestions-validation-989", "mrqa_naturalquestions-validation-9987", "mrqa_newsqa-validation-1146", "mrqa_newsqa-validation-1160", "mrqa_newsqa-validation-1179", "mrqa_newsqa-validation-1265", "mrqa_newsqa-validation-1285", "mrqa_newsqa-validation-1357", "mrqa_newsqa-validation-1386", "mrqa_newsqa-validation-1407", "mrqa_newsqa-validation-1475", "mrqa_newsqa-validation-1525", "mrqa_newsqa-validation-1599", "mrqa_newsqa-validation-1663", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1673", "mrqa_newsqa-validation-1687", "mrqa_newsqa-validation-1744", "mrqa_newsqa-validation-1752", "mrqa_newsqa-validation-1857", "mrqa_newsqa-validation-189", "mrqa_newsqa-validation-2014", "mrqa_newsqa-validation-2139", "mrqa_newsqa-validation-221", "mrqa_newsqa-validation-2213", "mrqa_newsqa-validation-2223", "mrqa_newsqa-validation-2230", "mrqa_newsqa-validation-2234", "mrqa_newsqa-validation-2255", "mrqa_newsqa-validation-2281", "mrqa_newsqa-validation-2348", "mrqa_newsqa-validation-2361", "mrqa_newsqa-validation-2379", "mrqa_newsqa-validation-2405", "mrqa_newsqa-validation-2412", "mrqa_newsqa-validation-2589", "mrqa_newsqa-validation-2614", "mrqa_newsqa-validation-2616", "mrqa_newsqa-validation-2621", "mrqa_newsqa-validation-2675", "mrqa_newsqa-validation-268", "mrqa_newsqa-validation-2684", "mrqa_newsqa-validation-2692", "mrqa_newsqa-validation-2701", "mrqa_newsqa-validation-2738", "mrqa_newsqa-validation-2901", "mrqa_newsqa-validation-2926", "mrqa_newsqa-validation-2956", "mrqa_newsqa-validation-2993", "mrqa_newsqa-validation-3035", "mrqa_newsqa-validation-3064", "mrqa_newsqa-validation-307", "mrqa_newsqa-validation-3077", "mrqa_newsqa-validation-308", "mrqa_newsqa-validation-3118", "mrqa_newsqa-validation-3124", "mrqa_newsqa-validation-3158", "mrqa_newsqa-validation-3170", "mrqa_newsqa-validation-3199", "mrqa_newsqa-validation-3231", "mrqa_newsqa-validation-3258", "mrqa_newsqa-validation-3305", "mrqa_newsqa-validation-3372", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3375", "mrqa_newsqa-validation-3464", "mrqa_newsqa-validation-3485", "mrqa_newsqa-validation-3536", "mrqa_newsqa-validation-3564", "mrqa_newsqa-validation-3597", "mrqa_newsqa-validation-3675", "mrqa_newsqa-validation-3713", "mrqa_newsqa-validation-3752", "mrqa_newsqa-validation-3872", "mrqa_newsqa-validation-3884", "mrqa_newsqa-validation-3925", "mrqa_newsqa-validation-3941", "mrqa_newsqa-validation-3966", "mrqa_newsqa-validation-400", "mrqa_newsqa-validation-4029", "mrqa_newsqa-validation-4043", "mrqa_newsqa-validation-4051", "mrqa_newsqa-validation-4061", "mrqa_newsqa-validation-4079", "mrqa_newsqa-validation-4159", "mrqa_newsqa-validation-4177", "mrqa_newsqa-validation-4189", "mrqa_newsqa-validation-437", "mrqa_newsqa-validation-443", "mrqa_newsqa-validation-491", "mrqa_newsqa-validation-506", "mrqa_newsqa-validation-587", "mrqa_newsqa-validation-664", "mrqa_newsqa-validation-678", "mrqa_newsqa-validation-705", "mrqa_newsqa-validation-735", "mrqa_newsqa-validation-942", "mrqa_newsqa-validation-965", "mrqa_newsqa-validation-970", "mrqa_searchqa-validation-10077", "mrqa_searchqa-validation-10146", "mrqa_searchqa-validation-10231", "mrqa_searchqa-validation-10351", "mrqa_searchqa-validation-10527", "mrqa_searchqa-validation-10763", "mrqa_searchqa-validation-10771", "mrqa_searchqa-validation-10879", "mrqa_searchqa-validation-11028", "mrqa_searchqa-validation-11077", "mrqa_searchqa-validation-11089", "mrqa_searchqa-validation-11111", "mrqa_searchqa-validation-11151", "mrqa_searchqa-validation-11196", "mrqa_searchqa-validation-11599", "mrqa_searchqa-validation-11976", "mrqa_searchqa-validation-11985", "mrqa_searchqa-validation-12092", "mrqa_searchqa-validation-12660", "mrqa_searchqa-validation-12942", "mrqa_searchqa-validation-12974", "mrqa_searchqa-validation-13042", "mrqa_searchqa-validation-13182", "mrqa_searchqa-validation-13352", "mrqa_searchqa-validation-13625", "mrqa_searchqa-validation-13654", "mrqa_searchqa-validation-13659", "mrqa_searchqa-validation-1371", "mrqa_searchqa-validation-13891", "mrqa_searchqa-validation-14001", "mrqa_searchqa-validation-14197", "mrqa_searchqa-validation-14198", "mrqa_searchqa-validation-14519", "mrqa_searchqa-validation-14614", "mrqa_searchqa-validation-14625", "mrqa_searchqa-validation-14705", "mrqa_searchqa-validation-14740", "mrqa_searchqa-validation-14770", "mrqa_searchqa-validation-14783", "mrqa_searchqa-validation-14805", "mrqa_searchqa-validation-15045", "mrqa_searchqa-validation-15157", "mrqa_searchqa-validation-15235", "mrqa_searchqa-validation-15394", "mrqa_searchqa-validation-15659", "mrqa_searchqa-validation-15746", "mrqa_searchqa-validation-15843", "mrqa_searchqa-validation-15883", "mrqa_searchqa-validation-16119", "mrqa_searchqa-validation-16140", "mrqa_searchqa-validation-16335", "mrqa_searchqa-validation-16515", "mrqa_searchqa-validation-1655", "mrqa_searchqa-validation-16644", "mrqa_searchqa-validation-16751", "mrqa_searchqa-validation-16786", "mrqa_searchqa-validation-16962", "mrqa_searchqa-validation-1741", "mrqa_searchqa-validation-1771", "mrqa_searchqa-validation-1897", "mrqa_searchqa-validation-2116", "mrqa_searchqa-validation-2215", "mrqa_searchqa-validation-2228", "mrqa_searchqa-validation-2392", "mrqa_searchqa-validation-2436", "mrqa_searchqa-validation-2801", "mrqa_searchqa-validation-2832", "mrqa_searchqa-validation-3026", "mrqa_searchqa-validation-3087", "mrqa_searchqa-validation-334", "mrqa_searchqa-validation-3347", "mrqa_searchqa-validation-3469", "mrqa_searchqa-validation-3496", "mrqa_searchqa-validation-3567", "mrqa_searchqa-validation-3760", "mrqa_searchqa-validation-3825", "mrqa_searchqa-validation-386", "mrqa_searchqa-validation-4023", "mrqa_searchqa-validation-4481", "mrqa_searchqa-validation-4512", "mrqa_searchqa-validation-4792", "mrqa_searchqa-validation-4808", "mrqa_searchqa-validation-5112", "mrqa_searchqa-validation-543", "mrqa_searchqa-validation-5466", "mrqa_searchqa-validation-5625", "mrqa_searchqa-validation-5649", "mrqa_searchqa-validation-5669", "mrqa_searchqa-validation-5733", "mrqa_searchqa-validation-5906", "mrqa_searchqa-validation-6142", "mrqa_searchqa-validation-629", "mrqa_searchqa-validation-6344", "mrqa_searchqa-validation-6616", "mrqa_searchqa-validation-6736", "mrqa_searchqa-validation-6759", "mrqa_searchqa-validation-69", "mrqa_searchqa-validation-6941", "mrqa_searchqa-validation-7139", "mrqa_searchqa-validation-7166", "mrqa_searchqa-validation-7440", "mrqa_searchqa-validation-746", "mrqa_searchqa-validation-7551", "mrqa_searchqa-validation-7753", "mrqa_searchqa-validation-8139", "mrqa_searchqa-validation-8239", "mrqa_searchqa-validation-826", "mrqa_searchqa-validation-8285", "mrqa_searchqa-validation-8293", "mrqa_searchqa-validation-8374", "mrqa_searchqa-validation-8383", "mrqa_searchqa-validation-8459", "mrqa_searchqa-validation-8575", "mrqa_searchqa-validation-861", "mrqa_searchqa-validation-8702", "mrqa_searchqa-validation-8721", "mrqa_searchqa-validation-8761", "mrqa_searchqa-validation-8933", "mrqa_searchqa-validation-9119", "mrqa_searchqa-validation-940", "mrqa_searchqa-validation-9461", "mrqa_searchqa-validation-9682", "mrqa_searchqa-validation-9752", "mrqa_searchqa-validation-9942", "mrqa_squad-validation-10026", "mrqa_squad-validation-10227", "mrqa_squad-validation-112", "mrqa_squad-validation-1204", "mrqa_squad-validation-1454", "mrqa_squad-validation-1758", "mrqa_squad-validation-1759", "mrqa_squad-validation-2225", "mrqa_squad-validation-2365", "mrqa_squad-validation-2466", "mrqa_squad-validation-2784", "mrqa_squad-validation-3080", "mrqa_squad-validation-3110", "mrqa_squad-validation-3130", "mrqa_squad-validation-3581", "mrqa_squad-validation-3632", "mrqa_squad-validation-4259", "mrqa_squad-validation-457", "mrqa_squad-validation-4621", "mrqa_squad-validation-4770", "mrqa_squad-validation-5010", "mrqa_squad-validation-5651", "mrqa_squad-validation-5784", "mrqa_squad-validation-5913", "mrqa_squad-validation-6166", "mrqa_squad-validation-6694", "mrqa_squad-validation-6789", "mrqa_squad-validation-6947", "mrqa_squad-validation-7214", "mrqa_squad-validation-7269", "mrqa_squad-validation-7521", "mrqa_squad-validation-7547", "mrqa_squad-validation-7596", "mrqa_squad-validation-7848", "mrqa_squad-validation-8052", "mrqa_squad-validation-8151", "mrqa_squad-validation-8733", "mrqa_squad-validation-8830", "mrqa_squad-validation-9233", "mrqa_squad-validation-930", "mrqa_squad-validation-9311", "mrqa_squad-validation-962", "mrqa_squad-validation-9816", "mrqa_squad-validation-9859", "mrqa_triviaqa-validation-1184", "mrqa_triviaqa-validation-1216", "mrqa_triviaqa-validation-124", "mrqa_triviaqa-validation-1450", "mrqa_triviaqa-validation-1547", "mrqa_triviaqa-validation-1552", "mrqa_triviaqa-validation-1567", "mrqa_triviaqa-validation-1585", "mrqa_triviaqa-validation-1923", "mrqa_triviaqa-validation-1968", "mrqa_triviaqa-validation-2038", "mrqa_triviaqa-validation-2200", "mrqa_triviaqa-validation-2208", "mrqa_triviaqa-validation-2246", "mrqa_triviaqa-validation-2505", "mrqa_triviaqa-validation-2668", "mrqa_triviaqa-validation-2912", "mrqa_triviaqa-validation-3160", "mrqa_triviaqa-validation-3190", "mrqa_triviaqa-validation-3226", "mrqa_triviaqa-validation-3249", "mrqa_triviaqa-validation-3400", "mrqa_triviaqa-validation-3434", "mrqa_triviaqa-validation-3471", "mrqa_triviaqa-validation-3707", "mrqa_triviaqa-validation-3796", "mrqa_triviaqa-validation-3823", "mrqa_triviaqa-validation-3908", "mrqa_triviaqa-validation-4365", "mrqa_triviaqa-validation-4385", "mrqa_triviaqa-validation-4404", "mrqa_triviaqa-validation-4483", "mrqa_triviaqa-validation-4519", "mrqa_triviaqa-validation-4660", "mrqa_triviaqa-validation-4737", "mrqa_triviaqa-validation-4831", "mrqa_triviaqa-validation-4876", "mrqa_triviaqa-validation-4890", "mrqa_triviaqa-validation-5158", "mrqa_triviaqa-validation-5309", "mrqa_triviaqa-validation-5361", "mrqa_triviaqa-validation-5457", "mrqa_triviaqa-validation-5644", "mrqa_triviaqa-validation-5706", "mrqa_triviaqa-validation-5809", "mrqa_triviaqa-validation-5820", "mrqa_triviaqa-validation-5832", "mrqa_triviaqa-validation-5851", "mrqa_triviaqa-validation-5891", "mrqa_triviaqa-validation-6239", "mrqa_triviaqa-validation-6300", "mrqa_triviaqa-validation-6329", "mrqa_triviaqa-validation-642", "mrqa_triviaqa-validation-6540", "mrqa_triviaqa-validation-6636", "mrqa_triviaqa-validation-6679", "mrqa_triviaqa-validation-6729", "mrqa_triviaqa-validation-6985", "mrqa_triviaqa-validation-7031", "mrqa_triviaqa-validation-712", "mrqa_triviaqa-validation-7145", "mrqa_triviaqa-validation-7219", "mrqa_triviaqa-validation-727", "mrqa_triviaqa-validation-7350", "mrqa_triviaqa-validation-7511", "mrqa_triviaqa-validation-7615", "mrqa_triviaqa-validation-83", "mrqa_triviaqa-validation-958"], "OKR": 0.80078125, "KG": 0.471875, "before_eval_results": {"predictions": ["Mount Rainier, Washington", "Douglas Jackson", "Austral L\u00edneas A\u00e9reas", "2", "Craig William Macneill", "USS Essex", "8,648", "three", "Jeffrey Adam \"Duff\" Goldman", "North Dakota", "most performed song of all time", "Oregon Ducks football", "rural Arkansas", "2011 Pulitzer Prize in General Nonfiction", "Golden Gate", "GZA", "Broadcasting House in London", "smith", "Barney Miller", "Lily Hampton", "President of the United States", "Big Machine Records", "constant support from propaganda campaigns", "\"The Heirs\" (2013), \"Descendants of the Sun\" (2016) and \"Fight for My Way\" ( 2017).", "Saturday Night Live", "god", "Tumi Holdings, Inc.", "Black Ravens", "commercial", "Suspiria", "Silvia Navarro", "22,500", "Warsaw, Poland", "Nelson County", "Han Moleman", "25 million", "Athenion", "James G. Kiernan", "MC5", "Naval Weapons Station Yorktown", "Arab", "Linda Ronstadt", "English", "August 19, 2013", "tropical terrestrial ecoregions of the Americas and the entire South American temperate zone", "The Omega Man", "five-time", "Stephen John Coogan", "13 May 2018", "Kevin Spacey", "Stalybridge Celtic", "a competitor or team in a sport or other tournament who is given a preliminary ranking for the purposes of the draw", "Frank Zappa", "In 1989", "applea", "fred Trueman", "Scotland", "Chesley \"Sully\" Sullenberger", "smitho", "Friday,", "Lifeboat", "a yobibyte", "stock-broker", "Zulfikar Ali Bhutto"], "metric_results": {"EM": 0.59375, "QA-F1": 0.7117261904761905}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, false, true, true, true, true, false, false, false, false, true, false, false, true, true, true, true, false, true, false, true, true, false, true, true, false, true, true, false, true, true, true, false, true, false, false, false, false, false, true, false, true, true, true, false, false, true, false, false, true, true, true, false, true, true, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 0.5, 0.5714285714285715, 0.0, 1.0, 0.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 0.2857142857142857, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.5, 0.8, 0.0, 0.3333333333333333, 0.16666666666666669, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.6666666666666666, 0.16, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.4]}}, "before_error_ids": ["mrqa_hotpotqa-validation-3017", "mrqa_hotpotqa-validation-1750", "mrqa_hotpotqa-validation-5715", "mrqa_hotpotqa-validation-2031", "mrqa_hotpotqa-validation-2805", "mrqa_hotpotqa-validation-5307", "mrqa_hotpotqa-validation-2523", "mrqa_hotpotqa-validation-2382", "mrqa_hotpotqa-validation-516", "mrqa_hotpotqa-validation-1581", "mrqa_hotpotqa-validation-4946", "mrqa_hotpotqa-validation-264", "mrqa_hotpotqa-validation-5552", "mrqa_hotpotqa-validation-150", "mrqa_hotpotqa-validation-5130", "mrqa_hotpotqa-validation-5160", "mrqa_hotpotqa-validation-3197", "mrqa_hotpotqa-validation-2282", "mrqa_hotpotqa-validation-4109", "mrqa_hotpotqa-validation-2156", "mrqa_naturalquestions-validation-10325", "mrqa_naturalquestions-validation-934", "mrqa_triviaqa-validation-7095", "mrqa_newsqa-validation-2470", "mrqa_searchqa-validation-572", "mrqa_triviaqa-validation-5432"], "SR": 0.59375, "CSR": 0.531875, "EFR": 1.0, "Overall": 0.701140625}]}