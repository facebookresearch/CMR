{"method_class": "er", "base_model_args": "Namespace(base_model_path='out/mrqa_squad_bart-base_1029_upstream_model//best-model.pt', model_type='facebook/bart-base')", "debugger_args": "Namespace(adam_epsilon=1e-08, ckpt_dir='experiments/ckpt_dirs/qa/er/QA_er_lr=5e-5_ep=3_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8', gradient_accumulation_steps=1, inference_query_size=1, init_memory_cache_path='na', kg_eval_freq=10, kg_eval_mode='metric', kr_eval_freq=10, kr_eval_mode='metric', learning_rate=5e-05, local_adapt_lr=1e-05, max_grad_norm=0.1, memory_key_encoder='facebook/bart-base', memory_path='experiments/ckpt_dirs/qa/er/QA_er_lr=5e-5_ep=3_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8/memory_dict.pkl', memory_store_rate=1.0, num_adapt_epochs=0, num_epochs=3.0, okr_sample_seed=1337, okr_sample_size=512, replay_candidate_size=8, replay_frequency=1, replay_size=64, save_ckpt_freq=10, skip_instant_eval=False, total_steps=10000, upstream_sample_ratio=0.5, use_replay_mix=True, warmup_steps=0, weight_decay=0.01)", "data_args": "Namespace(accumulate_eval_freq=-1, append_another_bos=1, do_lowercase=False, heldout_submission_data='experiments/eval_data/qa/heldout_eval.jsonl', max_input_length=888, max_output_length=50, max_timecode=100, num_beams=3, predict_batch_size=48, result_file='experiments/results/qa/QA_er_lr=5e-5_ep=3_rs=64_rf=1_T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8_result.json', submission_stream_data='experiments/eval_data/qa/submission_stream.T=100,b=64,alpha=0.9,beta=0.5,gamma=0.8.json', task_name='mrqa', train_batch_size=8, upstream_data_path='data/mrqa_squad/mrqa_squad_train.jsonl', upstream_eval_data='experiments/eval_data/qa/upstream_eval.jsonl')", "model_update_steps": 336, "online_eval_results": [{"timecode": 0, "UKR": 0.802734375, "KG": 0.3125, "before_eval_results": {"predictions": ["a plug valve", "1550", "French Louisiana west of the Mississippi River", "2012", "carbon dioxide", "the Lisbon Treaty", "all colors", "in the chloroplasts of C4 plants", "An attorney", "democracy", "The Greens", "third", "Enthusiastic teachers", "expositions", "no French regular army troops were stationed in North America", "estates of the Holy Roman Empire", "Stromatoveris", "2011", "Louis Pasteur", "the owner", "Time Lord", "mosaic floors", "economic", "1893", "environmental factors like light color and intensity", "Gandhi", "deforestation", "Middle Rhine Valley", "pump this into the mesoglea", "low-light conditions", "No Child Left Behind", "one way streets", "\u20ac25,000 per year", "England, Wales, Scotland, Denmark, Sweden, Switzerland", "unbalanced torque", "Ulaanbaatar", "power", "very weak", "Judith Merril", "Gender pay gap", "the Ilkhanate", "it is open to all irrespective of age, literacy level and has materials relevant to people of all walks of life", "University of Chicago campus", "3D printing technology", "1957", "2000", "a certain number of teacher's salaries are paid by the State", "the Dutch Republic", "San Jose Marriott", "April 20", "the Commission", "evacuate the cylinder", "the Swiss canton of Graub\u00fcnden in the southeastern Swiss Alps", "Hurricane Beryl", "temperature and light", "terra nullius", "growth", "human", "the \u2018combs\u2019", "1978", "non-Catholics", "Sanders", "vice president", "700 employees"], "metric_results": {"EM": 0.828125, "QA-F1": 0.8576388888888888}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, false, true, true, true, true, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, false], "QA-F1": [1.0, 1.0, 0.4444444444444444, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4444444444444445, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-10143", "mrqa_squad-validation-8841", "mrqa_squad-validation-2145", "mrqa_squad-validation-739", "mrqa_squad-validation-4452", "mrqa_squad-validation-3019", "mrqa_squad-validation-7449", "mrqa_squad-validation-9173", "mrqa_squad-validation-7364", "mrqa_squad-validation-9764", "mrqa_squad-validation-7051"], "SR": 0.828125, "CSR": 0.828125, "EFR": 0.8181818181818182, "Overall": 0.8231534090909092}, {"timecode": 1, "before_eval_results": {"predictions": ["1986", "Peridinin", "standardized", "50% to 60%", "Stromatoveris", "lower incomes", "Fort Duquesne", "Katharina von Bora", "Miller", "women", "Three's Company", "Frank Marx", "architect or engineer", "$2 million", "superintendent of New York City schools", "Santa Clara, California", "Kingdom of Prussia", "the same league as the Asian Economic Tigers", "Palestine", "Aristotle and Archimedes", "in the chloroplasts of C4 plants", "Outlaws", "increased blood flow into tissue", "Edgar Scherick", "14th to the 19th century", "Gibraltar and the \u00c5land islands", "the Evangelical Lutheran Church", "oxygen", "the BBC National Orchestra of Wales", "Thanksgiving", "the founding of new Protestant churches", "impossible", "Venus", "those who proceed to secondary school or vocational training", "zoning and building code requirements", "Ikh Zasag", "Central Bridge", "the Holy Roman Empire", "William Tyndale", "1935", "seven", "Grumman", "1191", "Maciot de Bethencourt", "Euclid", "case law by the Court of Justice", "long, slender tentacles", "mesoglea", "1970s", "white", "misguided", "2014", "Reconstruction and the Gilded Age", "European Parliament and the Council of the European Union", "the State Board of Education, the Superintendent of Public Instruction, the State Education Agency or other governmental bodies", "Manakin Episcopal Church", "Nicholas Stone", "ongoing tectonic subsidence", "the release of her eponymous debut album the following year", "a form of business network", "the Capitol held its first session of the United States Congress with both chambers in session on November 17, 1800", "It is the currency used by the institutions of the European Union", "Djokovic", "\"colorful\" mercenary group fought for Padua, Florence & other Italian city-states"], "metric_results": {"EM": 0.8125, "QA-F1": 0.8364955357142857}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, false, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, false, true, false, true, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.2857142857142857, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7332", "mrqa_squad-validation-8459", "mrqa_squad-validation-10339", "mrqa_squad-validation-10321", "mrqa_squad-validation-3021", "mrqa_squad-validation-3946", "mrqa_squad-validation-1906", "mrqa_squad-validation-5588", "mrqa_naturalquestions-validation-1912", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-1187", "mrqa_searchqa-validation-2579"], "SR": 0.8125, "CSR": 0.8203125, "retrieved_ids": ["mrqa_squad-train-35022", "mrqa_squad-train-75146", "mrqa_squad-train-29907", "mrqa_squad-train-22914", "mrqa_squad-train-85715", "mrqa_squad-train-54772", "mrqa_squad-train-76813", "mrqa_squad-train-83180", "mrqa_squad-train-4315", "mrqa_squad-train-39769", "mrqa_squad-train-55088", "mrqa_squad-train-48768", "mrqa_squad-train-51313", "mrqa_squad-train-80012", "mrqa_squad-train-67537", "mrqa_squad-train-42986", "mrqa_squad-train-54923", "mrqa_squad-train-85948", "mrqa_squad-train-17177", "mrqa_squad-train-286", "mrqa_squad-train-79598", "mrqa_squad-train-26443", "mrqa_squad-train-73738", "mrqa_squad-train-61062", "mrqa_squad-train-9928", "mrqa_squad-train-24127", "mrqa_squad-train-44267", "mrqa_squad-train-34442", "mrqa_squad-train-20002", "mrqa_squad-train-19373", "mrqa_squad-train-47430", "mrqa_squad-train-64282", "mrqa_squad-validation-739", "mrqa_squad-validation-3019", "mrqa_squad-validation-10143", "mrqa_squad-validation-2145", "mrqa_squad-validation-8841", "mrqa_squad-validation-4452", "mrqa_squad-validation-9173", "mrqa_squad-validation-7364", "mrqa_squad-validation-7051", "mrqa_squad-validation-7449", "mrqa_squad-validation-9764"], "EFR": 1.0, "Overall": 0.91015625}, {"timecode": 2, "before_eval_results": {"predictions": ["Lek", "prohibited emigration", "The Private Education Student Financial Assistance", "lower-paid", "Labor Party", "time and storage", "special efforts", "rhetoric", "British", "a year", "Genghis Khan", "a supervisory church body", "77", "a cubic interpolation formula", "King Sigismund III Vasa", "1835", "the exploitation of the valuable assets and supplies of the nation that was conquered", "poor management, internal divisions, and effective Canadian scouts", "five", "liquid oxygen", "Gosforth Park", "Metropolitan Police Authority", "18 February 1546", "2005", "1.7 billion years ago", "Mike Carey", "coal", "18 February", "Stanford University", "1976", "LOVE Radio", "ambiguity", "Khasar", "Sky Digital", "99.4", "about a third", "the issue of laity having a voice and vote in the administration of the church", "1995", "Endosymbiotic gene transfer", "rocketry and manned spaceflight", "linebacker", "feed water", "Sir Edward Poynter", "oxygen", "August 1967", "Velamen parallelum", "human rights abuses and war crimes", "three", "Lowry Digital", "the worst-case time complexity T(n)", "2010", "33 feet", "Buffalo Lookout", "Missouri", "The User State Migration Tool", "1773", "Cadmium", "October 6, 2017", "11 p.m. to 3 a.m", "Haliaeetus", "Sir Henry Bartle Frere", "James Zeebo", "through the weekend", "Tom Hanks"], "metric_results": {"EM": 0.828125, "QA-F1": 0.8766540750915751}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, true, true, true, true, false, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.33333333333333337, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6153846153846153, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.8571428571428571, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-7357", "mrqa_squad-validation-2886", "mrqa_squad-validation-1672", "mrqa_squad-validation-7612", "mrqa_squad-validation-6171", "mrqa_squad-validation-3812", "mrqa_squad-validation-9717", "mrqa_squad-validation-1708", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-6211"], "SR": 0.828125, "CSR": 0.8229166666666666, "retrieved_ids": ["mrqa_squad-train-51723", "mrqa_squad-train-65615", "mrqa_squad-train-85967", "mrqa_squad-train-79786", "mrqa_squad-train-41149", "mrqa_squad-train-61945", "mrqa_squad-train-48129", "mrqa_squad-train-11511", "mrqa_squad-train-10977", "mrqa_squad-train-60754", "mrqa_squad-train-53374", "mrqa_squad-train-5769", "mrqa_squad-train-34564", "mrqa_squad-train-60596", "mrqa_squad-train-25929", "mrqa_squad-train-81802", "mrqa_squad-train-43596", "mrqa_squad-train-30819", "mrqa_squad-train-23374", "mrqa_squad-train-12581", "mrqa_squad-train-60003", "mrqa_squad-train-43110", "mrqa_squad-train-15309", "mrqa_squad-train-51651", "mrqa_squad-train-76033", "mrqa_squad-train-38386", "mrqa_squad-train-74978", "mrqa_squad-train-63123", "mrqa_squad-train-14848", "mrqa_squad-train-45452", "mrqa_squad-train-57634", "mrqa_squad-train-19764", "mrqa_naturalquestions-validation-1912", "mrqa_squad-validation-7449", "mrqa_squad-validation-3019", "mrqa_squad-validation-7364", "mrqa_squad-validation-4452", "mrqa_squad-validation-10339", "mrqa_squad-validation-10321", "mrqa_squad-validation-3021", "mrqa_squad-validation-7332", "mrqa_squad-validation-8459", "mrqa_squad-validation-5588", "mrqa_squad-validation-7051", "mrqa_squad-validation-8841", "mrqa_searchqa-validation-2579", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-191", "mrqa_squad-validation-3946", "mrqa_squad-validation-10143", "mrqa_squad-validation-2145", "mrqa_squad-validation-739", "mrqa_squad-validation-1906", "mrqa_squad-validation-9764", "mrqa_squad-validation-9173"], "EFR": 1.0, "Overall": 0.9114583333333333}, {"timecode": 3, "before_eval_results": {"predictions": ["female", "1884", "Sayyid Abul Ala Maududi", "a family member", "James E. Webb", "the Lutheran and Reformed states in Germany and Scandinavia", "the phycoerytherin", "can also concentrate wealth, pass environmental costs on to society, and abuse workers and consumers", "swimming-plates", "10 July 1856", "130 million cubic foot", "teleforce", "Heinrich Himmler", "34\u201319", "Baptism", "Decision problems", "customs", "1953", "The Day of the Doctor", "Muhammad Khan", "Sun Life Stadium", "the Council", "February 9, 1953", "March", "sea gooseberry", "1961", "the Trio Tribe", "Dai Setsen", "the Late Medieval Catholic Church", "January 1979", "phagocytic", "Rankine cycle", "$2.2 billion", "Seine", "Newton's Law of Gravitation", "15 February 1546", "Marquis de la Jonqui\u00e8re", "BBC Dead Ringers", "Kenyans for Kenya", "Fresno", "Saudi", "the Presiding Officer", "an intuitive understanding", "default emission factors", "Inherited wealth", "Michael P. Millardi", "Goldman Sachs", "the BRAAVOO website", "the world's catalog of ideas", "the central U.S. state", "the Latin word was loaned into Old English", "the children were nestled all snug in their beds", "the U.N. organization raised the temples of Abu Simbel", "Leyden jar", "a better-paid legislator", "the last two of these had libretti by Gaetano Rossi", "the borders of Germany, and a part of French Flanders", "70%", "the First Macy's Thanksgiving Day Parade", "the Great keepsake ornaments", "the British", "early 1980s", "April 1917", "close quarters and poor hygiene"], "metric_results": {"EM": 0.625, "QA-F1": 0.6759706439393939}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, false, true, true, true, true, false, true, true, true, false, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, false, true, true, false, false, false, false, false, false, true, false, false, false, false, false, false, false, false, true, true], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.5454545454545454, 0.6666666666666666, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.33333333333333337, 0.0, 0.0, 0.8, 1.0, 1.0]}}, "before_error_ids": ["mrqa_squad-validation-3270", "mrqa_squad-validation-8595", "mrqa_squad-validation-7525", "mrqa_squad-validation-2595", "mrqa_squad-validation-6072", "mrqa_squad-validation-5860", "mrqa_squad-validation-5262", "mrqa_squad-validation-10369", "mrqa_squad-validation-3863", "mrqa_squad-validation-7457", "mrqa_searchqa-validation-123", "mrqa_searchqa-validation-8711", "mrqa_searchqa-validation-4319", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-3451", "mrqa_searchqa-validation-14194", "mrqa_searchqa-validation-9536", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-2568", "mrqa_searchqa-validation-4367", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-1156", "mrqa_searchqa-validation-11367", "mrqa_naturalquestions-validation-844"], "SR": 0.625, "CSR": 0.7734375, "retrieved_ids": ["mrqa_squad-train-40862", "mrqa_squad-train-81958", "mrqa_squad-train-13263", "mrqa_squad-train-81424", "mrqa_squad-train-78938", "mrqa_squad-train-9826", "mrqa_squad-train-59882", "mrqa_squad-train-33313", "mrqa_squad-train-26026", "mrqa_squad-train-24041", "mrqa_squad-train-18874", "mrqa_squad-train-5425", "mrqa_squad-train-80035", "mrqa_squad-train-73777", "mrqa_squad-train-42814", "mrqa_squad-train-2695", "mrqa_squad-train-29373", "mrqa_squad-train-33925", "mrqa_squad-train-55635", "mrqa_squad-train-2404", "mrqa_squad-train-84007", "mrqa_squad-train-80675", "mrqa_squad-train-61714", "mrqa_squad-train-6029", "mrqa_squad-train-20075", "mrqa_squad-train-12884", "mrqa_squad-train-5442", "mrqa_squad-train-59228", "mrqa_squad-train-64741", "mrqa_squad-train-72788", "mrqa_squad-train-30634", "mrqa_squad-train-6761", "mrqa_naturalquestions-validation-191", "mrqa_squad-validation-3946", "mrqa_squad-validation-5588", "mrqa_searchqa-validation-2579", "mrqa_squad-validation-10143", "mrqa_squad-validation-4452", "mrqa_squad-validation-2886", "mrqa_squad-validation-6171", "mrqa_squad-validation-2145", "mrqa_squad-validation-1708", "mrqa_squad-validation-7612", "mrqa_squad-validation-7051", "mrqa_squad-validation-7332", "mrqa_squad-validation-10321", "mrqa_squad-validation-7449", "mrqa_squad-validation-3019", "mrqa_squad-validation-7357", "mrqa_naturalquestions-validation-6211", "mrqa_squad-validation-9173", "mrqa_squad-validation-3021", "mrqa_naturalquestions-validation-5780", "mrqa_squad-validation-10339", "mrqa_squad-validation-739", "mrqa_squad-validation-1906", "mrqa_squad-validation-3812", "mrqa_squad-validation-9764", "mrqa_squad-validation-9717", "mrqa_squad-validation-8841", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-1187", "mrqa_squad-validation-7364", "mrqa_naturalquestions-validation-1912"], "EFR": 0.9166666666666666, "Overall": 0.8450520833333333}, {"timecode": 4, "before_eval_results": {"predictions": ["boom-and-bust cycles", "The Prince of P\u0142ock", "hormones", "1840", "occupational stress", "in the parts of the internal canal network", "separating faith and reason", "Tesla Electric Company", "African-American", "Thomson", "1905", "\"Nun komm, der Heiland\"", "John Fox", "in all health care settings", "cut in half", "the study of rocks", "colonies", "lower wages", "geophysical", "Protestantism", "social power and wealth", "2,900 kilometres", "Elie Metchnikoff", "an algorithm", "Immediately after Decision Time", "Confucian propriety and ancestor veneration", "25-minute", "eight", "elude host immune responses", "Pusey Library", "inequality", "designs into reality", "cytokines", "requiring his arrest", "wide sidewalks", "other members", "Air Force", "an occupancy permit", "reactive allotrope of oxygen", "Nederrijn at Angeren", "a multi-cultural city", "pump water out of the mesoglea", "Tim Johnson", "Australia", "a judicial officer", "mathematical model", "Henry Purcell", "Ram Nath Kovind", "embryo", "Cheap trick", "Sandy Knox and Billy Stritch", "Hudson Bay", "Etienne de Mestre", "a bow bridge with 16 arches shielded by ice guards", "1991", "Nicole Gale Anderson", "1", "sedimentary", "Mrs. Wolowitz", "plate tectonics", "Colombia", "Yolande of Brienne", "Kris Allen", "Colombian"], "metric_results": {"EM": 0.640625, "QA-F1": 0.7048137626262627}, "metric_results_detailed": {"EM": [true, true, true, true, true, false, false, true, true, true, true, false, true, false, true, true, true, false, true, false, false, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, true, false, true, true, true, false, false, false, false, true, true, false, true, false, true, false, false, false, true, true, false, false, false, false, false, true, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.0, 1.0, 1.0, 1.0, 1.0, 0.888888888888889, 1.0, 0.888888888888889, 1.0, 1.0, 1.0, 0.5, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3636363636363636, 0.0, 1.0, 1.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4539", "mrqa_squad-validation-2463", "mrqa_squad-validation-2456", "mrqa_squad-validation-6319", "mrqa_squad-validation-7338", "mrqa_squad-validation-2943", "mrqa_squad-validation-8093", "mrqa_squad-validation-3497", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-2476", "mrqa_naturalquestions-validation-4674", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-3672", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-7080", "mrqa_naturalquestions-validation-8792", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-4002", "mrqa_triviaqa-validation-5855", "mrqa_hotpotqa-validation-4815", "mrqa_searchqa-validation-172"], "SR": 0.640625, "CSR": 0.746875, "retrieved_ids": ["mrqa_squad-train-11499", "mrqa_squad-train-85688", "mrqa_squad-train-14006", "mrqa_squad-train-8219", "mrqa_squad-train-84349", "mrqa_squad-train-4702", "mrqa_squad-train-73024", "mrqa_squad-train-37168", "mrqa_squad-train-66826", "mrqa_squad-train-20574", "mrqa_squad-train-73155", "mrqa_squad-train-39411", "mrqa_squad-train-10077", "mrqa_squad-train-67443", "mrqa_squad-train-58650", "mrqa_squad-train-14445", "mrqa_squad-train-50017", "mrqa_squad-train-34654", "mrqa_squad-train-76697", "mrqa_squad-train-79612", "mrqa_squad-train-82942", "mrqa_squad-train-9939", "mrqa_squad-train-1454", "mrqa_squad-train-9980", "mrqa_squad-train-57404", "mrqa_squad-train-80782", "mrqa_squad-train-86532", "mrqa_squad-train-69368", "mrqa_squad-train-23409", "mrqa_squad-train-50296", "mrqa_squad-train-9579", "mrqa_squad-train-46303", "mrqa_naturalquestions-validation-844", "mrqa_squad-validation-3021", "mrqa_squad-validation-3863", "mrqa_searchqa-validation-2568", "mrqa_searchqa-validation-4367", "mrqa_naturalquestions-validation-1187", "mrqa_squad-validation-7332", "mrqa_squad-validation-2886", "mrqa_squad-validation-10321", "mrqa_squad-validation-7357", "mrqa_squad-validation-1672", "mrqa_squad-validation-2145", "mrqa_squad-validation-9764", "mrqa_searchqa-validation-8711", "mrqa_squad-validation-6072", "mrqa_searchqa-validation-11367", "mrqa_squad-validation-5860", "mrqa_squad-validation-3946", "mrqa_squad-validation-6171", "mrqa_squad-validation-7525", "mrqa_naturalquestions-validation-1912", "mrqa_squad-validation-10339", "mrqa_squad-validation-1906", "mrqa_squad-validation-7612", "mrqa_squad-validation-10143", "mrqa_squad-validation-3270", "mrqa_naturalquestions-validation-9712", "mrqa_squad-validation-8459", "mrqa_squad-validation-7364", "mrqa_naturalquestions-validation-5780", "mrqa_squad-validation-7449", "mrqa_squad-validation-3812"], "EFR": 0.9565217391304348, "Overall": 0.8516983695652174}, {"timecode": 5, "before_eval_results": {"predictions": ["former flooded terraces", "20th century", "1974", "ABC", "dictatorial authority", "Ben Johnston", "quantum", "Book of Exodus", "Synthetic aperture radar", "Mission Impossible", "patients' prescriptions and patient safety issues", "No, that's no good", "1697", "3 January 1521", "magma", "a \"principal hostile country\"", "Jan Hus", "Newton", "Croatia", "2011", "Swynnerton Plan", "machine gun", "Theatre Museum", "August 10, 1948", "they are distinct or equal classes", "the 2004 Treaty establishing a Constitution for Europe", "Serge Chermayeff", "Thomas Edison", "Mnemiopsis", "the flail of God", "Woodward Park", "The Melbourne Cricket Ground", "Wednesdays", "most common", "concentration gradient", "tears and urine", "six years", "plants and algae", "Republic Day", "1913", "Yuzuru Hanyu", "Konakuppakatil Gopinathan Balakrishnan", "1942", "March 2016", "Texas, Oklahoma, and the surrounding Great Plains to adjacent regions", "a balance sheet as an asset", "Mayor Hudnut", "1995", "William the Conqueror", "1922", "an anembryonic gestation", "Bemis Heights", "9pm ET ( UTC - 5 )", "twice", "S\u00e9rgio Mendes", "Lituya Bay in Alaska", "Sarai", "routing table", "The euro", "Ultraviolet Ultraviolet", "2000", "KCNA", "Peachtree Street", "Viets"], "metric_results": {"EM": 0.59375, "QA-F1": 0.6739020942825291}, "metric_results_detailed": {"EM": [true, true, true, false, false, false, false, true, true, true, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, false, true, true, true, true, false, true, true, true, false, false, false, true, false, true, true, true, true, false, false, false, false, false, true, false, true, false, false, true, false, true, false, true, true, false, true, false, false, false], "QA-F1": [1.0, 1.0, 1.0, 0.0, 0.4, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2608695652173913, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.923076923076923, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.8, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.19999999999999998, 0.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 0.3076923076923077, 0.5714285714285715, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-5818", "mrqa_squad-validation-1827", "mrqa_squad-validation-1566", "mrqa_squad-validation-10388", "mrqa_squad-validation-3770", "mrqa_squad-validation-1780", "mrqa_squad-validation-3985", "mrqa_squad-validation-4572", "mrqa_squad-validation-8904", "mrqa_squad-validation-6439", "mrqa_squad-validation-8471", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-3686", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-5721", "mrqa_triviaqa-validation-2749", "mrqa_newsqa-validation-2404", "mrqa_searchqa-validation-14371", "mrqa_searchqa-validation-15169"], "SR": 0.59375, "CSR": 0.7213541666666667, "retrieved_ids": ["mrqa_squad-train-52547", "mrqa_squad-train-48978", "mrqa_squad-train-50669", "mrqa_squad-train-62976", "mrqa_squad-train-14137", "mrqa_squad-train-14393", "mrqa_squad-train-32729", "mrqa_squad-train-34529", "mrqa_squad-train-21243", "mrqa_squad-train-60623", "mrqa_squad-train-36588", "mrqa_squad-train-19324", "mrqa_squad-train-85994", "mrqa_squad-train-59808", "mrqa_squad-train-40043", "mrqa_squad-train-77475", "mrqa_squad-train-25723", "mrqa_squad-train-38876", "mrqa_squad-train-5889", "mrqa_squad-train-71297", "mrqa_squad-train-9628", "mrqa_squad-train-37939", "mrqa_squad-train-79019", "mrqa_squad-train-63358", "mrqa_squad-train-18631", "mrqa_squad-train-26891", "mrqa_squad-train-7650", "mrqa_squad-train-64218", "mrqa_squad-train-23509", "mrqa_squad-train-76398", "mrqa_squad-train-80880", "mrqa_squad-train-56500", "mrqa_squad-validation-6072", "mrqa_searchqa-validation-15194", "mrqa_naturalquestions-validation-8792", "mrqa_squad-validation-6319", "mrqa_triviaqa-validation-5855", "mrqa_squad-validation-3019", "mrqa_squad-validation-7338", "mrqa_squad-validation-4452", "mrqa_squad-validation-2943", "mrqa_squad-validation-5262", "mrqa_searchqa-validation-123", "mrqa_squad-validation-739", "mrqa_naturalquestions-validation-9712", "mrqa_squad-validation-2456", "mrqa_searchqa-validation-14194", "mrqa_squad-validation-8459", "mrqa_hotpotqa-validation-4815", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8356", "mrqa_squad-validation-7457", "mrqa_naturalquestions-validation-5780", "mrqa_squad-validation-8841", "mrqa_squad-validation-2886", "mrqa_squad-validation-2145", "mrqa_naturalquestions-validation-7080", "mrqa_searchqa-validation-3451", "mrqa_naturalquestions-validation-1987", "mrqa_squad-validation-1708", "mrqa_squad-validation-3946", "mrqa_squad-validation-3270", "mrqa_squad-validation-8093", "mrqa_searchqa-validation-9536"], "EFR": 1.0, "Overall": 0.8606770833333334}, {"timecode": 6, "before_eval_results": {"predictions": ["four", "2 million", "ranges from 53% in Botswana to -40% in Bahrain", "Pliocene", "relationship between teachers and children", "LeGrande", "sixth", "Jason Bourne", "11.1", "60,000", "University of Chicago College Bowl Team", "organized labor", "Santa Clara Marriott", "oxygen chambers", "two", "two catechisms", "Cologne", "1991", "Silk Road", "Surveyor 3", "145", "growth and investment", "the centers were computer service bureaus, offering batch processing services", "Vampire bats", "antiforms", "U. S. flags left on the Moon during the Apollo missions were found to still be standing", "weight", "Genghis Khan's Mongolia", "oil was priced in dollars", "Beyonc\u00e9 and Bruno Mars", "a university or college", "1 million", "pseudorandom number generators", "Japan", "the Coriolis force", "Mickey Rourke", "May 2016", "Nicklaus", "Superstition Mountains", "Panama Canal Authority", "silk, hair / fur", "France", "two", "Sebastian Vettel", "April 10, 2018", "Gorakhpur", "How I Met Your Mother", "elected", "December 15, 2016", "Abraham Gottlob Werner", "Jourdan Miller", "1991", "Samantha Jo", "the Greek name", "Broken Hill and Sydney", "159", "China", "Judiththia Aline Keppel", "medellin", "Crown", "Expedia", "the Large Orbiting Telescope", "Zed", "the character and resolve of the American people"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6882111378205128}, "metric_results_detailed": {"EM": [true, true, false, true, true, true, true, true, false, false, true, false, true, true, true, true, true, true, true, true, true, true, false, true, true, false, true, false, false, true, true, true, false, true, false, true, true, true, false, false, false, false, true, true, true, false, false, false, false, false, true, false, false, false, true, true, false, false, true, false, true, false, true, false], "QA-F1": [1.0, 1.0, 0.19999999999999998, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.15384615384615383, 1.0, 0.6666666666666666, 0.09523809523809523, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 0.25, 0.25, 0.5, 0.4, 1.0, 1.0, 1.0, 0.5, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.125, 0.5714285714285715, 1.0, 0.5, 1.0, 0.3333333333333333, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7445", "mrqa_squad-validation-6965", "mrqa_squad-validation-5435", "mrqa_squad-validation-7422", "mrqa_squad-validation-4838", "mrqa_squad-validation-3998", "mrqa_squad-validation-6228", "mrqa_squad-validation-3718", "mrqa_squad-validation-9161", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-1415", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-5531", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-9737", "mrqa_naturalquestions-validation-2102", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-9818", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-6106", "mrqa_hotpotqa-validation-1471", "mrqa_searchqa-validation-10372", "mrqa_newsqa-validation-429"], "SR": 0.578125, "CSR": 0.7008928571428572, "retrieved_ids": ["mrqa_squad-train-64985", "mrqa_squad-train-6646", "mrqa_squad-train-80879", "mrqa_squad-train-38150", "mrqa_squad-train-7238", "mrqa_squad-train-79007", "mrqa_squad-train-44882", "mrqa_squad-train-4190", "mrqa_squad-train-31025", "mrqa_squad-train-62024", "mrqa_squad-train-12865", "mrqa_squad-train-61070", "mrqa_squad-train-24423", "mrqa_squad-train-55015", "mrqa_squad-train-68960", "mrqa_squad-train-79021", "mrqa_squad-train-71336", "mrqa_squad-train-6412", "mrqa_squad-train-84234", "mrqa_squad-train-2748", "mrqa_squad-train-67336", "mrqa_squad-train-44261", "mrqa_squad-train-82976", "mrqa_squad-train-58108", "mrqa_squad-train-76128", "mrqa_squad-train-41206", "mrqa_squad-train-80248", "mrqa_squad-train-46464", "mrqa_squad-train-1322", "mrqa_squad-train-22881", "mrqa_squad-train-8161", "mrqa_squad-train-72006", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-3672", "mrqa_naturalquestions-validation-1911", "mrqa_squad-validation-10321", "mrqa_naturalquestions-validation-8792", "mrqa_squad-validation-1906", "mrqa_squad-validation-2456", "mrqa_squad-validation-2943", "mrqa_naturalquestions-validation-8116", "mrqa_newsqa-validation-2404", "mrqa_naturalquestions-validation-8765", "mrqa_squad-validation-7457", "mrqa_squad-validation-3021", "mrqa_hotpotqa-validation-4815", "mrqa_squad-validation-4452", "mrqa_squad-validation-5818", "mrqa_squad-validation-5262", "mrqa_naturalquestions-validation-5780", "mrqa_squad-validation-5860", "mrqa_naturalquestions-validation-2476", "mrqa_searchqa-validation-15194", "mrqa_squad-validation-2595", "mrqa_naturalquestions-validation-8239", "mrqa_squad-validation-10339", "mrqa_squad-validation-9173", "mrqa_squad-validation-6072", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-6211", "mrqa_searchqa-validation-3451", "mrqa_naturalquestions-validation-1912", "mrqa_squad-validation-8595", "mrqa_naturalquestions-validation-3686"], "EFR": 0.8518518518518519, "Overall": 0.7763723544973545}, {"timecode": 7, "before_eval_results": {"predictions": ["Director", "travel literature, cartography, geography, and scientific education", "oxygen chambers", "Graham Gano", "Two", "In 1066", "2008", "Mojave Desert", "to build a nationwide network in the UK", "St. Lawrence and Mississippi watersheds", "27", "4000", "Rhine Gorge", "Helicoid stromal thylakoids", "16,000", "impact process effects", "Asian, African and Caribbean countries", "Warner Bros. Presents", "pharmacists", "high-frequency power experiments", "4:51", "Kabaty Forest", "ABC Circle A", "strong sedimentation in the western Rhine Delta", "The European Commission", "SAP Center", "respiration", "352", "eliminate the accusing law", "October 6, 2004", "\"The Day of the Doctor\"", "Pakistan", "November 1999", "September 6, 2019", "English", "During the fourth season", "once", "Nick Kroll", "The Ranch is an American comedy web television series starring Ashton Kutcher, Danny Masterson, Debra Winger, Elisha Cuthbert, and Sam Elliott that debuted in 2016 on Netflix", "Billy Gibbons", "Star Wars", "generally involved in the regulation of blood pressure", "31", "in the 1970s", "Consular Report of Birth Abroad for children born to U.S. citizens ( who are also eligible for citizenship ), including births on military bases in foreign territory", "Art Carney", "accomplish the objectives of the organization", "The female excavates a hole, using her hind legs, and lays her eggs in it.", "By late 1922", "Category 4", "September 2017", "3 September, after a British ultimatum to Germany to cease military operations was ignored, Britain and France declared war on Germany", "southern USA, although its prickled trunks and limbs require safety buffer zones, especially around the trunks, in order to protect people and domesticated animals from its prickles. Ceiba speciosa", "Terrell Owens", "since 3, 1, and 4 are the first three significant digits of \u03c0", "five", "Robert Duncan McNeill -- Kevin Corrigan   Anthony De Longis -- Blade   Tony Carroll -- Beast Man   Pons Maar -- Saurod   Robert Towers -- Karg   Peter Brooks -- Narrator", "Hampton Court Palace", "Sela Ward", "Alice Horton", "the popular television game show Jeopardy!", "Benjamin Britten", "A SCALENE triangle", "NOW Magazine"], "metric_results": {"EM": 0.5625, "QA-F1": 0.6162337662337662}, "metric_results_detailed": {"EM": [true, true, true, true, true, true, true, true, false, true, true, true, true, true, false, true, false, true, false, false, true, true, false, true, true, true, true, true, true, true, true, true, true, true, false, false, false, true, false, false, false, false, false, false, false, true, true, false, false, true, true, false, false, true, false, false, false, true, false, false, false, true, false, false], "QA-F1": [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2222222222222222, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 1.0, 1.0, 0.1818181818181818, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.5, 0.0, 1.0, 0.04761904761904763, 0.0, 0.0, 0.0, 0.0, 0.6666666666666666, 0.06666666666666667, 1.0, 1.0, 0.14285714285714288, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.4444444444444445, 0.0, 1.0, 0.5, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4629", "mrqa_squad-validation-4348", "mrqa_squad-validation-1938", "mrqa_squad-validation-6409", "mrqa_squad-validation-1195", "mrqa_squad-validation-5859", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-473", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-6998", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-2016", "mrqa_naturalquestions-validation-801", "mrqa_hotpotqa-validation-62", "mrqa_newsqa-validation-2112", "mrqa_searchqa-validation-16130", "mrqa_triviaqa-validation-7496", "mrqa_triviaqa-validation-6548"], "SR": 0.5625, "CSR": 0.68359375, "retrieved_ids": ["mrqa_squad-train-42241", "mrqa_squad-train-79402", "mrqa_squad-train-11812", "mrqa_squad-train-6695", "mrqa_squad-train-11379", "mrqa_squad-train-25000", "mrqa_squad-train-35796", "mrqa_squad-train-37261", "mrqa_squad-train-19447", "mrqa_squad-train-63287", "mrqa_squad-train-5192", "mrqa_squad-train-31192", "mrqa_squad-train-2183", "mrqa_squad-train-80740", "mrqa_squad-train-37059", "mrqa_squad-train-65904", "mrqa_squad-train-86502", "mrqa_squad-train-58855", "mrqa_squad-train-64678", "mrqa_squad-train-21996", "mrqa_squad-train-26707", "mrqa_squad-train-67377", "mrqa_squad-train-48915", "mrqa_squad-train-66614", "mrqa_squad-train-84723", "mrqa_squad-train-75262", "mrqa_squad-train-58100", "mrqa_squad-train-78512", "mrqa_squad-train-39691", "mrqa_squad-train-73159", "mrqa_squad-train-32815", "mrqa_squad-train-56785", "mrqa_squad-validation-8841", "mrqa_squad-validation-1827", "mrqa_squad-validation-3985", "mrqa_naturalquestions-validation-2102", "mrqa_squad-validation-7364", "mrqa_searchqa-validation-2568", "mrqa_squad-validation-6965", "mrqa_naturalquestions-validation-3672", "mrqa_naturalquestions-validation-9240", "mrqa_squad-validation-7357", "mrqa_hotpotqa-validation-1471", "mrqa_squad-validation-8459", "mrqa_squad-validation-7525", "mrqa_squad-validation-6072", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-8356", "mrqa_triviaqa-validation-5855", "mrqa_searchqa-validation-14194", "mrqa_squad-validation-3718", "mrqa_naturalquestions-validation-8792", "mrqa_hotpotqa-validation-4815", "mrqa_squad-validation-8471", "mrqa_squad-validation-7338", "mrqa_squad-validation-5588", "mrqa_squad-validation-2943", "mrqa_squad-validation-4572", "mrqa_squad-validation-3812", "mrqa_searchqa-validation-15194", "mrqa_naturalquestions-validation-844", "mrqa_squad-validation-5818"], "EFR": 0.8928571428571429, "Overall": 0.7882254464285714}, {"timecode": 8, "before_eval_results": {"predictions": ["cytokines", "William Pitt", "North Carolina", "p-adic norm", "Hassan al Banna", "Gottfried Fritschel", "\"The Day of the Doctor\"", "ular plastoglobulus", "pound-force", "the Song dynasty", "Dorothy and Michael Hintze", "The Small Catechism", "36", "Giacomo della Porta", "April 20", "biomass", "punishment", "K MJ-TV", "the Foreign Protestants Naturalization Act", "southern and central parts of France", "1.1 \u00d7 1011 metric tonnes", "Not designed to fly through the Earth's atmosphere or return to Earth", "Metro Trains Melbourne", "BBC 1", "$2 million", "Vince Lombardi Trophy", "Galileo", "linked groups or chains", "Mama Said", "Tiber", "1885", "James Madison", "Ryan Pinkston", "federal republic", "the chyle to the thoracic duct where it is emptied into the bloodstream at the subclavian vein", "21 June 2007", "foreign investors", "N\u0289m\u0289n\u0289\u0289", "8ft", "Bartolomeu Dias", "William Wyler", "1961", "March 1930", "Julie Adams", "Thomas Jefferson", "Majo to Hyakkihei 2", "October 29, 2015", "United States customary system", "Millerlite", "Sunday night", "Billy Hill", "Mara", "Malina Weissman", "September 6, 2019", "1773", "A lacteal", "April 26, 2005", "Jennifer Eccles", "Albert", "shot in the head during an armed robbery", "Croatia", "Drew Kesse", "six", "stop, speed racers, stop"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6440848214285715}, "metric_results_detailed": {"EM": [true, true, false, false, true, true, false, false, true, false, true, true, true, false, true, true, true, false, true, true, false, true, true, true, true, true, true, false, false, true, false, true, true, true, false, false, false, false, false, true, true, true, true, true, true, false, false, false, false, true, true, false, true, true, true, true, true, true, false, false, false, false, false, false], "QA-F1": [1.0, 1.0, 0.5714285714285715, 0.0, 1.0, 1.0, 0.0, 0.6666666666666666, 1.0, 0.5, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.4, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.75, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.6666666666666666, 0.0, 0.0, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-6355", "mrqa_squad-validation-8958", "mrqa_squad-validation-7876", "mrqa_squad-validation-8786", "mrqa_squad-validation-8184", "mrqa_squad-validation-5724", "mrqa_squad-validation-4715", "mrqa_squad-validation-4181", "mrqa_squad-validation-8769", "mrqa_naturalquestions-validation-9715", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-8339", "mrqa_hotpotqa-validation-2800", "mrqa_newsqa-validation-3043", "mrqa_searchqa-validation-2141", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-1538", "mrqa_newsqa-validation-3476"], "SR": 0.578125, "CSR": 0.671875, "retrieved_ids": ["mrqa_squad-train-35279", "mrqa_squad-train-49484", "mrqa_squad-train-4575", "mrqa_squad-train-66809", "mrqa_squad-train-38061", "mrqa_squad-train-45155", "mrqa_squad-train-38521", "mrqa_squad-train-45987", "mrqa_squad-train-25353", "mrqa_squad-train-50736", "mrqa_squad-train-31107", "mrqa_squad-train-68277", "mrqa_squad-train-36915", "mrqa_squad-train-49109", "mrqa_squad-train-28187", "mrqa_squad-train-965", "mrqa_squad-train-77176", "mrqa_squad-train-12941", "mrqa_squad-train-54126", "mrqa_squad-train-69546", "mrqa_squad-train-79516", "mrqa_squad-train-83547", "mrqa_squad-train-20811", "mrqa_squad-train-44282", "mrqa_squad-train-48786", "mrqa_squad-train-1031", "mrqa_squad-train-17736", "mrqa_squad-train-82378", "mrqa_squad-train-45106", "mrqa_squad-train-59280", "mrqa_squad-train-35208", "mrqa_squad-train-50436", "mrqa_squad-validation-4539", "mrqa_squad-validation-10388", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-5855", "mrqa_squad-validation-739", "mrqa_squad-validation-9764", "mrqa_squad-validation-7612", "mrqa_hotpotqa-validation-1471", "mrqa_squad-validation-1906", "mrqa_naturalquestions-validation-712", "mrqa_squad-validation-3998", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-10460", "mrqa_squad-validation-6965", "mrqa_squad-validation-4572", "mrqa_searchqa-validation-123", "mrqa_naturalquestions-validation-3672", "mrqa_squad-validation-3497", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-8765", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-8356", "mrqa_squad-validation-5435", "mrqa_squad-validation-10339", "mrqa_searchqa-validation-4367", "mrqa_squad-validation-5859", "mrqa_squad-validation-3946", "mrqa_naturalquestions-validation-6524", "mrqa_searchqa-validation-1156"], "EFR": 0.8518518518518519, "Overall": 0.7618634259259259}, {"timecode": 9, "before_eval_results": {"predictions": ["in an attempt to emphasize academics over athletics", "3,600", "nine", "individual states and territories", "30%\u201350% O2 by volume", "one of his wife's ladies-in-waiting", "liquid phase", "their greatest common divisor is one", "Europe", "the cell membrane", "\"Professor Sherlockarty to the Doctor's Sherlock Holmes\"", "Laverne & Shirley", "carbohydrates", "his butchery", "Jean Ribault", "March 2011", "Continental Edison Company in France", "2010", "more equality in the income distribution", "X reduces to Y", "38", "1887", "1469", "a \"world classic of epoch-making oratory.\"", "up to half the carbon fixed by the Calvin cycle", "B0-E1-D2-G2", "WD-40", "Gretchen Wilson", "Georgie Porgie", "Vodka", "William Shaksper", "The Fray", "Venus", "Helen Hayes", "Canberra", "Million Dollar Baby", "Alexander Graham Bell", "Anna Pavlova", "a person who computes premium rates, dividends, risks, etc.", "Lasorda", "Azuki beans", "Chicago Cubs", "the flag of Mongolia", "a goat", "a father of seven", "the Medal", "a skydiving accident", "the lake named for this man receives the Victoria Nile from Lake Victoria", "a dual role", "the chimney", "Andrew Jackson", "Madonna", "Fauves", "a sailfish", "a metallic barrette", "Matilda Fitzwater", "Egypt", "James Hutton", "Morocco", "Stuart Neame", "Total Nonstop Action Wrestling", "Hirsch index rating of all living chemists", "China and Japan", "The United Nations is calling on NATO to do more to stop the Afghan opium production"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6693709935897436}, "metric_results_detailed": {"EM": [false, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, false, true, true, true, true, true, true, true, true, false, true, true, true, false, false, true, true, true, true, false, true, false, false, false, false, true, false, false, false, false, false, false, false, true, true, true, false, true, false, false, false, true, true, false, true, false, false, false], "QA-F1": [0.923076923076923, 1.0, 1.0, 1.0, 0.4, 1.0, 1.0, 1.0, 1.0, 1.0, 0.8333333333333334, 1.0, 1.0, 1.0, 1.0, 1.0, 0.7499999999999999, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.6666666666666666, 0.0, 0.6666666666666666, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.5, 1.0, 0.6, 0.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-7943", "mrqa_squad-validation-3687", "mrqa_squad-validation-7700", "mrqa_squad-validation-1240", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-10856", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-1053", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-11532", "mrqa_searchqa-validation-13151", "mrqa_searchqa-validation-13600", "mrqa_searchqa-validation-3613", "mrqa_searchqa-validation-16627", "mrqa_searchqa-validation-15202", "mrqa_searchqa-validation-6445", "mrqa_searchqa-validation-6463", "mrqa_searchqa-validation-11137", "mrqa_searchqa-validation-15770", "mrqa_naturalquestions-validation-1378", "mrqa_triviaqa-validation-6421", "mrqa_hotpotqa-validation-929", "mrqa_newsqa-validation-1007", "mrqa_newsqa-validation-2179"], "SR": 0.578125, "CSR": 0.6625, "retrieved_ids": ["mrqa_squad-train-75157", "mrqa_squad-train-15139", "mrqa_squad-train-15260", "mrqa_squad-train-79547", "mrqa_squad-train-28117", "mrqa_squad-train-7044", "mrqa_squad-train-78493", "mrqa_squad-train-50441", "mrqa_squad-train-74443", "mrqa_squad-train-40317", "mrqa_squad-train-48552", "mrqa_squad-train-52264", "mrqa_squad-train-36757", "mrqa_squad-train-59750", "mrqa_squad-train-16534", "mrqa_squad-train-10787", "mrqa_squad-train-7015", "mrqa_squad-train-71429", "mrqa_squad-train-58777", "mrqa_squad-train-40209", "mrqa_squad-train-49264", "mrqa_squad-train-19069", "mrqa_squad-train-15409", "mrqa_squad-train-42483", "mrqa_squad-train-35711", "mrqa_squad-train-63266", "mrqa_squad-train-35762", "mrqa_squad-train-42134", "mrqa_squad-train-17382", "mrqa_squad-train-57828", "mrqa_squad-train-10008", "mrqa_squad-train-46001", "mrqa_naturalquestions-validation-8934", "mrqa_hotpotqa-validation-62", "mrqa_searchqa-validation-3451", "mrqa_newsqa-validation-429", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-2016", "mrqa_searchqa-validation-123", "mrqa_squad-validation-10143", "mrqa_naturalquestions-validation-4644", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-129", "mrqa_searchqa-validation-11367", "mrqa_squad-validation-6439", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-6211", "mrqa_squad-validation-4539", "mrqa_squad-validation-6965", "mrqa_squad-validation-5435", "mrqa_searchqa-validation-2579", "mrqa_naturalquestions-validation-3442", "mrqa_squad-validation-8904", "mrqa_squad-validation-7364", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-712", "mrqa_squad-validation-7357", "mrqa_squad-validation-8459", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-1415", "mrqa_squad-validation-7332", "mrqa_naturalquestions-validation-6106", "mrqa_searchqa-validation-5631"], "EFR": 0.8888888888888888, "Overall": 0.7756944444444445}, {"timecode": 10, "UKR": 0.7890625, "OKR_sampled_ids": ["mrqa_hotpotqa-validation-21", "mrqa_hotpotqa-validation-2800", "mrqa_hotpotqa-validation-4886", "mrqa_hotpotqa-validation-62", "mrqa_hotpotqa-validation-929", "mrqa_naturalquestions-validation-10039", "mrqa_naturalquestions-validation-10156", "mrqa_naturalquestions-validation-10298", "mrqa_naturalquestions-validation-10311", "mrqa_naturalquestions-validation-10348", "mrqa_naturalquestions-validation-10460", "mrqa_naturalquestions-validation-10554", "mrqa_naturalquestions-validation-10670", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1187", "mrqa_naturalquestions-validation-1220", "mrqa_naturalquestions-validation-129", "mrqa_naturalquestions-validation-1309", "mrqa_naturalquestions-validation-1378", "mrqa_naturalquestions-validation-1385", "mrqa_naturalquestions-validation-1863", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-1911", "mrqa_naturalquestions-validation-1987", "mrqa_naturalquestions-validation-2368", "mrqa_naturalquestions-validation-2395", "mrqa_naturalquestions-validation-2452", "mrqa_naturalquestions-validation-2466", "mrqa_naturalquestions-validation-2659", "mrqa_naturalquestions-validation-291", "mrqa_naturalquestions-validation-2934", "mrqa_naturalquestions-validation-2969", "mrqa_naturalquestions-validation-3028", "mrqa_naturalquestions-validation-3055", "mrqa_naturalquestions-validation-307", "mrqa_naturalquestions-validation-3302", "mrqa_naturalquestions-validation-3329", "mrqa_naturalquestions-validation-3332", "mrqa_naturalquestions-validation-3392", "mrqa_naturalquestions-validation-3394", "mrqa_naturalquestions-validation-3442", "mrqa_naturalquestions-validation-3558", "mrqa_naturalquestions-validation-3672", "mrqa_naturalquestions-validation-3898", "mrqa_naturalquestions-validation-3935", "mrqa_naturalquestions-validation-4002", "mrqa_naturalquestions-validation-4071", "mrqa_naturalquestions-validation-4096", "mrqa_naturalquestions-validation-430", "mrqa_naturalquestions-validation-4326", "mrqa_naturalquestions-validation-4348", "mrqa_naturalquestions-validation-4505", "mrqa_naturalquestions-validation-4517", "mrqa_naturalquestions-validation-4674", "mrqa_naturalquestions-validation-469", "mrqa_naturalquestions-validation-4697", "mrqa_naturalquestions-validation-4823", "mrqa_naturalquestions-validation-4880", "mrqa_naturalquestions-validation-4906", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-5067", "mrqa_naturalquestions-validation-5087", "mrqa_naturalquestions-validation-5160", "mrqa_naturalquestions-validation-5211", "mrqa_naturalquestions-validation-5348", "mrqa_naturalquestions-validation-5477", "mrqa_naturalquestions-validation-5509", "mrqa_naturalquestions-validation-5676", "mrqa_naturalquestions-validation-5709", "mrqa_naturalquestions-validation-5709", "mrqa_naturalquestions-validation-5721", "mrqa_naturalquestions-validation-5739", "mrqa_naturalquestions-validation-5780", "mrqa_naturalquestions-validation-5817", "mrqa_naturalquestions-validation-5998", "mrqa_naturalquestions-validation-5999", "mrqa_naturalquestions-validation-6088", "mrqa_naturalquestions-validation-6106", "mrqa_naturalquestions-validation-6276", "mrqa_naturalquestions-validation-6289", "mrqa_naturalquestions-validation-6347", "mrqa_naturalquestions-validation-6358", "mrqa_naturalquestions-validation-6461", "mrqa_naturalquestions-validation-6500", "mrqa_naturalquestions-validation-6524", "mrqa_naturalquestions-validation-6998", "mrqa_naturalquestions-validation-7095", "mrqa_naturalquestions-validation-712", "mrqa_naturalquestions-validation-7242", "mrqa_naturalquestions-validation-7390", "mrqa_naturalquestions-validation-7554", "mrqa_naturalquestions-validation-7628", "mrqa_naturalquestions-validation-7694", "mrqa_naturalquestions-validation-7859", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-801", "mrqa_naturalquestions-validation-8103", "mrqa_naturalquestions-validation-8116", "mrqa_naturalquestions-validation-8189", "mrqa_naturalquestions-validation-8239", "mrqa_naturalquestions-validation-837", "mrqa_naturalquestions-validation-844", "mrqa_naturalquestions-validation-8454", "mrqa_naturalquestions-validation-8464", "mrqa_naturalquestions-validation-8514", "mrqa_naturalquestions-validation-8792", "mrqa_naturalquestions-validation-8934", "mrqa_naturalquestions-validation-8944", "mrqa_naturalquestions-validation-8983", "mrqa_naturalquestions-validation-9240", "mrqa_naturalquestions-validation-9453", "mrqa_naturalquestions-validation-955", "mrqa_naturalquestions-validation-9597", "mrqa_naturalquestions-validation-9712", "mrqa_naturalquestions-validation-9737", "mrqa_naturalquestions-validation-9753", "mrqa_naturalquestions-validation-9818", "mrqa_newsqa-validation-1080", "mrqa_newsqa-validation-1510", "mrqa_newsqa-validation-1538", "mrqa_newsqa-validation-174", "mrqa_newsqa-validation-2042", "mrqa_newsqa-validation-2112", "mrqa_newsqa-validation-2179", "mrqa_newsqa-validation-3043", "mrqa_newsqa-validation-3331", "mrqa_newsqa-validation-429", "mrqa_newsqa-validation-825", "mrqa_searchqa-validation-1053", "mrqa_searchqa-validation-11137", "mrqa_searchqa-validation-11367", "mrqa_searchqa-validation-11532", "mrqa_searchqa-validation-1156", "mrqa_searchqa-validation-1279", "mrqa_searchqa-validation-13232", "mrqa_searchqa-validation-13600", "mrqa_searchqa-validation-14371", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-15169", "mrqa_searchqa-validation-15194", "mrqa_searchqa-validation-15202", "mrqa_searchqa-validation-15770", "mrqa_searchqa-validation-16308", "mrqa_searchqa-validation-16439", "mrqa_searchqa-validation-16546", "mrqa_searchqa-validation-16627", "mrqa_searchqa-validation-172", "mrqa_searchqa-validation-2141", "mrqa_searchqa-validation-2568", "mrqa_searchqa-validation-2579", "mrqa_searchqa-validation-3245", "mrqa_searchqa-validation-3613", "mrqa_searchqa-validation-393", "mrqa_searchqa-validation-3960", "mrqa_searchqa-validation-4258", "mrqa_searchqa-validation-4319", "mrqa_searchqa-validation-4367", "mrqa_searchqa-validation-5035", "mrqa_searchqa-validation-5149", "mrqa_searchqa-validation-5631", "mrqa_searchqa-validation-6234", "mrqa_searchqa-validation-6463", "mrqa_searchqa-validation-7514", "mrqa_searchqa-validation-792", "mrqa_searchqa-validation-8401", "mrqa_searchqa-validation-9284", "mrqa_searchqa-validation-9536", "mrqa_squad-validation-10000", "mrqa_squad-validation-10115", "mrqa_squad-validation-10136", "mrqa_squad-validation-1017", "mrqa_squad-validation-10181", "mrqa_squad-validation-10184", "mrqa_squad-validation-10217", "mrqa_squad-validation-10263", "mrqa_squad-validation-10281", "mrqa_squad-validation-10290", "mrqa_squad-validation-10321", "mrqa_squad-validation-10339", "mrqa_squad-validation-10361", "mrqa_squad-validation-10369", "mrqa_squad-validation-1038", "mrqa_squad-validation-10410", "mrqa_squad-validation-10454", "mrqa_squad-validation-10496", "mrqa_squad-validation-1095", "mrqa_squad-validation-1125", "mrqa_squad-validation-115", "mrqa_squad-validation-1156", "mrqa_squad-validation-1177", "mrqa_squad-validation-1181", "mrqa_squad-validation-1195", "mrqa_squad-validation-120", "mrqa_squad-validation-1226", "mrqa_squad-validation-1240", "mrqa_squad-validation-1254", "mrqa_squad-validation-1269", "mrqa_squad-validation-1371", "mrqa_squad-validation-1499", "mrqa_squad-validation-1521", "mrqa_squad-validation-1533", "mrqa_squad-validation-1566", "mrqa_squad-validation-1651", "mrqa_squad-validation-166", "mrqa_squad-validation-1672", "mrqa_squad-validation-1708", "mrqa_squad-validation-1748", "mrqa_squad-validation-1780", "mrqa_squad-validation-1787", "mrqa_squad-validation-1848", "mrqa_squad-validation-1863", "mrqa_squad-validation-1892", "mrqa_squad-validation-1924", "mrqa_squad-validation-1938", "mrqa_squad-validation-195", "mrqa_squad-validation-1953", "mrqa_squad-validation-1998", "mrqa_squad-validation-2019", "mrqa_squad-validation-2041", "mrqa_squad-validation-2050", "mrqa_squad-validation-2059", "mrqa_squad-validation-2108", "mrqa_squad-validation-2145", "mrqa_squad-validation-2209", "mrqa_squad-validation-2233", "mrqa_squad-validation-2241", "mrqa_squad-validation-2243", "mrqa_squad-validation-2248", "mrqa_squad-validation-2352", "mrqa_squad-validation-2365", "mrqa_squad-validation-2411", "mrqa_squad-validation-2438", "mrqa_squad-validation-2456", "mrqa_squad-validation-2463", "mrqa_squad-validation-2467", "mrqa_squad-validation-247", "mrqa_squad-validation-2521", "mrqa_squad-validation-2545", "mrqa_squad-validation-2589", "mrqa_squad-validation-2595", "mrqa_squad-validation-2642", "mrqa_squad-validation-27", "mrqa_squad-validation-2751", "mrqa_squad-validation-2820", "mrqa_squad-validation-2885", "mrqa_squad-validation-2886", "mrqa_squad-validation-2897", "mrqa_squad-validation-2943", "mrqa_squad-validation-2959", "mrqa_squad-validation-3019", "mrqa_squad-validation-3039", "mrqa_squad-validation-305", "mrqa_squad-validation-3076", "mrqa_squad-validation-3144", "mrqa_squad-validation-3164", "mrqa_squad-validation-317", "mrqa_squad-validation-3184", "mrqa_squad-validation-322", "mrqa_squad-validation-3230", "mrqa_squad-validation-3270", "mrqa_squad-validation-334", "mrqa_squad-validation-335", "mrqa_squad-validation-3358", "mrqa_squad-validation-3364", "mrqa_squad-validation-3376", "mrqa_squad-validation-3380", "mrqa_squad-validation-3392", "mrqa_squad-validation-34", "mrqa_squad-validation-3406", "mrqa_squad-validation-3435", "mrqa_squad-validation-3497", "mrqa_squad-validation-358", "mrqa_squad-validation-3605", "mrqa_squad-validation-3605", "mrqa_squad-validation-3626", "mrqa_squad-validation-3687", "mrqa_squad-validation-3703", "mrqa_squad-validation-3718", "mrqa_squad-validation-374", "mrqa_squad-validation-3769", "mrqa_squad-validation-3770", "mrqa_squad-validation-381", "mrqa_squad-validation-3824", "mrqa_squad-validation-3829", "mrqa_squad-validation-3842", "mrqa_squad-validation-3848", "mrqa_squad-validation-3852", "mrqa_squad-validation-3863", "mrqa_squad-validation-3909", "mrqa_squad-validation-3917", "mrqa_squad-validation-3946", "mrqa_squad-validation-3955", "mrqa_squad-validation-3985", "mrqa_squad-validation-3986", "mrqa_squad-validation-3998", "mrqa_squad-validation-4000", "mrqa_squad-validation-4009", "mrqa_squad-validation-402", "mrqa_squad-validation-4031", "mrqa_squad-validation-4066", "mrqa_squad-validation-4175", "mrqa_squad-validation-4181", "mrqa_squad-validation-4187", "mrqa_squad-validation-4213", "mrqa_squad-validation-4291", "mrqa_squad-validation-4312", "mrqa_squad-validation-4348", "mrqa_squad-validation-4446", "mrqa_squad-validation-4450", "mrqa_squad-validation-4452", "mrqa_squad-validation-4452", "mrqa_squad-validation-4467", "mrqa_squad-validation-4468", "mrqa_squad-validation-4509", "mrqa_squad-validation-451", "mrqa_squad-validation-4530", "mrqa_squad-validation-4538", "mrqa_squad-validation-4539", "mrqa_squad-validation-4557", "mrqa_squad-validation-4557", "mrqa_squad-validation-4572", "mrqa_squad-validation-4583", "mrqa_squad-validation-4629", "mrqa_squad-validation-4715", "mrqa_squad-validation-4838", "mrqa_squad-validation-491", "mrqa_squad-validation-494", "mrqa_squad-validation-4986", "mrqa_squad-validation-5004", "mrqa_squad-validation-5014", "mrqa_squad-validation-5019", "mrqa_squad-validation-5064", "mrqa_squad-validation-5110", "mrqa_squad-validation-5140", "mrqa_squad-validation-516", "mrqa_squad-validation-5262", "mrqa_squad-validation-5396", "mrqa_squad-validation-5436", "mrqa_squad-validation-5448", "mrqa_squad-validation-5453", "mrqa_squad-validation-5479", "mrqa_squad-validation-5493", "mrqa_squad-validation-5527", "mrqa_squad-validation-5546", "mrqa_squad-validation-5572", "mrqa_squad-validation-5588", "mrqa_squad-validation-5602", "mrqa_squad-validation-5631", "mrqa_squad-validation-5664", "mrqa_squad-validation-5677", "mrqa_squad-validation-57", "mrqa_squad-validation-5726", "mrqa_squad-validation-5750", "mrqa_squad-validation-5763", "mrqa_squad-validation-5781", "mrqa_squad-validation-5806", "mrqa_squad-validation-5818", "mrqa_squad-validation-5852", "mrqa_squad-validation-5860", "mrqa_squad-validation-5865", "mrqa_squad-validation-5960", "mrqa_squad-validation-6030", "mrqa_squad-validation-6031", "mrqa_squad-validation-6066", "mrqa_squad-validation-6069", "mrqa_squad-validation-6171", "mrqa_squad-validation-6176", "mrqa_squad-validation-6206", "mrqa_squad-validation-6222", "mrqa_squad-validation-6229", "mrqa_squad-validation-6240", "mrqa_squad-validation-6243", "mrqa_squad-validation-6319", "mrqa_squad-validation-6330", "mrqa_squad-validation-6347", "mrqa_squad-validation-6353", "mrqa_squad-validation-6355", "mrqa_squad-validation-6409", "mrqa_squad-validation-6439", "mrqa_squad-validation-6502", "mrqa_squad-validation-6517", "mrqa_squad-validation-6543", "mrqa_squad-validation-6551", "mrqa_squad-validation-6611", "mrqa_squad-validation-6649", "mrqa_squad-validation-6664", "mrqa_squad-validation-6694", "mrqa_squad-validation-6790", "mrqa_squad-validation-6815", "mrqa_squad-validation-6838", "mrqa_squad-validation-6875", "mrqa_squad-validation-6876", "mrqa_squad-validation-6879", "mrqa_squad-validation-6898", "mrqa_squad-validation-6951", "mrqa_squad-validation-6957", "mrqa_squad-validation-6965", "mrqa_squad-validation-6999", "mrqa_squad-validation-7036", "mrqa_squad-validation-7039", "mrqa_squad-validation-7064", "mrqa_squad-validation-7192", "mrqa_squad-validation-7205", "mrqa_squad-validation-7228", "mrqa_squad-validation-7260", "mrqa_squad-validation-7261", "mrqa_squad-validation-7297", "mrqa_squad-validation-7332", "mrqa_squad-validation-7338", "mrqa_squad-validation-7357", "mrqa_squad-validation-7364", "mrqa_squad-validation-7368", "mrqa_squad-validation-7380", "mrqa_squad-validation-739", "mrqa_squad-validation-7390", "mrqa_squad-validation-7422", "mrqa_squad-validation-7445", "mrqa_squad-validation-7457", "mrqa_squad-validation-7470", "mrqa_squad-validation-7492", "mrqa_squad-validation-7503", "mrqa_squad-validation-7525", "mrqa_squad-validation-7608", "mrqa_squad-validation-7612", "mrqa_squad-validation-7613", "mrqa_squad-validation-7618", "mrqa_squad-validation-762", "mrqa_squad-validation-7693", "mrqa_squad-validation-7700", "mrqa_squad-validation-7708", "mrqa_squad-validation-7717", "mrqa_squad-validation-7775", "mrqa_squad-validation-7781", "mrqa_squad-validation-7785", "mrqa_squad-validation-779", "mrqa_squad-validation-7863", "mrqa_squad-validation-7871", "mrqa_squad-validation-7917", "mrqa_squad-validation-7943", "mrqa_squad-validation-7954", "mrqa_squad-validation-7982", "mrqa_squad-validation-7984", "mrqa_squad-validation-7993", "mrqa_squad-validation-8016", "mrqa_squad-validation-8043", "mrqa_squad-validation-8093", "mrqa_squad-validation-8125", "mrqa_squad-validation-8154", "mrqa_squad-validation-8177", "mrqa_squad-validation-8184", "mrqa_squad-validation-8192", "mrqa_squad-validation-8232", "mrqa_squad-validation-8282", "mrqa_squad-validation-829", "mrqa_squad-validation-8309", "mrqa_squad-validation-8365", "mrqa_squad-validation-8414", "mrqa_squad-validation-8449", "mrqa_squad-validation-8459", "mrqa_squad-validation-8471", "mrqa_squad-validation-8484", "mrqa_squad-validation-8500", "mrqa_squad-validation-852", "mrqa_squad-validation-8568", "mrqa_squad-validation-8585", "mrqa_squad-validation-8661", "mrqa_squad-validation-8670", "mrqa_squad-validation-8670", "mrqa_squad-validation-8754", "mrqa_squad-validation-8769", "mrqa_squad-validation-8809", "mrqa_squad-validation-8841", "mrqa_squad-validation-888", "mrqa_squad-validation-8904", "mrqa_squad-validation-8925", "mrqa_squad-validation-893", "mrqa_squad-validation-8933", "mrqa_squad-validation-8958", "mrqa_squad-validation-8985", "mrqa_squad-validation-908", "mrqa_squad-validation-9095", "mrqa_squad-validation-9161", "mrqa_squad-validation-9166", "mrqa_squad-validation-9170", "mrqa_squad-validation-9173", "mrqa_squad-validation-9176", "mrqa_squad-validation-9193", "mrqa_squad-validation-9234", "mrqa_squad-validation-9403", "mrqa_squad-validation-9405", "mrqa_squad-validation-9446", "mrqa_squad-validation-9464", "mrqa_squad-validation-9556", "mrqa_squad-validation-957", "mrqa_squad-validation-9594", "mrqa_squad-validation-9615", "mrqa_squad-validation-9669", "mrqa_squad-validation-9716", "mrqa_squad-validation-9717", "mrqa_squad-validation-9764", "mrqa_squad-validation-9814", "mrqa_squad-validation-9816", "mrqa_squad-validation-9876", "mrqa_squad-validation-9907", "mrqa_squad-validation-9928", "mrqa_triviaqa-validation-2749", "mrqa_triviaqa-validation-4444", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-5855", "mrqa_triviaqa-validation-6421", "mrqa_triviaqa-validation-6548", "mrqa_triviaqa-validation-7463"], "OKR": 0.896484375, "KG": 0.4484375, "before_eval_results": {"predictions": ["Northern Europe and the Mid-Atlantic", "$2 million", "fish stocks to collapse", "Chris Keates", "its many castles and vineyards", "Selmur Productions library", "Antigone", "3.5 million", "Carolina Panthers", "1997", "A \u2192 G deamination gradients", "since 2001", "surface proteins", "1784", "Narrow alleys", "another problem", "economic growth", "John and Benjamin Green", "1530", "installed electrical arc light based illumination systems", "two", "the poor", "Irish Sweepstakes", "Pearl Jam", "Grey's Anatomy", "Textile Dyes", "Bruce Springsteen", "Wounded Knee", "Maria Callas", "Henry Moore", "Boston Red Sox", "Charlotte", "Turnberry", "Narcissus", "Howard Cosell", "Orange River", "needles", "the Holy Grail", "Smashing Pumpkins", "Fran", "Ludwig Van Beethoven", "Lake Victoria", "sea", "Dr Pepper", "FRAM", "O Pioneers", "Velvet Revolver", "Francis Bacon", "jet streams", "You Bet Your Life", "China", "Nova Scotia", "Breathless", "lion Aslan", "Franklin Pierce", "Pearl Harbor", "Michael Schumacher", "a four - page pamphlet", "pool", "Glasgow", "Event Horizon", "Hugh Dowding", "NATO fighters", "National Association of Broadcasters"], "metric_results": {"EM": 0.578125, "QA-F1": 0.6672743055555556}, "metric_results_detailed": {"EM": [true, true, false, true, false, false, true, true, false, true, true, true, false, true, true, true, false, true, true, true, true, true, false, true, true, false, true, true, true, true, true, false, false, true, true, false, true, true, true, false, true, true, false, false, true, false, true, false, false, true, false, false, false, false, true, false, true, false, false, false, false, true, true, false], "QA-F1": [1.0, 1.0, 0.888888888888889, 1.0, 0.7499999999999999, 0.4, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.0, 1.0, 1.0, 0.6666666666666666, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.5, 1.0, 0.0, 0.0, 0.0, 0.6666666666666666, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0]}}, "before_error_ids": ["mrqa_squad-validation-4326", "mrqa_squad-validation-8990", "mrqa_squad-validation-5887", "mrqa_squad-validation-22", "mrqa_squad-validation-6655", "mrqa_squad-validation-7353", "mrqa_searchqa-validation-12363", "mrqa_searchqa-validation-3530", "mrqa_searchqa-validation-11388", "mrqa_searchqa-validation-16908", "mrqa_searchqa-validation-8760", "mrqa_searchqa-validation-2761", "mrqa_searchqa-validation-7269", "mrqa_searchqa-validation-4393", "mrqa_searchqa-validation-4394", "mrqa_searchqa-validation-9148", "mrqa_searchqa-validation-6909", "mrqa_searchqa-validation-14569", "mrqa_searchqa-validation-7517", "mrqa_searchqa-validation-14361", "mrqa_searchqa-validation-2866", "mrqa_searchqa-validation-6181", "mrqa_naturalquestions-validation-5702", "mrqa_triviaqa-validation-4307", "mrqa_triviaqa-validation-6896", "mrqa_hotpotqa-validation-1843", "mrqa_newsqa-validation-1422"], "SR": 0.578125, "CSR": 0.6548295454545454, "retrieved_ids": ["mrqa_squad-train-48709", "mrqa_squad-train-74789", "mrqa_squad-train-31851", "mrqa_squad-train-81303", "mrqa_squad-train-7923", "mrqa_squad-train-28441", "mrqa_squad-train-37720", "mrqa_squad-train-84327", "mrqa_squad-train-48918", "mrqa_squad-train-7877", "mrqa_squad-train-23849", "mrqa_squad-train-11081", "mrqa_squad-train-86339", "mrqa_squad-train-61694", "mrqa_squad-train-29794", "mrqa_squad-train-17106", "mrqa_squad-train-72286", "mrqa_squad-train-35329", "mrqa_squad-train-83868", "mrqa_squad-train-19376", "mrqa_squad-train-16340", "mrqa_squad-train-45362", "mrqa_squad-train-54436", "mrqa_squad-train-8543", "mrqa_squad-train-17952", "mrqa_squad-train-48604", "mrqa_squad-train-33045", "mrqa_squad-train-52590", "mrqa_squad-train-69086", "mrqa_squad-train-3771", "mrqa_squad-train-70683", "mrqa_squad-train-78900", "mrqa_naturalquestions-validation-4924", "mrqa_naturalquestions-validation-10460", "mrqa_squad-validation-7525", "mrqa_naturalquestions-validation-4002", "mrqa_searchqa-validation-2141", "mrqa_naturalquestions-validation-8983", "mrqa_newsqa-validation-2404", "mrqa_naturalquestions-validation-7896", "mrqa_naturalquestions-validation-8277", "mrqa_naturalquestions-validation-9715", "mrqa_searchqa-validation-14480", "mrqa_searchqa-validation-15194", "mrqa_naturalquestions-validation-7080", "mrqa_squad-validation-3946", "mrqa_squad-validation-7332", "mrqa_searchqa-validation-11367", "mrqa_naturalquestions-validation-8356", "mrqa_naturalquestions-validation-191", "mrqa_naturalquestions-validation-3672", "mrqa_squad-validation-7357", "mrqa_searchqa-validation-9536", "mrqa_searchqa-validation-1279", "mrqa_squad-validation-1906", "mrqa_searchqa-validation-10372", "mrqa_squad-validation-7612", "mrqa_squad-validation-3812", "mrqa_searchqa-validation-6463", "mrqa_squad-validation-6355", "mrqa_squad-validation-7700", "mrqa_hotpotqa-validation-4815", "mrqa_squad-validation-2145", "mrqa_squad-validation-3985"], "EFR": 0.8518518518518519, "Overall": 0.7281331544612794}]}